The security of computer systems fundamentally relies on memory isolation, e.g., kernel address ranges are marked as non-accessible and are protected from user access. On affected systems, Meltdown enables an adversary to read memory of other processes or virtual machines in the cloud without any permissions or privileges, affecting millions of customers and virtually every user of a personal computer. Instead, Meltdown exploits side-channel information available on most modern processors, e.g., modern Intel microarchitectures since 2010 and potentially on other CPUs of other vendors.While side-channel attacks typically require very specific knowledge about the target application and are tailored to only leak information about its secrets, Meltdown allows an adversary who can run code on the vulnerable processor to obtain a dump of the entire kernel address space, including any mapped physical memory. The root cause of the simplicity and strength of Meltdown are side effects caused by out-of-order execution.Out-of-order execution is an important performance feature of today's processors in order to overcome latencies of busy execution units, e.g., a memory fetch unit needs to wait for data arrival from memory. We show how out-of-order execution can be combined with a microarchitectural covert channel to transfer the data from an elusive state to a receiver on the outside. We present an end-to-end attack combining out-oforder execution with exception handlers or TSX, to read arbitrary physical memory without any permissions or privileges, on laptops, desktop machines, mobile phones and on public cloud machines. In Section 7, we discuss the effects of the software-based KAISER countermeasure and propose solutions in hardware. Out-of-order execution is an optimization technique that allows maximizing the utilization of all execution units of a CPU core as exhaustive as possible. In practice, CPUs supporting out-of-order execution allow running operations speculatively to the extent that the processor's out-of-order logic processes instructions before the CPU is certain that the instruction will be needed and committed. In this paper, we refer to speculative execution in a more restricted meaning, where it refers to an instruction sequence following a branch, and use the term out-of-order execution to refer to any way of getting an operation executed before the processor has committed the results of all prior instructions.In 1967, Tomasulo [61] developed an algorithm that enabled dynamic scheduling of instructions to allow outof-order execution. AGUs, as well as load and store execution units, are directly connected to the memory subsystem to process its requests.Since CPUs usually do not run linear instruction streams, they have branch prediction units that are used to obtain an educated guess of which instruction is executed next. If the prediction was incorrect, the reorder buffer allows to rollback to a sane state by clearing the reorder buffer and re-initializing the unified reservation station.There are various approaches to predict a branch: With static branch prediction [28], the outcome is predicted solely based on the instruction itself. A virtual address space is divided into a set of pages that can be individually mapped to physical memory through a multi-level page translation Figure 2: The physical memory is directly mapped in the kernel at a certain offset. A physical address (blue) which is mapped accessible to the user space is also mapped in the kernel space through the direct mapping.are used to enforce privilege checks, such as readable, writable, executable and user-accessible. These pools are virtual memory regions in the kernel address space mapping physical pages to virtual addresses which are either required to remain in the memory (non-paged pool) or can be removed from the memory because a copy is already stored on the disk (paged pool). Combined, these memory pools will typically map a large fraction of the physical memory into the kernel address space of every process.The exploitation of memory corruption bugs often requires knowledge of addresses of specific data. In order to speed-up memory accesses and address translation, the CPU contains small memory buffers, called caches, that store frequently used data. Address space translation tables are also stored in memory and, thus, also cached in the regular caches.Cache side-channel attacks exploit timing differences that are introduced by the caches. In this section, we start with a toy example, i.e., a simple code snippet, to illustrate that out-of-order execution can change the microarchitectural state in a way that leaks information. Regardless 1 raise_exception(); 2 // the line below is never reached 3 access(probe_array [data * 4096] of whether this exception is raised due to a memory access, e.g., by accessing an invalid address, or due to any other CPU exception, e.g., a division by zero, the control flow continues in the kernel and not with the next user space instruction. Due to the exception, the instructions executed out of order are not retired and, thus, never have architectural effects.Although the instructions executed out of order do not have any visible architectural effect on registers or memory, they have microarchitectural side effects. As data is multiplied by 4096, data accesses to probe array are scattered over the array with a distance of 4 KB (assuming an 1 B data type for probe array). Iterating over all pages (e.g., in the exception handler) shows only a cache hit for page 84 This shows that even instructions which are never actually executed, change the microarchitectural state of the CPU. The toy example in Section 3 illustrated that side-effects of out-of-order execution can modify the microarchitectural state to leak information. As described in Section 2.2, the address space of every process typically includes the entire user space, as well as the entire kernel space, which typically also has all physical memory (inuse) mapped. Furthermore, we call any sequence of instructions containing at least one transient instruction a transient instruction sequence.In order to leverage transient instructions for an attack, the transient instruction sequence must utilize a secret value that an attacker wants to leak. Section 4.1 describes building blocks to run a transient instruction sequence with a dependency on a secret value.The second building block of Meltdown is to transfer the microarchitectural side effect of the transient instruction sequence to an architectural state to further process the leaked secret. Note that attacks targeting code that is executed within the context (i.e., address space) of another process are possible [40], but out of scope in this work, since all physical memory (including the memory of other processes) can be read through the kernel address space regardless.Accessing user-inaccessible pages, such as kernel pages, triggers an exception which generally terminates the application. A trivial approach is to fork the attacking application before accessing the invalid memory location that terminates the process and only access the invalid memory location in the child process. If an exception occurs within the transaction, the architectural state is reset, and the program execution continues without disruption.Furthermore, speculative execution issues instructions that might not occur on the executed code path due to a branch misprediction. Note that the receiver is not part of the transient instruction sequence and can be a different thread or even a different process e.g., the parent process in the fork-and-crash approach.We leverage techniques from cache attacks, as the cache state is a microarchitectural state which can be reliably transferred into an architectural state using various techniques [55,63,22]. Thus, depending on the secret value, the transient instruction sequence (cf. Section 4.1) performs a regular memory access, e.g., as it does in the toy example (cf. Section 3). Thus, the sender can transmit a '1'-bit by accessing an address which is loaded into the monitored cache, and a '0'-bit by not accessing such an address.Using multiple different cache lines, as in our toy example in Section 3, allows to transmit multiple bits at once. By performing a Flush+Reload attack on all of the 256 possible cache lines, the receiver can recover a full byte instead of just one bit. Finally, we discuss a concrete implementation of Meltdown allowing to dump arbitrary kernel memory with 3.2 KB/s to 503 KB/s. In the attack scenario, the attacker has arbitrary unprivileged code execution on the attacked system, i.e., the attacker can run any code with the privileges of a normal user. The transient instruction sequence acts as the transmitter of a covert channel (cf. Section 4.2), ultimately leaking the secret value to the attacker.Meltdown consists of 3 steps:Step 1 The content of an attacker-chosen memory location, which is inaccessible to the attacker, is loaded into a register.Step 2 A transient instruction accesses a cache line based on the secret content of the register.Step 3 The attacker uses Flush+Reload to determine the accessed cache line and hence the secret stored at the chosen memory location. By repeating these steps for different memory locations, the attacker can dump the kernel memory, including the entire physical memory.Listing 2 shows the basic implementation of the transient instruction sequence and the sending part of the covert channel, using x86 assembly instructions. Hence, modern operating systems always map the entire kernel into the virtual address space of every user process.As a consequence, all kernel addresses lead to a valid physical address when translating them, and the CPU can access the content of such addresses. However, Meltdown exploits the out-of-order execution of modern CPUs, which still executes instructions in the small time window between the illegal memory access and the raising of the exception.In line 4 of Listing 2, we load the byte value located at the target kernel address, stored in the RCX register, into the least significant byte of the RAX register represented by AL. The execution of a µOP can be delayed if execution units are already used to their corresponding capacity, or operand values have not been computed yet.When the kernel address is loaded in line 4, it is likely that the CPU already issued the subsequent instructions as part of the out-of-order execution, and that their corresponding µOPs wait in the reservation station for the content of the kernel address to arrive. Furthermore, processor interconnects [31,3] and cache coherence protocols [59] guarantee that the most recent value of a memory address is read, regardless of the storage location in a multi-core or multi-CPU system.When the µOPs finish their execution, they retire inorder, and, thus, their results are committed to the architectural state. If this transient instruction sequence is executed before the MOV instruction is retired (i.e., raises the exception), and the transient instruction sequence performed computations based on the secret, it can be utilized to transmit the secret to the attacker.As already discussed, we utilize cache attacks that allow building fast and low-noise covert channels using the CPU's cache. Hence, our probe array is 256 × 4096 bytes, assuming 4 KB pages.Note that in the out-of-order execution we have a noise-bias towards register value '0'. The address will be loaded into the L1 data cache of the requesting core and, due to the inclusiveness, also the L3 cache where it can be read from other cores. In step 3, the attacker recovers the secret value (step 1) by leveraging a microarchitectural side-channel attack (i.e., the receiving end of a microarchitectural covert channel) that transfers the cache state (step 2) back into an architectural state. However, as the memory access to the kernel address raises an exception that terminates the program, we use one of the methods from Section 4.1 to handle or suppress the exception.As all major operating systems also typically map the entire physical memory into the kernel address space (cf. Section 2.2) in every user process, Meltdown can also read the entire physical memory of the target machine. The reason for this bias to '0' may either be that the memory load is masked out by a failed permission check, or a speculated value because the data of the stalled load is not available yet.This inherent bias results from the race condition in the out-of-order execution, which may be won (i.e., reads the correct value), but is often lost (i.e., reads a value of '0'). Consequently, our Meltdown implementation performs a certain number of retries when the code in Listing 2 results in reading a value of '0' from the Flush+Reload attack. Due to the inherent bias of Meltdown, a cache hit on cache line '0' in the Flush+ Reload measurement, does not provide the attacker with any information. To minimize the number of cases where no cache hit on a nonzero line occurs, we retry reading the address in the transient instruction sequence until it encounters a value different from '0' (line 6). In either case, the time until exception handling or exception suppression returns the control flow is independent of the loop after the invalid memory access, i.e., the loop does not slow down the attack measurably. If we read and transmit multiple bits at once, the likelihood that all bits are '0' may be quite small for actual user data. Hence, the number of bits read and transmitted at once is a tradeoff between some implicit error-reduction and the overall transmission rate of the covert channel.However, since the error rates are quite small in either case, our evaluation (cf. Section 6) is based on the singlebit transmission mechanics.Exception Suppression using Intel TSX. In 2013, kernel address space layout randomization (KASLR) was introduced to the Linux kernel (starting from version 3.14 [11]) allowing to randomize the location of kernel code at boot time. With KASLR also the direct-physical map is randomized and not fixed at a certain address such that the attacker is required to obtain the randomized offset before mounting the Meltdown attack. We evaluated Meltdown on both Linux (cf. Section 6.1.1), Windows 10 (cf. Section 6.1.3) and Android (cf. Section 6.1.4), without the patches introducing the KAISER mechanism. We also evaluated the effect of the KAISER patches on Meltdown on Linux, to show that KAISER prevents the leakage of kernel memory (cf. Section 6.1.2). Thus, all kernel addresses are also mapped into the address space of user space applications, but any access is prevented due to the permission settings for these addresses.As Meltdown bypasses these permission settings, an attacker can leak the complete kernel memory if the virtual address of the kernel base is known. Since all major operating systems also map the entire physical memory into the kernel address space (cf. Section 2.2), all physical memory can also be read.Before kernel 4.12, kernel address space layout randomization (KASLR) was not active by default [57]. Assuming that the target system has at least 8 GB of physical memory, the attacker can test addresses in steps of 8 GB, resulting in a maximum of 128 memory locations to test. Consequently, Meltdown cannot leak any kernel or physical memory except for the few memory locations which have to be mapped in user space.We verified that KAISER indeed prevents Meltdown, and there is no leakage of any kernel or physical memory.Furthermore, if KASLR is active, and the few remaining memory locations are randomized, finding these memory locations is not trivial due to their small size of several kilobytes. Thus, Meltdown can read kernel memory which is mapped in the kernel address space, i.e., any part of the kernel which is not swapped out, and any page mapped in the paged and non-paged pool, and the system cache.Note that there are physical pages which are mapped in one process but not in the (kernel) address space of another process, i.e., physical pages which cannot be attacked using Meltdown. The device is equipped with a Samsung Exynos 8 Octa 8890 SoC consisting of a ARM Cortex-A53 CPU with 4 cores as well as an Exynos M1 "Mongoose" CPU with 4 cores [6]. Running Meltdown inside a container allows to leak information not only from the underlying kernel but also from all other containers running on the same physical host.The commonality of most container solutions is that every container uses the same kernel, i.e., the kernel is shared among all containers. We observed that if the attacker is able to trigger a legitimate load of the target address, e.g., by issuing a system call (regular or in speculative execution [40]), on the same CPU core as the Meltdown attack, the attacker can leak the content of the uncacheable pages. In this scenario, we achieved average reading rates of up to 582 KB/s (µ = 552.4, σ = 10.2) with an error rate as low as 0.003 % (µ = 0.009, σ = 0.014) using exception suppression on the Core i7-8700K over 10 runs over 10 seconds. Furthermore, on the Intel Core i7-6700K if the data resides in the L3 data cache but not in L1, the race condition can still be won often, but the average reading rate decreases to 12.4 KB/s with an error rate as low as 0.02 % using exception suppression. It can be assumed that the execution units for the load and the TLB are designed differently on ARM, AMD and Intel and, thus, the privileges for the load are checked differently and occurring faults are handled differently, e.g., issuing a load only after the permission bit in the page table entry has been checked. There is no documentation whether a fix requires the development of completely new hardware, or can be fixed using a microcode update.As Meltdown exploits out-of-order execution, a trivial countermeasure is to disable out-of-order execution completely. However, this involves a significant overhead to every memory fetch, as the memory fetch has to stall until the permission check is completed.A more realistic solution would be to introduce a hard split of user space and kernel space. Due to the design of the x86 architecture, several privileged memory locations are still required to be mapped in user space [20], leaving a residual attack surface for Meltdown, i.e., these memory locations can still be read from user space. While KVA Shadow only maps a minimum of kernel transition code and data pages required to switch between address spaces, it does not protect against side-channel attacks against KASLR [39]. Similar to Linux and Windows, macOS shared the kernel and user address spaces in 64-bit mode unless the -no-shared-cr3 boot option was set [46]. Meltdown also shows that even error-free software, which is explicitly written to thwart side-channel attacks, is not secure if the design of the underlying hardware is not taken into account.With the integration of KAISER into all major operating systems, an important step has already been done to prevent Meltdown. For these providers, changing their infrastructure to full virtualization or using software workarounds such as KAISER would both increase the costs significantly.Concurrent work has investigated the possibility to read kernel memory via out-of-order or speculative execution, but has not succeeded [13,50]. Listing 3 shows a memory dump using Meltdown on an Intel Core i7-6700K running Ubuntu 16.10 with the Linux kernel 4.8.0. The exploit dumps the memory of a specific process, provided either the process id (PID) or the process name.First, the exploit de-randomizes the kernel address space layout to be able to access internal kernel structures. As the Linux KASLR implementation only has an entropy of 6 bits [37], there are only 64 possible randomization offsets, making this approach practical.The difference between the found address and the nonrandomized base address is then the randomization offset of the kernel address space. If the direct-physical map is randomized, it can be extracted from the kernel's page offset base variable.Starting at the root of the victim's multilevel page table, the exploit can simply traverse the levels down to the lowest level.