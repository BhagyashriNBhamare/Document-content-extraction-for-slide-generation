The goal of searchable encryption (SE) is to enable a client to execute searches over encrypted files stored on an untrusted server while ensuring some measure of privacy for both the encrypted files and the search queries. We thoroughly study file-injection attacks-in which the server sends files to the client that the client then encrypts and stores-on the query privacy of single-keyword and conjunctive SE schemes. The goal of searchable encryption (SE) is to enable a client to perform keyword searches over encrypted files stored on an untrusted server while still guaranteeing some measure of privacy for both the files themselves as well as the client's queries. In light of the above, researchers have focused on the development of novel SE schemes that are much more efficient, at the expense of allowing some information to "leak" to the server [19,9,8,11,6,16,12,20,13,5]. The prevailing argument is that L1 leakage is inconsequential in practice, and so represents a reasonable sacrifice for obtaining an efficient SE scheme.In truth, the ramifications of different types of leakage are poorly understood; indeed, characterizing the real-world consequences of the leakage of existing SE schemes was highlighted as an important open question in [6]. They also ex-plored the effects of even greater leakage, and showed how query-recovery attacks could serve as a springboard for learning further information about the client's files.A different attack for query recovery was given by Liu et al. [14]. Our attacks differ in that the server must inject files, but as argued above this is easy to carry out in practice.We consider both adaptive and non-adaptive attacks, where adaptivity refers (in part) to whether the server injects files before or after the client's query is made. (Forward privacy means that the server cannot tell if a newly inserted file matches previous search queries. Our attacks still outperform prior work [10,4], having a significantly higher recovery rate and requiring a lower fraction of the client's files to be known.We additionally investigate the effectiveness of padding files with random keywords (suggested in [10,4]) as another countermeasure against our attacks. We show that the performance of our attacks degrades only slightly when such padding is used, in contrast to prior attacks that fail completely.Finally, we initiate a study of the implications of leakage on conjunctive queries, and show how to extend our attacks to this setting. The client then downloads the appropriate files.Because the token is generated deterministically from the keyword, the server can tell when queries repeat and thus learn the query pattern; the returned file identifiers reveal the file-access pattern. Our attacks rely only on knowledge of the file-access pattern, though we additionally assume that the server can identify when a specific file identifier corresponds to some particular file injected k0 k1 k2 k3 k4 k5 k6 k7File 1: k0 k1 k2 k3 k4 k5 k6 k7File 2: k0 k1 k2 k3 k4 k5 k6 k7 If file 2 is returned in response to some token, but files 1 and 3 are not, the keyword corresponding to that token is k 2 . This is reasonable to assume, even if file identifiers are chosen randomly by the client, for several reasons: (1) the server can identify the file returned based on its length (even if padding is used to mitigate this, it is impractical to pad every file to the maximum file length); (2) in SE schemes supporting updates, the server can inject a file F and then identify F with the next (encrypted) file uploaded by the client; (3) if the server can influence the queries of the client, or even if it knows some of the client's queries, then the server can use that information to identify specific injected files with particular file identifiers. This violates query privacy, which is important in its own right, and-as noted by Cash et al. [4]-can also be leveraged to violate file privacy since it reveals (some of) the keywords contained in (some of) the files. We assume for simplicity that |K| is a power of 2, and identify K with the set {0,. The attack begins by having the server generate a set F of log |K| files to be injected, where the ith file contains exactly those keywords whose ith mostsignificant bit is equal to 1. The number of injected files needed for this attack is quite reasonable; with a 10,000-keyword universe, a server who sends only one email per day to the client can inject the necessary files in just 2 weeks.Small keyword universe. For completeness and future reference, we note that the binary-search attack can be optimized if the hidden keyword is known to lie in some smaller universe of keywords, or if the server only cares about keywords lying in some subset of the entire keyword universe (and gives up on learning the keyword if it lies outside this subset). For example, in the Enron email dataset [1] with roughly 5,000 keywords (see Section 5 for further details), the average number of keywords per email is 90; only 3% of the emails contain more than 200 keywords. Using the threshold countermeasure with T = 200 would thus affect only 3% of the honest client's files, but would require the server to inject many more files in order to carry out a naive variant of the binary-search attack. Unfortunately, as we explore in detail in the following section, the threshold countermeasure can be defeated using fewer injected files via more-sophisticated attacks.Note also that the threshold countermeasure does not affect the binary-search attack with small keyword universe K 񮽙 ⊂ K, as long as |K 񮽙 | ≤ 2T . Then, in the following section, we show attacks that reduce the number of injected files even further, but based on the assumption that the server has information about some fraction of the client's files. Algorithm F ← Inject Files hierarchical(K) 1: Partition the universe into w = 񮽙|K|/T 񮽙 sub- sets K 1 ,. ,w/2 do 5:F i ← Inject Files(K 2i−1 ∪ K 2i ). In Step 3 of Inject Files hierarchical, the server injects 񮽙|K|/T 񮽙 files, and in Step 5 it injects 񮽙|K|/2T 񮽙 · ·log 2T 񮽙 files. So the total number of injected files can be improved to񮽙|K|/2T 񮽙 · (񮽙log 2T 񮽙 + 1) − 1 . We highlight again that the same injected files can be used to recover the keywords corresponding to any number of tokens; i.e., once these files are injected, the server can recover the keywords of any future searches made by the client.We remark that an adaptive version of the above attack is also possible. This requires only 񮽙|K|/T 񮽙 + log T − 1 injected files, but has the disadvantage of being adaptive and hence requires the SE scheme to not satisfy forward privacy. We let f (t) denote the exact (observed) frequency of token t, and let f (t 1 ,t 2 ) be the joint frequency 2 We stress that our attacks only rely on the content of these leaked files; we do not assume the server can identify the file identifiers corresponding to the leaked files after they have been uploaded to the server.Algorithm k ← Inject Files Single(t, K)1: Let K 񮽙 be the set of 2T keywords with estimated frequencies closest to f (t). We use f * (k) to denote the estimated frequency of keyword k, and define f * (k 1 , k 2 ) analogously. The server first constructs a candidate universe K 񮽙 for the keyword corresponding to t consisting of the 2T keywords whose estimated frequencies are closest to f (t). This means the attack only applies to SE schemes that do not satisfy forward privacy. In particular, if the observed and estimated frequencies are far apart, or the number of keywords whose estimated frequencies are close to the observed frequency is larger than 2T , the server may fail to recover the keyword corresponding to the token. A natural way to attempt to reduce the number of injected files is for the server to determine a candidate universe of size 2T for each token and then use the union of those candidate universes when injecting the files. Therefore, the recovery rate of this attack would be low.Instead, we propose a more-complex attack that recovers multiple tokens by taking into account the joint frequencies for tokens and keywords. We then use a small-universe, binary-search attack to recover the corresponding keywords exactly.Note that in the above attack the ability to tell whether a token is recovered correctly when building the ground truth is crucial-otherwise the ground-truth set could contain many incorrect associations.Parameter selection. We do so because those keywords can be recovered correctly with higher probability, as we explain next.If the leaked files are chosen uniformly from the set of all files, then using statistical-estimation theory as above the attacker can compute a value δ such that at least 99% of the time it holds that | f * (k) − f (t)| ≤ ε · f * (k), where k denotes the (unknown) keyword corresponding to t. Thus, if the attacker sets the candidate universe K t to be the set of all keywords whose estimated frequencies are within distance ε · f * (k) of f (t), the candidate universe will include the keyword corresponding to t at least 99% of the time. 9: Add (t, k t ) to G.Recover the remaining tokens, let t 2 be the set of unrecovered tokens.10: for each token t 񮽙 ∈ t 2 do 11: Set its candidate universe K t 񮽙 as the set of 2T keywords with estimated frequencies f * (k) nearest to f (t 񮽙 ). for each keyword k 񮽙 ∈ K t 񮽙 do 13: for each token/keyword pair (t, k) ∈ G do 14: If | f (t,t 񮽙 ) − f * (k, k 񮽙 )| > δ · f * (k, k 񮽙 ), For our experiments we use the Enron email dataset [1], consisting of 30,109 emails from the "sent mail" folder of 150 employees of the Enron corporation that were sent between 2000-2002. Doing so results in approximately 77,000 keywords in total.In our experiments, we chose the top 5,000 most frequent keywords as our keyword universe (as in CGPR15). Therefore, in our experiments we choose the client's queries uniformly from the keyword universe, as in CGPR15. It can be observed that our attack performs quite well even with only a small fraction of leaked files, e.g., recovering the keyword about 70% of the time once only 20% of the files are leaked, and achieving 30% recovery rate even when given only 1% of the files.Neither the IKK12 attack nor the CGPR15 attack applies when the server is given the search results of only a single token. (As noted in the previous section, the CGPR15 attack inherently requires search results for multiple tokens; this explains why the results for the CGPR15 attack in Figure 7a are almost identical to the results for their attack in Figure 6.) The number of files injected never exceeds 40, and in many cases it is even less than that. We also highlight that the number of files injected to recover the keywords associated with 100 tokens is more than an order-of-magnitude smaller than 100× the number of files injected to recover the keyword associated with a single token in the previous section.The number of files injected by our attack first increases with the fraction of leaked files, and then decreases; we briefly explain why. Prior work [10,4] suggests keyword padding as another potential countermeasure for attacks that exploit the fileaccess pattern. These countermeasures defeat the attacks in prior work, but we show that they have little effect on our attacks.We remark that keyword padding seems difficult to apply in the dynamic setting, where new files are uploaded after the initial setup done by the client. In fact, this is an over-estimate since if k is uniform then on average only half the injected files contain k.For the Enron dataset with |K| = 5, 000, F = 30, 109, 񮽙 = 560, and β = 0.6, and assuming half the injected files contain the keyword in question, the probability that the binary-search attack succeeds is 0.93. Although our attacks with partial file leakage use information about keyword frequencies and joint frequencies, they are still not significantly affected by the padding countermeasures. This is even more so the case with regard to joint frequencies, since these do not change unless two keywords are both associated with the same random file that contains neither of those keywords, something that happens with low probability.To validate our argument, we implement the padding countermeasure proposed in [4] and repeat the experiments using our attacks. In particular, it recovers only 57% of the tokens even with 100% file leakage when β = 0.2, and recovers nothing even with 100% file leakage when β = 0.6. We refer to ∩S i as the ideal access-pattern leakage for a conjunctive query, and show attacks based only on such ideal leakage. We remark, however, that no known efficient SE scheme achieves ideal leakage. We first present a non-adaptive attack to recover the keywords used in a conjunctive query involving two keywords. Since these files always contain k 2 , the search results of the conjunctive query on these injected files is exactly the same as the search results of k 1 on these files, and we can thus recover k 1 as before. Given ideal access-pattern leakage, the above attack above only works for conjunctive queries involving two keywords. For conjunctive searches using the SE scheme of Cash et al. [6], though, the above attack can be extended to work for conjunctive queries involving any number of keywords since the pairwise intersections are leaked as described earlier. 2: Find i such that neither F i 1 nor F i 2 is in the search result (i.e., to the previous attack, however, this attack does not always succeed.r i 1 = r i 2 = 0). If parameters are set appropriately, the search result on q will include some of the injected files with high probability. Since each file is generated independently, the expected number of files that match the query is n/2; moreover, the number n 񮽙 of files that match the query follows a binomial distribution and so the Chernoff bound impliesPr 񮽙 񮽙 񮽙 񮽙n 񮽙 − n 2 񮽙 񮽙 񮽙 ≥ θ √ n 2 񮽙 ≤ e −θ 2 /2 . If this file is in the search result for the query, the server learns that all the keywords involved in the query have index at most |K|/2. See Figure 12. Algorithm k ← Attack Conjunctive(q, K)1: Initialize k = / 0. 9:else 10:b = b + |K i |/2 j . It is also worth observing that the number of injected files is essentially optimal for a deterministic attack with success probability 1, because the search results on d log |K| files contain at most d log |K| bits of information, which is roughly the entropy of a conjunctive search involving d keywords from a universe of size |K|. This suggests a (partial) countermeasure that can be used in dynamic SE schemes that support updates: rather than uploading each new file as it arrives, the client should wait until there are several (say, B) new files and then upload this "batch" of B files at once. Our paper shows that file-injection attacks are devastating for query privacy in searchable encryption schemes that leak file-access patterns. We suggest, therefore, that future research on searchable encryption focus on reducing or eliminating this leakage rather than accepting it as the default. Our work also highlights the need to design efficient schemes satisfying forward privacy. It would also be of interest to explore lower bounds on the efficiency that searchable encryption can achieve as a function of how much about the file-access pattern is leaked.