Either the server needs to constantly generate, store, and transmit large keys, or it needs to receive, store, and use large keys from the clients. This paper describes a protocol, suitable for today's networks and tiny servers, in which clients transmit their code-based one-time public keys to servers. The "SYN flooding" denial-of-service attack [14] rose to prominence twenty years ago when it was used to disable an ISP in New York, possibly in retaliation for anti-spam efforts; see [9]. "SYN cookies" [4] address SYN flooding, but from a broader security perspective they are highly unsatisfactory, as we now explain.Recall that in a normal TCP connection, say an HTTP connection, the client sends a TCP "SYN" packet to the server containing a random 32-bit initial sequence number (ISN); the server sends back a "SYNACK" packet acknowledging the client ISN and containing another random ISN; the client sends an "ACK" packet acknowledging the server ISN. A SYN-flooding attacker simply sends a stream of SYNs to the server without responding to the resulting SYNACKs. If the server has enough SYN-SYNACK memory for c connections, but is receiving 100c indistinguishable SYNs per RTT, then a legitimate client's ACK fails with probability at least 99%. The server allocates memory for the established TCP connection and for the HTTP state, much more memory than would have been used for a SYN-SYNACK pair. Forcing attackers to be on-path might deter casual attackers but will not stop serious attackers (see, e.g., [15]). The bottom line is that DNS can, and at some sites does, serve any number of clients using a constant amount of server memory.Another classic example is NFS, Sun's Network File System [28]. The client of a stateful server, on the other hand, needs to either detect a server failure and rebuild the server's state when it comes back up, or cause client operations to fail.This may not sound like an important issue, but it affects the protocol in some unexpected ways. The obvious security advantage of designing a protocol to allow tiny network servers-see Section 2-is that these servers are immune to server-memory denial of service.What is not clear, however, is that tiny network servers are compatible with other security requirements. The pursuit of other security requirements has created, for example, DNS over TLS and DNS over HTTPS, and all implementations of these protocols allow attackers to trivially deny service by filling up server memory, while the original DNS over UDP allows tiny network servers that are not vulnerable to this attack.In this section we highlight three fundamental security requirements, and analyze the difficulty of building a tiny network server that meets these requirements. • We require cryptography to be protected against quantum computers.Typical cryptographic protocols such as HTTPS handle the first two requirements, and are beginning to tackle the third. For each active client, the server has to maintain per-client state for a TCP connection, plus per-client state for a TLS handshake followed by TLS packet processing, plus per-client state for HTTP. The "Trickles" network stack from Shieh, Myers, and Sirer [31,32] stores all of the server's TCP-like metadata as a cookie, and also provides an interface allowing higher-level applications to store their own state as part of the cookie. Why not apply the same generic transformation to the entire per-connection HTTPS server state X, straightforwardly obtaining a higheravailability protocol where a tiny network server stores X as a cookie on the client?The problem with this approach, in a nutshell, is packet size. This paper focuses on clients and servers connected by a network that delivers 1280-byte packets.It is not entirely inconceivable that all essential details of an HTTPS state could be squeezed into such a small packet, with enough restrictions and modifications to HTTPS. This protocol takes advantage of the small size of public keys in elliptic-curve cryptography (ECC), specifically 32 bytes for Curve25519.A DNSCurve client starts with knowledge of the server's long-term public key sG, previously retrieved from a parent DNS server. ECC public keys are small, so the traffic overhead is small; ECC operations are very fast, so there is no problem in CPU time. However, our goal is actually to upgrade to post-quantum cryptography, which uses much larger keys, creating performance problems; see below.A more efficient fix is for the server to encrypt and authenticate the 256-bit shared secret key under a key known only to the server, obtaining a cookie. The question addressed in the rest of this paper is whether tiny network servers can achieve encryption, authentication, and key erasure for much larger post-quantum keys. Niederreiter's original proposal involved some codes which turned out to be weak, but using Niederreiter's short ciphertexts with the binary Goppa codes [16] proposed by McEliece in his encryption scheme combines the benefits of both schemes.McBits, by Bernstein, Chou, and Schwabe [7], extends this public-key primitive into a full IND-CCA2 secure encryption scheme, combining it with a KEM-DEM [13] construction. The description is independent of the exact parameters; we use these for illustration purposes whenever concrete sizes are necessary and because these parameters are recommended for long-term security.The codes considered in this paper are binary codes, meaning that all entries are in {0, 1} and that computations follow the rules of IF 2 , i.e., 0 + 0 = 1 + 1 = 0, 0 + 1 = 1, 1 · 1 = 1, and, as always, 0 · a = 0 for any a. The public key is a binary matrix K = (I|K ) with n columns and n − k rows. This computation takes the first row k 1 of K and computes the dot product with e, resulting in the first bit of Ke, takes the second row k 2 to similarly produce the second bit of Ke, etc.Example 2 Continuing in the setting of Example 1 and choosing e = (0, 1, 0, 0, 0, 1, 0) ⊥ gives c = (0, 0, 1) ⊥ , the sum of the second and the sixth column.Decapsulation uses the private representation of the code to recover the vector e from Ke. For a small example like Example 1 it is easy to check all possibilities of low-weight vectors e but the complexity of these attacks grows exponentially with n and t. For code-based cryptography based on binary Goppa codes the key-size (n − k) · k grows with the security level λ (meaning an attacker takes 2 λ operations) as (c 0 + o(1))λ 2 (lg λ) 2 , with c 0 ≈ 0.7418860694, for the best attacks known today. It splits K and uses that the computation Ke can naturally be composed using parts of K and e. Let K = (I|K ) and writeK =      K 1,1 K 1,2 K 1,3 . . . K 1, K 2,1 K 2,2 K 2,3 . . . K 2, . . . . . . . . . . . . . . . K r,1 K r,2 K r,3 . . . K r,      ,where the submatrices K i, j are chosen to be approximately equally sized and small enough to fit into a network packet along with other message parts described in the next section.For ease of exposition assume that each K i, j has x columns and y rows, so k = x · and n − k = y · r; in general the pieces may have different sizes as specified by the system parameters. Upon receipt of K i, j the server computes the partial result c i, j = K i, j e j , where e j denotes the matching part of e and c i, j the matching part of the resulting vector c. For example, c 1, = K 1, e takes e as the last x positions of e, and computes the matrix-vector multiplication K 1, e resulting in the length-y vector c 1, . The first y coordinates of c are given by c 1 = e 1,0 + c 1,1 + c 1,2 + · · · + c 1, , with e 1,0 the first y positions of e.Example 3 In the setting of Example 1 submatrices may be chosen asK 1,1 = (1 1), K 1,2 = (0 1), K 2,1 = (1 0), K 2,2 = (1 1), K 3,1 = (0 1), and K 3,2 = (1 1). McTiny makes it possible for the server to compute Ke, for a big matrix K and chosen weight-t vector e (see Section 4), without requiring the server to allocate any per-client memory and without needing more temporary memory than what fits into a network packet. The details of how this shared key is computed match Classic McEliece [6] and the client can use decapsulation from Classic McEliece.Besides code-based cryptography for the public-key operations, McTiny uses authenticated encryption with symmetric keys. The PQCRYPTO recommendations [2] suggest either AES-GCM with AES-256 or Salsa20-Poly1305 with 256-bit encryption keys and 128-bit authentication keys. The server has a long-term public key pk which is used to authenticate the server and to derive a shared secret key to encrypt and authenticate all messages after the initiation message. The client and the server use S to encrypt and authenticate all following messages.In phase 1 the client sends the matrix parts K i, j to the server and the server replies with encryptions of the partial encryptions c i, j . In the McTiny protocol the server is responsible for generating a random 22-byte N from which most nonces are generated as n = (N, N 0 , N 1 ) in a deterministic way. McTiny makes heavy use of encrypted cookies to store intermediate results in the network/on the client's computer. In mctiny6960119 we specify the time interval as one minute and specify that the server remembers 8 cookie keys in any time interval, i.e. while it uses s m it also remembers s m−1 , s m−2 , . . . s m−7 but not s m−8 or earlier keys. In total, C 0 has 32 + 32 + 16 + 1 = 81 bytes and the message to the client has 40 bytes more for the nonce N, 1, 0 and the authenticator under S.(k, K) ←$ KGen ( ¯ c, ¯ C, S) ← ENC(pk) R ←$ {0, 1} 176 AE(0 : R, 0, 0 : S) hash(pk), ( ¯ c, ¯ C), (R, 0, 0) S ← DEC( ¯ c, ¯ C, sk) N ←$ {0, 1} 176 E ←$ SeedGen s m ← current cookie key C 0 ← (AE(S, E : N, 1, 0 : hash(s m )), mmodAE(K i, j : N, 2(i − 1), 64 + j − 1 : S) C 0 , (N, 2(i − 1), 64 + j − 1) handle C 0 , M, s m . . . Recover S, E from C 0 s m ← current cookie key C 0 ← (AE(S, E : N, 1, 0 : hash(s m )), m mod 8) s ← hash(s m , S) M ←$ {0,1} Phase 1 sends the matrix pieces K i, j to the server which then computes the partial matrix-vector products as described in Section 5. Here we detail the cryptographic protections for this computation.For every partial matrix K i, j the client sends AE(K i, j : N, 2(i − 1), 64 + j − 1 : S),C 0 , (N, 2(i − 1), 64 + j − 1) to the server, where 1 ≤ i ≤ r is the row position and 1 ≤ j ≤ is the column position. The server then recomputes C 0 = (AE(S, E : N, 1, 0 : hash(s m )), b), using the current cookie key s m and the same nonce N, 1, 0 as before. It picks a fresh 22-byte random nonce M, sends AE(C 0 ,C i, j : M, 2i − 1, 64 + j − 1 : S), (M, 2i − 1, 64 + j − 1) to the client, and forgets all data related to the client.The client verifies, decrypts, updates C 0 , and stores C i, j for future use. Once the client has obtained all blocks in one batch-this may be part of a row as C i,wJ+1 ,C i,wJ+2 , . . . ,C i,wJ+w or cover one or several rows asC iv−v+1,1 ,C iv−v+1,2 , . . . ,C iv−v+1, , . . . ,C iv,1 ,C iv,2 , . As described in Section 5, the server computes c j = e j,0 + c j,1 + c j,2 + · · · + c j, , with e j,0 the matching y positions of e. Finally it sends AE(C 0 , c iv−v+1 , c iv−v+2 , . . . , c iv :M, 2i − 1, 64 + 32 : S), (M, 2i − 1, 64 + 32). The client verifies, decrypts, updates C 0 , and stores c iv−v+1 , c iv−v+2 , . . . , c iv for future use. The McTiny key exchange ends at this point, and the client communicates securely with the server using session key Z. Details of a session protocol are outside the scope of this paper, but the main point is that the client can include (C Z , M) in subsequent packets so that the server can reconstruct Z. Any packet back includes an updated cookie (C Z , M) using a fresh nonce; the session protocol can update Z here for prompt key erasure within a session. Traffic is encrypted under the key Z exchanged by the McTiny protocol, so the question is whether the attacker learns Z for past connections.The secret key sk allows the attacker to decapsulate all KEM messages ever sent to the server (phase 0) and obtain all shared keys S. However, unless there is a security problem with the McEliece system, the attacker cannot determine Z from this ciphertext.By stealing the server, the attacker also learns the server's recent cookie keys s m , . . . , s m−z+1 . Cookies are often repeated across packets, but this linking of packets is already clear from simple traffic analysis.Here is what the attacker sees for an older McTiny connection, a connection that completed more than z intervals before the theft: the client's short-term McEliece public key K (in blocks K i, j ); a random ciphertext (c,C) sent to this key, communicating a secret key Z to the client; and the cookies C 0 and C i, j for 1 ≤ j ≤ , 1 ≤ i ≤ r.The shared secret Z could be computed from E included in C 0 , but the keys to all the C 0 cookies are erased.Each c i j includes information on e as a much simpler decoding problem, but the c i j are encrypted in the C i j under erased cookie keys. An attacker planning to steal a server in the future has an interest in keeping a connection alive by replaying messages from the client. If AE is AES-GCM, and an attacker sees AE(T 1 : N : S) and AE(T 2 : N : S) for T 1 = T 2 , then the attacker can also produce authenticators for arbitrary ciphertexts under (N : S) for any N . Our choice of XSalsa20-Poly1305 for AE limits the impact, but the attacker can still produce authenticators for arbitrary ciphertexts under (N : S). This makes the choice of nonce deterministic for each encryption and the same nonce and key are used when retransmitting in the same phase, but only to encrypt the same plaintext.The attacker also sees C 0 = (AE(S, E : N, 1, 0 : hash(s m )), m mod 8) using several cookie keys s m under the same nonce N, 1, 0. The Classic McEliece KEM is secure against active attacks, hence the shared secret S is not known to the attacker. For the outer encryption a random M (or N in phase 0) is chosen, hence only the last two bytes of the nonce repeat, the rest of the nonce differs, meaning no loss in security. Initiating a new connection and thus changing E leads to a fresh choice of N.The malicious client can send K 11 and K 11 , likely causing c 11 = c 11 . The McTiny protocol is designed to make the well-studied McEliece cryptosystem practical for tiny network servers. This means that even an active attacker with a quantum computer cannot break the public-key encryption.All of the keys for symmetric cryptography are 32 bytes, providing ample protection against Grover's algorithm and the choice of XSalsa20-Poly1305 for AE follows recommendations for post-quantum security. The implementation is now available at https://mctiny.org. Our software provides four main tools:• master creates a new mctiny6960119 server identity: a long-term public key and a long-term secret key. We reused existing Classic McEliece software [6] for key generation (in master for long-term keys, and in client for short-term keys), encryption (in client for long-term keys), and decryption (in server for long-term keys, and in client for short-term keys). The tests described below use version 20191017 of SUPERCOP, the latest version at the time of this writing.For our new McTiny software components, we selected the C programming language, with the goal of eliminating unnecessary performance overheads. 5 We wrote new cryptographic software for mctiny6960119's matrix-partitioning encryption (in server), ensuring compatibility of the final result with Classic McEliece. The file mctiny.h is output by a 160-line mctiny.py that supports variations in McTiny parameters. The "c" and "h" columns are the number of lines in file.c and file.h. Sizes of binaries listed here include sizes for cryptographic software imported from SUPERCOP (e.g., the Classic McEliece software), but do not include sizes for standard shared libraries from the OS (e.g., getaddrinfo). SUPERCOP's latest benchmarks report the following speeds for mceliece6960119 on one Haswell core: 0.71 · 10 9 cycles median for keygen (with high variance: the quartiles are 0.50 · 10 9 and 1.31 · 10 9 ), 153 944 cycles for enc (much less variance: quartiles 148 612 and 169 396), and 305 880 cycles for dec (quartiles 304 616 and 306 232). To estimate the total server time, we ran a series of 1000 key exchanges and observed in ps that the server process had accumulated 17 seconds of CPU time, i.e., 17 milliseconds (53 million cycles on one CPU core) per key exchange. Within the 44.4 million cycles, 20.8 million cycles (standard deviation 0.4 million cycles) were spent on the core cryptographic computations in phase 1: regenerating the lowweight vector from a seed and computing the corresponding partial encryption. In our server software, the maximum cycles per byte are spent in McEliece decapsulation for the first packet, about 400 cycles per byte to handle 810 bytes of application-layer data (and slightly fewer cycles per byte when bandwidth overhead is taken into account). We built the server software to avoid allocating memory in response to client packets; we audited the source code for this property; and we checked with strace that, once the program entered its packet-handling loop, its system calls consisted entirely of recvfrom, sendto, and an occasional 6 key-file access. In short, this is a tiny network server, making it immune to server-memory denial of service.The previous sections have shown that at very little overhead in the number of packets and a few extra round trips, the conservative McEliece system can be fit into tiny network servers for forward secrecy without using any per-client memory.Server operators might be concerned about the generous usage of randomness on the server side. As a running example, this appendix reports measurements of data transfer between one computer in the United States and another computer in Europe. The flow of data in a protocol implies that a certain number of round trips must be consumed, no matter how much bandwidth is available for sending packets in parallel.To see that this is not the complete picture, consider a test TCP server that accepts a connection and then sends a serverspecified amount of data over the connection. Evidently only 1.25 megabytes per second were being transmitted during these 0.832 seconds.One might try to explain this as the total 12.5-megabyteper-second bandwidth being split across 10 users, so that each user has only 1.25 megabytes per second of available bandwidth. Suppose a router receives packets on a fast LAN more quickly than it can deliver those packets to the Internet. The details are the topic of thirty years of active research.In particular, when a TCP connection begins, the sender starts slowly, in case the network does not have much available bandwidth. The horizontal position is the total number of bytes in all packets that have been sent, including the application-layer data (eventually reaching 1 megabyte) and 78 bytes of per-packet overhead: 20-byte TCP header, 20-byte IPv4 header, 26-byte Ethernet header, and 12 bytes of spacing between Ethernet packets. We ran ethtool --offload eth0 tx off rx off to disable TCP segmentation offload, so that the same tools would show the packets on the wire; we did not find any resulting differences in TCP latency.Each network packet received by the server produces a blue cross and a green cross in the figure, at the time in seconds when the server receives the packet. Comparing the figures also shows that BBR sent slightly more acknowledgment traffic (590 packets from the client, consuming 46 028 bytes including per-packet overhead) than CUBIC did, and also that BBR sent more data between time 0.702 and time 0.819 than CUBIC did, saving time overall.The bottom line is that, because of congestion control, TCP takes about 9.1 round-trip times to send 1MB using CUBIC, or 8.5 round-trip times to send 1MB using BBR. For comparison, Figures 2 and 3 show times on the server, but in those cases the 1MB of data was being sent by the server whereas in Figure 4 the 1MB of data is being sent by the client.As the figure shows, our BBR implementation paces packets somewhat more smoothly than the Linux TCP BBR implementation, but overall we increase rate along essentially the same curve as in Figure 3. There is more data sent and received in Figure 4 than in Figure 3-there is more overhead in each packet for cryptographic protection, data is sent in somewhat smaller packets, and each packet is acknowledged-but this makes relatively little difference in latency.To summarize, our McTiny software is using the network in this example with similar efficiency to TCP, plus two roundtrip times for final cleanup in the McTiny protocol.