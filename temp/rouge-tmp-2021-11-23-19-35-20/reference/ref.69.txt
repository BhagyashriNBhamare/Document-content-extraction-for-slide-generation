We demonstrate that an untrusted operating system can observe enclave page accesses without resorting to page faults, by exploiting other side-effects of the address translation process. We contribute two novel attack vectors that infer enclaved memory accesses from page table attributes, as well as from the caching behavior of unprotected page table memory. Xu et al. [48] first showed how a malicious OS can use page faults as a noise-free controlled-channel to extract rich information (full text and images) from a single run of a victim enclave. The research community has since proposed a number of compile-time and hardware-enabled defense techniques [40,10,39] that hide enclave page accesses from the OS. â€¢ We demonstrate the effectiveness of our attacks by extracting private EdDSA session keys from the widely used Libgcrypt cryptographic library.Our attack framework and evaluation scenarios are available as free software, licensed under GPLv3, at https://github.com/jovanbulck/sgx-pte. Recent Intel x86 processors from Skylake onwards are being shipped with Software Guard eXtensions (SGX) [32,1,23] that enable strong, hardware-enforced trusted computing guarantees in an untrusted execution environment. SGX extends the instruction set and memory access logic of the Intel architecture to allow the execution of securitysensitive application logic in protected enclaves in isolation from the remainder of the system, including privileged OS or hypervisor.Memory Protection. The PRM region is subdivided into two data structures: the Enclave Page Cache (EPC) and the Enclave Page Cache Map (EPCM). SGX furthermore offers dedicated ring-zero instructions to securely evict and reload enclave pages between EPC memory and untrusted storage.An important design decision of SGX is that it leaves page tables under explicit control of the untrusted operating system. Furthermore, a page fault is signaled to the untrusted OS for EPC accesses that either do not belong to the currently executing enclave, are accessed through an unexpected virtual address, or do not comply with the read/write/execute permissions imposed by the EPCM.To speed up subsequent memory accesses, SGX employs the processor's Translation Lookaside Buffer (TLB) as a trusted cache of already checked page permissions. SGX therefore flushes the TLB and internal paging-structure caches whenever entering or exiting an enclave, and requires the OS to engage in a hardwareverified protocol that ensures proper TLB invalidation before evicting an EPC page.SGX's dual permission lookup scheme prevents malicious system software from mounting active memory mapping attacks [9]. However, this design also implies that an attacker controlling page table permissions can cause enclave code to cause page faults, and be notified when certain pages are accessed. In case of a page fault, SGX also takes care of zeroing out the twelve least significant bits of the faulting address, revealing only the page number, but not the 12-bit offset within that page.Importantly, SGX enclave threads are unaware of interrupts by design, and have to be resumed explicitly by invoking eresume from the unprotected application context. Since eresume cannot be intercepted however, an enclave has no way of enforcing its internal exception handler to be actually called.SGX's exception model ensures that the untrusted operating system remains in control of shared platform resources such as memory or CPU time, and prevents direct information leakage of register contents. Like previous SGX attacks [48,40,13,37,28], we finally assume knowledge of the (compiled) source code of the target application.At the system level, we assume a classical MMU-based architecture where the system software maintains a multilevel page table data structure in OS memory to control virtual to physical page mappings. As explained above, a page fault during enclave execution triggers an AEX that hands over control to the untrusted operating system, revealing the base address of the faulting page. Their controlled-channel attacks exploit secret-dependent control flow and data accesses in unmodified legacy applications running on top of the SGX-based Haven [3] architecture. Shinde et al. [40] introduce the notion of PF-obliviousness which requires that any information leaked via page fault patterns can also be learned from running the program without inducing any page faults. The hardware is modified to report page faults directly to the enclave, without OS intervention, so as to enable protected enclave programs to detect contract violations. The enclave's fault handler can decide to either forward the page fault to the OS, abort the enclave program, or perform a fake execution to hide the page fault completely.It seems that Intel made a first step towards supporting contractual execution on SGX platforms. Since TSX lacks hardware support to distinguish between page faults and regular interrupts in the abort handler, T-SGX restarts transactions by default, and only terminates the enclave program after counting too many consecutive aborts of the same transaction. T-SGX prevents reruns by requiring the remote enclave owner's consent before starting the enclaved application.Note that T-SGX does not consider frequent enclave preemptions suspicious (up to 10 consecutive transaction aborts are allowed for each individual basic block). Not only does Sanctum dispatch page faults directly to enclaves, but it also allows them to maintain their own virtual-to-physical mappings in a separate page table hierarchy in enclave-private memory. We finally explain how to infer conditional control or data flow in large programs by correlating subsequent page accesses in page sets as a more stealthy alternative to the page fault sequences introduced by Xu et al. [48]. Our attacks are based on the important observation that a processor in enclave mode accesses unprotected page table memory during the address translation process.1 void inc_secret (int s) { 2 if (s) 3 * a += 1; 4 else 5 * b += 1; 6 } 1 int compare_and_swap ( int old, int new) { 2 if ( * a == old) 3 return ( * a=new);The key intuition is to exploit side-effects of the page table walk to identify which page has been accessed. A/D attributes are stored in kernel-space memory, alongside the physical address of the page being referenced by the corresponding PTE entry, and need to be explicitly cleared by software.We experimentally confirmed that A/D bits are also updated in enclave mode. Cache memories introduce a measurable timing difference for DRAM accesses and enable a powerful class of microarchitectural side-channel attacks, for they are shared among all software running on the platform.A reliable and powerful class of access-driven cache attacks based on the FLUSH+RELOAD [50] technique exploits the availability of physical shared memory between the attacker and the victim, as is often the case with shared libraries. Afterwards, she carefully times the amount of time it takes to reload the data, so as to determine whether or not the address has been accessed by the victim in the meantime.One cannot directly apply FLUSH+RELOAD techniques to SGX enclaves, since the clflush instruction requires read permissions on the provided memory location [23]. Since page table entries are stored in regular DRAM, they are subject to the same caching mechanisms as any other memory location [23,15] Additionally, modern Intel CPUs employ an internal paging-structure cache for page table entries that reference other paging structures (but not those that map pages), and cache physical addresses in the TLB. However, since the data cache hierarchy remains explicitly untouched, an adversarial OS can perform a FLUSH+RELOAD-based cache timing attack on the page table itself.In our inc_secret running example, a kernel-space attacker uses clflush to evict the last-level PTEs referenced by a as well as b, before entering the enclave. This is not really a practical concern, however, since previous fault-based attacks [48,40] do not rely specifically on write accesses. PTE monitoring at a cache line granularity can thus conveniently be modelled as spying on enlarged (8 * 4 KB= 32 KB) pages. For now, we assume the ec_mul function is situated on code page P 1 , whereas the subroutines point_double and point_add are located on distinct pages P 2 and P 3 . Previous fault-driven attacks [40] recovers the private scalar by observing different page fault sequences for iterations corresponding to a one (P 1 , P 2 , P 1 , P 3 , P 1 , P 2 ) or zero (P 1 , P 2 , P 1 , P 2 ) bit.The key difference in our stealthy attacker model, as compared to the page fault channel, is that we are not notified in case of a memory access. The main challenge now becomes that SGX caches address translations in the TLB, implying that only the first access to a specific page results in a page table walk. We explicitly interrupt the enclaved victim application in order to reliably evict cached address translations without provoking page faults. In this respect, note that concurrent, unpublished work [46] has demonstrated that Intel's HyperThreading technology can be abused to evict TLB entries from a co-resident logical processor in real-time, without interrupting the victim enclave.Our spy thread monitors one or more page table entries in a tight loop, preempting the victim enclave CPU after a page access has been detected. From the point of view of the enclave, IPIs are directly handled by the CPU's local Advanced Programmable Interrupt Controller (APIC), and are thus indistinguishable from regular interrupts sent by a benign operating system.Monitoring A/D Bits. Naturally, the probability of an overlapping victim access increases as the length of the time slot decreases, whereas a longer time slot increases detection latency and might miss subsequent memory accesses by the victim. Moreover, the victim only makes a single memory access to the monitored PTE entry, for subsequent accesses to the same page hit the TLB. Spying on page table memory the FLUSH+FLUSH way thus ensures we can see all page accesses with a minimal detection latency.FLUSH+FLUSH also confronts us with a new challenge however, since the microarchitectural timing differences of the clflush instruction are inherently more subtle than the apparent timing penalty for a DRAM access in FLUSH+RELOAD [16]. In this respect, a fault-driven attack can be modelled as having zero latency between detecting a page access and interrupting the victim.Page Fault Sequences. Xu et al. [48] overcome this challenge by identifying unique page fault sequences that lead to a particular code or data access. Since a PF-aware attacker does not have to cope with latency in the measurement process, she may construct page access sequences at instruction-level granularity.In the running example of Fig. 3, the ec_mul function on P 1 serves as a trampoline to redirect control flow to either point_double on page P 2 or point_add on page P 3 , based on the secret scalar bit under consideration. Where a page fault only leaks one bit of information (i.e., the trigger page was accessed), our notion of page sets allows a spy to capture the maximum information for every trigger page interrupt.Applying our page set theory to the running example of Fig. 3, the spy thread monitors the trigger page P 2 holding a.o., point_double, and matches the page set {P 1 , P 3 } on every interrupt. Finally, in case P 1 as well as P 3 were both not accessed, P 2 must have been accessed from an execution context other than the targeted point_double invocation, and we classify the interrupt as a false positive.After identifying secret-dependent control flow or data accesses in the victim application, a successful attack comes down to designating specific pages to be tracked in the spy thread, and recognizing the associated page set patterns. Analogous to previous fault-based attacks [48,40], we first perform a detailed offline analysis of the enclaved application binary to extract an ideal trace of instructiongranular page accesses for a known input. From this ideal trace, we select a suitable candidate trigger page, and we construct the sets of all pages accessed or not accessed in between two hits on the trigger page. The libOS relies on a small Platform Adaptation Layer (PAL) to translate platform-independent host ABI calls into a narrow set of system calls to the underlying host operating system, which remains, however, explicitly trusted from a security perspective.Graphene-SGX [45] -like other recently proposed SGX-based shielding systems including Haven [3], Panoply [41], and SCONE [2] -improves over this situation by not only protecting libOS instances from each other, but also from a malicious host operating system. Graphene-SGX furthermore relies on an untrusted Linux driver for enclave creation/tear down and protected memory management via the dedicated ring-zero SGX instruction set.Attack Framework. We run our core attacker code in kernel mode to be able to easily send IPIs, inspect PTE attributes, and monitor page 6 Upon detecting an access on the trigger page, the spy interrupts the victim thread as soon as possible. 7 The IPI handler on the victim CPU now establishes the access pattern for the monitored page set using either the noise-free FLUSH+RELOAD or A/D mechanism. Note that it has been shown [48] that hypothetical support for conventional address space layout randomization, which only randomizes the application's base address, could be easily defeated by observing page access patterns.Inter-Processor Interrupts. For our PF-oblivious attacks on the contrary, we define IPI latency as the number of instructions executed by the victim enclave after accessing a trigger page, and before being interrupted by the spy thread. To study the behavior of target applications, previous controlled-channel attacks [48] record a complete, byte-granular trace of page fault addresses by running the application outside of the enclave with at most one code and data page allocated at all times. We simplify this process via a GNU debugger script that extracts an instruction-granular code page trace by single-stepping through the unprotected application binary, recording the symbolic name and virtual page address of the instruction pointer. The machine runs Ubuntu 15.10, with a generic 64-bit Linux 4.2.0 kernel. Recall from Section 4 that we want to minimize the number of instructions executed by the victim enclave after accessing a trigger page, and before being interrupted by a targeted IPI from the spy thread. We repeat all experiments 10,000 times for a spy thread that monitors the trigger page through the "accessed" PTE attribute, as well as for a spy that repeatedly flushes page table memory locations. We furthermore found the technique to be reliable, for FLUSH+FLUSH recorded all 10,000 page accesses, without false positives, and with significantly less noise (smaller standard deviation) than an A/D spy.The increased advantage of a FLUSH+FLUSH spy, as opposed to a spy monitoring A/D bits, can be understood from the effects on the caching behavior of the page table walk. For the victim CPU needs to perform another memory access to reload the PTE entry from DRAM when the A bit was not set, and the corresponding cache line has been flushed by a concurrent spy thread. Interestingly, we found that the victim's second PTE memory access, where the A bit is updated, is more noticeable from a FLUSH+FLUSH spy thread. The latter can be explained from the additional page table walk that retrieves the physical memory address of the data operand for the first add instruction.Finally, we performed an experiment that entirely disables instruction and data caching on the victim CPU by setting the CR0.CD bit, as explained in Section 4. However, while the hardened algorithm of Libgcrypt v1.6.3 greatly reduces the attack surface by cutting down the amount of secret-dependent code, we show that even the short if branch on line 9 remains vulnerable to page table side-channel attacks during the public key generation phase. Our stealthy spy thread monitors the A attribute of the trigger page table entry holding the physical page address of point_set, which is accessed 126 or 127 times each iteration, depending on the scalar bit under consideration. Our A/D attack on Libgcrypt v1.6.3 interrupts the victim enclave about 60,000 times.To attack the standard multiplication (lines 14 to 18) in the latest Libgcrypt v1.7.5, we spy on the A attribute of the PTE that references the test_bit code page. The address of the error number for the current thread can be retrieved via the __errno_location function, residing at a remote location within the libc memory layout.Our stealthy FLUSH+FLUSH spy uses the code page for the __errno_location libc function as a reliable trigger page that does not share a cache line with any of the other pages accessed in the loop. While DÃ©jÃ  Vu would likely recognize frequent enclave preemptions as a side-effect of our current attack framework, we argue that heuristic defenses do not address the root causes of page table-based information leakage. In contrast, their work focusses on the A/D channel rather than PTE caching, and shows that HyperThreading technology allows TLB entries to be evicted without interrupting the victim enclave. Masking A/D attributes in enclave mode is neither sufficient nor desirable, as it cannot prevent our cache-based attacks, and disrupts benign OS memory management decisions.At the application level, we believe the academic community should investigate different defense strategies based on the type of enclave. Finally, between submission and publication of this paper, the SGX research community has witnessed a steady stream of microarchitectural side-channel attacks; either by abusing the branch prediction unit [28], or in the form of finegrained PRIME+PROBE [13,37,5,33] cache attacks.In a more general, non-PMA context, there exists a vast amount of research on microarchitectural cache timing vulnerabilities [35,50,17]. Our work shows that page table walks in unprotected memory leak enclave page accesses to untrusted system software. The PTE sets are based on plain Libgcrypt, Libgpg-error, and Graphene-libc binaries, as generated by gcc v5.2.1 from the default .