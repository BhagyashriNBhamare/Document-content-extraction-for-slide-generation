We describe and evaluate an extensible bug-finding tool, Sys, designed to automatically find security bugs in huge code-bases, even when easy-to-find bugs have been already picked clean by years of aggressive automatic checking. Sys finds many security bugs (51 bugs, 43 confirmed) in well-checked code-the Chrome and Firefox web browsers-and code that some symbolic tools struggle with-the FreeBSD operating system. One of our previous static tools-which looks for simple buggy patterns in source code, along the lines of [39,60,85,121]-found only three security bugs in browsers [40]. To address the drawbacks of both approaches, we combine them: static analysis, cheap and imprecise, achieves high recall in identifying possible errorsites, and symbolic analysis, expensive and thorough, achieves high precision in reasoning about those errorsites.Sys first uses a static analysis pass to identify potential errorsites. Fine-grained value reasoning means that symex can find bugs that static can't, but also makes symex routinely intractable, even for small programs: it reasons about all possible values, whereas simple static analysis reasons primarily about dataflows.Sys sidesteps the symex bottleneck by only symbolically executing small snippets of code that the static analysis pass flags as potentially buggy. Browser vendors classify security bugs as [53,105]: sec-high, e.g., bugs attackers can use to corrupt the browser's memory and hijack its control flow to, for instance, steal bank account information; sec-medium, e.g., bugs attackers can use to leak browser memory like login cookies; sec-low, bugs whose scope is limited, but would otherwise be considered higher severity. Finally, the mystery patch row indicates patches that are unaccounted for: they patch bugs that Sys found, but because of backports, we can't tell when they were patched.Finally, we designed Sys to be flexible, because real-world checking is a game of iterative hypothesis testing: in our experience, it takes many tries to express a property (e.g., use of uninitialized memory) correctly, and many more to suppress false positives-and both tasks often take advantage of ad hoc, program-specific information. We wanted Sys to combine the flexibility of a standard static checking framework (e.g., the Clang Static Analyzer [87,151]) with the power of a symbolic execution engine.The challenge of building a flexible symbolic checking tool is that symex is inherently complicated-it has to reason about each individual bit in the program under test-but flexibility requires that using and changing the system be easy. Sys found 51 bugs (Figure 1) in the Chrome browser, the Firefox browser, and the FreeBSD operating system, many in complicated C++ code. Sys also discovered a trio of bugs with a CVE in Firefox (CVE-2019-9805) [3], two more browser CVEs [4,7], a user-after-free bug in Firefox [14], and a bountied bug in Chrome's audio support [2]. It is easy to write new checkers (our static extensions are < 280 LOC; our symbolic checkers are ≤ 110 LOC), add false positive suppression heuristics ( §5.1,5.2), and even extend the core system ( §3). Figure 2 shows the bug, an exploitable out-of-bounds write caused by integer overflow of an allocation size. Then, the big memset on line 3419 will be out-of-bounds [1]. Our group's previous tool, KLEE [45], does whole program symbolic execution on 10-30KLOC of C, not millions of lines of C++. We walk through Sys's three steps below: (1) statically scanning the source and marking potential errors, (2) jumping to each marked location to check it symbolically, and (3) reasoning about state that Sys misses because it skips code.Static Clients write small static extensions-similar to checkers that identify patterns in source code-to quickly scan all checked code and mark potential errorsites (Figure 4). This extension looks for memory operations like malloc(x) and index operations like memset(y) where there is some relationship between x and y. Intuitively, the reason we look for this construct is that the dependency gives us enough information to compensate for unknown state (e.g., we probably won't know the values of x and y, but knowing their relationship can be enough to find bugs). Finally, when it matches on indexing operations (GetElementPtr on line 17), it marks any path where the index size has a dependency on the object's allocated size.Symbolic The static pass produces potentially buggy paths, which Sys then feeds to the symbolic pass. It: (1) automatically symbolically executes the entire path 4 and (2) applies the user's symbolic checker to the path.Our tool, like other bit-accurate symbolic tools before it [47], aims to accurately track memory down to the level of a single bit-i.e., to assert for sure that a bit must be 0, must be 1, or may feasibly be either. It receives either UNSAT if the path's constraints can never evaluate to true, or SAT if the path's constraints can.The symbolic checker, in Figure 5, uses information that the static extension marked to figure out if an out-of-bounds write is possible. Mechanically, these SysDSL functions add new constraints to the logical formula, alongside the constraints Sys automatically adds when symbolically executing the path. At the other, starting at main and attempting to reach each site is the equivalent of traditional symbolic execution.Unknown state Sys's approach of jumping over code to the error site is both its strength and its weakness. Thus, the struggle is how to (1) make up fake copies of skipped state, and (2) ensure that missing constraints do not lead to explosions of false positives.Sys makes up state using lazy allocation, similar to the UC-KLEE system [115]. For example, the malloc checker looks for out-ofbounds access in code snippets where there's a dependency between an object's allocation size and its index size. Our goal was to build a symbolic checking system that was not just accurate, but also flexible enough to express checkers that could find bugs in huge codebases. There should be direct, high-level ways to express both symbolic checks (e.g., "is x uninitialized") and ad hoc information (e.g., "all size arguments to malloc are greater than zero.") Expressive: we can't anticipate all the extensions and checkers that Sys clients may want, so our challenge is to ensure that they can express any checkable property or take advantage of any latent program fact. Second, to make sure that their interface to the system internals-in this case, the static extension and symbolic checkers' interface to Sys internals-is sufficiently powerful, core components of the system itself must be built atop the same interface. We want a system that makes it as easy as possible to get constraints right, and types can help us avoid malformed constraints early.In the rest of this section, we quickly describe the design of the static extension system. Since the details of our static extension system are relatively standard, we only discuss one idiosyncrasy of Sys's static system here: Sys does both its static and symbolic passes on LLVM IR (or bytecode). Running checkers on bytecode is even more suboptimal in some ways, but we do it because: (1) it makes communication between the static and symbolic passes simple; (2) we can check any language that emits LLVM IR; (3) it lets us "see inside" complicated C++ code for free; and (4) it allows our checkers to comprehend and take advantage of compiler optimizations ( §6). David's and our own experiences with KLEE convinced us that we needed a high-level way of expressing constraints that didn't force users to emulate a C compiler.At the same time, checking LLVM IR by hacking directly on SMT constraints-as we did in early versions of Sys-had its own challenges. After that, we wanted to express constraints in a way that protected users from hand-translating IR into SMT. In particular, with SysDSL, users can create symbolic variables and constants from LLVM ones; perform binary op- erations, assignments, comparisons, and casts on these variables and constants; set and get fields in symbolic aggregate structures; and, load and store to symbolic memory. If, say, addr is 32-bits in an LLVM file that specifies 64-bit pointers, the SysDSL will exit with an error.Second, SysDSL exposes functions that are polymorphic over LLVM types to reflect LLVM's polymorphism-e.g., that rmwOp (line 10) operates on all widths of integer and vectors-and to simplify both the symex engine and checker implementations. Similarly, load and store always load from and store to the most recent version of symbolic memory. We use KLEE as a comparison point, since it: (1) also focuses on bit-precise symbolic execution and (2) is relatively well known [47] (e.g., it has its own workshop [23]). Memory In order to perform queries on a memory location in the checked program, a symbolic tool must map program memory to a corresponding memory representation in its constraint solver. If we use array mem to represent memory and p to be a fully symbolic expression, the query *p == 0 directly translates to mem[p] = 0. Double-, triple-, quadruple-(or more) indirect pointers take no special effort; ***p == 0 simply becomes mem[mem[mem [p]]] = 0. If checked code ever stores the canary bit-pattern itself, the tool will flag false positives, and tracking small units like single bits is clearly infeasible. This restriction goes a long way to defeating the point of symbolic checking, since (among other issues), the checker will miss all errors where a pointer could point to both initialized and uninitialized locations.The standard approach that dynamic tools like Valgrind [106], Purify [82], and Eraser [123] take is to associate each memory location m with a corresponding shadow memory location m that stores metadata about m. For example, if the user tracks a shadow bit for each location, the expression *p maps to mem [p], and the expression shadow[p/32] checks p's shadow bit (assuming 32-bit pointers). Second, in a flat memory model, out-of-bounds memory accesses turn into out-of-bounds accesses in symbolic memory. Effectiveness: can we use Sys to find new security bugs in aggressively tested, huge codebases without sieving through thousands of false positives?We answer these questions by implementing three checkers that look for two kinds of classic memory safety bugs-use of uninitialized memory and out-of-bounds reads and writesin browser code, and one system-specific checker that finds unvalidated use of untrusted user data in the FreeBSD kernel.Workflow We built and debugged checkers on parts of browser code (e.g., the Prio or Skia library) on our laptops. Chrome took longest (under an hour for the out-of-bounds checkers and six hours for the uninitialized memory checker) while FreeBSD was quick (six minutes for user input). Both browsers run bug bounty programs that reward security bug reports [51,103]. Chrome also encourages developers to write fuzz targets for the their own components [102], and combined, Google fuzzers and test cases reach 73% line coverage of the entire browser [54]. Firefox also runs the Infer static analyzer [15] alongside their Coverity scans (integrated in 2006) [20], which resulted in many thousands of bug fixes.How good are the bugs we find? The Prio bugs have existed since Prio's introduction last year ( §5.1), the SQLite pattern has existed for at least nine years ( §5.2), and the Opus codec bug has existed for three and a half years ( §5.3). If there is no obvious store to s, the extension marks the first load of s as potentially uninitialized. The checker associates each bit in s with a shadow bit s b and initially sets each shadow bit s b to 1 (uninit). Finally, at the end of the first block in which s is read, the checker runs the following snippet with s as uninitVar; it will emit an error if any bit in s b is set: uninitCheck uninitVar uninitType = do uninitSym <-getName uninitVar shadowResult <-loadShadow uninitSym uninitType isSet <-uninitConst uninitType assert $ isEq uninitType shadowResult isSetThe last line adds a solver constraint that the checked location uninitSym's shadow memory, shadowResult, has a bit set (implying uninitialized). This initially caused a serious number of false positives whenever an uninitialized variable x was passed to a skipped function and then used (e.g., init(x); *x;). Before we built shadow memory, we tried two failed approaches: 1. Unintuitively (to us), this version of symbolic false positive suppression was actually far easier and more effective than the static one.The second initial source of false positives arose because we run checkers on the optimized release builds of Chrome and Firefox, the code that gets shipped to millions of users. A benefit of checking IR: checking IR means that we see any compiler-generated code, and thus can detect errors in it, or errors in assumptions programs make about it. Checking checkers: checkers have errors, just like the code they check. After looking an NSS bug Sys found [12] (and an audit of NSS for more occurrences of the bug), a triage developer said "at the very minimum, the problem in PRZoneCalloc should be found by something. This checker (Figure 8) discovered 21 out-of-bounds bugs, including a group of 13 in Chrome's SQLite with a bounty and a CVE. Many system components we check have an internal security model where values from outside (e.g., user SQL) need to be checked, but data internal to the browser is trusted. One of these bugs is in Chrome's LibDRM, an interface for communicating with GPUs [6]: For realistic values, size_items can be large enough to wrap a 32-bit integer but not a 64-bit integer: the size passed to drmMalloc will wrap around to a small value and become the target of huge overflow when memcpy copies the unwrapped number of bytes. We found three separate instances of malloc routines designed to take ints (or i32s on x86-64) used with memory operations designed to take size_ts (or i64s on x86-64). / This section focuses on a specialty of static checkers and even compilers: stack and heap out-of-bounds bugs caused by indices that are always concretely out-of-bounds. The static pass currently ignores indices into: parent class objects, since these objects may have a different layout than child object; dynamically-sized struct fields (i.e., in C++ accesses off the end of arrays of size [1 x type] in structs); single-index out-of-bounds (because of C++ iterators); and union types. Symbolic checker: determines that the out-of-bounds indexing is possible. In this section, we experimentally compare Sys with stateof-the-art static analysis and symbolic execution tools ( §6.1). To understand the importance of our extensible, combined static and symbolic approach for checking large codebases, we run Sys and a variety of other tools on the Firefox web browser. We choose these two analysis tools because (1) they scale to huge codebases like Firefox and (2) Mozilla already uses both tools (e.g., they are the two systems in their new static analysis bug bounty program [119]); there are many other similar tools [19,48,85]. We manually examined each report to determine: (1) if the report was caused by purported stack uninitialized memory or by something else (e.g., shift by a negative number) and (2) for the stack uninit reports, whether the result was a true positive or a false positive. For bugs we were not not completely confident in, we checked the latest Firefox source for the bug and checked whether or not the alert had been suppressed by Firefox: if the bug was still in the source but not in the latest Clang reports, we marked it as a false positive (since it had likely been suppressed). We also checked the latest Firefox source and Clang report for bugs we were confident to be true positives. Alternatively, we could send Sys down all paths that Clang or Semmle identify as possibly buggy.Reasons for false negatives Sys did not identify the two Semmle bugs or ten of the thirteen Clang bugs. 9 We use these tools to represent the fully symbolic approach and the UC approach, respectively.Firefox We ran angr in its default configuration (but using underconstrained mode) to detect uninitialized memory in Firefox. It spent roughly twenty-four hours in a profiling function before we stopped it, and it did not detect any errors.We did not run KLEE on Firefox largely because our angr experiment: since UC symbolic execution doesn't scale to the browser, full symbolic execution is even less likely to. 10 We ran KLEE for three days, configured with a symbolic input file of 4096 bytes and symbolic stdin of 1024 bytes; we used a large file because many bugs (e.g., our malloc bug) require very large tables. Then, for each real bug, we wrote a report explaining that bug, sent it to browser developers, and then communicated with those developers about the details of the report.Writing checkers To understand the challenges of writing checkers with SysDSL, we report on the experience of the second author of this paper writing their first Sys checker. The static extension tracks freed variables (and their aliases), and flags any uses (operands to load and store, and arguments to function calls). The false-positive suppression ignores UAFs in reference counting code.The final checker (110 LOC extension, 80 LOC symbolic) flagged a true positive bug in Firefox (in the HarfBuzz text shaping engine), which was fixed within a few hours of our report [14]. Sys does not find bugs at the lowest optimization levels because its static analysis pass matches on patterns more common in production builds; future work is understanding if Sys can find additional bugs at different, higher optimization levels in the browser, and determining whether building static analysis specifically for lower optimization levels can yield new bugs, as well. Other symbolic execution tools like KLEE, UC-KLEE, and angr symbolically execute whole programs or whole functions, and so miss fewer bugs but also cannot scale to check browsers as written. In the future, we plan to eliminate the easy half by jumping back to callers and re-checking for bugs.Sys, like all extensible checking systems (e.g., Pin [98], angr [131], Semmle [126], etc.), requires users to write new checkers if they want to find new styles of bugs; users may obviously re-use any existing checkers to find new bugs in different systems. Finally, Sys runs on LLVM IR, which means that developers must be able to compile their code to use it-which can be a problem in practice, for example, when checking closed source systems, or when integrating with a new build system [39,41]. UC-KLEE's main goals were to scale symex while (1) checking C program correctness without user intervention and (2) avoiding false negatives [114]. Though Saturn found many locking bugs in the Linux kernel, the tool is not designed to check large C++ codebases (e.g., it relies on a custom front-end compiler and IR that models C, and does not let users encode heuristics or false positive suppressions). This problem matters less for them, since they check code that is orders of magnitude smaller than browsers.The Dowser system finds buffer overflow vulnerabilities by combining fuzzing, program analysis, and symbolic execution: it performs static analysis to identify complicated program pieces, and then uses combined symbolic execution and fuzzing to steer the program towards the target lines [81]. Finally, Parvez et al. [109] use static analysis to identify potentially buggy statements, and then use symbolic execution to synthesize test cases that hit the statements.Other systems combine static and symex for failure reproduction. All of these approaches demonstrate the power of symbolic execution combined with static analysis. UC-KLEE [115], the first system to support underconstrained symbolic execution [63], deals with the problem of undefined state by cross-checking a patched and unpatched function: if the two versions differ beyond the bug fix, UC-KLEE reports an error. But, since full symbolic execution struggles to scale [36,47,131], much past work has focused on tackling this challenge. Finally, for more information on the benefits and drawbacks of underconstrained symbolic execution compared to traditional symbolic execution-in other words, information on the impact of skipping code-Ramos [113] directly compares KLEE and UC-KLEE along a number of axes (e.g., scalability, false positives, etc). TFuzz [111], for example, scales fuzzing by skipping complex constrains and uses symbolic execution to determine if the bugs flagged bugs are real; it, however, relies on full symbolic execution which does not scale to checking browsers.Extensible static checking. These efforts are largely complimentary; indeed, an future direction is to combine such source-level static analysis with low-level symbolic execution.Memory safety bug checkers We are not the first to identify uninitialized memory, buffer overflow, and use-after-free bugs; we chose these classes of bugs because they are aggressively checked for and thus good test cases for new tools. nThis paper presents Sys, an extensible framework for automatically detecting bugs using a combination of static analysis and symbolic execution: static analysis identifies potential errorsites cheaply, while symbolic execution reasons deeply about whether the sites are actually in error. This paper presents Sys, an extensible framework for automatically detecting bugs using a combination of static analysis and symbolic execution: static analysis identifies potential errorsites cheaply, while symbolic execution reasons deeply about whether the sites are actually in error.