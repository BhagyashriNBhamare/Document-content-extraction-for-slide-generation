Some of them (e.g., incorrect use of SSL API, and integer overflow of memory allocation size) can cause serious security vulnerabilities (e.g., man-in-the-middle (MITM) attack, and privilege escalation). We applied APISAN to 92 million lines of code, including Linux Kernel, and OpenSSL, found 76 previously unknown bugs, and provided patches for all the bugs. Broadly, all existing techniques either require (1) manual effort-API-specific specifications (e.g., SSL in SSLint [26], setuid [10,15]), code annotations (e.g., lock operations in Sparse [41]), correct models (e.g., file system in WOODPECKER [11]), or (2) an accurate analysis of source code [6,7], which is hard to scale to complex, real-world system software written in C/C++. Once APISAN extracts such semantic beliefs, it reports deviations from the beliefs as potential errors together with a probabilistic ranking that reflects their likelihood.A hallmark of APISAN compared to existing approaches [1,18,28,29] for finding bugs by detecting contradictions in source code is that it achieves precision by considering semantic constraints in API usage patterns. The technique, called relaxed symbolic execution, circumvents the path-explosion problem by limiting exploration to a bounded number of intraprocedural paths that suffice in practice for the purpose of inferring semantic beliefs.APISAN computes a database of symbolic contexts from the source code of different programs, and infers semantic beliefs from the database by checking four key aspects: implications of function return values, relations between function arguments, causal relationships between functions, and implicit pre-and post-conditions of functions. We describe eight such cases in APISAN that are tailored to check a variety of properties with security implications, such as cryptographic protocol API misuses, integer overflow, improper locking, and NULL dereference.Our evaluation shows that APISAN's approach is scal- Figure 1: (a) A memory leak vulnerability found by APISAN in OpenSSL 1.1.0-pre3-dev. We develop a fully automated way of finding API misuses that infers semantic beliefs from existing API uses and probabilistically ranks deviant API usages as bugs. APISAN found 76 new bugs in system software and libraries, including Linux, OpenSSL, PHP, and Python, which are 92 million LoC in total. To find API usage errors, APISAN automatically infers semantic correctness, called semantic beliefs, by analyzing the source code of different uses of the API.We motivate our approach by means of an example that illustrates an API usage error. For example, considering the use of the OpenSSL API in Figure 1(a) together with other uses of the API shown in Figure 1(b), APISAN infers the majority pattern as freeing the allocated context after initialization failure (i.e., EVP_PKEY_keygen_init() <= 0), and thereby reports the use in Figure 1(a) as an error. We describe three key challenges that hinder existing approaches in finding the error in the above example.1. These specifications are not expressive enough to capture correct API uses inferred by APISAN; for example, type-state specifications can capture finite-state rules but not rules involving a more complex state, such as the rule in the box in Figure 1(a), which states that EVP_PKEY_CTX_free() must be called if EVP_PKEY_CTX_init() <= 0. However, functions such as EVP_PKEY_keygen_init() in Figure 1 contain a function pointer, which is hard to resolve in static analysis, and cryptographic functions have extremely complex path constraints that pose scalability challenges to symbolic execution based approaches. It first builds symbolic contexts using symbolic execution techniques on existing programs' source code and creates a database of symbolic traces ( §3.1). Finally, it locates API misuses in the programs' source code using the inferred beliefs and domain-specific knowledge if necessary ( §3.3, §4). We formalize our approach as a general framework, shown in Figure 5, which can be tuned using two parameters: the context checking function, which enables tailoring the checking of symbolic contexts to different API usage aspects, and an optional hint ranking function, which allows customizing the ranking of bug reports. To precisely capture API usages involving a complex state, APISAN infers semantic beliefs from the results of symbolic execution. These results, represented in the form of symbolic constraints, on one hand contain precise semantic information about each individual use of an API, and on the other hand are abstract enough to compare across uses of the API even in different programs. APISAN automatically infers correct API usage patterns from existing source code without any human intervention (e.g., manual annotation or providing an API list), and ranks potential API misuses based on the extent to which they deviate from the observed usage pattern. The key challenge of building symbolic contexts in large and complex programs is to overcome the path-explosion problem in symbolic execution.We made two important design decisions for our symbolic execution to achieve scalability yet extract accurate enough information about symbolic contexts. = NULL d→ports[0] == NULL return IRQ_HANDLED spin_lock(&lock) external call symbolic constraints spin_unlock(&lock)... these two design decisions within the context of finding API misuses, and provide a performance optimization that memoizes the predominant symbolic states. In our experience with APISAN, limiting inter-procedural analysis is reasonable for accuracy and code coverage, since most API usages can be captured within a caller function without knowing API internals.Unrolling a loop. This helps scalability because APISAN can deterministically explore the symbolic execution tree, and all intermediate results can be cached in interior nodes; most importantly, the cached results (i.e., predominant symbolic contexts) can be safely re-used because there is no control flow from a child to its ancestors. Each event a is either a call to a function f with a sequence of symbolic expressions ¯ e as arguments, or an assume constraint, which is a pair consisting of a symbolic expression e and its possible value ranges ¯ r. (function) f ∈ F (integer) n ∈ Z, (natural) i ∈ N (symbolic variable) α ::= ⟨arg, i⟩ | ⟨ret, i⟩ (symbolic expression) e ::= n | α | uop e | e 1 bop e 2 (integer range) r ::= [n 1 , n 2 ] (event in trace) a ::= call f ( ¯ e) | assume(e, ¯ r) (trace) t ::= ¯ a (database of traces) D ::= { t 1 ,t 2 , ··· }The following three traces are computed by APISAN for the code snippet in Figure 3 (ignoring unseen parts) 1 :t 1 : assume(d→count, [MIN, 0]) t 2 : assume(d→count, [1, MAX]); assume(d→ports[0], [0, 0]) t 3 : assume(d→count, [1, MAX]); assume(d→ports[0], [[MIN, −1], [1, MAX]]); call spin_lock(&d→ports[0]→lock); call spin_unlock(&d→ports[0]→lock)1 MIN and MAX stand for the minimum and maximum possible values of a related type, respectively. • Return value: Not only does a function return the result of its computation, but it often implicates the status of the computation through the return value; for example, non-zero value in glibc and PTR_ERR() in the Linux kernel. • Conditions: API semantics can imply certain preor post-conditions; for example, verifying a peer certificate is valid only if the peer certificate exists. Return value is usually used to return the computation result (e.g. pointer to an object) or execution status (e.g., errno) of a function. Procedures CONTEXTS and HINT are abstract; Figure 6 shows concrete instances of these procedures implemented in APISAN. Moreover, missing return value checks can lead to privilege escalation like CVE-2014-4113 [12]. if ( f 'Properly checking return values seems trivial at the outset, but it is not in reality; since each API uses return values differently (e.g., 0 can be used to denote either success or failure), it is error-prone. For an API function f, APISAN extracts all symbolic constraints on f's return values from symbolic execution traces. APISAN reports such cases that the probability of constraints is below a certain threshold as potential bugs; the lower the probability of correctness, the more likely those cases are to be bugs.Our framework can be easily instantiated to capture return value context by defining the context function returnValueContexts(t, i), as shown in Figure 6, which extracts all checks on the return value of the function called at t[i] (i.e., the i th event in trace t). APISAN then classifies the calls where the probability is lower than a certain threshold as potential bugs.Another important type of relation on arguments is the constraint on a single argument, e.g., an argument is expected to be a format string. Both direct and constrained causality relationships can be effectively captured in the APISAN framework by defining a parametric context function causalityContexts⟨ ¯ r⟩ shown in Figure 6, which extracts all pairs of API calls with ¯ r as the context constraints between them. Similarly, SSL_get_verify_result(), an OpenSSL API which verifies the certificate presented by the peer, is meaningful only when SSL_get_peer_certificate() returns a non-NULL certificate of a peer, though which could happen either before or after SSL_get_verify_result(). For example, if an API name contains a sub-string alloc, which indicates that it is very likely to handle memory allocation, we can customize APISAN to give more weight for its misuse in the return value checking. The checker classifies such function calls into three categories: (1) correct check, (2) incorrect check, and (3) Figure 10: An integer overflow vulnerability found in Linux by APISAN. The checker concludes that an API is more integer overflow-sensitive if the ratio of correct checks over total checks is higher. In this manner, APISAN effectively captures typical usage patterns of memory allocation and free routines to report potential memory leaks. However, in the case of programs that have their own printf-like functions (e.g., PHP), compilers cannot detect such errors.To infer whether a function argument is a format string, we use a simple heuristic: if the majority of symbolic expressions for an argument is a constant string and contains well-known format codes (e.g, %s), then the argument is considered as a format string. Lines of code To evaluate APISAN, this section attempts to answer the following questions:• We applied APISAN to Linux v4.5-rc4, OpenSSL 1.1.0-pre3-dev, PHP 7.0, Python 3.6, and all 1,204 debian packages using the OpenSSL library. For eight types of API misuses described at §4, we developed five checkers: return value checker (rvchk), causality checker (cpair), argument relation checker (args) implicit pre-and postcondition checker (cond), and integer overflow checker (intovfl).1 # run a causality checker 2 $ apisan --checker=cpair 3 @FUNC: EVP_PKEY_keygen_init 4 @CONS: ((-2147483648, 0),) 5 @POST: EVP_PKEY_CTX_free 6 @CODE: {'req.c:1745'} 7 ...APISAN can also be run against multiple databases generated by different project code repositories. APISAN found 11 NULL dereference bugs caused by missing return value checks of OPENSSL_malloc(), which are already fixed in the latest OpenSSL. In this section, we investigate two aspects of our ranking scheme: (1) where true-positives are located in bug reports and (2) author audited the top 445 reports out of 2,876 reports for two days and found 54 new bugs. To understand what causes false positives, we manually investigated all false positive cases in the top 445 reports, and found a few frequent reasons: diverse patterns of return value checking, wrapper functions delegating return value checking to callers, and semantically correct, but rare patterns.Some kernel APIs, such as snd_pcm_new() [40], return zero on success or a negative error code on failure. APISAN found 37 pairs out of 187 such causal relations.The inaccuracy of APISAN mainly stems from a small number of API usages and limited symbolic execution. While investigating PHP integer overflow bugs in Figure 13, we found that the bug was newly introduced when changing string allocation APIs; the new string allocation API, zend_string_alloc(), omits an internal integer overflow check, making its callers vulnerable to integer overflow. In this case, APISAN's inference results can be used to provide missing manual annotations required by other checkers. In contrast, APISAN statistically infers semantic correctness from source code; it is generic without requiring models or annotations, but it could incur higher false positives than techniques that use precise semantic correctness information.Checking API usages. These approaches would be useful in APISAN as well.Automatic generation of specifications has been explored by Kremenek et al. [28] for resource allocation, by PRMiner [29] for causal relations, by APIMiner [1] for partial ordering of APIs, by Daikon [19] from dynamic execution traces, by Taghdiri et al. [43] for structural properties, by PRIME [33] for temporal specifications, by Nguyen et al. [35] for preconditions of APIs, by Gruska et al. [23] for sequences of functions, by JIGSAW [44] for resource accesses, by MERLIN [31] for information flow specifications, and by Yamaguchi et al. [47] for taint-style vulnerabilities. Our results show that APISAN's approach is effective in finding new bugs and is general enough to extend easily to custom API checkers based on APISAN. It is defined as follows:if e ≡ uop e ′ argvars(e 1 ,t) ∪ argvars(e 2 ,t) if e ≡ e 1 bop e 2