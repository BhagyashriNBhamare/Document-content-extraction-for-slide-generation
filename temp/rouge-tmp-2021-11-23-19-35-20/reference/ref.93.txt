However, existing tools, and specifically , static analysis tools, trade soundness of the analysis for precision and performance, and are hence soundy. This paper proposes the Mutation-based soundness evaluation (µSE) framework, which systematically evaluates Android static analysis tools to discover, document, and fix, flaws, by leverag-ing the well-founded practice of mutation analysis. Applications can neither be trusted to be well-written or benign, and to prevent misuse of such access through malicious or vulnerable apps [59,44,98,80,35,87,32], it is imperative to understand the challenges in securing mobile apps.Security analysis of third-party apps has been one of the dominant areas of smartphone security research in the last decade, resulting in tools and frameworks with diverse security goals. For instance, prior work has designed tools to identify malicious behavior in apps [34,99,12], discover private data leaks [33,13,42,15], detect vulnerable application interfaces [38,22,62,54], identify flaws in the use of cryptographic primitives [35,32,87], and define sandbox policies for third-party apps [47,50]. While this particular case is well-known and documented, many such unsound design choices are neither well-documented, nor known to researchers outside a small community of experts.Security experts have described such tools as soundy, i.e., having a core set of sound design choices, in addition to certain practical assumptions that sacrifice soundness for precision [61]. While our work is motivated by the manifesto, we leverage soundiness at the general, conceptual level of design choices, and attempt to resolve the status quo of soundy tools by making them more secure as well as transparent.This paper proposes the Mutation-based Soundness Evaluation (µSE, read as "muse") framework that enables systematic security evaluation of Android static analysis tools to discover unsound design assumptions, leading to their documentation, as well as improvements in the tools themselves. We propose a semiautomated methodology to analyze the uncaught mutants, resolve them to flaws in the tool, and confirm the flaws experimentally.We demonstrate the effectiveness of µSE by evaluating static analysis research tools that detect data leaks in Android apps (e.g., FlowDroid [13], IccTA [55]). Thus, µSE not only helps researchers, tool designers, and analysts uncover undocumented flaws and unsound choices in soundy security tools, but may also provide immediate benefits by discovering easily fixable, but evasive, flaws.This paper makes the following contributions:• We introduce the novel paradigm of Mutationbased Soundness Evaluation, which provides a systematic methodology for discovering flaws in static analysis tools for Android, leveraging the well-understood practice of mutation analysis. Our analysis leads to the documentation of unsound assumptions, and immediate security fixes in some cases.Threat Model: µSE is designed to help security researchers evaluate tools that detect vulnerabilities (e.g., SSl misuse), and more importantly, tools that detect malicious or suspicious behavior (e.g., data leaks). Therefore, to evaluate the soundness of existing tools that detect such behavior, µSE has to develop mutants that mimic such adversarial behavior as well, by defining mutation schemes of an adversarial nature. That is, security tools may already have a core set of sound design decisions (i.e., the sound core), and may claim soundness based on those decisions. Systematically identifying unsound decisions may allow researchers to resolve flaws and help extend the sound core of their tools.Moreover, research papers and tool documentations indeed do not articulate many of the unsound assumptions and design choices that lie outside their sound core, aside from some well-known cases (e.g., choosing not to handle reflection, race conditions), as confirmed by our results (Section 6). Consider the following motivating example of a prominent static analysis tool, FlowDroid [13]:FlowDroid [13] is a highly popular static analysis framework for detecting private data leaks in Android apps by performing a data flow analysis. However, through a systematic evaluation of FlowDroid, we discovered a security limitation that is not well-known or accounted for in the paper, and hence affects guarantees provided by the tool's analysis. Thus, we were able to discover and fix an undocumented design flaw that significantly affected FlowDroid's soundness claims, thereby expanding its sound core. However, we have confirmed that FlowDroid v2.5 [88] still fails to detect leaks in fragments, and are working with developers to resolve this issue.Through this example, we demonstrate that unsound assumptions in security-focused static analysis tools for Android are not only detrimental to the validity of their own analysis, but may also inadvertently propagate to future research. We propose µSE, a semi-automated framework for systematically evaluating Android static analysis tools that adapts the process of mutation analysis commonly used to evaluate software test suites [74]. µSE executes the tool on mutants, i.e., apps to which security operators (i.e., security-related mutation operators) are applied, as per a mutation scheme, which governs the placement of code transformations described by operators in the app (i.e., thus generating mutants). The security operators represent anomalies that the static analysis tools are expected to detect, and hence, are closely tied to the security goal of the tool. Knowing these boundaries would be immensely useful for analysts who use security tools, for developers looking for ways to improve tools, as well as for end users who benefit from the security analyses provided by such tools. Thus, the mutation schemes, i.e., the placement of the target, unwanted behavior in the app, must consider Android's abstractions and application model for effectiveness. In Step 1, we specify the security operators and mutation schemes that are relevant to the security goals of the tool being evaluated (e.g., data leak detection), as well as certain unique abstractions of Android that separately motivate this analysis. In Step 2, we mutate one or more Android apps using the security operators and defined mutation schemes using a Mutation Engine (ME). In Step 3, we apply the security tool under investigation to analyze the mutated app, leading it to detect some or all of the mutants as anomalies.We perform a methodological manual analysis of the undetected mutants, which may lead to documentation of flaws, and software patches.Note that tools sharing a security goal (e.g., FlowDroid [13], Argus [39], HornDroid [20] and BlueSeal [84] all detect data leaks) can be analyzed using the same security operators and mutation schemes, and hence the mutated apps, significantly reducing the overall cost of operating µSE (Goal G4). However, for evaluating a tool that detects vulnerable SSL connections (e.g., CryptoLint [32]), we may want to express the use of vulnerable SSL APIs (i.e., of SSL classes that can be overridden, such as a custom TrustManager that trusts all certificates) without much concern for what data is exported. That is, the requirements are practically orthogonal for these two use cases, rendering a generic operator useless, while precisely designing tool-specific operators may not scale.In µSE, we take a balanced approach to solve this problem: instead of tying a security operator to a specific tool, we define it in terms of the security goal of the concerned tool (Goal G1). Moreover, security operators generalize to other security goals as well; a simple operator for evaluating tools that detect vulnerable SSL use (e.g., MalloDroid) could add a TrustManager with a vulnerable isServerTrusted method that returns true, which, when combined with our expressive mutation schemes (Section 4.2), would generate a diverse set of mutants.To derive security operators at the granularity of the security goal, we must examine the claims made by existing tools; i.e., security tools must certainly detect the unwanted behavior that they claim to detect, unless affected by some unsound design choice that hinders detection. However, we do not create operators using the limitations and assumptions already documented in the paper or well-known in general (e.g., leaks in reflection and dynamically loaded code), as µSE seeks to find unknown assumptions. We define the specific methods for choosing where to apply security operators to inject mutations within Android apps as the mutation scheme.The mutation scheme depends on a number of factors: (1) Android's unique abstractions, (2), the intent to over-approximate reachability for coverage, and (3) the security goal of the tool being analyzed (i.e., similar to security operators). Note that while mutation schemes using the first two factors may be generally applied to any type of static analysis tool (e.g., SSL vulnerability and malware detectors), the third factor, as the description suggests, will only apply to a specific security goal, which in the light of this paper, is data leak detection.We describe each factor independently, as a mutation scheme, in the context of the following running example described previously in Section 2:Recall that FlowDroid [13], the target of our analysis in Section 2, detects data leaks in Android apps. We design our mutation scheme to 1 final Button button = findViewById(R.id.button_id); 2 button.setOnClickListener(new View.OnClickListener() {public void onClick(View v) {// Code here executes on main thread after user presses button}});Listing 2: Dynamically created onClick callback place mutants within methods of fragments and activities where applicable, so as to test a tool's ability to model the activity and fragment lifecycles. For instance, consider the example in Listing 2, where the onClick() callback can execute at any point of time.3) Intent messages: Android apps communicate with one another and listen for system-level events using Intents, Intent Filters, and Broadcast Receivers [2,1]. 4) XML resource files: Although Android apps are primarily written in Java, they also include resource files that establish callbacks. In keeping with our motivating example (Section 2) and our evaluation (Section 6), we develop an example mutation scheme that can be specifically applied to evaluate data leak detectors. This scheme infers two ways of adding mutants: 1) Taint-based operator placement: This placement methodology tests the tools' ability to recognize an asynchronous ordering of callbacks, by placing the source in one callback and the sink in another. As per the activity lifecycle, the onResume() callback always executes right after the onStart() callback. µSE allows the analyst to dynamically implement such rules, as long as the input and output are both strings, and the rule complicates the path between them by sending the input through an arbitrary set of transformations.In a traditional mutation analysis setting, the mutation placement strategy would seek to minimize the number of non-compilable mutants. However, as our goal is to evaluate the soundness of Android security tools, we design our mutation scheme to over-approximate. The following methodology is used by an analyst for each undetected mutant after testing a given security tool to isolate and confirm flaws: 1) Identifying the Source and Sink: During mutant generation, µSE's ME injects a unique mutant identifier, as well as the source and sink using util.Log.d statements. Thus, a security analyst inspects the code of a mutated app, and identifies the observable call sequences from various entry points. This section provides the implementation details of µSE: (1) ME for mutating apps, and (2) EE for exercising mutants to filter out non-executing ones. µSE takes a systematic approach toward applying mutants to a target app, and for each mutant location stipulated by the MIP for a given app, a mutant is seeded. µSE can be extended to additional security operators and mutation schemes by adding methods to derive the MIP, and perform target code transformations.Given the time cost in running the studied security-focused static analysis tools on a set of apks, µSE breaks from the process used by traditional mutation analysis frameworks that seed each mutant into a separate program version, and seeds all mutants into a single version of a target app. Specifically, we focus on a set of seven data leak detectors for Android that use static analysis, primarily due to the availability of their source code, namely FlowDroid [13], Argus [39] (previously known as AmanDroid), DroidSafe [43], IccTA [55], BlueSeal [84], HornDroid [20], and DidFail [53]. For all the tools except FlowDroid, we use the latest release version when available; in FlowDroid's case, we used its v2.0 release for our µSE analysis, and confirmed our findings with its later releases (i.e., v2.5 and v2.5.1). In the second experiment (Section 6.3), we perform an in-depth analysis of FlowDroid by applying our systematic manual analysis methodology (Section 4.3) on the output of µSE for FlowDroid.Finally, our third experiment (Section 6.4) measures the propagation and prevalence of the flaws found in FlowDroid, in tools from our dataset apart from FlowDroid, and two newer versions of FlowDroid.These experiments are motivated by the following research questions: RQ1 Can µSE find security problems in static analysis tools for Android, and help resolve them to flaws/ unsound choices? Moreover, it takes our analyst, a graduate student with background in Android security, one hour per flaw (in the worst case), due to our systematic analysis methodology, as well as our dynamic filter (Section 4.3), which filters out over 73 % of the seeded non-executable mutants (RQ3). Methodology: We create 21 mutated APKs from 7 target applications, with 7, 584 leaks among them, by combining the security operators described in Section 4.1, with mutation schemes from Section 4.2. Next, we configure FlowDroid, Argus, and DroidSafe and evaluate each tool with µSE individually, by running them on the mutated apps (with non-executable leaks excluded) and recording the number of leaks not detected by each tool (i.e., the surviving mutants). Results: µSE injects 7, 584 leaks into the Android apps, of which, 5, 558 potentially non-executable leaks are filtered out using our EE, leaving only 2, 026 leaks confirmed as executable in the mutated apps. This experiment demonstrates an in-depth, manual analysis of FlowDroid, which we choose for two reasons: (1) impact (FlowDroid is cited by 700 papers and numerous other tools depend on it), and (2) potential for change (since FlowDroid is being maintained at the moment, any contributions we can make will have immediate benefits). In fact, we developed patches to correctly implement Fragment support (i.e., flaw 13 in Table 2), which were accepted by developers.To gain insight about the practical challenges faced by static analysis tools, and their design flaws, we further categorize the discovered flaws into the following flaw classes: FC1: Missing Callbacks: The security tool (e.g., FlowDroid) does not recognize some callback method(s), and will not find leaks placed within them. FlowDroid misses the onReceive() callback of a BroadcastReceiver implemented programmatically and registered within another programmatically defined and registered BroadcastReceiver's onReceive() callback. FlowDroid misses the flow to a sink within a Runnable.run() method started by a Thread, only when that Thread is saved to a variable before Thread.start() is called.Helper, both added in API 1, are not interfaces, but abstract classes. Methodology: We check if the two newer release versions of FlowDroid (i.e., v2.5, and v2.5.1), as well as 6 other tools (i.e., Argus, DroidSafe, IccTA, BlueSeal, HornDroid, and DidFail), are susceptible to any of the flaws discussed previously in FlowDroid v2.0, by using the tools to analyze the minimal example APKs generated during the in-depth analysis of FlowDroid. However, BlueSeal and DroidSafe both augment the graph in novel ways, and thus don't exhibit the flaws found in FlowDroid.Finally, our analysis does not imply that FlowDroid is weaker than the tools which have fewer flaws in Table 3. Out of the 13 flaws discovered by µSE, the Android-influenced mutation scheme (Section 4.2.1) revealed one (i.e., BroadCastReceiver in Table 3), while the rest were evenly distributed among the other two mutation schemes; i.e., the schemes that evaluate reachability (Section 4.2.2) or leverage the security goal (Section 4.2.3). Insight 5: Benchmarks need to evolve with time.While manually-curated benchmarks (e.g., DroidBench [13]) are highly useful as a "first line of defense" in checking if a tool is able to detect wellknown flaws, the downside of relying too heavily on benchmarks is that they only provide a known, finite number of tests, leading to a false sense of security. Mutation Analysis for Android: Deng et al. [26] introduced mutation analysis for Android and derived operators by analyzing the syntax of Android-specific Java constructs. Recently, Acar et al. have systematized Android security research [9], and we discuss work that introduces static analysis-based countermeasures for Android security issues according to Acar et al.'s categorization.Perhaps the most prevalent area of research in Android security has concerned the permissions system that mediates access to privileged hardware and software resources. Rather, mSE provides a systematic approach to semi-automatically uncover flaws in existing security tools, which is a significant advancement over manually-curated tests. We proposed the µSE framework for performing systematic security evaluation of Android static analysis tools to discover (undocumented) unsound assumptions, adopting the practice of mutation testing from SE to security. Note that while we did not execute the apps to determine if the fragment code was really executed, the fact that 7,860 out of 8,664 top apps, or 91% of popular apps contain fragment code indicates the possibility that fragments are widely used, and that accidental or malicious data leaks in a large number of apps could evade FlowDroid due to this flaw. Note that while we did not execute the apps to determine if the fragment code was really executed, the fact that 7,860 out of 8,664 top apps, or 91% of popular apps contain fragment code indicates the possibility that fragments are widely used, and that accidental or malicious data leaks in a large number of apps could evade FlowDroid due to this flaw. Since the goal of the EE is to explore as many screens of a target app as possible, the EE forgoes certain combinations of exploration strategies from CRASHSCOPE (e.g., entering unexpected text or disabling contextual features) prone to eliciting crashes from apps.