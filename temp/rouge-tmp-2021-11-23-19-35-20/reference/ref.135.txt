Simple path tracing tools such as traceroute allow malicious users to infer network topologies remotely and use that knowledge to craft advanced denial-of-service (DoS) attacks such as Link-Flooding Attacks (LFAs). While solving this problem exactly is hard, we show that NetHide can obfuscate topologies at scale by only considering a subset of the candidate solutions and without reducing obfuscation quality. Such attacks can be divided in two categories depending on whether they target end-hosts and services (volume-based attacks) or the network infrastructure itself (link-flooding attacks, LFAs). Link-flooding attacks (LFAs) [26,38] are more sophisticated and work by having a botnet generate lowrate flows between pairs of bots or towards public services such that all of these flows cross a given set of network links or nodes, degrading (or even preventing) the connectivity for all services using them. As an illustration, our simulations indicate that congesting an arbitrary link without knowing the topology requires 5 times more flows, while congesting a specific link is order of magnitudes more difficult.Nowadays, attackers can easily acquire topology knowledge by running path tracing tools such as traceroute [17]. In fact, previous studies have shown that entire topologies can be precisely mapped with traceroute provided enough vantage points are used [37], a requirement easily met by using large-scale measurement platforms (e.g., RIPE Atlas [16]). We also show that NetHide is useful when partially deployed: 40 % of programmable devices allow to protect up to 60 % of the flows.Contributions Our main contributions are:• A novel formulation of the network obfuscation problem in a way that preserves the usefulness of existing debugging tools ( §3). • An encoding of the obfuscation task as a linear optimization problem together with a random sampling technique to ensure scalability ( §4). To deploy NetHide, we assume that some of the routers are programmable in a way that allows them to: (i) match Botnet Public servers Figure 1: Link Flooding Attacks (LFAs) work by routing many legitimate low-volume flows over the same set of physical links in order to cause congestion. LFAs assume that the attacker can discover the network topology, usually using traceroute-like tracing.on arbitrary IP Time-to-Live (TTL) values; (ii) change the source and destination addresses of packets (e.g., UDP packets for traceroute) depending on the original destination address and the TTL; and (iii) restore the original source and destination addresses when replies (e.g., ICMP packets) to modified packets arrive. However, the attacker can learn the network topology using traceroute-like tracing techniques [17]. More specifically, traceroute leverages the fact thatNetwork components (Nodes) N ⊆ N = {n 1 , . . . , n N } (Links) L ⊆ N × N (Forwarding tree) T n = (N, L n ), tree rooted at n (Forwarding trees) T = n∈N T n (Flows) F ⊆ N × N Network topologies (Physical) P = (N, L, T ) (Virtual) V = (N , L , T ) N ⊆ N Metrics (Flows per link) f (T, l) = {(s, d) ∈ F | l ∈ T d } (Flow density) fd(T, l) = | f (T, l)| (Capacity) c : L → N (Accuracy) acc : ((s, d) , P,V ) → [0, 1] (Utility) util : ((s, d) , P,V ) → [0, 1]Figure 2: NetHide notation and metrics TTL values are decremented by one at each router, and that the first router to see a TTL value of 0 sends a response to the source of the probe. For example, a packet with TTL value of 3 sent from A to B will cause the third router along the path from A to B to send an ICMP time exceeded message to A. By aggregating paths between many host pairs, it is possible to determine the topology and the forwarding behavior of the network [37]. We remark that in addition to revealing forwarding paths, traceroute-like probes also disclose the Round-Trip Time (RTT), i.e., the time difference between the moment a probe is sent and the corresponding ICMP time exceeded message is received, which can be used as a side-channel to gain intuition about the feasibility of a (potentially obfuscated) path returned by traceroute. We address the following network obfuscation problem: Given a physical topology P, the goal is to compute an obfuscated (virtual) topology V such that V is secure and is as similar as possible to P. For the similarity between the physical topology P and the obfuscated topology V , we refer to §3 where we present metrics which represent the accuracy of paths reported by traceroute and the utility of link failures in P being closely represented in V . Specifically, we consider the task of obfuscating a network with 6 routers: A, . . . , F in which the core link (C, D) acts as bottleneck and is therefore a potential target for an LFA.Inputs NetHide takes four inputs: (i) the physical network topology graph; (ii) a specification of the forwarding behavior (a forwarding tree for each destination according to the physical topology and incorporating potential link weights); (iii) the capacity c of each link (how many flows can cross each link before congesting it); along with (iv) the set of attack flows F to protect against. Given these inputs, NetHide produces an obfuscated virtual topology V which: (i) prevents the attacker(s) from determining a set of flows to congest any link; while (ii) still allowing non-malicious users to perform network diagnosis. In addition to enabling NetHide to scale, this random selection also acts as a secret which makes it significantly harder to invert the obfuscation algorithm.NetHide obfuscates network topologies along two dimensions: (i) it modifies the topology graph (i.e., it adds or removes links); and (ii) it modifies the forwarding behavior (i.e., how flows are routed along the graph). For instance, in Fig. 3, the two shown candidate solutions V 1 and V 2 both contain two virtual links used to "route" flows from A to E and from B to F.Selecting a usable obfuscated topology While there exist many secure candidate topologies, they differ in terms of usability, i.e., their perceived usefulness for benign users. In contrast, simpler approaches which answer to tracing packets at the network edge or from a central controller (e.g., [28,39]) render network debugging tools unusable.Consider again Fig. 3 (right). Observe that, in addition to ensure the utility (see above), making the intended router answer to the probe also ensures that the measured round trip times are realistic (cf. §5). NetHide finds a virtual topology that is secure and has maximum accuracy compared with the physical topology.w acc ∈ [0, 1], w util ∈ [0, 1], w acc + w util = 1 Hard Constraints (Security) ∀l ∈ L : fd(V, l) ≤ c(l) (C1) (Complete) n ∈ N ⇒ n ∈ N (C2) (Reach) ∀n ∈ N : |{T n |T n ∈ T }| = 1 (C3) ∀T ∈ T : ∀l ∈ T : l ∈ L (C4) (n, n ) ∈ L ⇒ {n, n } ∈ N (C5)NetHide finds a virtual topology V , then V is secure with respect to the attacker model and the capacities.To ensure that the virtual topology V is valid, NetHide incorporates additional constraints capturing that: (C2) all physical nodes in N are also contained in the virtual topology with nodes N ; (C3) there is exactly one virtual forwarding tree for each node; and (C4-5) links and nodes in the virtual forwarding trees are contained in N . Formally, given a flow (s, d), the accuracy is defined as:acc ((s, d), P,V ) = 1 − LD(T s→d , T s→d ) |T s→d | + T s→dWhere LD(T s→d , T s→d ) is Levenshtein distance [32] and |T s→d | denotes the length of the path from s to d.The overall accuracy of a topology (as referred to in §6) is defined as the average accuracy over all flows in F:A avg (P,V ) = avg (s,d)∈F acc((s, d), P,V )We point out that the accuracy metric in NetHide can also be computed by any other function to precisely represent the network operator's needs.Input: Flow (s, d) ∈ F, physical topology P = (N, L, T ), virtual topology V = (N , L , T ) Output: utility u ∈ [0, 1] for n ∈ T s→d do C ← T s→n ∩ T s→d [0 : n] // common links u n ← 1 2 |C| |T s→n | + |C| |T s→d [0:n]| // utility u ← 1 |T s→d | ∑ n∈T s→d u n // averageAlgorithm 1: Utility metric. It incorporates the likelihood that a failure in the physical topology P is visible in the virtual topology V and that a failure in V actually exists in P. Note that we treat T s→d as a set of links. NetHide computes the overall utility by taking the average utility computed over all flows:U avg = avg (s,d)∈F util((s, d), P,V )As with accuracy, a network operator is free to implement a custom utility metric.In most cases, the accuracy and utility are strongly linked together (we show this in §6). This is repeated until the specified number of forwarding trees per node is obtained while the weights are randomly chosen w(e) ∼ Uniform(1, 10) for each iteration.As NetHide pre-computes a fixed number of forwarding trees per node, the ILP solver later only needs to find an optimal combination of O(|N |) forwarding trees instead of O(|N | 2 ) links and O(|N | |N | ) forwarding trees.We point out that the reduction from individual links or paths to forwarding trees and the small number of considered forwarding trees does not affect the security of V as security is a hard constraint and thus, NetHide never produces a topology that is insecure. We consider two distinct attacker strategies: (i) reconstructing the physical topology P from the virtual topology V ; and (ii) choosing an attack based on the observed virtual topology V (without explicitly reconstructing P). The obfuscation function is therefore not injective, which entails that NetHide guarantees opacity [35], a well-known security property stipulating that the attacker does not know the secret P.Given that the attacker cannot reconstruct P with certainty, she may attempt to make an educated guess based on the observed V and her knowledge about NetHide's obfuscation function. A more advanced attacker would leverage her knowledge about the observed topology to select the set of flows such that the likelihood of a successful attack is maximized.In our evaluation, we consider three concrete strategies: (i) random, where the attacker selects the set of flows uniformly at random, (ii) bottleneck+random, where the attacker selects a link with the highest flow density and selects additional flows uniformly at random from the remaining set of flows, and (iii) bottleneck+closeness, where the attacker selects a link with the highest flow density and selects additional flows based on their distance to the link. For example, NetHide provides 90 % accuracy and 72 % utility while limiting the probability of success to 1 % for an attacker which can run twice the required number of flows and follows the bottleneck+random strategy in a physical topology where 20 % of the links are insecure.Finally, we remark that while our results indicate that NetHide successfully mitigates advanced attackers, providing a formal probabilistic guarantee on the success of the attacker is an interesting and challenging open problem. In the following, we explain the major challenges which need to be addressed by the design and the implementation of the NetHide topology deployment in order to provide high security, accuracy, utility and performance.Reflecting physical events in virtual topology Maintaining the usefulness of network tracing and debugging tools is a major requirement for any network obfuscation scheme to be practical. Software targets (e.g., [13]) provide an environment to develop and test P4 programs while hardware targets (such as [3]) can run P4 programs at line rate.A P4 program is composed of a parser, which parses a packet and extracts header data according to specified protocols, a set of match+action tables and a control program that specifies how these tables are applied to a packet before the (potentially modified) packet is sent to the output port. Instead, it purely relies on the TTL value, the source and destination of a packet and-if needed-it obfuscates traffic of all applications.Encoding the virtual topology If a packet needs to be modified, NetHide queries the match+action table which returns the required changes for the packet. However, if the virtual path for this packet has a different length than the physical path, the TTL needs to be incremented or decremented by the difference of the virtual and the physical path length.If the packet has a low TTL value which will expire before the packet reaches its destination, NetHide needs to ensure that the packet expires at the correct node with respect to V . This meta header is placed on top of the layer 3 payload and is thus contained in ICMP time exceeded replies.Preventing packet injections Coming back to the first check when a packet arrives: if it contains a meta header and the signature is valid (i.e., corresponds to the device), NetHide restores the original source and destination addresses of the packet and removes the meta header before sending it to the outgoing interface. In this section, we show that NetHide: (i) obfuscates topologies while maintaining high accuracy and utility ( §6.2, §6.3); (ii) computes obfuscated topologies in less than one hour, even when considering large networks ( §6.4). Metrics To be able to compare the results of our evaluation with different topologies, we use the average flow density reduction factor, which denotes the ratio between the flow density in the physical topology P = (N, L, T ) and in the virtual topology V = (N , L , T ): FR = 1 − avg l∈L fd(V, l) avg l∈L fd(P, l)The flow density denotes the number of flows that are carried at each link (cf. §2.3). As baseline, we include the results of a naive obfuscation algorithm that computes V by adding links at random positions and routing traffic along a shortest path.NetHide scores close to the optimal point especially for large topologies. While adding enough links randomly will eventually result in a complete graph, the small number of forwarding trees considered by NetHide does not always contain enough links to build a complete graph.In Fig. 8 (right), we show the percentage of flows that do not need to be modified (i.e., have 100 % accuracy and utility) depending on the flow density reduction factor. We specify the capacity of each link to 10 % of the maximum flow density listed in Table 1 and observe that w acc has a relatively small impact for our accuracy and utility metrics especially for large topologies. As the results in Fig. 11 show, virtual paths are shorter than physical paths (the ratio is ≤ 1)-intuitively because removing a node from a path has a smaller impact on our accuracy and utility metrics than adding one) andfor the medium and large topology-the virtual paths are less than 10 % shorter both on average and in the 10 th percentile for a flow density reduction of 80 %. Therefore, the key challenge for the attacker is to select the flows such that they result in a successful attack on P.Besides the attacker's budget, her chances of success also depend on the robustness of P: If P is weak (i.e., the capacity of many links is exceeded), it either needs to be obfuscated more or attacks are more likely to succeed.In this experiment, we simulate three feasible strategies for an attacker to select b flows:• Random: Samples b flows uniformly at random from the set of all flows F.• Bottleneck+Random: Identifies the link with the highest flow density in V (a "bottleneck" link l b ) and attacks by initiating all the fd(l b ) flows that cross this link plus (b − fd(l b )) random additional flows. Bottleneck+Closeness is slightly more powerful than Bottleneck+Random (Fig. 14), which results in more obfuscation that is required.Input: Virtual topology V = (N , L , T ), Flow (s, d) ∈ N × N , Flow path T s→d Bottleneck link (n 1 , n 2 ) ∈ L Output: Preference p ∈ [0, 1] if (n 1 ∈ T s→d ) ∧ (n 2 ∈ T s→d ) then p ← 1/| links between n 1 and n 2 in T s→d | else if (n 1 ∈ T s→d ) ∧ (n 2 / ∈ T s→d )then n a ← node after n 1 in T s→d n b ← node before n 1 in T s→d p a ← length of path from n 2 to n a p b ← length of path from n 2 to n b p ← 1/ min(p a , p b ) else if (n 1 / ∈ T s→d ) ∧ (n 2 ∈ T s→d ) then (see above with n 1 and n 2 flipped) else p ← 0 Algorithm 2: Flow preference metric. But since V contains links that are not in P or vice-versa, a physical link failure can be observed as multiple link failures or as the failing of another virtual link.In Fig. 13, we show that the vast majority of physical link failures is precisely reflected in the virtual topology. Not at the moment, but after the following extensions: (i) instead of an exact path for each flow, we specify the expected load that a flow adds to each link (e.g., using max-min fair allocation as in [30]); (ii) the constraints regarding the flow density now constrain the expected flow density; (iii) the virtual topology can contain multiple parallel paths and probabilities with which each path is taken; and (iv) the runtime randomly selects one of the possible paths.How close to the optimal is the solution computed by NetHide? Instead, we measure the distance between the virtual and the physical topology ( §6.2) and show that the virtual topology is already very close (in terms of accuracy and utility) to the physical one. It allows an AS to route traffic from and to another AS along a path that is not affected by an LFA.On the other hand, proactive solutions-including NetHide-aim at preventing LFAs from happening and are typically based on obfuscation. Other approaches that are related to LFAs but not particularly to our work are based on virtual networks [22], require changes in protocols or support from routers and end-hosts [19,29] or focus on the detection of LFAs [41]. The core idea is to phrase the obfuscation task as a multi-objective optimization problem where security requirements are encoded as hard constraints and usability ones as soft constraints using the notions of accuracy and utility.As a proof-of-concept, we built a system, called NetHide, which relies on an ILP solver and effective heuristics to compute compliant obfuscated topologies and on programmable network devices to capture and modify tracing traffic at line rate.