Local differential privacy, where each user shares locally perturbed data with an untrusted server, is often used in private learning but does not provide the same accuracy as the central model, where noise is applied only once by a trusted server. Existing solutions to compute the differentially private median provide good accuracy only for large amounts of users (local model), by using a trusted third party (central model), or for a very small data universe (secure multi-party computation). Specifically, how multiple users can compute rank-based statistics over their sensitive data, with high accuracy, a strong privacy guarantee, and without resorting to trusted third parties. We use differential privacy (DP) [25,28], a rigorous privacy notion, restricting what can be inferred about any individual in the data, used by Google [15,31], Apple [1,66], Microsoft [23] and the US Census bureau [2]. The median is a robust statistical method used to represent a "typical" value from a data set, e.g., insurance companies use the median life expectancy to adjust insurance premiums.Previous work on DP median computation either require a large number of users to be accurate [27,34,63], rely on a trusted third party [51,58], or cannot scale to large universe or data set sizes [14,30,59]. Their approach, while more general, is only practical for a universe size of 5 elements, whereas our protocol is sublinear in the size of the universe and handles billions of elements. In summary, our contribution is a protocol for securely computing the differentially private median• with high accuracy even for small data sets (few users) and large universe sizes (see Section 3.4 for our theoretical errors bounds, Appendix F for a comparison of that bound to related work, and Section 5.3 for empirical comparison to related work),• that is efficient (practical running time for millions of users) and scalable (sublinear in the data universe size) (Sections 4, 5),• secure in the semi-honest model with an extension to the malicious model (Section 4.6) and outputs the differentially private median according to the exponential mechanism by McSherry and Talwar [52],• evaluated using an implementation in the SCALE-MAMBA framework [6], for 1 million users using 3 semi-honest computation parties with a running time of seconds in a LAN, and 3 minutes in a WAN with 100 ms network delay, 100 Mbits/s bandwidth (Section 5). In the following, we introduce preliminaries for differential privacy and secure multi-party computation.We consider a set of input parties P = {P 1 , . . . , P n }, where party P i holds a datum d i , and D denotes their combined data set. Differential privacy (DP), introduced by Dwork et al. [25,28], is a strong privacy guarantee restricting what a mechanism operating on a sensitive data set can output. Randomization is essential for differential privacy to hide an individual's inclusion in the data [29]. For any utility function u : (U n × R ) → R and a privacy parameter ε, the exponential mechanism EM ε u (D) outputs r ∈ R with probability proportional to exp( εu (D,r) 2∆u ), where∆u = max ∀r∈R ,DD u(D, r) − u D , ris the sensitivity of the utility function. Trusted Serverd 1 d n M ( f (d 1 , . . . , d n )) (a) Central Model C 1 . . . Untrusted Serverr 1 =M (d 1 ) r n =M (d n ) f (r 1 , . . . , r n ) (b) Local Model C 1 . . . Shuffler Untrusted Serverr 1 =M (d 1 ) r n =M (d n ) r π(1) . . . r π(n) f r π(1) , . . . , r π(n)(c) Shuffle Model with permutation π Figure 1: Models for DP mechanism M . Client C i sends a message (raw data d i or randomized r i ) to a server, who computes function f over the messages, and releases the result. Recently, an intermediate shuffle model ( Figure 1c) was introduced [15,18]: A trusted party is added between client and server in the local model, the shuffler, who does not collude with anyone.The shuffler permutes and forwards the randomized client values. As our goal is high accuracy without trusted parties even for small number of users, we simulate the central model in a distributed setting via secure multi-party computation (MPC), which is often used in DP literature [26,30,38,59,60,65]. The sensitivity is the largest difference a single change in any possible database can have on the function result. To illustrate that additive noise can be high, we empirically evaluated the absolute error of the Laplace mechanism with smooth sensitivity, the exponential mechanism, and our protocol in Figure 2 on real-world data sets [42,67]. Secure multi-party computation (MPC) [36] allows a set of three or more parties P = {P 1 , . . . , P n }, where party P i holds sensitive input d i , to jointly compute a function y = f (d 1 , . . . , d n ) while protecting their inputs. There are two main implementation paradigms for MPC [32,46]: garbled circuits [68] 2 , where the parties construct a (large, encrypted) circuit and evaluate it at once, and secret sharing [12,21,57,62], where the parties interact for each circuit gate. We select the best subrange and also split it into k subranges for the next iteration, until the last subrange is small enough to directly select the final output from it. Each subrange selection increases the overall privacy loss ε, and we enable users to select a trade-off between running time, privacy loss and accuracy by presenting three protocols to compute unnormalized selection probabilities, which we call weights, w.r.t. ε:• Weights ln(2) fixes ε = ln(2) to compute exp(εy) as 2 y ,• Weights ln(2)/2 d allows ε = ln(2) 2 d for some integer d > 0, • Weights * supports arbitrary ε.On a high-level, we have three phases in each iteration:1. Therefore, we combine them via MPC to preserve privacy. To combine local utility scores per party into a global score for all, we require utility functions to be decomposable: Convex optimization: find x that minimizes ∑ n i=1 l(x, d i ) with convex loss function l defined over D; e.g., empirical risk minimization in machine learning [10,63], and integer partitions (password frequency lists) [16] − ∑ n i=1 l(x, d i )Unlimited supply auction: find price x maximizing revenue x ∑ i b i (x), where bidder demand curve b i indicates how many goods bidder i will buy at price x; e.g., digital goods [52] x ∑ i b i (x)Frequency: select x based on its frequency in D; e.g., mode [48] ∑ n i=1 1 x=d iRank-based statistics: select x based on its rank in sorted D; e.g., k th -ranked element [48] See Section 3.2 Table 1: Applications with decomposable utility functions.Definition 4 (Decomposability). Reporting the median in addition to the mean allows the collector to detect skew in the distribution. The additional communication stemming from our secure median computation can be shifted to few parties who are not network resource constrained, e.g., mobile phones on WiFi networks.To be sublinear in the size of the universe we consider decomposability w.r.t. ranges instead of elements: parties only report one utility score per range, instead of one score per element. We focus on MPC of the differentially private median with rank n/2 but Definition 5 supports any k th -ranked element. However, a naive implementation of u µ leaks information as the iteration count depends on the number of duplicates in the data. Initialize S = U and repeat below steps s times:(a) Every party p ∈ P divides S into k equal-sized subranges{R i = [r i l , r i u )} k i=1 i. if ε j = ln(2)/2 d in step j (with integer d ≥ 0), input rank D p (r i l ), rank D p (r i u ) k i=1 , d ii. Definition 5 and 6 are equivalent as can be seen by proof by cases (see Appendix B), and u c µ is decomposable w.r.t.:u (D i , R) =      rank D i (r u ) − |D i | 2 if rank D (r u ) < n 2 |D i | 2 − rank D i (r l ) if rank D (r l ) > n 2 0 else , where rank D (r) = ∑ n i=1 rank D i (r)for range endpoints r. For Weights * we let the parties input weights, i.e., exp(εu ), which we can efficiently combine via multiplication. The ideal functionality F EM * in Figure 3 describes our DP median protocol EM * as executed by a trusted third party, which we later replace by implementing F EM * with MPC. Overall, F EM * provides ε-differential privacy: Theorem 1. Next, we discuss how the data distribution influences accuracy and present worst-case bounds on the accuracy of the exponential mechanism for median selection. As neighbor D may contain values from the gaps of D, these gap values must be output with a non-zero probability. Then, smooth sensitivity is extremely large with 10 9 and the exponential mechanism outputs a value at uniform random. The child nodes are equal-sized subranges of the parent node and R j i denotes the i th subrange in level j. R = {R j 1 , . . . , R j k } of data universe U. Then, output of EM ε u (D, R )contains an element at most ln(k/β) ε positions away from median position n 2 with probability at least 1 − β. First, we bound the utility difference between optimal and selected output. For r u < µ we have d = |rank D (r u ) − n 2 | = n 2 − rank D (r u ) from which we obtain rank D (r u ) > n 2 − ln |R |+t εwith probability at least 1 − exp(−t). We have k = |R | and setting β = exp(−t) concludes the proof.To obtain an absolute error with regards to data elements, consider universe elements instead of subranges as the output of the exponential mechanism.Corollary 1 (Median Accuracy). However, sequential (subrange) selections consumes ε j per selection step j which adds up to a total privacy budget of ε = ∑ j ε j as described in Section 3.3. We now show how to choose ε j to select the subrange containing the median in each iteration step with probability at least 1 − β.Theorem 3 (Choice of ε). For low epsilon (e.g., ε = 0.1) we want to use the entire privacy budget on the actual median selection to achieve high accuracy. Output / FunctionalityRec(a) a, reconstructed from a Add(a, b) a + b Sub(a, b) a − b Mul(a, b) a · b Mod2m(a, b) a mod 2 b ,where b is public Trunc(a, b) a/2 b , where b is public Rand(b) r with uniform random b-bit value r Choose(a, b, c) a if bit c = 1 otherwise b LT(a, b) 1 if a < b else 0 Int2FL(a)converts integer a to secret shared float In the following, we describe details of our protocol EM * , which implements ideal functionality F EM * , analyse its running time and security. We adopt the notation from Aliasgari et al. [5] and represent a floating-point number f as (1 − 2s)(1 − z) · v · 2 x with sign bit s set when the value is negative, zero bit z only set when the value is zero, l v -bit significand v, and l x -bit exponent x. To refer to, e.g., the significand v of f we will write f.v. (Privacy violations and mitigations w.r.t. limited machine precision are discussed in Appendix D.) The basic MPC protocols used in our protocol are listed in Table 2. Output: Differentially private median of D.1: r l , r u ← 0, |U| 2: for j ← 1 to s do 3:r # ← max{1, r u −r l k } 4:k ← min{k, r u − r l } Define array W of size k if ε j = ln(2)/2 d for some integer d then 7: sively divided into k subranges until the last subrange, after at most log k |U| iterations, contains only one element: the differentially private median 7 . Alternatively, one can use fewer selection steps s and select an element from the last subrange at uniform random (line 15 in Algorithm 1). We use decomposable utility functions to combine local evaluations over each party's data into a global utility score for the joint data. Solutions for secure exponentiation of 2 u exist where u is an integer or a float Algorithm 2 Algorithm Select.Input: List W FL of weights with size k. Output: Index j ∈ [1, k] M[ j] FL ← FLAdd(W [ j] FL , M[ j − 1] FL ) 5: end for 6: t ← IntRand(b) //Bitlength b 7: f FL ← Int2FL(t) 8: x ← IntSub( f.x, b) 9: f FL ← ( f.v, x, f.z, f.s) 10: r FL ← FLMul(M[k] FL , f FL ) 11: i l ← 1; i u ← k 12: while i l < i u do 13: i m ← i l +i u 2 14: c ← FLLT(M[i m ] FL , r FL ) 15:c ← Rec(c) i l ← i m + 1 if c = 1 else i u ← i m 17: end while 18: return i l [5,7,20,43]. The complexity of the integer-based solution is linear in the bit-length of u, however, this is not sufficient for us: Recall, that the utility is based on ranks, i.e., counts of data elements, thus u can be roughly as large as the size of the data. We analyse the running time of EM * w.r.t. MPC protocols from for j ← 1 to k do //Divide range into k subranges 4:i l ← r l + ( j − 1) · r # 5: i u ← r u if j = k else r l + j · r # 6: W l [ j] FL ← FLMul(W l [ j] FL , e ε |Dp | 2 −rank Dp (U[i l ]) FL ) 7: W u [ j] FL ← FLMul(W u [ j] FL , e ε rank Dp (U[i u ])− |Dp | 2 | FL )8:end for 9: end for 10: for j ← 1 to k do 11:c u ← FLLT(W u [ j] FL , 1 FL ) 12: c l ← FLLT(W l [ j] FL , 1 FL ) 13: t FL ← FLChoose(W u [ j] FL , 1 FL , c u ) 14: W [ j] FL ← FLChoose(W l [ j] FL , t FL , c l ) 15: end for 16: return W FLand their complexity is given in Appendix C. Weight computation via Weights * requires 2km float multiplications FLMul, 2k float comparisons FLLT and 2k float selections FLChoose. Each invocation of Select requires k − 1 float additions FLAdd, only one random draw IntRand, conversion Int2FL and float multiplication FLMul. Our protocol consists of multiple subroutines realized with MPC protocols listed in Table 2 (for details and security proof references we refer to [6]). To prove semi-honest security we show the existence of a simulator Sim according to Goldreich [36] such that the distributions of the protocol transcript EM * is computationally indistinguishable from simulated transcript using F EM * produced in an "ideal world" with a trusted third party.Note that an adversary in the ideal world learns nothing except the protocol inputs and outputs, hence, if he cannot distinguish simulated transcripts (from ideal world) and actual transcripts (in the real world), he learns nothing in our realworld implementation. Altogether, a semi-honest adversary cannot learn more than the (ideal-world) simulator as this information is sufficient to produce a transcript of our (real-world) protocol.For malicious adversaries, we need to ensure consistency between rounds based on Aggarwal et al. [3], who securely compute the (non-DP) median via comparison-based pruning rounds. Informally, we have two consistency constraints: First, valid rank inputs must be monotone within a step. The latter can be a subset of the input parties or non-colluding untrusted servers (e.g., multiple cloud service providers). Next, we evaluate the running time, privacy budget and accuracy of our solution and refer to Appendix E for additional evaluations. We performed our evaluation on t2.medium AWS instances with 2GB RAM, 4 vCPUs [8] and the Open Payments data set from the Centers for Medicare & Medicaid Services (CMS) [33]. For detailed measurements see Table 4 in Appendix E.WAN: We consider m computation parties, which already received and combined secret-shared inputs from 10 6 users (Section 4.7), and report the average running time of our protocol. We split the m parties into two regions, Ohio (us-east-2) and Frankfurt (eu-central-1), and measured an inter-region round time trip (RTT) of approx. 100 ms with 100 Mbits/s bandwidth. Larger k leads to larger running times, as the number of costly secure computations depends on the number of ranges times the number of selection steps (k · log k |U|), which increases proportionally to k. However, smaller values for k require more selection steps (log k |U|), which lead to an increase in the privacy budget. The 8 "Small" data is the most challenging regime for DP [15,56], thus, we use small data sets to better illustrate the accuracy differences. Pettai & Laud [59] (SA in Figure 6) securely compute the noisy average of the 100 values closest to the median within a clipping range. However, the exponential mechanism EM, and our protocol EM * , provide the best accuracy for low ε, i.e., high privacy, compared to additive noise approaches [58,59]. Eigner et al. [30] present a carefully designed secure exponential mechanism in the multiparty setting. We consider the multi-party setting and provide pure differential privacy.DP Median: Pettai and Laud [59] securely compute DP statistics, including the DP median, via sample-and-aggregate [58]. Dwork and Lei [27] consider robust privacy-preserving statistics with a trusted third party where data samples are known to be drawn i.i.d. from a distribution. For the DP median, the exponential mechanism provides better accuracy for low epsilon and can be efficiently computed, whereas computation of smooth sensitivity requires full data access in clear or the error increases (see Section 2.1.2). Smith et al. [63] and Gaboardi et al. [34] consider the restrictive non-interactive local model, where at most one message is sent from client to server, and achieve optimal local model error. Decomposability: MapReduce is a programming paradigm for distributed data aggregation where a mapper produces intermediary results (e.g., partial sums) that a reducer combines into a result (e.g., total sum). We implemented our protocol in the SCALE-MAMBA framework [6], and evaluated it for 1 million users using 3 semihonest computation parties achieving a running time of seconds in a LAN, and 3 minutes in a WAN (100 ms latency, 100 Mbits/s bandwidth). Note that Choose(a, b, c) is implemented with one multiplication and two additions (b + (a − b) · c), and that IntRand uses correlated randomness already exchanged in the offline phase (hence zero interaction and rounds). The online and offline phase are integrated in newer versions of SCALE-MAMBA, thus, we only provide measurements for the total protocol, i.e., offline as well as online phase.Running time in a LAN: We compare our running time to This work has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 825333 (MOSAICrOWN).