Our key idea is to slightly shift the GPS location so that the fake navigation route matches the shape of the actual roads and trigger physically possible instructions. We perform extensive evaluations using a trace-driven simulation (600 taxi traces in Manhattan and Boston), and then validate the complete attack via real-world driving tests (attacking our own car). GPS is vulnerable to spoofing attacks where adversaries can inject falsified GPS signals to control the victim's GPS device [55]. In 2013, a luxury yacht was intentionally diverted from Monaco to Greece by spoofing its receiving GPS signals [46]. Other works have examined GPS spoofing attacks on systems in the open environment (e.g., open air/water) such as drones and ships [28,46] where a simple GPS change could (stealthily) steer their navigation.So far, it is still an open question regarding whether attackers can manipulate the road navigation systems by spoofing the GPS inputs. Since the possibility of the attack is not yet clear, most civilian systems don't have any defense mechanisms in place.In this paper, we take systematic steps to explore the feasibility of manipulating road navigation systems stealthy by carefully crafting the spoofed GPS inputs.The goal is to manipulate the turn-by-turn navigation and guide a victim to a wrong destination without being noticed. To these ends, if an attacker identifies an attacking route that mimics the shape of the route displayed on the map, then it is possible to trigger navigation instructions that are consistent with the physical environment (e.g., triggering the "turning right" prompt only when there is an actual right-turn ahead) to avoid alerting users.To understand the attack feasibility, we take four key steps 1 . We show that adversaries can build a portable spoofer with low costs (about $223), which can easily penetrate the car body to take control of the GPS navigation system. 1 Our study received the approval from our local IRB (#17-936). We demonstrate the feasibility of the attack to trigger the target navigation instructions in real-time while the victim (the author) is driving.User Study.Finally, we examine the attack feasibility with users (non-authors) in the loop. We customize the driving simulator to load a high-resolution 3D street map of real-world cities. We apply deception by phrasing the study as a "usability test of the driving software", while we perform spoofing attacks during the experiment (informed consent obtained afterwards). The results provide key insights into how common driving habits make users vulnerable.We hope the results can help to raise the attention in the community to develop practically deployable defense mechanisms (e.g., location verification, signal authentication, sensor fusion) to protect the massive GPS device users and emerging GPS-enabled autonomous systems. In this section, we start by providing the background of GPS spoofing attacks and describing the unique challenges in road navigation scenarios.Global Positioning System (GPS). However, smooth takeover requires specialized hardware to real-time track and synchronize with the original signals at the victim's location (costly) [26,41]. In this paper, we explore a novel attack against road navigation systems by spoofing the GPS inputs. The attacker aims to guide the victim into a dangerous situation, for example, entering the wrong way on a highway.In our threat model, the attacker has no access to the internal software/hardware of the target GPS device or those of the navigation service. In addition, we assume the attacker knows the victim's rough destination area (e.g., a financial district, a hotel zone) or the checkpoint that the victim will bypass (e.g., main bridges, tunnels, highway entrances). In addition, human drivers are in the loop of the attack, which makes a stealthy attack necessary.The scope of the attack is limited to scenarios where users heavily rely on the GPS device for navigation. In addition, the attack will be applicable to self-driving cars that rely on GPS and the physical-world road conditions for navigation (instead of the human drivers). We implemented a portable GPS spoofer to perform controlled experiments. The spoofer consists of four components: a HackRF One-based frontend, a Raspberry Pi, a portable power source and an antenna. We obtained a temporary legal permission from the local radio regulation authority in Chengdu, China for conducting the experiments. Third, we have carefully tested the GPS signal strength at the edge of the parking lot to make sure the signals did not affect the outside areas.Our measurement focuses on two possible attacking cases to spoof the GPS device in a moving car (Figure 2). Second, if the spoofer cannot be attached to the victim's car, then the attacker may tailgate the victim's car by driving or flying a drone that carries the spoofer.Same-Car Setting.In the same car setting, we place the smartphone (XIAOMI MIX2 with Android 8.0) as the victim GPS device in the dashboard area. The result shows that the average takeover time is slightly higher from the trunk (48 seconds) than that from the backseat (35 seconds), but the difference is minor. The result shows the average takeover time remains similar (41.2 seconds). To further examine the sustainability of the signal lock-in, we fix the location of the spoofer's car, and let the victim's car drive in circles (about 10 mph) while keeping a distance for 15 meters. The measurement results demonstrate the initial feasibility, and the next question is how to make the attack more stealthy. In order to make the driver believe he is driving on the original route, the key is to find a virtual route that mimics the shapes of the real roads. The attacker creates false GPS signals to set the GPS location to a nearby "ghost" location B. To cope with the false location drift, the navigation system will recalculate a new route between B and D. Depending on the purpose of the attack, the attacker may pre-define the target destination C or simply aims to divert the victim from arriving the original destination D.In practice, when the attacker changed the GPS information from A to B, it may or may not trigger the "recalculating" voice prompt in the navigation system. Our user study (Section 7) shows that users often encounter inaccurate GPS positioning (e.g., urban canyon effect in big cities) and don't treat the one-time "recalculating" as an anomaly.Symbol Definition G A geographic area. Γ o , Γ g , Γ vOriginal route, ghost route, victim route.Loc a , Loc g actual location, ghost location. Given a starting point and a destination point, a navigation route Γ is calculated by the navigation system represented by road segments: Γ = (r 1 , r 2 , ..., r n ). Consequently, the victim will follow navigation instructions from Γ g and will end up traversing a victim route Γ v = (S v 1 , S v 2 , ..., S v m ). Note that Γ v might contain wrong-way segments (if S v i 's direction is against the traffic) or loops (if S v has the same starting and ending point). If the attacker aims to divert the victim to a pre-defined destination area C, then the attacker only needs to search the o i where Γ vi bypasses C. The attack algorithm contains two key components: road network construction and attack route search. Using the searching algorithms, the attacker can also specify a target destination (area) to divert the victim to. Given graph G, victim's current location Loc a , destination D and constraints Ω, we design a basic search algorithm for the ghost locations and victim routes. In order to find as many victim Input: G, D, Loc a , Ω dri f tDis , Ω speed Output: O = {o 1 , o 2 , ..., o K }, o i = (Γ v , Γ g , Loc g ) i 1: Initialization: O ← / 0← / 0 7: for j = 1 to m do 8: if U j−1 == / 0 then 9: break 10: end if 11: for u ∈ U j−1 do 12: v ← u.end point 13: for s ∈ segments with starting point of v do 14: if s has passed the search criteria then 15: Append u.append(s) to U j 16: end if 17: end for 18: end for 19: end for 20: end for 21: return O ALGORITHM 1: Basic attack algorithmroutes as possible, we traverse the graph from the actual location via an m-depth breadth-first search. We keep the candidate routes that satisfy the following criteria at every step:• Turn Pattern Matching: To make sure the navigation instructions of the ghost route can be applied to the victim route, we need to match the turn patterns of the two routes: φ (S v i , S v i+1 ) and φ (S g i , S g i+1 ) ∈ same maneuver instruction category. • Segment Length Matching: Given a speed scale factor Ω speed , the travel distance of the ghost should be within (1 ± Ω speed ) times the victim's actual travel distance on each segment, namely,(1−Ω speed )·S v i ≤ S g i ≤ (1 + Ω speed ) · S v i. By iteratively applying the basic attack algorithm, the attack performance can be significantly improved since partially matched victim-ghost routes can be used forInput: G, D, Ω dri f tDis , Ω speed , O 0 , I, attack goal Output: O i , where i = 1, 2, ..., I − 1 1: Initialization: carryover Γ v ← / 0, carryover Γ g ← / 0, O i ← / 0, i = 1, 2, ..., I 2: for i = 1 to I − 1 do 3:if attack goal has been achieved then4: return 5: end if 6: U 1 ,U 2 , ...,U m ← O i−1 7: for j = 1 to m do 8: if U j = / 0 then 9: break 10: end if 11:for u in U j do 12:Γ g u ← O i−1 [u] 13:for k = start j to end j do 14:Appendbasic attack(G, D, Γ g u [k]) to O i 15: Append Γ g u [: k] to carryover Γ g [u] 16: Append Γ vu [: ˆ k] to carryover Γ v [u]17: end for 18: end for 19: end for 20: Save (O i , carryover Γ v , carryover Γ g ) 21: end for 22: return ALGORITHM 2: Iterative attack algorithmsearching new routes as the victim moves. Then the attacker can run the basic or iterative algorithm to compute all the possible victim routes and identify those that bypass the pre-selected grid. Then we implement algorithms and conduct real-world driving tests to validate the attack feasibility in real-time. For example, Manhattan has more regular grids with a 17.8 • standard deviation of turn angles, while Boston has more curvy roads (20.5 • standard deviation). To examine the attack performance on realistic driving trips, we obtain taxi trip datasets from NYC Taxi and Limousine Commission (TLC) [5] and the Boston taxi trace dataset used by MIT Challenge [1]. We follow Waze's standard [7] to identify the continuous road ( [−30 • , 30 • ]]), left/right-turn ( [30 • , 170 • ]), and U-turn ( [170 • , 180 • ]). Recall in our threat model (Section 2.1), we defined three types of attacks which need different evaluation metrics. On average, each trip has 335 qualified victim routes, indicating a wide range of attack opportunities. On average, about 40% of the trips can be diverted 500 meters away.One specific goal of the Deviating Attack could be delaying the victim's trip by leading the victim to loop routes. If the attacker aims to divert the user to a pre-defined location, the evaluation metric will focus on hit rate. For a given taxi trip, the hit rate reflects how likely a victim route can bypass the attacker-defined destination to achieve targeted diverting. The result shows that we can achieve about 70%, 47%, 20% median hit rate in Manhattan with r= 500m, 1000m, and 2000m respectively. Note that even with 20% hit rate in 2000m range, if the attacker provides three candidate target destination grids, the success rate will be higher 1 − (1 − 0.2) 3 = 48.8%. The basic algorithm identified a wrong-way victim route for 599 out of the 600 taxi trips (99.8%). Our attack works for small cities, but will yield fewer options for attackers (validated in our real-world driving test). The goal of the real-world driving tests is to examine if the spoofer can trigger the fake navigation instruction in real-time right before users need to make a navigation decision.Similar as early measurements, we obtained a legal permission from the local radio regulation authority, and conducted the experiments exclusively in China. To minimize the impact of the spoofing signals, we reduce the transmit power of the spoofer to the minimum (-40 dBm) and then use attenuators (30 dB) to reduce the signal strength after locking in. In addition, there is another -42.41 dB free space propagation loss at a two-meter distance. This means, beyond two meters away from the car, the signal strength is already very weak (about -127.41 dBm), which cannot take the lock of any GPS devices.In total, we tested on two different routes as shown in Figure 6. Despite the potential crosschecks of heading and filters embedded in Google Maps, the navigation instructions were triggered in time. Next, we examine how stealthy the attack can be to human drivers (victims) through a user study. Our study received the approval of our local IRB (#17-936). The study takes about 50 minutes and we compensate each participant $10.Pre-study Survey.The survey asks two questions: (1) how often do you use GPS navigation services when driving in familiar locations (e.g., home and work) and unfamiliar locations (e.g., visiting a new city). Second, the simulator can load real-world maps where the 3D street view mimics the reality. We provide a demo video under this link 2 . In this way, we can directly manipulate the GPS read of the smartphone for the user study.To examine user reactions to the attack, we assign each participant driving tasks. The participants will drive to deliver packages to a given destination following the navigation of Google Maps. The experiment stops whenever the participant recognizes the attack. Note that the attack covers the takeover phase when the phone loses the GPS signal for a while and then jumps to a new location.To help the participants to get familiar with the driving simulator, we spend about 5-10 minutes to let the partic-ipants play with the simulator before the real tests. During the real test, we encourage the participants to thinkaloud and record the audio.Post-study Interview.In the interview, we first debrief the participants about the real purpose of the study. Driving and Navigation Habits.Users are more likely to use GPS navigation systems when traveling in unfamiliar areas. The results from China are consistent (10.0 vs. 3.93). The rest 38 participants all finished the four rounds of driving tasks and followed the navigation to reach the wrong destinations.Both participants recognized the attack because they detected certain inconsistency between the navigation information and the surrounding environment on the road. The Chinese participant (user#5, m, 26-35, driving <3 years) recognized the attack during the first round (rainy night), alerted by the "highway and local way" inconsistency.During the driving task, we observe that almost all the participants noticed when the GPS signals are lost during the takeover phase (about 30 seconds), but still kept driving on the road. Our interview later shows most users have experienced malfunctioned GPS before, which is not enough to alert them.User Perceptions to the Attack.During the interview, we find that most users have experienced GPS malfunction in real life. Overall, the results show that our attacks are highly effective even when human drivers are [12,27,36,49,50] High High High High GPS receiver hardware [24,31,35,40,47,73] Medium High High High GPS receiver software [32,35,47,48,55,63,65 in the loop. The results also point out three types of inconsistencies that are likely to alert users: (1) inconsistency between highway and local ways; (2) inconsistent street names; (3) inconsistent landmarks (e.g., gas station). In the following, we discuss key directions of countermeasures.In Table 3, we classify different methods based on whether (or how much) they require modifications to the existing GPS. However, due to the constraints in government policies, and the significant costs, dedicated ground infrastructures are also unlikely to be widely deployed.Finally, we can modify the GPS receivers. In addition, a navigation system may cross-check the GPS locations with dead reckoning results based on inertial measurement unit (IMU) sensors (e.g., accelerometer, gyroscope, magnetometer) [19,57]. However, this method in general suffers from accumulative IMU sensor errors and becomes ineffective as the time drifts.Computer Vision based Location Verification.We believe a promising defense direction is to use computer vision techniques to automatically cross-examine the physical-world landmarks and street signs with the digital maps. However, given that 54% of the world's population lives in urban areas [9], the attack can potentially impact many people. To date, researchers and hackers have successfully spoofed GPS devices in moving trucks [62], ships [46], drones [28] and mobile platforms [25,61] using off-the-shelf GPS signal simulator [62] or software defined radios [25,28,46,61]. Compared to [71], we have made significant contributions by proposing new attack algorithms (e.g., iterative attack, targeted diverting attack), and more importantly conducting real-world driving tests and user studies to validate the feasibility.GPS spoofing belongs to the broad category of sensor manipulation. In the Targeted Deviating Attack, the attacker aims to divert the user to a pre-defined location. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of any funding agencies.