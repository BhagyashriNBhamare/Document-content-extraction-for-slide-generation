FANCI is a novel system for detecting infections with domain generation algorithm (DGA) based malware by monitoring non-existent domain (NXD) responses in DNS traffic. It relies on machine-learning based classification of NXDs (i.e., domain names included in negative DNS responses), into DGA-related and benign NXDs. Modern botnets rely on domain generation algorithms (DGAs) for establishing a connection with their command & control (C2) server instead of using fixed domain names or fixed IP addresses [14,2]. FANCI's classification module uses an machine learning (ML)-classifier (random forests (RFs) or support vector machines (SVMs)) to separate NXDs into benign nonexistent domains (bNXDs) and mAGDs. Other contextual information extracted from the full NXD response that carried the domain name, from other related DNS responses, or from any other source are not required.We extensively evaluate FANCI's classification module on malicious data obtained from DGArchive [14] and data recorded in the campus network of RWTH Aachen University 2 , and in the internal network of the Siemens AG 3 . Finally, our system is very efficient with respect to both training (5.66 min on 92,102 samples) and prediction (0.0025 s per sample) such that it is even able to perform on-thefly detection in large networks without sampling.FANCI's lightweight feature design and its generalizability allows for versatile application scenarios, including the use of its classification as a service, and its use in large-scale networks as well as on home-grade hardware. This is followed by an overview of the supervised learning classifiers we use in this work. mAGDs of VolatileCedar are all permutations of the same base domain name and Dyre generates mAGDs of equal length that consist of a 3 character prefix followed by a hash-like string.In addition to NXDs generated by DGAs (i.e., mAGDs), there are mainly three groups of benign non-existent domains (bNXDs) originating from typing errors, misconfigurations, and misuse, respectively, where misconfiguration and misuse belong to the group of benign algorithmically-generated domains (bAGDs). In our work, we focus on supervised learning classifiers, more specifically on random forests (RFs) and support vector machines (SVMs) using the two labels benign and malicious. Predicting the label of an unknown sample using an RF is performed by a majority vote of all DTs in the forest. We divide the presented features into three categories: structural features, linguistic features, and statistical features. Throughout the rest of this paper we use the notations detailed in the following.A domain name d is a sequence of characters from an alphabet Σ. A valid top level domain (TLD) is a TLD that is part of the official list of TLDs maintained by the Internet Assigned Numbers Authority (IANA), for example, org, com, eu, and edu [3]. Features ignoring both operate on a string referred to as dot-free public-suffix-free5 https://publicsuffix.org # Feature Output F (d 1 ) F (d 2 )1 Domain Name Length integer 19 34 2 † Number of Subdomains integer 2 2 3 † Subdomain Length Mean rational 7.5 25 4 Has www Prefix binary 0 0 5 Has Valid TLD binary 1 1 domain and denoted by d ds f . Although a DGA may vary the public suffix among its mAGDs, it is only able to choose from the official pool of available public suffixes as otherwise the resulting domain names would not be resolvable on the public Internet. de and d 2 = dekh1her76avy0qnelivijwd1.ddns.net, where d 1 is benign and d 2 is a known mAGD.In the following, we discuss the non-self-explanatory structural features #7, #9, #10, and #12 in more detail. de it evaluates to 0. In the following, we discuss the non-self-explanatory linguistic features #17, #18, and #19 in detail. Considering the example domain name d = bnxd.rwth-aachen. The n-gram frequency distribution feature is defined as g n = ( f n , σ ( f n ), min( f n ), max( f n ), ˜ f n , f n 0.25 , f n 0.75 ), where f n is the arithmetic mean of f n , σ ( f n ) the corresponding standard deviation, min( f n ) the minimum, max( f n ) the maximum, ˜ f n the median, f n 0.25 the lower quartile, and f n 0.75 the upper quartile. FANCI is a lightweight system for classifying arbitrary NXDs into benign and DGA-related solely based on domain names. The classification module classifies arbitrary NXDs into mAGDs and bNXDs based on a model it receives from the training module (see middle part of Figure 3). The classification module operates on an NXD, that is, on an individual domain name as input submitted for classification either by an intelligence module (see Section 4.3) or by any other source as indicated with a dashed arrow in Figure 3. As opposed to the classification module, which only takes the NXD itself as input, the intelligence module additionally takes the source and destination IP address and the timestamp of each NXD response as input in order to be able to map a malicious label as classification result back to the device that initiated the query.In a first preprocessing step this module extracts the domain name and the aforementioned meta data from an NXD response. It consists of the top X Alexa domains 6 , where the exact amount X to use in this step is configurable. The first case considers the usage of FANCI with all of its three modules at a single operation site, while the second case takes advantage of FANCI's modular design and considers a distributed use of FANCI. Local. The chance an infected device is able to contact its C2 server before it has queried a non-resolving mAGD seem very slim.In less permissive networks (e.g., in large corporate networks) DNS traffic may not allow for a direct mapping to devices, for example, because of a hierarchical DNS infrastructure, where central DNS servers only communicate with subordinate domain controllers. Domains that were classified as mAGDs by FANCI can be considered to be high-confidence indicators of compromise (IOCs). FANCI generalizes well to unknown environments, which means that some parts can be outsourced. We compare SVMs and RFs to find the best performing classifier setup for detecting mAGDs and show that RFs slightly outperform SVMs in this use case. We show that FANCI's classification module generalizes well to unknown network environments and present a real world application test, whereby we are able to report new DGAs. We recorded 31 days overall, more precisely from 22 May 2017 until 21 June 2017. In total, this data set comprises 35.8 million unique NXDs.Siemens. We obtained data of a two-month period from September and October 2017 (i.e., 61 days) comprising 31.2 million unique NXDs overall.The long recording periods for both benign data sets guarantee a representative data set including different times of the day, different days of the week, and working and non-working days. We were able to obtain mAGD data for 1,344 days, ranging from 12 February 2014 until 30 January 2018. In this section, we first determine the best performing classifier or ensemble of classifiers for detecting mAGDs. This includes the ability to detect unknown seeds and unknown DGAs as well as showing that FANCI's classification module generalizes very well. The first scenario considers single-DGA detection, (i.e., one classifier targeting one specific DGA), where the second targets multi-DGA detection (i.e., one classifier trained to detect all DGAs). In all experiments, we consider accuracy (ACC) as primary metric to characterize a classifier's performance defined as ACC = |T P| + |T N|/|population|, where |T P| is the amount of true positives and |T N| the amount of true negatives. However, for each experiment we additionally present statistics of the following four metrics: true positive rate (TPR), true negative rate (TNR), false negative rate (FNR), and false positive rate (FPR). For each metric we consider the arithmetic mean x, the standard deviation σ , the minimum x min , the mediañ x, and the maximum x max . The mean ACC is 0.99936 with a small standard deviation of 0.00190. RFs detect 6 out of 59 DGAs (Bamital, Blackhole, Dyre, Sisron, Tofsee, and UD2) with 100 percent ACC.Unknown Seeds. In this experiment, we focus on evaluating the detection of mAGDs generated by a DGA with a new seed, where the model is trained with mAGDs generated by the same DGA using known seeds.To evaluate this scenario we perform an LOGO CV, that is, we perform training with mAGDs of all but one seed of a certain single DGA, perform prediction on the skipped one, and repeat this procedure for each seed and DGA. SVMs achieve a mean ACC of 0.98315 with a much smaller standard deviation of 0.06166, but with a similar wide range from 0.49850 to 1.0. Next, we examine how well a single classifier trained on some mAGDs of the known DGAs is able to detect other mAGDs generated by one of these known DGAs.We created 20 sets of a targeted size of 100,000 containing an equal number of mAGDs of each of the 59 DGAs. To verify that our classifiers are able to generalize to mAGDs of unknown DGAs we performed LOGO CV regarding a grouping by DGA, that is, mAGDs of all but one DGA are used for training and mAGDs of the left out DGA are predicted. The ACC is between 0.97972 and 0.98119 and the mean of the ACC is 0.98073 with a very small standard deviation of 0.00034. We conclude that we are able to detect mAGDs of unknown DGAs.Classifier Selection. Next, we carry out two experiments proving that our trained classifiers generalize well to unknown networks, that is, we examine the scenario of training a classifier using data from a certain network but use this classifier somewhere else. The mean ACC is 0.99534, with a small standard deviation of 0.00018. However, the false negatives (FNs) even decrease.Mixed DGAs, Training Siemens, Prediction RWTH Table 10 shows results for considering sets containing bNXDs from Siemens for training and bNXD data from RWTH Aachen for prediction. As we use a local specific whitelist in the second filtering step, we consider two data sets, one for RWTH Aachen FP bNXDs (6,522) and one for Siemens FP bNXDs (11,431). For the Siemens network, this list for example contains: siemens.net, trendmicro.com, mcafee.com, and bayer.com. Additionally, we assume that certain companies, such as, Sophos, McAfee, and TrendMicro do not host a C2 server. For our real world application test of FANCI we consider a fresh one-month recording from the central DNS resolver of RWTH Aachen University comprising 31 days, more precisely from 13 October 2017 until 12 November 2017, where the data amount is similar to the recording from Section 5.1. This means that FANCI has to handle approximately 700 million NXD responses in total, containing 35 million unique NXDs. Applying these two steps we obtained 22,755 unique positive NXDs (∼ 0.065%) that occur in 45,510 NXD responses (∼ 0.0065%) in total. We carried out the labeling of the groups with the help of DGArchive, domain knowledge, and manual research.By implication, we have seen at most 22,345 unique FPs in our one-month, real-world test resulting in a worst-case FPR of approximately 0.00064. As it is hard to determine correct ground truth in a real-world application, this FPR is only of limited significance. However, monitoring only NXD responses has the advantage that infections with bots can be detected with less delay and while processing significantly less traffic as the vast majority of DGAs issue many more NXDs than registered names.While the prior works show promising detection capabilities on specific data sets, little information on their generalizability and the efficiency of their detection process in terms of time and memory requirements is reported. FANCI is highly efficient with respect to both prediction (0.0025s/sample) and training (5.66min on 92102 samples) and shows a high accuracy with low FPR in very large scale realistic scenarios even when trained on a different network.A fair comparison between FANCI and the prior approaches with respect to detection accuracy and efficiency is hard to achieve as they aim at slightly different targets and use different data sets even if they do aim at the same target. Like FANCI, Exposure is based on ML-classification and uses a small set of carefully selected features. Due to requiring sensitive and contextual information, Exposure is not as versatile as FANCI especially when it comes to software-as-aservice deployments.Winning with DNS Failures. Applying their system in a large ISP environment over a period of 15 months, they discovered twelve new DGAs, where six of them are completely new and six are variants of previously known ones.Pleidas uses a set of statistical and structural features, where all features are extracted from groups of NXD responses originating from a single host. For a group size of 5 NXD responses of each host the TPR is in the range of 95 and 99 percent and the FPR is between 0.1 and 1.4 percent. In this case, the TPR is in a range of 99 and 100 percent, where the FPR ranges between 0 and 0.2 percent.As Pleidas requires tracking of DNS responses for feature extraction, we expect that it is much less efficient than FANCI. The reported detection quality is similar to FANCI but FANCI is evaluated on a more extensive data set that uses far more DGAs and real world-benign traffic instead of the top 10,000 domains of Alexa. They perform an anomaly detection based on the assumption that normal behaviour of a host is to request an IP address via DNS for a certain domain name, followed by one or multiple connections to this newly resolved IP address. Their paper is based on the collection and reverse engineering of DGA-based malware and provides detailed technical insights in the functionality of modern DGAs divisible in three main contributions: a taxonomy of DGAs, a database of DGAs and corresponding mAGDs called DGArchive, and an analysis of the landscape of registered mAGDs. While Plohmann et al. do not implement an automated detection, the DGArchive provides the means to blacklist known mAGDs. In an one-month real-world application in a large university network, we were able to discover ten new DGA-related groups of mAGDs, where at least four of them originate from brand new DGAs.With its empirically proven detection capabilities and a successful real-world test, FANCI can make a decisive contribution to combating DGA-based botnets. The final parameter selection for multi-DGA detection is based on mathematical constraints of the respective ML algorithm and on domain knowledge on the classification problem. As our feature vector is of length 44, F is an integer selected from [2,44], where each possible value is assigned to F. All measurements were performed single-threaded on a Dell OptiPlex 980 with Intel i7 870@2.93GHz CPU and 16GB RAM running Ubuntu Linux 16.04. This means that on average performing classification of a single unknown sample takes 0.0025 seconds for RFs including feature extraction.Based on the measurements presented above FANCI is able to perform classification for 400 packets per second on a general purpose computer using a single thread. Feature extraction is included in time measurement.On average, this results in a training time of 339.71 seconds (5, 66 minutes) for an RF.An RF is able to classify 92,102 unknown samples within 234.76 seconds. This means that on average performing classification of a single unknown sample takes 0.0025 seconds for RFs including feature extraction.Based on the measurements presented above FANCI is able to perform classification for 400 packets per second on a general purpose computer using a single thread.