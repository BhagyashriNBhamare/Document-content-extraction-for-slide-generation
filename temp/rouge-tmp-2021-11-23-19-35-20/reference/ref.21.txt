Recent work on temporal memory safety has focused on using explicit lock-and-key mechanisms (objects are assigned a new lock upon allocation, and pointers must have the correct key to be dereferenced) or corrupting the pointer values upon free(). A temporal memory error occurs when code uses memory that was allocated, but since freed (and therefore possibly in use for another object), i.e., when an object is accessed outside of the time during which it was allocated.Suppose we have a function pointer stored on the heap that points to function Elmo() (see Figure 1) at address 0x05CADA. In their scheme, the allocator places each allocated object on a distinct virtual page, even though different objects may share the same physical page; when an object is deallocated, the corresponding virtual page is rendered inaccessible, causing pointer accesses after deallocation to fail. Since then, researchers have proposed more elaborate techniques (CETS [31], DangSan [41], Dangling Pointer Nullification [27] ("DangNull") and FreeSentry [42]), relying on combinations of deeper static analysis and comprehensive instrumentation of heap operations such as object allocation, access, and pointer arithmetic. We make the following contributions:• We study in detail the overhead contributed by the distinct factors of the scheme -shared memory mappings, memory-protection system calls invoked during allocation and deallocation, and more page table entries and virtual memory areas -using the standard SPEC CPU 2006 benchmarks (Section 3). The simplicity of the scheme leads to excellent compatibility, deployability, and the lowest overhead: for example, on SPEC CPU, CETS and FreeSentry have 48% and 30% runtime overhead on hmmer respectively, vs. our 0.7% overhead; on povray, DangNull has 280% overhead while ours is < 5%. In this section, we show how different published schemes map to this metaphor, explicitly and sometimes implicitly, and we argue that page-permission-based protection may be the most promising approach for many workloads (see Table 1 for a summary). The keys for someFuncPtr and callback no longer match the lock past line 7, avoiding use after free (Figure 3). Indeed, one of the key advances of CETS over prior lock-and-key schemes is that it uses a disjoint metadata space, with a separate entry for each pointer that stores the key and the lock location; this avoids changing the memory layout of the program. Revoking keys is harder than changing the lock, since it requires tracking of key propagation.Example Systems: To our knowledge, this has not been used for any published explicit lock-and-key scheme; but, it segues to the next idea that has been used in prior work: revoking the keys with implicit lock-and-key. Although this scheme does not need to allocate memory for explicit lock or key fields, it does need to track the location of each pointer, which means the physical memory overhead is at least proportional to the number of pointers. Implicit lock-and-key requires less instrumentation than explicit lock-and-key, and changing locks is simpler than tracking and revoking keys. By removing the mapping or changing the page permissions, we can make a virtual page inaccessible; the underlying physical memory can then be mapped to a different virtual address (changed lock) for reuse. This would still have less overhead than an explicit lock-and-key scheme, because we would not need to instrument pointer arithmetic.Example Systems: Electric Fence [9] implements this scheme, by placing one object per physical frame. The physical memory overhead -one page table entry, one kernel virtual memory area struct, plus some user-space allocator metadata, per object -is proportional to the number of live objects. Implicit lock-and-key schemes that change the lock (i.e., one object per virtual page) are advantageous by having no overhead for any pointer arithmetic, and no direct cost (barring TLB and memory pressure) for pointer dereferences. These measurements informed our approach for reducing the overhead, which are described in the second part of this paper.To help us improve the performance of shadow-pagebased schemes, we first measure their costs and break Explicit lock-and-key: changing the lock e.g., Implicit lock-and-key: revoking the keys e.g., Implicit lock-and-key: changing the lock e.g., down the source of overhead. We measure how much each contributes to the overhead, so we can separate out the cost of each.It is natural to hypothesize that syscall overhead should be proportional to the number of malloc/free operations, as page-permissions-based schemes add one or two syscalls per malloc and free. We quantified the overhead by building and measuring incrementally more complex schemes that bridge the design gap from glibc's malloc to one with shadow virtual pages, one overhead factor at a time.Our first scheme simply changes the memory allocation method. We do not read or write from the padding space, as the goal is simply to measure the reduced locality of reference.Create/disable shadows creates and disables shadow pages in the malloc and free functions using mremap and mprotect(PROT_NONE) respectively, but does not access memory via the shadow addresses; the canonical address is still returned to the caller. To enable the free function to disable the shadow page, we stored the shadow address inside the inline metadata field (recall that in the complete scheme, this stores the canonical). We configured libstdc++ with --enable-libstdcxx-allocator=malloc, and configured the kernel at run-time to allow more virtual memory mappings.We counted malloc and free operations using mtrace. The remaining four benchmarks (perlbench, dealII, omnetpp, xalancbmk) exhaust the physical memory on the machine when creating/disabling shadows, due to the accumulation of vm area structs corresponding to mprotect'ed pages of "freed" objects. We therefore defer discussion of them until the following section, which introduces our improvements to the baseline design.Even for the complete but unoptimized scheme (Use shadows), most benchmarks have low overhead. The cost of using shadows -via TLB pressure -can be reduced with hardware improvements, such as larger TLBs (see Section 6.2). Since disabled shadows still occupy virtual address space, new shadows will not reuse the addresses of old shadows, thus preventing use-after-free of old shadows. As we show in Section 6.1, virtual address space exhaustion is an unlikely, tractable problem.Our scheme, including the high water mark, is compatible with address space layout randomization (ASLR). Over the lifetime of a program, that chunk may be allocated, freed, allocated, freed, etc., resulting in syscalls to create a shadow, destroy a shadow, create a shadow, destroy a shadow, etc. However, for large objects that malloc places on their own physical page frames, Oscar does not need more than one shadow per page frame. However, if the reallocated object (new canonical) is large enough to be stored on its own MAP PRIVATE pages, create shadow will allocate a different set of physical page frames instead of creating an alias. Copying is mildly inefficient, but few programs use realloc extensively.The overhead saving is upper-bounded by the original cost of MAP SHARED arenas.Abandoned approach: Batching system calls. In a microbenchmark, creating and destroying 100 million shadows took roughly 90 seconds with individual mremap/munmap calls (i.e., 200 million syscalls) vs. ≈80 seconds with our batched syscall. We also tried batch-disabling shadows: any objects that are free()'d are stored in a "quarantine" of 100 objects, and when the quarantine becomes full, we disable all 100 shadows with a single batched syscall, then actually free those 100 objects. These two optimizations do not benefit mcf, as its overhead was entirely due to MAP SHARED arenas; instead, fortuitously, the overhead is eliminated by the MAP PRIVATE optimization. Refreshing shadows reduces overhead somewhat for perlbench and omnetpp but increases overhead for xalancbmk and dealII.The MAP PRIVATE optimization had a negligible effect, except for perlbench, which became 30 p.p. slower. A caveat is that CETS' reported overheads are based on providing temporal protection for both the stack and heap, which is more comprehensive than Oscar's heaponly protection. As seen in the graphs, our re-run results are very similar to DangSan's reported results; thus, unless otherwise stated, we will compare Oscar against the latter.Across the complete set of C/C++ SPEC CPU2006 benchmarks, Oscar and DangSan have the same overall overhead, within rounding error (geometric means of 40% and 41%). However, for all four of the allocationintensive benchmarks, as well as astar and gcc, the overheads of both Oscar and DangSan are well above the 10% overhead threshold [39], making it unlikely that either technique would be considered acceptable. In many cases, Oscar has almost zero overhead, implying there are few mallocs/frees (the source of Oscar's overhead); we expect the negligible overhead generalizes to any system. Oscar's performance is excellent compared to FreeSentry and DangNull, even though DangNull provides less comprehensive protection: DangNull only protects pointers to heap objects if the pointer is itself stored on the heap. indicates that DangNull did not report memory usage for dealII, omnetpp, or perlbench, and we could not re-run DangSan on the latter two. We compare Oscar to the temporal-only mode of SoftBoundCETS [32] (which we will also call "CETS" for brevity), since that has lower overhead and a more comprehensive dataset than the original CETS paper.The latest publicly available version of SoftBound-CETS for LLVM 3.4 7 implements both temporal and spatial memory safety. The geometric mean across CETS' subset of CPU2006 benchmarks is 2.8% for Oscar compared to 36% for CETS. com/santoshn/softboundcets-34/commit/ 9a9c09f04e16f2d1ef3a906fd138a7b89df449968 In any case, since CETS has 23% and 114% overhead on bzip2 and mcf respectively -compared to less than 1.5% on each for Oscarincluding them in the comparison would not be favorable to CETS. It is unclear what memory consumption metric DangNull used, so some care should be taken when interpreting their overheads.The RSS values reported in /proc/pid/status are misleading for Oscar because it double-counts every shadow page, even though many of them are aliased to the same canonical. Even if we omit DangSan's pathological case of omnetpp (reported overhead of over 13,000%), Oscar is still far more memory-efficient with 52% overhead vs. 90% for DangSan. DangNull has roughly 127% memory overhead, but, as also noted by the DangSan authors, DangNull did not report data for many of the memory-intensive benchmarks. After fork, in the child, we make a copy of all heap objects, unmap their virtual addresses from the shared physical page frames, remap the same virtual addresses to new (private) physical page frames, and repopulate the new physical page frames with our copy of the heap objects. After this, the child address space is correct, except that the malloc'd memory regions are aliased with the parent's physical page frames.2. in the child process:(a) for each canonical page in the heap: 12 glibc's malloc stores the main heap state in a static variable (not shared between parent and child), but also partly through inline metadata of heap objects (shared); thus, when the parent or child allocates memory post-fork, the heap state can become inconsistent or corrupted. (b) for each live object: use mremap to recreate a shadow at the same virtual address as before (using the child's new physical page frames). To cover the remaining, less common case of programs that arbitrarily mix threads and fork, Oscar could "stop the world" as in garbage collection, or LeakSanitizer (a memory leak detector) [1]. The overheads reported for SPEC CPU are based on instrumenting the standard malloc/free only, providing a level of protection similar to prior work. Since standard schemes for temporal memory safety require instrumenting memory allocation and deallocation functions, without special provisions none of them -including Oscar -will protect objects allocated via arbitrary CMAs. We compiled memcached 1.4.25 (and its prerequisite, libevent) and benchmarked performance using memaslap.When we wrapped only glibc's malloc, the overhead was negligible: throughput was reduced by 0-3%, depending on the percentage of set operations ( Figure 17). However, this is misleadingly low, as it fails to provide temporal memory safety for objects allocated by the CMA. Additionally, we partitioned the address space to use separate high-water marks for the malloc wrapper and CMA wrapper.We identified that allocations and deallocations via memcached's slab allocator are all made through the do item alloc and item free functions. If Oscar switched to a disjoint metadata store (e.g., a hashtable), it would be easy to extend Oscar to protect any custom memory allocators (not just CMAs with malloc-like interfaces) that are identified: as with glibc's malloc, the allocator function simply needs to be wrapped to return a new shadow, and the deallocator function wrapped to destroy the shadow. The distinguishing feature is that only the entire region can be freed, but not individual objects.Region-based allocators by themselves are not resistant to use-after-free, since the blocks from malloc may be reused, but they provide temporal memory safety when the underlying malloc/free is protected by a lock-and-key scheme. Thus, there is no need to explicitly identify region-based CMAs; merely wrapping glibc's malloc/free with Oscar suffices to provide temporal memory safety for such programs i.e., Oscar would provide full use-after-free protection for a region-based allocator, without the need for any custom modifications.Oscar's performance is especially good for programs that use region-based allocators: since there are few malloc()s or free()s to instrument, and correspondingly low memory or TLB pressure, Oscar imposes negligible overhead. For example, with perlbench, which allocates 361 million objects (≈1.4TB of shadow virtual pages; >99% of objects fit in one page) over 25 minutes, it would take 1.6 days (albeit less on newer, faster hardware) to allocate 128TB. Due to the high overhead of software-based temporal memory safety for C, some have proposed hardware extensions (e.g., Watchdog [30]). For example, DangNull/FreeSentry do not work correctly with encrypted pointers (e.g., PointGuard [21]) or with typecasting from non-pointer types. CETS has false positives when casting from a non-pointer to pointer, as it will initialize the key and lock address to invalid values.Additionally, DangNull does not allow pointer arithmetic on freed pointers. It does work with DangSan and FreeSentry (since they only change the top bits) and with Oscar.DangSan, DangNull and FreeSentry only track the location of pointers when they are stored in memory, but not registers. Unfortunately, writes to old (pre-fork) heap objects will be propagated between parent and children (see Section 5.1), resulting in memory corruption.While Dhurjati and Adve did measure the runtime of their particular scheme, their measurements do not let us break down how much each aspect of their scheme contributes to runtime overhead. For these reasons, in this work we undertook a more systematic study of the sources of overhead in shadow-page-based temporal memory safety schemes.To reduce their system's impact on page table utilization, Dhurjati and Adve employed static sourcecode analysis (Automatic Pool Allocation) -to separate objects into memory pools of different lifetimes, beyond which the pointers are guaranteed not to be dereferenced. Oscar's optimizations do not require application source code or compiler changes.We cannot directly compare Oscar's overhead to Dhurjati and Adve's full scheme with automatic pool allocation, since they did not report numbers for SPEC CPU.Oscar usually keeps less state for freed objects: they retain a page table entry (and associated vm area struct) for each freed object in live pools -some of which may be long-lived -whereas Oscar munmaps the shadow as soon as the object is freed (Table 2). This is perfectly secure, does not require application source code (change the free function to be noop), has excellent compatibility, and low run-time overhead. It would be impractical to rewrite all legacy C/C++ software in Rust, let alone provide Rust's guarantees to binaries that are compiled from C/C++. They do not provide SPEC results, but we expect it to be even slower than DangNull/FreeSentry, because Undangle determines how pointers are propagated by, in effect, interpreting each x86 instruction.Safe dialects of C, such as CCured [33], generally require some source code changes, such as removing unsafe casts to pointers. Cling [11] only reuses memory among heap objects of the same type, so it ensures type-safe heap memory reuse but not full heap temporal memory safety. Note that the memory overhead comparison in Section 4.3 already counts the size of paging structures against Oscar, yet Oscar still has lower overall overhead despite not cleaning up the paging structures at all.We did not encounter any issues with users' mmap requests overlapping Oscar's region of shadow addresses (or vice-versa), but it would be safer to deterministically enforce this by intercepting the users' mmap calls.Currently, all threads share the same high-water mark for placing new shadows, and this high-water mark is protected with a global mutex. The overheads reported for SPEC CPU are based on instrumenting the standard malloc/free only, providing a level of protection similar to prior work. Oscar thereby brings page-permissions-based protection schemes to the forefront of practical solutions for temporal memory safety.