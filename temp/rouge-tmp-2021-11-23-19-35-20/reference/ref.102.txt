We show how to compile our new calculus into the applied pi-calculus so that protocols can be automatically checked with the ProVerif tool and we use this to analyse distance bounding protocols from Master-Card and NXP. Thieves relay signals from a victim's key fob (located inside the victim's house) to the victim's car (parked outside), which enables the thieves to unlock the car, start the engine, and drive away.Distance bounding protocols [11] use round trip times to establish an upper-bound on the distance between a "prover", e.g., a contactless payment card or key fob, and a "verifier", e.g., a payment machine or car. Attackers may relay, replay and alter messages, as well as trying to predict or preempt timed challenges. The literature on symbolic verification of distance bounding protocols includes five different types of attacks, each of which uses some combination of basic, unprivileged attackers, dishonest prover attackers, and terrorist fraud attackers. These protocols need not defend against at-tacks requiring dishonest provers, because if an attacker gets access to the secret keys, they can clone the cards or key fobs, and make payments or gain access without a need to relay the original device, i.e., protection is only needed for an uncompromised device.However, we expect some devices (e.g., EMV cards or car fobs) may be compromised at some point, and we would like to ensure that the compromise of a particular prover would not lead to an attacker being able to successfully attack other provers. None of the commonly considered distance bounding security properties (which are presented in the next section) match this attacker model.Using our calculus, we are able to consider all possible combinations of verifiers, provers and dishonest provers and so enumerate all possible distance bounding attack scenarios. Moreover, it shows that when an attacker can only act remotely, protection against "distance hijacking" attacks [13] is the most powerful property needed. Defending against this kind of attack is the strongest security property needed for protocols such as MasterCard's RRP to protect contactless payment cards or NXP's proximity check when being used to protect, e.g., access to buildings.We demonstrate the applicability of our results by analysing MasterCard's RRP protocol for distance bounding of contactless EMV [20], and a distance bounding protocol from NXP [14,25]. Our models, compiler and full paper (with proofs) are on our project website https://cs.bham.ac.uk/ ~ tpc/ distance-bounding-protocols/ Related work: Some prior work on the verification of distance bounding protocols has used manual reasoning, e.g., [30,34] in the symbolic model, [4,9,10,18] in the computational model and [13,34] using theorem provers.Some previous work on automatic analysis of distance bounding protocols has been based on the applied picalculus: Malladi et al. [27] analyse single runs, Chothia et al. [12] analyse an arbitrary number of runs for relay attacks, and Debant et al. [15] provide a model with a formal correctness proof, which uses a definition of relay attack that is close to our definition of uncompromised distance bounding.Nigam et al. [31] introduce an extension to strand spaces to model security protocols that include time and Kanovich et al. [26] consider a multiset rewriting model and compare discrete and continuous time. Mauw et al. [28] improves on the framework of [34] looking at causality between actions to make a framework for automatically testing distance fraud and terrorist fraud.None of the previous papers on symbolic checking of distance bounding protocols consider the full range of distance bounding properties or makes comparisons between them.A recent survey [3] gives many examples of distance bounding protocols and attacks. However, as we discuss in Section 5, if an EMV card has been compromised, then there is no need to relay it, hence such "distance fraud attacks" are not the correct attacker model for contactless EMV. The prover waits for nonce chal before revealing nonce resp, hence, the nonce is only revealed once the verifier's timer is running.This protocol is not vulnerable to relay fraud because only the prover can decrypt the challenge and response, and an honest prover will not release the response until it receives the challenge, i.e., the attacker cannot learn the response until the timer has started, and then, if the prover is remote from the verifier, it will be impossible to get this response to the prover without the timer expiring.Our example protocol does not defend against a dishonest prover that tries to trick the verifier, i.e., a prover can convince the verifier that it is nearer than it really is. • Terrorist Fraud [16]: A terrorist fraud attack involves one attacker acting locally to the verifier along with a remote dishonest prover, with the goal of making the verifier believe that the remote dishonest prover is in fact local. • Assisted Distance Fraud [13]: A terrorist prover remotely authenticates to a verifier, assuming the cooperation of another dishonest prover that is colocated with the verifier.We can stop our example protocol being vulnerable to distance fraud attacks by adding a new nonce that is sent with the challenge, and also needs to be included with the response. However, such a protocol would still be vulnerable to terrorist fraud attacks, because a remote dishonest terrorist fraud prover could decrypt the challenge and response and send them to an accomplice attacker that is local to the verifier, which can then use them to answer the verifier's challenge within the time limit.This terrorist fraud attack can be stopped by, for instance, requiring the prover to hash the response with their secret key. However, if the same key is used by multiple provers then the protocol is vulnerable to distance hijacking and assisted distance fraud, because the dishonest prover could send the challenge and response to some honest prover that is co-located with the verifier. We assume that the attacker Figure 1 The timer location calculus syntaxM, N ::= terms x, y, z variables a, b, c, k names f (M 1 , . . . , M n ) constructor application D ::= g(M 1 , . . . , M n ) destructor application P, Q ::= processes 0 nil out(N). P replication new a.P restriction let x = D in P else Q term evaluation event(M 1 , . . . , M n )an event startTimer.P timer activation stopTimer.P timer terminationS ::= systems [{P 1 , . . . , P n }] r a location newãnew˜newã.S restriction [{P 1 , . . . , P n }] r | S locationscontrols the network, so processes are not able to ensure that a particular output goes to a particular input. PRole(id)We define PRole(id) in the next example to model a single run of the protocol with identity "id", so ! new id" term at the front of the process generates an arbitrary number of new process ids.Cryptography is modelled using constructors and destructors, e.g., symmetric key encryption can be modelled using a binary constructor enc(m, k) to represent the message m encrypted with the key k and a binary destructor function dec with the rewrite rule dec(enc(m, k), k) = m. Functions can be public, i.e., available for use by the attacker, or private meaning that they cay only be used by processes specified as party of the protocol. A single run of the prover role of the protocol informally described in Example 1, with identity id, can be modelled as the process:PRole(id) = out(id) . Next, we present our additions, namely, locations and timers.The process startTimer.P represents starting a timed challenge and stopTimer.P represents ending a challenge. We require that every start timer action is matched by exactly one stop timer action along all possible paths, and replication and parallel composition are forbidden between start and stop timer actions.Example 5. in(id) . Hence, in the latter system, it should not be possible for the prover to answer the timed challenge within the time limit, therefore a correct distance bounding protocol will not allow the prover to be verified.Semantics: Dynamic behaviour of processes (which model protocols) can be examined using the semantics of our language (Figure 2), which is defined over system configurations, denoted E, L , where that E is a set of free names and L is a finite multiset of systems.The set E keeps track of the names that have been assigned so far, making it possible for the new command to pick fresh previously unused names, this is done by the (NEW) rule. The (REPL) rule creates a copy of a replicated process, the (LET 1) rule can be used to apply functions, e.g., for decryption, and the (LET 2) rule selects the else branch when no function reductions are possible (this, for instance, allows us to define equality tests). Rule (I/O LOCAL) defines local communication, which allows messages to be exchanged between co-located processes, regardless of whether timers are running.Example 7 (Local communication). P, P}] r } (REPL) E, L ∪ { [P ∪ {P | Q}] r } → E, L ∪ { [P ∪ {P, Q}] r } (PAR) E, L ∪ { [P ∪ {new a.P}] r } → E ∪ {a }, L ∪ { [P ∪ {P{a /a}}] r } (NEW) for some name a / ∈ E E, L ∪ { [P ∪ {let x = D in P else Q}] r } → E, L ∪ { [P ∪ {P{M/x}}] r } (LET 1) if there exists M such that D → M E, L ∪ { [P ∪ {let x = D in P else Q}] r } → E, L ∪ { [P ∪ {Q}] r } (LET 2) if there is no M such that D → M E, L ∪ { [P ∪ {out(M). P P such that processes P V and P P do not contain variable x (hence, we need not consider substitutes for x in these processes). P P 1 →E, stopTimer.P V , P P 1 →E, P V , P P 0By comparison, the processes cannot complete the challenge from distinct locations. P P 0 } → * E, { stopTimer.P V 1 P P 0 } → E, { P V 0 P P 0 }Note that the message received by P V uses the name p rather than the challenge name a, hence, when using preemption there is no way in which the answer to the response to a timed challenge can be based on the message outputted as part of that challenge.Rule (ASYNC) defines asynchronous communication, which prevents processes from blocking when they are ready to output. We require that no further events are used in either process and the only free names (i.e., names not declared as new or bound by an input) used are those iñ n and the public channel c.Process Q models a single run of a prover with the identity id and P(id) represents arbitrarily many distinct provers, each of which can run arbitrarily many times. These holes denote the locations in a system where the attacker can act, and we write them as A. E.g., the system contextC 1 = new k.[Veri f ierE | A ] | [ ProverE(id) | A ]represents a scenario in which the attacker can be co-located with the verifier V , and co-located with the prover Q, whereasC 2 = new k.[ Veri f ierE ] | [ ProverE(id) | A ]represents a scenario in which the attacker is co-located with the prover and is remote from the verifier. Given a name id and a system context C, we write verified(id):C if there exists a process P A and a trace:{c},C[P A ] − → * E, L ∪ {[P ∪ {new id.P}] r } − → E ∪ {id }, L ∪ { P ∪ {P{ id / id }} r } − → * E , L ∪ {[P ∪ {event(verify(id )). There is no process P A such that verified(id):[ Veri f ierE | P A ] | [ProverE(id) | P A ], i.e., no attacker can trick the verifier into believing that it has verified id when the provers are at a different location. Q | A, where Q outputs bound and free names of Q (including names iñ n, which are otherwise hidden from the attacker) and the results of any private function applications in Q, and A is the context hole.The process DP-A(id) reveals all the secret values of a normal prover to the attacker, which captures a dishonest prover attacker.Example 11. out(k) | P A ] can reduce such that the verifier can perform the veri f ied event, which means that verified(id) : [ VerifierE ] | [ DP-A(id) ] holds and the attack is possible.The attack works because the attacker can preempt the challenge. Intuitively, the nonce c2 is only sent when the timer is running, so the attacker can never return this in time if not co-located with the verifier.Terrorist provers are less powerful than dishonest provers, because they will not send their secret values to a third party. [ V | DP-A(id ) ] | [ T P-A(id) ]where P(id) = ! This suffices to show verified(id):new k.[ V | A ] | [ T P-A(id) ],hence, the specification is vulnerable to terrorist fraud.Example 13. let (chal, resp) = dec(x, lookup(id)) in out(ready) . These scenarios consider the following terms:• V | A, a verifier co-located with a basic attacker (relay fraud and terrorist fraud); • V , a verifier in isolation (distance fraud);• V | P(id ), a verifier co-located with honest provers (distance hijacking); • V | DP-A(id ), a verifier co-located with dishonest provers (assisted distance fraud);• P(id) | A, remote provers co-located with an attacker (relay fraud); • DP-A(id), remote dishonest provers in isolation (distance fraud and distance hijacking); and • T P-A(id), remote terrorist provers in isolation (terrorist fraud and assisted distance fraud). For any distance bounding protocol specification (P(id),V, ˜ n), from which we derive DP-A and T P-A, and for all system contexts C, sets of names E and names x ∈ {id, id }, we haveverified(id):C[A | P(x)] ⇒ verified(id):C[T P-A(x)] ⇒ verified(id):C[DP-A(x)]Moreover, no reverse implication holds.By filling a context's hole with a process containing a hole (as above), we derive a context (which is required by the verified predicate). For any distance bounding protocol specification (P(id),V, ˜ n), from which we derive DP-A and T P-A, and for any system contexts C[ ], sets of names E, names id and id , and X ∈ {P, DP-A, T P-A}, we have:verified(id):C[X(id ) | X(id)] ⇔ verified(id):C[X(id)]It follows from Lemma 2 that if process X(id) is present, then it is not necessary to consider the corresponding X(id ) process as well.When there is a dishonest prover at a different location to a basic attacker process, the dishonest prover could send all of its secrets to the basic attacker process enabling it to also act as a dishonest prover:Lemma 3. This partial ordering of attack scenarios the Appendix tells us that protection against distance hijacking attacks is strictly stronger than security against distance fraud attacks, and that security against assisted distance fraud is stronger than security against terrorist fraud attacks, which in turn is a stronger property than security against relay attacks. Therefore, the strongest property that a distance bounding protocol can have is protection from both distance hijacking and assisted distance fraud.To separate many of the distance bounding properties we need to consider a verifier that will verify any process that sends it a secret key. We write [V (id) | P] | [Q] for verified(id):[V | P] | [Q] Distance Fraud [V(id)] | [DP(id)] Mafia fraud/Relay [V(id)|A] | [P(id)|A] [V(id)] | [P(id)|A] [V(id)|P(id')] | [P(id)|A] Terrorist Fraud [V(id)|A] | [TP(id)] [V(id)|P(id')|A] | [TP(id)] Distance Hijacking [V(id)|P(id')] | [DP(id)][V(id)] | [P(id)|DP(id')] [V(id)|A] | [P(id)|TP(id')] [V(id)|P(id')] | [P(id)|DP(id')] [V(id)|P(id')|A] | [P(id)|TP(id')]No terrorist a6ackerRemote and local a6ackersKey: P(id): honest provers with idenGty "id" V(id): verifier wishing to verifier "id" A: a6acker process TP(id): terrorist provers, acGng as "id" DP(id): dishonest provers, acGng as "id"Prover being checked is compromisedProver being checked is not compromised a distance bounding protocol is secure against this attack scenario, then none of the other attacks are possible. Given a name id and a distance bounding protocol (V, P(id), ˜ n), from which we derive a dishonest prover DP-A(id ), we say that the protocol is vulnerable to an uncompromised distance bounding attack if: verified(id):newñnew˜newñ. [V | DP-A(id )] | [P(id) | A]therefore any of these system contexts could be used to represent uncompromised distance bounding attacks.We choose the one that makes it clear that the dishonest prover can act at both locations.The purple dot-dashed line separates the attack scenarios that have only a remote attacker from those that let the attacker act both locally to the verifier and remotely. • If a distance bounding protocol assumes trusted hardware devices, then the strongest attack that needs to be defended against is relay hijacking:verified(id):[V | P(id ) | A] | [P(id) | A]. L n , where L 1 , . . . , L n are linear processes.Linear processes allow us to express all distance bounding protocols from the literature, so they do not reduce the usefulness of our method.Using linear processes, we introduce a technique to simplify the detection of vulnerabilities and define a compiler that allows us to take advantage of that technique. V L | L v | A] | [L p | A], sets of names E and name id, such that V L , L v and L p are linear processes and only V L contains a timer, we have:verified(id):newñnew˜newñ. Thus, compilation encodes timers as phases.Encoding the activation and deactivation of timers as phases is straightforward, indeed, we merely replace startTimer.P with 1 : P and stopTimer.Q with 2 : Q. But, encoding the advancement of other processes at the same location as the timer from phase 0 to phase 1 is problematic, as is advancing processes at different locations from phase 0 to phase 2, because we cannot know when processes should advance. P n where {P 1 , . . . , P n } = phasesSet(P , ds), P equals P with every in(x) replaced with in(c,x) and every out(M) replaced with out(c,M) and function phasesSet is defined as follows:phasesSet(P, [d]) = {C[d : in(M, x). new id.phases(P L , [2]) | phases(L p , [2]))where tToPh(L) is L after replacing startTimer.P with 1 : P and stopTimer.Q with 2 : Q and every in(x) replaced with in(c,x) and every out(M) replaced with out(c,M)Timers limit communication between locations. 1 : in(priv, x).2 : out(c, x), which allows messages sent on public channel c in phase 0 (before the timer starts), respectively private channel priv in phase 1 (whilst the timer is running), to be received on private channel priv in phase 1, respectively public channel c in phase 2 (after the timer stops). P L | L p | A]and a name id, we define compile(id, S) asnew priv.newñnew˜newñ. P j } → E j ∪ {b j }, P i ∪ {P j {b j /a j }}The following theorem tells us that we can check the compiled system in the applied pi-calculus and concluded security results about the system with locations:Theorem 1. P L | L p | A], and a name id, we have not ev(verify(id)), {c} : compile(id, S) ⇒ ¬ verified({c}, id):S We have implemented the compiler introduced in the previous section. The EMV protocol comprises of an exchange of transaction data and then the card generates a MAC (called the Application Cryptogram or AC) using a session key based on a key shared between the smart card and the card issuer and the Application Transaction Counter (ATC), which equals the number of times the card has been used and will provide freshness to the transaction. In a regular EMV session, a transaction is initiated by executing the SE-LECT command, to select the EMV applet on the smart card, and then the GET PROCESSING OPTIONS command to provide information about the capabilities of the terminal to the card.The card will typically respond to the GET PRO-CESSING OPTIONS message with the Application Interchange Profile (AIP) and Application File Locator (AFL), used to indicate the capabilities of the card and the location of data files respectively. This means that we do not consider attacks such as terrorist fraud or distance hijacking applicable to these protocols.NXP's distance bounding protocols: NXP's Mifare Plus cards are used in, for example, public transport and for building access control and also make use of the ISO/IEC 14443 specification for contactless communication. The card generates a random 8-byte number n P and sends timing information to the reader indicating how long a n V ∈ R {0, 1} 64 PROXIMITY CHECK, n V timed n P VPC, MAC k (VPC, n V , n P ,ti) MAC k (CK, n V , n P ,ti)reply to the distance bounding check should take. We check that every end event has a corresponding start event, i.e., the verifier only accepts timing information as valid for a prover if the prover also performed a session with that timing information.Analysis and results: We modelled MasterCard's RRP, PaySafe, NXP's protocols and several protocols from the literature as well as our example protocols in our calculus. It follows that your bank card is safe from relay attacks, even if someone else's card is compromised. This would represent a major security risk with, for example, a single compromised key fob putting all cars at risk.The only property that can distinguish the case where one compromised device leads either to an attack only on this one device or to the compromise of the complete system, is our proposed uncompromised distance bounding property. We have defined a compiler from our calculus to the applied pi-calculus and use this compiler to analyse several distance bounding protocols, including protocols by MasterCard and NXP.