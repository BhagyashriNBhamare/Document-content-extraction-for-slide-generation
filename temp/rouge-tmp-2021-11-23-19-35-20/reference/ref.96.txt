The recent European General Data Protection Regulation (GDPR) restricts the processing and exploitation of some categories of personal data (health, political orientation , sexual preferences, religious beliefs, ethnic origin , etc.) due to the privacy risks that may result from malicious use of such information. This paper quantifies the portion of Facebook users in the European Union (EU) who were labeled with interests linked to potentially sensitive personal data in the period prior to when GDPR went into effect. In particular, the GDPR defines as sensitive personal data: "data revealing racial or ethnic origin, political opinions, religious or philosophical beliefs, or trade union membership, and the processing of genetic data, biometric data for the purpose of uniquely identifying a natural person, data concerning health or data concerning a natural person's sex life or sexual orientation". Due to the legal, ethical and privacy implications of processing sensitive personal data, it is important to know whether online services are commercially exploiting such sensitive information. This illustrates that FB may be actually processing sensitive personal information, which is now prohibited under the EU GDPR without explicit consent and also under some national data protection regulations in Europe. We leave analysis of Facebook data practices following the May 25, 2018 GDPR effective date (when violations could be enforceable) to future work.To achieve our goal we analyze more than 5.5M ad preferences (126K unique) assigned to more than 4.5K FB users who have installed the Data Valuation Tool for Facebook Users (FDVT) browser extension [12]. The reason for using ad preferences assigned to FDVT users is that we can prove the ad preferences considered in our study have been indeed assigned to real users.The first contribution of this paper is a methodology that combines natural language processing techniques and manual classification conducted by 12 panelists to obtain those ad preferences in our dataset potentially linked to sensitive personal data. For instance, the ad preferences "Homosexuality" and "Communism" may reveal the sexual orientation and the political preference of a user, respectively.Once we have identified the list of potentially sensitive ad preferences, we use it to query the FB Ads Manager in order to obtain the number of FB users and citizens exposed to these ad preferences in the whole EU as well as in each one of its member states. -We perform a ball-park estimation that suggests that unveiling the identity of FB users labeled with potentially sensitive ad preferences may be as cheap as e0.015 per user. The FB Ads Manager offers advertisers a wide range of configuration parameters such as (but not limited to): location (country, region, city, zip code, etc.), demographic parameters (gender, age, language, etc.), behaviors (mobile device, OS and/or web browser used, traveling frequency, etc.), and interests (sports, food, cars, beauty, etc.). An example of an audience could be "Users living in Italy, ranging between 30 and 40 years old, male and interested in Fast Food". 3 Therefore, if a user is assigned "Watches" within her list of ad preferences, she will be a potential target of any FB advertising campaign configured to reach users interested in watches.Any user can access and edit (add or remove) her ad preferences, 4 but we suspect that few users are aware of this option. By examining 5.5M ad preferences assigned to FDVT users (see Subsection 2.3), we have found 6 reasons for the assignment of ad preferences: (i) This is a preference you added, (ii) You have this preference because we think it may be relevant to you based on what you do on Facebook, such as pages you've liked or ads you've clicked, (iii) You have this preference because you clicked on an ad related to..., (iv) You have this preference because you installed the app..., (v) You have this preference because you liked a Page related to..., (vi) You have this preference because of comments, posts, shares or reactions you made related to... 2 Business and industry, Education, Family and relationships, Fitness and wellness, Food and drink, Hobbies and activities, Lifestyle and culture, News and entertainment, People, Shopping and fashion, Sports and outdoors, Technology, Travel places and events, Empty.3 Given that interests and ad preferences refer to the same thing, we use these two terms interchangeably in the rest of the paper 4 Access and edit ad preference list: https://facebook.com/ ads/preferences/edit The Data Valuation Tool for Facebook Users (FDVT) [12] is a web browser extension currently available for Google Chrome 5 and Mozilla Firefox. We leverage this information to identify potentially sensitive ad preferences assigned to users that have installed the FDVT. Article 9 is entitled "Processing of special categories of personal data" and states in its first paragraph: "Processing of personal data revealing racial or ethnic origin, political opinions, religious or philosophical beliefs, or trade union membership, and the processing of genetic data, biometric data for the purpose of uniquely identifying a natural person, data concerning health or data concerning a natural person's sex life or sexual orientation shall be prohibited". In the fine's resolution [6] the AEPD claims that FB collects, stores and processes sensitive personal data for advertising purposes without obtaining consent from users. More details about the analysis of FB terms of service are provided in Appendix C. To uncover potentially sensitive ad preferences and quantify the portion of EU FB accounts associated with them, we seek to collect a dataset of ad preferences linked to actual EU FB accounts. These 4577 FDVT users have been assigned 5.5M ad preferences in total of which 126192 are unique.Our dataset includes the following information for each ad preference:-ID of the ad preference: This is the key we use to identify an ad preference independently of the language used by a FB user. For instance, the ad preference {Milk, Leche, Lait} that refers to the same thing in English, Spanish and French, is assigned a single FB ID. -Topic Category: In many cases, some of the 14 first level interests introduced in Section 2.1 are assigned to contextualize ad preferences. For instance, Manchester United F.C. is linked to Sports and Outdoors.-Audience Size: This value reports the number of Facebook users that have been assigned the ad preference worldwide.-Reason why the ad preference is added to the user: The reason why the ad preference has been assigned to the user according to FB. However, it is important to note that many ad preferences still reach a reasonable portion of users. However, manually classifying 126K ad preferences would be unfeasible. Sensitive categories: To identify likely sensitive ad preferences in an automated manner, we select five of the relevant categories listed as Sensitive Personal Data by the GDPR: (i) data revealing racial or ethnic origin, (ii) data revealing political opinions, (iii) data revealing religious or philosophical beliefs, (iv) data concerning health, and (v) data concerning sex life and sexual orientation. For instance, the ad preferences "Socialism","Islam","Reproductive Health","Homosexuality" or "Black Feminism" may suggest political opinion, religious belief, health issue, sexual orientation or ethnic or racial origin of the users that have been assigned them, respectively. Our automated process will classify an ad preference as likely sensitive if we can semantically map that ad preference name into one of the five sensitive categories analyzed in this paper. It is worth noting that this approach makes our methodology flexible, since the dictionary can be extended to include new keywords for the considered categories or other categories, which may uncover additional potentially sensitive ad preferences.We next describe the semantic similarity computation in detail.Semantic similarity computation: The semantic similarity computation process takes two inputs: the 126K ad preferences from our FDVT dataset and the 264 keyword dictionary associated with the considered sensitive categories. As result of this process, each one of the 126K ad preferences is assigned a similarity score, which indicates its likelihood to be a sensitive ad preference.To implement the semantic similarity comparison task, we leverage the Spacy package for python 11 (see details about Spacy in Appendix D). This similarity score represents the anticipated likelihood for an ad preference to be sensitive.In this step of the process, we have to select a relatively high similarity score threshold that allows us to create a subset of likely sensitive ad preferences that can be manually labeled with reasonable manual effort. The resulting automatically filtered subset includes 4452 ad preferences (3.5% of the 126K), which is a reasonable number to be manually tagged.Note that the CDF has two jumps at similarity scores equal to 0.5 and 0.58. To carry out the manual labeling, the researchers were given all the contextual information Facebook offers per ad preference: name, disambiguation category (if available) and topic (if available). We use majority voting [20] to classify each ad preference either as sensitive or non-sensitive. This indicates an almost perfect agreement among the panelists' votes that link an ad preference to a sensitive category [16]. Hence, we conclude that (almost) every ad preference classified as sensitive corresponds to a unique sensitive category among the 5 considered.The 2092 ad preferences manually labeled as sensitive are distributed as follows across the five sensitive categories: 58.3% are related to politics, 20.8% to religion, 18.2% to health, 1.5% to sexuality, 1.1% to ethnicity and just 0.2% present discrepancy among votes. The complete list of the ad preferences classified as sensitive can be accessed via the FDVT site. An example of this for N = 3 could 13 https://fdvt.org/usenix2018/panelists.html be "how many people in France are interested in Communism OR Islam OR Veganism". It is computed as the ratio between the number of FB users that have been assigned at least one of the top N potentially sensitive ad preferences and the total number of FB users in country C, which can be retrieved from the FB Ads Manager.-FC(C,N): This is the percentage of citizens in country C (or all EU countries together) that have been assigned at least one of the top N potentially sensitive ad preferences. Beyond N = 1000 interests the API provides a fixed number of FB users independently of the defined audience. There are very few cases (0.03%) in which users proactively include potentially sensitive ad preferences in their list of ad preferences using the configuration setting offered by FB. We note that we have obtained the same stable result for each individual EU country. This indicates that any user tagged with potentially sensitive ad preferences outside the top 500 16 has likely been already tagged with at least one potentially sensitive ad preference within the top 500. In contrast, the 5 countries least impacted are: Germany (30.24%), Poland (31.62%), Latvia (33.67%), Slovakia (35%) and Czech Republic (35.98%). This means that approximately 2/3 or more of FB users in any EU country are tagged with some of the top 500 potentially sensitive ad preferences.These results suggest that a very significant part of the EU population can be targeted by advertising campaigns based on potentially sensitive personal data. These findings suggest that FB may have used GDPR-relevant data for a large percentage of EU citizens in the period prior to when the GDPR became enforceable. Figures 6 and 7 report the results for age and gender groups, respectively.The Early Adulthood group is clearly the most exposed age group to suspected (20-expert-verified) sensitive ad preferences. This result suggests the existence of a gender bias, which despite its obvious interest is out of the scope of this paper. Between October 6 and October 15, 2017 we ran three FB ad campaigns using expert-verified sensitive ad preferences such as: "religious beliefs" (targeting users interested in Islam OR Judaism OR Christianity OR Buddhism), "political opinions" (targeting users interested in Communism OR Anarchism OR Radical feminism OR Socialism) and "sexual orientation" (targeting users interested in Transsexualism OR Homosexuality). Below, we illustrate two specific examples of potential attacks.Hate campaigns: An attacker could create hate speech campaigns using sensitive ad preferences representative of a specific sensitive social group within its target audience. For instance, a neo-Nazi organization could create ads campaigns with offensive messages targeting people interested in Judaism or Homosexuality. Using as a reference this success rate for phishing attacks and the results from the ad campaigns described in Section 7, we can make a ball-park estimation of the cost of identifying users tagged with expert-verified sensitive ad preferences. We spent e35 on our ad campaigns to reach 26K users from which 2.34K (according to the 9% reference success rate) may provide personal information on the attacker's webpage that could reveal their identity. For instance, (i) in countries where homosexuality is considered illegal or immoral governments or other organizations could obtain the identity of people that are likely homosexual (e.g., interested in homosexuality,LGBT, etc.); (ii) neo-Nazi organizations could identify people in specific regions (by targeting a town or even a zip code) that are likely Jewish (e.g., interested in Judaism, Shabbat, etc.); (iii) health insurance companies could try to identify people that may have non-profitable habits (e.g., interested in tobacco, fast food, etc.) or health problems (e.g., food intolerance) to reject them as clients or charge them more for health insurance. Users may face the negative consequences of such phishing-like attacks even if FB has wrongly labeled them with some sensitive ad preference.In summary, although Facebook does not allow third parties to identify individual users directly, ad preferences can be used as a very powerful proxy to perform identification attacks 18 based on potentially sensitive personal data at a low cost. To set this threshold, we use the automatically filtered dataset from Section 5.1.2. Even though the classifier may be imperfect, it still may achieve the goal of increasing collective awareness among FB users regarding the potential use of sensitive personal data for advertising purposes. They create bots, referred to as personas, with very specific interest profiles (e.g., persona interested in cars) and measure how many of the received ads actually match the specific interest of the analyzed persona. The authors state that if some of the unveiled inserts are sensitive, it could imply serious privacy risks for users.Venkatadri et al. [26] and Speicher et al.[25] exposed privacy and discrimination vulnerabilities related to FB advertising. They conclude that the reasons why ad preferences are assigned are vague.In summary, the existing literature suggests that the online advertising ecosystem (beyond Facebook) exploits sensitive personal information for commercial purposes. We illustrate how FB users that have been assigned sensitive ad preferences could face risks, like low-cost targeted attacks seeking to identify such users. The results of our paper urge a quick reaction from Facebook to eliminate all ad preferences that can be used to infer the political orientation, sexual orientation, health conditions, religious beliefs or ethnic origin of a user for two reasons: (i) this may avoid Facebook running afoul of Article 9 of the GDPR, and (ii) it may protect users from threats that exploit this sensitive data. In this section, users are informed that FB can use the user information, name, picture, etc. for advertising and commercial purposes.Section 10. 26 The latter document includes 13 sections from which Section 4.12 27 23 https://www.facebook.com/terms.php (accessed December 19,2017) 24 https://www.facebook.com/about/privacy/ (accessed December 19,2017) 25 https://www.facebook.com/legal/self_service_ads_ terms (accessed December 19, 2017) 26 https://www.facebook.com/policies/ads/ (accessed December 19,2017) 27 https://www.facebook.com/policies/ads/prohibited_ content/personal_attributes (accessed December 19,2017) (4-Prohibited Content; 12-Personal attributes) is very relevant for our paper. Examples of what content is allowed and what content is prohibited are provided in the Advertising Policies. In addition, Spacy also takes into account context to define the representation of a word, which allows Spacy to better identify its meaning considering the surrounding words. R. Cuevas acknowledges funding from the European H2020 project SMOOTH (786741). xA GDPR exceptions for processing sensitive personal dataBelow we list the exceptions included in GDPR Article 9 that allow processing sensitive information. B Spanish DPA resolution related to FB fineIn this appendix, we list the main elements included in the Spanish DPA resolution associated with the e1.2M fine imposed on FB for violating the Spanish data protection regulation.-The Agency notes that the social network collects, stores and uses data, including specially protected data, for advertising purposes without obtaining consent.-The data on ideology, sex, religious beliefs, personal preferences or browsing activity are collected directly, through interaction with their services or from third party pages without clearly informing the user about how and for what purpose will use those data.-Facebook does not obtain unambiguous, specific and informed consent from users to process their data since the information it offers is not adequate -Users' personal data are not totally canceled when they are no longer useful for the purpose for which they were collected, nor when the user explicitly requests their removal. (g) "processing is necessary for reasons of substantial public interest, on the basis of Union or Member State law which shall be proportionate to the aim pursued, respect the essence of the right to data protection and provide for suitable and specific measures to safeguard the fundamental rights and the interests of the data subject". (j) "processing is necessary for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes in accordance with Article 89(1) based on Union or Member State law which shall be proportionate to the aim pursued, respect the essence of the right to data protection and provide for suitable and specific measures to safeguard the fundamental rights and the interests of the data subject".