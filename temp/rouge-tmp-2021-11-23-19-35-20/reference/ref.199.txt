Mutation-based fuzzing is one of the most popular vulnerability discovery solutions. MOPT utilizes a customized Particle Swarm Optimization (PSO) algorithm to find the optimal selection probability distribution of operators with respect to fuzzing effectiveness, and provides a pacemaker fuzzing mode to accelerate the convergence speed of PSO. Many new solutions have been proposed in the past years, including the ones that improve the seed generation solution [1,2,3], the ones that improve the seed Chenyang Lyu and Shouling Ji are the co-first authors. Shouling Ji and Chao Zhang are the co-corresponding authors. Thus, fuzzers that select mutation operators with the uniform distribution are likely to spend unnecessary computing power on inefficient operators and decrease the overall fuzzing efficiency.One operator's efficiency varies with target programs. Inspired by the well-known optimization algorithm Particle Swarm Optimization (PSO) [19], MOPT dynamically evaluates the efficiency of candidate mutation operators, and adjusts their selection probability towards the optimum distribution.MOPT models each mutation operator as a particle moving along the probability space [x min , x max ], where x min and x max are the pre-defined minimal and maximal probability, respectively. We further demonstrated the rationality, steadiness and low costs of MOPT.In summary, we have made the following contributions:• We investigated the drawbacks of existing mutation schedulers, from which we conclude that mutation operators should be scheduled based on their history performance. We open source MOPT-AFL along with the employed data, seed sets, and results at https://github.com/puppet-meteor/MOpt-AFL to facilitate the research in this area. The fuzzer (1) maintains a queue of seed test cases, which can be updated at runtime; (2) selects some seeds from the queue in certain order; (3) mutates the seeds in various ways; (4) tests target programs with the newly generated test cases, and reports vulnerabilities or updates the seed queue if necessary; then (5) goes back to step (2). in practice these fuzzers, including AFL [16] and its descendants, libFuzzer [17], honggfuzz [18] and VUzzer [6], usually predefine a set of mutation operators, and choose some of them to mutate seeds at runtime. AFL applies a deterministic scheduling scheme for seed test cases that are picked to mutate for the first time. More specifically, we aim at finding an optimal probability distribution, following which the scheduler could select better mutation operators and improve the fuzzing efficiency. For most programs, the operators bitflip 1/1, bitflip 2/1 and arith 8/8 could yield more interesting test cases than other operators. • AFL spends most time on the deterministic stage. But according to Fig. 4 58.1%41.9% 77.7% 8.8%98.8%1.2%87.9% Figure 5: Percentages of time and interesting test cases used and found by the three stages in AFL, respectively.decreases the fuzzing efficiency.Motivation. It employs multiple particles to search the solution space iteratively, in which a position is a candidate solution.As shown in Fig. 6, in each iteration, each particle is moved to a new position x now , based on (1) its inertia (i.e., previous movement v now ), (2) displacement to its local best position L best that this particle has found so far, and (3) displacement to the global best position G best that all particles have found so far. where w is the inertia weight and r ∈ (0, 1) is a random displacement weight. Rather than employing particles to explore candidate distributions directly, we propose a customized PSO algorithm to explore each operator's optimal probability first, and then construct the optimal probability distribution. Similar to PSO, MOPT also appoints the best position that a particle has ever found as its local best position.For a given particle, a position x 1 is better than x 2 , if and only if, its corresponding operator yields more interesting test cases (with a same amount of invocations) in the former position than the latter. Instead, different particles have different global best positions (in different spaces) here.In PSO, global best positions depend on the relationship between different particles. However, unlike the original PSO swarm that has multiple particles exploring the solution space, the swarm defined by MOPT actually only explores one candidate solution (i.e., probability distribution) in the solution space, and thus is likely to fall into local optimum. Here, we define the swarm's efficiency (denoted as swarm e f f ) as the number of interesting test cases contributed by this swarm divided by the number of new test cases during one iteration.Overview: In summary, MOPT employs multiple swarms and applies the customized PSO algorithm to each swarm. More specifically, for a particle P j in a swarm S i , we update its position as follows.v now [S i ][P j ] ←w × v now [S i ][P j ] +r × (L best [S i ][P j ] − x now [S i ][P j ]) +r × (G best [P j ] − x now [S i ][P j ]). (4)where w is the inertia weight and r ∈ (0, 1) is a random displacement weight. The other three modules form an iteration loop and work together to continuously fuzz target programs.In each iteration of the loop, the PSO particles are updated once. More specifically, MOPT (1) sets the initial location x now of each particle in each swarm with a random value, and normalizes the sum of x now of all the particles in one swarm to 1; (2) sets the displacement of particle movement v now of each particle in each swarm to 0.1; (3) sets the initial local efficiency e f f now of each particle in each swarm to 0; (4) sets the initial local best position L best of each particle in each swarm to 0.5; and (5) sets the initial global best position G best of each particle across swarms to 0.5. The process of fuzzing with a specific swarm is as follows.For each swarm, its probability distribution is used to schedule the selection of mutation operators and fuzz the target program. With the information provided by the pilot and core fuzzing modules, this module updates the particles in each swarm, following Equations 3 and 4. • The deterministic stage may have good performance at the beginning of fuzzing, but becomes inefficient after a while. This mode selectively disables this stage only after the efficiency slows down, and thus benefits from this stage while avoiding wasting much time on it.More specifically, MOPT provides two types of pacemaker fuzzing modes for AFL, based on whether the deterministic stage will be re-enabled or not: (1) MOPT-AFL-tmp, which will re-enable the deterministic stage again when the number of new interesting test cases exceeds a predefined threshold; (2) MOPT-AFL-ever, which will never re-enable the deterministic stage in the following fuzzing process. All the experiments run on a virtual machine configured with 1 CPU core of 2.40GHz E5-2640 V4, 4.5GB RAM and the OS of 64-bit Ubuntu 16.04 LTS.Initial seed sets. As a result, the proposed MOPT can improve the coverage of AFL remarkably. Since the main difference between the two fuzzers is whether using the deterministic stage later, it may be an interesting future work to figure out how to employ the deterministic stage properly. However, since the deterministic stage performs multiple kinds of operators on each bit/byte of the test cases, it takes a lot of time to finish all the operations on each test case in the fuzzing queue, leading to the low efficiency. Thus, a powerful fuzzer is needed to improve the security patching.Case study: CVE-2018-18054 in pdfimages. First, mutation-based fuzzing has randomness, and naturally such randomness may cause performance shaking within a short time. The mutation strategy of VUzzer is different from AFL. For completeness, we test AFL, MOPT-AFLever, AFLFast, MOPT-AFLFast-ever, VUzzer and MOPTVUzzer on LAVA-M with the same initial seed set and the same settings as in Section 5.7, for 5 hours. • The fuzzers, which use symbolic execution or similar techniques, perform significantly better than others on LAVA-M. In particular, p1 is the p value yielded from the difference between the performance of MOPT-AFL-ever and AFL, p2 is the p value yielded from the difference between the performance of MOPT-AFL-ever and Angora, and p3 is the p value generated from the difference between the performance of MOPT-AFL-ever and VUzzer.We further validate the reliability of our p value analysis leveraging the Benjamini-Hochberg (BH) procedure [31]. Note that if without the pacemaker fuzzing mode, MOPT-AFL-off uses the havoc stage less frequently and iterates the selection distribution USENIX Association 28th USENIX Security Symposium 1961 more slowly, which limits the performance of the MOPT main framework. As a conclusion, both two comparison groups demonstrate that the MOPT scheme without the pacemaker fuzzing mode can also improve the performance of AFL on exploring unique crashes and paths, but a better performance can be achieved if integrating the pacemaker fuzzing mode.Pacemaker Fuzzing Mode. The results are consistent with our motivation that it is desired to dynamically determine the selection probability of operators during the fuzzing process. Then the selection probability converges quickly and MOPT iterates fast. By using MOPT to search the optimal selection distribution for mutation operators and leveraging the pacemaker fuzzing mode to further accelerate the convergence speed of searching, MOPT can efficiently and effectively determine the proper distribution for selecting mutation operators. We would also like to thank the anonymous reviewers for their valuable comments and input to improve our paper.