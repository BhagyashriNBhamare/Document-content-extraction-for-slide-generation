Yet, they lack rigorous principles for setting bounty amounts and require high payments to attract economically rational hackers. Our framework transforms programs via N-of-N-version programming , a variant of classical N-version programming that runs multiple independent program instances. We design a simple, automated version of the Hydra Framework for Ethereum (ethereum.org) and implement two Hydra contracts, an ERC20 standard token and a Monty-Hall game. For example, while Apple offers a maximum 200k USD bounty, a broker intermediary such as Zerodium purportedly offers 1.5 million USD for certain iPhone jailbreaks. Pricing bounties appropriately can also be hard because of a lack of research giving principled guidance. This uncertainty creates a market inefficiency that limits incentives for rational hackers to uncover vulnerabilities.We introduce the Hydra Framework, the first principled approach to bug bounty administration that addresses these challenges. A variant of classical N-version programming, NNVP leverages multiple versions of a program that are independently developed, or otherwise made heterogeneous. In the Hydra Framework, these program versions, or heads, are executed in parallel within a meta-program called a Hydra program.In stark contrast to N-version programming's goal of fault tolerance (i.e., where the program attempts to produce a correct output even in the face of partial failures), NNVP focuses on error detection and safe termination. Moreover, an adversary that breaks one head and, instead of claiming a bounty, tries to generalize the exploit, risks preemption by honest bounty hunters. We show that even when an exploit's market value exceeds the bounty by multiple orders of magnitude, economically rational hackers are incentivized to disclose bugs rather than attempt an exploit.A Hydra Framework for smart contracts. • Graceful termination: Smart contracts are not (yet) mission critical software and can often be aborted with minimal adverse effects, as required for NNVP. Remediation of the DAO and Parity multisig attacks involved refunding users, a mechanism considered in this paper.We design a Hydra Framework for Ethereum and evaluate it on two applications, an ERC20 token [55] and a Monty Hall game [56]. Our full framework code, tests, and experiments are available at thehydra.io.Major challenges. As a result, a na¨ıvelyna¨ıvely implemented bounty contract is vulnerable to bug-withholding attacks: upon finding a bug in one head, a hacker can withhold it and try to compromise all heads to exploit the full contract. We formally define security for Submarine Commitments and prove that they effectively prevent bug withholding. We introduce the idea of an exploit gap and explore N-of-N-version programming (NNVP) as a specific instantiation. From a state s, running f on input x produces output y and updates s. For an input sequence X = [x 1 , x 2 , . . . ], we denote by run( f , X) := [y 1 , y 2 , . . . ] a serial execution trace of f starting at the initial state and outputting y i on input x i . The input space is assumed to be bounded and input sequences are finite.We assume that a program may produce a fallback output ⊥ if it detects that the execution is diverging from intended behavior (e.g., throwing an exception on a stack overflow). A program's execution trace is a fallback trace if it agrees with the ideal program up to some input x i , and then outputs ⊥. The set of fallback traces is thenY ⊥ := Y | ∃i.[y 1 , . . . , y i ] run(I, X) ∧ n j=i+1 (y j = ⊥) ,We define an exploit against f as any input sequence X for which f 's output is neither that of the ideal program nor a fallback trace. A program transformation T( f 1 , f 2 , . . . , f N ) := f * introduces an affirmative exploit gap for a distribution D over inputs sequences X if gap := Pr X∈D X ∈ N i=1 E( f i , I) Pr X∈D [X ∈ E( f * , I)] > 1 . (1)The exploit gap is empirically measurable and its magnitude reflects the likelihood that an input sequence that is an exploit for some f i does not affect f * . If the exploit gap is large (gap 1), then a discovered bug likely affects one of the programs f i but not f * . These transformations operate on N > 1 programs and aim at full availability (i.e., no fallback outputs), a natural requirement in mission-critical systems.We focus on N-version (or multiversion) programming, which we build upon in Section 3. It further defines how to combine outputs of different versions (see Step 3). N-version programming traditionally uses majority voting between programs to induce an exploit gap [17,6].3 N-of-N-version Programming N-version programming assumes that heterogeneous implementations have weakly correlated failures [17]. This setup is not suitable for smart-contracts: As in centralized financial institutions (e.g., stock-markets [48]), the cost of a fault typically trumps that of a temporary loss of resource availability.Ethereum's community exemplified its preference for safety in this trade-off, when attackers found an exploit in the Parity Multisig Wallet [11] and stole user funds. The simple escape hatch in this scenario (i.e., move funds to a safe account) was deemed a successful alternative to an actual exploit.We propose trading availability for safety in N-version programming, by replacing the goal of fault-tolerance by one of error detection and safe termination. We revisit experiments on the cost-effectiveness of Nversion programming, in light of our NNVP alternative.Knight and Leveson [34] first showed that the nullhypothesis of statistical independence between program failures should be rejected. Yet, such correlated failures only invalidate the N-version paradigm if increased development costs outweigh failure rate improvements.Unfortunately, in an experiment at NASA, Eckhardt et al. [21] found that the correlation between individual versions' faults could be too high to be considered costeffective, with a majority vote between three programs reducing the probability of some fault classes by only a small factor (as we show in Appendix A, some of the workloads in [21] yield an exploit gap of gap ≈ 5 using majority voting between three programs). The actual exploit gap is probably much larger, as Eckhardt et al. did not consider whether program failures were identical or not. Smart contracts store large financial values in small applications with an exceptionally high "price per line of code" (some token contracts hold over 1M USD per line [1]). Bounties administered by smart contracts can satisfy fair exchange of bounties for bugs and guaranteed payment for disclosure of valid bugs [53]. T NNVP combines N smart contracts (or heads) f 1 , . . . , f N into a contract f * , which delegates incoming calls to each head. To maintain consistency while interacting with external contracts, the MC checks that all heads agree on which external interaction to perform, executes the interaction once, and distributes the obtained response (if any). Best practices [23] suggest enhancing smart contracts with an escape hatch mode, which enables the contract's funds to be retrieved, before it's eventual termination and redeployment. The design of the escape hatch mode depends on the application, but there are some universal design criteria:• Security: The escape hatch's correctness requires special care, as it will not be protected by NNVP. That is, x is an exploit if run(f * , X [x]) = run(I, X [x]), where X is the sequence of all inputs previously submitted to f * and denotes concatenation.If an honest party finds an input x that yields an exploit for at least one of the heads (∃i ∈ [1, N] : x ∈ E( f i , I)), then the party is awarded a bounty of value $bounty and the contract's escape hatch is triggered. If a malicious party finds an exploit against the full Hydra contract (x is an exploit for each head), the party can use this exploit to steal the entirety of the contract's balance, $balance.We model bug finding as a Poisson process with rate λ i , which captures a party's work rate towards finding bugs. The waiting times for both events are exponentially distributed with respective rates λ i andλ i · Pr x∈D x ∈ E( f * , I) | x ∈ N i=1 E( f i , I) = λ i · Pr x∈D x ∈ E( f * , I) ∧ x ∈ N i=1 E( f i , I) Pr x∈D x ∈ N i=1 E( f i , I) = λ i · Pr x∈D [x ∈ E( f * , I)] Pr x∈D x ∈ N i=1 E( f i , I) = λ i · gap −1 . (2)Let us first consider the strong assumption of independent program failures. We analyze two cases: (1) A finds an exploit against f * , and (2) A finds a bug for a strict subset of the heads.In the first case, it is clear that A has no incentive to disclose, unless the bounty exceeds the contract's value. However, the probability of this bad event occurring isPr[T M < T H ] = λ M · gap −1 λ H + λ M · gap −1 = λ M λ H · gap + λ M ,which naturally decays as the exploit gap increases.In the second case, a bounty can incentivize early disclosure. Then, for independent program failures (see Equation (3)) the bounty decays exponentially in the number of heads N.Thus, given estimates of α and gap, we get a principled bounty pricing that incentivizes bug disclosure. For example, in the experiment of Eckhardt et al. [21], a three-headed Hydra could sustain a bounty 3 to 4 orders of magnitude below an exploit's value.This analysis also provides insight into why bounties are paid when bugs are not necessarily actively exploitable against the target system. Suppose an adversary has found a bug in one or more heads in a Hydra contract, and aims to find a stronger exploit against all heads. By front-running, though, the adversary can ensure it claims the bounty first, thus nullifying any economic incentives for early disclosure.We propose a formal model for blockchain security, expressed as an ideal functionality F withhold . Refining our analysis of Section 4, we show how bug withholding breaks incentives for bug disclosure in BountyContract. In our model, A can mount strong history-revision attacks, overwriting blocks at the head of the blockchain, and can delay any transaction by a bounded number of blocks.This reflects an adversary's ability to monitor transactions, mount network-level attacks, control client accounts, and even corrupt or bribe miners to alter legitimate blocks. Let B = {B 1 , . . . , B B.Height } be a blockchain, i.e., an ordered sequence of blocks. Here, B.Height is the BountyContract with B, P = {P 0 , P 1 , . . . , P m }, ∆, $deposit, $bountyInit: CommitList, RevealList ← / 0On receive τ = ("commit", comm, $val) from P i : // P i commits to bug if $val ≥ $deposit then CommitList.append(comm, B.Height; P i ) On receive τ = ("reveal", (comm, height), (witness, bug)) from P i : if (comm, height; P i ) ∈ CommitList then // P i reveals commitment assert (B.Height − height) ≤ ∆ assert Decommit(comm; (witness, bug)) ∧ IsValidBug(bug) RevealList.append(height; P i ) On receive τ = ("claim", height) from P i :// P i tries to claim bounty assert (height; P i ) ∈ RevealList assert B.Height − height > ∆ assert (height ; P i ) ∈ RevealList s.t. height < height send $bounty to P i and halt // Pay bounty and ignore further messages number of blocks in B. The contract in Figure 3 uses a cryptographic commit-reveal scheme, a simple folklore solution to certain front-running attacks [31]. A then knows that P 0 is trying to claim a bounty, and can front-run P 0 's commitment by posting her own "commit" ahead in the blockchain.This problem arises in many other scenarios, e.g., token sales or auctions, where a user must send funds to place her bid, thus exposing the bid on the blockchain.Impact of bug withholding. In our analysis of Hydra bug bounties in Section 4.2, we assumed that A risks forfeiting a payout of $bounty if she conceals a bug. This is a powerful, general solution to the problem of front-running that may be of independent interest, as it can be applied to smart-contract-based auctions, exchange transactions, and other settings.As the name suggests, a Submarine Commitment is a transaction whose existence is temporarily concealed, but can later be surfaced to a target smart contract. As we show in Appendix B.2, such sends are common in Ethereum and, for a reasonable commitreveal period (e.g., 25 minutes), form an anonymity set of hundreds of transactions with a diverse range of values among which $val is statistically hidden. Notably, the anonymity set represents 2-3% of all transaction traffic over the commit-reveal window. Figure 4 shows the simple game used in our security analysis, denoted by Exp bntyrace A . The game is played between an honest user P * = P 0 , and a user P 1 controlled by A. W.l.o.g., P * models a collection of honest players, while P 1 models players controlled by A. Our results also hold in that setting, with a slightly tighter bound for Theorem 3 below (see [13] for a proof). P * posts a "reveal" in block revblock P * = commblock P * + ρ.A wins the game if she posts a valid "commit" before P * does, and also posts a corresponding "reveal" to claim Experiment Exp bntyrace A (n , δ , ρ, s; ∆, $deposit, $bounty)Init: n ← n − ∆, $cost ← 0, commblock P * ←$ [1, n]A {B←F withhold ({P 0 =P * ,P 1 },n,δ ,ρ,s)} //A interacts with F withhold for i = 1 to n if ("commit", $deposit) ∈ B i then . But A can rewind at most ρ blocks (i.e., block B j−ρ cannot be erased), so A only succeeds if it has previously posted a "commit" in the interval[B j−ρ−∆ , B j−ρ ]. Intuitively, this is because front-running is expensive: Since A observes a "commit" message from P * too late to remove it by rewinding, A must post "commit" messages continuously to ensure that it can front-run P * . In the extended version of this paper [13], we consider a generalized α-revealing strategy that involves conditional preemptive bug disclosure. While we could also run a bounty program off-chain (for a single deployed contract), this would not provide an exploit gap, a key property in our analysis of attacker incentives.The main challenge is the implementation of the "Execution Environment" [17,6], the agent that coordinates the N heads and combines their outputs. As we showed in Figure 2, the logical embodiment of a Hydra contract is a proxy meta-contract (MC), which coordinates N deployed contract versions (or heads). As the EVM execution is deterministic, the result of a contract call is fully determined by the call's input, the contract code and the current blockchain state. However, most smart contracts also interact with the blockchain, e.g., by accessing information about the current transaction (such as the sender's address) or by calling other contracts, and the MC must thus guarantee consistency among the heads.We illustrate the issue in Figure 5 with a Solidity code snippet (top-left) and corresponding EVM opcodes (bottom-left). With N heads, g(x) is called N times instead of once.The heads might also obtain different return values.To resolve these issues, the heads are instrumented prior to deployment so that all interactions with the blockchain are mediated by the MC. While these modifications could be made in a high-level language (e.g., Solidity), we opt for a more generic, automated, and globally applicable solution that operates on the EVM opcodes of a compiled contract (the instrumentation is thus agnostic to the language used to develop the heads). That is, when the first head runs, the MC executes all callbacks (e.g., external calls) and records the callback arguments and return values. If heads request different callbacks, the MC throws an exception, reverting all changes and triggering the bounty payment.To maintain consistency between heads, and avoid potential read-write inversions (e.g., if heads send ether and read contract balances in different orders), the program specification is required to define a total-ordering of the read and write operations issued by the heads.Tail-call optimization. Our Hydra head instrumenter, written in Haskell, applies simple opcode rewriting rules (see Figure 5), which are verified to preserve program invariants such as stack and memory layout. We do not yet support opcodes that modify a head's code (e.g., DELEGATECALL). We note however that code delegation is typically at odds with the multiversion programming philosophy: if all heads call the same library contract, a library bug could yield an exploit. To test soundness, applicability and performance of Hydra contracts, we use three workloads: (1) The official suite of test contracts for the EVM 1 ; (2) All contracts used in Ethereum between Dec. 7 2017 and Feb. 7 2018; and (3) two representative smart-contract applications developed by the authors. • The Hydra ERC20 token: The ERC20 token-transfer API has been thoroughly peer reviewed [55], and is supported by most of the highest-dollar contracts in Ethereum (as of February 2018, the combined market cap of the top ten Ethereum tokens is over 20 billion USD [1]). Notably, the exploit in the DAO [15] was partially present in the code managing tokens. To evaluate completeness of our Hydra instrumenter, we consider all Ethereum transactions for blocks 4690101 -5049100 (Dec. 7 2017to Feb. 7 2018. For each transaction, we test whether our instrumenter supports the evaluated code (see Section 6.2 for unsupported opcodes). This analysis supports the fact that Hydra could be usable for the majority of Ethereum contracts, both by deployed code and transaction volume. Some Ethereum projects, notably the Vyper language, already trade gas efficiency for security. As the MC calls all the heads in a single transaction, this fee is amortized, leading to sub-linear scaling of the gas-cost for N-headed Hydras. Figure 6 compares gas costs for Hydra contracts with 1-5 heads to a linear scaling of a single non-instrumented contract. After writing three heads independently, we commonly tested our contracts for discrepancies and found multiple bugs in each head, none of which impacted all heads simultaneously. Notably, all these bugs could have been exploited against a single contract, yet none of them appear useful against all heads simultaneously.In addition to the exploit gap induced by Hydra, the NNVP development process itself increased the quality of our contracts. Bitcoin and, more importantly, Ethereum [14] have popularized smart contracts [52] and script-enhanced cryptocurrency [30]. We have described one such strategy, N-of-N-version programming (NNVP), a variant of N-version programming that detects divergences between multiple program instances.We have applied our framework to smart contracts, highly valuable and vulnerable programs that are particularly well suited for fair and automated bug bounties. We have gap ma j = ˜ P one˜P one˜ one˜P maj and gap NNV P ≥ ˜ P one˜P one˜ one˜P all ,where the inequality for gap NNV P is because NNVP only fails if all programs fail identically (the results in [21] only give us an upper bound for this probability In all cases, the lowest exploit gap is obtained for the third work-load (denoted S 1,0 in [21]), which has the lowest failure rate overall.If we combine all work-loads into one, and assume that hackers sample uniformly from the test inputs used in the experiment, we obtain:N Majority Voting NNVP 2 N.A. gap NNV P ≥ 79 3 gap ma j = 7gap NNV P ≥ 4409 5 gap ma j = 709 gap NNV P ≥ 282,605Note that NNVP makes sense even in the case N = 2, and yields gaps that are multiple orders of magnitude greater than the ones obtained with majority voting. CREATE2 creates new smart contracts, much like an already existing CREATE opcode. BountyContract verifies that the commit indeed occurred in block commitBlk (e.g. using Appendix B.2). The root hash of this tree is included in the block header and the block header is hashed into the block hash, which can be queried from inside a smart contract by means of the BLOCKHASH opcode.We implemented this verification procedure in a smart contract that takes a block number, the transaction data, and a Merkle-Patricia proof of transaction inclusion as inputs, and outputs accept or reject. Let A := addr(Contract) and let E : {0, 1} → {0, . . . , b − 1} k be the function that takes an integer (encoded as a binary string) and reencodes it as a string of length k in base b. P sends $deposit to address addr = H(H(. . . H(A, E(x) 1 +1) . . . , E(x) k−1 +1), E(x) k +1) . For n = 80, in the ROM, a choice of b = 4 minimizes the expected number of contract creations log b (2 n ) 1 + b−1 2 . This research was supported by NSF CNS-1330599, CNS-1514163, CNS-1564102, and CNS-1704615, ARL W911NF-16-1-0145, and IC3 Industry Partners. Philip Daian is supported by the National Science Foundation Graduate Research Fellowship DGE-1650441.