To demonstrate the viability of these attacks, we focus on the MMU, demonstrating that indirect cache attacks based on translation operations performed by the MMU are practical and can be used to bypass all the existing software-based defenses. Cache attacks are increasingly being used to leak sensitive information from a victim software component (e.g., process) running on commodity CPUs [8,11,12,15,19,21,22,26,29,31,32,33,42]. In response to these attacks, state-of-the-art defenses use software-or hardware-enforced mechanisms to partition CPU caches between mutually distrusting components.Given the lack of dedicated hardware support for the mitigation of cache attacks, current hardware-enforced mechanisms re-purpose other CPU features, originally intended for different applications, to partition the shared caches. For example, Intel CAT, originally designed to enforce quality-of-service between virtual machines [18], can be re-purposed to coarsely partition the shared last level cache [30]. Our focus on the MMU is motivated by (i) the MMU being part of the standard hardware equipment on commodity platforms exposed to side-channel attacks, and (ii) the activity of the MMU being strongly dependent on the operations performed by the CPU, making it an appealing target for practical indirect cache attacks.In detail, we show how our concrete attack implementation, named XLATE, can program the MMU to replace the CPU as the active actor, mounting attacks such as FLUSH + RELOAD and PRIME + PROBE. XLATE attacks show that the translation structures (i.e., page tables) and any other data structures used by other cache-enabled trusted hardware/software components should be subject to the same partitioning policy as regular code/data pages in existing and future cache defenses. We show that retrofitting this property in existing defenses is already challenging for XLATE attacks, let alone for future, arbitrary indirect cache attacks, which we anticipate can target a variety of other trusted hardware/software components.Summarizing, we make the following contributions:• The reverse engineering of the internal architecture of the MMU, including translation and page table caches in a variety of CPU architectures. Our XLATE attack implementation can program the MMU to indirectly perform a variety of existing cache attacks in practical settings. To overcome the performance gap between processors and memory, multiple caches in the processor store recently-accessed memory locations to hide the memory's high latency. Recently accessed memory locations by the victim process will be in the cache and EVICT + TIME [27] time PRIME + PROBE [21,31] time PRIME + ABORT [8] TSX FLUSH + RELOAD [42] time FLUSH + FLUSH [16] time attackers can probe for this information by observing the state of the caches to leak sensitive information about the secret operation of the victim process. Where these caches are private to each core, all cores share the L3 which is the last-level cache (LLC). Furthermore, because of its size, the LLC is always set-associative, i.e., it is divided into multiple cache sets where part of the physical address is used to index into the corresponding cache set. PRIME + PROBE and PRIME + ABORT In a PRIME + PROBE attack, the attacker builds an eviction set of memory addresses to fill a specific cache set. While PRIME + PROBE originally targeted the L1 cache [33] to monitor accesses from the same processor core or another hardware thread, the inclusive nature of the LLC in modern Intel processors has led recent work to target the LLC [21,23,31], enabling PRIME + PROBE in cross-core and cross-VM setups. Further, Yarom and Falkner [42] observe that CLFLUSH evicts a memory line from all the cache levels, including the lastlevel cache (LLC) which is inclusive of the lower cache levels and shared between all processor cores, thus enabling an attacker to monitor a victim from another processor core. Given the knowledge of how memory is mapped to the CPU caches, these defenses can freely partition the memory between distrusting processes in a way that partitions the cache, thus preventing the eviction of each other's cache lines. Similarly, older ARM processors such as the ARM Cortex A9 implement Cache Lockdown [6,35], which enables software to pin cache lines within the L2 cache by restricting the cache ways that can be allocated.Another hardware mechanism is ARM AutoLockoriginally an inclusion policy designed to reduce power consumption that also happens to prevent cross-core attacks by locking cache lines in the L2 cache when they are present in any of the L1 caches [13,40]. As a result, to use ARM AutoLock as a defense, sensitive data has to be kept in the L1 caches, which are limited in size.Intel TSX introduces support for hardware transactions where the L1 and L3 are used as write and read sets, respectively, to keep track of accesses within the transaction. On contemporary processors, the LLC is both setassociative and physically indexed, i.e. part of the physical address determines to which cache set a certain physical memory address maps. Thus, pages with a different page color do not map to the same cache sets, a property originally used to improve the overall system performance [3,24,43] or the performance of real-time tasks [28] by reducing cache conflicts. As each memory access from the CPU induces a virtual-to-physical address translation for which the MMU has to consult multiple page tables, the MMU tries to keep the results and the intermediate state for recent translations close to itself by interacting with various caches, including the CPU caches. Since the CPU and the MMU share the CPU caches, it is possible to build an eviction set of virtual addresses of which the page table entries map to certain cache sets, allowing one to monitor activities in these cache sets in a similar fashion to PRIME + PROBE.As the activity of the MMU is trusted, existing software-based defenses do not attempt to isolate page table pages. Although prior work has proposed page table deduplication to share identical page tables between processes [9] (enabling MMU-based FLUSH + RELOAD), this feature is not readily accessible on commodity platforms.All of the XLATE attacks rely on the same building block, namely finding an eviction set of virtual addresses of which the page table entries map to the same cache set. For XLATE attacks, eviction sets can be found using a similar approach, but by using page tables instead of pages.In XLATE + TIME, we fill a specific cache set with the page table entries from the eviction set and then measure the victim's execution time to determine if the victim is accessing the same cache set. As mentioned, all these defenses focus on isolating untrusted components such as code running in a virtual machine, but allow unrestricted access to the cache to trusted operations-such as the page Figure 1: The top shows the LLC being divided into 128 unique page colors, the bottom left shows how the LLC can be partitioned such that programs can only access a subset of these page colors, the bottom right shows the situation for their respective page tables.performed by the MMU. Even though the cache lines of the pages themselves are limited to a specific subset of page colors, and thus a specific subset of cache sets, their respective page tables are able to access all page colors. As the page table accesses by the MMU are not monitored by the page fault handler, accesses to page tables that map to the same cache set as the sensitive data, do not reload those cache lines. Before we can use the MMU to mount XLATE attacks, we need to fully understand how the MMU performs a page table walk when translating virtual addresses into their physical counterparts. In Section 6.2, we show how we retrofit an existing algorithm for building PRIME + PROBE eviction sets to instead build suitable eviction sets for XLATE attacks. These translations are stored in page tables-a directed tree of multiple levels, each of which is indexed by part of the virtual address to select the next level page tables, or at the leaves, the physical page. To further improve the performance of a TLB miss, the PTEs for the different page table levels are not only stored in the CPU caches, but modern processors also store these in page table caches or translation caches [1]. Figure 3 visualizes how different caches interact when the MMU translates a virtual address.We rely on the fact that the MMU's page table walk ends up in the target processor's data caches to learn about translation caches. If the translation caches are not flushed, then the page table walk skips part of the page table hierarchy and simply starts from a lower level page table. Thus, if we access any page within that 2 MiB region, the page table walk loads the corresponding PTE pointing to the second-level page table to the translation cache. More specifically, we first find eviction sets for the available subset of page colors: Algorithm 1: Algorithm to build eviction sets dynamically for either a given or a randomly chosen target.Input: a set of potentially conflicting cache lines pool, all set-aligned, and an optional target to find an eviction set for. Output: the target and the eviction set for that target working set ← {}; if target is not set then target ← choose(pool); remove(pool, target); end while pool is not empty do repeat member ← choose(pool); remove(pool, member); append(working set, member); until evicts(working set, target); foreach member in working set do remove(working set, member); if evicts(working set, target) then append(pool, member); else append(working set, member); end end foreach member in pool do if evicts(working set, member) then remove(pool, member); end end end return target, working set 1 We allocate a sufficiently large pool of pages to build these eviction sets. If the amount of page colors is restricted, this results in fewer eviction sets, whereas if the amount of cache ways is restricted, these eviction sets consist of fewer entries.Using page tables Now we retrofit this algorithm to use the MMU to evict a given page, the target of our choice. We can then repeat this for other pages until all the page tables have been colored, yielding eviction sets for all the available colors in our security domain.Defeating way partitioning To defeat software-based cache defenses using way partitioning, we now try to find eviction sets that cover the whole cache set. Since these eviction sets of page tables map to the full cache sets, they bypass way partitioning.Defeating set partitioning In case of StealthMem and cache defenses using set partitioning, or more specifically, page coloring, we end up with a pool of the remaining page tables that could not be colored. To minimize the noise for XLATE attacks, we rely on the following: (1) translation caches, (2) pointer chasing, (3) re-using physical pages, (4) and transactions.Translation caches Now that we have reverse engineered the properties of the MMU, we can control which PTEs hit the LLC when performing a page table walk. Algorithm 2 extends PRIME + PROBE to flush Algorithm 2: XLATE + PROBE method for determining whether an eviction sets evicts a given cache line.Input: the eviction set eviction set and the target target. timings ← {}; repeat access(target); map(access, TLB set); map(access, eviction set); map(access, reverse(eviction set)); map(access, eviction set); map(access, reverse(eviction set)); append(timings, time(access(target))); until length(timings) = 16; return true if median(timings) ≥ threshold else false the TLB using the technique described in Section 6.1. First, we can exploit page coloring to ensure that the pages pointed to by page tables in the eviction set do not share the same page color as the target page. Second, by carefully selecting the virtual addresses of the pages in our eviction set, we can ensure that the cache lines of these pages do not align with the cache line of the target page. cessors, we also found translation caches available for 32 Page Directory Entries (PDEs) and 4 Page Directory Pointer Table Entries (PDPTEs). On AMD, we found that AMD K10 employs a 24-entry dedicated and unified page table cache and AMD Bobcat employs an 8 to 12 entries variant, respectively. Since AMD Bulldozer, the L2 TLB has been re-purposed to also host page table entries, allowing it to store up to 1024 PDEs on AMD Bulldozer and Piledriver and up to 1536 PDEs on AMD Zen. We also found that AMD Zen introduces another L2 TLB with 64 entries dedicated to 1G pages, allowing it to store up to 64 PDPTEs. We used our framework to compare the raw bandwidth, the (correct) bandwidth, and the bit error rate between hardware threads on the same CPU core and between different CPU cores. While FLUSH + FLUSH performs quite well on the cross-core setup with a bandwidth of about 4 KiB/s, it performs much worse on the cross-thread setup with a bandwidth of a mere 500 bytes/s. More specifically, by choosing p i and using new random plain text bytes for p j , where i = j, while triggering encryptions, an attacker can find which p i remains to always cause a cache hit for the first cache line in a T-table. By extending this attack to cover all 16 cache lines of the T-table, an attacker can derive the four upper bits for each byte in secret k, thus revealing 64 bits of the secret key k. Figure 5 shows that all the cache attacks we considered, including XLATE + PROBE and XLATE + ABORT, are able to effectively retrieve the signal. Since StealthMem uses dedicated cache sets to pin cache lines, this defense is already subsumed by page coloring.Without additional assumptions, PRIME + PROBE would trivially fail in this scenario, since the preliminary eviction set building step would never complete due to the cache set and ways restrictions. As shown in the figure, both page coloring and way partitioning disrupt any signal to mount (even oracle-based) PRIME + PROBE attacks, given that the eviction set is prevented from sharing cache sets or ways (respectively) with the victim. Even though existing software-based cache defenses are effective against existing side-channel attacks such as PRIME + PROBE and PRIME + ABORT, they are not effective against the XLATE family of attacks. By applying the same subset of page colors to both pages and page table pages on a per-domain basis, it is impossible for an attacker to control page table pages outside the assigned security domain.We show that extending page coloring to also color the page tables is effective by extending the experiment presented in Section 7.4. For each attack on OpenSSL, we compared the PRIME + PROBE and XLATE + PROBE signals for the baseline, after applying traditional page coloring, and after applying both page and page table coloring (full coloring). More specifically, StealthMem pins these memory pages to their respective cache sets by monitoring page faults for pages that map to the same cache set. At first glance, bypassing this challenge and coloring all the "special pages" such as page table pages with a reserved "special color" may seem plausible, but the issue is that the attacker can then mount indirect cache attacks against the special pages of the victim (e.g., MMU-to-MMU attacks) to leak information. To bypass these defenses, Van Bulck et al. [38] observe that malicious operating systems can monitor memory accesses from enclaves without resorting to page faults, by exploiting other sideeffects from the address translation process. The AnC attack [12] shows an EVICT + TIME attack on the MMU that leak pointers in JavaScript, breaking ASLR.Hund et al. [20] demonstrate three different timing side-channel attacks to bypass KASLR. We have exemplified this new class of attacks with MMU-based indirect cache attacks and demonstrated their effectiveness against existing defenses in practical settings. The research leading to these results has received funding from the European Union's Horizon 2020 Research and Innovation Programme, under Grant Agreement No. 786669 and was supported in part by the MALPAY project and by the Netherlands Organisation for Scientific Research through grants NWO 639.023.309 VICI "Dowsing", NWO 639.021.753 VENI "PantaRhei", and NWO 629.002.204 "Parallax".