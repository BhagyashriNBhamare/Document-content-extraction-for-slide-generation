Advanced knowledge of which vulnerabilities are being or likely to be exploited would allow system administrators to prioritize patch deployments, enterprises to assess their security risk more precisely, and security companies to develop intrusion protection for those vulnerabil-ities. Our results show that by observing up to 10 days' worth of data, we can successfully detect vulnerability exploitation with a true positive rate of 90% and a false positive rate of 10%. However, the installation/deployment of software patches on millions of vulnerable hosts worldwide are in a race with the development of vulnerability exploits. The severity of problem was highlighted in 2017 by the the WannaCry and NotPetya outbreaks, as well as the Equifax data breach exposing sensitive data of more than 143 million consumers; in all three cases the underlying vulnerability had been patched (but not deployed) months before the incident [46,47,20]. For example, intrinsic attributes of vulnerabilities, such as the CVSS score [28], are not strong predictors of eventual exploitation [36], underlining the Early detection in this study refers to the ability to detect after t C , i.e., post-disclosure, but much earlier than t E , the current state of the art.need for detection techniques based on field measurements. We show that this early detection can be well accomplished by using two datasets: end-host software patching behavior and a set of reputation blacklists (RBLs) capturing IP level malicious (spam) activities. We show that there is strong empirical evidence of a strong correlation between risk profiles and infection symptoms, which enables early detection of exploited vulnerabilities, even in cases where the exploit was not yet discovered and where causal connection between exploitation and the symptom is not known.By observing these signals up to 10 days after vulnerability disclosure (t C ), we can detect exploits with true and false positive rates of 90% and 10%, respectively. Note that compared to other techniques such as detection of exploits from social media posts (which usually appear around the time exploits are discovered) [36], we base our detection on statistical evidence of exploitation from real-world measurements, which can capture much weaker indications of exploits shortly after the public disclosure of a vulnerability.Our main contributions are summarized as follows:1. The community structure generated during feature extraction can also be used to identify groups of hosts at risk to specific vulnerabilities currently being exploited, adding to our ability to strengthen preventative and protective measures.4. In Section 7 we present case studies of our system's output, evaluate the robustness of our technique against strategic adversaries, and discuss how our proposed methodology could be used in practice. This led us to consider a more verifiable hypothesis: entities (to be precisely defined shortly) that exhibit similar patching behavior in a particular vulnerability (and thus their vulnerability state) might also exhibit similar patterns of infection associated with that vulnerability if it is being actively exploited; on the other hand, the same similarity association should not exist if the vulnerability is not being actively exploited. If this hypothesis holds, then it follows that one should be able to assess the strengths of association between patching behavior and infection symptoms and use it to detect whether a vulnerability is likely being actively exploited. Comparing Figure 2b to 2a and then 2c to 2a, we see a large overlap between the symptom group and the group at risk to strain 1 (through air contamination), indicating a likelihood that stain 1 is active; by contrast, the symptom group and those at risk to strain 2 (through water contamination) are largely disjoint, suggesting that strain 2 is likely not active.To apply this analogy in our context, the symptom pattern refers to malicious activities while risk behavior refers to host patching. First, the telemetry that many security vendors collect on end-hosts is often anonymized, for user privacy reasons, and omits attributes that may identify the host, such as its IP address. However, as is evident from our results in Section 6.2, aggregation at the ISP level is not too coarse so as to impede our technique from detecting actively exploited vulnerabilities.Our second challenge is in determining the right metric to use to capture "similarity" both in the patching behavior and in the symptoms. This results in two similarity matrices, one from the patching behavior data for a specific vulnerability, one from the symptomatic infection data (collected following that vulnerability's disclosure from spam lists). To this end, we present the use of community detection [10,51] over the symptom similarity matrix to identify groups of similar ISPs; this is then followed by quantifying the consistency between the risk behavior similarity matrix and the detected community structure. Our results show that indeed for vulnerabilities with known exploits, this match is much stronger than that for those without known exploits.We then use the consistency measures as features, along with a number of other intrinsic features, to train a classifier aimed at detecting exploitations. These include the host patching data [14], the National Vulnerability Database (NVD) [33], and release notes from software vendors of the products examined in our study.Patch deployment measurements This data source allows us to observe users' patching behavior to assess their susceptibility to known vulnerabilities. In addition, we extract the security flaws affecting each application version from the National Vulnerability database (NVD), where each vulnerability is denoted by its Common Vulnerabilities and Exposures Identifier (CVE-ID). For this study, we analyze user patching behavior over 7 applications with the best host coverage in our dataset, namely Google Chrome, Mozilla Firefox, Mozilla Thunderbird, Safari, Opera, Adobe Acrobat Reader, and Adobe Flash Player; we ignore hosts that have recorded less than 10 events for all of these applications. Combining all curated datasets we obtain 56 exploited-in-the-wild (EIW) and 300 not-exploited-in-the-wild (NEIW) vulnerabilities.Software release notes To find whether a host is susceptible to a vulnerability and to address the issue of parallel product lines, we utilize the release date of each application version included in our study. In this study, we use 5 common daily IP address based RBLs from January 2013 to July 2014 which overlap with the patch deployment measurements.Note that the use of spam data is only a proxy for host infection caused by vulnerability exploits and an imperfect one at that. Our results show the opposite; the detection performance we are able to achieve suggests that spam is a very good proxy for this purpose despite the existence of non-vulnerability related spamming bot distributions.Note that hosts in our patch deployment dataset are anonymized, but can be aggregated at the Internet Service Provider (ISP) level. This is the case with both the patching data and the RBLs and our aggregation takes this into account by similarly mapping the same host to multiple ISPs whenever this is indicated in the data.Aggregating the RBL signals at the ISP level is relatively straightforward. The normalized time series r n (t) will also be referred to as the symptom signal of ISP n.Aggregating the patching data at an ISP level is significantly more involved. To quantify the risk of a given host, we first extract known vulnerabilities affecting each application version from NVD using the Common Vulnerabilities and Exposures Identifier (CVE-ID) of the vulnerability. This heuristic allows us to discern different product lines of each application and users that have installed multiple product lines on their respective machines at any point in time, leading to a more accurate estimate of their states.We quantify the vulnerability of a single host h to CVE j on day t by counting how many versions present on the host on day t are subject to this CVE. We have now obtained two types of time series for each ISP n: r n (t) denoting the normalized malicious activities (also referred to as the symptom signal), and w j n (t), j âˆˆ V , denoting the normalized risk with respect to CVE j; the latter is a set of time series, one for each CVE in the set V (also referred to as the risk signal). As described in the introduction and highlighted in Fig- ure 2, our basic methodology relies on identifying the similarity structure using symptom data and quantifying how strongly the risk patterns are associated with the symptom similarity structure. 1 For simplicity of presentation, we shift t j o to origin, which gives us two symptom signals of length d + 1: r n [0 : d] and r m [0 : d], and a pairwise symptom similarity measure S j r n ,r m using Equations (1) and (2). In this section, we first use community detection methods [10,51] to identify the underlying communities in the pairwise symptom similarities. A community detection algorithm can then be run over this graph to identify hidden structures.The general goal of community detection is to uncover hidden structures in a graph; a typical example is the identification of clusters (e.g., social groups) that are strongly connected (in terms of degree), whereby nodes within the same cluster have a much higher number of in-cluster edges than edges connecting to nodes outside the cluster. This has been an extensive area of research within the signal processing and machine learning community and has found diverse applications including biological systems [18,43,52], social networks [23,51,52], influence and citations [31,51,52], among others.In our context, the similarity matrix S j [n, m] induces a weighted and fully-connected graph. We now verify the hypothesis stated in the introduction; that is, if a CVE is being actively exploited, then ISPs showing similar vulnerabilities to this CVE are also likely to exhibit similar infection symptoms, while on the other hand if a CVE is not actively exploited, then the similarity in vulnerabilities may not be associated with similarity in symptoms. Figure 5 shows the distribution of these values within each group for two distinct CVEs, one is known to have an exploit in the wild (detected by Symantec 20 days post-disclosure), and the other has no known exploits in the wild.The difference between the two is both evident and revealing: for the CVE without a known exploit, Figure 5a shows virtually no difference between the two distributions, indicating that the risk similarity values are not differentiated by the symptom patterns. Also worthy of note is the fact that for the exploited CVE, the earliest date of exploit observation on record is 20 days post-disclosure (disclosure on 01/15/2014, observation in the wild on 02/05/2014), whereas this analysis is feasible within 10 days of the disclosure (01/15-01/25/2014). This allows us to quantify the strength of association between risk and symptoms for any arbitrary CVE; a high D j indicates that there is a statistically significant difference between intra-cluster and inter-cluster risk similarities, which in turn provides evidence for active exploitation. Our results in the previous section shows that the intraand inter-cluster risk similarity distributions as well as the difference D j are statistically meaningful in separating one group of CVEs (exploited) from another (not exploited). In addition to the spam/symptom data and patching/risk data we analyzed rigorously in the previous section, we will also use intrinsic attributes associated with each CVE extracted from NVD. â€¢ [Community]: The difference in distribution (intra-cluster minus inter-cluster similarity) shown in Figure 5, in the form of histograms with 20 bins. For each CVE, we use three metrics: AcessVecotr, AccesComplexity, and Authentication, which measure the exploit range, required attack complexity and the level of authentication needed for successful exploitation, respectivelyWe can also categorize these sets of features as graphbased ( [Community], [Direct], [Raw]) and intrinsic ( [In- trinsic], [CVSS]) features. Our results in the following section demonstrate that while intrinsic features alone are poor predictors of eventual exploitation of a CVE, combining intrinsic attributes with graph-based features enables early and accurate detection of EIW vulnerabilities. For this reason, the training and testing are conducted using 20 rounds of random sub-sampling from the NEIW set to match its size with the EIW set; for each round, we apply 5-fold cross validation to split the dataset into training and test sets. We train and compare multiple classifiers on different sets of features:â€¢ "All features": This is a classifier trained with all features using 10 days of data post-disclosure. â€¢ "Direct+Raw+Intrinsic": This is a classifier trained with [Intrinsic], [Direct], and [Raw] features on 10 days of observational data post-disclosure. The reason why extracted features perform better than raw features is because with the latter a lot of the temporal information embedded in the time series data is underutilized (e.g., in decision tree type of classifiers, time series data are taken as multiple individual inputs), whereas the features we extract (either in the form of community comparison or in the form of row-by-row correlation) attempt to preserve this temporal information.Additionally, we see that combining community features with intrinsic features achieves very good detection performance, almost similar to the concatenation of all features; this suggests that when combined with intrinsic features, community features can effectively replace the use of raw and direct features. However, the ground-truth for testing the performance of our technique is independent of the aforementioned sources of noise, and the observed performance shows that our method is, to a large extent, robust to these imperfections.We next examine the impact of the length of the observational period when using community detection, by comparing the ROCs of classifiers trained using different number of days, immediately following disclosure, as well as starting from a few days before disclosure. In this section we present a few examples of our system's output for (potentially) zero-day EIW vulnerabilities, and discuss the robustness of our technique against strategic attackers, and its practical utility for building real-world monitoring of software vulnerabilities. While this vulnerability has been reported as exploited in the wild, the earliest report was on 01/28/2014 [11]; our results suggest that this CVE might have been exploited months before this date. The intention of this manipulation is to make these N values very similar to each other, each a small perturbed version of the common average; this revision also preserves the original average so as to minimize the likelihood detection by a simple statistical test.For each selection N we perform 20 random trials of the detection algorithm, each over different random perturbations shown above. This system is not meant to alter individual enduser patching behavior, but would allow users through silent updates to get patches sooner for vulnerabilities most at risk of being exploited.Furthermore, [30] suggests that in the timeline of evolution of software patches, patch development happens soon after vulnerability disclosure, yet there is a gap prior to patch deployment, as, e.g., enterprises want to test patches before they deploy them. Nevertheless, infected hosts discovered by alternative bot detection techniques (e.g., scanning activity extracted from network telescope data and/or honeypots [3]) can be appended to the proposed symptomatic data, in order to build a more robust system.Finally, while our technique is evaluated over measurements that are 3-4 years old (due to unavailability of the WINE dataset), the updating mechanism employed by the software examined herein have remained largely the same. Allodi [2] conducts an empirical study on the economics of vulnerability exploitation, by analyzing data collected from an underground cybercrime market.Prior studies on end-host patching behavior heavily focus on understanding the patching behavior itself and its implication on user vulnerability and how it decays/evolves over time; these include e.g., observing patching patterns at different stages [35], the decay rate [15,53], patching behavior across different update mechanisms [13,19], vulnerability decay and threat by shared libraries [30], among others. Our results show that by observing up to 10 days worth of data post-disclosure, we can successfully detect the presence of exploits at 90% accuracy.