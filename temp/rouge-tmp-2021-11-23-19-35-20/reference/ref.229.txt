Popular services feature volunteers who answer questions about photos or videos (e.g., to identify a medical prescription). To better understand the privacy concerns regarding the disclosure of background objects to different types of human assistants (friends, family, and others), we conducted an online survey with 155 visually impaired participants. These camera-based assistive technologies simplify a wide range of everyday tasks such as navigating social spaces, 1 identifying objects or color, 2 recognizing familiar faces or facial expressions, 3 and reading documents. 4 In contrast to automated systems, which use computer vision and machine learning, 3 human-powered systems leverage human assistants (volunteers, professional agents, or friends and family members) to answer questions about photos (or live video) taken by people with VIPs [1,2,16]. We considered the privacy risks of objects both in the foreground (the objects people ask questions about) and background (other objects present in the image not directly associated with the question), and explored privacy concerns when sharing photos or video with three types of human assistants: friends, family members, and crowdworkers (professional agents, mechanical turk workers, and volunteers). Specifically, we focus on the following research questions:R1: What are the privacy concerns of people with visual impairments in the context of background objects that are inadvertently captured and included in photos sent to human assistants?R2: While using such technologies, how do their privacy concerns vary for different classes of background objects and the type of human assistants (friends, family, volunteers or crowd-workers)? To answer these research questions, we conducted an online survey with 155 visually impaired participants examining three everyday scenarios in the context of three different types of human assistants. Their information-disclosing behaviors depended on the nature of the background objects present in the image as well as the types of human assistants. Such technologies include object identifiers 6 [45] and barcode readers, 7 [52] text readers, 4 color readers, 2 money readers, 8 and crowd-sourced visual question-answering systems [1,2] for multiple purposes such as identifying objects, reading prescriptions, and answering subjective questions. Camerabased assistive solutions also assist people with VIPs in their social interactions by recognizing faces and facial attributes of people in the vicinity [25,43,50]. To capture a high-quality picture, these applications automatically guide users to improve the focus, lighting, or composition [5,44,72]. Such applications allow visually impaired users to send pictures or make video calls for getting answers to their visual questions from a sighted crowd-worker or volunteer. To provide greater support to visually impaired users, VizWiz Social [20] expands the initial VizWiz application by including friend-sourced answers (using Twitter, Facebook, or email from their known contacts) along with crowd-sourced answers (Mechanical Turk, IQ Engines). In our work, we consider three different types of human assistants (friends, family members, and volunteers or crowd-workers) and focus on better understanding the preferences of people with VIPs while seeking help from various types of human assistants. Ahmed et al. explored the privacy and security concerns of people with VIPs that are not solved by current technology and suggested new directions for improving camera-based assistive systems [6]. More specific to video based assistive technology, camerabased assistive devices can collect rich visual information and create additional privacy risks for both the device user and bystanders. Ahmed et al. investigated the concerns of bystanders while information about them is shared through camera-based assistive technologies to a visually impaired person [7]. In real time crowd-sourced assistive systems, users are limited in the amount of time to review the content they are sharing and might capture and share sensitive information mistakenly [15,53]. They showed that workers can be engaged in potentially malicious tasks for personal gain, such as copying a credit card number from another task. Moreover, our work provides insight into what should be shared (or not) as background objects depending on the human-sourced assistive technologies with the goal of better understanding their privacy concerns and, therefore, providing design recommendations to develop assistive devices for avoiding inadvertent sharing of private visual information. Our surveys captured peoples' concerns related to sharing information across three different scenarios: in home (located within a residential space), office (located at the place of employment), and restaurant (located at a dining establishment) settings. In the survey, we referred to the objects that users ask the question about as "foreground" objects (primary objects) and the objects which are present in the photo but not primary objects as "background" objects. Since most camera-assisted technologies follow a similar approach, the publicly available VizWiz dataset illustrated common privacy issues that may arise while using such a service.The dataset comprises 20,000 publicly available images and the associated questions (as text) about the images. After analyzing the dataset, we observed five major privacy violations as foreground objects or background objects in the images: address information (e.g., on envelopes), prescription labels, credit card information, contents of digital screens (e.g., computer screen), and the presence of the face or other body parts of the user (as well as of bystanders). The selection of the background objects for each scenario varied slightly; six objects were common to all scenarios whereas the rest were specific to the scenario description. Participants were asked to select from a 5-point Likert scale: (1) extremely uncomfortable (2) somewhat uncomfortable (3) neither uncomfortable nor comfortable (4) somewhat comfortable (5) extremely comfortable.Q2. Please briefly explain your selection above. Participants were asked to explain their selections for feeling comfortable or uncomfortable while sharing photos or videos with a human assistant. • Three scenarios, presented in random order (within subjects), each with three questions about the foreground object, background objects (in random order), and an explanation for their selections. We shared our recruitment sign-up form through email lists of various organizations including the National Federation of the Blind (NFB) and the American Council of the Blind (ACB). Next, one researcher interacted with each individual participant and inquired about their level of visual impairment and blindness. Additionally, we recruited (or retained the data of) only those participants who sufficiently described their level of VIPs in their free-text responses in our survey and sign-up instruments. Three of the pilot Three participants participated in the survey using computers and one from a mobile phone. We have one dependent variable (comfort level for sharing information) and several independent variables (human assistants, scenarios, objects). To analyze our data, we conducted an overall Kruskal-Wallis test (for multiple groups and between subjects), a Wilcoxon rank sum test (for two groups and between subjects), a Friedman rank sum test (for multiple groups and within subjects), and a Wilcoxon signed rank test (two groups within subjects) across all conditions to see if there was any significant difference in the measured variables among the conditions. The analysis showed that 50 participants per condition would provide enough statistical power to detect 0.25 ('small') sized effects (α = 0.05,1 − β = 0.90). The researchers coded each response into one of seven reasons for their information sharing practices: 'burden' (does not want to bother family or friends), 'impression' (does not want to feel embarrassed or awkward), 'indifferent' (does not mind if information is shared), 'relevance' (does not want to share any unnecessary information), 'professionalism' (does not want to share with volunteers), 'trust' (has more faith in friends or family members), and 'security' (does not want identity to be compromised). We then present findings about the audiences participants were selectively disclosing to and emergent issues related to audience and disclosure. Among the participants, 101 (61.2%) were totally blind, whereas 64 (38.8%) live with different levels of VIP such as 'low vision' and 'blind in one eye and low vision in the other.' Some of the most popular assistive technologies used by the participants were Seeing AI (80%), TapTapSee (70.3%), BeMyEyes (69.6%), and KNFB Reader (65.8%). Participants also reported how they sought help from sighted people: 122 (81.8%) for reading documents , 101 (67.7%) for identifying objects, 95 (63.7%) for identifying color, and 46 (30.8%) for seeking subjective opinions (e.g. how the participant looked in new clothing). 9 We categorized the background objects in our survey into four types: (1) Personally Identifiable Information or PII (credit card numbers, bills, mail showing one's address, and official documents) [55], (2) objects affecting one's impression management (mess, medical prescriptions), 10 (3) general objects (food, books), and (4) laptop screens. They were somewhat comfortable with laptop To understand the concerns with sharing photos that capture people in the background, we considered two types of content pertaining to people: 'self-disclosure' (e.g., reflection of the participant's face on the laptop screen, capturing the participant's face or body part, or a photo frame with a picture of the participant) and 'bystanders' in the photo (e.g., other people in a restaurant or the face or body part of a colleague). Surprisingly, our analysis found that participants were more comfortable revealing themselves (µ = 3.6,σ = 1.31,95% CI [3.5,3.7]) than bystanders (µ = 3.0,σ = 1.4,95% CI [2.9,3.2]) to human assistants. To explore the effect of the social relationship on participants' information sharing preferences, we analyzed the interaction between the different types of background information with the type of human assistant. Overall, participants are slightly more comfortable if family members see sensitive objects compared to other assistants. With bystanders, however, the type of audience did not appear to matter. We conducted an overall KruskalWallis test and observed significant differences in the sharing preference with audiences for PII, impression management, and general objects (PII: χ 2 (1) = 26.07, p < 0.001, impression management: χ 2 (1) = 12.627, p < 0.001, general: χ 2 (1) = 13.181, p < 0.001). However, in the case of impression management, they were more concerned with sharing these with friends, likely because impression management is less concerning with family and anonymous volunteers, and people might be least comfortable with friends when it came to one's living conditions or medications. Overall, our female participants were slightly less comfortable (µ = 3.1,σ = 1.5,95% CI [3.0,3.1]) than the male participants (µ = 3.3,σ = 1.4,95% CI [3. Overall female participants were slightly less comfortable in disclosing background information compared to male participants, although the difference was mainly attributable to information related to impression management, in which case the difference was sizeable. We observed that the participants from age group 18-34 (µ = 3.4,σ = 1.52,95% CI We explored the interaction of age and type of background object and found a significant difference (p < 0.005) for PII, self, and general objects. We conducted an overall Wilcoxon rank sum test, and the result shows that participants with low vision (µ = 3.0,σ = 1.51,95% CI [2.9,3.0]) are significantly more concerned (W = 19865004, p < 0.0001) than the totally blind (µ = 3.3,σ = 1.44,95% CI [3.2,3.3]) participants.To observe the relation between different levels of VIP and the sharing preference of different objects, we conducted Wilcoxon rank sum test for each group of objects and found significant differences (p < 0.001) for PII and self-disclosure. In light of these concerns, a common defensive strategy was to physically clear the exposed areas and remove the sensitive contents before using the cameras: "I would need to keep in mind who I was asking for assistance, I would also check the area to make sure it was clear of clutter and other objects. We highlight interesting cases such as 'impersonal trust' and anonymous interaction in the following sections. Participants mentioned feeling embarrassed, and preferred to avoid sharing a messy area: "I'm very picky about being messy, I wouldn't want people to get the wrong impression of me by watching other people's mess!" Our participants reported mixed reactions about laptop screens in the background that varied based on what might be displayed on the laptop screen. [P34]While participants were comfortable sharing background objects with family member, they preferred not to compromise the privacy of bystanders, even with their family. "I would feel extremely uncomfortable with the visibility of all the items which are personal to me or to a coworker because they could be potentially misused by the stranger who is looking at the picture. [P100]Impersonal trust: Prior research shows that 'impersonal trust' (where trust is not based on immediate personal relationships) can influence interactions between people and institutions [36,65]. Due to the anonymity of interactions with volunteers, participants were less concerned about sharing information, such as messy surroundings and body parts, and anticipated volunteers to be less judgmental. However, the anxieties of being a burden to the family often limited them from soliciting aid from family.Trust and reliance: We found that family is one of the most trusted support systems for people with VIPs, and they are comfortable sharing almost any kind of information with them when seeking support. [P73]Social costs of burden: Previous research has shown that people can be reluctant to ask for help from their known networks to balance social costs [63]. They would avoid asking help from family if could manage issues on their own or from other sources. [P47]Some participants felt that asking for help from family members may prove their dependency and helplessness and would prefer alternatives. Privacy and trust: Several participants indicated trusting their friends with all types of information. "I wouldn't mind showing food or maybe myself but any private info depending who I was talking to especially a credit card with all the scams going on I wouldn't really like, though I would try to make sure that I didn't show that stuff." Also, if they have a picture on their phone that contains personal info about me, this creates an opportunity for someone other than my friend to see the picture on my friend's phone (e.g., friend's family members, romantic partner), which would jeopardize the privacy and security of the information." In the context of image sharing by 'lifeloggers,' Hoyle et al. [41,42] did not study specific audiences, but they also found that participants were concerned about private information (such as screens and other objects with textual information), impression management, and the presence of bystanders in their photos. This finding is consistent with prior work showing people are more willing to share private information with stronger social ties [74]. In the same vein, Dosono et al. found that college Reserve Officers' Training Corps (ROTC) students were more comfortable sharing personal crises related to impression management (e.g., physical injuries) with family and counselors instead of their ROTC peers [28]. It may be that people who are totally blind are less aware of the possible privacy risks than people with low vision or are more willing to compromise their privacy because they have become accustomed to a higher need for assistance and 'acceptance' of less privacy in general.Finally, prior work has found that people may have more trust in volunteers compared to paid workers because of a stronger perception of altruism and sincerity of the volunteer [39]. Many of these concerns were related to how camera-based assistive systems were creating a lack of security in people's daily lives -that is, these systems were serving to further marginalize their identities.Broadly speaking, when populations are marginalized based on their identities, they are placed at the edge, beyond boundaries, or on the outside of what is considered normative, and individuals and groups can be marginalized on various intersections of their identity, such as their race, gender, sexual orientation, socioeconomic status, or perceived ability [64]. Our identity defines us as an individual; it is the sense of self that we refer to and that others see us as, giving us security in our daily lives [22,31]. Thus, we argue that in order to create more private and secure assistive technologies, we must begin to humanize assistive technology; that is, we must train computer vision algorithms to better understand what kinds of objects people might want others to (not) see, as well as be cognizant of where we need to enforce human assistance as opposed to algorithmic assistance. In this view, context is actively produced throughout the course of interaction; it is determined by the people who are present and in how they generate, together, the rules and norms for their interaction. For example, if only one person is present in their home (i.e., a homeowner), they may feel free to engage in actions that they may otherwise feel uncomfortable with others present, such as taking a shower with the door open. Given that some of this information was not appropriate for certain audiences, computer vision algorithms should be designed more empathetically such that they detect content deemed inappropriate for certain audiences and blur them, redact them, or generate other novel solutions that are context aware and thus sensitive to the desires of those who are using camera-based assistive technologies. Technologies should help to decide the appropriate audience for the type of question and take appropriate measures for detecting privacy violations for that audience, or, conversely, pick the right audience based on all subject matter in the photo (and not just the foreground object). Our participant sample was small, limited to a few national blind foundations, and restricted to those who chose to respond to an ad about camera-based assistive technology, so it is difficult to know how well our findings generalize to the greater population. We found that while people with visual impairments have privacy and security concerns about revealing background objects, their information disclosure preferences vary according to the types of objects and human assistants. For example, participants were more concerned with the privacy of bystanders than their own privacy and they were more comfortable sharing concerns about self-presentation with family (and possibly crowd workers) as opposed to friends. This material is based upon work supported in part by the US National Science Foundation under awards CNS-1408730, CNS-1252697, and IIS-1657429. -Laptop or notebook computer -Smart phone -Tablet computer -Desktop computer -Smart watch -Fitness tracker -Wearable devices -Smart glasses (e.g. Google glass, Hololens) -Other (Open text) Q4. Please select all that apply. -I ask my friends -I ask my family members -I ask random strangers -I ask professional agents or crowd workers or volunteers through assistive technology -I don't ask anyone Q7.Which of the following assistive technologies have you used so far? Please select all that apply.-To identify an object -For reading documents or screens or labels -To get a general description of a scene -To get the friend's opinion on something (e.g. -Identify the color of a dress or any object -Other (Open text) Scenarios: Suppose there is an assistive technology where you can seek help from your friends by taking a photo of the object, recording the question and sending it to them. Suppose while taking the picture there were some other objects captured along with the soda can. How comfortable would you feel if the following were present in the photo and visible to your friends along with the soda can? If there was an assistive technology where you could ask your friends to identify the medicine bottles by taking a picture of the medicines, how comfortable would you feel asking them for help? Suppose, while taking the picture of medicine bottles there were some other objects captured along with the medicines. Suppose, while taking the picture of the dress/suit and scarf/tie, there were some other objects captured along with the dress. How comfortable would you feel if the following were present in the photo and visible to your friends along with the dress/suit? Please select all that apply? Please select all that apply.-To identify an object -For reading documents or screens or labels -To get a general description of a scene -To get the friend's opinion on something (e.g. If there was an assistive technology where you could ask your friends to identify the soda can by taking a picture of it, how comfortable would you feel asking them for help? If there was an assistive technology where you could ask your friends to identify the medicine bottles by taking a picture of the medicines, how comfortable would you feel asking them for help? Can you please briefly explain your selection above?