Despite the pervasive nature of Internet censorship and the continuous evolution of how and where censorship is applied, measurements of censorship remain comparatively sparse. Diversity is important even within countries, because political dynamics can vary internally, and because different ISPs may implement filtering policies differently.Unfortunately, most mechanisms for measuring Internet censorship currently rely on volunteers who run measurement software deployed on their own Internetconnected devices (e.g., laptops, phones, tablets) [43,49]. Performing measurements of the scale and frequency necessary to understand the scope and evolution of Internet censorship calls for fundamentally new techniques that do not require human involvement or intervention.We aim to develop techniques that can perform widespread, longitudinal measurements of global Internet manipulation without requiring the participation of individual users in the countries of interest. To achieve high detection accuracy, we rely on a collection of metrics that we base on the underlying properties of DNS domains, resolutions, and infrastructure.One set of detection metrics focuses on consistencyintuitively, when we query a domain from different locations, the IP addresses contained in DNS responses should reflect hosting from either a common server (i.e., the same IP address) or the same autonomous system.Another set of detection metrics focuses on independent verifiability, by comparison to independent information such as the identity in the TLS certificate for the website corresponding to the domain. To this end, our design takes steps to ensure that, to the extent possible, we only query open DNS resolvers hosted in Internet infrastructure (e.g., within Internet service providers or cloud hosting providers), in an attempt to eliminate any use of resolvers or forwarders in the home networks of individual users. However, we find that the resulting coverage still suffices to achieve a global view of DNS manipulation, andimportantly-in a safer way than previous studies that exploit open DNS resolvers.Our work makes the following contributions. Studies have also explored the employment of various censorship methods, e.g., injection of fake DNS replies [5,36], blocking of TCP/IP connections [54], and applicationlevel blocking [19,33,41]. Most of these were apparently intended to prevent citizens from reaching social media to spread unwanted information.Other studies have demonstrated that government censorship covers a broad variety of services and topics, including video portals (e.g.,youtube.com) [51], blogs (e.g., livejournal.com) [3], and news sites (e.g., bbc.com) [9]. These human involvements make it more challengingif not impossible-to gather continuous and diverse measurements.Pearce et al. recently developed Augur, a method to perform longitudinal global measurement using TCP/IP side channels [42]. Although Augur examines a similar set of domains and countries as Iris, it focuses on identifying IP-based disruption rather than DNS-based manipulation.Measuring DNS manipulation. There are many country-specific studies that show how different countries use a variety of DNS manipulation techniques to exercise Internet censorship. A number of studies have explored DNS manipulation at a larger scale by probing the IPv4 address space to find open resolvers. A similar scan by anonymous authors [4] in 2012 showed evidence of Chinese DNS censorship affecting non-Chinese systems.Follow-on work in 2015 by Kührer et al. tackled a much larger scope: billions of lookups for 155 domain names by millions of open resolvers [34]. In contrast, we frame an explicit, reproducible method for globally measuring DNS-based manipulation in an ethically responsible manner.In In this section we describe Iris, a scalable, lightweight system to detect DNS manipulation. We aim to identify DNS manipulation, which we define as the instance of a DNS response both (1) having attributes (e.g., IP addresses, autonomous systems, web content) that are not consistent with respect to a welldefined control set; and (2) returning information that is demonstrably incorrect when compared against independent information sources (e.g., TLS certificates). Detecting DNS manipulation is conceptually simple: At a high-level, the idea entails performing DNS queries through geographically distributed DNS resolvers and analyzing the responses for activity that suggests that the responses for a DNS domain might be manipulated. Iris queries a list of sensitive URLs compiled by Citizen Lab [14]. We then supplement this list by adding additional domain names selected at random from the Alexa Top 10,000 [2]. Finally, when attributing DNS manipulation to a particular country or dependent territory, we rely on the country information available from Censys [21] supplemented with MaxMind's [37] dataset to map a resolver to a specific country (or dependent territory). With these concerns in mind, we consider the ethics of performing measurements with Iris, using the ethical guidelines of the Belmont Report [10] and Menlo Report [20] to frame our discussion.One important ethical principle is respect for persons; essentially, this principle states that an experiment should respect the rights of humans as autonomous decisionmakers. Iris's design relies heavily on this principle: Specifically, we note that the benefit of issuing DNS queries through tens of millions of resolvers has rapidly diminishing returns, and that using only open resolvers that we can determine are unlikely to correspond to individual users greatly reduces the risk to any individual without dramatically reducing the benefits of our experiment. To obtain a wide range of measurement vantage points, we use open DNS resolvers deployed around the world; such resolvers will resolve queries for any client.Measurement using open DNS resolvers is an ethically complex issue. Despite efforts to reduce both the prevalence of open resolvers and their potential impact [40], they remain commonplace.Due to these and the ethics considerations that we discussed in §3.2, we restrict the set of open resolvers that we use to the few thousand resolvers that we are reasonably certain are part of the Internet infrastructure (e.g., belonging to Internet service providers, online cloud hosting providers), as opposed to attributable to any single individual. Conceptually, the process comprises two steps: (1) scanning the Internet for open DNS resolvers; or (2) pruning the list of open DNS resolvers that we identify to limit the resolvers to a set that we can reasonably attribute to Internet infrastructure.By using DNS resolvers we do not control, we cannot differentiate between country-wide or state-mandated censorship and localized manipulation (e.g., captive portals, malware [34]) at individual resolvers. In §4.1, we explore the population of open DNS resolvers that we use for our study.Step 2: Identifying Infrastructure DNS Resolvers. At a high level, Iris resolves each DNS domain using the global vantage points afforded by the open DNS resolvers, annotates the response IP addresses with information from both outside datasets as well as additional active probing, and uses consistency and independent verifiability metrics to identify manipulated responses. In addition to the DNS domains that we are interested in testing, we include 3 DNS domains that are under our control to help us compute our consistency metrics when identifying manipulation. To cope with specific resolvers that are unstable or timeout frequently, the tool provides a configurable failure threshold that halts a specific resolver's set of measurements should too many queries fail.To ensure the domains we query are not overloaded, the tool randomizes the order of domains and limits the number of resolvers queried in parallel such that in the worst case no domain experiences more than 1 query per second, in expectation.Step 2: Annotating DNS responses with auxiliary information. Iris annotates each IP address returned in the set of DNS responses with additional information about each IP address's geolocation, autonomous system (AS), port 80 HTTP responses, and port 443 HTTPS X.509 certificates. As a result, when Censys retrieves certificates via port 443 (HTTPS) across the entire IPv4 address space, the certificate that Censys retrieves might differ from the certificate that the server would return in response to a query via TLS's Server Name Indication (SNI) extension. To determine whether a DNS response is manipulated, Iris relies on two types of metrics: consistency metrics and independent verifiability metrics. These controls give us a set of high-confidence correct answers we can use to identify consistency across a range of IP address properties. For example, if Control A returns the answer 192.168.0.10 and 192.168.0.11 and Control B returns 192.168.0.12, we create a set of consistent IP set of (192.168.0.10, 192.168.0.11, 192.168.0.12). When a request returns multiple records, we check all records and consider the reply good if any response passes the appropriate tests.Additionally, unmanipulated passive DNS [6] data collected simultaneously with our experiments across a geographically diverse set of countries could enhance (or replace) our consistency metrics. To account for these inconsistencies, we need additional consistency metrics at higher layers of the protocol stack (specifically HTTP and HTTPS), described next.HTTP Content. As discussed in §5.1, this metric is also useful in identifying sites with dynamic content but shared infrastructure. In another example, much of Google's web hosting infrastructure will return the byte-wise identical redirection page to http://www.google.com/ for HTTP GETs without a valid Google host header. We consider a non-control response as consistent if the PTR record for that response points to the same CDN. Since Iris relies entirely on open infrastructure resolvers that we do not control, in regions with few resolvers, we cannot differentiate between localized manipulation by the resolver's operator and ISP or country-wide manipulation. Analysis of incorrect results focusing on consistency across ISP or country, or examination of webpage content, could aid in identifying localized manipulation.Domain Bias. An adversary could also exploit our consistency metrics and inject incorrect IP addresses within the same AS as the targets.Geolocation Error. Incorrect labeling would identify country-wide manipulation as incomplete (false negatives), or identify manipulation in countries where it is not present (false positives). Due to the ethical considerations we outlined in §3.2, we restrict this set of resolvers to 6,564 infrastructure resolvers, in 157 countries, again with a median of 6 resolvers per country. We also use 4 geographically diverse resolvers for controlled experiments; the 2 Google Public DNS servers [28], a German open resolver hosted on Amazon AWS, and a resolver that we manage at the University of California, Berkeley. We augment this list with 1,000 domains randomly selected from the Alexa Top 10,000, as well as 3 control domains we man- age that should not be manipulated. The common cause of this behavior was rate limiting, as our Internet-wide scans queried resolvers only once, whereas our experiments necessitated repeated queries. We removed another 12 domains and their 72K corresponding query responses as their DNS resolutions failed an automated sanity check; resolvers across numerous countries provided the same incorrect DNS resolution for each of these domains, and the IP address returned was unique per domain (i.e., not a block page or filtering appliance). We did not expect censors to exhibit this behavior; a single censor is not likely to operate across multiple countries or geographic regions, and manipulations such as block pages that use a single IP address across countries should also be spread across multiple domains. Timeouts denote connections where the resolver did not respond to our query within 15 seconds.Server failures indicate when a resolver could not recursively resolve a domain within its own pre-configured time allotment (10 seconds by default in BIND). We found that the most prevalent NX behavior occurred in the countries of Tonga and Pakistan; both countries exhibited censorship of multiple content types, including adult and LGBT. By applying our consistency and independent verifiability metrics, we identify 41,778 responses (0.31%) as manipulated, spread across 58 countries (and dependent territories) and 1,408 domains. "Same HTTP Page" is also relatively effective, as many geographically distributed deployments of the same site (such as with Points-ofPresence) have either identical content or infrastructure error characteristics (see §3.5.1). Iran (122) 6.02% 5.99% 22.41% 0.00% China (62) 5.22% 4.59% 8.40% 0.00% Indonesia (80) 0.63% 2.81% 9.95% 0.00% Greece (26) 0.28% 0.40% 0.83% 0.00% Mongolia (6) 0.17% 0.18% 0.36% 0.00% Iraq (7) 0.09% 1.67% 5.79% 0.00% Bermuda (2) 0.04% 0.04% 0.09% 0.00% Kazakhstan (14) 0.04% 0.30% 3.90% 0.00% Belarus (18) 0.04% 0.07% 0.30% 0.00% Table 6: Top 10 countries by median percent of manipulated responses per resolver. For example, the leftmost pair of bars shows that, while less than 5% of all responses in our dataset came from Iranian resolvers, the responses that we received accounted for nearly 40% of manipulated responses in the dataset. Table 8 shows the extent to which countries return private IP addresses in responses, for the top 10 countries ranked by the relative amount of DNS manipulation compared to the total number of results from that country. Similarly, one set of domains in China experiences manipulation by approximately 80% of resolvers, and another set experiences manipulation only half the time. Iran (122) 6.02% 0.01% China (62) 4.52% 99.46% Indonesia (80) 2.74% 95.08% Iraq (7) 1.68% 1.49% New Zealand (16) 1.59% 100.00% Turkey (192) 0.84% 99.81% Romania (45) 0.77% 100.00% Kuwait (10) 0.61% 0.00% Greece (26) 0.41% 100.00% Cyprus (5) 0.40% 100.00% Heterogeneity across a country may suggest a situation where different ISPs implement filtering with different block lists; it might also indicate variability across geographic region within a country. Although no single domain experiences manipulation in more than 19 countries, several categories experience manipulation in more than 30 countries, indicating that while broad categories appear to be commonly targeted, the specific domains may vary country to country.To study how manipulated categories vary across countries, we analyzed the fraction of resolvers within each country that manipulate a particular category. The major contributions of our work are: (1) Iris: a scalable, ethical system for measuring DNS manipulation; (2) an analysis technique for disambiguating natural variation in DNS responses (e.g., due to CDNs) from more nefarious types of manipulation; and (3) a largescale measurement study that highlights the heterogeneity of DNS manipulation, across countries, resolvers, and domains. Category # Cn # Res We also note that commonly measured sites such as The Tor Project, Google, and Twitter, experience manipulation across significantly fewer countries than some sites.