zxcvbn is an alternative password strength estimator that is small, fast, and crucially no harder than LUDS to adopt. We find 1.5 MB of compressed storage is sufficient to accurately estimate the best-known guessing attacks up to 10 5 guesses, or 10 4 and 10 3 guesses, respectively, given 245 kB and 29 kB. We argue that anything beyond a small client library with a simple interface is too costly for most would-be adopters, and that estimator accuracy is most important at low magnitudes and often not important past anywhere from 10 2 to 10 6 guesses depending on site-specific rate limiting capabilities.The Dropbox tech blog presented an early version of zxcvbn in 2012 [55]. Section 5.2.3 demonstrates that this simple minimum rank over several lists is responsible for most of zxcvbn's accuracy.Section 4 generalizes this idea in two ways. For each password in a test set sampled from real leaks, we take the minimum guess attempts needed over these four models as our conservative gold standard for strength. Section 5 measures accuracy by comparing strength estimations of each password to this gold standard. For such a policy, an adopter needs confidence that their estimator won't overestimate below their chosen N value. The Green Book suggested evaluating password strength in terms of guessing space, modeled as S = A M , where S is the maximum guess attempts needed to guess a password, M is the password's length, and A is its alphabet size. len 3: e ← e + 6 if p contains upper and non-alpha 4: e ← e + 6 if p.len < 20 and p 񮽙 ∈ dict 5: return e That is, NIST adds 4 bits for the first character in a password p, 2 bits each for characters 2 through 8, progressively fewer bits for each additional character, 6 more bits if both an uppercase and non-alphabetic character are used -so far, all LUDS. Shay et al. [48] studied Carnegie Mellon University's policy migration as part of joining the InCommon Federation and seeking its NIST-entropy-derived Silver Assurance certification [9], to give one notable example.Whether used for feedback or for requirements, the goal of any LUDS formulation is ultimately to guide users towards less guessable passwords, 3 and herein lies the first problem -it's ineffective. Wang and Wang [52] studied the password composition policies of 50 sites in 2015 (30 from mainland China, the rest mostly American) and found that no two sites enforced the same policy. Carnavalet and Mannan [25] investigated the registration flows of 18 prominent services spanning multiple countries, platforms, and product domains, and with three exceptions (Google, Dropbox, and KeePass), they found simple but widely inconsistent LUDS-based calculations powering visual feedback, sometimes combined with dictionary checks. Because our gold standard should be a safe lower bound not just over the theoretical best attacks, but also the best-productized attacks in common use by professionals, we further run Hashcat [2] and John the Ripper [3] mangled dictionary models with carefully tuned rule sets.Throughout this paper, we will differentiate between online guessing, where an attacker attempts guesses through a public interface, and offline guessing, where, following a theft of password hashes, an attacker makes guesses at a much higher rate on their own hardware. This language is also one of the first to allow customized user feedback, a precursor to today's ubiquitous password strength meters. None of these early rule-based systems estimate password strength, making it hard to correctly balance usability and answer whether a password is sufficiently unguessable.Spafford and others proposed space-efficient dictionary lookup techniques using Bloom filters [49,40] and decision trees [15,18]. Melicher et al.'s concurrent and independent research on lean estimation with Recurrent Neural Networks is quite promising [42]. KeePass (reviewed in [25]) matches several common patterns including a dictionary lookup with common transformations, then applies an optimal static entropy encoder documented in their help center [4] to search for the simplest set of candidate matches covering a password. It employs a client-server architecture that is hosted as a stand-alone site, and does not output a guess attempt estimate or equivalent, so we do not evaluate it as a candidate LUDS alternative.Ur et al.[50] and Egelman et al.[28] studied the effect of strength meters on password composition behavior. Bonneau and Preibusch [21] demonstrated that the big detailscryptography and rate-limiting, for example -are commonly lacking throughout the Internet with little economic incentive to do better. Because guessing attacks often rank low on a user's list of worries, short and memorable password choices are often driven by rational cost-benefit analysis as opposed to ignorance [31]. 3class8 is a prime offender in this category.While underestimation harms usability, overestimation is arguably worse given an estimator's primary goal of mitigating guessing attacks. This detail provides adopters with an intuitive language for modeling guessing threats and balancing usability. For example, given enough samples, [26] is accurate up to the highest feasible guessing ranges, whereas with 1.5MB of data, zxcvbn is only highly accurate up to 10 5 guesses. By studying leaked password distributions, [30] also points out that an attacker guessing in optimal order would face a reduction in success rate by approximately 5 orders of magnitude upon reaching 10 6 guesses.While we use 10 6 as an online cutoff for safe and simple analysis in Section 5, we recognize that an upper bound on online guessing is highly dependent on sitespecific capabilities, and that some sites will be able to stop an online attack starting at only a few guesses. Current bandwidth averages should factor into this discussion: a South Korean product might tolerate a gzipped-5MB estimator (downloadable in 2 seconds at 20.5Mbps national average in Q3 2015 [14] 4 ), whereas 1.5MB is a reasonable global upper bound in 2016 (2.3 seconds at 5.1Mbps Q3 2015 global default). For example, if a password consists of two top-100 common words, it models an attacker who makes guesses as concatenations of two words from a 100-word dictionary, calculating 100 2 as its worst-case guess attempt estimate.To help prevent overly complex matching, zxcvbn now loosens the 2012 assumption by instead assuming the attacker knows the patterns that make up a password, but not necessarily how many or in which order. To illustrate the difference, compare the respective 2012 and 2016 analyses of jessiah03:jess(name) i(word) ah0(surname) 3(bruteforce) jessia(name) h03(bruteforce)The 2012 version has no bias against long pattern sequences, matching i and jess as common words. "To formalize this difference in behavior, at a high level, both versions consist of three phases: match, estimate and search. For example, given lenovo1111 as input, this phase might return lenovo (password token), eno (English "one" backwards), no (English), no (English "on" backwards), 1111 (repeat pattern), and 1111 (Date pattern, 1/1/2011). Before attempting length-|S| sequences, zxcvbn assumes that a guesser attempts lower-length pattern sequences first with a minimum of D guesses per pattern, trying a total of ∑|S|−1 l=1 D l ≈ D |S|−1 guesses for suffi- ciently large D.For example, if a password consists of the 20th most common password token t with a digit d at the end -a length-2 pattern sequence -and the attacker knows the D = 10000 most common passwords, and further, td is not in that top-10000 list (otherwise it would have been matched as a single token), the D 1 term models an attacker who iterates through those 10000 top guesses first before moving on to two-pattern guessing. While an attacker might make as few as 10 guesses for a single-digit pattern or as many as tens of millions of guesses iterating through a common password dictionary, we've found D = 1000 to D = 10000 to work well in practice and adopt the latter figure for zxcvbn.In practical terms, the additive D penalty and multiplicative |S|! An input @BA1one is first lowercased to @ba1one. If the l33t table maps @ to a and l to either i or l, it tries two additional matches by subbing [@->a, 1->i] and [@->a, 1->l], finding abalone with the second substitution.Taking a cue from KeePass, sequence matching in zxcvbn looks for sequences where each character is a fixed Unicode codepoint distance from the last. The repeat matcher runs a match-estimatesearch recursively on its winning repeated unit, such that, for example, repeated words and dates are identified.The keyboard matcher runs through password linearly, looking for chains of adjacent keys according to each of its keyboard adjacency graphs. Additional layouts can be prepackaged or dynamically added.Date matching considers digit regions of 4 to 8 characters, checks a table to find possible splits, and attempts a day-month-year mapping for each split such that the year is two or four digits, the year isn't in the middle, the month is between 1 and 12 inclusive, and the day is between 1 and 31 inclusive. Green Book-style guessing space calculations then follow, but for patterns instead of random strings, where a guesser attempts simpler or more likely patterns first.For tokens, we use the frequency rank as the estimate, because an attacker guessing tokens in order of popularity would need at least that many attempts. A reversed token gets a doubled estimate, because the attacker would then need to try two guesses (normal and reversed) for each token. Guesses for keyboard patterns are estimated as:1 2 L ∑ i=1 min(T,i−i) ∑ j=1 񮽙 i − 1 j − 1 񮽙 SD j (3)where L is the length of the pattern, T is the number of terms, D is the average number of neighbors per key (a tilde has one neighbor on QWERTY, the 'a' key has four) and S is the number of keys on the keyboard. For T turns throughout a length L keyboard pattern, we assume a guesser attempts lower-length, lower-turn patterns first, starting at length 2. Repeat guess attempts are then estimated as g · n. For example, nownownow is estimated as requiring 126 guesses: now is at rank 42 in the Wiktionary set, times 3. Sequences are scored according to s · n · |d|, where s is the number of possible starting characters, n is the length, and d is the codepoint delta (e.g., -2 in 9753). × Π 6:if g < g opt 7: g opt ← g 8:l opt ← l 9: Π opt [k][l] ← Π 10: B opt [k][l] ← mAt the end, UNWIND steps through the backpointers to form the final optimal sequence: return S Each match m ∈ S is considered only once during the search, yielding a runtime of O(l max · (n + |S|)), where l max is the maximum value of l opt over each k iteration. In practice, l max rarely exceeds 5, and this method rapidly terminates even for passwords of hundreds of characters and thousands of matches.1: function UNWIND(n) 2: S ← [ ] 3: l ← l opt 4: k ← n − 1 5: while k ≥ 0 6: m ← B opt [k][l] zxcvbn is written in CoffeeScript and compiled via an npm build flow into both a server-side CommonJS module and a minified browser script. Running javascript with or without a web view works similarly on Android.Dropbox uses zxcvbn for feedback and has never enforced composition requirements other than a 6-character minimum. zxcvbn ports exist for Java, Objective-C, Python, Go, Ruby, PHP, and more. For our password strength gold standard, as introduced in Section 2.2, we ran the min_auto configuration of PGS [8] with the same training data found to be most effective in [51]. The PGS training data (roughly 21M unique tokens) consists of the RockYou'09 password leak (minus a randomly sampled 15k test set), Yahoo'12 leak (minus a similar 15k test set), MySpace'06 leak, 1-grams from the Google Web Corpus, and two English dictionaries. While a real attacker wouldn't have training data from their target distribution, they might be able to tailor their attack by deriving partial knowledge -common locales and other user demographics (RockYou includes many Romanian-language passwords in addition to English), site-specific vocabulary (game terminology, say), and so on.Our estimators are given ranked lists of common tokens as their training data, with one separately ranked list per data source. Instead of counting top passwords from the MySpace'06 leak, our estimators use the Xato'15 corpus which is over 200 times bigger.In all, we count top tokens from the PGS training portion of RockYou'09 and Yahoo'12 (test sets are excluded from the count), Xato'15, 1-grams from English Wikipedia, common words from a Wiktionary 29M-word frequency study of US television and film [10], and common names and surnames from the 1990 US Census [1]. When PGS is unable to guess a password, we exclude it from our sample set S. On each sampled password x i ∈ S, we then measure an algorithm's estimation error by computing its order-of-magnitude difference ∆ i from PGS,∆ i = log 10 g alg (x i ) g pgs (x i )(4)where g alg is the guess attempt estimate of the algorithm and g pgs is the minimum guess order of the four PGS guessing attacks. We compare PGS to the estimator algorithms in three ways. Of the RockYou 15k test set, PGS cracked 39.68% within our online guessing range of up to 10 6 guesses and 52.65% above 10 6 , leaving 7.67% unguessed. Points above the top / below the bottom dotted lines over/underestimate by more than 2 orders of magnitude (∆ i > 2 above the top line, ∆ i < −2 below the bottom line). Hence, the greatest overestimation in both cases happens between the estimator dictionary cutoff and PGS dictionary cutoff, high- lighting the sensitivity of estimator dictionary size.The horizontal banding at fixed orders of magnitude in zxcvbn corresponds to bruteforce matches where no other pattern could be identified. Figures 3, 5, and 6 show zxcvbn with the 100k, 10k and 1k token sets. To measure zxcvbn runtime performance, we concatenated the RockYou'09 and Yahoo'12 test sets into a single 30k list. To the extent that our estimator is trained on the same or similar password leaks and dictionaries as employed by attackers, we've demonstrated that checking the minimum rank over a series of frequency ranked lists, combined with light pattern matching, is enough to accurately and conservatively predict today's best guessing attacks within the range of an online attack. zxcvbn works entirely client-side, runs in milliseconds, and has a configurable download size: 1.5MB of compressed storage is sufficient for high accuracy up to 10 5 guesses, 245 kB up to 10 4 guesses, or 29 kB up to 10 3 guesses. For the sake of reproducibility, we detail the specifics of the algorithms and data we employed in our experiments. The 100k token set described in Section 5 consists of about 390k unique tokens (consisting of several lists ending up to rank-100k). We cut this list off at 10k top tokens, given the smaller size of the leak.Xato: Mark Burnett's 10M password corpus, released in 2015 on Xato.net and compiled by sampling thousands of password leaks over approximately 15 years. 40k unique tokens.USCensus: Names and surnames from the 1990 United States Census [1] ranked by frequency as three separate lists: surnames, female names, and male names. We offer the same explanation as with RockYou: PGS is trained on a little over 10 7 unique tokens, some of which are long and unrecognized by the estimators. PGS occasionally succeeds making single-token guesses at these higher magnitudes, leading to a spike in inaccuracy between estimator dictionary cutoff and PGS dictionary cutoff.In Figure 11, we see a similar ∆ i spike at zero for zxcvbn followed by a sharp decline to the right, indicating high accuracy and low overestimation within an online range. The bottom portion of Table 2 shows the cumulative effect of matching additional pattern types.