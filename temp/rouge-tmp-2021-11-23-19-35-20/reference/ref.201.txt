The attack integrates information leaked by three independent sources: the timing of keystrokes manifested in packet inter-arrival times, percent-encoded Space characters in a URL, and the static Huffman code used in HTTP2 header compression. While each source is a relatively weak predictor in its own right, combined, and by leveraging the relatively low entropy of English language, up to 15% of search queries are identified among a list of 50 hypothesis queries generated from a dictionary with over 12k words. To protect user privacy, all major search engines now encrypt search query traffic.Autocomplete is a feature that provides suggested queries to the user as they type based on the partially completed query, trending topics, and the user's search history [2]. The attack detects keystrokes in encrypted network traffic and identifies search queries using information from three independent sources: keystroke timings manifested in packet inter-arrival times, percent-encoding of Space characters in a URL, and the static Huffman code used in HTTP2 header compression.The attack we developed, called KREEP (Keystroke Recognition and Entropy Elimination Program), consists of five stages: keystroke detection, which separates packets that correspond to keystrokes from background traffic; tokenization to delineate words in the packet sequence; dictionary pruning, which uses an HTTP2 header compression side channel to eliminate words from a large dictionary; word identification, performed by a neural network that predicts word probabilities from packet inter-arrival times; and a beam search, which generates hypothesis queries using a language model. We demonstrate our attack on two popular search engines and evaluate its performing using a collected dataset of 16k search queries. However, with autocomplete, a search query is built up incrementally one character at a time and then recompressed. We describe a method to leverage this information leakage to prune a dictionary, which increases the accuracy of our remote keylogging attack.3) A neural network that identifies words from keystroke timings. The network is trained on keystrokes recorded from 83k typists, and words are correctly identified with 19% accuracy.4) The integration of a language model and keystroke timing attack to leverage the relatively low entropy of English language. The use of a language model significantly improves performance.In the next section, we provide background information on keylogging side channels and autocomplete. The attack workflow and threat model are described in Section 3, followed by keystroke detection and tokenization in Section 4. Such attacks have been demonstrated for a wide range of modalities such as acoustics [5], seismic activity [31], hand motion [54], and spikes in CPU load [46]. Remote keystroke timing attacks may target applications in which a keystroke induces network traffic from the victim's host, such as SSH [47] or a search engine with autocomplete functionality [51]. For the purpose of identifying search queries, we assume natural language input which enables KREEP to leverage a language model in generating hypothesis queries.Two main problems arise when trying to determine keystrokes from timings. In our attack, we assume that each key is either an English alphabetic character (A-Z) or the Space key, for a total of 27 keys.We address the problems of keystroke detection and key identification separately. As changes to the query are detected, the client sends an HTTP GET request to the server and the server responds with a list of suggested search queries [26]. This results in a series of HTTP requests following keyboard events, such as those shown in Figure 1 Figure 1: Autocomplete requests for the query "the lazy dog" in Google (left) and Baidu (right). After each key press, the client sends an HTTP GET request that contains the partially completed query in the URL (shown in bold). In this situation when the typing rate exceeds the polling rate, the keyboard input event times are not faithfully preserved in packet inter-arrival times due to multiple keys being merged into a single request.The second method of implementing autocomplete is a callback model in which the requests are triggered by HTML DOM keydown or keyup input events. Non-printable characters, such as Shift, Ctrl, and Alt, are ignored since these alone do not result in visible changes to the query.We focus only on search engines that implement autocomplete requests triggered by keydown events. Because Yandex is not vulnerable to the method of tokenization described in Section 4, we consider only search engines Google and Baidu. This excludes queries that were copied and pasted, the use of Backspace and Delete keys, and any other input that might cause the cursor to change position, such as arrow keys. The victim might select an autocomplete suggestion before typing a complete query; KREEP can identify the query up to the point a selection was made.The query must contain words in a large English dictionary known to the attacker. We use a dictionary of over 12k words comprised of the 10k most common English words [32] together with English words that appear in the Enron email corpus and English gigaword newswire corpus [19] (used to simulate search queries, see Section 7.1 for dataset details). Beam search: word probabilities are combined with a language model in a beam search that generates hypothesis queries. Likewise, a tokenization false positive occurs when a letter is incorrectly labeled as a Space, and false negative occurs when a Space is missed. We compare this to the information gain in a classical compression side channel where only the total compressed size of the query is known.For word identification, we report the word classification accuracy from packet timings, assuming perfect detection and tokenization. As the user types a query into a search engine with autocomplete, the client emits HTTP requests that contain the partially completed query, such as those shown in Figure 1. We perform keystroke detection by isolating a subsequence of packets that exhibit this pattern, taking into account the particular behavior of each search engine described below.The behavior of each search engine is characterized by the sequence of size differences between successive autocomplete request packets. Figure 3 shows the distribution of d i as a function of query length for both Google and Baidu. From this figure and a manual inspection of several HTTP request packets, we make several observations about the behavior of each search engine. As each new character is appended to the "q=" parameter of the URL, the size increases by about a byte. At this point, an additional "gs_mss" parameter with the partially completed query is added to the URL. The request then continues to increase by about 1 byte per character thereafter.The autocomplete packet sizes of Baidu typically increase by either 2 or 4 bytes per character, with a larger increase of 7 or 9 bytes at the beginning of the sequence. For example, if the user types "th", the first request will contain "wd=t" followed by "wd=th&pwd=t", resulting in a 7 byte increase (6 bytes for "&pwd=t" and 1 byte for "h"). In Google, this parameter is "cp=", where "cp" increments with each request (see Figure 1), and Baidu uses the "csor=" parameter. On the 10th request, "cp=9" becomes "cp=10", resulting in an additional 1 byte increase. To that end, we generalize the LIS problem to that of finding the longest subsequence accepted by a sequence detector DFA based on observations in the previous section.We define a DFA that accepts a sequence of packet size differences generated by the autocomplete of each search engine. States a and b correspond toa b c d d = 0 d > 3 d = 0 1 ≤ d ≤ 3 1 ≤ d ≤ 3 1 ≤ d ≤ 3 d > 3 1 ≤ d ≤ 3Figure 4: DFA that accepts a sequence of packet size differences generated by autocomplete in Google search.increases of between 0 and 3 bytes prior to the large increase from the addition of the "gs_mss" parameter, and states c and d are reached after the large increase. The Huffman code for characters "%", "2", and "0" have bit lengths 6, 5, and 5 respectively, and the sequence "%20" has a total compressed bit length of 16 bits. Baidu does not use HTTP2, so the escape sequence "%20" occupies 3 bytes. The encoded symbols occupy 6+5+6+5=22 bits, which is then padded with 2 bits for a total size of 3 bytes.It was previously determined that size alone does not leak a considerable amount of information in HPACK [50]. Instead of b, an adversary observes byte size B = p+∑ h i 8 where 0 ≤ p ≤ 7 is an unknown amount of padding to align the compressed bit string with the nearest octet.However, the query in a sequence of autocomplete requests grows incrementally. The observed size sequence B 1 , . . . , B n is compared to every sequence B w,p 0 1 , . . . , B w,p 0 n in the dictionary to discover potential matches and eliminate words that could not have been typed by the user.An example is shown in Figure 6 where the user typed a 4 letter word with cumulative byte size [1,2,3,3]. The observed sequence [1, 2, 3, 3] matches "dogs" with no padding and "guns" with 0 or 1 byte padding; "cats" has no matches and can be safely eliminated.with p 0 = 0 or p 0 = 1. Since the lengths of lowercase ASCII characters range from 5 to 7 bits, an increase of at least 1 byte is guaranteed when p i−1 < 5. For example in Figure 6, P ([1, 2, 3, 3] |"guns") = 2 8 since the sequence [1, 2, 3, 3] is possible for the word "guns" with paddings of 0 and 1 out of 8 possible padding amounts. However, the information gain from cumulative size increases for longer words due to the "uniqueness" of the cumulative byte sizes revealed through incremental compression. Word probabilities are determined for the remaining words in the dictionary after pruning, and these probabilities are combined with a language model in a beam search to generate hypothesis queries. The model takes as input the sequence of latencies τ i for 0 ≤ i ≤ n and predicts P (k i ), the probability of each key k i for 1 ≤ i ≤ n.The first layer of the network is a bidirectional recurrent neural network (RNN) with gated recurrent units (GRU) that takes as input the sequence of n + 1 time intervals. For example, if a particular pattern of latencies is indicative of the sequence "th", the model can learn to recognize "th" in different words such as "the", "there", "beneath", and so on. As an example, consider trying to predict an 8-letter word that follows the sequence "recovering from a _". Beam search is a breadth-first greedy search algorithm that maintains a list of top candidates (the "beam") as it progresses the search tree.For each token, all the words in the dictionary are appended to each hypothesis in the beam, which starts with the empty string. In this section, we describe our data collection setup and evaluate attack performance. The measurement setup consists of a keystroke dataset previously collected from human subjects, browser automation with Selenium WebDriver, and a process to replay keystrokes by writing keyboard events to /dev/uinput in real time.To train the neural network, we used a subset of a publicly available keystroke dataset collected from over 100k users typing excerpts from the Enron email corpus and English gigaword newswire corpus [15]. None of the users in the evaluation data appeared in the dataset used to train the neural network.Each capture proceeded as follows. This ensures keyboard event times are replayed with high fidelity and not quantized due to the presence of a global system timer.We captured 4k unique queries on search engines Google and Baidu, both of which default to an HTTPS connection and generate autocomplete requests upon key-press events. To understand how the browser itself might affect network timings, the data collect was performed in both Chrome (v.71, with QUIC disabled) and Firefox (v.64). In HPACK, the string length starts as a 7-bit integer (see Figure Google Google Table 2: Top-50 classification accuracy: % of queries that are correctly identified among the 50 hypothesis queries.5). False negatives in both Google and Baidu were due mainly to larger changes in packet size coinciding with a Space. These larger changes (> 10 bytes) mask the change in size due to the Space key (2 or 4 bytes). The hypothesis queries have the same total length as the true query but differ in word lengths, resulting in relatively high edit distance.The proportion of attacks in which the true query is identified among the hypotheses queries, analogous to a top-50 classification accuracy, is shown Table 2. Baseline performance is obtained by generating 50 ran-Perfect detection/tokenization Keystroke detection false negative Tokenization false positive he is recovering from a sprained 0 to be president from a position 18 is to learn from such a position 23 he is recovering from a strained 1 to be president from a business 17 is to learn from such a purchase 23 he is recovering from a fracture 7 to be president just a fraction 22 is to learn more from a position 20 he is recovering from a position 7 to be president from a possible 18 is to learn from such a pressing 22 he is recovering from a possible 7 to be president from a southern 18 is to learn from such a practice 21Figure 9: Query hypotheses in three different scenarios: perfect detection and tokenization (left), false negative keystroke detection (center, the 7th packet is missed), and false positive tokenization (right, the 11th packet is labeled as a Space). The edit distance to the true query "he is recovering from a sprained", is shown to the right of each hypothesis. We did not find any significant difference in performance across browsers, but did achieve overall higher query identification rates on Google due information leaked through incremental compression.We found the example in Figure 9 to be representative of attack success which generally had polarized outcomes: the hypotheses were either very similar to or very different from the true query. These results are shown in Figure 12 with baseline performance as described in the previous section. Incremental gains are then achieved when the dictionary is pruned. In this regard, variations in routing delay potentially provide a natural defense to remote keystroke timing attack.The Laplace distribution has previously been proposed as a model for PDV [60]. packets in the trace remain unchanged such that the padding defense could be implemented entirely in the client side autocomplete logic. Search engines with autocomplete are part of a larger class of applications in which the manifestation of human-computer interactions in network traffic can lead to a remote side channel attack. This includes VoIP: as utterances are compressed and transmitted in real time, spoken phrases can be identified in encrypted network traffic [55,56]; SSH: single characters are transmitted to and echoed back by the server, exposing the timing of key presses [47]; HTTP: unencrypted network traces contain a user's web browsing activity [36,57]; and HTTPS: in dynamic web applications, server response size can reveal interactions with specific elements on a web page [12]. Our work confirms that assumption by using timings obtained from actual network traffic and users typing complete phrases instead of isolated bigrams.There have been numerous works focused on the detection of keyboard events (which enables a timing attack), such as through spikes in CPU load [45], cache and memory usage [41], and the proc filesystem [23]. In a recent work, we characterized the autocomplete network traffic of five major search engines and measured the correlation between key-press latencies on the host and packet inter-arrival times observed remotely [35], finding search engines Google and Baidu to leak the most information. There have been several attacks on HTTPS based on this principle.The CRIME attack exploits compression in TLS and in the now deprecated SPDY protocol [42]. This attack requires a man-in-the-middle vantage in which an attacker inserts a guess for a secret, e.g., an HTTP cookie or a CSRF token, into a message and observes the compressed size. For example, to find out whether a secret starts with "p", an attacker guesses "secret=p_" and "secret=_p": if the sizes are the same, then only Huffman coding is used and the guess is wrong; otherwise, if the sizes are different, the LZ77 component was invoked based on redundancy between the first guess and the secret, and only Huffman coding was invoked in the second guess.HPACK, the header compression format in HTTP2, was designed to be resistant to CRIME-like attacks targeting LZ77 compression, although HTTP2 borrowed many concepts from SPDY [39]. Potential matches to a secret are revealed by comparing its cumulative compressed size to every word in the dictionary.Search query identification Previous work on identifying search queries has utilized features obtained primarily through traffic analysis. In [12], an attacker guesses a victim's query one letter at a time by trying all combinations and matching the server response size. In practice, this is difficult because autocomplete suggestions depend on the victim's search history and location, among other factors [2]. However, we have confirmed that padding by a small random amount (1 byte with probability 0.5) does effectively mitigate tokenization and incremental compression. This approach has the cost of increased bandwidth, a tradeoff reminiscent of the anonymity trilemma [13], and requires some cooperation from the server to ignore the dummy requests.Merge requests Most search engines make an autocomplete request immediately following each new character appended to the input field [35]. We point out several limitations of our attack, emphasizing the conditions under which it succeeds, and identify ways in which KREEP could be extended or improved.Other websites In this work, KREEP has only been tested on search engines Google and Baidu. For websites that aren't vulnerable to tokenization, delimiters might be identified based on packet interarrival times (e.g., larger intervals indicate Space, smaller intervals indicate letters). We assumed that no deletions or corrections were made and that the user did not press any non-printable keys, e.g., arrow keys, that cause the caret to change position. We verified this difference by comparing the frequency of characters in the AOL search dataset to the keystroke dataset we used to evaluate KREEP (which itself borrowed phrases from the Enron email corpus [15]). Notably, the frequencies of "w" and "c" in search queries are about twice that of natural language, likely due to the presence of navigational queries to a specific URL, such as "www.example.com". Besides websites that provide search suggestions, this could include mapping services, which modify the geographic coordinates in a URL as the user drags the map center location, or websites that autosave the contents of a text field.Likewise, websites that generate network traffic in response to user input events may be vulnerable to timing attack. We thank the anonymous reviewers and our shepherd for valuable feedback during the review process. yKREEP is available at https://github.com/vmonaco/ kreep. KREEP is available at https://github.com/vmonaco/ kreep.