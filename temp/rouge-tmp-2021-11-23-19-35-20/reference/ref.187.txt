Due to ever-increasing amounts of automation and research on better fuzzing strategies , large-scale, dragnet-style fuzzing of many hundreds of targets becomes viable. In this paper, we introduce several techniques to protect a binary executable against an analysis with automated bug finding approaches that are based on fuzzing, symbolic/con-colic execution, and taint-assisted fuzzing (commonly known as hybrid fuzzing). More specifically, we perform a systematic analysis of the fundamental assumptions of bug finding tools and develop general countermeasures for each assumption. Just as obfuscation techniques increase the amount of human labor needed to find a vulnerability, our techniques render automated fuzzing-based approaches futile. Additionally, fuzzers typically required large, exhaustive seed corpora or a precise description of the input format in form of a grammar. This push toward automation greatly simplifies the usage of these tools. This can be achieved by adding mechanisms to the software such that the final binary executable is protected against fuzzing: the maintainers can then build an internal version that can be tested thoroughly, while an attacker can only access the protected binary which prohibits automated tests. In this paper, we tackle this challenge and present several general methods to impede large scale, automated fuzzing audit of binary executables. We present several techniques that can be added during the compilation phase of a given software project such that the resulting binary executable withstands fuzzing and significantly hampers automated analysis. We find that all of them rely on at least one of the following four basic assumptions: (i) coverage yields relevant feedback, (ii) crashes can be detected, (iii) many executions per second are achievable, and (iv) constraints are solvable with symbolic execution. Based on these insights, we develop fuzzing countermeasures and implement a lightweight protection scheme in the form of a configurable, auto-generated single C header file that developers can add to their application to impede fuzzers. Our evaluation with several different programs shows that with a negligible performance overhead, ANTIFUZZ hardens a target binary executable such that none of the tested fuzzers are able to find any bugs.To foster research on this topic, we release our implementation and the data sets used as part of the evaluation at https://github.com/RUB-SysSec/antifuzz. Even though this technique is surprisingly simple-particularly when compared to static program analysis techniques-with a sufficient number of executions per second it has been helpful at finding bugs in complex, real-world software in the past.In recent years, the computer security community paid much more attention to improving the performance and scalability of fuzzing. To improve the usability of fuzzers in such scenarios, the biggest focus of the research community is to automatically overcome hard-to-fuzz code constructs that previous methods could not successfully solve with the goal of reaching deeper parts of the code. For example, symbolic execution and its somewhat more scalable derivative concolic execution was used to overcome hard branches and trigger bugs that are only trigger-able by rare conditions [25-27, 31, 42, 48, 50, 54]. Two approaches were commonly applied: mutational fuzzing and generational fuzzing.Mutational fuzzers require a good corpus of inputs to mutate. Generally, mutational fuzzers do not know which code regions depend on the input file and which inputs are necessary to reach more code regions. The second approach is generational fuzzing: fuzzers which employ this technique need a formal specification to define the input format. The additional need for a formal specification makes this approach much less useful for largescale bug hunting with little human interaction. In contrast, a blind fuzzer introduces random mutations to the input without knowing how those mutations affect the program. It effectively relies on pure chance for finding crashing inputs, while a coverage-guided fuzzer could mutate the same input file iteratively to increase the code coverage and thus get closer to new regions where a crash could happen. Different fuzzers tend to use the coverage feedback obtained in different ways. To illustrate these differences, we select two well-known coverage-guided fuzzers; namely AFL and VUZZER. However, due to the unique usage of coverage information in VUZZER, we describe it as well.AFL A key factor behind the success of AFL is an efficient, approximate representation of the code coverage. For example, in Listing 1, AFL cannot distinguish the coverage produced by lines 2 and 3 when called from line 10 from the coverage produced by the same lines (lines 2 and 3) in the second call. It is worth to mention that this drastically increases the number of entries in the bitmap, and therefore ANGORA might need a bigger bitmap.Listing 1: A sample code which illustrates the differences between AFL and ANGORA on distinguishing coverage information1 b o o l cmp ( char * a , char * b ) { 2 i f ( a [ 0 ] = = b [ 0 ] ) { 3 i f ( a [ 1 ] = = b [ 1 ] ) { 4r e t u r n t r u e ; 5 } 6 } 7 r e t u r n f a l s e ; 8 } 9 . . . . 10 i f ( cmp ( i n p u t , " f o " ) ) { 11 i f ( cmp ( i n p u t +2 , " ba " ) ) { 12. . . . To further improve the feedback mechanism, VUZZER excludes basic blocks that belong to error paths by measuring the coverage produced by random inputs. By using symbolic execution or taint analysis, a fuzzer is able to reason what inputs are necessary to cover new edges and basic blocks. Instead of only relying on random mutations and selection by information gathered through feedback mechanisms, these tools try to calculate and extract the correct input necessary for new code coverage. In contrast, QSYM [54] identified this behavior as a weakness since the fuzzer can validate that the input proposed by the symbolic or concolic execution generates new coverage very cheaply. Once T-FUZZ finds a crashing input for the patched program, it uses symbolic execution to calculate an input that actually crashes the unpatched target program. The first insight is that while many aspects of fuzzing have changed since 1981, two basic assumptions which were originally made still apply to most modern fuzzers: these two basic original assumptions are crash detection and high execution throughput. We divide the current fuzzing assumptions into the following four groups:(A) Coverage Yields Relevant Feedback Coverageguided fuzzers typically assume that novel code coverage also strongly correlates with novel behavior. (C) Many Executions per Second To efficiently generate input files with great coverage, the number of executions per second needs to be as high as possible. Hybrid fuzzers or tools based on symbolic execution such as DRILLER, KLEE, QSYM, and T-FUZZ need to be able to represent the program's behavior symbolically and solve the resulting formulas. This means that the internal representation of the state of the symbolic/concolic execution engine has to be small enough to store and the resulting constraints set has to be solvable by current solvers to avoid problems related to state explosion.Summary We compiled a list of 19 different bug finding tools and systematically check which assumptions they rely on. Based on the analysis results of the previous section, we now introduce techniques to break the identified assumptions of bug finding tools in a systematic and generic way. Additionally, smart fuzzing techniques outperform source-based fuzzing even in binary-only targets [8,54]. As an alternative, projects with such a successful history of community integration can choose to release unprotected binaries to a set of trusted security researchers. As mentioned previously, the core assumption of coverageguided fuzzers is that new coverage indicates new behavior in the program. Thereby, we weaken the fuzzer's ability to use the feedback mechanism in any useful way and thus remove their advantage over blind fuzzers.To introduce noise into the coverage information, we use two different techniques. The rationale behind this is that according to the coverage-guide assumption, any new coverage means that the fuzzer found an input that causes new behavior. Therefore, if the program always displays new coverage (due to our fake code), the fuzzer cannot distinguish between legitimate new coverage and invalid fake coverage. We create this fake code by creating random trees of nested conditions with conditions on the input ranging from simple to complicated.Evasion Overall, the attack on the code-coverage assumption consists of a combination of these two techniques to fool the fuzzer into believing that most inputs lead to new code coverage and thus they are classified as "interesting". This fills up the attention mechanism of the fuzzer (e.g., AFL's bitmap or a queue) with random information which breaks the assumption that the feedback mechanism is helpful in determining which inputs will lead to interesting code. Our third countermeasure attacks this assumption, without reducing the overall performance of the protected program, as follows: we check whether the input is a well-formed input; if and only if we detect a malformed input, we enforce an artificial slowdown of the application. We believe that even if malformed input files occasionally happen in real scenarios, a slowdown of e.g., 250ms per invalid input is barely noticeable to the end user in most cases. However, to harden this technique against automated code analysis and patching tools, one can add a computationallyheavy task (e.g., encryption, hash calculation, or even cryptocurrency mining) to the protected program such that the resulting solution is necessary to continue the execution.Evasion Most applications expect some kind of structure for their input files and have the ability to tell if the input adheres to this structure. This breaks the assumption that the application can be executed hundreds or thousands of times per second, thus severely limiting the chances of efficiently finding new code coverage. However this technique has one weakness: If a seed file is provided that contains the correct value, a concolic execution engine might still be able to continue solving other branches.As a second technique, we can encrypt and then decrypted the input with a block cipher. Evasion By sending the input data through a strong block cipher and replacing direct comparisons of input data to magic bytes by hash operations, symbolic, concolic, and taint-based execution engines are significantly slowed down and hampered in their abilities to construct valid inputs. As explained above, the use case for ANTIFUZZ is a developer who has access to source code and wants to protect his application from attackers who use automatic bug finding tools to find bugs cost-effectively. For our experiments, we analyzed the time it took us to apply ANTIFUZZ to LAVA-M (which consists of the four programs base64, md5sum, uniq, and who). The core idea here is to use every byte of the input file in a way that could lead to a new basic block, e.g., by making it depend on some constraints or by comparing it to randomly generated constants. Depending on the configurable number of constraints and the size of the input file, every byte could be part of multiple constraints and constant comparisons.Implementation-wise, although it is possible to generate code for ANTIFUZZ dynamically at runtime, this might cause problems for fuzzers relying on static code instrumentation (i.e., they might not be able to "see" code introduced by ANTI-FUZZ). This behavior could also be replaced by an exit or by calling additional functions that lead to fake code coverage to keep up a facade of a working fuzzer.In the case of ptrace, we use a well-known anti-debugging technique [34] to detect if we are being observed by ptrace: we check whether we can ptrace our own process. Most applications already have some kind of error handling for malformed input, which either discards the input or terminates the application. There are two main parts to our countermeasures against symbolic/concolic execution and taint analysis engines: replacing constant comparisons with comparisons of their respective cryptographic hashes, and putting the input through a cryptographic block cipher before usage.The first part is implemented via the SHA-512 hash function. Additional layers of fake edges and constraints are specifically targeting coverage-guided fuzzers. This step basically is the anti-crash detection implementation of ANTIFUZZ, which works together with an execution delay mechanism. , we demonstrate that modifying a custom dummy application (which is illustrated in Listing 2) using the state-of-the-art obfuscation tool TIGRESS [15] does not yield a satisfying level of protection against current fuzzers.Following the answer to RQ 1. to evaluate eight fuzzers and bug-finding tools, namely: AFL 2.52b, VUZZER, HONGGFUZZ 1.6, DRILLER commit 66a3428, ZZUF 0.15, PEACH 3.1.124, and QSYM commit d4bf407. , we test a subset of these fuzzers against the LAVA-M dataset to demonstrate that ANTIFUZZ is able to prevent bug finding in real-world applications. • Delaying Execution: The signal handler introduces a slowdown in case of a crash to timeout the application (in addition to slowdowns due to malformed inputs). • Overloading Symbolic Execution Engines: Important comparisons for equivalence were replaced with SHA-512 hash comparisons and the input data was encrypted and decrypted via AES-256 in ECB mode.If the fuzzer supported both binary instrumentation and compile-time instrumentation, we used the compile-time instrumentation. Thus, obfuscating the control flow via common techniques such as control flow flattening or virtual machine based obfuscation [21] might impact coverage-guided fuzzers.Experiment To demonstrate that obfuscation techniques alone do not protect an application from automatic bug finding tools, we obfuscated a dummy application (see Listing 2) with TIGRESS 2.2 [15] and let different fuzzers find the correct crashing input. The exact configuration is shown in Table 1 of Appendix A.Result This experiment revealed that all fuzzers could find the crashing input despite all obfuscation techniques being enabled. (1) If a fuzzer is unable to find this very shallow bug, they will most likely also fail to find more complex crashes, and (2) the code is simple enough to be adjusted to different systems and fuzzers (e.g., DRILLER needs CGC binaries). Any input that is not the crashing input is deemed to be malformed, i.e., ANTIFUZZ decides to slow down the application in that case. Similarly, PEACH was evaluated on an ELF64 parser means ANTIFUZZ was successful in preventing bug finding (no crash was found) and means that at least one crashing input was found. None means ANTIFUZZ was disabled, All means that all techniques against fuzzers (Coverage, Crash, Speed and Symbolic Execution) were turned on. Comparing this table to Table 1 shows that our techniques clearly address the fundamental assumptions that fuzzers use to find bugs.All coverage-guided fuzzers were impeded by our anticoverage feature. ZZUF was able to crash the target because there were only 256 different inputs to try.As expected, KLEE was not able to find the correct input once countermeasures against symbolic execution were activated. means ANTIFUZZ was successful in preventing bug finding (no crash was found) and means that at least one crashing input was found, the # sign denotes the number of unique crashes found. For blind fuzzers like ZZUF, solving four bytes is too hard, thus one constraint was reduced to a single bit-flip for this fuzzer alone.Results Table 4 shows our result. In summary, these results demonstrate that our anti-fuzzing features are applicable to real-world binaries to prevent bug finding. More specifically, we evaluated AFL, HONGG-FUZZ, VUZZER, and QSYM against eight real-world binaries from the binutils collection (namely addr2line, ar, size, strings, objdump, readelf, nm-new, strip-new). Two of the insignificant results are from VUZZER, which displayed rather low coverage scores even without ANTIFUZZ enabled. The 95th percentile of coverage was less than 13% of the code that the fuzzers found when targeting an unprotected program. The remaining benchmarks ran for three iterations each and were averaged over ten runs with the geometric mean.Result The impact of ANTIFUZZ for each benchmark was insignificant enough to bear little to no observable overhead (see Table 5): most applications show small negative overheads (with the outlier being gcc with -3.80%), but the positive overheads also never reach 1%. Reading the file to memory and checking if the input data is well-formed usually happens only once in the beginning, thus it does not impact the computationally intensive main part of the benchmarks at all. Moreover, many other works have detailed techniques to prevent modification and human analysis using software obfuscation techniques [16,17,21,24,41,43,53]. In particular, we require the developer to perform the following tasks: (a) find error paths, (b) replace constant comparisons, and (c) annotate functions which read user input or data. We assume that using our prototype AES implementation to encrypt and decrypt every input significantly increases the overhead on I/O bound tasks. Therefore, tools like ANTIFUZZ can never completely guarantee that they can defeat a motivated human analyst. The control flow can be further cloaked by creating many seemingly dissimilar paths that are picked randomly [43] to thwart dynamic analysis based approaches. This approach has the advantage that it works against many different kinds of attack scenarios. Additionally, fuzzers generally tend to find many hundreds to thousands of crashes for each real bug uncovered. Adding some more crashes does not prevent the fuzzer from finding real bugs. In contrast, our techniques effectively prevent fuzzers from finding crashing inputs in simple programs, even if the crash was found in seconds in an unprotected application. Furthermore, we demonstrated that we get the same result for real-world applications, i.e., fuzzers are unable to detect any crashes or even achieve a significant amount of new code coverage. We would like to thank our shepherd Mathias Payer and the anonymous reviewers for their valuable comments and suggestions. The Research Executive Agency is not responsible for any use that may be made of the information it contains.