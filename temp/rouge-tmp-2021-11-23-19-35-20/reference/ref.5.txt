In this work, we develop sybilhunter, a system for detecting Sybil relays based on their appearance, such as configuration ; and behavior, such as uptime sequences. Our work shows that existing Sybil defenses do not apply to Tor, it delivers insights into real-world attacks, and provides practical tools to uncover and characterize Sybils, making the network safer for its users. As the attacker's consensus weight grows, the following attacks become easier.Exit traffic tampering: When leaving the Tor network, a Tor user's traffic traverses exit relays, the last hop in a Tor circuit. End-to-end correlation: By running both entry guards and exit relays, an attacker can use timing analysis to link a Tor user's identity to her activity, e.g., learn that Alice is visiting Facebook. In Section 5.1, we provide evidence for what appears to be botnets whose zombies are running Tor relays, perhaps because of a misguided attempt to help the Tor network grow.Motivated by the lack of practical Sybil detection tools, we design and implement heuristics, leveraging our observations that Sybils (i) frequently go online and offline simultaneously, (ii) share similarities in their configuration, and (iii) may change their identity fingerprint-a relay's fingerprint is the hash over its public key-frequently, to manipulate Tor's DHT. Other heuristics produced a large number of results, and seem well-suited to spot the "low hanging fruit." 2 We find that Sybils run MitM attacks, DoS attacks, and are used for research projects.The rest of this paper is structured as follows. 2 The datasets are available online at https://nymity.ch/sybilhunting/. In addition, a major factor contributing to Tor's network growth is the low barrier of entry, allowing operators to set up relays both quickly and anonymously. 3 Note that we could create such a relationship by, e.g., linking relays to their operator's social networking account, or by creating a "relay operator web of trust," but again, we believe that such an effort would alienate relay operators and see limited adoption.Orthogonal to social constraints, computational resource constraints guarantee that an attacker seeking to operate 100 Sybils needs 100 times the computational resources she would have needed for a single virtual identity. Computational constraints are inherently tied to running a relay.In summary, we believe that existing Sybil defenses are ill-suited for application in the Tor network; its distinctive features call for customized solutions that con-sider the nature of Tor relays. First, directory authorities-the "gatekeepers" of the Tor network-accept at most two relays per IP address to prevent low-resource Sybil attacks [3,2]. The Tor Project has recently increased the minimal time until relays obtain the Stable flag (seven days) and the HSDir flag (96 hours). This change increases the cost of Sybil attacks and gives Tor developers more time to discover and block suspicious relays before they get in a position to run an attack. Guard: Guard relays are the rarely-changing first hop for Tor clients. Running: A relay is running if the directory authorities could connect to it in the last 45 minutes.Tor relays are uniquely identified by their fingerprint, a Base32-encoded and truncated SHA-1 hash over their public key. Such Sybils are no threat to the Tor network, which is why we refer to them as benign Sybils.What we are interested in is malicious Sybils whose purpose is to deanonymize or otherwise harm Tor users.To uncover malicious Sybils, we draw on two datasets-one publicly available and one created by us. Archived consensuses and router descriptors (in short: descriptors) allow us to (i) restore past states of the Tor network, which sybilhunter mines for Sybil groups, and to (ii) find "partners in crime" of malicious exit relays that we discovered by running exitmap, a scanner for Tor exit relays that we discuss below. Therefore, relays can spoof information such as their operating system, Tor version, and uptime.Consensuses Each hour, the nine directory authorities vote on their view of all Tor relays that are currently online. As of June 2016, consensuses contain approximately 7,000 router statuses, i.e., each hour, 7,000 router statuses are published, and archived, by CollecTor. We add these relays to our dataset because they frequently surface in groups, as malicious Sybils, because an attacker runs the same attack on several, physically distinct exit relays. We also seek to find potential "partners in crime" of each newly discovered malicious relay, which we discuss in Section 4.3.4. Our primary concern is protecting Tor users from harm, and we do not need to identify the culprit to do so.In addition to using the original exitmap modules [37, § 3.1], we implemented modules that detect HTML and HTTP tampering by connecting to a decoy server under our control, and flagging an exit relay as malicious if the returned HTML or HTTP was modified, e.g., to inject data or redirect a user over a transparent HTTP proxy. Our modules ran periodically from August 2014 to January 2016, and discovered 251 malicious exit relays whose attacks are discussed in Appendix A. Shared configuration parameters such as port numbers and nicknames cause similar appearance whereas Sybils behave similarly when they reboot simultaneously, or exhibit identical quirks when relaying traffic.Sybilhunter can analyze (i) historical network data, dating back to 2007; (ii) online data, to detect new Sybils as they join the network; and (iii) find relays that might be associated with previously discovered, malicious relays. Depending on the analysis technique, sybilhunter's output is either CSV files or images.While developing sybilhunter, we had to make many design decisions that we tackled by drawing on the experience we gained by manually analyzing numerous Sybil groups. We iteratively improved our code and augmented it with new features when we experienced operational shortcomings. An unexpectedly high churn rate between two subsequent consensuses means that many relays joined or left, which can reveal Sybils and other network issues because many Sybil operators start and stop their Sybils at the same time, to ease administration-they behave similarly.The Tor Project is maintaining a Python script [15] that determines the number of previously unobserved relay fingerprints in new consensuses. These are mere examples, however; the shape of a time series cannot tell us anything about the nature of the underlying incident.To quantify the churn rate α between two subsequent consensus documents, we adapt Godfrey et al.'s formula, which yields a churn value that captures both systems that joined and systems that left the network [13, § 2.1]. To address this issue, we split the formula in two parts, creating a time series for new relays (α n ) and for relays that left (α l ). (1)Both α n and α l are bounded to the interval [0,1]. 4 We found that many churn anomalies are caused by relays that share a flag, or a flag combination, e.g., HSDir (onion service directories) and Exit (exit relays). To fill this gap, we complement the churn analysis with an uptime matrix that we will now present.This uptime matrix consists of the uptime patterns of all Tor relays, which we represent as binary sequences. Each hour, when a new consensus is published, we add a new data point-"online" or "offline"-to each Tor relay's sequence. We visualize all sequences in a bitmap whose rows represent consensuses and whose columns Figure 7: The uptime matrix for 3,000 Tor relays for all of November 2012. This type of visualization was first proposed by Ensafi and subsequently implemented by Fifield [12]. We sort sequences using single-linkage clustering, a type of hierarchical clustering algorithm that forms groups bottomup, based on the minimum distance between group members. A coefficient of −1 denotes perfect anti-correlation (relay R 1 is only online when relay R 2 is offline) and 1 denotes perfect correlation (relay R 1 is only online when relay R 2 is online). Attackers can exploit the ability to predict the DHT position by repeatedly generating identity keys until their fingerprint is sufficiently close to the targeted onion service's index, thus becoming its HSDir [4, § V.A]. Our algorithm ranks relays by comparing these configuration parameters.To quantify the similarity between two relays, we use the Levenshtein distance [18], a distance metric that takes as input two strings and determines the minimum number of modifications-insert, delete, and modifythat are necessary to turn string s 2 into s 1 . To turn string s 2 into s 1 , six operations are necessary; four modifications (green) and two deletions (red):s 1 : Foo10.0.0.19001 s 2 : Bar10.0.0.2549001Our algorithm determines the Levenshtein distance between a "seed" relay and all other relays in a consensus. We did not set any thresholds, to capture every single churn value, fingerprint, and uptime sequence, resulting in an unfiltered dataset of several megabytes of CSV files and uptime images. Instead of providing an exhaustive list of all potential Sybils, we focus on our most salient findings-relay groups that were either clearly malicious or distinguished themselves otherwise. The columns show (i) what we believe to be the purpose of the Sybils, (ii) when the Sybil group was at its peak size, (iii) the ID we gave the Sybils, (iv) the number of Sybil fingerprints at its peak, (v) the analysis techniques that could discover the Sybils, and (vi) a short description. The analysis techniques are abbreviated as "N" (Neighbor ranking), "F" (Fingerprint), "C" (Churn), "U" (Uptime), and "E" (exitmap). For the seven-digit prefix above, this results in 2 5·7−1 = 2 34 operations. On this GPU, a partial collision for a seven-digit prefix can be found in 2 34 · 1 90,000,000 񮽙 190 seconds, i.e., just over three minutes.We inspected some of the phishing domains and found that the attackers further replaced the original Bitcoin addresses with addresses that are presumably controlled by the attackers, enabling them to hijack Bitcoin transactions. In fact, we cannot rule out that the adversary was upstream of the exit relay, or gained control over these relays.The "FDCservers" Sybils Attackers used these Sybils to deanonymize onion service users, as discussed by The Tor Project in a July 2014 blog post [8]. Sup- posedly, CMU/SEI-affiliated researchers were executing a traffic confirmation attack by sending sequences of RELAY _ EARLY and RELAY cells as a signal down the circuit to the client, which the reference implementation never does [8,7]. For October 2015, we found "default" relays in 73 countries, with the top three countries being Germany (50%), Russia (8%), and Austria (7%). The majority of these relays had little uptime and exhibited a diurnal pattern, suggesting that they were powered off regularly-as it often is the case for desktop computers and laptops.To get a better understanding of the number of "default" relays over time, we analyzed all consensuses, extracting the number of relays whose nickname was "default," whose onion routing port was 443, and whose directory port was 9030. After that, only 1-3 relays remained in the consensus.The "Amazon EC2" Sybils The relays all used randomly-generated nicknames, consisting of sixteen or seventeen letters and numbers; Tor in version 0.2.2.37; GNU/Linux; and IP addresses in Amazon's EC2 netblock. This behavior appears to be a clear attempt to manipulate Tor's DHT.We believe that this Sybil group was run by Biryukov, Pustogarov, and Weinmann as part of their Security and Privacy 2013 paper "Trawling for Tor Hidden Services" [4]-one of the few Sybil groups that were likely run by academic researchers.The "Anonpoke" Sybils All relays shared the nickname "Anonpoke" and were online for four hours until they were rejected. The relays advertized the default bandwidth of 1 GiB/s on port 9001 and 9030. The majority of machines were middle relays (96%), but the attackers also started some exit relays (4%). If all relays would have obtained the HSDir flag, they would have constituted almost 50% of all onion service directories; the median number of onion service directories on December 26 was 3,551. For the fingerprint method, we raised an alert if a relay changed its fingerprint at least ten times per month, and for uptime visualizations we raised an alert if at least five relays exhibited an identical uptime sequence. Unsurprisingly, relays with the Guard, HSDir, and Stable flag experience the least churn, probably because relays are only awarded these flags if they are particularly stable. Interestingly, the median churn rate of the network has steadily decreased over the years, from 0.04 in 2008 to 0.02 in 2015. Analysis We generated relay uptime visualizations for each month since 2007, resulting in 100 images. The Sybils belonged to a researcher who, as documented by The Tor Project [20], started several hundred Tor relays on PlanetLab for research on scalability (the "PlanetLab" Sybils discussed above). The relays appeared in December 2011, and started exhibiting the diurnal step pattern (nine hours uptime followed by fifteen hours downtime) in March 2012. Figure 14 illustrates the largest Sybil group to date, comprising 4,615 Tor relays (the "LizardNSA" Sybils discussed above). Figure 15 further contains a peculiar plateau, shown in the shaded area between index 707 and 803. We also found that many IP addresses in the netblock 199.254.238.0/24 frequently changed their fingerprint. In addition, the number of Sybils we found is only a lower bound-we are unlikely to have detected all Sybil groups. We chose the bad exit Sybils because we observed them running identical, active attacks, which makes us confident that they are in fact Sybils. Ideally, all neighbors are family members, but the use of relay families as ground truth is very likely to overestimate results because family operators frequently configure their relays identically on purpose. At the time of this writing, a popular relay family has the nicknames "AccessNow000" to "AccessNow009," adjacent IP addresses, and identical contact information-perfect prerequisites for our algorithm. Not a single ranking had perfect accuracy and 59% of all rankings had an accuracy in the interval [0.3, 0.6]. Nevertheless, we find that our algorithm facilitates manual analysis given how quickly it can provide us with a list of the most similar relays. Network churn calculation is very fast; it takes as input only two consensus files and can easily be run for every new network consensus. Our practical work with sybilhunter taught us that analyzing Sybils frequently requires manual verification, e.g., (i) comparing an emerging Sybil group with a previously disclosed one, (ii) using exitmap to send decoy traffic over Sybils, or (iii) sorting and comparing information in relay descriptors. Our detection techniques and code are freely available while our adversaries operate behind closed doors, creating an uphill battle that is difficult to sustain given our limited resources. Instead, we are proposing to add a layer of obscurity on top of existing defense layers.We are working with The Tor Project on incorporating our techniques in Tor Metrics [33], a website containing network visualizations that are frequented by numerous volunteers. In Section 4.2, we argued that we are unable to expose all Sybil attacks, so our results represent a lower bound. Indeed, Table 2 contains six Sybil groups that sybilhunter was unable to detect. For example, Sybils that are (i) operated in "bulletproof" autonomous systems [17, § 2], (ii) show signs of not running the Tor reference implementation, or (iii) spoof information in their router descriptor all suggest malicious intent. In the end, Sybil groups have to be evaluated case by case, and the advantages and disadvantages of blocking them have to be considered.Finally, there is significant room for improving our nearest neighbor ranking. Given the lack of a central identity-verifying authority, it is always possible for well-executed Sybil attacks to stay under our radar, but we found that a complementary set of techniques can go a long way towards finding malicious Sybils, making the Tor network more secure and trustworthy for its users.All our code, data, visualizations, and an open access bibliography of our references are available online at https://nymity.ch/sybilhunting/. We also want to thank Georg Koppen, Prateek Mittal, Stefan Lindskog, the Tor developers, and the wider Tor community for helpful feedback. The system presented by Ling et al. behaves the same [23]; the authors proposed to run intrusion detection systems on Tor traffic by setting up an exit relay that runs an NIDS system, and routes the traffic back into the Tor network after having inspected the traffic.Oct 2014 1 The relay injected JavaScript into returned HTML. 1 The relay used OpenDNS as DNS resolver and had the website category "proxy/anonymizer" blocked, resulting in several inaccessible websites, including torproject.org. The impersonation domain looked identical to the original, but had different Bitcoin addresses. We believe that this was attempt to trick Tor users into sending Bitcoin transactions to phishing addresses. The system presented by Ling et al. behaves the same [23]; the authors proposed to run intrusion detection systems on Tor traffic by setting up an exit relay that runs an NIDS system, and routes the traffic back into the Tor network after having inspected the traffic.Oct 2014 1 The relay injected JavaScript into returned HTML. The impersonation domain looked identical to the original, but had different Bitcoin addresses. We believe that Sybil groups marked with an * , †, and ‡ were run by the same adversary.