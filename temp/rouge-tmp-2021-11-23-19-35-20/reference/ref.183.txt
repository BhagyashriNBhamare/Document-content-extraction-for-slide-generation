Research on transient execution attacks including Spectre and Meltdown showed that exception or branch mispredic-tion events might leave secret-dependent traces in the CPU's microarchitectural state. Our systematization uncovers 6 (new) transient execution attacks that have been overlooked and not been investigated so far: 2 new exploitable Meltdown effects: Meltdown-PK (Protection Key Bypass) on Intel, and Meltdown-BND (Bounds Check Bypass) on Intel and AMD; and 4 new Spectre mistraining strategies. Modern CPU pipelines are massively parallelized allowing hardware logic in prior pipeline stages to perform operations for subsequent instructions ahead of time or even out-of-order. Pipeline flushes may occur even without prediction mechanisms, as on modern CPUs virtually any instruction can raise a fault (e.g., page fault or general protection fault), requiring a roll-back of all operations following the faulting instruction. These attacks exploit transient execution to encode secrets through microarchitectural side effects (e.g., cache state) that can later be recovered by an attacker at the architectural level. We also debunk implicit assumptions including that AMD or the latest Intel CPUs are completely immune to Meltdown-type effects, or that serializing instructions mitigate Spectre Variant 1 on any CPU.In this paper, we present a systematization of transient execution attacks, i.e., Spectre, Meltdown, Foreshadow, and related attacks. The hierarchical and extensible nature of our taxonomy allows to easily identify residual attack surface, leading to 6 previously overlooked transient execution attacks (Spectre and Meltdown variants) first described in this work. Two of the attacks are Meltdown-BND, exploiting a Meltdown-type effect on the x86 bound instruction on Intel and AMD, and Meltdown-PK, exploiting a Meltdown-type effect on memory protection keys on Intel. The contributions of this work are: and classify gadgets in Section 5 and defenses in Section 6. The microarchitecture then describes how the ISA is implemented in a processor in the form of pipeline depth, interconnection of elements, execution units, cache, branch prediction. The microarchitectural state includes, for instance, entries in the cache and the translation lookaside buffer (TLB), or the usage of the execution units. This allows the CPU to execute µOPs not only in the sequential order provided by the instruction stream but to dispatch them in parallel, utilizing the CPU's execution units as much as possible and, thus, improving the overall performance. The CPU takes care to retire µOPs in-order, deciding to either discard their results or commit them to the architectural state. Therefore, the CPU may have executed so-called transient instructions [56], whose results are never committed to the architectural state. In particular, Flush+Reload allows observations across cores at cache-line granularity, enabling attacks, e.g., on cryptographic algorithms [26,43,92], user input [24,55,72], and kernel addressing information [23]. If the victim used the cache line, accessing it will be fast; otherwise, it will be slow.Covert channels are a special use case of side-channel attacks, where the attacker controls both the sender and the receiver. This can be any instruction that causes subsequent operations to be eventually squashed, e.g., due to an exception or a mispredicted branch or data dependency. However, in the final phase of the attack, unauthorized transient computation results are recovered at the receiving end of the covert channel, e.g., by timing memory accesses to deduce the secret-dependent loads from the transient instructions. Where the former relies on dedicated control or data flow prediction machinery, the latter merely exploits that data from a faulting instruction is forwarded to instructions ahead Table 1: Spectre-type attacks and the microarchitectural element they exploit ( ), partially target ( ), or not affect ( ). Attack Element BTB BHB PHT RSB STLSpectre-PHT (Variant 1) [50] Spectre-PHT (Variant 1.1) [48] Spectre-BTB (Variant 2) [50] Spectre-RSB (ret2spec) [52,59] Spectre-STL (Variant 4) [29] Glossary: Branch Target Buffer (BTB), Branch History Buffer (BHB), Pattern History Table (PHT), Return Stack Buffer (RSB), Store To Load (STL). Essentially, the different root cause of the trigger instruction (Spectre-type misprediction vs. Meltdown-type fault) determines the nature of the subsequent unauthorized transient computations and hence the scope of the attack.That is, in the case of Spectre, transient instructions can only compute on data which the application is also allowed to access architecturally. Spectre thus transiently bypasses software-defined security policies (e.g., bounds checking, function call/return abstractions, memory stores) to leak secrets out of the program's intended code/data paths. in-place/ same-addressspace out-of-place/ same-addressspace Victim branch Congruent branch Figure 3: A branch can be mistrained either by the victim process (same-address-space) or by an attacker-controlled process (cross-address-space). As the first level of our classification tree, we categorize Spectre attacks based on the microarchitectural root cause that triggers the misprediction leading to the transient execution:• Spectre-PHT [48,50] exploits the Pattern History Table (PHT) that predicts the outcome of conditional branches. We now propose a second-level classification scheme for Spectre variants that abuse history-based branch prediction (i.e., all of the above except Spectre-STL). Since branch prediction buffers in modern CPUs [19,50] are com-monly indexed based on the virtual address of the branch instruction, mistraining can happen either within the same address space or from a different attacker-controlled process. We thus enhance the field of Spectre-type branch poisoning attacks with 4 distinct mistraining strategies: 1. Executing a congruent branch in the victim process (sameaddress-space out-of-place). Kocher et al. [50] first introduced Spectre Variant 1, an attack that poisons the Pattern History Table (PHT) to mispredict the direction (taken or not-taken) of conditional branches. The above code snippet features an explicit example of a "leak gadget" that may act as a microarchitectural covert channel: depending on the out-of-bounds value being read, the transient Table 2: Spectre-type attacks performed in-place, out-of-place, same-address-space (i.e., intra-process), or cross-addressspace (i.e., cross-process). S p e c t r e -P H T S p e c t r e -B T B S p e c t r e -R S B S p e c t r e -S T L Intel intra-process in-place [48,50] [59][29] out-of-place[13] [52,59] cross-process in-place [13,50] [52, 59] out-of-place [50] [52]ARM intra-process in-place [48,50] [6][6] out-of-place [6] cross-process in-place [6,50] out-of-place AMD intra-process in-place [50] [29] out-of-place cross-process in-place [50] out-of-placeSymbols indicate whether an attack is possible and known ( ), not possible and known ( ), possible and previously unknown or not shown ( ), or tested and did not work and previously unknown or not shown ( ). Consider the following code line:if (x < len(array)) { array[x] = value; }After mistraining the PHT component, attackers controlling the untrusted index x can transiently write to arbitrary outof-bounds addresses. This effectively rules out current state-of-the-art SGXSpectre [63] attacks that repeatedly execute the victim enclave to mistrain the PHT branch predictor. Our novel outof-place PHT poisoning strategy, on the other hand, allows us to perform the training phase entirely outside the enclave on the same physical core by repeatedly executing a congruent branch in the untrusted enclave host process (cf. Figure 3). Adopting established techniques from return-oriented programming (ROP) attacks [75], but abusing BTB poisoning instead of application-level vulnerabilities, selected code "gadgets" found in the victim address space may be chained together to construct arbitrary transient instruction sequences. Spectre-BTB was initially demonstrated on Intel, AMD, and ARM CPUs using a cross-address-space in-place mistraining strategy [50]. Much like Spectre-PHT, such same-address-space in-place BTB (Spectre-BTB-SA-IP) poisoning abuses the victim's own execution to mistrain the underlying branch target predictor. Since the branch destination address is now determined by the victim code and not under the direct control of the attacker, however, Spectre-BTB-SA-IP cannot offer the full power of arbitrary transient control flow redirection. Maisuradze and Rossow [59] and Koruyeh et al. [52] introduced a Spectre variant that exploits the Return Stack Buffer (RSB). Furthermore, same-address-space adversaries may explicitly overwrite return addresses on the software stack, or transiently execute call instructions which update the RSB without committing architectural effects [52]. Starting from Skylake, Intel CPUs use the BTB as a fallback [19,52], thus allowing Spectre-BTB-style attacks triggered by ret instructions. Furthermore, in line with ARM's own analysis [6], we successfully poisoned RSB entries within the same-address-space but did not observe any cross-address-space leakage on ARM CPUs. However, even before the addresses of all prior stores in the pipeline are known, the CPUs' memory disambiguator [3,33,44] may predict which loads can already be executed speculatively.When the disambiguator predicts that a load does not have a dependency on a prior store, the load reads data from the L1 data cache. Like previous attacks, Spectre-STL adversaries rely on an appropriate transient instruction sequence to leak unsanitized stale values via a microarchitectural covert channel. The CPU's in-order instruction retirement mechanism takes care to discard any architectural effects of such computations, but as with the Spectre-type attacks above, secrets may leak through microarchitectural covert channels. Leaks M e m o r y C a c h e R e g i s t e r C r o s s -C P L Meltdown-US (Meltdown) [56] Meltdown-P (Foreshadow-NG) [90] Meltdown-P (Foreshadow-SGX) [85] Meltdown-GP (Variant 3a) [8] Meltdown-NM (Lazy FP) [78] Meltdown-RW (Variant 1.2) [48] Meltdown-PK Meltdown-BR Symbols indicate whether an attack crosses a processor privilege level () or not (), whether it can leak secrets from a buffer ( ), only with additional steps ( ), or not at all ( ). Through this systematization, we discovered several previously unknown Meltdown variants that exploit different exception types as well as page-table protection bits, including two exploitable ones. The original Meltdown attack [56] reads kernel memory from user space on CPUs that do not transiently enforce the user/supervisor flag. While extraction rates are significantly higher when the kernel data resides in the CPU cache, Meltdown has even been shown to successfully extract uncached data from memory [56]. Van Bulck et al. [85] presented Foreshadow, a Meltdown-type attack targeting Intel SGX technology [30]. Any data present in L1 and tagged with that physical address will now be forwarded to the transient execution, regardless of access permissions.Although Meltdown-P-type leakage is restricted to the L1 data cache, the original Foreshadow [85] attack showed how SGX's secure page swapping mechanism might first be abused to prefetch arbitrary enclave pages into the L1 cache, including even CPU registers stored on interrupt. However, if this offset is a valid physical address, any cached memory at that location leaks to an unprivileged Foreshadow-OS attacker.Even worse is the Foreshadow-VMM variant, which allows an untrusted virtual machine, controlling guest-physical addresses, to extract the host machine's entire L1 data cache (including data belonging to the hypervisor or other virtual machines). Similar to previous Meltdown-type attacks, however, the attack exploits that the transient execution following the faulting instruction can still compute on the unauthorized data, and leak the system register contents through a microarchitectural covert channel (e.g., Flush+Reload). The first FPU instruction issued after the FPU was marked as "not available" causes a device-not-available (#NM) exception, allowing the OS to save the FPU state of previous execution context before marking the FPU as available again.Stecklina and Prescher [78] propose an attack on the above lazy state switch mechanism. As such, analogous to previous Meltdown-type attacks, a malicious transient instruction sequence following the faulting instruction can encode the unauthorized FPU register contents through a microarchitectural covert channel (e.g., Flush+ Reload). The ability to transiently overwrite read-only data within the current privilege level can bypass software-based sandboxes which rely on hardware enforcement of read-only memory.Confusingly, the above Meltdown-RW attack was originally named "Spectre Variant 1.2" [48] as the authors followed a Spectre-centric naming scheme. Meltdown-PK works if an attacker has code execution in the containing process, even if the attacker cannot execute the wrpkru instruction (e.g., blacklisting). According to Intel [36], Meltdown-PK can be mitigated using address space isolation. Specifically, Intel's analysis [40] only briefly mentions MPX-based bounds check bypass as a possibility, and M D -N M [ 7 8 ] M D -R W [ 4 8 ] M D -P K M D -B R M D -D E M D -A C M D -U D M D -S S M D -X D M D -S M Intel ARM AMDSymbols indicate whether at least one CPU model is vulnerable (filled) vs. no CPU is known to be vulnerable (empty). All tests performed without defenses enabled.recent defensive work by Dong et al. [16] highlights the need to introduce a memory lfence after MPX bounds check instructions. According to Oleksenko et al. [64], neither bndcl nor bndcu exert pressure on the branch predictor, indicating that there is no prediction happening. Similar to Spectre-PHT, Meltdown-BR is a bounds check bypass, but instead of mistraining a predictor it exploits the lazy handling of the raised #BR exception. This is the first experiment demonstrating a Meltdown-type transient execution attack exploiting delayed exception handling on AMD CPUs [4,56]. In our experiments, we consistently found no traces of transient execution beyond traps or aborts, which leads us to the hypothesis that Meltdown is only possible with faults (as they can occur at any moment during instruction execution). Thus, according to our experiments Meltdown-DE is not possible, as no real values are leaked.Supervisor Access. Although supervisor mode access prevention (SMAP) raises a page fault (#PF) when accessing user-space memory from the kernel, it seems to be free of any Meltdown effect in our experiments. On our test systems, we did not succeed in transiently executing instructions residing in non-executable memory (i.e., Meltdown-XD), or following an invalid opcode (#UD) exception (i.e., Meltdown-UD). We deliberately oriented our attack tree (cf. Figure 1) on the microarchitectural root causes of the transient computation, abstracting away from the underlying covert channel and/or code gadgets required to carry out the attack successfully. For sandboxed adversaries (e.g., Spectre-PHT [50]), on the other hand, much of the gadget functionality has to be provided by "confused deputy" code executing in the victim domain. Using a contention channel like execution unit contention [2,9] or an AVX channel as claimed by Schwarz et al. [74], an attacker might be able to leak data. Guarnieri et al. [25] mention that oo7 would still flag code locations that were patched with Speculative Load Hardening [12] as it would still match the vulnerable pattern.Another approach, called Spectector [25], uses symbolic execution to detect Spectre-PHT gadgets. According to Carpenter [10], the tool reported 736 gadget candidates in April 2018, whereas the kernel only featured about 15 Spectre-PHT-resistant array indices at that time. This provides further evidence that patching Spectre-PHT gadgets in real-world software is an ongoing effort and that automated detection methods and gadget classification pose an important research challenge. Likewise, Chen et al. [13] analyzed various trusted enclave runtimes for Intel SGX and found several instances of vulnerable branches with attacker-controlled input registers, plus numerous exploitable gadgets to which transient control flow may be directed to leak unauthorized enclave memory. Our analysis also shows that more dangerous gadgets that either allow more than 1-bit leakage or even arbitrary code execution are not frequently occurring. Second, we consider Meltdown and Spectre as two problems with different root causes, leading to a A defense considers the microarchitectural element ( ), partially considers it or same technique possible for it ( ) or does not consider it at all ( ). While their prototype implementation protects only caches (and the TLB), other channels, e.g., DRAM buffers [69], or execution unit congestion [1,9,56], remain open.Yan et al. [91] proposed InvisiSpec, a method to make transient loads invisible in the cache hierarchy. Many covert channels require an accurate timer to distinguish microarchitectural states, e.g., measuring the memory access latency to distinguish between a cache hit and cache miss. C2: Mitigating or aborting speculation if data is potentially accessible during transient execution.Since Spectre-type attacks exploit different prediction mechanisms used for speculative execution, an effective approach would be to disable speculative execution entirely [50,79]. Furthermore, new system registers allow to restrict speculative execution and new prediction control instructions prevent control flow predictions (cfp), data value prediction (dvp) or cache prefetch prediction (cpp) [7]. To mitigate Spectre-STL, ARM introduced a new barrier called SSBB that prevents a load following the barrier from bypassing a store using the same virtual address before it [6]. This, for instance, includes powering up the AVX functional units, instruction cache fills, and iTLB fills which still leak data.Evtyushkin et al. [18] propose a similar method to serializing instructions, where a developer annotates potentially leaking branches. In that case, the attack would still be possible.Google proposes a method called retpoline [83], a code sequence that replaces indirect branches with return instructions, to prevent branch poisoning. To mitigate this possibility, future CPUs also implement hardware defenses for Spectre-BTB called enhanced IBRS [39]. The more significant impact of this approach is that mispredictions on the branch instruction used for type checks results in the wrong type being used for the pointer.Google proposes another defense called site isolation [81], which is now enabled in Chrome by default. These approaches aim to keep architecturally inaccessible data also inaccessible at the microarchitectural level.Gruss et al. originally proposed KAISER [22,23] to mitigate side-channel attacks defeating KASLR. In the case of the former, Intel suggests placing 4 KB of dummy data at the start of the physical address space, and clearing the PS bit in page tables to prevent attackers from exploiting huge pages.For SGX enclaves or hypervisors, which cannot trust the address translation performed by an untrusted OS, Intel proposes to either store secrets in uncacheable memory (as specified in the PAT or the MTRRs), or flush the L1 data cache when switching protection domains. However, the Foreshadow [85] attack showed that it is possible to actively provoke another fault by unmapping the enclave page, making SGX enclaves susceptible to the Meltdown-P variant.Preventing the fault is also the countermeasure for Meltdown-NM [78] that is deployed since Linux 4.6 [57]. Several defenses only consider a specific covert channel (see Table 9), i.e., they only try to prevent an attacker from recovering the data using a specific covert channel instead of targeting the root cause of the vulnerability. Taint tracking theoretically mitigates all forms of Spectretype attacks as data that has been tainted cannot be used in a transient execution. On an i5-6200U (Skylake), an i7-8700K (Coffee Lake), and an i7-8565U (Whiskey Lake), we were able to successfully run a Meltdown-MPX, Meltdown-BND, and Meltdown-RW attack. To show the overall decrease on a Linux 4.19 kernel with the default mitigations enabled, Larabel [54] performed multiple benchmarks to determine the impact. KAISER/KPTI [21] 0-2.6 % System call rates Retpoline [11] 5-10 % Real-world workload servers Site Isolation [81] 10-13 % Memory overhead InvisiSpec [91] 22 % SPEC SafeSpec [45] -3 % SPEC on MARSSx86 DAWG [47] 1-15 % PARSEC , GAPBS SLH [12] 29-36.4 % Google microbenchmark suite YSNB [65] 60 % Phoenix IBRS [82] 20-30 % Sysbench 1.0.11 STIBP [53] 30-50 % Rodinia OpenMP, DaCapo Serialization [12] 62-74.8 % Google microbenchmark suite SSBD/SSBB [15] 2-8 % SYSmark 2018, SPEC integer L1TF Mitigations [38] -3-31 % SPEC data centers, it is harder as it depends on the needs of their customers and one has to evaluate this on an individual basis. We want to thank the anonymous reviewers and especially our shepherd, Jonathan McCune, for their helpful comments and suggestions that substantially helped in improving the paper.This work has been supported by the Austrian Research Promotion Agency (FFG) via the K-project DeSSnet, which is funded in the context of COMET -Competence Centers for Excellent Technologies by BMVIT, BMWFW, Styria and Carinthia. This project has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement No 681402).