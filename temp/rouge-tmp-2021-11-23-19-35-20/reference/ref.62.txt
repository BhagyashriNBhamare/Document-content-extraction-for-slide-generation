Existing techniques, however, generate many false positives, make "closed-world" assumptions (i.e., the adversary must know in advance that the streamed video belongs to a small known set), or are not robust to noise in the network or the adversary's measurements.Further, prior work assumes that the adversary can directly observe the encrypted video stream either at the network layer (e.g., a malicious Wi-Fi access point) [11] or physical layer (e.g., a Wi-Fi sniffer) [43,46], or else that the adversary's virtual machine is co-located with the user's virtual machine [1]. We demonstrate that packet bursts in encrypted streams correspond to segment requests from the client and that burst sizes are highly correlated with the sizes of the underlying segments.Second, we demonstrate that this leak is a fingerprint for about 20% of YouTube videos because their burst patterns are highly distinct. This attacker is much weaker than malicious ISPs and Wi-Fi access points typically considered in the traffic analysis literature.In summary, we (1) explain the root causes of burst patterns in encrypted video streams, (2) show how to exploit these patterns for video identification in an "openworld" setting, (3) develop and evaluate a noise-tolerant identification methodology based on deep learning, and (4) demonstrate how a remote attacker without direct observations of the network can identify streamed videos. Modern video streaming services have broadly adopted [34,59] the MPEG-DASH standard [49,52] for Dynamic Adaptive Streaming over HTTP (DASH, in short). All popular streaming services use variable-bitrate (VBR) encoding, where the bitrate of an encoded video varies with its content. We conjecture that a suffix of the vector of segment sizes, arranged in the order they are fetched from the server (which corresponds to the order of presentation), can be estimated from the observable characteristics of encrypted streaming traffic, up to a small error induced by the varying overheads of lower network layers.Example. Audio and video segment-files corresponding to a given time segment are fetched at roughly the same time, on two respective HTTPS request-response pairs.As this video is being streamed, we observe the initial buffering period of about 50 seconds, during which segment-files are fetched at a rate higher than their presentation rate. This includes malicious Wi-Fi access points, proxies, routers, enterprise networks, ISPs, tapped network cables, etc.Cross-site and cross-device attacker. A remote attacker who has no foothold in the victim's network can use the same network congestion side channel as our JavaScript attack for coarse-grained traffic measurement [15,17,23]. The required capture length depends on the attacker's vantage point: we used 60 seconds per sample for the Netflix on-path attacker, 5-6 minutes per sample for the JavaScript attacker. Because video traffic is very distinct and can be accurately recognized from coarse-grained features [66], we assume that the attacker can tell approximately when video playback begins.He then applies his detectors to the collected measurements to identify the streamed video or determine that it is not one of the videos for which he has detectors. To evaluate off-path attacks, we assume that the attacker executes his JavaScript client code either in the same browser that is receiving the target stream (the cross-site attack), or on a machine on the same local network as the device that is receiving the target stream (the cross-device attack). For videos with an initial title sequence, this (non-unique) sequence is downloaded as part of the initial buffering; the bursts in the on-off phase correspond to the segments of unique content.We captured the network traffic of each streaming session for a certain duration (see below) using Wireshark's tshark [60]. When the points correspond to arrival times and packet sizes, bursts are presumably associated with the transmission of higher-level elements such as HTTP responses (see Section 2). We discarded these and only used the remaining 18 titles, with 3-minute content captures for each.We also downloaded actual 720p MP4 file video files (as opposed to their network streams) for the 3,558 titles from the crawl, using the SAVEFROM.NET Web tool. We now show that for 19% of YouTube files, this leak is actually a fingerprint: the sequence of segment sizes identifies the video with virtually no false positives.Modeling the server.We used the Bento4 MPEG-DASH toolset [4] to process our 3,558 YouTube videos (see Section 5.2) for standardized streaming, i.e., divide them into time segments and create the manifests. Let s m = mean(T S), the element-wise average over T S. Training produces α(s m ), which is the attacker's fingerprint of m.During the attack, the attacker is given the victim's trace t ∈ R k and computes its traceprint, α(t). Total error is thus bounded by B with 1 With longer captures, we could have estimated this error directly.very high probability, Pr t←T m [α(t) − α(s m ) 1 ≤ B] ≥ 1 − 7 · 10 −12 ≥ 1 − 10 −11 , implying very high recall.Attacker's precision.Even if the distance between the attacker-measured "traceprint" and the video's fingerprint is small, the attacker may still misclassify the video if its fingerprint is close to another one. There are no such collisions in our dataset.To estimate the attacker's precision, we need to assume that s m , the series of average burst sizes used to compute the fingerprint, is similar to the corresponding series of segment sizes z m in the following sense: ifα(z m ) − α(z m ) 1 ≥ 2B, then α(s m ) − α(s m ) 1 ≥ 2B. Section 6 explains why DASH-based video streams are fingerprintable, but the theoretical model underestimates the capabilities of realistic attackers who can use traffic features other than burst sizes (e.g., packet timing). The subsequent (low) levels typically infer representations of the features of the input, and the final (high) layers perform the learning task (e.g., classification) given these features.DNNs are good at capturing high-level concepts that are easy for humans to agree on but hard to express formally. The dataset was normalized on a per-feature basis: the time-series vector representing a given feature in each sample was divided by the maximum of the aggregated values of this feature. For example, it achieves 90% accuracy given just the times of packet arrivals at a very coarse granularity of 0.25-second intervals (i.e., the PPS feature). tive rate is 0.01 (0.99 recall), and precision is better than accuracy (0.995). This connection, however, may have different network characteristics, such as bandwidth, latency, congestions and packet drops, all of which affect the collected traces.We conjecture that our classifiers learn high-level features of video streams, such as burst patterns, that are robust to reasonable differences in network characteristics and will therefore maintain high accuracy even when trained on a different network (in the absence of pathological conditions such as excessive packet loss or inadequate bandwidth for streaming). More expressive classifiers (e.g., with more hidden layers) suffer from over-fitting, but it may be solved with more data, e.g., 1000 captures per video.Finally, the low base rate potentially motivates the use of detection cascades [56] consisting of a series of classifiers, each of which is more complex (with a larger input feature space and more hidden layer activations) than the previous one. "Open world," when the attacker does not know a priori a relatively small set of possibilities for the video being streamed, is characterized by an extremely low base rate, i.e., probability P(M) that the video actually corresponds to any of the attacker's detectors. We cannot simply plug Pr (A|¬M) and Pr (A|M) into the BDR formula and expect to get a good estimation, since the distribution that this classifier was trained on-without samples from the catchall "other" class-is fundamentally different from the distribution of videos that might be streamed by the victim.Similarly to the previous section, there are two causes of false positives: similarities in the videos' burst patterns (which is what the classifier learns), i.e., a classifier-collision false positive, and noise in the measurements, i.e., a network-noise false positive.The confusion matrix (Figure 7.3b) shows no pairwise classifier collisions for the 100 titles. In particular, even if the victim is streaming a video in another tab of the same browser, confined JavaScript code cannot directly access the URL or content displayed in that tab.The same origin policy does permit the attacker's JavaScript code to communicate with its own origin (e.g., the Web server that served the ad). This leaks information about the content streamed from a different origin by the same browser (a cross-site attack, see We implemented a malicious NODE.JS Web server which, when accessed by the victim's browser, serves detector code written in JavaScript. All traffic between victim-LAN (which includes the streaming client and the attack JavaScript client) and the Internet (which includes the streaming server and the attack server) thus flows through a bandwidth-constrained router.Data. The attack server was sending an 8KB message every 1.5ms, about 300 KBps short of saturating the network link.In this experiment, we smoothed the time series of the delay measurements by averaging over 0.1-second intervals, filtered it for delays y > 2.1ms, computed the burst series with 0.5-second intervals, and filtered out all bursts whose sizes were below 10. Figure 9.5: Cross-device attack on a Roku streamer. The timing of the messages observed by the detector code on the neighbor device exhibits clear patterns corresponding to the stream received by the viewer device. If the noise is so significant as to dramatically change the traffic characteristics of the stream (e.g., if the same network connection is used to watch multiple concurrent videos, upload media files, or for some other bandwidthintensive activity), the attack may not succeed.In the off-path attack, the attacker's server sends large amounts of traffic to congest a shared network link and his JavaScript client measures arrival times in the victim's browser. In this paper, we did not evaluate a scenario where the victim is experiencing erratic network conditions causing frequent switches between encodings.Our techniques aim to identify standard, unmodified streaming video (e.g., Netflix movies). In [31], Liu et al. use aggregated traffic throughput traces (as opposed to frame-size time series) and report 1% false positive rate and 90% recall rate.These methods operate on time series resembling, and close to the granularity of, the sizes of individual frames. This approach has not been evaluated in an off-path setting, where the attacker has only noisy side-channel measurements, nor for any streaming services other than Netflix.Mass fingerprinting in [44] relies on the metadata sent by Netflix to the client at an early stage of the streaming process, namely the . Felten and Schneider [13] observed that JavaScript can infer information from the timing of cross-origin requests; Bortz and Boneh [5] demonstrated several timing-related Web attacks; Van Goethem et al. [55] proposed timing techniques that tolerate network noise and server-side mitigations. Segmenting VBR video into uniformly sized segments is futile because then their duration will differ, thus the timing of client requests will still leak similar information.Constant-rate encoding with tight rate control and large segments will eliminate the leak, at the cost of a very inefficient encoding. Client-side-only changes are easier to deploy than changes to segmentation on the server, but devising such a regime is non-trivial even if we allow changes to both client side and server side.For example, consider a variable-size buffer that fetches equally-sized segments every X seconds (where X is fixed). We also show how an off-path adversary who merely serves a Web page or ad to a user can, via the network congestion side channel, perform the measurements needed for the attack and identify videos being streamed by the user on the same or different device. First, we have to align the stream with the file, i.e., match traffic bursts corresponding to segment-files to the segment-files' presentation time. We implemented and tried this approach for the Netflix dataset (which does not contain the "other" class, so we used a threshold of 0, i.e., a match is always accepted) and the YouTube dataset, with thresholds of 1, 5, and 10. We added a random number of bytes between 0 and 2% to each burst size in the dataset and measured the accuracy of the B classifier vs. our CNNbased classifiers, which use the total burst series (see Section 5.2) and are trained for 1,400 and 700 epochs on the Netflix and YouTube data, respectively.