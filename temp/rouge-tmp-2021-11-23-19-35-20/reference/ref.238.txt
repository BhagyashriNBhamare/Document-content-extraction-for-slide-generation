Exploitable hardware resources include the branch prediction unit [3][4][5], the DRAM [33,50,54] and the cache [7,15,22,47,48,61]. To this end, several proposals [10,13,36,49,64] use hardware performance counters (HPCs) to detect ongoing microarchitectural attacks. • shows that the proposed attack causes negligible cache misses on the victim, which renders it undetectable by state-of-the-art countermeasures.2 Background and related work CPU caches are small banks of fast memory located between the CPU cores and the RAM. The address bits are divided into offset (lowest-order bits used to locate data within a line), index (log 2 (S) consecutive bits starting from the offset bits that address the set) and tag (remaining bits which identify if the data is cached). One year later, Bansal et al. [9] presented their solution based on LFU and CLOCK, which they named CAR (Clock with Adaptive Replacement). They later complemented their original work [2] and found a model that explained the eviction policy in other machines (Intel Core 2 Duo E6750 and E8400). However, some works [10,36] consider its effect also on the victim's side and succeed in its detection. Then, he waits and finally probes the desired set looking for time variations that carry information about the victim activity.This attack was first proposed for the L1 data cache in [48] and was later expanded to the L1 instruction cache [6]. Detection systems can use time measurements [12], hardware performance counters [10,13,36,64] or place data in transactional regions [18] defined with the Intel TSX instructions. Input: Eviction_set, Conflicting_set Output: Accuracy of the policy hits/trials function TESTPOLICY(eviction_set, conflicting_set) hits = 0; while i ≤ num_experiments do j = 0,i++; control_array ← {}; address_array ← {}; initialize_set(); Fills address and control arrays lim = random(); while j ≤ lim do lfence; j++; next_data = eviction_set[random()]; measure time to read next_data; if time ≥ ll_threshold then LLC access update(control_array, next_data); con f _element = con f licting_set[random()]; read(con f _element);Force miss candidate=getEvictionCandidate(); if (testDataEvicted() ==candidate) then hits++; return hits/num_experiments; We have performed experiments in different machines, each of them including an Intel processor from different generations. Algorithm 1 summarizes this procedure. Algorithm 1 tries to emulate by software the behavior of the hardware (of the cache). Thus, in our procedure, the control bits would be -1 (line empty), 0 (line not recently used), and 1 (line recently used). The getEvictionCandidate function will return one array position whose control bit value is -1, or, if no control bit is equal to -1, one whose control bit is equal to 0. In case multiple addresses have control bits equal to -1 or to 0, the function will return the first address whose control bits are -1 or 0, that it encounters when traversing the control_array from the beginning. Figure 1 shows the distinction between accesses to low and last level caches based on reload times observed in the i7-4790 machine and validated with performance counters. The region coloured in blue controls the policy 1, and the region coloured in red controls the policy 2. The sets with a fixed policy for each of the slices are depicted in figure 4. The remaining processors (6th, 7th and 8th generations) always insert the blocks with age 2, which is equivalent to the mode 1 in the previous generations.In order to help the reader to understand how the cache works, figure 5 shows an example of how the contents of a cache set are updated with each access according to each policy. When the processor requests the line "d", there is an empty block in the set, so "d" is placed in that set and it gets age 2 (Mode 1) or age 3 (Mode 2). In mode 1, the eviction candidate is now "a" because it is the only one with age 3, whereas in mode 2 the eviction candidate is "d" as it has age 3 and is on the left of "a". The element ev W −1 is forced out of the cache, so it could be used to create a new conflict on the next iteration.When the cache policy is working in mode 2, each element is inserted with age 3. In this case, steps 1 to 5 are equivalent. Input: Eviction_set, Target_address Output: Reload time function RELOAD(Target_address,eviction_set) "rdtsc"; "lfence"; read(eviction_set[w − 1]); Forces a miss "lfence"; f lush(eviction_set[w − 1]); "lfence"; read(Target_address); f lush(Target_address); "lfence"; read(Target_address);Reload on first position "lfence"; "rdtsc"; read(eviction_set [0]); return time_reload; Algorithms 2 and 3 summarize the steps of the RELOAD+REFRESH attack when the insertion age is two (newest Intel generations or mode 1 in oldest generations). The same assumption is true for the conflicting address or the element W − 1 of the eviction set, which would have to be flushed only in that situation. Low reload times mean the data was used by the victim, whereas high reload times mean it was not.The REFRESH function is meant for a 12 way set. The attacker can Input: Eviction_set Output: Refresh time function REFRESH(Eviction_set) volatile unsigned int time; asm __volatile__( " lfence \n" " rdtsc \n" " movl %%eax, %%esi \n" " movq 8(%1), %%rdi \n" Eviction_set[1] " movq (%%rdi), %%rdi \n" " movq (%%rdi), %%rdi \n" " movq (%%rdi), %%rdi \n" " movq (%%rdi), %%rdi \n" " movq (%%rdi), %%rdi \n" " movq (%%rdi), %%rdi \n" " movq (%%rdi), %%rdi \n" " movq (%%rdi), %%rdi \n" " movq (%%rdi), %%rdi \n" " movq (%%rdi), %%rdi \n" Eviction_set[w-2] " lfence \n" " rdtsc \n" " subl %%esi, %%eax \n" Time value on %eax ); return time_re f resh;gain information about the victim by reloading the target address, and he must begin by refreshing the third element of the eviction set and finish with the first one which will evict the "noise" from the cache, so the age of all the blocks is set to 2 again. 2 The sender transmits a 1 by accessing a memory location from a shared library and a 0 by not-accessing it. The receiver monitors the cache utilization using each of the aforementioned techniques and determines whether a 1 or a 0 was transmitted. That is, it accesses one memory location (sends 1) and then waits (transmits 0) for a fixed time before the following access. In scenarios where victim and attacker do not interfere with each other (such as the attack against AES in section 5.2), the eviction rate of this approach is around 99%. However, in a different scenario where interference is possible, as in the case of the attack against RSA (section 5.3) or when the interval between monitored accesses is low, the number of false positives slightly increases with this approach. These experiments were performed in the i5-7600K machine (Table 1). Note that when the waiting time between samples is low, both PRIME+PROBE and RELOAD+REFRESH are not able to distinguish between 1 and 0. Note that, in this case, we sometimes do not get two samples for each window (access and idle), we do not consider as false positives the samples classified as 1 in that window.Even when RELOAD+REFRESH has lower resolution than other attacks, it can be used to retrieve secret keys of cryptographic implementations. We demonstrate this statement and replicate two published attacks: one against the T-Table implementation of AES (section 5.2) and one against Table 2: F-Score for the different attacks when the sender accesses the data at different and fixed intervals (ns). Our scenario is similar to the one described by Irazoqui et al. [7], which was later replicated by Briongos et al. [11]. As the content of the tables is publicly available from the source code, they obtained the secret final round key by xoring the table content hold in the cache line, with the ciphertext.Besides performing the attack against the AES T-Table implementation (OpenSSL 1.0.1f compiled with gcc and the no-asm and no-hw flags) using the RELOAD+REFRESH (R+R) technique, we have performed the same attack using the FLUSH+RELOAD (F+R) and PRIME+PROBE (P+P) techniques, to provide a fair comparison regarding the number of traces required to obtain the key. Figure 7 shows the resulting distribution of the number of misses the victim sees for each attack and for the normal execution of the encryption.As implied by Figure 7, our attack cannot be distinguished from the normal performance of the AES encryption process by measuring the number of L3 cache misses. As we did before, we performed the attack using our stealthy technique as well as using the FLUSH+RELOAD and PRIME+PROBE techniques.The targeted crypto library is libgcrypt version 1.5.0, which includes the aforementioned square and multiply implementation. Figure 9 compares part of a trace retrieved using the RELOAD+REFRESH approach with the real execution of a RSA decryption operation (we collect timestamps). The concrete mean values of the misses are presented in Table 5. The results of the analysis are summarized in Table 5.