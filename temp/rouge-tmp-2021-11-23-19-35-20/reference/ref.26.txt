We also show that by applying Cloak to code running inside In-tel SGX enclaves we can effectively block information leakage through cache side channels from enclaves, thus addressing one of the main weaknesses of SGX. We ensure permanent cache residency of sensitive code and data using widely available hardware transactional memory (HTM), which was originally designed for high-performance concurrency.HTM allows potentially conflicting threads to execute transactions optimistically in parallel: for the duration of a transaction, a thread works on a private memory snapshot. Thus, current implementations like Intel TSX require that all accessed memory remains in the CPU caches for the duration of a transaction. However, code inside SGX enclaves is as much vulnerable to cache attacks as normal code [7,20,46,57] and, when running in a malicious OS, is prone to other memory access-based leakage including page faults [10,61]. In Section 7, we show how Cloak makes SGX a highly secure execution environment. The last-level cache (LLC), is typically unified and shared among all cores. Each cache is organized in cache sets and each cache set consists of multiple cache lines or cache ways. If the eviction of a cache set results in longer execution time, the attacker learns that the victim likely accessed it. This includes different parts of the CPU's branch-prediction facility [1,15,40], the DRAM row buffer [5,55], the page-translation caches [21,28,36] and other microarchitectural elements [14]. Concurrent read accesses by other threads to the read set are generally allowed; however, concurrent writes are problematic and-depending on the actual HTM implementation and circumstances-likely lead to transactional aborts. Depending on the implementation, read and write set can have different sizes, and set sizes range from multiple KB to multiple MB of HTM space.Due to HTM usually being implemented within the CPU cache hierarchy, HTM has been proposed as a means for optimizing cache maintenance and for performing security-critical on-chip computations: Zacharopoulos [64] uses HTM combined with prefetching to reduce the system energy consumption. While the attacker has more control over the software running on the machine, the SGX protections prevent sharing of memory pages between the enclave and untrusted processes, which renders Flush+Reload attacks ineffective in this setting.All other side-channels, including power analysis, and channels based on shared microarchitectural elements other than caches are outside our scope. * ( v o l a t i l e s i z e t * ) p ; A E S e n c r y p t ( p l a i n t e x t , c i p h e r t e x t , &key ) ; x e n d ( ) ; } R2 A transaction aborts immediately when any part of transactional memory leaves the cache hierarchy.R3 All pending transactional memory accesses are purged during a transactional abort.R4 Prefetching decisions outside of transactions are not influenced by transactional memory accesses.R1 ensures that all sensitive code and data can be added to the transactional memory in a deterministic and leakage-free manner. Our experiments and previous work [19] find the read set size to be ultimately constrained by the size of the LLC: Figure 2 shows the failure rate of a simple TSX transaction depending on the size of the read set. The Intel manual states that "an implementationspecific second level structure" may be available, which probabilistically keeps track of the addresses of read-set 0 1,000 2,000 3,000 4,000 5,000 0% 50% 100% Array size in KB cache lines that were evicted from the L1 cache. To be not constrained to the small L1 in SGX nonetheless, we propose solutions to detect and prevent such attacks later on in Section 7.2. Hence, forms of R1 and R2 can also be ensured for code in the L1 instruction cache without it being part of the write set.In summary, we can fulfill requirements R1 and R2 by moving code into the read set or, using undocumented microarchitectural effects, by limiting the amount of code to the L1 instruction cache and preloading it via execution. The victim in this experiment starts the transaction, by placing data and code into transactional memory in a uniform manner (using either reads, writes or execution). The left region corresponds to the preloading of sensitive code/data at the beginning of the transaction. To extend the working set beyond L1, sensitive read-only data can also be kept in the LLC as described in Section 5.1.1. For example, reserving the L1 cache sets with indexes 0 and 1 gives a conflict-free write set of size 2 · 8 · 64 B = 1 KB. As described in Section 5.1.2, we preload code into the read set and optionally into the L1 instruction cache. We implemented the read-set preloading strategy from Section 5.2.1 in a small C++ container template library.The library provides generic read-only and writable arrays, which are allocated in "read" or "write" cache lines respectively. For programmer-annotated functions on Windows, the compiler adds code for starting and ending transactions, ensures that all code cache lines are preloaded (via read or execution according to Section 5.2.2) and, to not pollute the write set, refrains from unnecessarily spilling registers onto the stack after preloading. The preloading step fetches the 4 T-Tables, i.e., it adds 4 KB of data to the read set.We performed roughly 2 billion encryptions in an asynchronous attack and measured the cache hits on the T-table cache lines using Prime+Probe and Flush+ Reload. This is due to the TSX transaction failing more often if under attack.While not under attack the implementation protected with Cloak started 0.8% more encryptions than the baseline implementation (i.e., with preloading) and less than 0.1% of the transactions failed. In the case of Flush+Reload only 1.4 million out of 4.9 billion transactions succeeded. Less than 0.1% of the transactions failed, leading to an overall performance penalty of 1.2%. The preloading step fetches 1 cache line per function, i.e., 128 B of code are added to the read set. During these 1 million exponentiations, only 0.5% of the transactions failed. Instead of multiple binary searches that leak information we only identified one binary search that is still performed upon every keystroke.In order to demonstrate the general applicability of Cloak, we reproduced the attack by Gruss et al. [24] on a recent version of the GDK library (3.18.9) which comes with Ubuntu 16.10. To demonstrate Cloak's applicability to the SGX environment and its capability to support larger working sets, we adapted an existing C++ implementation of a decision tree classification algorithm [49] using the toolset described in Section 5.3. Each input record is a vector of 54 floating point values. In particular, malicious system software, i.e., the OS, can amplify sidechannel attacks by concurrently (A1) interrupting and resuming enclave threads [40], (A2) unmapping enclave pages [61], (A3) taking control of an enclave thread's sibling hyper-thread (HT) [11], or (A4) repeatedly resetting an enclave. In case unexpected aborts of this type occur, the enclave may terminate itself as a countermeasure.Preventing A3 is more involved and requires several steps: before executing a transaction, we demand that (i) both HTs of a CPU core enter the enclave and (ii) remain there. One way of doing so is to transmit a secret (derived using the rdrand instruction inside the enclave) over a timing-less L1-based TSX covert channel: for each bit in the secret, the receiver starts a transaction and fills a certain L1 cache set with write-set cache lines and busy-waits within the transaction for a certain time; if the current bit is 1, the sender aborts the receiver's transaction by touching conflicting cache lines of the same cache set. Fourth, variants of Prime+Probe that deliberately evict read set cache lines from L1 to the LLC but not to DRAM could potentially obtain side-channel information without causing transaction aborts. Mimosa builds upon the existing TRE-SOR system [47], which ensures that a symmetric master key is always kept in the CPU's debug registers. At its core, T-SGX leverages the property that exceptions within TSX transactions cause transactional aborts and are not delivered to the OS. Like T-SGX, the recent Déjà Vu [8] approach also attempts to detect page-fault side-channel attacks from within SGX enclaves using TSX: an enclave thread emulates an non-interruptible clock through busy waiting within a TSX transaction and periodically updating a counter variable. Other defenses aim at detecting potential side-channel leakage and attacks, e.g., by means of static source code analysis [13] or by performing dynamic anomaly detection using CPU performance counters. Finally, we showed that one of the main limitations of Intel SGX, the lack of side-channel protections, can be overcome by using Cloak inside Intel SGX enclaves.Listing 2: Decision tree classification before and after Cloak: the code in black is shared by both versions, the code before Cloak is in dark gray(lines 1-3), and Cloakspecific additions are in blue (lines 5-7, 11, 12, 15).1 using Nodes = nelem_t*; 2 using Queries = Matrix<float>; 3 using LeafIds = uint16_t*; 4 5 using Nodes = ReadArray<nelem t, NCS R>; 6 using Queries = ReadMatrix<float, NCS R>; 7 using LeafIds = WriteArray<uint16 t, NCS W>; 8 9 void tsx protected look up_leafi ds ( 10 Nodes & nodes , Queries & Listing 2 gives an example of the original code for tree traversal and its Cloak-protected counterpart. Access to a node determines which feature is used to make a split and its threshold on the value of this feature indicates whether the traversal continues left or right.