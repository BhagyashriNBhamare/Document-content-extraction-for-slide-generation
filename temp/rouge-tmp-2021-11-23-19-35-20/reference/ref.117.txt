Short notices based on information extracted from privacy policies have been shown to be useful but face a significant scalability hurdle, given the number of policies and their evolution over time. At the core of Polisis is a privacy-centric language model, built with 130K privacy policies, and a novel hierarchy of neural-network classifiers that accounts for both high-level aspects and fine-grained details of privacy practices. Although some service providers have improved the comprehensibility and readability of their privacy policies, these policies remain excessively long and difficult to follow [1,2,3,4,5]. In addition, emerging technologies brought along new forms of user interfaces (UIs), such as voice-controlled devices or wearables, for which existing techniques for presenting privacy policies are not suitable [3,6,7,8]. The problem lies in stakeholders lacking the usable and scalable tools to deal with the breadth and depth of privacy policies.Several proposals have aimed at alternative methods and UIs for presenting privacy notices [8], including machine-readable formats [13], nutrition labels [14], privacy icons (recently recommended by the EU [15]), and short notices [16]. The existing research towards automating this process has been limited in scope to a handful of "queries," e.g., whether the policy mentions data encryption or whether it provides an opt-out choice from third-party tracking [16,17]. Polisis uses these classes to enable scalable, dynamic, and multi-dimensional queries on privacy policies, in a way not possible with prior approaches.At the core of Polisis is a novel hierarchy of neuralnetwork classifiers that involve 10 high-level and 122 fine-grained privacy classes for privacy-policy segments. We demonstrate and evaluate the modularity and utility of Polisis with two robust applications that support structured and free-form querying of privacy policies.The structured querying application involves extracting short notices in the form of privacy icons from privacy policies. To build PriBot, we overcame the non-existence of a public, privacy-specific QA dataset by casting the problem as a ranking problem that could be solved using the classification results of Polisis. PriBot matches user questions with answers from a previously unseen privacy policy, in real time and with high accuracy -demonstrating a more intuitive and user-friendly way to present privacy notices and controls. With this paper we make the following contributions:• We design and implement Polisis, an approach for automatically annotating previously unseen privacy policies with high-level and fine-grained labels from a prespecified taxonomy (Sec. 2, 3, 4, and 5). • We make Polisis publicly available by providing three web services demonstrating our applications: a service giving a visual overview of the different aspects of each privacy policy, a chatbot for answering user questions in real time, and a privacy-labels interface for privacy policies. One example of such a taxonomy was introduced by Wilson et al. [11] (see also Fig. 3 privacy policy, thus providing the users with high modularity in posing their queries. In this layer, a Query Module receives the User Query about a privacy policy (Step 1 in Fig. 1). Each of the resulting segments can be independently consumed by both the humans and programming interfaces.Machine Learning Layer (Sec. 4): In order to enable a multitude of applications to be built around Polisis, the ML layer is responsible for producing rich and fine-grained annotations of the data segments. Policy Extraction: Given the URL of a privacy policy, the segmenter employs Google Chrome in headless mode (without UI) to scrape the policy's webFurther useful privacy and security related materials can be found through Google's policies and principles pages, including: o Information about our technologies and principles, which includes, among other things, more information on • how Google uses cookies. o A page that explains what data is shared with Google when you visit websites that use our advertising, analytics and social products. For example, when the user expands a collapsible paragraph, a local JavaScript exposes an offline HTML snippet; no further downloading takes place.We confirmed this with the privacy policies of the top 200 global websites from Alexa.com. Using a fuzzy string matching library, 1 we found that the segmenter's scraped policy covers, on average, 99.08% of the content of the manually fetched policy.List Aggregation: Second, the segmenter handles any ordered/unordered lists inside the policy. Our handling of the lists involves two techniques: one for short list items (e.g., the inner list of Fig. 2) and another for longer list items (e.g., the outer list of Fig. 2). For that purpose, we use custom, domain-specific word embeddings that we generated using our corpus of 130K privacy policies (cf. Sec. 4). This section describes the components of Polisis' Machine Learning Layer in two stages: (1) an unsupervised stage, in which we build domain-specific word vectors (i.e., word embeddings) for privacy policies from unlabeled data, and (2) a supervised stage, in which we train a novel hierarchy of privacy-text classifiers, based on neural networks, that leverages the word vectors. For example, replacing the word "erase" by the word "delete" can significantly change the classification result if "delete" was not in the classifier's training set.Word embeddings solve this issue by extracting generic word vectors from a large corpus, in an unsupervised manner, and enabling their use in new classification problems (a technique termed Transfer Learning). These policies typically describe the overall data practices of the apps' companies.We crawled the metadata of more than 1.4 million Android apps available via the PlayDrone project [27] to find the links to 199,186 privacy policies. A major advantage of using fastText is that it allows training vectors for subwords (or character n-grams of sizes 3 to 6) in addition to words. For that purpose, we leverage the Online Privacy Policies (OPP-115) dataset, introduced by Wilson et al. [11]. First, paragraph-sized segments were annotated according to one or more of the 10 high-level categories in Fig. 3 (e.g., First Party Collection, Data Retention). To account for the multiple granularity levels in the policies' text, we build a hierarchy of classifiers that are individually trained on handling specific parts of the problem.At the top level, a classifier predicts one or more highlevel categories of the input segment x (categories are the top-level, shaded boxes of Fig. 3). Each classifier produces the probabilities p(v j |x) for the values v j ∈ V (b) of a single attribute b. For example, given the attribute b=information type, the corresponding classifier outputs the probabilities for elements in V (b): {financial, location, user profile, health, demographics, cookies, contact information, generic personal information, unspecified, . . . }. • financial • health • contact • location • … Information Type • opt-in • opt-out • opt-out-link • … Choice Type • advertising • marketing • analytics • legal requirement • … Purpose • stated period • limited • indefinitely • unspecified • other Retention PeriodAn important consequence of this hierarchy is that interpreting the output of the attribute-level classifier depends on the categories' probabilities. Then, a max-pooling layer combines the vectors resulting from the different windows into a single vector. This vector then passes through the first dense (i.e., fully-connected) layer with a ReLU activation function, and finally through the second dense layer. In Table 1, we present the evaluation metrics on the testing set for the category classifier intended for free-form queries. In addition to the precision, recall and F1 scores (macro-averaged per label 3 ), we also show the top-1 precision metric, representing the fraction of segments where the top predicted category label oc- curs in the annotators' ground-truth labels. A structured query is a combination of first-order logic predicates over the predicted privacy classes and the policy segments, such as: ∃s (s ∈ policy ∧ information type(s)=location ∧ purpose(s) = marketing ∧ user choice(s)=opt-out). Users: Polisis can automatically populate several of the previously-proposed short notices for privacy policies, such as nutrition tables and privacy icons [3,18,31,32]. A user can build on Polisis' output to automatically quantify the privacy utility of a certain policy.For example, such a privacy metric could be a combination of positive scores describing privacy-protecting features (e.g., policy containing a segment with the label: retention period: stated period ) and negative scores describing privacy-infringing features (e.g., policy containing a segment with the label: retention period: unlimited ). Otherwise, discrepancies between policies and notices might arise over time, which deters companies from adopting the short notices in the first place.By answering free-form queries with relevant policy segments, Polisis can remove the interface barrier between the policy and the users, especially in conversational interfaces (e.g., voice assistants and chatbots). One example query can be formed by joining the label information type: health with the category of First Party Collection or Third Party Sharing.Regulators: Numerous studies from regulators and law and public policy researchers have manually analyzed the permissiveness of compliance checks [21,37]. ⎫ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎬ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎭Yellow: All segments in S have category: user-choice-control andchoice-type ∈ [opt-in, opt-out-link, opt-out-via-contacting-company] Green: S = φ Red: Otherwise Expected Collec- tionDiscloses whether it allows other companies like ad providers and analytics firms to track users on the site?Red: Yes, w/o choice to opt-out. Let S be the segments with category: third-party-sharing-collection, purpose: ∈ [advertising,analytics-research ], and action-third-party ∈ [track-on-first-party-website-app,collecton-first-party-website-app]. Discloses whether the site or service tracks a user's actual geolocation?Red: Yes, possibly w/o choice.Yellow: Yes, with choice.Green: No.Let S be the segments with personal-information-type: location. The database powering these icons originated from TRUSTe (re-branded later as TrustArc), a privacy compliance company, which carried out the task of manually analyzing and labeling privacy policies.In what follows, we first establish the accuracy of Polisis' automatic assignment of privacy icons, using the Disconnect icons as a proof-of-concept. Hence, this represents our best effort to reproduce the icons, but these rules could easily be adapted as needed.To evaluate the efficacy of automatically selecting appropriate privacy icons, we compare the icons produced with Polisis' automatic labels to the icons produced based on the law students' annotations from the OPP-115 dataset [11]. Table 3 shows the accuracy obtained per icon, measured as the fraction of policies where the icon based on automatic labels matched the icon based on the experts' labels. This result is significant in view of Miyazaki and Krishnamurthy's finding [21]: the level of agreement among 3 trained human judges assessing privacy policies ranged from 88.3% to 98.3%, with an average of 92.7% agreement overall. Given that we achieve a high accuracy in assigning privacy icons, it is intuitive to investigate how they compare to the icons assigned by Disconnect and TRUSTe. To answer this question, we designed an experiment to compare the icons extracted by Polisis' automatic labels to the icons assigned by Disconnect on real policies.One obstacle we faced is that the Disconnect icons have been announced in June 2014 [41]; many privacy policies have likely been updated since then. We do not report the rest of the icons because the location information label in the OPP-115 taxonomy included non-precise location (e.g., zip codes), and there was no label that distinguishes the exact retention period. The discrepancy between the two distributions is obvious: the vast majority of the Disconnect icons have a yellow label, indicating that the policies offer the user an opt-out choice (from unexpected use or collection). This result indicates that the majority of policies do not provide users a choice within the same segments describing data usage for advertising or data collection by third parties.We go one step further to follow an even more permissive strategy where we assign the yellow label to any policy with S! For example, a policy where third-party advertising is mentioned in the middle of the policy while the opt-out choice about another action is mentioned at the end of the policy would still receive a yellow label. A developer could still utilize Polisis to extract the rest of the icons by either augmenting the existing taxonomy or by performing additional natural language processing on the segments returned by Polisis. This is because Polisis already predicts a comprehensive set of labels, covering a wide variety of rules.Furthermore, by automatically generating icons, we do not intend to push humans completely out of the loop, especially in situations where legal liability issues might arise. PriBot is primarily motivated by the rise of conversation-first devices, such as voice-activated digital assistants (e.g., Amazon Alexa and Google Assistant) and smartwatches. To support these new forms of services and the emerging need for automated customer support in this domain [43], we present PriBot as an intuitive and userfriendly method to communicate privacy information. Ranking Score: In order to answer the user question, PriBot ranks each potential answer 6 a by computing a proximity score s(q, a) between a and the question q. Given the output of the Segment Classifier, an answer is represented as a vector:α α α = {p(c i |a) 2 × p(v j |a) | ∀c i ∈ C , v j ∈ V (c i )}for categories c i ∈ C and values v j ∈ V (c i ) descending from c i . This measure is derived from the entropy of the normalized probability distribution (p n ) of the predicted categories:cer(a) = 1 − (− ∑ (p n (c i |a) × ln(p n (c i |a))) / ln(|C |))(1) Akin to a dot product between two vectors, we compute the score s(q, a) as:s(q, a) = ∑ i (β i × min(β i , α i )) ∑ i β 2 i × cer(a)(2)As answers are typically longer than the question and involve a higher number of significant features, this score prioritizes the answers containing significant features that are also significant in the question. Intuitively, the confidence in an answer should be low when (1) the answer is semantically far from the question (i.e., s(q, a) is low), (2) the question is interpreted ambiguously by Polisis, (i.e., classified into multiple high-level categories resulting in a high classification entropy), or (3) when the question contains unknown words (e.g., in a non-English language or with too many spelling mistakes). Our requirements for this dataset were that it (1) must include free-form questions about the privacy policies of different companies and (2) must have a ground-truth answer for each question from the associated policy.To this end, we collected, from Twitter, privacy-related questions users had tweeted at companies. "Next, two of the authors independently validated each of the tweets to remove question tweets (a) that were not related to privacy policies, (b) to which the replies are not from the official company account, and (c) with inaccessible privacy policy links in their replies. We compare PriBot's QA model against three baseline approaches that we developed: (1) Retrieval reflects the state-of-the-art in term-matching retrieval algorithms, (2) SemVec representing a single neural network classifier, and (3) Random as a control approach where questions are answered with random policy segments.Our first baseline, Retrieval, builds on the BM25 algorithm [48], which is the state-of-the-art in ranking models employing term-matching. Here, we evaluate the predictive accuracy of PriBot's QA model by comparing its predicted answers against expert-generated ground-truth answers for the questions of the Twitter QA Dataset.Ground-Truth Generation: Two of the authors generated the ground-truth answers to the questions from the Twitter QA Dataset. Fig. 8a shows how the top-k score varies as a function of k. PriBot's model has the best performance over the other three models by a large margin, especially at the low values of k. For example, at k = 1, PriBot has a top-k score of 0.68, which is significantly larger than the scores of 0.39 (Retrieval), 0.27 (SemVec), and 0.08 (Random) (p-value < 0.05 according to pairwise Fisher's exact test, corrected with Bonferroni method for multiple comparisons). To put these numbers in the wider context of free-form QA systems, we note that the top-1 accuracy reported by IBM Watson's team on a large insurance domain dataset (a training set of 12,889 questions and 21,325 answers) was 0.65 in 2015 [51] and was later improved to 0.69 in 2016 [52]. This indicates that PriBot is poised to perform better in a system where low values of k matter the most.Second, to further focus on the effect of policy length, we categorize the policy lengths (#segments) into short, medium, and high, based on the 33rd and the 66th percentiles (i.e., corresponding to #segments of 28 and 46). Pre-trained Embeddings Choice As discussed in Sec. 4, we utilize our custom Policies Embeddings, which have the two properties of (1) being domainspecific and (2) using subword embeddings to handle out-of-vocabulary words. First, we can see that our Policies Embeddings outperform the other models for all values of k, scoring 14% and 5% more than the closest variant at k = 1 and k = 2, respectively. Of these, 15 are a random subset of the pool of 360 QA pairs (of the evaluated condition) such that a participant does not receive two QA pairs with the same question. User Study Results: As in the previous section, we compute the top-k score for relevance (i.e., the portion of questions having at least one user-relevant answer in the top k returned answers). In comparison, for k = 1, the scores were 46% and 48% for the Retrieval and the SemVec models respectively (p-value <= 0.05 according to pairwise Fishers exact test, corrected with Holm-Bonferroni method for multiple comparisons). While the modified policy has the same meaning, Polisis might misclassify the modified segments.Deployment: We provide three prototype web applications for end-users. Following the trend of automation in legal advice [56], insurance claim resolution [57], and privacy policy presentation [58,16], third parties, such as automated legal services firms or regulators, can deploy Polisis as a solution for their users. It allows transitioning from labeling of policies with a few practices (e.g., the works by Zimmeck and Bellovin [16] and Sathyendra et al. [17]) to a much more fine-grained annotation (up to 10 high-level and 122 fine-grained classes), thus enabling a richer set of applications. Our main contribution is that we build a QA system, without a dataset that includes questions and answers, while achieving results on par with the state of the art on other domains. In the first example, we use Polisis' output to extract short notices from the privacy policy in the form of privacy icons and to audit TRUSTe's policy analysis approach.