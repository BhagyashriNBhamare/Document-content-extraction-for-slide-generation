For this purpose, SCATTERCACHE retrofits skewed associative caches with a keyed mapping function, yielding a security-domain-dependent cache mapping. Our security analysis reveals that even in the strongest possible attacker model (noise-free), the construction of a reliable eviction set for PRIME+PROBE in an 8-way SCATTERCACHE with 16384 lines requires observation of at least 33.5 million victim memory accesses as compared to fewer than 103 on commodity caches. These recent examples highlight the importance of finding practical approaches to thwart cache attacks.To cope with cache attacks, there has been much research on ways to identify information leaks in a software's memory access pattern, such as static code [19,20,41,45] and dynamic program analysis [34,71,74,77]. SCATTERCACHE is a novel and highly flexible cache design that prevents cache attacks such as EVICT+RELOAD and PRIME+PROBE and severely limits cache covert channel capacities by increasing the number of cache sets beyond the number of physically available addresses with competitive performance and implementation cost. Hence, and as our security analysis shows, the construction of a reliable eviction set for PRIME+PROBE in an 8-way SCATTERCACHE with 16384 lines requires observation of at least 33.5 million victim memory accesses as compared to fewer than 103 on commodity caches, rendering these attacks impractical on real systems with noise.Additionally, SCATTERCACHE effectively prevents FLUSH+RELOAD-based cache attacks, e.g., on shared libraries, as well. This cache hierarchy typically consists of 2 to 4 layers, where the offset set [idx+2] set [idx-2] set [idx-1] set [idx+1] way 0 way 1 way 2 way 3 index tag Figure 1: Indexing cache sets in a 4-way set-associative cache. The last-level cache is often inclusive, i.e., any cache line in a lower level cache must also be present in the last-level cache.Caches are typically organized into cache sets that are composed of multiple cache lines or cache ways. (1) By continuously removing (i.e., evicting or flushing) a cache line from the cache and measuring the access latency, an attacker can determine whether this cache line has been accessed by another process. More recently, PRIME+PROBE attacks on last-level caches have also been demonstrated in various generic use cases [4,44,48,50,59,79]. Instead of an attacker process attacking a victim process, both processes collude to covertly communicate using the cache as transmission channel. While optimized addressing logic can lead to efficient implementations, these designs differ significantly from conventional architectures.Time-Secure Caches [67] is based on standard setassociative caches that are indexed with a keyed function that takes cache line address and Process ID (PID) as an input. SCATTER-CACHE can be seen as a generalization of this approach with higher entropy in the indexing of cache lines.CEASER [55] as well uses standard set-associative caches with keyed indexing, which, however, does not include the PID. Between software defined security domains (e.g., different processes or users on the same machine, different VMs, . . . ), even for exactly the same physical addresses, cache lines should only be shared if cross-context coherency is required (i.e., writable shared memory). This means that all addresses mapping to the same cache set are congruent and enables PRIME+PROBE-style attacks.In SCATTERCACHE, on the other hand, the cache set for a particular access is a pseudorandom selection of arbitrary n ways cache lines from all available lines. This IDF effectively randomizes the mapping from addresses to cache sets as well as the composition of the cache set itself.Instead, as shown at the bottom of Figure 2, at best, partially overlapping cache sets can be found (cf. Section 4.3), which makes exploitation tremendously hard in practice. Instead, as shown in Figure 4, each index addresses a separate memory, i.e., an independent cache way.On the one hand, this change is counter-intuitive as it decreases the number of possible cache sets from n ways ·2 b indices +n ways −1 n ways to 2 b indices ·n ways . This effectively precludes the introduction of systematic biases for potentially "weak" address-key-SDID combinations that map to fewer than n ways cache lines.In terms of cache-replacement policy, SCATTERCACHE uses simple random replacement to ensure that no systematic bias is introduced when writing to the cache and to simplify the security analysis. (3) Recovering the key should be infeasible given input and output for the function.Existing Building Blocks: Cryptographic primitives like (tweakable) block ciphers, Message Authentication Codes (MACs), and hash functions are designed to provide these kind of security properties (e.g., indistinguishability of encryptions, existential unforgeability, pre-image and collision resistance). Using such cryptographic primitives, we define the following two variants of building IDFs:Hashing Variant (SCv1): The idea of SCv1 is to combine all IDF inputs using a single cryptographic primitive with pseudo random output. Using a tag dependent permutation of the input index mitigates this problem by design since permutations are bijections that, for a specific tag, cannot yield colliding mappings.Like in the hashing variant, a tweakable block cipher can be used to compute the permutation. They are the only ones who can make a profound decision given that they know the exact instantiation parameters (e.g., SDID/key/index/tag bit widths, number of cache ways) as well as the allocatable area, performance, and power budget in their respective product. This approach prevents various kinds of software-based attacks and is only possible due to the separation of key and SDID.The hardware for key management is comparably simple as well. SCATTERCACHE is a generic approach for building processor caches that are hard to exploit in cache-based side channel attacks. Considering that this number is even lower than the time it takes to check the L1 and L2 caches on recent processors (e.g., 3 ns on a 4 GHz Intel Kabylake [2], 9 ns on an ARM Cortex-A57 in an AMD Opteron A1170 [1]), implementing IDFs without notable latency seems feasible. In more detail, one or more bits can be embedded into each PTE that select from a list, via one level of indirection, which SDID should be used when accessing the respective page.Both ARM and Intel processors already support a similar mechanism to describe memory attributes of a memory mapping. Furthermore, by reusing the SDID of the OS, also shared memory between user space processes can easily be implemented without security impact.Interestingly, SCATTERCACHE fully preserves the capability of the OS to share read-only pages (i.e., libraries) also across security domains as no cache lines will be shared. While certain types of cache attacks, such as FLUSH+FLUSH, FLUSH+RELOAD and EVICT+RELOAD, require a particular cache line to be shared, attacks such as PRIME+PROBE have less stringent constraints and only rely on the cache being a shared resource. In particular, SCATTERCACHE maintains a separate copy of shared read-only memory in cache for each security domain, i.e., the cache lines belonging to the same shared memory region are not being shared in cache across security domains anymore. Even if attackers are able to profile information about the mapping of memory addresses to cache-sets in their own security domain, it does not allow them infer the mapping of cache-sets to memory addresses in other security domains. Many other microarchitectural attacks are not fully mitigated but hindered by SCATTERCACHE. A 4-way cache, for example, with b indices = 12 index bits yields 2 48 different cache sets, which already exceeds the address space of state-of-the-art systems. This approximation allows to determine the number of cache lines n hit that are expected to be hit in a certain cache way when n accesses random accesses to the specific way are performed.E(n hit ) = n lines · (1 − e − naccesses n lines )(1)Using n hit , we can estimate the number of independent accesses to be performed to a specific cache way such that a portion β of the respective cache way is evicted.E(n accesses ) = −n lines · ln(1 − β)For the same 8-way SCATTERCACHE with 2 11 lines per way as before, we therefore require roughly 2 16 independent accesses to evict β = 99 % of the cache. To overcome these issues, attackers may profile a system to construct eviction sets for specific memory addresses of the victim, i.e., they try to find a set of addresses that map to cache sets that partially overlap with the cache set corresponding to the victim address. For an 8-way SCATTER-CACHE with 2 11 cache lines per way, roughly 275 addresses with single-way cache collisions are needed to evict the respective cache set with 99 % probability. However, the actual attacks utilizing these sets are also made more complex by SCATTERCACHE.In this section, we make the strong assumption that an attacker has successfully profiled the victim process such that they have found addresses which collide with the victim's target addresses in exactly 1 way each, have no collisions with each other outside of these and are sorted into subsets corresponding to the cache line they collide in.Where in normal PRIME+PROBE an attacker can infer victim accesses (or a lack thereof) with near certainty after only 1 sequence of priming and probing, SCATTERCACHE degrades this into a probabilistic process. The amount of colliding addresses we need to find during profiling depends on how often a full cache flush is performed. This method requires the least amount of accesses to the target, at the cost of either execution time (full cache flushes) or memory and profiling time (constructing many eviction sets). Generally, for a PRIME+PROBE attack we need to (1) generate an eviction set (cf. Section 4.3), and (2) use the eviction set to monitor a victim memory access. Gülmezoglu et al. [29] recovered the full AES key from an AES T-tables implementation with only 30 000 encryptions in a fully synchronized setting (that can be implemented with PRIME+PROBE as well [26]), taking 15 seconds, i.e., 500 µs per encryption. Namely, on real systems cache attacks will suffer from both systematic and random noise, which reduces the effectiveness of profiling and the actual attack.Systematic noise is introduced, for example, by the victim as it executes longer code sequences in between the attacker's prime and probe steps. Also when probing addresses of an eviction set in an actual attack, random noise is likely to be sampled as attacks on SCATTERCACHE demand for large eviction sets. Additionally, systematic and random noise introduced during both profiling and attack further increase the complexity of actual attacks, rendering attacks on most real-world systems impractical. Additionally, to closer investigate the impact of SCATTERCACHE on larger workloads, a custom cache simulator is used for SPEC CPU 2017 benchmarks. Besides SCATTERCACHE in both variants (1) SCv1 and (2) SCv2 and standard set-associative caches with (3) LRU, (4) BIP, and (5) random replacement, we also evaluated (6) skewed associative caches [63] with random replacement as we expect them to have similar performance characteristics as SCv1 and SCv2.On the software side, we used the Poky Linux distribution from Yocto 2.5 (Sumo) with kernel version 4.14.67 after applying patches to run within gem5. We are therefore confident that, if desired, hiding the latency of the IDF by computing it in parallel to the lower level cache lookup is feasible.However, we still also conducted simulations with latency overheads between 1 and 5 cycles by increasing the tag_latency of the cache in gem5. For example, the 8-way SCv1 SCATTERCACHE with 512 kB that is simulated in the following section, uses two parallel instances of QARMA-64 with 5 rounds as IDF. Interestingly, with similar size, also a sponge-based SCv1 IDF (e.g., 12 rounds of Keccak[200] [11]) can be instantiated. b c k r o n b c u r a n d b f s k r o n b f s u r a n d c c k r o n c c u r a n d p r k r o n p r u r a n d s s s p k r o n s s s p u r a n d t c k r o n t c u r a n d m e a n 0 BIP LRU Rand SCv1 SCv2 Skewed Figure 10: Cache hit rate, simulated with gem5, for scimark2. However, in some individual benchmarks (e.g., qsort in small, jpeg in large), skewed cache architectures like SCAT-TERCACHE outmatch the fixed set appraoches.In summary, our evaluations with gem5 in full system simulation mode show that the performance of SCATTERCACHE, in terms of hit rate, is basically identical to contemporary fixed set-associative caches with random replacement policy. On a larger configuration with 64 B cache lines, 32 kB 8-way L1 and 2 MB 16-way LLC, the results show a slim improvement of 0.035 ± 0.10 pp for SCATTERCACHE and 0.37 ± 1.14 pp for LRU over random replacement. This project has received funding from the European Research Council (ERC) under Horizon 2020 grant agreement No 681402. The simulator implements the set-associative replacement policies Pseudo-LRU (Tree-PLRU), LRU (ideal), BIP as described in [56], and random replacement, as well as the two x a l a n c b m k x z m e a n Lastly, we evaluated the performance of SCATTERCACHE using the SPEC CPU 2017 [66] benchmark with both the "SPECspeed 2017 Integer" and "SPECspeed 2017 Floating Point" suites.