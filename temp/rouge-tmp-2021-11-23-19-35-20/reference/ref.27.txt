We present a new approach for detecting credential spearphishing attacks in enterprise settings. Comparing our anomaly scoring method against standard anomaly detection techniques, we find that standard techniques using the same features would need to generate at least 9 times as many alerts as our method to detect the same number of attacks. However, in our work, which draws upon several years worth of data from the Lawrence Berkeley National Lab (LBNL), a large national lab supported by the US Department of Energy, none of the successful spearphishing attacks involved a malicious attachment. Thus, although other forms of spearphishing constitute an important threat, credential spearphishing poses a major and unsolved threat in-and-of itself.Our work presents a new approach for detecting credential spearphishing attacks in enterprise settings. Second, we introduce a simple, new anomaly detection technique (called DAS) that requires no labeled training data and operates in a non-parametric fashion. Combining these two ideas together, we present the design of a real-time detector for credential spearphishing attacks.Working with the security team at LBNL, we evaluated our detector on nearly 4 years worth of email data (about 370 million emails), as well as associated HTTP logs. Whereas regular phishing emails primarily aim to make money by deceiving any arbitrary user [18,22], spearphishing attacks are specifically targeted at users who possess some kind of privileged access or capability that the adversary seeks. To accomplish this, Mallory needs to imbue her email with a Previously Unseen Attacker "Enterprise X IT Staff" <director@enterpriseY.com> Lateral Attacker "Alice Good" <alice@enterpriseX.com> Name Spoofer "Alice Good" <alice@evil.com> Address Spoofer "Alice" <alice@enterpriseX.com> Real User "Alice Good" <alice@enterpriseX.com> Figure 1: Examples of four different impersonation models for a real user "Alice Good". In the address spoofer impersonation model, an attacker might also spoof the username to exactly match the true user's (e.g., by using Alice Good instead of just Alice). Attackers typically achieve this by sending the email under the identity of a trusted or authoritative entity and then including some compelling content in the email.Impersonation Model: Spearphishing involves impersonating the identity of someone else, both to create trust in the recipient and also to to minimize the risk of attribution and punishment. Three types of exploitation are commonly seen: (i) attachments or URLs that contain malware, (ii) URLs leading to websites that attempt to trick Alice into revealing her credentials, and (iii) out-of-band actions (e.g., tricking a company's CFO into wiring money to a fake, malicious "corporate partner"). We assume that the adversary can send arbitrary emails to the victim and can convince the recipient to click on URLs embedded in the adversary's email (leading the victim to a credential phishing website). The LDAP logs contain one entry for each login where an employee authenticated from an IP address that he/she has never used in prior (successful) logins.false alarms per day that take at most minutes for an incident response team to process. Given that current methods for detecting credential spearphishing often rely on users to report an attack, if our approach can detect even a moderate number of true positives or identify undiscovered attacks, while achieving a low false positive rate, then it already serves as a major improvement to the current state of detection and mitigation. These logs contain information about all emails sent to and from the organization's employees (including emails between two employees), a total of 372,530,595 emails. LBNL has a distributed network monitor (Bro) that logs all HTTP GET and POST requests that traverse its borders. 1 Each time any URL embedded in an email gets visited as the destination of an HTTP request, the NIDS will record information about the request, including the URL that was visited and the entry in the SMTP logs for the email that contained the fetched URL. From these LDAP logs, we received anonymized information about login sessions where (1) the login IP address had never been used by the user during any previous successful login, (2) the user had more than 25 prior logins, and (3) the login IP address did not belong to LBNL's network. rates (FPR) are 1% or higher, which is far too high for our setting: a FPR of 1% would lead to 3.7 million false alarms on our dataset of nearly 370 million.In this section, we identify several issues that make spearphishing detection a particularly difficult challenge. Specifically, when operating on a real-world volume of millions of emails per week, the diversity of benign behavior produces an untenable number of false positives for detectors that merely look for anomalous header values. Thus, even if one ran a detector retrospectively to alert on every email with a From name that had never been seen before and did not eventually become an active and engaged sender, it would produce over 1.1 million alerts: a false positive rate of less than 1% on our dataset of nearly 370 million emails, but still orders of magnitude more than our target. Even though spam might account for a proportion of these emails with new From names, LBNL's security staff investigated a random sample of these emails and found a spectrum of benign behavior: event/conference invitations, mailing list management notices, trial software advertisements, and help support emails. Generating an alert for each of these emails would far exceed our target of 10 alerts per day.This large number of new email addresses per From name stems from a variety of different sources: work vs. personal email addresses for a user, popular human names where each email address represents a different person in real life (e.g., multiple people named John Smith), professional society surveys, and functionality-specific email addresses (e.g. Foo <noreply@foo.com>, Foo <help@foo.com>, Foo <donate@foo.com>). For example, consider the case where Alice suddenly sends email from a new email address, whose domain is a large email hosting provider; this could either correspond to Alice sending email from her personal email account, or it might rep-resent a name spoofer using a Gmail account with a spoofed From name.Given the prevalence of emails with anomalous, yet benign, header values, a practical detector clearly needs to leverage additional signals beyond an email's header values. 3 Thus, we analyze every email that contains a link that a user clicked on; we call this clicked link a click-in-email event.As discussed in our taxonomy ( § 2.1), spearphishing attacks consist of two necessary stages: the lure stage, where the attacker persuades the victim to trust him, and the exploit stage, where the victim performs a dangerous action for the attacker. Prior work has often used features that capture only the lure or the exploit; our insight is that we can do significantly better by using both types of features.Accordingly, we have two classes of features: domain reputation features, and sender reputation features. Effectively, the sender reputation features capture elements of the lure (by recognizing different types of spoofing that the attacker might use to gain the victim's trust), and the domain reputation features capture characteristics of the exploit.Because the sender reputation features differ for each impersonation model ( § 5.2.2), our detector actually consists of three sub-detectors, one for each impersonation model. Based on these two ideas, the first feature counts the number of prior visits to any URL with the same fully qualified domain name (FQDN) as the clicked URL; this is a global count across all employees' visits, from the NIDS logs. Additionally, using a coarser granularity such as the URL's registered domain name or its effective second-level domain could allow attackers to acquire high reputation attack URLs by hosting their phishing webpages on popular hosting sites (e.g., attacker.blogspot.com). Intuitively, the idea is that From names that frequently and consistently send emails will be perceived as familiar and trustworthy.Previously Unseen Attacker: In this threat model ( § 2.1.1), Mallory chooses a name and email address that resembles a known or authoritative entity, but where the name and email address do not exactly match any existing entity's values (e.g.,IT Support Team <helpdesk@company.net>); if the name or address did exactly match an existing entity, the attack would instead fall under the name spoofer or address spoofer threat model. It then extracts two features: the number of distinct employees that have logged in from city C, and the number of previous logins where this sender-employee logged in from an IP address that geolocated to city C.Content-Based Features: As discussed in Section 3, for privacy reasons we do not have access to either the bodies of emails or the contents of a clicked URL's webpage. Then, in the following subsection, we present a new technique that our detector uses to overcome the limitations of these canonical approaches.Manual Thresholds: The simplest approach would be to manually select a threshold for each feature, and generate an alert if all feature values are below the threshold. While the machine learning community has explored a number of techniques for addressing imbalanced training data [6,10], such as undersampling the over-represented class or synthetically generating samples for the under-represented class, these techniques do not scale to imbalances on the order of millions to one.Standard Anomaly Detection: Alternatively, one might consider unsupervised or semi-supervised anomaly detection techniques. While a number of such techniques exist, including density estimation techniques such as Gaussian Mixture Models (GMMs) [5] and clustering and distance-based techniques such as k-nearestneighbor (kNN) [13], these classical techniques suffer from three limitations.First, in a number of security settings, scalar features often have a directionality to their values; and indeed, all of our features have this property. Consequently, in our setting, classical techniques will generate Algorithm 1 Scoring and Alert Selection in DAS Score(E, L):1: for each event X in L do: 2:if E is more suspicious than X in every dimension: 3:Increment E's score by oneAlertGen(L (a list of events), N):1: for each event E in L do: 2:Score(E, L) 3: Sort L by each event's score 4: return the N events from L with the highest scores many spurious alerts for events that are only anomalous in a few dimensions. As we show in Section 6.3, this causes classical techniques to miss the vast majority of spearphishing attacks in our dataset because they exhaust their alert budget with emails that have benign feature values in all but one dimension.Third, classical techniques are parametric: they either assume the data comes from a particular underlying distribution, or they contain a number of parameters that must be correctly set by their deployer in order for the technique to obtain acceptable performance. Once all events have been ranked, DAS simply selects the N most suspicious (highest-ranked) events, where N is the security team's alert budget.Algorithm 1 shows the procedure for scoring and generating alerts with DAS. Concretely, DAS first assigns an anomaly score for each event, E, by computing the total number of other events where E's feature vector is at least as suspicious as the other event in every feature dimension. As we show in Section 6, DAS achieves orders-of-magnitude better results than classical anomaly detection techniques because it leverages domain knowledge about which regions of the feature space are most suspicious; in particular, it overcomes all three limitations of classical techniques discussed in Section 5.3. Our detector has access to the enterprise's log data, realtime network traffic (e.g., via a NIDS like Bro), and an alert budget β for each sub-detector, which specifies the daily volume of alerts that the security team deems acceptable. We evaluated our real-time detector on our dataset of 370 million emails from LBNL, measuring its detection performance (true positives), the time burden (false positives) it imposes on an enterprise's security staff, and how it performs relative to standard anomaly detection techniques that use the same set of features.For each click-in-email event, we computed its reputation features using log data from a sliding window over the six months prior to the click event. To divide this budget among each of our three sub-detectors, we allocated 4 alerts per day for each of the name spoofer and previously unseen attacker sub-detectors and 2 alerts per day for our lateral attacker sub-detector; since lateral spearphishing requires the use of a compromised account, we expect it to occur less often than spoofing-based spearphishing. From this procedure, we identified a total of 19 spearphishing campaigns: 9 which succeeded in stealing an employee's credentials and 10 where the employee clicked on the spearphishing link, but upon arriving at the phishing landing page, did not enter their credentials. Overall, our real-time detector successfully identifies 17 out of 19 spearphishing campaigns, a 89% true positive rate.Of these, LBNL's incident database contained 7 known, successful spearphishing campaigns (their incident database catalogues successful attacks, but not ones that fail). At a daily budget of 10 alerts per day, our detector achieved an average false positive rate of 0.004% (the median number of emails per day is 263,086). Surprisingly, LBNL's security staff reported that a single analyst could process an entire month's worth of alerts in under 15 minutes (and thus, on average, under one minute to analyze one day's worth of alerts). For example, emails with subjects such as "Never Lose Your Keys, Wallet, or Purse Again!" See Video Here" are surely not spearphishing attacks.While the more time-intensive 2% of alerts contained mostly false positives (i.e., not spearphishing), the analysts found two interesting classes of alerts. For quantitative comparisons, we computed (1) the number of attacks that would have been detected by each classical technique if it used the same budget that our real-time detector used and (2) the daily budget the classical technique would need to detect all of the attacks that our DAS-driven detector identified.Like other machine learning methods, these classical algorithms require the user to set various hyperparameters that affect the algorithm's performance. Moreover, in order for KDE (the best performing classical technique) to detect as many attacks as DAS, it would need a daily budget nearly an order of magnitude larger than ours.To illustrate why standard unsupervised techniques perform so poorly, the two plots in Figure 7 show the sender reputation features for a random sample of 10,000 lateral attacker click-in-email events. For each of the standard anomaly detection algorithms, the first row shows the number of attacks detected under the same daily budget as ours; the second row shows what the classical technique's budget would need to be to detect all 17 attacks that our realtime detector identified on a daily budget of 10 alerts per day.of points in the upper-right corner, which illustrates one of limitations of standard techniques discussed in Section 5.4: they do not take into account the directionality of feature values. Because extremely large feature values occur infrequently, KDE ranks those events as highly anomalous, even though they correspond to benign login sessions where the user happened to login from a new IP address in a residential city nearby LBNL. Both of these are typical challenges that network-level monitoring faces in practice.One strategy for alleviating this problem would be to use endpoint monitoring agents on employee machines. Since our detector relies on access to a user's prior login information to detect lateral spearphishing attacks, it will not have the necessary data to compute the features for this sub-detector. In particular, rather than treating an event E as more suspicious than another event X only if E is more suspicious than X in every dimension, the scoring algorithm could be changed to treat E as more suspicious if it is more suspicious than X in at least k dimensions.Prior History for Feature Extraction: For each clickin-email event, our detector leveraged 6 months of prior log data in order to compute meaningful reputation features. This prior work cannot detect spearphish sent by a previously unseen attacker since the sender has no prior history (and thus no behavioral model to compare the attack email against). Two key contributions enabled our detector to achieve practical performance: (1) a new set of features that targets the two fundamental stages of successful spearphishing attacks, and (2) a new anomaly detection technique that leverages these features to detect attacks, without the need for any labeled training data.We evaluated our approach on an anonymized dataset of over 370 million emails collected from a large national lab. Name spoofer Features Comparator for DAS Host age of clicked URL ≤ (email ts − domain's 1st visit ts) # visits to clicked URL's host prior to email ts ≤ # weeks that From name has ≥ sent email on ≥ 5 days # days that From name and From addr ≤ have appeared together in emails Table 5: Summary of the feature vector for our name spoofer sub-detector and the "suspiciousness" comparator we provide to DAS for each feature. From these figures, we see that over 95% of employees would see fewer than 10 interstitials across the entire time span of nearly 3.5 years.