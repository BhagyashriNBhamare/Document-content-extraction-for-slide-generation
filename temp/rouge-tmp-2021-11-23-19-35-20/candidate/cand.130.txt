This isolation is a cornerstone of our computing environments and allows running multiple applications at the same time on personal devices or executing processes of multiple users on a single machine in the cloud.On modern processors, the isolation between the kernel and user processes is typically realized by a supervi-sor bit of the processor that defines whether a memory page of the kernel can be accessed or not. Instead, Meltdown exploits side-channel information available on most modern processors, e.g., modern Intel microarchitectures since 2010 and potentially on other CPUs of other vendors.While side-channel attacks typically require very specific knowledge about the target application and are tailored to only leak information about its secrets, Meltdown allows an adversary who can run code on the vulnerable processor to obtain a dump of the entire kernel address space, including any mapped physical memory. The root cause of the simplicity and strength of Meltdown are side effects caused by out-of-order execution.Out-of-order execution is an important performance feature of today's processors in order to overcome latencies of busy execution units, e.g., a memory fetch unit needs to wait for data arrival from memory. In this paper, we refer to speculative execution in a more restricted meaning, where it refers to an instruction sequence following a branch, and use the term out-of-order execution to refer to any way of getting an operation executed before the processor has committed the results of all prior instructions.In 1967, Tomasulo [61] developed an algorithm that enabled dynamic scheduling of instructions to allow outof-order execution. Furthermore, the reservation unit connects all execution units via a common data bus (CDB). If an operand is not available, the reservation unit can listen on the CDB until it is available and then directly begin the execution of the instruction.On the Intel architecture, the pipeline consists of the front-end, the execution engine (back-end) and the memory subsystem [32]. AGUs, as well as load and store execution units, are directly connected to the memory subsystem to process its requests.Since CPUs usually do not run linear instruction streams, they have branch prediction units that are used to obtain an educated guess of which instruction is executed next. If the prediction was incorrect, the reorder buffer allows to rollback to a sane state by clearing the reorder buffer and re-initializing the unified reservation station.There are various approaches to predict a branch: With static branch prediction [28], the outcome is predicted solely based on the instruction itself. A physical address (blue) which is mapped accessible to the user space is also mapped in the kernel space through the direct mapping.are used to enforce privilege checks, such as readable, writable, executable and user-accessible. On Linux and OS X, this is done via a direct-physical map, i.e., the entire physical memory is directly mapped to a pre-defined virtual address (cf. Figure 2). These pools are virtual memory regions in the kernel address space mapping physical pages to virtual addresses which are either required to remain in the memory (non-paged pool) or can be removed from the memory because a copy is already stored on the disk (paged pool). Combined, these memory pools will typically map a large fraction of the physical memory into the kernel address space of every process.The exploitation of memory corruption bugs often requires knowledge of addresses of specific data. The Flush+Reload attack has been used for attacks on various computations, e.g., cryptographic algorithms [63,36,4], web server function calls [65], user input [23,47,58], and kernel addressing information [21]. However, despite its simplicity, it is used as a basis for Section 4 and Section 5, where we show how this change in state can be exploited for an attack.Listing 1 shows a simple code snippet first raising an (unhandled) exception and then accessing an array. Regardless 1 raise_exception(); 2 // the line below is never reached 3 access(probe_array [data * 4096] of whether this exception is raised due to a memory access, e.g., by accessing an invalid address, or due to any other CPU exception, e.g., a division by zero, the control flow continues in the kernel and not with the next user space instruction. We can leverage a microarchitectural side-channel attack such as Flush+Reload [63], which detects whether a specific memory location is cached, to make this microarchitectural state visible. As data is multiplied by 4096, data accesses to probe array are scattered over the array with a distance of 4 KB (assuming an 1 B data type for probe array). A trivial approach is to fork the attacking application before accessing the invalid memory location that terminates the process and only access the invalid memory location in the child process. Note that the receiver is not part of the transient instruction sequence and can be a different thread or even a different process e.g., the parent process in the fork-and-crash approach.We leverage techniques from cache attacks, as the cache state is a microarchitectural state which can be reliably transferred into an architectural state using various techniques [55,63,22]. Thus, depending on the secret value, the transient instruction sequence (cf. Section 4.1) performs a regular memory access, e.g., as it does in the toy example (cf. Section 3). Thus, the sender can transmit a '1'-bit by accessing an address which is loaded into the monitored cache, and a '0'-bit by not accessing such an address.Using multiple different cache lines, as in our toy example in Section 3, allows to transmit multiple bits at once. The advantage of the Flush+ Reload cache covert channel is the noise resistance and the high transmission rate [22]. Most importantly, we assume a completely bug-free operating system, thus, no 1 ; rcx = kernel address, rbx = probe array 2 xor rax, rax 3 retry: 4 mov al, byte [rcx] 5 shl rax, 0xc 6 jz retry 7 mov rbx, qword [rbx + rax] Listing 2: The core of Meltdown. The transient instruction sequence acts as the transmitter of a covert channel (cf. Section 4.2), ultimately leaking the secret value to the attacker.Meltdown consists of 3 steps:Step 1 The content of an attacker-chosen memory location, which is inaccessible to the attacker, is loaded into a register.Step 2 A transient instruction accesses a cache line based on the secret content of the register.Step 3 The attacker uses Flush+Reload to determine the accessed cache line and hence the secret stored at the chosen memory location. Hence, modern operating systems always map the entire kernel into the virtual address space of every user process.As a consequence, all kernel addresses lead to a valid physical address when translating them, and the CPU can access the content of such addresses. However, Meltdown exploits the out-of-order execution of modern CPUs, which still executes instructions in the small time window between the illegal memory access and the raising of the exception.In line 4 of Listing 2, we load the byte value located at the target kernel address, stored in the RCX register, into the least significant byte of the RAX register represented by AL. If this transient instruction sequence is executed before the MOV instruction is retired (i.e., raises the exception), and the transient instruction sequence performed computations based on the secret, it can be utilized to transmit the secret to the attacker.As already discussed, we utilize cache attacks that allow building fast and low-noise covert channels using the CPU's cache. Hence, our probe array is 256 × 4096 bytes, assuming 4 KB pages.Note that in the out-of-order execution we have a noise-bias towards register value '0'. The position of the cached cache line within the probe array depends only on the secret which is read in step 1. However, as the memory access to the kernel address raises an exception that terminates the program, we use one of the methods from Section 4.1 to handle or suppress the exception.As all major operating systems also typically map the entire physical memory into the kernel address space (cf. Section 2.2) in every user process, Meltdown can also read the entire physical memory of the target machine. Inherent bias towards 0. In either case, the time until exception handling or exception suppression returns the control flow is independent of the loop after the invalid memory access, i.e., the loop does not slow down the attack measurably. Hence, the number of bits read and transmitted at once is a tradeoff between some implicit error-reduction and the overall transmission rate of the covert channel.However, since the error rates are quite small in either case, our evaluation (cf. Section 6) is based on the singlebit transmission mechanics.Exception Suppression using Intel TSX. This results in higher channel capacity, as suppressing the exception is significantly faster than trapping into the kernel for handling the exception, and continuing afterward.Dealing with KASLR. Thus, all kernel addresses are also mapped into the address space of user space applications, but any access is prevented due to the permission settings for these addresses.As Meltdown bypasses these permission settings, an attacker can leak the complete kernel memory if the virtual address of the kernel base is known. Consequently, Meltdown cannot leak any kernel or physical memory except for the few memory locations which have to be mapped in user space.We verified that KAISER indeed prevents Meltdown, and there is no leakage of any kernel or physical memory.Furthermore, if KASLR is active, and the few remaining memory locations are randomized, finding these memory locations is not trivial due to their small size of several kilobytes. This is not surprising, since Meltdown does not exploit any software issues, but is caused by a hardware issue.In contrast to Linux, Windows does not have the concept of an identity mapping, which linearly maps the physical memory into the virtual address space. Thus, Meltdown can read kernel memory which is mapped in the kernel address space, i.e., any part of the kernel which is not swapped out, and any page mapped in the paged and non-paged pool, and the system cache.Note that there are physical pages which are mapped in one process but not in the (kernel) address space of another process, i.e., physical pages which cannot be attacked using Meltdown. Running Meltdown inside a container allows to leak information not only from the underlying kernel but also from all other containers running on the same physical host.The commonality of most container solutions is that every container uses the same kernel, i.e., the kernel is shared among all containers. We observed that if the attacker is able to trigger a legitimate load of the target address, e.g., by issuing a system call (regular or in speculative execution [40]), on the same CPU core as the Meltdown attack, the attacker can leak the content of the uncacheable pages. With the Core i7-6700K we achieved 569 KB/s (µ = 515.5, σ = 5.99) with an minimum error rate of 0.002 % (µ = 0.003, σ = 0.001) and 491 KB/s (µ = 466.3, σ = 16.75) with a minimum error rate of 10.7 % (µ = 11.59, σ = 0.62) on the Xeon E5-1630. However, as the state becomes visible on the microarchitectural level, such implementations are vulnerable.However, for both ARM and AMD, the toy example as described in Section 3 works reliably, indicating that out-of-order execution generally occurs and instructions past illegal memory accesses are also performed. There is no documentation whether a fix requires the development of completely new hardware, or can be fixed using a microcode update.As Meltdown exploits out-of-order execution, a trivial countermeasure is to disable out-of-order execution completely. Thus, this is not a viable solution.Meltdown is some form of race condition between the fetch of a memory address and the corresponding permission check for this address. With this hard split, a memory fetch can immediately identify whether such a fetch of the destination would violate a security boundary, as the privilege level can be directly derived from the virtual address without any further lookups. As the Linux kernel continued the development of the original KAISER patch and Windows [53] and macOS [34] based their implementation on the concept of KAISER to defeat Meltdown, we will discuss KAISER in more depth.Although KAISER provides basic protection against Meltdown, it still has some limitations. Meltdown fundamentally changes our perspective on the security of hardware optimizations that manipulate the state of microarchitectural elements. The fact that hardware optimizations can change the state of microarchitectural elements, and thereby imperil secure software implementations, is known since more than 20 years [41]. Meltdown shifts the granularity from a comparably low spatial and temporal granularity, e.g., 64-bytes every few hundred cycles for cache attacks, to an arbitrary granularity, allowing an attacker to read every single bit. For these providers, changing their infrastructure to full virtualization or using software workarounds such as KAISER would both increase the costs significantly.Concurrent work has investigated the possibility to read kernel memory via out-of-order or speculative execution, but has not succeeded [13,50]. In this paper, we presented Meltdown, a novel softwarebased attack exploiting out-of-order execution and side channels on modern processors to read arbitrary kernel memory from an unprivileged user space program. Without requiring any software vulnerability and independent of the operating system, Meltdown enables an adversary to read sensitive data of other processes or virtual machines in the cloud with up to 503 KB/s, affecting millions of devices. The exploit dumps the memory of a specific process, provided either the process id (PID) or the process name.First, the exploit de-randomizes the kernel address space layout to be able to access internal kernel structures. Finally, the root of the victim's multilevel page table is extracted from the task structure and traversed to dump any of the victim's pages.The three steps of the exploit are combined to an endto-end exploit which targets a specific kernel build and a specific victim. If the direct-physical map is randomized, it can be extracted from the kernel's page offset base variable.Starting at the root of the victim's multilevel page table, the exploit can simply traverse the levels down to the lowest level.