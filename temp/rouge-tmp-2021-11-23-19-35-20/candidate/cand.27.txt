We also establish that our detector's false positive rate is low enough to be practical: on average, a single analyst can investigate an entire month's worth of alerts in under 15 minutes. Leveraging these attacks, adversaries have successfully compromised a wide range of government systems (e.g., the US State Department and the White House [1]), prominent companies (e.g., Google and RSA [3]), and recently, political figures and organizations (e.g., John Podesta and the DNC [21]). From a defender's perspective, spearphishing is difficult to counter due to email's susceptibility to spoofing and because attackers thoughtfully handcraft their attack emails to appear legitimate. First, we present an analysis of character-istics that we argue are fundamental to spearphishing attacks; from this analysis, we derive a set of features that target the different stages of a successful spearphishing attack. Whereas regular phishing emails primarily aim to make money by deceiving any arbitrary user [18,22], spearphishing attacks are specifically targeted at users who possess some kind of privileged access or capability that the adversary seeks. To accomplish this, Mallory needs to imbue her email with a Previously Unseen Attacker "Enterprise X IT Staff" <director@enterpriseY.com> Lateral Attacker "Alice Good" <alice@enterpriseX.com> Name Spoofer "Alice Good" <alice@evil.com> Address Spoofer "Alice" <alice@enterpriseX.com> Real User "Alice Good" <alice@enterpriseX.com> Figure 1: Examples of four different impersonation models for a real user "Alice Good". Attackers typically achieve this by sending the email under the identity of a trusted or authoritative entity and then including some compelling content in the email.Impersonation Model: Spearphishing involves impersonating the identity of someone else, both to create trust in the recipient and also to to minimize the risk of attribution and punishment. In recent years, these protocols have seen increasingly widespread adoption, with many large email providers, such as Gmail, deploying them in response to the rise of phishing attacks [4].2. A previously unseen attacker selects a name and email address to put in the From field of the spearphishing email, where neither the name nor the email address actually match a true user's name or email address (though they might be perceived as trustworthy or similar to a real user's identity). Once Mallory has gained Alice's trust, she then needs to exploit this trust by inducing Alice to perform some dangerous action. Three types of exploitation are commonly seen: (i) attachments or URLs that contain malware, (ii) URLs leading to websites that attempt to trick Alice into revealing her credentials, and (iii) out-of-band actions (e.g., tricking a company's CFO into wiring money to a fake, malicious "corporate partner"). Given that current methods for detecting credential spearphishing often rely on users to report an attack, if our approach can detect even a moderate number of true positives or identify undiscovered attacks, while achieving a low false positive rate, then it already serves as a major improvement to the current state of detection and mitigation. Table 1 shows the relevant information in these datasets and Table 2 summarizes the size and timeframe of our data. The SMTP logs contain anonymized SMTP headers for all inbound and outbound emails during the Mar 1, 2013 -Jan 14, 2017 time period. The NIDS remembers URLs for at least one month after an email's arrival; all HTTP visits to a URL are matched to the earliest email that contained the URL.We received anonymized logs of all HTTP requests, with a keyed hash applied to each separate field. rates (FPR) are 1% or higher, which is far too high for our setting: a FPR of 1% would lead to 3.7 million false alarms on our dataset of nearly 370 million.In this section, we identify several issues that make spearphishing detection a particularly difficult challenge. For example, consider the case where Alice suddenly sends email from a new email address, whose domain is a large email hosting provider; this could either correspond to Alice sending email from her personal email account, or it might rep-resent a name spoofer using a Gmail account with a spoofed From name.Given the prevalence of emails with anomalous, yet benign, header values, a practical detector clearly needs to leverage additional signals beyond an email's header values. Effectively, the sender reputation features capture elements of the lure (by recognizing different types of spoofing that the attacker might use to gain the victim's trust), and the domain reputation features capture characteristics of the exploit.Because the sender reputation features differ for each impersonation model ( § 5.2.2), our detector actually consists of three sub-detectors, one for each impersonation model. While a number of such techniques exist, including density estimation techniques such as Gaussian Mixture Models (GMMs) [5] and clustering and distance-based techniques such as k-nearestneighbor (kNN) [13], these classical techniques suffer from three limitations.First, in a number of security settings, scalar features often have a directionality to their values; and indeed, all of our features have this property. Consequently, in our setting, classical techniques will generate Algorithm 1 Scoring and Alert Selection in DAS Score(E, L):1: for each event X in L do: 2:if E is more suspicious than X in every dimension: 3:Increment E's score by oneAlertGen(L (a list of events), N):1: for each event E in L do: 2:Score(E, L) 3: Sort L by each event's score 4: return the N events from L with the highest scores many spurious alerts for events that are only anomalous in a few dimensions. As we show in Section 6.3, this causes classical techniques to miss the vast majority of spearphishing attacks in our dataset because they exhaust their alert budget with emails that have benign feature values in all but one dimension.Third, classical techniques are parametric: they either assume the data comes from a particular underlying distribution, or they contain a number of parameters that must be correctly set by their deployer in order for the technique to obtain acceptable performance. GMMs assume the data comes from a mixture of Gaussian distributions, KDE has a bandwidth parameter that requires tuning by the deployer, and kNN needs the deployer to select a value of k (the number of nearest neighbors/most similar events, which the algorithm will use to compute an event's anomaly score). Concretely, DAS first assigns an anomaly score for each event, E, by computing the total number of other events where E's feature vector is at least as suspicious as the other event in every feature dimension. After scoring every event, our algorithm simply sorts all events by their scores and outputs the N highest-scoring events.Formally, we identify each event with its feature vector E ∈ R d . As we show in Section 6, DAS achieves orders-of-magnitude better results than classical anomaly detection techniques because it leverages domain knowledge about which regions of the feature space are most suspicious; in particular, it overcomes all three limitations of classical techniques discussed in Section 5.3. Our detector has access to the enterprise's log data, realtime network traffic (e.g., via a NIDS like Bro), and an alert budget β for each sub-detector, which specifies the daily volume of alerts that the security team deems acceptable. However, this might miss attacks that would have been detected by the batch algorithm, as some days might have many benign but seeminglysuspicious events that mask a true attack.Instead, we use a more sophisticated algorithm that comes closer to the batch algorithm, yet operates in real time. We evaluated our real-time detector on our dataset of 370 million emails from LBNL, measuring its detection performance (true positives), the time burden (false positives) it imposes on an enterprise's security staff, and how it performs relative to standard anomaly detection techniques that use the same set of features.For each click-in-email event, we computed its reputation features using log data from a sliding window over the six months prior to the click event. Out of 19 spearphishing attacks, our detector failed to detect 2 attacks (one that successfully stole an employee's credentials and one that did not); both of these missed attacks fall under the previously unseen attacker threat model, where neither the username nor the email address matched an existing entity.7 known successful spearphishing attacks; this includes 1 spearphishing exercise, designed by an external security firm and conducted independently of our work, that successfully stole employee credentials. We generated these alerts from a combination of running (1) an older version of our detector that used manually chosen thresholds instead of the DAS algorithm; and (2) a batched version of our anomaly scoring detector, which ran the full DAS scoring procedure over the click-in-email events in our evaluation window (Sep. 2013 onward) and selected the highest scoring alerts within the cumulative budget for that timeframe. Even for specific public examples, without actual historical log data one can only speculate on what the values of our reputation features should be.To evaluate our true positive rates, we ran our realtime detector ( § 5.5) on each attack date, with a budget of 10 alerts per day. This rapid processing time arises because the analysts were able to develop a two-pass workflow that enabled them to quickly discard over 98% of the alerts, at a rate of 2 seconds per alert; and then follow up with a more indepth analysis pass (e.g., analyzing detailed HTTP logs and examining the full email headers) over the remaining 2% of alerts, at a rate of 30 seconds per alert. Now, we evaluate the effectiveness of DAS compared to traditional unsupervised anomaly detection techniques.We tested three common anomaly detection techniques from the machine learning literature: Kernel Density Estimation (KDE), Gaussian Mixture Models (GMM), and k-Nearest Neighbors (kNN) [5]. We then normalized these feature values and ran each of the three classical anomaly detection techniques on this set of click-in-email events for each attack date. Moreover, in order for KDE (the best performing classical technique) to detect as many attacks as DAS, it would need a daily budget nearly an order of magnitude larger than ours.To illustrate why standard unsupervised techniques perform so poorly, the two plots in Figure 7 show the sender reputation features for a random sample of 10,000 lateral attacker click-in-email events. Both of these are typical challenges that network-level monitoring faces in practice.One strategy for alleviating this problem would be to use endpoint monitoring agents on employee machines. Alternatively, a detector could leverage SNI [23] to develop its domain reputation for HTTPS and identify when users visit potentially dangerous HTTPS domains.In addition to limited network visibility, our detector might miss attacks if a spearphishing email came from a compromised personal email account. To overcome this problem, the security staff could increase the detector's alert budget on days with many attack alerts.Aside from trying to mask one attack campaign with another, an adversary could attempt to escape detection by crafting an email whose domain or sender reputation features are high. For example, if an adversary compromises a popular video website (e.g., netflix.com), many users might find it unusual for that popular domain to suddenly start asking for the user's enterprise credentials.Alternatively, an attacker could attempt to inflate the sender reputation features of their adversarial email before using it in an attack. With just one month of prior data, too many click-in-email events have the smallest possible feature values; this causes our detector to select entire batches of them because they share the same DAS score.Extending to Preventative Protection: One could extend our real-time detector to operate in a preventative fashion. Our computations show that if we used our real-time detector with a budget of 10 alerts/day, an employee would encounter a median of 2 interstitial pages over the nearly 4-year time span of our evaluation data (Appendix B). Closest to our work, the systems proposed by Stringhini et al. [19], Duman et al. [8], and Khonji et al. [12] build behavioral models for senders based on metadata, stylometry, and timing features. Two key contributions enabled our detector to achieve practical performance: (1) a new set of features that targets the two fundamental stages of successful spearphishing attacks, and (2) a new anomaly detection technique that leverages these features to detect attacks, without the need for any labeled training data.We evaluated our approach on an anonymized dataset of over 370 million emails collected from a large national lab.