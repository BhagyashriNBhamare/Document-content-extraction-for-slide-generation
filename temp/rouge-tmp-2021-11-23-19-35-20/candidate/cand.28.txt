In order to effectively contain advanced attack campaigns, analysts need a new generation of tools that not only assist with detection but also produce a compact summary of the causal chains that summarize an attack. Such a summary would enable an analyst to quickly ascertain whether there is a significant intrusion, understand how the attacker initially breached security, and determine the impact of the attack.The problem of piecing together the causal chain of events leading to an attack was first explored in Backtracker [25,26]. Dealing with common usage scenarios: How does one cope with normal, benign activities that may resemble activities commonly observed during attacks, e.g., software downloads? Experiments show that our tagbased approach is very effective: for instance, SLEUTH can analyze 38.5M events and produce an attack scenario graph with just 130 events, representing five orders of magnitude reduction in event volume.The fourth contribution of this paper, aimed at tackling the last two challenges mentioned above, is a customizable policy framework (Section 4) for tag initialization and propagation. Since we can process and analyze audit data tens of thousands of times faster than the rate at which it is generated, efficient, parallel, real-time testing of alternate hypotheses is possible.The final contribution of this paper is an experimental evaluation (Section 6), based mainly on a red team evaluation organized by DARPA as part of its Transparent Computing program. In this evaluation, SLEUTH was able to:• process, in a matter of seconds, audit logs containing tens of millions of events generated during the engagement;• successfully detect and reconstruct the details of these attacks, including their entry points, activities in the system, and exfiltration points;• filter away extraneous events, achieving very high reductions rates in the data (up to 100K times), thus providing a clear semantic representation of these attacks containing almost no noise from other activities in the system; and• achieve low false positive and false negative rates.Our evaluation is not intended to show that we detected the most sophisticated adversary; instead, our point is that, given several unknown possibilities, the prioritized results from our system can be right on spot in real-time, without any human assistance. The number of objects/subjects in our largest data set was a few orders of magnitude smaller than this number.While our design emphasizes compact data structures for objects and subjects, compactness of events is far more important: events outnumber objects and subjects by about two orders of magnitude in our largest data set. This means that the relative index stored with object-event record can be 12 bits or less in most cases, thus allowing these records to be 16 bits or less in the typical case.This design thus allows us to store bidirectional timestamped edges in as little as 6 bytes (4 bytes for a subjectevent record and 2 bytes for an object-event record). This assessment can be based on three main factors:• Provenance: the tags on the immediate predecessors of an object or subject in the dependence graph,• Prior system knowledge: our knowledge about the behavior of important applications, such as remote access servers and software installers, and important files such as /etc/passwd and /dev/audio, and• Behavior: observed behavior of subjects, and how they compare to their expected behavior.We have developed a policy framework, described in Section 4, for initializing and propagating tags based on these factors. • Benign tag reflects a reduced level of trust than benign authentic: while the data/code is still believed to be benign, adequate authentication hasn't been performed to verify the source. More importantly, it can significantly speed up forensic analysis by focusing it on fewer suspicious events, while substantially reducing the size of the reconstructed scenario. Note that in our threat model, audit data is trustworthy, so tags provide a sound basis for detection.A second constraint in SLEUTH is that detection methods should not require detailed application-specific knowledge. This requires expert knowledge about the application, or in-the-field training in a dynamic environment, where applications may be frequently updated.Instead of focusing on application behaviors that tend to be variable, we focus our detection techniques on the high-level objectives of most attackers, such as backdoor insertion and data exfiltration. Note that our tags are designed to capture means: if a piece of data or code bears the unknown t-tag, then it was derived from (and hence influenced by) untrusted sources.As for the high-level objectives of an attacker, several reports and white papers have identified that the following steps are typical in most advanced attack campaigns [1, 2, 3]:1. Even in those cases where the attacker's goal could be achieved without establishing a permanent base, the third step usually represents an essential attacker goal.Based on the above reasoning, we define the following policies for attack detection that incorporate the attacker's objectives and means:• Untrusted code execution: This policy triggers an alarm when a subject with a higher code t-tag executes (or loads) an object with a lower t-tag 3 . Today's vulnerability exploits typically do not involve untrusted code in their first step, and hence won't be detected by the untrusted code execution policy. However, the eventual goal of an attacker is to execute his/her code, either by downloading and executing a file, or by adding execute permissions to a memory page containing untrusted data. Moreover, setting of unknown t-tag at suspect nodes preserves the dependency structure between the graph vertices that cause alarms, a fact that we exploit in our forensic analysis.The fact that many of our policies are triggered by untrusted code execution should not be interpreted to mean that they work in a static environment, where no new code is permitted in the system. We express policies using a simple rule-based notation, e.g.,exec(s, o) : o.ttag < benign → alert("UntrustedExec")This rule is triggered when the subject s executes a (file) object o with a t-tag less than benign. While we use a rule-based notation to specify policies in this paper, in our implementation, each rule is encoded as a (C++) function.To provide a finer degree of control over the order in which different types of policies are checked, we associate policies with trigger points instead of events. The first column identifies events, the second column specifies the direction of information flow, and the last two columns define the trigger points associated with these events.Note that we use a special event called define to denote audit records that define a new object. Note the use of regular expressions to conveniently define initial tags for groups of objects.init(o): match(o.name, "^IP:(10\.0|127)") → o.ttag = BENIGN AUTH, o.ctag = PRIVATE init(o): match(o.name, "^IP:") → o.ttag = UNKNOWN, o.ctag = PRIVATE init(o): o.type == FILE → o.ttag = BENIGN AUTH, o.ctag = PUBLICThe first rule specifies tags for intranet connections, identified by address prefixes 10.0 and 127 for the remote host. A similar comment applies to programs such as software updaters and installers that download code from untrusted sites, but verify the signature of a trusted software provider before the install.propRd(o, s): match(s.cmdline, "^/sbin/sshd$") → skipMoreover, when the login phase is complete, typically identified by execution of a setuid operation, the process should be assigned appropriate tags.propSu ( The goal of backward analysis is to identify the entry points of an attack campaign. In particular, if an unknown tag exists for some node A, that means that there exists at least a path from an untrusted entry node to node A, therefore node A is more likely to be part of an attack than other neighbors with benign tags. In addition, our shortest path formulation addresses the multiple paths chalenge by by preferring the entry point closest (as measured by path cost) to a suspect node.For shortest path, we use Dijkstra's algorithm, as it discovers paths in increasing order of cost. In particular, edges between nodes with high confidentiality tags (e.g., secret) and nodes with low code integrity tags (e.g., unknown process) or low data integrity tags (e.g., unknown socket) are assigned a cost of 0, while edges to nodes with benign tags are assigned a high cost. Attack data sets were collected on Windows (W-1 and W-2), Linux (L-1 through L-3) and FreeBSD (F-1 through F-3) by three research teams that are also part of the DARPA TC program. The last column in the table identifies the scenario graph constructed by SLEUTH for each campaign. The campaigns are aimed at achieving varying adversarial objectives, which include dropping and execution of an executable, gathering intelligence about a target host, backdoor injection, privilege escalation, and data exfiltration.Being an adversarial engagement, we had no prior knowledge of the attacks planned by the red team. Of the 8 attack scenarios successfully reconstructed by SLEUTH, we discuss campaigns W-2 (Windows) and F-3 (FreeBSD) in this section, while deferring the rest to Section 6.10. Backdoor insertion: Once Firefox is compromised, a malicious program called dropper is downloaded and executed. Note that though there is no direct evidence from the audit data about the stolen ssh credentials, because of the subsequent events (scp) from this shell, we conclude this as a sign of an attacker that uses stolen ssh credentials. To assess the effectiveness of SLEUTH in capturing essential stages of an APT, in Table 6, we correlate pieces of attack scenarios constructed by SLEUTH with APT stages documented in postmortem reports of notable APT campaigns (e.g., the MANDIANT [3] report). Cleaning the attack footprint is a common element of an APT campaign.W-1 W-2 L-1 L-2 L-3 F-1 F-2 F-3In our experiments, in 5 of the 8 scenarios, SLEUTH uncovered attack cleanup activities, e.g., removing dropped executables and data files created during the attack. This is because both apt and unattended-upgrades verify and authenticate the hash on the downloaded packages, and only after these verifications do they invoke dpkg to extract the contents and write to various directories containing binaries and libraries. Across all data sets, SLEUTH needed about 8 bytes of memory per event on the larger data sets, and about 20 bytes per event on the smaller data sets. It can be thought of as the number of simultaneous data streams that can be handled by SLEUTH, if CPU use was the only constraint.In summary, SLEUTH is able to consume and analyze audit COTS data from several OSes in real time while having a small memory footprint. The third column shows the final number of events that go into the attack scenario graph.The fourth column shows the reduction factor when a naive forward analysis with single trustworthiness tag (single t-tag) is used from the entry points identified by our backward analysis. The last column shows the overall reduction we get over original events using split (code and data) trustworthiness tags and performing the simplification.Overall, the combined effect of all of these steps is very substantial: data sets consisting of tens of millions of edges are reduced into graphs with perhaps a hundred edges, representing five orders of magnitude reduction in the case of L-2 and L-3 data sets, and four orders of magnitude reduction on other data. In this attack (Figure 13), the nginx server is exploited to drop and execute via shell the file dropper. The first mozillanightly process downloads and executes the file photosnap.exe, which takes a screenshot of the victim's screen and saves it to a png file. We omit comparison to proprietary products from the industry as there is scarce technical documentation available for an indepth comparison.Provenance tracking and Forensics Several logging and provenance tracking systems have been built to monitor the activities of a system [21,41,23,22,13,45,9] and build provenance graphs. Setting aside hardware comparisons, we note that Bactracker took 3 hours for analyzing au- dit data from a 24-hour period, whereas SLEUTH was able to process 358 hours of logs in a little less than 3 minutes. Host-based intrusion detection techniques mainly fall into three categories: (1) misuse-based, which rely on specifications of bad behaviors associated with known attacks; (2) anomaly-based [19,32,47,20,30,11,48], which rely on learning a model of benign behavior and detecting deviations from this behavior; and (3) specification-based [27,54], which rely on specifications (or policies) specified by an expert.