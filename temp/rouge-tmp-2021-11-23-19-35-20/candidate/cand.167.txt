Advanced knowledge of which vulnerabilities are being or likely to be exploited would allow system administrators to prioritize patch deployments, enterprises to assess their security risk more precisely, and security companies to develop intrusion protection for those vulnerabil-ities. The severity of problem was highlighted in 2017 by the the WannaCry and NotPetya outbreaks, as well as the Equifax data breach exposing sensitive data of more than 143 million consumers; in all three cases the underlying vulnerability had been patched (but not deployed) months before the incident [46,47,20]. For example, intrinsic attributes of vulnerabilities, such as the CVSS score [28], are not strong predictors of eventual exploitation [36], underlining the Early detection in this study refers to the ability to detect after t C , i.e., post-disclosure, but much earlier than t E , the current state of the art.need for detection techniques based on field measurements. To put this on the appropriate time scale, we illustrate the sequence of events associated with a vulnerability in Figure 1: its introduction at t A with application installation, disclosure at t C , patching at t F ; and for those eventually exploited in the wild, detection at t E . There are two strains of viruses: those exposed to air contamination are more at risk/susceptible to strain 1, while those exposed to water contamination are more at risk/susceptible to strain 2. By comparing the symptom group to the risk groups we can infer which strain is likely to be the underlying cause of the infection. This led us to consider a more verifiable hypothesis: entities (to be precisely defined shortly) that exhibit similar patching behavior in a particular vulnerability (and thus their vulnerability state) might also exhibit similar patterns of infection associated with that vulnerability if it is being actively exploited; on the other hand, the same similarity association should not exist if the vulnerability is not being actively exploited. Comparing Figure 2b to 2a and then 2c to 2a, we see a large overlap between the symptom group and the group at risk to strain 1 (through air contamination), indicating a likelihood that stain 1 is active; by contrast, the symptom group and those at risk to strain 2 (through water contamination) are largely disjoint, suggesting that strain 2 is likely not active.To apply this analogy in our context, the symptom pattern refers to malicious activities while risk behavior refers to host patching. However, as is evident from our results in Section 6.2, aggregation at the ISP level is not too coarse so as to impede our technique from detecting actively exploited vulnerabilities.Our second challenge is in determining the right metric to use to capture "similarity" both in the patching behavior and in the symptoms. To this end, we present the use of community detection [10,51] over the symptom similarity matrix to identify groups of similar ISPs; this is then followed by quantifying the consistency between the risk behavior similarity matrix and the detected community structure. This method involves finding the state of a host, i.e., the set of applications installed on the machine, for any point throughout the observation period, and extracting the set of disclosed vulnerabilities corresponding to those application versions from NVD. For this study, we analyze user patching behavior over 7 applications with the best host coverage in our dataset, namely Google Chrome, Mozilla Firefox, Mozilla Thunderbird, Safari, Opera, Adobe Acrobat Reader, and Adobe Flash Player; we ignore hosts that have recorded less than 10 events for all of these applications. Thus, we also use release dates from Nappa et al. [30] who automatically extract software release dates by selecting the first date when the version appears in the patch deployment dataset [14]. In this study, we use 5 common daily IP address based RBLs from January 2013 to July 2014 which overlap with the patch deployment measurements.Note that the use of spam data is only a proxy for host infection caused by vulnerability exploits and an imperfect one at that. Our results show the opposite; the detection performance we are able to achieve suggests that spam is a very good proxy for this purpose despite the existence of non-vulnerability related spamming bot distributions.Note that hosts in our patch deployment dataset are anonymized, but can be aggregated at the Internet Service Provider (ISP) level. This is the case with both the patching data and the RBLs and our aggregation takes this into account by similarly mapping the same host to multiple ISPs whenever this is indicated in the data.Aggregating the RBL signals at the ISP level is relatively straightforward. Formally, let R n (t) denote the total number of unique IPs listed on these RBLs on day t that belong to ISP n (by mapping the IPs to prefixes associated with this ISP). However, this extraction is complicated by the fact that there may be multiple product lines present on a host, or when a user downgrades to an earlier release. This heuristic allows us to discern different product lines of each application and users that have installed multiple product lines on their respective machines at any point in time, leading to a more accurate estimate of their states.We quantify the vulnerability of a single host h to CVE j on day t by counting how many versions present on the host on day t are subject to this CVE. We have now obtained two types of time series for each ISP n: r n (t) denoting the normalized malicious activities (also referred to as the symptom signal), and w j n (t), j ∈ V , denoting the normalized risk with respect to CVE j; the latter is a set of time series, one for each CVE in the set V (also referred to as the risk signal). Our pairwise similarity measure is defined by the maximum of these correlations subject to a lower bound on how long the vector should be:S u,v = max( max 0≤k≤d−a (S u,v (k)), max 0≤k≤d−a (S v,u (k)),(2)where a is a lower bound to guarantee the correlation is computed over vectors of length at least d − a to prevent artificially high values. 1 For simplicity of presentation, we shift t j o to origin, which gives us two symptom signals of length d + 1: r n [0 : d] and r m [0 : d], and a pairwise symptom similarity measure S j r n ,r m using Equations (1) and (2). This matrix is equivalently represented as a weighted (and undirected) graph, where I is the set of vertices (each vertex being an ISP) and the pairwise similarity S j r n ,r m is the edge weight between vertices n and m (note each edge weight is a number between 0 and 1). We now verify the hypothesis stated in the introduction; that is, if a CVE is being actively exploited, then ISPs showing similar vulnerabilities to this CVE are also likely to exhibit similar infection symptoms, while on the other hand if a CVE is not actively exploited, then the similarity in vulnerabilities may not be associated with similarity in symptoms. This allows us to quantify the strength of association between risk and symptoms for any arbitrary CVE; a high D j indicates that there is a statistically significant difference between intra-cluster and inter-cluster risk similarities, which in turn provides evidence for active exploitation. We observe a general downward trend in the mean, i.e., for exploits spotted earlier their inter-cluster and intra-cluster similarity difference is also more pro- nounced. This suggests that these can be used as features in building a classifier aiming at exploits detection. We observe that keywords such as attack, exploit, server, and allow, have higher mutual information with labels of exploited, which is consistent with common understanding of what might motivate exploits.Below we summarize the complete set of features used in this study (each family is given a category name), some of which are introduced for comparison purposes as we describe in detail next. For each CVE, we use three metrics: AcessVecotr, AccesComplexity, and Authentication, which measure the exploit range, required attack complexity and the level of authentication needed for successful exploitation, respectivelyWe can also categorize these sets of features as graphbased ( [Community], [Direct], [Raw]) and intrinsic ( [In- trinsic], [CVSS]) features. For this reason, the training and testing are conducted using 20 rounds of random sub-sampling from the NEIW set to match its size with the EIW set; for each round, we apply 5-fold cross validation to split the dataset into training and test sets. The reason why extracted features perform better than raw features is because with the latter a lot of the temporal information embedded in the time series data is underutilized (e.g., in decision tree type of classifiers, time series data are taken as multiple individual inputs), whereas the features we extract (either in the form of community comparison or in the form of row-by-row correlation) attempt to preserve this temporal information.Additionally, we see that combining community features with intrinsic features achieves very good detection performance, almost similar to the concatenation of all features; this suggests that when combined with intrinsic features, community features can effectively replace the use of raw and direct features. For instance the one-to-multiple mapping from symptoms of malicious behavior (indicated by RBLs) to vulnerabilities, especially when multiple vulnerabilities appear in the same time window, and hosts appearing in a blacklist for reasons other than exploitation of software vulnerabilities, can introduce noise in the measured symptoms (malicious activities). In this section we present a few examples of our system's output for (potentially) zero-day EIW vulnerabilities, and discuss the robustness of our technique against strategic attackers, and its practical utility for building real-world monitoring of software vulnerabilities. Since our detection method relies on models trained using measurement data, it is potentially vulnerable to attempts of data manipulation. Specifically, we randomly select a set of N ISPs from the total population I and revise their risk signals as follows:w j n (t) ←− ∑ i∈N w j i (t) N ± γ · w j n (t), n ∈ N,(3)where the first term is the average value among this controlled group of ISPs, and γ is randomly drawn from the set (0.1, 0.2, 0.3) for each n (similarly, ± is determined by a random coin flip) to serve as a small perturbation around the average. Even though a vulnerability might be used mainly for non-spam activities, one can detect exploitation as long as a portion of infected devices are used for sending spam. This supports our claim that the same dynamics apply to more recent vulnerabilities, where even though patches are developed and disseminated by vendors through automated mechanisms, users and enterprises often opt out of keeping their software up to date, leading to eventual exploitation, and then followed by observation of symptoms. WannaCry and NotPetya outbreaks (exploiting CVE-2017-0144), and the Equifax data breach (caused by CVE-2017-5638) are all recent examples of this phenomena, where patches for the underlying vulnerabilities had been disseminated by software vendors months before each incident, but had not yet been deployed on the compromised machines [46,47,20]. To the best our knowledge, ours is the first study that attempts to to detect active exploitation by correlating patching behavior and vulnerability data with host infection data inferred from a set of spam blacklists.Detection of community structures in graphs or networks is an increasingly active field in graph mining and has seen extensive work, see e.g., [17]. The latter was then compared to the former to quantify whether the underlying risks are consistent with the observed global symptomatic community structure, which then allowed us to statistically determine whether a given vulnerability is being actively exploited.