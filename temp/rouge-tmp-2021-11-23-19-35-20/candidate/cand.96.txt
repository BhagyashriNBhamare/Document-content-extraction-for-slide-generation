The recent European General Data Protection Regulation (GDPR) restricts the processing and exploitation of some categories of personal data (health, political orientation , sexual preferences, religious beliefs, ethnic origin , etc.) due to the privacy risks that may result from malicious use of such information. EU member states were given until May 2018 to incorporate it into their national legislation.The GDPR (and previous EU national data protection laws) defines some categories of personal data as sensitive and prohibits processing them with limited exceptions (e.g., the user provides explicit consent to process that data for a specific purpose). In particular, the GDPR defines as sensitive personal data: "data revealing racial or ethnic origin, political opinions, religious or philosophical beliefs, or trade union membership, and the processing of genetic data, biometric data for the purpose of uniquely identifying a natural person, data concerning health or data concerning a natural person's sex life or sexual orientation". This illustrates that FB may be actually processing sensitive personal information, which is now prohibited under the EU GDPR without explicit consent and also under some national data protection regulations in Europe. For instance, the ad preferences "Homosexuality" and "Communism" may reveal the sexual orientation and the political preference of a user, respectively.Once we have identified the list of potentially sensitive ad preferences, we use it to query the FB Ads Manager in order to obtain the number of FB users and citizens exposed to these ad preferences in the whole EU as well as in each one of its member states. 2 In addition to the interests included in this hierarchy, the FB Ads Manager offers a Detailed Targeting search bar where users can type any free text and it suggests interests linked to such text. In this paper, we leverage the interest parameter to identify potential sensitive interests.Advertisers can configure their target audiences based on any combination of the described parameters. By examining 5.5M ad preferences assigned to FDVT users (see Subsection 2.3), we have found 6 reasons for the assignment of ad preferences: (i) This is a preference you added, (ii) You have this preference because we think it may be relevant to you based on what you do on Facebook, such as pages you've liked or ads you've clicked, (iii) You have this preference because you clicked on an ad related to..., (iv) You have this preference because you installed the app..., (v) You have this preference because you liked a Page related to..., (vi) You have this preference because of comments, posts, shares or reactions you made related to... 2 Business and industry, Education, Family and relationships, Fitness and wellness, Food and drink, Hobbies and activities, Lifestyle and culture, News and entertainment, People, Shopping and fashion, Sports and outdoors, Technology, Travel places and events, Empty.3 Given that interests and ad preferences refer to the same thing, we use these two terms interchangeably in the rest of the paper 4 Access and edit ad preference list: https://facebook.com/ ads/preferences/edit The Data Valuation Tool for Facebook Users (FDVT) [12] is a web browser extension currently available for Google Chrome 5 and Mozilla Firefox. More details about the analysis of FB terms of service are provided in Appendix C. To uncover potentially sensitive ad preferences and quantify the portion of EU FB accounts associated with them, we seek to collect a dataset of ad preferences linked to actual EU FB accounts. -Disambiguation Category: For some ad preferences Facebook adds this in a separate field or in parenthesis to clarify the meaning of a particular ad preference (e.g., Violet (color); Violet: Clothing (Brand)) We have identified more than 700 different disambiguation category topics (e.g., Political Ideology, Disease, Book, Website, Sport Team, etc.). For instance, Manchester United F.C. is linked to Sports and Outdoors.-Audience Size: This value reports the number of Facebook users that have been assigned the ad preference worldwide.-Reason why the ad preference is added to the user: The reason why the ad preference has been assigned to the user according to FB. However, it is important to note that many ad preferences still reach a reasonable portion of users. We rely on a group of researchers with some knowledge in the area of privacy to manually identify potentially sensitive ad preferences within our pool of 126K ad preferences retrieved from FDVT users. Note that all these examples of ad preferences have been extracted from our dataset; thus they have been assigned to actual FB users. To this end, we have defined a dictionary including both keywords and short sentences 7 If we consider 10s as the average time required to classify an ad preference as sensitive vs. non-sensitive, this task would require 44 full eight-hour days.representative of each of the five considered sensitive categories. It is worth noting that this approach makes our methodology flexible, since the dictionary can be extended to include new keywords for the considered categories or other categories, which may uncover additional potentially sensitive ad preferences.We next describe the semantic similarity computation in detail.Semantic similarity computation: The semantic similarity computation process takes two inputs: the 126K ad preferences from our FDVT dataset and the 264 keyword dictionary associated with the considered sensitive categories. As result of this process, each one of the 126K ad preferences is assigned a similarity score, which indicates its likelihood to be a sensitive ad preference.To implement the semantic similarity comparison task, we leverage the Spacy package for python 11 (see details about Spacy in Appendix D). Some of these cases are: physical persons such as politicians (which may reveal the political opinion of the user); political parties with names that do not include any standard political term; health diseases or places of religious cults that may have names with low semantic similarity with health and religious related keywords in our dictionary, respectively. Therefore, if the ad preference under analysis has a disambiguation category field, we used the disambiguation category string instead of the ad preference name to obtain the semantic similarity score of the ad preference.Selection of likely sensitive ad preferences: The semantic similarity computation process assigns a similarity score to each one of the 126K ad preferences in our dataset. We asked them to classify each ad preference into one of the five considered sensitive categories (Politics, Health, Ethnicity, Religion, Sexuality), in the category "Other" (if it does not correspond to any of the sensitive categories), or in the category "Not known" (if the panelist does not know the meaning of the ad preference). 2092 out of the 4452 ad preferences are labeled as sensitive, i.e., have been classified into a sensitive category by at least 3 voters. This represents 1.66% of the 126K ad preferences from our dataset.An ad preference classified as sensitive may have been assigned to different sensitive categories (e.g., politics and religion) by different voters. Hence, we conclude that (almost) every ad preference classified as sensitive corresponds to a unique sensitive category among the 5 considered.The 2092 ad preferences manually labeled as sensitive are distributed as follows across the five sensitive categories: 58.3% are related to politics, 20.8% to religion, 18.2% to health, 1.5% to sexuality, 1.1% to ethnicity and just 0.2% present discrepancy among votes. This allows us to compute the number of FB users assigned at least one of the Top N potentially sensitive ad preferences (with N ranging between 1 and 2092). It is computed as the ratio between the number of FB users that have been assigned at least one of the top N potentially sensitive ad preferences and the total number of FB users in country C, which can be retrieved from the FB Ads Manager.-FC(C,N): This is the percentage of citizens in country C (or all EU countries together) that have been assigned at least one of the top N potentially sensitive ad preferences. This fixed number is 2.1B which to the best of our knowledge refers the total number of FB users included in the Ads Manager. If we focus only on EU users, which are the focus of this paper, 2848 (90%) have been tagged with potentially sensitive ad preferences. The 25th and 75th percentiles are 5 and 21, respectively.Our FDVT dataset includes the reason why, according to FB, each ad preference has been assigned to a user. If we focus on individual countries, FC(C,N=500) reveals that in 7 of them more than half of their citizens are tagged with at least one of the top 500 potentially sensitive ad preferences: Malta (66.37%), Cyprus (64.95% ), Sweden (54.53%), Denmark (54.09%), Ireland (52.38%), Portugal (51.33%) and Great Britain (50.28%). org/usenix2018/top500.html country C FFB(C,500) FC (C,500) country C FFB(C,500) FC (C,500 Tables 4 and 5 show the percentage of FB users (FFB) and citizens (FC) tagged with each of the 20 expertverified sensitive ad preferences per EU country. The gender analysis considers two groups, men vs. women, while the age analysis considers four age groups following the division proposed by Erikson et al. [7]: 13-19 (Adolescence), 20-39 (Early Adulthood), 40-64 (Adulthood) and 65+ (Maturity). Between October 6 and October 15, 2017 we ran three FB ad campaigns using expert-verified sensitive ad preferences such as: "religious beliefs" (targeting users interested in Islam OR Judaism OR Christianity OR Buddhism), "political opinions" (targeting users interested in Communism OR Anarchism OR Radical feminism OR Socialism) and "sexual orientation" (targeting users interested in Transsexualism OR Homosexuality). BE BG HR CY CZ DK EE FI FR DE GR HU IE IT LV LT LU MT NL PL PT RO SK SI ES SE GB To the best of our knowledge the conducted ad campaigns were compliant with the Terms of service of Facebook introduced in Section 3.3 and Appendix E. For instance, in the example of the iPhone X giveaway, the landing page can show a message congratulating the user for winning the phone requesting that the user provides personal data (name, address, phone number, etc.) for shipping purposes.A recent study [13] ran experiments implementing email-based phishing attacks in which 9% of the users posted their credentials (username and password) to the phishing site (i.e., attacker's landing page). To this end, we have extended the FDVT browser extension to inform users about the potentially sensitive ad preferences that FB has assigned them: (i) we have built a classifier to automatically tag ad preferences assigned to FDVT users as sensitive or non-sensitive; (ii) we have modified the FDVT back-end and front-end to incorporate this new feature. We store the history of potentially sensitive ad preferences assigned to the user to notify her of those preferences that FB has removed. Castellucia et al. [5] show that an attacker that gets access (e.g., through a public WiFi network) to the Google ads received by a user could create an interest profile that could reveal up to 58% of the actual interests of the user. The GDPR became enforceable on May 25, 2018. The results of our paper urge a quick reaction from Facebook to eliminate all ad preferences that can be used to infer the political orientation, sexual orientation, health conditions, religious beliefs or ethnic origin of a user for two reasons: (i) this may avoid Facebook running afoul of Article 9 of the GDPR, and (ii) it may protect users from threats that exploit this sensitive data. 26 The latter document includes 13 sections from which Section 4.12 27 23 https://www.facebook.com/terms.php (accessed December 19,2017) 24 https://www.facebook.com/about/privacy/ (accessed December 19,2017) 25 https://www.facebook.com/legal/self_service_ads_ terms (accessed December 19, 2017) 26 https://www.facebook.com/policies/ads/ (accessed December 19,2017) 27 https://www.facebook.com/policies/ads/prohibited_ content/personal_attributes (accessed December 19,2017) (4-Prohibited Content; 12-Personal attributes) is very relevant for our paper. (d) "processing is carried out in the course of its legitimate activities with appropriate safeguards by a foundation, association or any other not-for-profit body with a political, philosophical, religious or trade union aim and on condition that the processing relates solely to the members or to former members of the body or to persons who have regular contact with it in connection with its purposes and that the personal data are not disclosed outside that body without the consent of the data subject". (h) "processing is necessary for the purposes of preventive or occupational medicine, for the assessment of the working capacity of the employee, medical diagnosis, the provision of health or social care or treatment or the management of health or social care systems and services on the basis of Union or Member State law or pursuant to contract with a health professional and subject to the conditions and safeguards referred to in paragraph 3". (h) "processing is necessary for the purposes of preventive or occupational medicine, for the assessment of the working capacity of the employee, medical diagnosis, the provision of health or social care or treatment or the management of health or social care systems and services on the basis of Union or Member State law or pursuant to contract with a health professional and subject to the conditions and safeguards referred to in paragraph 3".