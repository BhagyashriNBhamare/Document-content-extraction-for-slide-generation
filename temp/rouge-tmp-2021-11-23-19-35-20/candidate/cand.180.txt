To this end, we consider multilayer perceptron and convolu-tional neural networks as the machine learning architectures of choice and assume a non-invasive and passive attacker capable of measuring those kinds of leakages. Practical results are shown on an ARM Cortex-M3 microcontroller, which is a platform often used in pervasive applications using neural networks such as wearables, surveillance cameras, etc. Our experiments show that a side-channel attacker is capable of obtaining the following information: the activation functions used in the architecture, the number of layers and neurons in the layers, the number of output classes, and weights in the neural network. As a consequence, there is an increasing interest in deploying neural networks on low-power processors found in always-on systems, e.g., ARM Cortex-M microcontrollers.In this work, we focus on two neural network algorithms: multilayer perceptron (MLP) and convolutional neural networks (CNNs). Even if we disregard privacy issues, obtaining useful information from neural network architectures can help acquiring trade secrets from the competition, which could lead to competitive products without violating intellectual property rights [3]. Nevertheless, even when this is the case, a viable alternative is to exploit side-channel leakages.Side-channel analysis attacks have been widely studied in the community of information security and cryptography, due to its potentially devastating impact on otherwise (theoretically) secure algorithms. Here, we start by considering some of the basic building blocks of neural networks: the number of hidden layers, the basic multiplication operation, and the activation functions.For instance, the complex structure of the activation function often leads to conditional branching due to the necessary exponentiation and division operations. By using the known divide-and-conquer approach for side-channel analysis, (i.e., the attacker's ability to work with a feasible number of hypotheses due to, e.g., the architectural specifics), the information at each layer could be recovered. Yet, this task is not so simple since one needs to know what kind of architecture is used (e.g., convolutional neural network or multilayer perceptron, the number of layers, the activation functions, access to training data, etc.) while limiting the number of queries to ensure the approach is realistic [39]. The proposed attack exploits a specific design choice, i.e., the line buffer in a convolution layer of a CNN.In a nutshell, both previous reverse engineering efforts using side-channel information were performed on very special designs of neural networks and the attacks had very specific and different goals. Our work is more generic than those two as it assumes just a passive adversary able to measure physical leakages and our strategy remains valid for a range of architectures and devices. In order to mount the attack in practice, they estimate the error between the true hyper-parameter and the estimated one.In this work, we further explore the problem of reverse engineering of neural networks from a more generic perspective. For example, we show that even a side-channel attack that failed can provide sensitive information about the target due to the precision error. We emphasize that the simplicity of our attack is its strongest point, as it minimizes the assumption on the adversary (no pre-processing, chosen-plaintext messages, etc.) In this section, we give details about artificial neural networks we consider in this paper and their building blocks. A perceptron is a linear binary classifier applied to the feature vector as a function that decides whether or not an input belongs to some specific class. Multilayer perceptron (MLP) is a feed-forward neural network that maps sets of inputs onto sets of appropriate outputs. Backpropagation is used by the gradient descent optimization algorithm to adjust the weight of neurons by calculating the gradient of the loss function [34]. To enable calculations of nontrivial functions for ANN using a small number of nodes, one needs nonlinear activation functions as follows.y = Activation( ∑ (weight · input) + bias). The range of a logistic function is [0,1], which means that all the values going to the next neuron will have the same sign.f (x) = 1 1 + e −x . To denote a vector, we represent it in bold style.f (x) j = e x j ∑ K k=1 e x k , f or j = 1, . . . , K.(4)The Rectified Linear Unit (ReLU) is a nonlinear function that is differing from the previous two activation functions as it does not activate all the neurons at the same time [35]. In this work, we apply SPA, or actually SEMA to reverse engineer the architecture of the neural network.Differential Power (or Electromagnetic) Analysis (DPA or DEMA). We select to work with MLP and CNNs since: 1) they are commonly used machine learning algorithms in modern applications, see e.g., [16,11,36,48,25,21]; 2) they consist of different types of layers that are also occurring in other architectures like recurrent neural networks; and 3) in the case of MLP, the layers are all identical, which makes it more difficult for SCA and could be consequently considered as the worst-case scenario. The attacker only controls the execution of it through selecting the inputs, but An adequate use case would be when the attacker legally acquires a copy of the network with API access to it and aims at recovering its internal details e.g. for IP theft. • ARM Cortex-M3: This is a modern 32-bit microcontroller architecture featuring multiple stages of the pipeline, on-chip co-processors, low SNR measurements, and wide application. We show that the developed methodology is indeed versatile across targets with a relevant update of measurement capability.In addition, real-world use cases also justify our platforms of choice. Moreover, as for ARM Cortex-M3, low SNR of the measurement might force the adversary to increase the number of measurements and apply signal pre-processing techniques, but the main principles behind the analysis remain valid.As already stated above, the exploited leakage model of the target device is the Hamming weight (HW) model. Note that, with our approach, there is no limit in the number of layers or nodes we can attack, as the attack scales linearly with the size of the network. We collect EM traces and measure the timing of the activation function computation from the measurements. As shown in Figure 3, the timing behavior of the four tested activation functions have distinct signatures allowing easy characterization.Different inputs result in different processing times. On the other hand, tanh and sigmoid might have similar timing delays, but with different pattern considering the input (see Figure 4b and Figure 4b), where tanh is more symmetric in pattern compared to sigmoid, for both positive and negative inputs. We can observe that softmax function will require most of the processing time, since it requires the exponentiation operation which also depends on the number of neurons in the output layer. Moreover, the attacker can sometimes pre-characterize (or profile) the timing behavior of the target activation function independently for better precision, especially when common libraries are used for standard functions like multiplication, activation function, etc. 1 CPA targets the multiplication m = x · w of a known input x with a secret weight w. Using the HW model, the adversary correlates the activity of the predicted output m for all hypothesis of the weight. Namely, while cryptographic operations are always performed on fixed length integers, in ANN we are dealing with real numbers.We start by analyzing the way the compiler is handling floating-point operations for our target. Although, in the later phase of the experiment, we targeted the floating point and fixed-point representation (2 32 in the worst case scenario on a 32-bit microcontroller, but could be less if the value is for example normalized), instead of the real value, which could in principle cover all possible floating values.In Figure 5, we show the result of the correlation for each byte with the measured traces. In the figure, the black plot denotes the correlation of the "correct" mantissa weight (|m( ˆ w) − m(w)| < 0.01), whereas the red plots are from all other weight candidates in the range described earlier. When attacking real numbers, small precision errors due to rounding off the intermediate values still result in useful information.To deal with more precise values, we can target the mantissa multiplication operation directly. In this case, the search space can either be [0, 2 23 − 1] to cover all possible values for the mantissa (hence, more computational resources will be required) or we can focus only on the most significant bits of the mantissa (lesser candidates but also with lesser precision). mantissa w , then taking the 23 most significant bits after the leading 1, and normalization (updating the exponent if the result overflows) if necessary.In Figure 6, we show the result of the correlation between the HW of the first 7-bit mantissa of the weight with the traces. Thus, in both cases, we have shown that we can recover the weights from the SCA leakage.In Figure 7, we show the composite recovery of 2 bytes of the weight representation i.e., a low precision setting where we recover sign, exponent, and most significant part of mantissa. To determine if the targeted neuron is in the same layer as previously attacked neurons, or in the next layer, we perform a weight recovery using two sets of data.Let us assume that we are targeting the first hidden layer (the same approach can be done on different layers as well). This can be recovered by the combination of SPA/SEMA and DPA/DEMA technique described in the previous subsection (2 times CPA for each weight candidate w, so in total 2n L 0 2 d CPA required), in parallel with the weight recovery. The same steps are repeated in the subsequent layers (L 1 , ..., L N−1 , so in total at most 2Nn L 2 d , where n L is max(n L 0 , ..., n L N−1 )) until the structure of the full network is recovered.The whole procedure is depicted in Figure 9. 4 Experiments with ARM Cortex-M3In the previous section, we propose a methodology to reverse engineer sensitive parameters of a neural network, which we practically validated on an 8-bit AVR (Atmel ATmega328P). Since the certification labs use machine learning to evaluate the resilience of cryptographic implementations to profiled attacks, an attacker being able to reverse engineer that machine learning would be able to use it to attack implementations on his own. This was resolved by measuring two consecutive layers at a time • We had to resynchronize traces each time according to the target neuron which is a standard pre-processing in side-channel attacks. The MNIST database contains 60 000 training images and 10 000 testing images where each image has 28 × 28 pixel size. The accuracy of the original network is equal to 98.16% while the accuracy of the reverse engineered network equals 98.15%, with an average weight error converging to 0.0025. We emphasize that both attacks (on DPAcontest v4 and MNIST) were performed following exactly the same procedure as in previous sections leading to a successful recovery of the network parameters. Next, for pooling layer, once the weights in the convolution part are recovered, the output can be calculated. Still, because the max pooling layer is based on the following conditional instruction, conditional(i f (a > max)max = a), it is straightforward to differentiate it from the average pooling that has summation and division operations. As it can be seen, by using sufficient measurements (e.g., ∼ 50 000), we are able to reverse engineer CNN architecture as well. Every computation of f (x, w) is transformed into f m (x⊕m 1 , w⊕m 2 ) = f (x, w)⊕m, where m 1 , m 2 are uniformly drawn random masks, and f m is the masked function which applies mask m at the output of f , given masked inputs x ⊕ m 1 and w ⊕ m 2 . Shuffling and masking require a true random number generator that is typically very expensive in terms of area and performance.