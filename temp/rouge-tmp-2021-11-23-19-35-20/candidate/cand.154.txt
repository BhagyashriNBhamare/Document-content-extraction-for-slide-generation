This represents a severe privacy concern for general users [62], but in some contexts, searches are used to arrest (or worse) dissidents, journalists, and humanitarian aid workers.Proposals for privacy-enhancing tools to combat compelled access are not new, but typically do not consider the range of technical skills and preparedness of the increasingly broad population of targeted users, nor the frequently cursory nature of these searches. We leave open the theoretical question of whether one can build self-revocable encryption from weaker assumptions.We bring all the above together to realize BurnBox, the first encrypted cloud file storage application with selfrevocation achieving our CAS privacy target. Our work therefore also surfaces a number of open problems, including: how to build operating systems that better support privacy for self-revocable encryption, improvements to our cryptographic constructions, what level of security can be achieved when cloud providers actively modify ciphertexts, and more. After using their application for some time, a physically present authority forces the user to disclose or use their access credentials (passwords, biometric, pin code, etc.) to allow the adversary access to the device and, in particular, the state of the storage application's client. In these settings, standard client-side encryption proves insufficient: because the user is compelled to give access to their device and all passwords they have, the authority gains both the credentials to access the cloud and the keys necessary to perform decryption.Surveilled cloud storage. Given that most users do not really understand basic encryption [60,63,70], this seems a significant barrier to useful deployment.Our goal will instead be for the user to genuinely comply with demands for access to the device and everything they know, and not force them to manage cover data or lie to achieve any security. While we will pro- The content of deleted or revoked files should be hidden upon compromise The name of deleted or revoked files should be hidden upon compromise Temporarily revoked files should be indistinguishable from securely deleted files upon compromise The timings of deletions and revocations should be hidden (hard) Formalized with a simulation-based notion of real/ideal world parameterized by a leakage regime (Real protocol can be simulated using leakage) -Leaks operation ordering for cloud accesses and adds along with pseudonym for target file -Seems fundamental when remote server processes operations for single files (can hide by batch processing, e.g. ORAM) -Journaling / log-based file storage -Solution: secure deletion with trusted hardware -Indexing, background processes -Solution (partial): FUSE to interact with BurnBox -Temporary files, swap files -Solution: Open (restrict to supported BurnBox app?) Moreover, it allows the adversary to check if a user owns a flagged file from a list of, e.g., politically "subversive" works.We next describe two secondary goals to support the (optional) ability of a person to equivocate about revocation and deletion history. If that were possible, then one can only provide privacy via secure deletion (which is supported by BurnBox). Fourth, we assume the adversary only has passive access to the cloud.Finally, although we hide the individual number of deleted or revoked files, we will not target hiding the sum of these values, meaning the total number of files that have been either revoked or deleted. Thus cryptographic erasure does not provide a full solution to the problem.Following the approach of many searchable encryption schemes [23], one could create a "PRF index" that replaces with a filename pseudonym t = F k () where F is a secure pseudorandom function (PRF). This raises two distinct problems: first any data that has been overwritten or deleted from the table may still be be retained by the file system (e.g., in a journaled file system) or physically extractable from the drive (e.g., due to ware-leveling for SSDs or the hysteresis of magnetic storage media). [47] achieve privacy for a particular update to the data structure even if an attacker has access to a snapshot both before and after a series of updates.In the compelled access setting, however, due to the previously stated non-assumption of persistent storage deletion (e.g., journaling or hardware forensics), the attacker may get snapshots at each and every update. Thus, these kinds of generic history-independent data structure techniques do not seem suitable for our setting.We therefore take an application-specific approach, arranging that our data structures are used in a way that is independent of our application's privacy-sensitive information. When adding a file to the storage, we generate a restoration ciphertext of the form Enc pk res ( || k) which contains both the key k for a given file and its filename . • st i+1 ,tok res ←$ Restore(st i ,tok res ) : The restore algorithm takes as input a state and secret restoration token, and outputs a new state with all self-revoked files restored along with a (potentially new) restoration token.We require our schemes to be correct. We will make use of an initialize operation (T ← Tbl.Init( )), insert and lookup key operations notated by brackets (T [k]), and a delete key operation (Tbl.Delete(T, k)). This operation acts to lazily construct a random function and is used in the protocol to map filenames to random values used for key derivation, Init():T ← Tbl.Init() / / index B ← Tbl.Init() / / backup pk res , sk res ←$ PKKeyGen() st ← T || B || pk restok res ← pk res || sk res return st, tok res Add(st, , m):(T, B, pk res ) ← st (id, k m ) ←$ Tbl.RandMap(T, ) B[id] ←$ PKEnc pk res ( || id || k m ) Put(id, Enc km (m))return st ← T || B || pk res Delete(st, ):(T, B, pk res ) ← st if T [] = ⊥ : return st (id, k m ) ← T [] B[id] ← PKEnc pk res (0 ||+2n ) Tbl.Delete(T, )return st ← T || B || pk res Access(st, ):(T, B, pk res ) ← st if T [] = ⊥ : return st, ⊥ (id, k m ) ← T [] ct ← Get(id) m ← Dec km (ct) st ← T || B || pk res return st, mRevoke(st, ):(T, B, pk res ) ← st Tbl.Delete(T, )return st ← T || B || pk res Restore(st,tok res ):(T, B, pk res ) ← st (pk res , sk res ) ← tok res for (id, ct) ∈ B : (, id, k m ) ← PKDec skres (ct) if || id || k m = 0 ||+2n : T [] ← id || k m st ← T || B || pk res return st, tok res We formalize compelled access security (CAS) for SR-ECS schemes. To address the first concern, our cryptographic analysis (Section 5.3) will not only reduce to a leakage regime, but then also evaluate the implications of our chosen leakage regime by formally analyzing the implications of leakage using property-based security games. The ideal world is parameterized by a leakage regime L and a simulator S.A leakage regime L = {L init , L add , L acc , L del , L rev , L res , L com }consists of a sequence of leakage algorithms, one for each oracle. The leakage regime therefore forms a kind of whitelist for what information about queries can be leaked by a scheme.A simulator S attempts to use the leakage to effectively "simulate" the transcript τ and compromised state using only the leakage values σ output by L. The adversary can make queries to Encrypt, Decrypt at any point in the games, including after the Compromise query is made.In the ideal world the Encrypt and Decrypt oracles are implemented by the simulator S. Operations that do not interact with the remote server, L del , L rev , L res , do not leak anything when first called, but do update the leakage state to change the set of files that are leaked upon compromise.Pseudonymous operation history leakage fits the SR-ECS setting with an adversary-controlled remote server processing Add and Access operations for individual files. First, we show that our protocol is secure with respect to the pseudonymous operation history leakage regime L POH , by presenting a simulator S POH (see Figure 6) that can effectively emulate the real world protocol given only access to the leakage in the ideal world. Then we give adversary B such that if A makes at most q Add , q Enc , q Dec queries to Add, Encrypt, Decrypt, respectively, and runs in time T then(P, R) ← st L p ←$ {0, 1} n \ P P[] ← (p, m) σ ← (Add, p, |m|) st L ← P || R return st L , σ L acc (st L , ): (P, R) ← st L (p, m) ← P[] σ ← (Access, p) return st L , σ L del (st L , ): (P, R) ← st L Tbl.Delete(P, ) return st L ← P || R L rev (st L , ): (P, R) ← st L R[] ← P[] Tbl.Delete(P, ) return st L ← P || R L res (st L ,tok res ): (P, R) ← st L forP[] ← (p, m) Tbl.Delete(R, ) return st L ← P || R L com (st L ): (P, R) ← st L σ ← (Compromise, P) return σAdv cas Π,S POH ,L POH (A) ≤ Adv indcpa PKE (B) + q Add · (2q Add + q Dec ) 2 nwhere n is the length of identifiers and symmetric keys. To simulate client state, the simulator must provide (1) restoration ciphertexts and (2) keys and file S add (st S , p, |m|):(T S , B, D, pk res ) ← st S (id, k m ) ←$ {0, 1} 2n ct ←$ {0, 1} clen(|m|) T S [p] ← (id, k m , ct) B[id] ←$ PKEnc pk res (0 ||+n ) st S ← T S || B || D || pk res τ = [(Put, id, ct)]return st S , τ S com (st S , P):(T S , B, D, pk res ) ← st S T ← Tbl.Init() for (, (p, m)) in P : (id, k m , ct) ← T S [p] T [] ← id || k m D[k m || ct] ← m st S ← T S || B || D || pk res st ← T || B || pk res return st S , st S acc (st S , p): (T S , B, D, pk res ) ← st S if p = ⊥ : return st S , ⊥ (id, k m , ct) ← T S [p] τ = [(Get, id)]return st S , τ S enc (st S , k, m): contents that are consistent with the ciphertexts to which the simulator previously committed. The remaining part of the bound, 2q 2(T S , B, D, pk res ) ← st S ct ←$ {0, 1} clen(|m|) D[k || ct] ← m st S ← T S || B || D || pk res return st S , ct S dec (st S , k, ct): (T S , B, D, pk res ) ← st S return st S , D[k || ct]Add /2 n , accounts for the need in the proof to switch identifiers to being chosen without replacement and then back again.Property-based security. Then we give an adversary B such thatAdv FilePrivacy Π (A) ≤ 2 · Adv cas Π,S POH ,L POH (B)where if A runs in time T and makes at most q oracle queries, B runs in time T ≈ T and makes at most q queries to the CAS oracle defined in Figure 4. Then we give an adversary B such thatAdv DelRevOblivious Π (A) ≤ 2 · Adv cas Π,S POH ,L POH (B)where if A runs in time T and makes at most q oracle queries, B runs in time T ≈ T and makes at most q queries to the CAS oracle defined in Figure 4. The core cryptographic functionality is exposed through a file system in userspace (FUSE) [8] that can be deployed as a SR-ECS scheme by mounting it within a cloud synchronization directory, e.g., Dropbox. Revoke and Restore are implemented as special FUSE commands and can be invoked through either the file system user interface or a command-line interface.BurnBox maintains local state in an erasable index (Section 3) which stores filenames, file keys, and restoration ciphertexts. Untrusted applications can be run in a container with access to BurnBox and a temporary file system that can be wiped on application exit.for doing so, but the functionality can be constructed from, for example, SGX [2]. In particular, we allow running an application within a Docker container given access to BurnBox and a temporary file system that is wiped on application exit. For example, a device can store 10 5 files in BurnBox while incurring less than 80 MB of local storage overhead. Nevertheless it is not prohibitively large, e.g., requiring 4.2 seconds for 10 5 files (Figure 8), since, once loaded, the index can be stored in memory using a fast data structure, e.g., a hash table.Next we turn to evaluating the latency of each operation. While these issues are independent of BurnBox and instead stem from the general use of cloud storage, we consider if compelled access presents a unique problem for access pattern attacks.By learning the plaintexts of undeleted files upon compelled access, the adversary may be able to better model the access distribution for a particular user leading to a stronger inference attack. Such concerns include: recently used file lists; indexes for OS wide search; application screen shots used for transitions 1 ; file contents from BurnBox memory being paged to disk; text inputs stored either in keyboard buffers or predictive typing mechanisms; byproducts of rendering and displaying files to the user; and the volume and timing of disk operations.Some of these issues can be handled by configuration or user action. Even if such fine grained information is not available, a flurry of file system activity, regardless of if it can be directly associated BurnBox, might suggest a user was revoking or deleting files immediately prior to a search, raising suspicion.Even should such operating-system leakage reveal timing, BurnBox may provide value in terms of delete timing privacy for attackers who do not conduct low level disk forensics. Gasti et al. [29] use deniable public-key encryption to build a cloud-backed file system These approaches do not hide file names or provide for self-revocation, and they require choosing a decoy message at file creation time.Honey encryption [35,37,38] targets ensuring decryption under wrong passwords results in decoy plaintexts, but only works for a priori known distributions of plaintext data, making it unsuitable for general use. We explored this approach in the context of encrypted cloud storage applications, showing that one can hide not only file contents but also whether and which files were revoked.We detailed a new cryptographic security notion, called compelled access security, to capture the level of access pattern leakage a scheme admits.