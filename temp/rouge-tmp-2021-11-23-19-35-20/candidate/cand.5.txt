These attacks take many shapes, such as sockpuppets hijacking online discourse [34]; the manipulation of BitTorrent's distributed hash table [35]; and, most relevant to our work, relays in the Tor network that seek to deanonymize users [8]. As the attacker's consensus weight grows, the following attacks become easier.Exit traffic tampering: When leaving the Tor network, a Tor user's traffic traverses exit relays, the last hop in a Tor circuit. In Section 5.1, we provide evidence for what appears to be botnets whose zombies are running Tor relays, perhaps because of a misguided attempt to help the Tor network grow.Motivated by the lack of practical Sybil detection tools, we design and implement heuristics, leveraging our observations that Sybils (i) frequently go online and offline simultaneously, (ii) share similarities in their configuration, and (iii) may change their identity fingerprint-a relay's fingerprint is the hash over its public key-frequently, to manipulate Tor's DHT. 3 Note that we could create such a relationship by, e.g., linking relays to their operator's social networking account, or by creating a "relay operator web of trust," but again, we believe that such an effort would alienate relay operators and see limited adoption.Orthogonal to social constraints, computational resource constraints guarantee that an attacker seeking to operate 100 Sybils needs 100 times the computational resources she would have needed for a single virtual identity. Operators can further assign a nickname to their Tor relays, which is a string that identifies a relay (albeit not uniquely) and is easier to remember than its pseudo-random fingerprint. Such Sybils are no threat to the Tor network, which is why we refer to them as benign Sybils.What we are interested in is malicious Sybils whose purpose is to deanonymize or otherwise harm Tor users.To uncover malicious Sybils, we draw on two datasets-one publicly available and one created by us. Archived consensuses and router descriptors (in short: descriptors) allow us to (i) restore past states of the Tor network, which sybilhunter mines for Sybil groups, and to (ii) find "partners in crime" of malicious exit relays that we discovered by running exitmap, a scanner for Tor exit relays that we discuss below. In addition to our publicly available and primary dataset, we collected malicious exit relays over 18 months. We add these relays to our dataset because they frequently surface in groups, as malicious Sybils, because an attacker runs the same attack on several, physically distinct exit relays. Our primary concern is protecting Tor users from harm, and we do not need to identify the culprit to do so.In addition to using the original exitmap modules [37, § 3.1], we implemented modules that detect HTML and HTTP tampering by connecting to a decoy server under our control, and flagging an exit relay as malicious if the returned HTML or HTTP was modified, e.g., to inject data or redirect a user over a transparent HTTP proxy. Shared configuration parameters such as port numbers and nicknames cause similar appearance whereas Sybils behave similarly when they reboot simultaneously, or exhibit identical quirks when relaying traffic.Sybilhunter can analyze (i) historical network data, dating back to 2007; (ii) online data, to detect new Sybils as they join the network; and (iii) find relays that might be associated with previously discovered, malicious relays. Tor network data first passes a filtering component that can be used to inspect a subset of the data, e.g., only relays with a given IP address or nickname. An unexpectedly high churn rate between two subsequent consensuses means that many relays joined or left, which can reveal Sybils and other network issues because many Sybil operators start and stop their Sybils at the same time, to ease administration-they behave similarly.The Tor Project is maintaining a Python script [15] that determines the number of previously unobserved relay fingerprints in new consensuses. In addition, The Tor Project's script does not consider relays that left the network, does not distinguish between relays with different flags, and does not adapt its threshold as the network grows. These are mere examples, however; the shape of a time series cannot tell us anything about the nature of the underlying incident.To quantify the churn rate α between two subsequent consensus documents, we adapt Godfrey et al.'s formula, which yields a churn value that captures both systems that joined and systems that left the network [13, § 2.1]. However, an unusually low number of systems that left could cancel out an unusually high number of new systems and vice versa-an undesired property for a technique that should spot abnormal changes. The diagram shows both the maximum and a more realistic estimate that accounts for the median number of new relays in consensuses.Finally, to detect changes in the underlying time series trend-flat hills-we can smooth α n,l using a simple moving average λ defined asλ = 1 w · w ∑ i=0 α i . To fill this gap, we complement the churn analysis with an uptime matrix that we will now present.This uptime matrix consists of the uptime patterns of all Tor relays, which we represent as binary sequences. This type of visualization was first proposed by Ensafi and subsequently implemented by Fifield [12]. The information a Tor client needs to connect to an onion service is stored in a DHT that consists of a subset of all Tor relays, the onion service directories (HSDirs). We needed an algorithm for nearest-neighbor ranking that takes as input a "seed" relay and creates as output a list of all relays, ranked by their similarity to the seed relay. Our algorithm ranks relays by comparing these configuration parameters.To quantify the similarity between two relays, we use the Levenshtein distance [18], a distance metric that takes as input two strings and determines the minimum number of modifications-insert, delete, and modifythat are necessary to turn string s 2 into s 1 . To turn string s 2 into s 1 , six operations are necessary; four modifications (green) and two deletions (red):s 1 : Foo10.0.0.19001 s 2 : Bar10.0.0.2549001Our algorithm determines the Levenshtein distance between a "seed" relay and all other relays in a consensus. We did not set any thresholds, to capture every single churn value, fingerprint, and uptime sequence, resulting in an unfiltered dataset of several megabytes of CSV files and uptime images. To defend against Sybil attacks, directory authorities can either remove a relay from the consensus, or take away its Valid flag, which means that the relay is still in the consensus, but Tor clients will not consider it for their first or last hop in a circuit. The columns show (i) what we believe to be the purpose of the Sybils, (ii) when the Sybil group was at its peak size, (iii) the ID we gave the Sybils, (iv) the number of Sybil fingerprints at its peak, (v) the analysis techniques that could discover the Sybils, and (vi) a short description. All relays had the Exit flag and replaced onion domains found in a web server's HTTP response 6 Our datasets and visualizations are available online, and can be inspected for an exhaustive set of potential Sybils. On this GPU, a partial collision for a seven-digit prefix can be found in 2 34 · 1 90,000,000 񮽙 190 seconds, i.e., just over three minutes.We inspected some of the phishing domains and found that the attackers further replaced the original Bitcoin addresses with addresses that are presumably controlled by the attackers, enabling them to hijack Bitcoin transactions. On July 8, 2014, The Tor Project blocked all 123 IP addresses that were running at the time.The "default" Sybils This group, named after the Sybils' shared nickname "default," has been around since September 2011 and consists of Windows-powered relays only. This behavior appears to be a clear attempt to manipulate Tor's DHT.We believe that this Sybil group was run by Biryukov, Pustogarov, and Weinmann as part of their Security and Privacy 2013 paper "Trawling for Tor Hidden Services" [4]-one of the few Sybil groups that were likely run by academic researchers.The "Anonpoke" Sybils All relays shared the nickname "Anonpoke" and were online for four hours until they were rejected. Considering that (i) there are 162 gaps in the archived data, that (ii) we created time series for joining and leaving relays, and that (iii) we determined churn values for all twelve relay flags, we ended up with (72, 061 − 162) · 2 · 12 = 1, 725, 576 churn values. The changelog says that in version four, routers that do not have the Running flag are no longer listed in the consensus.To alleviate the choice of a detection threshold, we plot the number of alerts (in log scale) in 2015 as the threshold increases. Upon inspection, we noticed that this was likely an experiment for a Security and Privacy 2013 paper on deanonymizing Tor onion services [4, § V]. Therefore, our evaluation is doomed to overestimate our algorithm's accuracy because we are unable to test it on the Sybils we did not discover.We evaluate our ranking algorithm on two datasets; the "bad exit" Sybil groups from Table 5, and relay families. We expect the operators of malicious Sybils, however, to go out of their way to obscure the relationship between their relays.To determine our algorithm's accuracy, we used all relay families that were present in the first consensus that was published in October 2015. 7 We stored our datasets on a solid state drive to eliminate I/O as performance bottleneck.The table columns contain, from left to right, our analysis technique, the technique's analysis window, and how long it takes to compute its output. Our practical work with sybilhunter taught us that analyzing Sybils frequently requires manual verification, e.g., (i) comparing an emerging Sybil group with a previously disclosed one, (ii) using exitmap to send decoy traffic over Sybils, or (iii) sorting and comparing information in relay descriptors. In practice, we can reduce this asymmetry and limit our adversaries' knowledge by keeping secret sybilhunter's thresholds and exitmap's detection modules, so our adversary is left guessing what our tools seek to detect. Instead, we are proposing to add a layer of obscurity on top of existing defense layers.We are working with The Tor Project on incorporating our techniques in Tor Metrics [33], a website containing network visualizations that are frequented by numerous volunteers. For example, Sybils that are (i) operated in "bulletproof" autonomous systems [17, § 2], (ii) show signs of not running the Tor reference implementation, or (iii) spoof information in their router descriptor all suggest malicious intent. By analyzing the Sybil groups sybilhunter discovered, we found that (i) Sybil relays are frequently configured very similarly, and join and leave the network simultaneously; (ii) attackers differ greatly in their technical sophistication; and (iii) our techniques are not only useful for spotting Sybils, but turn out to be a handy analytics tool to monitor and better understand the Tor network. Given the lack of a central identity-verifying authority, it is always possible for well-executed Sybil attacks to stay under our radar, but we found that a complementary set of techniques can go a long way towards finding malicious Sybils, making the Tor network more secure and trustworthy for its users.All our code, data, visualizations, and an open access bibliography of our references are available online at https://nymity.ch/sybilhunting/. Sep 20141 The exit relay routed traffic back into the Tor network, i.e., we observed traffic that was supposed to exit from relay A, but came from relay B. The system presented by Ling et al. behaves the same [23]; the authors proposed to run intrusion detection systems on Tor traffic by setting up an exit relay that runs an NIDS system, and routes the traffic back into the Tor network after having inspected the traffic.Oct 2014 1 The relay injected JavaScript into returned HTML. 1 The exit relay routed traffic back into the Tor network, i.e., we observed traffic that was supposed to exit from relay A, but came from relay B. The system presented by Ling et al. behaves the same [23]; the authors proposed to run intrusion detection systems on Tor traffic by setting up an exit relay that runs an NIDS system, and routes the traffic back into the Tor network after having inspected the traffic.Oct 2014 1 The relay injected JavaScript into returned HTML. 1 The relay used OpenDNS as DNS resolver and had the website category "proxy/anonymizer" blocked, resulting in several inaccessible websites, including torproject.org. The injected content was not clearly malicious, but suspicious.Apr 2015 70 † These exit relays transparently rewrote onion domains in returned HTML to an impersonation domain.