A temporal memory error occurs when code uses memory that was allocated, but since freed (and therefore possibly in use for another object), i.e., when an object is accessed outside of the time during which it was allocated.Suppose we have a function pointer stored on the heap that points to function Elmo() (see Figure 1) at address 0x05CADA. Stack-allocated variables are easier to protect, e.g., via escape analysis, which statically checks that pointers to a stack variable do not outlive the enclosing stack frame, or can be reduced to the heap problem, by converting stack allocations to heap allocations [33]. In their scheme, the allocator places each allocated object on a distinct virtual page, even though different objects may share the same physical page; when an object is deallocated, the corresponding virtual page is rendered inaccessible, causing pointer accesses after deallocation to fail. Since then, researchers have proposed more elaborate techniques (CETS [31], DangSan [41], Dangling Pointer Nullification [27] ("DangNull") and FreeSentry [42]), relying on combinations of deeper static analysis and comprehensive instrumentation of heap operations such as object allocation, access, and pointer arithmetic. We make the following contributions:• We study in detail the overhead contributed by the distinct factors of the scheme -shared memory mappings, memory-protection system calls invoked during allocation and deallocation, and more page table entries and virtual memory areas -using the standard SPEC CPU 2006 benchmarks (Section 3). • We evaluate Oscar experimentally using both SPEC CPU 2006 and the popular memcached service, showing that Oscar achieves superior performance, while providing more comprehensive protection than prior approaches.Our work shows, in principle and experimentally, that protection based on page permissions -previously thought to be an impractical solution -may be the most promising for temporal memory safety. Use of memory after it has been freed can be seen as an authorization problem: pointers grant access to an allocated memory area and once that area is no longer allocated, the pointers should no longer grant access to it. The scheme also creates one lock per object, but the number of objects is dominated by the number of pointers.Example Systems: Compiler-Enforced Temporal Safety for C (CETS) [31] is an example of this scheme. Although in our figure we have placed the key next to the pointer (similar to bounds-checking schemes that store Figure 1 for the 'Before'), object space can be reused safely.both the pointer plus the size [25], called plus-size pointers) and lock next to the object, this need not be the case in implementations. Revoking keys is harder than changing the lock, since it requires tracking of key propagation.Example Systems: To our knowledge, this has not been used for any published explicit lock-and-key scheme; but, it segues to the next idea that has been used in prior work: revoking the keys with implicit lock-and-key. Thus, instead of revoking a key from a separate explicit namespace, we can change the pointer's value [27]. Although this scheme does not need to allocate memory for explicit lock or key fields, it does need to track the location of each pointer, which means the physical memory overhead is at least proportional to the number of pointers. Placing one object per page (Figure 7) is wasteful of memory resources: it uses more memory and strains the cache and the TLB.It is not strictly necessary to use page permissions to enforce page inaccessibility after deallocation. However, the other costs (TLB pressure, etc.) are less predictable, so measurements are needed.Our baseline design [23] uses inline metadata to let us map from an object's shadow address to its canonical address.When the program invokes malloc(numBytes), we allocate instead with internal_malloc(numBytes + sizeof(void*)) to allocate an object within a physical page frame and then immediately perform a syscall to create a shadow page for the object. This change unfortunately affects the semantics of the program if it fork()s: the parent and child will share the physical page frames underlying the objects, hence writes to the object by either process will be visible to the other. We disabled hyper-threading and TurboBoost, for more consistent timings. We compiled the nonFortran SPEC CPU2006 benchmarks using gcc/g++ v4.8.4 with -O3. We configured libstdc++ with --enable-libstdcxx-allocator=malloc, and configured the kernel at run-time to allow more virtual memory mappings.We counted malloc and free operations using mtrace. We therefore defer discussion of them until the following section, which introduces our improvements to the baseline design.Even for the complete but unoptimized scheme (Use shadows), most benchmarks have low overhead. Inline padding is a negligible cost for all benchmarks.In Figure 10, we plot the run-time of creating/disabling shadows, against the number of shadow-pagerelated syscalls 2 . We calculated the y-values by measuring the runtime of Create/disable shadows (we used the high watermark optimization from Section 4 to ensure all benchmarks complete) minus MAP SHARED with padding: this discounts runtime that is not associated with syscalls for shadows. The accumulation of vm area structs for old shadows prevented a few benchmarks (and likely many real-world applications) from running to completion.We introduce a simple solution. As we show in Section 6.1, virtual address space exhaustion is an unlikely, tractable problem.Our scheme, including the high water mark, is compatible with address space layout randomization (ASLR). Except for the very first time a chunk has been created by malloc, every shadow creation is preceded by destroying a shadow.Oscar therefore speculatively creates a new shadow each time it destroys a shadow, in Figure 11 (right). However, if the reallocated object (new canonical) is large enough to be stored on its own MAP PRIVATE pages, create shadow will allocate a different set of physical page frames instead of creating an alias. As seen in the graphs, our re-run results are very similar to DangSan's reported results; thus, unless otherwise stated, we will compare Oscar against the latter.Across the complete set of C/C++ SPEC CPU2006 benchmarks, Oscar and DangSan have the same overall overhead, within rounding error (geometric means of 40% and 41%). We compare Oscar to the temporal-only mode of SoftBoundCETS [32] (which we will also call "CETS" for brevity), since that has lower overhead and a more comprehensive dataset than the original CETS paper.The latest publicly available version of SoftBound-CETS for LLVM 3.4 7 implements both temporal and spatial memory safety. com/santoshn/softboundcets-34/commit/ 9a9c09f04e16f2d1ef3a906fd138a7b89df449968 In any case, since CETS has 23% and 114% overhead on bzip2 and mcf respectively -compared to less than 1.5% on each for Oscarincluding them in the comparison would not be favorable to CETS. When applying Oscar to server applications -which are generally more complex than the SPEC CPU benchmarks -we encountered two major issues that resulted in incompatibility and incomplete protection: forking and custom memory allocators. Using MAP SHARED for all allocations is problematic for programs that fork, as it changes the semantics of memory: the parent and child's memory will be shared, so any post-fork writes to pre-fork heap objects will unexpectedly be visible to both the parent and child. After fork, in the child, we make a copy of all heap objects, unmap their virtual addresses from the shared physical page frames, remap the same virtual addresses to new (private) physical page frames, and repopulate the new physical page frames with our copy of the heap objects. We compiled memcached 1.4.25 (and its prerequisite, libevent) and benchmarked performance using memaslap.When we wrapped only glibc's malloc, the overhead was negligible: throughput was reduced by 0-3%, depending on the percentage of set operations ( Figure 17). If Oscar switched to a disjoint metadata store (e.g., a hashtable), it would be easy to extend Oscar to protect any custom memory allocators (not just CMAs with malloc-like interfaces) that are identified: as with glibc's malloc, the allocator function simply needs to be wrapped to return a new shadow, and the deallocator function wrapped to destroy the shadow. Thus, there is no need to explicitly identify region-based CMAs; merely wrapping glibc's malloc/free with Oscar suffices to provide temporal memory safety for such programs i.e., Oscar would provide full use-after-free protection for a region-based allocator, without the need for any custom modifications.Oscar's performance is especially good for programs that use region-based allocators: since there are few malloc()s or free()s to instrument, and correspondingly low memory or TLB pressure, Oscar imposes negligible overhead. Our experimental results confirm that prediction: Oscar's runtime overhead is lower than CETS, DangNull, and FreeSentry overall and on most benchmarks, and comparable to DangSan (but with lower memory overhead for Oscar), even though they all need source code while Oscar does not. Hard to Fill A concern might be that Oscar would exhaust the 2 47 B =128TB user-space virtual address space, necessitating reuse of addresses belonging to freed pages. For example, suppose we allocate a string p on the heap, search for a character, then free the string: char* p = strdup("Oscar"); // Memory from malloc char* q = strchr(p, 'a'); // Find the first 'a' free(p);Computing the index of "a" (q -p == 3) fails with DangNull, since p and q were nullified. Unfortunately, writes to old (pre-fork) heap objects will be propagated between parent and children (see Section 5.1), resulting in memory corruption.While Dhurjati and Adve did measure the runtime of their particular scheme, their measurements do not let us break down how much each aspect of their scheme contributes to runtime overhead. Finally, they used a custom benchmark and Olden [34], which make it harder to compare their results to other schemes that are benchmarked with SPEC CPU; and many of their benchmark run-times are under five seconds, which means random error has a large impact. For these reasons, in this work we undertook a more systematic study of the sources of overhead in shadow-page-based temporal memory safety schemes.To reduce their system's impact on page table utilization, Dhurjati and Adve employed static sourcecode analysis (Automatic Pool Allocation) -to separate objects into memory pools of different lifetimes, beyond which the pointers are guaranteed not to be dereferenced. This has the disadvantages of false positives and lower responsiveness.The Rust compiler enforces that each object can only have one owner [4]; with our lock-and-key metaphor, this is equivalent to ensuring that each lock has only one key, which may be "borrowed" (ala Rust terminology) but not copied. It would be impractical to rewrite all legacy C/C++ software in Rust, let alone provide Rust's guarantees to binaries that are compiled from C/C++. Their non-zero run-time benchmarks have significant overhead -183% for bzip2, 127% for gobmk, 124% for hmmer, and 120% for sjeng -though this in-cludes spatial and stack temporal protection.Dynamic instrumentation (e.g., Valgrind's memcheck [3]) is generally too slow other than for debugging.Undangle [15] uses taint tracking to track pointer propagation. However, due to the high overhead of prior temporal memory safety schemes, some papers trade off protection for speed.Many papers, starting with DieHard [13], approximate the infinite heap (use a heap that is M times larger than normally needed) and randomize where objects are placed on the heap. Both CPI and CPS require compiler support.CFI, CPS and CPI do not help against non-control data attacks, such as reading a session key or changing an 'isAdmin' variable [17]; recently, "data-oriented programming" has been shown to be Turing-complete [24]. Oscar is only a proof-of-concept for measuring the overhead on benchmarks, and is not ready for production, primarily due to the following two limitations.Reclaiming page-table memory takes some engineering, such as using pte free(). Note that the memory overhead comparison in Section 4.3 already counts the size of paging structures against Oscar, yet Oscar still has lower overall overhead despite not cleaning up the paging structures at all.We did not encounter any issues with users' mmap requests overlapping Oscar's region of shadow addresses (or vice-versa), but it would be safer to deterministically enforce this by intercepting the users' mmap calls.Currently, all threads share the same high-water mark for placing new shadows, and this high-water mark is protected with a global mutex. This work was supported by the AFOSR under MURI award FA9550-12-1-0040, Intel through the ISTC for Secure Computing, and the Hewlett Foundation through the Center for Long-Term Cybersecurity.We thank Nicholas Carlini, David Fifield, ´ Ulfar Erlingsson, and the anonymous reviewers for helpful comments and suggestions.