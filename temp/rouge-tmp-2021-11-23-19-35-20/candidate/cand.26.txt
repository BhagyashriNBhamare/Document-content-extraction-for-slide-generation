We address this problem with Cloak, a new technique that uses hardware transactional memory to prevent adversarial observation of cache misses on sensitive code and data. We also show that by applying Cloak to code running inside In-tel SGX enclaves we can effectively block information leakage through cache side channels from enclaves, thus addressing one of the main weaknesses of SGX. Similarly, the detection of cache side-channel attacks is not always sufficient, as recently demonstrated attacks may, for example, recover the entire secret after a single run of a vulnerable cryptographic algorithm [17,43,62]. We ensure permanent cache residency of sensitive code and data using widely available hardware transactional memory (HTM), which was originally designed for high-performance concurrency.HTM allows potentially conflicting threads to execute transactions optimistically in parallel: for the duration of a transaction, a thread works on a private memory snapshot. This behavior makes HTM a powerful tool to mitigate cache-based side channels.The core idea of Cloak is to execute leaky algorithms in HTM-backed transactions while ensuring that all sensitive data and code reside in transactional memory for the duration of the execution. However, code inside SGX enclaves is as much vulnerable to cache attacks as normal code [7,20,46,57] and, when running in a malicious OS, is prone to other memory access-based leakage including page faults [10,61]. We demonstrate and discuss how Cloak can reliably defend against such side-channel attacks on enclave code.We provide a detailed evaluation of Intel TSX as available in recent CPUs and investigate how different implementation specifics in TSX lead to practical challenges which we then overcome. Finally, we also discuss limitations of Intel TSX, specifically negative side effects of the aggressive and sparsely documented hardware prefetcher.The key contributions of this work are:• We describe Cloak, a universal HTM-based approach for the effective mitigation of cache attacks. If the eviction of a cache set results in longer execution time, the attacker learns that the victim likely accessed it. Concurrent read accesses by other threads to the read set are generally allowed; however, concurrent writes are problematic and-depending on the actual HTM implementation and circumstances-likely lead to transactional aborts. If data is Thread 1 Thread 2Begin transaction Read 0x20Write 0x40Read 0x20Write 0x40 wr ite co nfl ict un do End transaction Figure 1: HTM ensures that no concurrent modifications influence the transaction, either by preserving the old value or by aborting and reverting the transaction. Depending on the implementation, read and write set can have different sizes, and set sizes range from multiple KB to multiple MB of HTM space.Due to HTM usually being implemented within the CPU cache hierarchy, HTM has been proposed as a means for optimizing cache maintenance and for performing security-critical on-chip computations: Zacharopoulos [64] uses HTM combined with prefetching to reduce the system energy consumption. This enables the attacker to launch Flush+Reload attacks, in addition to Prime+Probe attacks.SGX In this scenario, the processor is trusted but the adversary has full control over the OS, the hypervisor, and all other code running on the system, except the victim's code. While the attacker has more control over the software running on the machine, the SGX protections prevent sharing of memory pages between the enclave and untrusted processes, which renders Flush+Reload attacks ineffective in this setting.All other side-channels, including power analysis, and channels based on shared microarchitectural elements other than caches are outside our scope. * ( v o l a t i l e s i z e t * ) p ; A E S e n c r y p t ( p l a i n t e x t , c i p h e r t e x t , &key ) ; x e n d ( ) ; } R2 A transaction aborts immediately when any part of transactional memory leaves the cache hierarchy.R3 All pending transactional memory accesses are purged during a transactional abort.R4 Prefetching decisions outside of transactions are not influenced by transactional memory accesses.R1 ensures that all sensitive code and data can be added to the transactional memory in a deterministic and leakage-free manner. The Intel manual states that "an implementationspecific second level structure" may be available, which probabilistically keeps track of the addresses of read-set 0 1,000 2,000 3,000 4,000 5,000 0% 50% 100% Array size in KB cache lines that were evicted from the L1 cache. This result strongly suggests that executed code does not become part of the read set and is in general not explicitly tracked by the CPU.To still achieve R1 and R2 for code, we attempted to make code part of the read or write set by accessing it through load/store operations. Hence, forms of R1 and R2 can also be ensured for code in the L1 instruction cache without it being part of the write set.In summary, we can fulfill requirements R1 and R2 by moving code into the read set or, using undocumented microarchitectural effects, by limiting the amount of code to the L1 instruction cache and preloading it via execution. The victim in this experiment starts the transaction, by placing data and code into transactional memory in a uniform manner (using either reads, writes or execution). We observed identical high-level re- sults for all forms of preloading (reading, writing, executing) and all forms of secret accesses (reading, writing, executing). For example, na¨ıvelyna¨ıvely preloading a large (> 32 KB) sequential read set after the write set leads to assured abortion during preloading, as some write set cache-lines are inevitably evicted from L1. Reversing the preloading order, i.e., read set before write set, partly alleviates this problem, but, depending on the concrete read set access patterns, one is still likely to suffer from aborts during execution caused by read/write set conflicts in the L1 cache. We implemented the read-set preloading strategy from Section 5.2.1 in a small C++ container template library.The library provides generic read-only and writable arrays, which are allocated in "read" or "write" cache lines respectively. For programmer-annotated functions on Windows, the compiler adds code for starting and ending transactions, ensures that all code cache lines are preloaded (via read or execution according to Section 5.2.2) and, to not pollute the write set, refrains from unnecessarily spilling registers onto the stack after preloading. We demonstrate that in all cases, in the local setting (Flush+Reload) as well as the cloud setting (Prime+Probe), Cloak is a practical countermeasure to prevent state-of-the-art attacks. The preloading step fetches the 4 T-Tables, i.e., it adds 4 KB of data to the read set.We performed roughly 2 billion encryptions in an asynchronous attack and measured the cache hits on the T-table cache lines using Prime+Probe and Flush+ Reload. We investigated leakage in the GTK framework, which performs a binary search to translate raw keyboard inputs to platform-independent key names and key values. Instead of multiple binary searches that leak information we only identified one binary search that is still performed upon every keystroke.In order to demonstrate the general applicability of Cloak, we reproduced the attack by Gruss et al. [24] on a recent version of the GDK library (3.18.9) which comes with Ubuntu 16.10. Thus, the overhead we introduce is negligible for the overall latency and performance.We conclude that Cloak can be used as a practical countermeasure to prevent cache template attacks on fine-grained information such as keystrokes. To demonstrate Cloak's applicability to the SGX environment and its capability to support larger working sets, we adapted an existing C++ implementation of a decision tree classification algorithm [49] using the toolset described in Section 5.3. The overhead increases with the batch size, because the baseline also profits from batching (i.e., "cache warming" effects and amortization of costs for entering/leaving the enclave), while the protected version experiences more transactional aborts for larger batches. Even though the experimental setting in Ohrimenko et al. [49] is not the same as ours (for instance they used the official Intel SGX SDK, an older version of the compiler, and their input data was encrypted) and they provide different guarantees, we believe that their reported overhead of circa +6 200% for a single query to SGX highlights the potential efficiency of Cloak. In particular, malicious system software, i.e., the OS, can amplify sidechannel attacks by concurrently (A1) interrupting and resuming enclave threads [40], (A2) unmapping enclave pages [61], (A3) taking control of an enclave thread's sibling hyper-thread (HT) [11], or (A4) repeatedly resetting an enclave. While SGX does not provide functionality to directly check for A1 and A2 or to prevent them, it is simple with Cloak: our experiments showed in line with Intel's documentation [31] that transactions abort with code OTHER (no bits set in the abort code) in case of interrupts or exceptions. One way of doing so is to transmit a secret (derived using the rdrand instruction inside the enclave) over a timing-less L1-based TSX covert channel: for each bit in the secret, the receiver starts a transaction and fills a certain L1 cache set with write-set cache lines and busy-waits within the transaction for a certain time; if the current bit is 1, the sender aborts the receiver's transaction by touching conflicting cache lines of the same cache set. 6 While a malicious OS could attempt to eavesdrop on the sender and replay for the receiver to spoil the check, a range of additional 6 Using the read set instead yields a timing-less cross-core covert channel with a raw capacity of 335 KB/s at an error rate of 0.4%. For example, the two threads could randomly choose a different L1 cache set (out of the 64 available) for each bit to transmit.To protect against A4, the enclave may use SGX's trusted monotonic counters [3] or require an online connection to its owner on restart.Finally, the enclave may demand a private LLC partition, which could be provided by the OS via Intel's recent Cache Allocation Technology (CAT) feature [32] or "cache coloring" [11,37,58]. Finally, it is important to note that Cloak is limited by the size of the CPU's caches, since code and data that have secret-dependent accesses must fit in the caches. Mimosa builds upon the existing TRE-SOR system [47], which ensures that a symmetric master key is always kept in the CPU's debug registers. However, a cache attack on the square-and-multiply routine of RSA in the presence of Mimosa would still be possible. To detect hardware faults, the HAFT system [39] inserts redundant instructions into programs and compares their behavior at runtime. For T-SGX, Shih et al. [59] reported performance overheads of 4%-108% across a range of algorithms and, due to the strategy of splitting code into small execution blocks, caused only very low rates of transactional aborts.The strategy employed by T-SGX cannot be generally transferred to Cloak, as-for security-one would need to reload the code and data of a sensitive function whenever a new block is executed. Like T-SGX, the recent Déjà Vu [8] approach also attempts to detect page-fault side-channel attacks from within SGX enclaves using TSX: an enclave thread emulates an non-interruptible clock through busy waiting within a TSX transaction and periodically updating a counter variable. We presented Cloak, a new technique that defends against cache side-channel attacks using hardware transactional memory. Finally, we showed that one of the main limitations of Intel SGX, the lack of side-channel protections, can be overcome by using Cloak inside Intel SGX enclaves.Listing 2: Decision tree classification before and after Cloak: the code in black is shared by both versions, the code before Cloak is in dark gray(lines 1-3), and Cloakspecific additions are in blue (lines 5-7, 11, 12, 15).1 using Nodes = nelem_t*; 2 using Queries = Matrix<float>; 3 using LeafIds = uint16_t*; 4 5 using Nodes = ReadArray<nelem t, NCS R>; 6 using Queries = ReadMatrix<float, NCS R>; 7 using LeafIds = WriteArray<uint16 t, NCS W>; 8 9 void tsx protected look up_leafi ds ( 10 Nodes & nodes , Queries & Listing 2 gives an example of the original code for tree traversal and its Cloak-protected counterpart.