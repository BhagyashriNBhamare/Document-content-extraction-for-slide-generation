We conclude by discussing how non-provable privacy-preserving sys-† Personal data holds a significant potential for researchers and organizations alike, yet its large-scale collection and use raise serious privacy concerns. While scientists have compared the impact of modern large-scale datasets of human behaviors to the invention of the microscope [1], numerous scandals, such as the recent Cambridge Analytica debacle [2] highlight the importance of privacy and data protection for the general public and modern societies.Historically, the balance between using personal data and preserving people's privacy has relied, both practically and legally, on the concept of data anonymization. Yet, efficient differential privacy mechanisms are generally very use case-specific and, even if a large range of differentially private mechanisms have been proposed, there is still no practical widely deployed differential privacy solution for general-purpose data analytics [13]. The attacks work in three parts: (i) canceling out part of the sticky noise using multiple queries, (ii) exploiting the noise Diffix adds to one query in order to learn information about the query set associated to this query, and (iii) using logical equivalence between queries to obtain independent noise samples for the same query. We develop two noise-exploitation attacks that take advantage of the structure of Diffix's sticky noise to infer private (also called secret) attributes of individuals in the dataset, violating the inference requirement from the Article 29 WP definition of anonymization [19]. It proceeds in two steps: (i) a validation step, searching for subsets of known attributes to use for the attack, that will satisfy the assumptions required for its success, and (ii) an inference step that uses the attributes found to predict users' private attribute's value. This paper makes the following contributions:• By developing and implementing two attacks, we demonstrate that Diffix alone does not currently satisfy the inference requirements of the Art. 29 WP. • We make a range of defense-in-depth proposals, which can be used to improve the practical privacy guarantees of both Diffix and other non-differentially private data anonymization tools. Section 5 discusses the assumptions of the attacks and potential solutions for Diffix to thwart noise-exploitation attacks moving forward. The analyst can send SQL queries to Diffix, which will process the queries and then output a noisy answer.We denote with A D the set of attributes in the database D. For instance, A D could contain 4 attributes A D = {gender, age, zip, HIV} with HIV a binary attribute (0 or 1). Diffix's output for Q on the database D is Q(D) = Q(D) + static[gender = M] + dynamic Q [gender = M] + static[age = 37] + dynamic Q [age = 37] + static[zip = 48828] + dynamic Q [zip = 48828]where Q(D) is a random value drawn from a normal distribution N (Q(D), 6). If Q(D) > 1, then Diffix computes a noisy threshold T ∼ N (4, 1/2), using the seed:threshold_seed = XOR(salt, hash(uid 1 ), . . . , hash(uid m ))If Q(D) < T , the query is suppressed; otherwise, the noisy output Q(D) is computed and sent to the analyst. Third, exploiting logical equivalence between some queries, it is possible to circumvent the "stickiness" of the noise by repeating (almost) the same query and consequently obtain independent noise samples. Our cloning attack relies on dummy conditions that conditionally strongly affect the output of the query depending on the value of the secret attribute. We first define further notations: with A ⊆ A D a set of attributes, x (A) is the restriction of the record x to A, i.e. the vector one obtains after removing from x every entry for attributes that are not in A. For example, if A D = {gender, age, zip, HIV}, x = (M, 27, 55416, 1) and A = {gender, age, HIV}, then x (A) = (M, 27, 1). H4 There exists an oracle Unique that takes as input any restricted record z (R) and outputs whether z (R) is unique.Unique(z (R) ) = True if and only if there is no other record y in D such that z (R) = y (R) . This alone already allows the attacker to infer Bob's secret, x (s) , with better than random accuracy.The third part of the attack allows us to strongly improve the accuracy of our inference. In our notation:Q j ≡ count    k i=1 i = j a i = x i ∧ s = 0    (7) Q j ≡ count    k i=1 i = j a i = x i ∧ a j = x j ∧ s = 0    (8)Running all queries {(Q j , Q j )} j≤k , the attacker collects a vector of realizations {q j } j≤k whereq j = Q j (D) − Q j (D). k ← |A|, Q ← / 0, R ← / 0 2 for j ← 1 to k do 3 I ← {i ∈ [1, k] | i = j} 4 Q ← count ( i∈I a i = x i ∧ s = 0) 5 Q ← count ( i∈I a i = x i ∧ a j = x j ∧ s = 0) 6 if Q > 0 and Q > 0 then 7 q j ← Q − Q 8 Q ← Q ∪ {q j } 9 end if 10 end for 11 for j ← 1 to k do 12 I ← {i ∈ [1, k] | i = j} 13 R ← count ( i∈I a i = x i ∧ s = 1) 14 R ← count ( i∈I a i = x i ∧ a j = x j ∧ s = 1) 15 if R > 0 and R > 0 then 16 r j ← R − R 17 R ← R ∪ {r j } 18end if 19 end for 20 if Q = / 0 and R = / 0 then21 return NoSamples 22 end if 23 f ← PDF of N (0, 2), g ← PDF of N (1, 2k + 2) 24 L ← ∏ q∈Q f (q) g(q) ∏ r∈R g(r) f (r) 25 return L ≥ 1 In this section, we present an extension of the differential noise-exploitation attack, which we call cloning attack. That is, Procedure FullDifferentialAttack(A * , x (A * ) , s) Input:∧ a∈A a = x (a)The attack addresses several limitations of the differential attack, making it much stronger in practice.First, the cloning attack does not require an oracle to confirm that the background information uniquely identifies a user. Furthermore, the cloning attack validates this automatically (and thus prevents bucket suppression) with high confidence.While much stronger, the attack relies on the attacker being able to produce a set of distinct dummy conditions ∆ = {∆ j } 1≤ j≤|∆| , where each ∆ j is an SQL statement such that the set of users matching A = x (A ) is the same as the set of users matching A = x (A ) ∧ ∆ j . For each dummy condition ∆ j , we define the two queries:Q j ≡ count A = x (A ) ∧ ∆ j ∧ s = 0 (9) Q j ≡ count A = x (A ) ∧ ∆ j ∧ u = x (u) ∧ s = 0(10)Withq j = Q j (D) − Q j (D), we have:q j = Q j (D) − Q j (D) − static[u = x (u) ] − dynamic Q j [u = x (u) ] + ∑ i∈A dynamic Q j [a (i) = x (i) ] + dynamic Q j [s = 0] − ∑ i∈A dynamic Q j [a (i) = x (i) ] − dynamic Q j [s = 0] + dynamic Q j [∆ j ] − dynamic Q j [∆ j ]By the same argument we presented for the differential attack, ifx (s) = 1 then Q j (D) = Q j (D)and most dynamic and static noises cancel out, giving:q j = − static[u = x (u) ] − dynamic Q j [u = x (u) ](11)As this value does not depend on the dummy condition used, we have that q 1 = q 2 = · · · = q |∆| . As the noise values given bydynamic Q j [∆ j ] and dynamic Q j [∆ j ]depend on ∆ j , the probability that all (or any) q j are equal is zero.We can therefore complete the attack by inferring that x (s) = 1 if q 1 = · · · = q |∆| , and x (s) = 0 otherwise. We now consider the case where results are rounded to the nearest nonnegative integer, and propose a simple modification of our attack that accounts for this.When the results of the queries Q j and Q j are rounded, the corresponding q j might not be identical if x (s) = 0. The user is value-unique in the dataset according to (A , u) for the secret attribute s.We here propose procedures for an attacker to determine whether (A , u) satisfies the two assumptions with high probability.Validating the first assumption can be done easily by submitting queries {Q j } 1≤ j≤|∆| and {Q j } 1≤ j≤|∆| to Diffix. Experiments in section 4 show that this heuristic works very well on real-world datasets.Procedure NoBucketSuppression(A , u, x (A ,u) , ∆, s, v)Input: known attributes (names A , u and values x (A ,u) ), dummy conditions ∆, secret s and target value v Output: True if (A , u) passes the tests and is deemed to satisfy assumption 1, False otherwise 1 ok Q ← 0, ok Q ← 0 2 for j ← 1 to |∆| do 3 ϕ ← A = x (A ) ∧ l = j ∆ l 4 Q ← count (ϕ ∧ s = v) 5 Q ← count ϕ ∧ u = x (u) ∧ s = v 6 if Q > 0Q ← count(A = x (A ) ∧ u = x (u) ) 2 return Q = 0The procedures CloningAttack and NoBucketSuppression both issue (the same) 2|∆| queries, while ValueUnique uses only one query. Using this heuristic, the attack targets 55.4% of the users in the dataset, achieving 91.7% accuracy with a maximum of 32 queries per user in our experiments.Procedure FullCloningAttack(A * , x (A * ) , ∆, s, v) In order to assess the effectiveness of our attacks, we implemented Diffix's mechanism for counting queries as described in the original paper [18]. CENSUS: U.S. Census dataset with 199,523 records and 42 attributes, incl. total personal income (digitized, null income as negative condition) as secret attribute [28]. To obtain a balanced experiment, for 50% of runs we select as the secret attribute a pair (location, time) where the user was present, and for the other 50% we select a pair where the user was absent. For instance, the average size of the value-unique class (i.e. the set of value-unique users sharing the same restricted record) in the ADULT dataset is 1.44, with no class containing more than 4 users and similar numbers for the other datasets. These conditions can be syntactic (e.g., age ≥ 15 for the query age = 23), semantic (e.g., status = retired for age = 23), or pragmatic (e.g., age = 15 against a database containing only adult individuals). If both pass and the ValueUnique test is passed as well, the attack proceeds with the actual inference procedure CloningAttack for both v = 0 and v = 1. Specifically, privacypreserving query-based system such as Diffix (regardless of whether they have provable guarantees or not) would benefit from a defense-in-depth approach, by monitoring the query stream for queries that are likely to lead to exploitation.Intrusion detection. If the user of such a system is authenticated, then a suspicious-looking query stream can lead to temporary account suspension and further investigations of their activity, including after the fact, as new attacks are being uncovered.Increased friction. Third, the cloning attack, which we developed after-wards, is able to validate its assumptions automatically and performs very well on a large range of real-world datasets.The code of our differential and cloning attacks, as well as the experiments performed in this paper, are available at https://cpg.doc.ic.ac.uk/signal-in-the-noise. While reconstruction attacks aim at inferring one or more attributes of some record in the dataset (violating the inference requirement of the Art. 29 WP), the goal of tracing attacks is only to determine whether the data about a certain individual (more precisely, their record) is present in the dataset. Specifically, Diffix allows for infinitely many queries with little noise added to outputs.General-purpose analytics usually refers to systems that allow analysts to send many queries of different type, and ideally permit to join different datasets. In 2017, Johnson et al. [13] proposed a new framework for general-purpose analytics, called FLEX, developed in collaboration with Uber. The attack by Pyrgelis et al. [43] is as follows: the attacker trains a machine learning algorithm on a linkability dataset (the attacker's background knowledge) to infer the presence of a user in a protected dataset (accessible only through queries on Diffix). Second, it assumes a strong adversary who has access to the full trajectory of a user exactly as it exists in the protected dataset, for a large number of users. This allows the attacker to produce a noisy linear system that can be solved using linear programming techniques to reconstruct the entire set of secret attributes {s 1 , . . . , s n } with perfect accuracy in polynomial time.While this attack can successfully reconstruct the entire dataset, it presents two limitations compared to our attack.First, it requires that the system allows queries of the type ∑ i∈I s i , i.e. queries that select any analyst-defined set of users I ⊆ [n], the "row-naming problem". The attacker would then perform a uniqueness attack on the reconstructed dataset to infer the secret attribute of the victim.On the contrary, the number of queries used by our attacks is independent of the number of records in the dataset. Furthermore, our results show that naive data-dependent noise leads to highly vulnerable systems.Our differential noise-exploitation attack, given little auxiliary information about the victim, combines specific queries and estimates how the noise is distributed to infer the value of the private attribute. In a synthetic best-case dataset, the attacker can predict with 92.6% accuracy private attributes, using only 5 attributes.Our cloning noise-exploitation attack extends the first one by adding "dummy" conditions that do not change the selected query set. Then p err 0 = p err 1 = Pr[α 0 Z 0 − α 1 Z 1 < 0]where, for i = 0, 1, Z i is a noncentral chi-squared distribution with n degrees of freedom and noncentrality parameterλ i = n µ i σ i + µ 0 σ 2 1 − µ 1 σ 2 0 σ i (σ 2 0 − σ 2 1 ) 2 and α i = σ 2 0 − σ 2 1 2σ 2 1−i . For simplicity, we suppose that Diffix's outputs are not rounded to the nearest nonnegative integer and bucket suppression is never triggered for the queries in the attack, so that every pair of queries ( Q j , Q j ) and ( R j , R j ) yields a valid sample. We focus only on the cloning attack, as it does not require an oracle and achieves much better accuracy.The cloning attack requires a set of attributes (A , u), where the restricted record x (A ,u) uniquely identifies the victim, but the vector x (A ) is shared across a larger population (to avoid bucket suppression). As in section 4, we used |∆| = 10 dummy conditions and ran the attack on 1000 random users.