Such technologies include object identifiers 6 [45] and barcode readers, 7 [52] text readers, 4 color readers, 2 money readers, 8 and crowd-sourced visual question-answering systems [1,2] for multiple purposes such as identifying objects, reading prescriptions, and answering subjective questions. In real time crowd-sourced assistive systems, users are limited in the amount of time to review the content they are sharing and might capture and share sensitive information mistakenly [15,53]. Several works reported situations when a visually impaired user inadvertently shared images containing private information with a crowd-worker, sometimes without understanding either the risk or that sensitive information is being captured [8,33,34]. Moreover, our work provides insight into what should be shared (or not) as background objects depending on the human-sourced assistive technologies with the goal of better understanding their privacy concerns and, therefore, providing design recommendations to develop assistive devices for avoiding inadvertent sharing of private visual information. After analyzing the dataset, we observed five major privacy violations as foreground objects or background objects in the images: address information (e.g., on envelopes), prescription labels, credit card information, contents of digital screens (e.g., computer screen), and the presence of the face or other body parts of the user (as well as of bystanders). To analyze our data, we conducted an overall Kruskal-Wallis test (for multiple groups and between subjects), a Wilcoxon rank sum test (for two groups and between subjects), a Friedman rank sum test (for multiple groups and within subjects), and a Wilcoxon signed rank test (two groups within subjects) across all conditions to see if there was any significant difference in the measured variables among the conditions. The researchers coded each response into one of seven reasons for their information sharing practices: 'burden' (does not want to bother family or friends), 'impression' (does not want to feel embarrassed or awkward), 'indifferent' (does not mind if information is shared), 'relevance' (does not want to share any unnecessary information), 'professionalism' (does not want to share with volunteers), 'trust' (has more faith in friends or family members), and 'security' (does not want identity to be compromised). Participants also reported how they sought help from sighted people: 122 (81.8%) for reading documents , 101 (67.7%) for identifying objects, 95 (63.7%) for identifying color, and 46 (30.8%) for seeking subjective opinions (e.g. how the participant looked in new clothing). They were somewhat comfortable with laptop To understand the concerns with sharing photos that capture people in the background, we considered two types of content pertaining to people: 'self-disclosure' (e.g., reflection of the participant's face on the laptop screen, capturing the participant's face or body part, or a photo frame with a picture of the participant) and 'bystanders' in the photo (e.g., other people in a restaurant or the face or body part of a colleague). The result indicates that participants who are low vision (µ = 2.0,σ = 1.37,95% CI [1.9,2.2]) were much more concerned than totally blind (µ = 2.6,σ = 1.51,95% CI [2.5,2.7]) participants for disclosing information related to PII.Similarly, for self-disclosure, low-vision (µ = 3.3,σ = 1.4,95% CI [3.2,3.5]) participants were more concerned than totally blind (µ = 3.7,σ = 1.23,95% CI [3.6,3.8]) participants. However, the anxieties of being a burden to the family often limited them from soliciting aid from family.Trust and reliance: We found that family is one of the most trusted support systems for people with VIPs, and they are comfortable sharing almost any kind of information with them when seeking support. Also, if they have a picture on their phone that contains personal info about me, this creates an opportunity for someone other than my friend to see the picture on my friend's phone (e.g., friend's family members, romantic partner), which would jeopardize the privacy and security of the information." Many of these concerns were related to how camera-based assistive systems were creating a lack of security in people's daily lives -that is, these systems were serving to further marginalize their identities.Broadly speaking, when populations are marginalized based on their identities, they are placed at the edge, beyond boundaries, or on the outside of what is considered normative, and individuals and groups can be marginalized on various intersections of their identity, such as their race, gender, sexual orientation, socioeconomic status, or perceived ability [64]. -I ask my friends -I ask my family members -I ask random strangers -I ask professional agents or crowd workers or volunteers through assistive technology -I don't ask anyone Q7.Which of the following assistive technologies have you used so far? Please select all that apply.-To identify an object -For reading documents or screens or labels -To get a general description of a scene -To get the friend's opinion on something (e.g. -Identify the color of a dress or any object -Other (Open text) Scenarios: Suppose there is an assistive technology where you can seek help from your friends by taking a photo of the object, recording the question and sending it to them. We used same 5-point Likert scale described in Q13 for each of the following options. We conducted an overall KruskalWallis test and observed significant differences in the sharing preference with audiences for PII, impression management, and general objects (PII: χ 2 (1) = 26.07, p < 0.001, impression management: χ 2 (1) = 12.627, p < 0.001, general: χ 2 (1) = 13.181, p < 0.001). Although there is a growing body of work exploring the needs of people with VIPs [16,61,62], our study yielded novel privacy and security concerns of people with VIPs related to their sharing of information with crowd workers and human assistants using camera-based assistive systems. As people with VIPs continue to leverage assistive technologies in their routine lives, this leads to the question of what privacy issues emerge and how we, as designers, can best design for the privacy of this particularly vulnerable population. More than half of the participants, 96 (60.4%), were visually impaired since birth, whereas the rest became visually impaired afterward: 34 (21.4%) since childhood, 15 (9.4%) since early adulthood (18-40 years old), 11 (6.9%) since middle adulthood (41-60 years old), and 3 (1.9%) since late adulthood (61+ years old). To explore the role of human assistance in their lives, participants were asked whom they usually asked for help and their purposes of seeking help from them. 9 We categorized the background objects in our survey into four types: (1) Personally Identifiable Information or PII (credit card numbers, bills, mail showing one's address, and official documents) [55], (2) objects affecting one's impression management (mess, medical prescriptions), 10 (3) general objects (food, books), and (4) laptop screens. "I have a close relationship with family, I generally don't care what they see. When others are present, such as guests, the context shifts and the rules and norms also change, and this same person may not feel comfortable engaging in these same behaviors.The continual shaping of context is related to impression management [31], where people are trying to control how they present themselves to others. If there was an assistive technology where you could ask your friends to identify the medicine bottles by taking a picture of the medicines, how comfortable would you feel asking them for help? Since most camera-assisted technologies follow a similar approach, the publicly available VizWiz dataset illustrated common privacy issues that may arise while using such a service.The dataset comprises 20,000 publicly available images and the associated questions (as text) about the images. We asked visually impaired assistive technology users to sign-up through a form provided if they met the following criteria: participants had to be (1) living in the United States for at least five years to help control for cultural variability [48]; (2) 18 years of age or older; and (3) visually impaired. In light of these concerns, a common defensive strategy was to physically clear the exposed areas and remove the sensitive contents before using the cameras: "I would need to keep in mind who I was asking for assistance, I would also check the area to make sure it was clear of clutter and other objects. In the same vein, Dosono et al. found that college Reserve Officers' Training Corps (ROTC) students were more comfortable sharing personal crises related to impression management (e.g., physical injuries) with family and counselors instead of their ROTC peers [28]. -I ask my friends -I ask my family members -I ask random strangers -I ask professional agents or crowd workers or volunteers through assistive technology -I don't ask anyone Q7.Which of the following assistive technologies have you used so far? Our surveys captured peoples' concerns related to sharing information across three different scenarios: in home (located within a residential space), office (located at the place of employment), and restaurant (located at a dining establishment) settings. "I wouldn't mind showing food or maybe myself but any private info depending who I was talking to especially a credit card with all the scams going on I wouldn't really like, though I would try to make sure that I didn't show that stuff." In the context of image sharing by 'lifeloggers,' Hoyle et al. [41,42] did not study specific audiences, but they also found that participants were concerned about private information (such as screens and other objects with textual information), impression management, and the presence of bystanders in their photos. Thus, we argue that in order to create more private and secure assistive technologies, we must begin to humanize assistive technology; that is, we must train computer vision algorithms to better understand what kinds of objects people might want others to (not) see, as well as be cognizant of where we need to enforce human assistance as opposed to algorithmic assistance. • Questions about which (if any) electronic devices and assistive technologies the participant uses, how frequently they use the camera and share images online, and questions on their level and duration of visual impairments. Please select all that apply.-To identify an object -For reading documents or screens or labels -To get a general description of a scene -To get the friend's opinion on something (e.g. In particular, we would like to understand how you would like to use such technologies to get help from your friends.Q13. Our participants shared extreme privacy and security concerns about volunteers and agents that varied based on impersonal trust and the anonymous nature of the interaction. In the context of level of impairment, prior work has found coping strategies such as 'acceptance' where people with visual impairments (especially the totally blind) felt they "had very little choice other than to accept the risks" [8]. A raffle-based approach is also less likely to invite abuse and instead stimulate voluntary participation and high-quality answers [17]. [P61] "Considering that this is my family, I am already comfortable with them assisting me with my needs. In the first phase, participants reported varying levels of accessibility issues they faced in the survey, such as difficulties in navigating through the text fields, not having a progress bar, and minor confusion about the wording of some questions. -Laptop or notebook computer -Smart phone -Tablet computer -Desktop computer -Smart watch -Fitness tracker -Wearable devices -Smart glasses (e.g. Google glass, Hololens) -Other (Open text) Q4. To address this problem, Brady et al. [18] introduce the idea of social microvolunteering, a type of intermediate friendsourcing in which a volunteer who participates ask his networks of friends to answer a visual question on behalf of a visually impaired person. • Questions about the kind of help they seek from sighted people, whether they shared images or made video calls to a sighted person for seeking help, and what questions they usually ask. We used same 5-point Likert scale described in Q16 for each of the following options. We conduct a quantitative analysis of their privacy preferences as well as a qualitative analysis of the reasons participants provided for their preferences.Our participants reported significant privacy and security concerns for information captured in the background. It may be that people who are totally blind are less aware of the possible privacy risks than people with low vision or are more willing to compromise their privacy because they have become accustomed to a higher need for assistance and 'acceptance' of less privacy in general.Finally, prior work has found that people may have more trust in volunteers compared to paid workers because of a stronger perception of altruism and sincerity of the volunteer [39]. To provide greater support to visually impaired users, VizWiz Social [20] expands the initial VizWiz application by including friend-sourced answers (using Twitter, Facebook, or email from their known contacts) along with crowd-sourced answers (Mechanical Turk, IQ Engines). Thus, we need to continue to understand where systems are creating insecurity through additional explorations of a broad range of assistive technologies amongst the visually impaired, while also uncovering new values that can drive future design. [P114]We sought to understand the disclosure behavior of the participants and found that participants considered sharing the image of bystanders without their consent to be a violation of their privacy. A deeper understanding of these concerns can provide insight into how AI and human assistance can be leveraged to provide both trustworthy and privacy aware visual assistance to people with VIPs.In this paper, we report on the privacy concerns of people with VIPs when using human-powered, camera-based assistive systems. Such applications allow visually impaired users to send pictures or make video calls for getting answers to their visual questions from a sighted crowd-worker or volunteer. Specifically, we focus on the following research questions:R1: What are the privacy concerns of people with visual impairments in the context of background objects that are inadvertently captured and included in photos sent to human assistants?R2: While using such technologies, how do their privacy concerns vary for different classes of background objects and the type of human assistants (friends, family, volunteers or crowd-workers)? To better understand the privacy concerns regarding the disclosure of background objects to different types of human assistants (friends, family, and others), we conducted an online survey with 155 visually impaired participants. No significant relationship was found for sharing laptop screens with audiences.Next, for all groups of objects (other than laptop screens) we conducted Dunn's post-hoc pairwise tests with BH correction to detect any significant differences for different audiences. To understand how sharing p