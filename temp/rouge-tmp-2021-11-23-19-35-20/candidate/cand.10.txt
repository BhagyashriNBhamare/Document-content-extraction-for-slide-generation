This considers a slightly different setting in which the parties repeatedly evaluate some function, and the goal is to obtain good amortized efficiency by batching the cut-and-choose procedure either across multiple instances of secure computation [19,11], or at the gate level [24,6]. In addition, MajorityCut works better for applications with long outputs as its cost does not grow with output length.When setting parameters for cut-and-choose protocols, in order to optimize efficiency for some target level of security, state-of-the-art approaches treat circuit checking roughly as expensive as circuit evaluation, and hence strive to optimize the total number of garbled cir- To be conservative in estimating r, figures assume 128-bit labels. However, the bandwidth costs are markedly different for checking and evaluating circuits: garbled circuits that are evaluated must be transmitted in their entirety, but checking garbled circuits can be done by generating the circuit from a short seed and committing to the circuit using a succinct commitment [7,14,2]. Table 1 presents, in the context of a few example applications, the bandwidth costs for sending an entire circuit (i.e. the costs for an evaluated circuit) versus the cost for committing to the circuit (which, for simplicity, requires only one SHA256 hash), and thus a sample ratio r that we use in this paper as a variable.Based on these observations, we propose a new approach to optimizing parameters in cut-and-choose protocols. Our approach casts the interaction between the circuit generator and circuit evaluator as a game, computes the optimal strategies in this game (which, interestingly, turn out to be mixed strategies), and then sets parameters while explicitly taking into account the relative costs of circuit checking and circuit evaluation. Our techniques enable optimization based on the precise relative costs of checking and evaluating, which in turn may depend on the function being computed as well as characteristics of specific deployment settings, such as software, hardware configuration and network condition, etc. We stress that, in contrast to the common belief used in the state-of-the-art cost analysis of cut-and-choose protocols, the cost of cut-and-choose is usually not best represented by n-the total number of circuits generated, but rather by a cost ratio r between checking and evaluation which depends on many factors such as (1) the kind of cost (e.g., bandwidth or computation); (2) the deployment environment (e.g., network condition, distribution of computation power on the players, buffering, etc.) (3) the specific cryptographic primitives and optimization techniques (e.g., the garbling scheme) used in a protocol. Hence, when the evaluator uses strategy x x x, the expected failure probability of the MajorityCut scheme is∑ i≤2b x i · 񮽙 n − b n − i n n − i 񮽙 Since i ≤ n and 񮽙 n−b n−i 񮽙 = 0 for all i < b, this sum can be further reduced to ∑ min(n,2b) i=b x i · 񮽙 n−b n−i n n−i񮽙 . In these settings, however, we opt to live with a suboptimal pure strategy, based on the observation that the standard deviation of e is already so small (less than 0.6 and only keeps decreasing as r grows) that the cost of a sub-optimal pure strategy (i.e. a combination of n and e) approximates the theoretical optimal pretty well ( Figure 3b). In comparison, the best protocols that use BatchedCut need to amortize 1000s of protocol executions to achieve security when sending roughly 10 circuits.In Figure 2, the cross-marked solid curve delineates the optimal cost of mixed strategies (among all strategies with public fixed n), while the dot-marked dashed curve delineates pure-strategy approximation of the optimal mixed strategies (efficiently computed as a result of step 2 of Figure 1 search algorithm). Our approach to MajorityCut applies to many published cut-and-choose based two-party computation protocols; in particular, it applies directly to those protocols in which the generator first commits to n garbled circuits, and later, after a cointossing protocol between generator and evaluator, opens each check circuit by sending either (a) both the 0 and 1 labels for all of its input wires, or (b) the random coins used to construct the circuit. (b) For n := n 0 to c * − (r − 1)(1 − ε), i. Solve the MajorityCut linear programming problem for (n, ε, r) to obtain (c, x x x) where c is the minimal cost of LP(n, ε, r) and x x x represents the corresponding strategy to achieve c. ii. The simulation of a malicious evaluator proceeds as in the original security proof with the exception that the simulator first samples e according to x x x using random tape ρ and then (as before), uses a simulated coin-tossing to ensure the outcome of the toss induces ρ. Similarly, the first protocol of Lindell and Pinkas [16] can be modified to adopt this idea: step (3) should send commitments to garbled circuits, modify step (4) to use the random tape from coin-tossing to sample e, modify step (8) so that the garbler sends the entire garbled circuits for the evaluation specimens as well as openings to the commitments so that the evaluator can check consistency.The idea seems applicable to many protocols which have the property that the set of checked circuits becomes publicly verifiable. In the latter case, the evaluator uses the two different authenticated output labels to recover the garbler's input, and then evaluate the function itself.The state-of-the-art SingleCut protocols implicitly assume r = 1, in which case an honest evaluator's best strategy is to evaluate each garbled circuit with probability 1/2, as there is only a single way for the malicious generator to win the cut-and-choose game. Therefore, fixing n, r and ε, the original cut-andchoose game configuration problem can be translated into the following linear programming problem:min x x x n + (r − 1) n ∑ i=0 x i · i Input: ε, r. Output: c * , n * , x x x *1. For n := n 0 to c * − (r − 1)(1 − ε), (a) Solve the SingleCut linear programming problem for (n, ε, r) to obtain (c, x x x) where c is the minimal cost of LP(n, ε, r) and x x x represents the corresponding strategy to achieve c.(b) If (c, x x x) 񮽙 = ⊥ and c * > c, then (c * , x x x * , n * ) := (c, x x x, n). In order to minimize ∑ n i=0 x i · i, we aim to maximize x i (which is upper-bounded by ε · 񮽙 n i 񮽙 and collectively constrained by ∑ n i=0 x i = 1) for all small i's. The savings due to our approach rise steadily for r < 10 4 and can get to about 10X for reasonably large r (e.g., r = 7 × 10 7 , which roughly corresponds to the bandwidth-based costratio for privately computing the edit distance between two 1000-character strings). This is because for any fixed ε, it does not make sense to trade in a larger n for a smaller e, • Add a step 0 to [15, Protocol 2], where an n is fixed in advance based on ε and r.• Change step 2(b) of [15, Protocol 2] to: P 2 picks the check-set J at random so that |J| = k, where k is randomly sampled from the distribution computable (from n, r, ε) by the 2-step algorithm given above.Afshar et al.[2] present a conceptually simple and elegant non-interactive secure computation protocol; it uses a cut-and-choose technique and achieves security 2 −40 by sending 40 garbled circuits. However, since their protocol is only 1 round, the cut-and-choose is implemented through oblivious transfer; specifically, the evaluator recovers a seed for all of the check circuits through OT, and the garbler sends all circuits in its one message. The basic idea of BatchedCut is to amortize the cost of cut-and-choose across either many protocol executions (of the same circuit) [11,19] or many basic gates [12,6,24] of a big circuit. Therefore, the problem reduces to the following constrained optimization Cost ratio rOptimal n (c) Figure 6: Characteristics of optimal mixed-strategy solutions for SingleCut protocols (ε = 2 −40 . First, as before, when i circuits are opened in the first phase, the garbler succeeds with probabilityPr c (N, B, T, τ, b, i) = (1 − τ) i 񮽙 b i 񮽙񮽙 T − b T − BN − i T T − BN 񮽙 . Finally, since phase 1 and phase 2 are independent, we conclude thatPr fail (N, B, T, τ, b) = b ∑ i=0 Pr c (N, B, T, τ, b, i)Pr e (N, B, b − i)The summation over i occurs because every check only succeeds with probability τ, and thus even after i checks on corrupted circuits, b − i corrupted circuits may remain in the second phase.Having explained the constraint, Figure 7 describes our search algorithm to solve the BatchedCut parameter optimization problem. This is consistent with our intuition: (1) It only makes sense to alternate B between two consecutive integers, which can be derived as a corollary of [12, Lemma 9]; (2) The strategy with smaller B is almost dominated by the one with larger B such that mixing them brings little extra benefit. Similarly, we have, there exists N 1 such that if N > N 1 , 񮽙 T −b T −BN−i 񮽙 񮽙 T T −BN 񮽙 ≥ 񮽙 T − BN − i + 1 T − i + 1 񮽙 i 񮽙 BN − b + i + 1 T − b + 1 񮽙 b−i 񮽙 L.So, we know that, for sufficiently large N, U 񮽙 񮽙 T −b T −BN−i 񮽙 񮽙 T T −BN 񮽙 ≤ U L = 񮽙 T − BN T − BN − i + 1 · T − i + 1 T 񮽙 i 񮽙 BN BN − b + i + 1 · T − b + 1 T − i 񮽙 b−i = 񮽙 (≤ 񮽙 1 + i − 1 T − BN − i + 1 񮽙 i 񮽙 1 + b − i − 1 BN − b + i + 1 񮽙 b−i (3) ≤ 񮽙 1 + i − 1 T − BN − i + 1 񮽙 i 񮽙 1 + b − 1 BN − b + 1 񮽙 b (4)Note that the inequality (3) , then Pr fail (N, B, T, τ, b) < ε.Proof Let 0 < τ ≤ 1 be the probability that P 2 detects the abnormality in checking garbled gate g conditioned on g is indeed bad.