For example, consider the following sentence from a popular Android application with over 10 million downloads:When you launch any of our applications, we collect information regarding your device type, operating system and version, carrier provider, IP address, Media Access Control (MAC) address, International Equipment Mobile ID (IMEI), whether you are using a point package, the game version, the device's geo-location, language settings, and unique device ID. Therefore, the application's privacy policy is also mandated to disclose the third-party entities with which they share data based on the CCPA.In this paper, we propose POLICHECK, which provides an entity-sensitive flow-to-policy consistency model to determine if an application's privacy policy discloses relevant data flows. Further, application markets could also leverage POLICHECK to triage and remove applications that are not correctly disclosing their privacy practices and to urge developers to provide clearer disclosures. In doing so, we bridge the gap between the low-level data types and DNS domains used by program analysis tools and the often higher-level concepts present in privacy policies. We define a data flow as a type of privacy-sensitive data (e.g., IMEI, location, email address) and the entity receiving the data (e.g., Facebook, TapJoy, AdMob). We differentiate vague disclosures from clear disclosures, because there is a risk that the language used to disclose the data flow is so broad that it encapsulates a wide-range of data flows, making it difficult to determine if third-party sharing or collection occurs. When requesting advertisements from TapJoy, the application obtains the user's Android advertising identifier and transmits it to ws.tapjoyads.com. In this case, we identify the following statement, "A device identifier and in-game or user session activity may be shared with the advertiser." Finally, we calculate a vagueness score for the resolved policy statement to allow a ranked ordering, which is based on a normalized ontological distance between the flow's data type and entity and the policy statements data type and entity. If we only considered the data type, we would identify the following policy statement: "When you access our Services, we automatically record and upload information from your device including, but not limited to attributes such as the operating system, hardware version, device settings, battery and signal strength, device identifiers..." This policy statement indicates application itself is collecting device identifiers. In this case, we only find two relevant policy statements, "On our apps, these third party advertising companies will collect and use your data to provide you with targeted advertising that is relevant to you and your preferences with your consent." A data flow f ∈ F is a tuple f = (e, d) where d ∈ D is the data type that is sent to an entity e ∈ E.For example, an application that sends the device's advertising identifier to AdMob can be concisely represented by the data flow tuple (AdMob, advertising identifier). Similar to PolicyLint [4], we represent a sharing and collection policy statement as a tuple (actor, action, data type, entity) where the actor performs an action on a data type, and an entity receives a data object of that type. Similarly, x o y ⇔ x o y ∨ x ≡ o y.In addition to these two ontological operators, we identify a third type of ontological operator that impacts flow-topolicy consistency analysis. Let x and y be terms partially ordered by "is-a" relationships in an ontologyo. Similar to logical contradictions, flow-sensitive contradictions result in an ambiguous policy when reasoning Table 1: Types of conflicting policy statements in a privacy policy: narrowing definitions (N 1−4 ) and logical contradictions from PolicyLint [4], and flow-sensitive contradictions (C 6−12 ). LogicExample * N 1 e i ≡ ε e j ∧ d k δ d l (Flurry, collect, Dev Info) (Flurry, not_collect, IMEI) N 2 e i ε e j ∧ d k δ d l (Flurry, collect, Dev Info) (Advertiser, not_collect, IMEI) N 3 e i ε e j ∧ d k ≡ δ d l (Advertiser, collect, IMEI) (Flurry, not_collect, IMEI) N 4 e i ε e j ∧ d k δ d l (Advertiser, collect, Dev Info) (Flurry, not_collect, IMEI) C 1 e i ≡ ε e j ∧ d k ≡ δ d l (Flurry, collect, IMEI) (Flurry, not_collect, IMEI) C 2 e i ≡ ε e j ∧ d k δ d l (Flurry, collect, IMEI) (Flurry, not_collect, Dev Info) C 3 e i ε e j ∧ d k ≡ δ d l (Flurry, collect, IMEI) (Advertiser, not_collect, IMEI) C 4 e i ε e j ∧ d k δ d l (Flurry, collect, IMEI) (Advertiser, not_collect, Dev Info) C 5 e i ε e j ∧ d k δ d l (Advertiser, collect, IMEI) (Flurry, not_collect, Dev Info) C 6 e i ≡ ε e j ∧ d k ≈ δ d l (Flurry, collect, Dev Info) (Flurry, not_collect, Track Info) C 7 e i ε e j ∧ d k ≈ δ d l (Flurry, collect, Dev Info) (Advertiser, not_collect, Track Info) C 8 e i ε e j ∧ d k ≈ δ d l (Advertiser, collect, Dev Info) (Flurry, not_collect, Track Info) C 9 e i ≈ ε e j ∧ d k ≡ δ d l (Analytic, collect, IMEI) (Advertiser, not_collect, IMEI) C 10 e i ≈ ε e j ∧ d k δ d l (Analytic, collect, IMEI) (Advertiser, not_collect, Dev Info) C 11 e i ≈ ε e j ∧ d k δ d l (Analytic, collect, Dev Info) (Advertiser, not_collect, IMEI) C 12 e i ≈ ε e j ∧ d k ≈ δ d l (Analytic, collect, Dev Info) (Advertiser, not_collect, Track Info) * P = {(e i , collect, d k ), (e j , not_collect, d l )}, f = (Flurry, IMEI)whether a specific data flow is disclosed. For example, consider we have the data flow (Flurry, advertising identifier) and the policy statements (analytic provider, collect, advertising identifier) and (advertiser, not_collect, advertising identifier). P C is the set of policy statements p ∈ P for which there exists a p ∈ P such that p and p have a logical contradiction (C 1−5 ) or a flow-sensitive contradiction (C 6−12 ). A data flow f is consistent with an application's privacy policy P if and only if ∃p ∈ P f such that p.c = collect ∧ ∃p ∈ P f such that p . An application's privacy policy has a clear disclosure of a data flow f if there exists a collect policy that uses terms of the same semantic granularity for both data type and entity, and there does not exist a conflicting not_collect policy for the data type and entity. e ≡ ε p.e and ∃p ∈ P f such that p . An application's privacy policy has a vague disclosure of a data flow f if there does not exist clear disclosure, but there does exist a collect policy using a broader semantic granularity for either the data type of entity, and there does not exist a conflicting not_collect policy for the data type and entity. More specifically, there is a vague disclosure of f if and only if ∃p ∈ P f such that p.c= collect ∧ f . However, if the terms in the matching policy statement are too broad, the disclosure may not be meaningful to the user.For example, the policy statement (third-party, collect, personal data) is considerably more vague than (AdMob, collect, advertising identifier) to describe the data flow (AdMob, advertising identifier). We chose dynamic analysis over static analysis, because it provides (1) evidence that the flow occurs (some ad libraries use serverside configuration to determine what data types to collect), and (2) the network destination of the flow. Domain-to-Entity Mapping: While data flows are represented as a type of data being transmitted to a domain or IP address, privacy policies discuss data flows using terms for entities instead of domains (e.g., cdp.cloud.unity3d.com We curated a list of 144 advertisers and 40 analytics providers on the Google Play store from AppBrain.com. After obtaining a list of potential domain names for each organization by keyword matching our search terms, we manually culled incorrect or irrelevant domain names. For example, if the flow (advertising identifier, analytics.mobile.walmart.com) occurs in the app com.walmart.android, we mark the flow as a first-party flow, as reversing walmart.com results in com.walmart, which matches the beginning of the package name. Data Type and Entity Ontology Extension: We extended PolicyLint's ontologies to include all of the data types involved in data flows and all of the entities identified when constructing the domain-to-entity mapping. In this section, we use POLICHECK to perform a large-scale study of analyzing the consistency of 45,603 data flows from 13,796 unique Android applications and their corresponding privacy policies. From those policies, 218,257 policy statements were extracted from 48,831 sentences that were identified as a sharing or collection sentence, such that 7,526 had negative sentiment and 210,731 had positive sentiment. Across all of the flows, Unity was the most common recipient, which accounted for 6,270 data flows containing 6 unique data types across 4,381 applications.We ran POLICHECK on the dataset and the raw statistics from analysis are listed in Table 3. However, we find that 74.7% of entities that receive Ad IDs also receive a persistent identifier. Therefore, we also consider Ad IDs to be PII, because mixing them with persistent identifiers nullifies their originally intended properties since they lose the property of non-persistence and tracking can be bridged across resets. Finding 1: Only 0.5% of data flows were explicitly discussed by sentences within the privacy policy in terms of the exact entity and exact data type. The data vagueness score of around 0.5 generally represents terms such as "personally identifiable information," "device information," or "user information." Further, 97.8% of applications with third-party vague disclosures contain 3 or fewer unique data types within its data flows. Therefore, it is largely feasible that developers explicitly disclose the exact data types being shared with the exact entities (clear disclosures) As the developers disclosed the behaviors within the privacy policy, albeit vaguely, they are likely aware that the third-party libraries collect some data. Surprisingly, they were only disclosed by the terms "device identifiers" or "identifiers" in 20.8% of the flows (192 / 925 For third-party flows, Figure 7 shows that sharing both Android IDs and Ad IDs with Crashlytics and Unity3d accounted for 27.8% (3,168/11,398) and 24.7% (2,810/11,398) omitted disclosures, respectively. This application collects the user's Android ID, but the privacy policy explicitly states, "We DO NOT collect your unique identificator [sic]," and also states "Anonymous identifiers, we use anonymous identifiers when you interact with services, such as advertising services and others." For example, we found that 35 applications contained first-party flows collecting a wide-range of data (e.g., location (22 apps), phone number (6 apps), email address (2 apps), applications installed (1 app), Ad IDs (3 apps), and various identifiers (3)). First, we manually validate a random selection of 153 data flows across 151 applications and show that POLICHECK has a 90.8% precision. We explored this direction by analyzing a select number of applications with the greatest number of omitted disclosures in our data set.Case Study: Omitted disclosures may also indicate confusing language in privacy policies: A popular game application with over 100M+ downloads called 'Ant Smasher by Best Cool & Fun Games," (com.bestcoolfungames.antsmasher) had 17 unique omitted disclosures. When validating these data flows, we found the following policy statement, which potentially discloses these practices albeit vaguely.For instance, whenever you access and start to interact with our Apps, we are able to identify your IP address, system configuration, browser type and other sorts of information arising from your device. To measure the impact of entities in flow-to-policy consistency, we simulated the error rate of entity-insensitive consistency models (i.e., models that do not consider entities) by running consistency analysis in the following three configurations: (1) without entities and without negations (negationinsensitive and entity-insensitive); (2) without entities (entityinsensitive); and (3) without negations (negation-insensitive). Of those results, 16.3% (6,937/ 42,592) were due to first-party policy (-, -, d): entity-insensitive and negation-insensitive * (-, c, d): entity-insensitive and negation-sensitive * (e, -, d): entity-sensitive and negation-insensitive statements and 14.3% (6,077/ 42,592) due to third-party policy statements with a semantically unrelated entity. While consistency models that are negation-sensitive and entity-insensitive (-, c, d) can theoretically identify incorrect disclosures and ambiguous disclosures, the results show that their identification of these disclosure types are imprecise due to not considering entities. The privacy policy is copied below in entirety, which shows the potential deceptiveness of their policy.Okay guys listen up, I'm forced to write this privacy policy or Google will take this APP from the store. Their application "Chhota Bheem Speed Racing" (com.nazara.tinylabproductions.chhotabheem-22002) has over 10M+ downloads and has 15 incorrect disclosures detected by POLICHECK. Even more so when considering that they're sending this information is likely being used to target ads towards children.In Nazara Games' privacy policies, that they do not sell or rent personal information unless the user gives consent.Nazara does not sell or rent your Personal Information to third-parties for marketing purposes without your consent.As some of these applications are for children, verifiable consent is required from the child's legal guardian according to regulations [2]. The main source of ambiguous disclosures were due to statements regarding allowing business partners to collect device identifiers, but then stating that third-parties will not collect device identifiers without consent.The "Bowmasters" game application (com.miniclip.bowmasters) has over 50M downloads and 12 unique ambiguous disclosures. However, as the current implementation of POLICHECK is built on top of PolicyLint [4] and AppCensus [6], we inherit their limitations. Future work can improve completeness of policy statement extraction and dynamic analysis, which can then be used as input to POLICHECK.Another limitation is that POLICHECK's domain-to-entity mapping may be incomplete, as our study is primarily focused on popular advertisers and analytics providers. Future work can explore more comprehensive approaches for resolving domains and IP addresses to entities and constructing domain-to-entity mappings.Moreover, while POLICHECK correctly reasons over thirdparty disclosures that are disclosed in terms of parent companies (i.e., subsidiary relationships), the current implementation does not capture subsidiary relationships of first-party disclosures. While much of the prior works [29,34,38] use Android's application program interface (API) calls to evaluate privacy breaches, Wang et al. [32] extended the taint sources to include sensitive data entered through an app's UI. In contrast, POLICHECK uses an automated, comprehensive policy analysis that improves precision by considering additional capabilities, such as semantic granularities and contradictions.Numerous works focus on the automated analysis of privacy policies themselves.