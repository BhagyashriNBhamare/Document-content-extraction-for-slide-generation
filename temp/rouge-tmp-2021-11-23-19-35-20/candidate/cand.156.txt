Our results show that the isolation enforced by existing defense techniques is imperfect and that generalizing such techniques to mitigate arbitrary cache attacks is much more challenging than previously assumed. In response to these attacks, state-of-the-art defenses use software-or hardware-enforced mechanisms to partition CPU caches between mutually distrusting components.Given the lack of dedicated hardware support for the mitigation of cache attacks, current hardware-enforced mechanisms re-purpose other CPU features, originally intended for different applications, to partition the shared caches. We show this strategy bypasses the imperfect partitioning of all state-of-the-art software-based defenses, which implicitly assume hardware components other than the CPU are trusted.To substantiate our claims, we focus on MMU-based indirect cache attacks and show how such attacks can bypass existing software-based defenses in practical settings. â€¢ An open-source test-bed for all the existing and new cache attacks considered in this paper, the corresponding covert-channel implementations, and applicable cache defenses, which can serve as a framework to foster future research in the area.The source code and further information about this project can be found here:https://vusec.net/projects/xlateThe remainder of the paper is organized as follows. To overcome the performance gap between processors and memory, multiple caches in the processor store recently-accessed memory locations to hide the memory's high latency. Recently accessed memory locations by the victim process will be in the cache and EVICT + TIME [27] time PRIME + PROBE [21,31] time PRIME + ABORT [8] TSX FLUSH + RELOAD [42] time FLUSH + FLUSH [16] time attackers can probe for this information by observing the state of the caches to leak sensitive information about the secret operation of the victim process. Where these caches are private to each core, all cores share the L3 which is the last-level cache (LLC). EVICT + TIME In an EVICT + TIME attack, the attacker evicts certain cache sets and then measures the execution time of the victim's code to determine whether the victim used a memory location that maps to the evicted cache sets. PRIME + ABORT monitors accesses to a single cache set by filling the cache set during a transaction as any additional accesses to same cache set causes the transaction to abort.FLUSH + RELOAD and FLUSH + FLUSH To reduce the memory footprint, running processes often share identical memory pages. Further, Yarom and Falkner [42] observe that CLFLUSH evicts a memory line from all the cache levels, including the lastlevel cache (LLC) which is inclusive of the lower cache levels and shared between all processor cores, thus enabling an attacker to monitor a victim from another processor core. Similarly, older ARM processors such as the ARM Cortex A9 implement Cache Lockdown [6,35], which enables software to pin cache lines within the L2 cache by restricting the cache ways that can be allocated.Another hardware mechanism is ARM AutoLockoriginally an inclusion policy designed to reduce power consumption that also happens to prevent cross-core attacks by locking cache lines in the L2 cache when they are present in any of the L1 caches [13,40]. As a result, to use ARM AutoLock as a defense, sensitive data has to be kept in the L1 caches, which are limited in size.Intel TSX introduces support for hardware transactions where the L1 and L3 are used as write and read sets, respectively, to keep track of accesses within the transaction. While effective, Cloak requires modification to the application code and is limited to computations whose working set can strictly fit inside CPU caches.Other than the scalability limitations mentioned above, another concern with hardware-based defenses is their lack of portability. When such accesses are monitored, StealthMem exploits the cache replacement policy to pin stealth pages in the LLC.CacheBar [44] allocates a budget per cache set to each security domain at the granularity of a page size, essentially representing the amount of cache ways that the security domain is allowed to use for each page color. To restrict the number of cache ways that are allocated by a security domain, CacheBar actively evicts pages from the cache following an LRU replacement policy.Note that all these defenses isolate the cache that untrusted, potentially attacker-controlled, code can directly access, but do not account for cache partitions the attacker can indirectly access by piggybacking on trusted components such as the MMU. For XLATE attacks, eviction sets can be found using a similar approach, but by using page tables instead of pages.In XLATE + TIME, we fill a specific cache set with the page table entries from the eviction set and then measure the victim's execution time to determine if the victim is accessing the same cache set. To avoid having to measure the execution time of the victim, we can mount a XLATE + PROBE attack where the attacker repeatedly measures the time it takes to refill the cache set, using the page table entries of the eviction set, as a memory access to the same cache set causes one of the page table entries to be evicted (resulting in a slowdown). As mentioned, all these defenses focus on isolating untrusted components such as code running in a virtual machine, but allow unrestricted access to the cache to trusted operations-such as the page Figure 1: The top shows the LLC being divided into 128 unique page colors, the bottom left shows how the LLC can be partitioned such that programs can only access a subset of these page colors, the bottom right shows the situation for their respective page tables.performed by the MMU. Therefore, the MMU is not restricted by this limitation and is free to allocate all the ways available in each cache set. As the page table accesses by the MMU are not monitored by the page fault handler, accesses to page tables that map to the same cache set as the sensitive data, do not reload those cache lines. By repeating this operation, the MMU eventually finds the corresponding physical page for 0x644b321f4000 at the lowest-level page table.The performance of memory accesses improves greatly if the MMU can avoid having to resolve a virtual address that it already resolved recently. If the translation caches are not flushed, then the page table walk skips part of the page table hierarchy and simply starts from a lower level page table. While the sizes of the TLB and the CPU caches are already known, the sizes of the translation caches are not.We can use the aforementioned mechanism to reverse engineer the size of translation caches. More specifically, we first find eviction sets for the available subset of page colors: Algorithm 1: Algorithm to build eviction sets dynamically for either a given or a randomly chosen target.Input: a set of potentially conflicting cache lines pool, all set-aligned, and an optional target to find an eviction set for. If the amount of page colors is restricted, this results in fewer eviction sets, whereas if the amount of cache ways is restricted, these eviction sets consist of fewer entries.Using page tables Now we retrofit this algorithm to use the MMU to evict a given page, the target of our choice. We can then repeat this for other pages until all the page tables have been colored, yielding eviction sets for all the available colors in our security domain.Defeating way partitioning To defeat software-based cache defenses using way partitioning, we now try to find eviction sets that cover the whole cache set. Since these eviction sets of page tables map to the full cache sets, they bypass way partitioning.Defeating set partitioning In case of StealthMem and cache defenses using set partitioning, or more specifically, page coloring, we end up with a pool of the remaining page tables that could not be colored. To minimize the noise for XLATE attacks, we rely on the following: (1) translation caches, (2) pointer chasing, (3) re-using physical pages, (4) and transactions.Translation caches Now that we have reverse engineered the properties of the MMU, we can control which PTEs hit the LLC when performing a page table walk. Algorithm 2 extends PRIME + PROBE to flush Algorithm 2: XLATE + PROBE method for determining whether an eviction sets evicts a given cache line.Input: the eviction set eviction set and the target target. To defeat adaptive cache replacement policies that learn from cache line re-use, we access the eviction set back and forth twice as shown in Algorithm 2.Re-using physical pages To perform a page table walk, we have to perform a memory access. Second, by carefully selecting the virtual addresses of the pages in our eviction set, we can ensure that the cache lines of these pages do not align with the cache line of the target page. We provide representative results from these attacks in this section and refer the interested reader to more extended results in Appendix A.Our evaluation answers four key questions: (i) Reverse engineering: Can we effectively reverse engineer translation caches on commodity microarchitectures to mount practical XLATE attacks? Since AMD Bulldozer, the L2 TLB has been re-purposed to also host page table entries, allowing it to store up to 1024 PDEs on AMD Bulldozer and Piledriver and up to 1536 PDEs on AMD Zen. We also found that AMD Zen introduces another L2 TLB with 64 entries dedicated to 1G pages, allowing it to store up to 64 PDPTEs. To evaluate the reliability of XLATE and compare against that of state-of-the-art cache attacks, we implemented an LLC-based covert channel framework, where the sender and the receiver assume the roles of the victim and the attacker respectively. The receiver mounts one of the cache attacks to monitor specific cache lines, while the sender accesses the cache line to transmit a one and does nothing to send a zero otherwise. The implementation of AES in our version of OpenSSL uses T-tables to compute the cipher text based on the secret key k and plain text p. More specifically, by choosing p i and using new random plain text bytes for p j , where i = j, while triggering encryptions, an attacker can find which p i remains to always cause a cache hit for the first cache line in a T-table. To evaluate the ability of XLATE attacks to bypass stateof-the-art software-based defenses, we perform the same experiment as in Section 7.3 but now in presence of stateof-the-art software-based cache defenses. Since StealthMem uses dedicated cache sets to pin cache lines, this defense is already subsumed by page coloring.Without additional assumptions, PRIME + PROBE would trivially fail in this scenario, since the preliminary eviction set building step would never complete due to the cache set and ways restrictions. Even though existing software-based cache defenses are effective against existing side-channel attacks such as PRIME + PROBE and PRIME + ABORT, they are not effective against the XLATE family of attacks. By applying the same subset of page colors to both pages and page table pages on a per-domain basis, it is impossible for an attacker to control page table pages outside the assigned security domain.We show that extending page coloring to also color the page tables is effective by extending the experiment presented in Section 7.4. The research leading to these results has received funding from the European Union's Horizon 2020 Research and Innovation Programme, under Grant Agreement No. 786669 and was supported in part by the MALPAY project and by the Netherlands Organisation for Scientific Research through grants NWO 639.023.309 VICI "Dowsing", NWO 639.021.753 VENI "PantaRhei", and NWO 629.002.204 "Parallax".