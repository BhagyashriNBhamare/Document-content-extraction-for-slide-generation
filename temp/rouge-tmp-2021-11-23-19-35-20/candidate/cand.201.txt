The attack detects keystrokes in encrypted network traffic and identifies search queries using information from three independent sources: keystroke timings manifested in packet inter-arrival times, percent-encoding of Space characters in a URL, and the static Huffman code used in HTTP2 header compression.The attack we developed, called KREEP (Keystroke Recognition and Entropy Elimination Program), consists of five stages: keystroke detection, which separates packets that correspond to keystrokes from background traffic; tokenization to delineate words in the packet sequence; dictionary pruning, which uses an HTTP2 header compression side channel to eliminate words from a large dictionary; word identification, performed by a neural network that predicts word probabilities from packet inter-arrival times; and a beam search, which generates hypothesis queries using a language model. However, the attack is not robust to padding and we propose a simple padding defense that mitigates both the HTTP2 header compression side channel and ability to delineate words.To summarize, the main contributions of this work include: 1) A method to detect packets induced by autocomplete and delineate words in a query. The use of a language model significantly improves performance.In the next section, we provide background information on keylogging side channels and autocomplete. Remote keystroke timing attacks may target applications in which a keystroke induces network traffic from the victim's host, such as SSH [47] or a search engine with autocomplete functionality [51]. The first is keystroke detection: given a sequence of events, such as network packets, spikes in CPU load, or memory accesses, determine which events correspond to keystrokes and which do not. In our attack, we consider a sequence of network packets emitted by the victim which includes background traffic in addition to the HTTP requests induced by autocomplete. This results in a series of HTTP requests following keyboard events, such as those shown in Figure 1 Figure 1: Autocomplete requests for the query "the lazy dog" in Google (left) and Baidu (right). The first is a polling model in which a web page periodically checks the contents of the query input field at fixed intervals. We do not make any assumptions about background traffic or the ability to detect when a web page loaded; KREEP is able to isolate the subsequence of packets that contain autocomplete requests.We assume the victim types only alphabetic keys and the Space key (27 keys total) to form a query made of lowercase English words with each word separated by a Space. Word identification: the probability of each word remaining in the dictionary is determined from the observed packet inter-arrival times, which faithfully preserve key-press latencies. Let fp, fn be the number of false positives and false negatives, and let tn, tp be the number of true negatives and true positives, respectively. We measure the performance of both keystroke detection and tokenization by the F-score,F 1 = 2 × Precision × Recall Precision + Recall(1)wherePrecision = tp tp+fp , Recall = tp tp+fn . (2)The F-score varies between 0, for missing all positives, and 1, for perfect precision and recall. We compare this to the information gain in a classical compression side channel where only the total compressed size of the query is known.For word identification, we report the word classification accuracy from packet timings, assuming perfect detection and tokenization. Edit distance is used instead of character or word classification accuracy since failures in keystroke detection can result in a predicted query that is either shorter or longer than the original query. We found that typing a query with 12 characters on Google search induces 95 outgoing packets with payload greater than 0 bytes (436 packets including those with empty payloads), only 12 of which correspond to autocomplete requests.Each autocomplete request contains a new character appended to the URL path. We perform keystroke detection by isolating a subsequence of packets that exhibit this pattern, taking into account the particular behavior of each search engine described below.The behavior of each search engine is characterized by the sequence of size differences between successive autocomplete request packets. This sequence reflects packet size growth as a function of query length, invariant to the size of other parameters contained in the request which vary across hosts due to different sized identifiers, authentication tokens, and page load options. The request then continues to increase by about 1 byte per character thereafter.The autocomplete packet sizes of Baidu typically increase by either 2 or 4 bytes per character, with a larger increase of 7 or 9 bytes at the beginning of the sequence. To that end, we generalize the LIS problem to that of finding the longest subsequence accepted by a sequence detector DFA based on observations in the previous section.We define a DFA that accepts a sequence of packet size differences generated by the autocomplete of each search engine. States a and b correspond toa b c d d = 0 d > 3 d = 0 1 ≤ d ≤ 3 1 ≤ d ≤ 3 1 ≤ d ≤ 3 d > 3 1 ≤ d ≤ 3Figure 4: DFA that accepts a sequence of packet size differences generated by autocomplete in Google search.increases of between 0 and 3 bytes prior to the large increase from the addition of the "gs_mss" parameter, and states c and d are reached after the large increase. We then need only check if the DFA that accepted the sequence ending in packet i can transition to packet j. Note that in general, these assumptions may not hold and thus the dynamic programming solution might be suboptimal; however, we found this method to work well in practice and leave for future work a formal treatment of the LAS problem. When the user types a Space into the search query field, this escape sequence is appended to the URL causing the uncompressed request packet to increase by 3 bytes.Google autocomplete packets increase by 2 bytes when the Space key is pressed as a result of HTTP2 header compression. In HPACK, the encoded string is padded with between 0 and 7 bits to align with the nearest octet boundary.The static Huffman code in HPACK was determined using a large sample of HTTP headers, and all HPACK implementations must use the same Huffman code defined in the specification [39]. Instead of b, an adversary observes byte size B = p+∑ h i 8 where 0 ≤ p ≤ 7 is an unknown amount of padding to align the compressed bit string with the nearest octet.However, the query in a sequence of autocomplete requests grows incrementally. Marginal entropy Info gain (cumulative size) Info gain (total size) Figure 7: Information gain from an incremental compression side channel, where the cumulative size of a string is exposed, compared to a conventional compression side channel, where only the total size is exposed. Unlike previous work which considered either each latency in isolation [47], or words in a limited dictionary [29], we define a model that predicts key probabilities considering their surrounding context and also able to recognize words not seen during training.We use a three-layer neural network to predict key probabilities. The model takes as input the sequence of latencies τ i for 0 ≤ i ≤ n and predicts P (k i ), the probability of each key k i for 1 ≤ i ≤ n.The first layer of the network is a bidirectional recurrent neural network (RNN) with gated recurrent units (GRU) that takes as input the sequence of n + 1 time intervals. The convolutional layer with kernel size 2 combines the latency immediately before and after key i, reducing the size of the sequence from n + 1 (number of latencies) to n (number of keys). In the last stage, word probabilities are combined with a language model to generate hypothesis queries in a beam search.We assume the query to be a sequence of N words w i for 1 ≤ i ≤ N and take advantage of the fact that some words are more likely to follow others in natural language. We combine the language model with the keystroke timing model to determine the probability of an entire query w = [w 1 , . . . , w N ], given byP (w) = ∏ w i ∈w P (w i |τ) P (w i |w 1 . . . w i−1 ) α (6)where α is a parameter that controls the weight of the language model. The measurement setup consists of a keystroke dataset previously collected from human subjects, browser automation with Selenium WebDriver, and a process to replay keystrokes by writing keyboard events to /dev/uinput in real time.To train the neural network, we used a subset of a publicly available keystroke dataset collected from over 100k users typing excerpts from the Enron email corpus and English gigaword newswire corpus [15]. This ensures keyboard event times are replayed with high fidelity and not quantized due to the presence of a global system timer.We captured 4k unique queries on search engines Google and Baidu, both of which default to an HTTPS connection and generate autocomplete requests upon key-press events. The captured dataset contains a total of 16k queries (4k queries × 2 search engines × 2 web browsers), obtained over approximately 7 days. In HPACK, the string length starts as a 7-bit integer (see Figure Google Google Table 2: Top-50 classification accuracy: % of queries that are correctly identified among the 50 hypothesis queries.5). When the number of compressed bytes exceeds 2 7 − 1, an additional byte is allocated for the string length, resulting in an overall increase of 2 bytes (+1 from the String Length increase and +1 from the new character in the query). The hypothesis queries have the same total length as the true query but differ in word lengths, resulting in relatively high edit distance.The proportion of attacks in which the true query is identified among the hypotheses queries, analogous to a top-50 classification accuracy, is shown Table 2. We did not find any significant difference in performance across browsers, but did achieve overall higher query identification rates on Google due information leaked through incremental compression.We found the example in Figure 9 to be representative of attack success which generally had polarized outcomes: the hypotheses were either very similar to or very different from the true query. The attack is relatively robust to PDV less then 8 ms, but approaches baseline performance with PDV in excess of 32 ms. With the attack being robust to low levels of network noise, we explored other means of mitigating attack success. This includes VoIP: as utterances are compressed and transmitted in real time, spoken phrases can be identified in encrypted network traffic [55,56]; SSH: single characters are transmitted to and echoed back by the server, exposing the timing of key presses [47]; HTTP: unencrypted network traces contain a user's web browsing activity [36,57]; and HTTPS: in dynamic web applications, server response size can reveal interactions with specific elements on a web page [12]. Our work confirms that assumption by using timings obtained from actual network traffic and users typing complete phrases instead of isolated bigrams.There have been numerous works focused on the detection of keyboard events (which enables a timing attack), such as through spikes in CPU load [45], cache and memory usage [41], and the proc filesystem [23]. The DEFLATE compression algorithm in SPDY uses redundancy to compress a string [14] such that the compressed size of a packet containing the correct guess will be smaller than an incorrect guess. For example, to find out whether a secret starts with "p", an attacker guesses "secret=p_" and "secret=_p": if the sizes are the same, then only Huffman coding is used and the guess is wrong; otherwise, if the sizes are different, the LZ77 component was invoked based on redundancy between the first guess and the secret, and only Huffman coding was invoked in the second guess.HPACK, the header compression format in HTTP2, was designed to be resistant to CRIME-like attacks targeting LZ77 compression, although HTTP2 borrowed many concepts from SPDY [39]. While keystroke detection may be possible in traffic over Tor, for example by detecting traffic that has "keystroke-like" packet inter-arrival times, tokenization and dictionary pruning cannot be applied since the autocomplete packet sizes are masked behind Tor cell sizes. An attack that uses only packet inter-arrival times might be feasible in Tor, but would require a different approach than our attack.While previous work has shown HTTP response size to leak a considerable amount of information about a user's query when autocomplete suggestions are provided [12], we chose to focus only on HTTP requests. This approach has the cost of increased bandwidth, a tradeoff reminiscent of the anonymity trilemma [13], and requires some cooperation from the server to ignore the dummy requests.Merge requests Most search engines make an autocomplete request immediately following each new character appended to the input field [35]. Combining requests could be achieved in several ways: 1) update the list of autocomplete suggestions after every other, or every nth, key (similar to Nagle's algorithm, except at the application level); 2) use a polling model with polling rate slower than the user's typing speed (Bing performs polling with 100ms interval, making this attack impractical for fast typists); or 3) trigger callbacks on keyup events instead of keydown events (DuckDuckGo does this), which merges requests when consecutive keystrokes overlap [35], a typing phenomenon referred to as rollover [15]. Targeted attacks Finally, while we made an effort to evaluate our attack on phrases that are representative of natural language, the content of actual search queries is quite different and varies between users as evidenced by the AOL search dataset [7,38]. Autocomplete request packets are detected based on packet size; queries are tokenized by detecting the presence of URL-escaped characters; keys are identified based on packet inter-arrival times; and impossible words are eliminated from a dictionary based on incremental compression. Besides websites that provide search suggestions, this could include mapping services, which modify the geographic coordinates in a URL as the user drags the map center location, or websites that autosave the contents of a text field.Likewise, websites that generate network traffic in response to user input events may be vulnerable to timing attack.