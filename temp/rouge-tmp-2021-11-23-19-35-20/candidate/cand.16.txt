For example, the Perl subroutine in Figure 1 generates optimized ARM code for OpenSSL's SHA-256 inner loop.Unfortunately, while the flexibility of script-generated assembly leads to excellent performance ( §5.1) and helps support dozens of different platforms, it makes the cryptographic code difficult to read, understand, or analyze. Such solvers can potentially blast their way through large blocks of assembly and tricky bitwise reasoning, making verification faster and easier.In this paper, we present Vale, a new language for expressing and verifying high-performance assembly code that strives to combine the advantages of both approaches; i.e., it combines flexible generation of high-performance assembly with automated, rigorous, machine-checked verification. As a powerful example of this post-analysis, we have developed a verified analyzer that checks Vale ASTs for potential information leakage through timing and memoryaccess channels.Although we trust our crypto specs, Dafny, and the assembly language semantics to be correct, as shown in Figure 2, neither Vale nor the information leakage analyzer is part of the trusted computing base. For example, even when using Dafny as a logical framework, Vale procedures are not executable Dafny methods, Vale while loops are not executable Dafny while loops, and executable Vale code is not compiled with Dafny's compiler, which compiles Dafny's own control constructs to C#. Instead, Vale relies on the logical framework mainly for mathematical reasoning in proofs, and uses executable Dafny code only for specialized tasks like printing assembly language code and static analysis of Vale code.The Vale language does not contain anything specific to a particular architecture such as x86 or ARM or to a particular assembler such as the GNU assembler or MASM. Furthermore, properties of programs are proven directly in terms of the method Main() { var code := Block( cons(Add(op_reg(R7), op_reg(R7), op_const(1)) ,cons(Add(op_reg(R7), op_reg(R7), op_const(1)) ,cons(Add(op_reg(R7), op_reg(R7), op_const (1) semantics of assembly language, so the Vale language and tool need not be trusted. Since Dafny is a general-purpose high-level language that knows nothing about assembly language instructions, operands, and registers, Vale provides domain-specific language support for declaring instructions, declaring and instantiating input and output operands, declaring which registers an instruction reads and modifies, and so on. Dafny checks the Vale-generated code object, using the Vale-generated proof, against a crypto specification the programmer writes in Dafny; hence, any mistakes in the code or proof will be caught by Dafny. var{:state ok()} ok:bool; var{:state reg(R0)} r0:uint32; var{:state reg(R1)} r1:uint32; ... var{:state reg(R12)} r12:uint32; var{:state reg(LR)} lr:uint32; var{:state mem()} mem:map(int, uint32); procedure AddOne(inout operand r:uint32) requires r < 0xffffffff; ensures r == old(r) + 1; { ADD(r, r, 1); } procedure Add3ToR7() modifies r7; requires r7 < 0xfffffffd; ensures r7 == old(r7) + 3; { AddOne(r7); AddOne(r7); AddOne(r7); } FIGURE 5-Examples of state declarations and inline procedure declarations in Vale.In addition to preconditions and postconditions, Vale also requires loop invariants for loops:while (r7 <= 100) // example loop in Vale invariant r7 <= 103; // loop invariant { Add3ToR7(); } For each procedure, the Vale tool generates a Dafny function that produces an AST value of type code. b ==> r1 == a[1] + 1; { inline if (b) { LDR(r1, r0, 0); //load memory [r0+0] into r1 AddOne(r1); } else { LDR(r1, r0, 4); //load memory [r0+4] into r1AddOne(r1); } } procedure{:recursive} AddNToR7(inline n:nat) modifies r7; requires r7 + n <= 0xffffffff; ensures r7 == old(r7) + n; { inline if (n > 0) { AddOne(r7); AddNToR7(n -1); } } FIGURE 7-Ghost and inline parameters in Vale. The ReadA procedure uses an inline bool to generate code to load from r0 + 0 if b = true, and to load from r0 + 4 if b = false. The AddNToR7 procedure uses an inline natural number n to repeat the AddOne instruction n times, generating a completely unrolled loop.From these, Vale generates functions parameterized over the inline b and n variables, so that each b and n produces a possibly different AST (see Figure 8). function method{:opaque} code_ReadA(b:bool):code { Block(cons(( if b then Block(cons(code_LDR( op_reg(R1), op_reg(R0), op_const(0)) ... else ... ))) } function method{:opaque} code_AddNToR7(n:nat):code { Block(cons(( if (n > 0) then Block(cons( code_AddOne(sp_op_reg(R7)) ... else ...))) } Although Vale ultimately proves properties in terms of the underlying machine semantics, it still structures its proofs to take advantage of the automated SMT-based reasoning provided by Dafny and Z3. By itself, reasoning about updates is acceptably fast, but the combination of updates and complex specifications leads to painfully slow reasoning.Therefore, Vale can also generate more sophisticated proofs that factor reasoning about updates and reasoning about specifications into two separate lemmas. They never need to examine the Vale-generated code objects and proofs, since all error messages are presented to the user in terms of user-generated Vale code and Dafny specifications.While Vale error messages do not assign blame to Valegenerated Dafny code, Vale does leverage Dafny's error handling. Thus, Vale gains Dafny's rich error handling without reducing usability.Similarly, in general, a basic Vale user only needs to know Vale and Dafny; they do not need to know internal pieces of Dafny's toolchain, such as Boogie or Z3, since code for those tools is generated by Dafny. Thus, to prove freedom from cache-based side channels, it suffices to show that an execution trace, which records all branches and memoryaccess locations, does not depend on secret inputs.To enable machine-checked verification of cache-based side-channel freedom in Vale, we expand the architectural model of the state with an additional ghost field trace that represents the execution trace defined above. A Vale method with code Code is leakage free if, for any two successful runs of Code, the following two conditions:• the two initial states, s and t, match in every location in PubStartLocs; and • the execution traces in those initial states, s.trace and t.trace, are identical imply the following two outcomes:• the two final states, s' and t', match in every location in PubEndLocs; and • the execution traces in those final states are identical. For instance, when the analysis merges taints for a given destination across multiple program paths (e.g., at the end of a loop), the analysis conservatively sets the destination's taint to the least upper bound of the destination's taint across all paths. However, given our focus on proving functional correctness of cryptographic code, we observe that we can carefully leverage the work already done to prove functional correctness, to drastically simplify memory taint analysis.Memory taint analysis is challenging because typically one cannot simply look at an instruction and determine which memory address it will read or write: the effective address depends on the particular dynamic values in the registers used as the base and/or offset of the access. For example, the developer cannot prove SHA-256 correct without proving that the output hash buffer does not overlap the unprocessed input.We can push some of the work of memory taint analysis to the developer by relying on her to provide lightweight annotations in the code. The analyzer also checks, for each store annotated as public, that the value being stored is actually public.To ensure that annotation errors will be caught during functional correctness verification, we expand the architectural model of the state with an additional ghost field pubaddrs, representing the set of addresses currently containing public information. This lets OpenSSL improve performance by calling the subroutine 16 times to unroll the loop: for($i=0;$i<16;$i++) { &BODY_00_15($i,@V); unshift(@V,pop(@V)); } Furthermore, each unrolled loop iteration is customized with a different mapping from SHA variables a. . Finally, a combination of Perl-based run-time checks (if ($i < 16)) and C preprocessor macros are used to select the most efficient available instructions on various versions of the ARM platform, as well as to further customize the last loop iteration (i = 15). It implements dozens of cryptographic algorithms on at least 50 different platforms, including many permutations of x86 and x64 (with and without SSE, SSE2, AVX, etc.) and similarly for various versions and permutations of ARM (e.g., with and without NEON support). As Figure 1 shows, the code comments are minimalist and often cryptic, e.g.,eor $t3,$B,$C @ magic ldr $t1,[sp,#'($i+2)%16'*4] @ from future BODY_16_xxIn the second line, the odd syntax with the backticks is used when the Perl code makes a second pass over the string representing the assembly code, this time acting as an interpreter to perform various mathematical operations, like ($i+2)%16. We also take advantage of Z3's bit-vector theory to automatically discharge relations like:(x&y) ⊕ (∼ x&z) == ((y ⊕ z)&x) ⊕ zwhich allow OpenSSL's code to optimize various SHA steps; e.g., the relation above saves an instruction by computing the right-hand side.To demonstrate that our implementation is not only correct but side-channel and leakage free, we run our verified analysis tool ( §3) on the Vale-generated AST. This required writing a trusted semantics for a subset of Intel's architecture, a trusted printer to translate instructions into assembly code, and a verified proof library (which in many cases differs very little from our corresponding ARM library). As we quantify in §5.1, implementations that take advantage of this hardware support are easily 3.5-4.0× faster than traditional hand-tuned assembly that does not.For this case study, we extended our x86 model from §4.2 by adding support for 128-bit XMM registers, definitions for Intel's six AES-support instructions [35], and four generic XMM instructions [39]. However, unlike the 926 26th USENIX Security Symposium USENIX Association code provided by Intel, our code includes a proof of its correctness. We see that OpenSSL's assembly code for SHA-256 on ARM gets up to 67% more throughput than its C code, and its assembly code for AES-CBC-128 on x86 gets 247-300% more throughput than its C code due to the use of SSE and AES-NI instructions.To accurately compare our performance with OpenSSL's, we make use of its built-in benchmarking tool openssl speed and its support for extensible cryptographic engines. The reasonably fast turnaround time for individual procedures is important, because the developer spends considerable time repeatedly running the verifier on each procedure when developing and debugging it.A key design decision in Vale is the verification of inlined procedures and unrolled loops before the inlining and unrolling occurs. The three lines show:• the cost of verifying an unrolled loop consisting entirely of x86 add eax, 1 instructions, ranging from 10 to 100 total instructions; • the cost of verifying an unrolled loop of x86 AES key inversions, up to the maximum 9 iterations performed by AES, where each iteration consists of 3 instructions; and • the cost of verifying an unrolled loop of x86 AES key expansions, up to the maximum 10 iterations performed by AES, where each iteration consists of 10 instructions. Their efforts have also proceeded without the need to modify Vale, even though they have enriched our relatively simple machine semantics, which we use to reason about cryptographic code, with details needed to program a microkernel, e.g., program status registers, privilege modes, interrupts, exceptions, and user-mode execution. Vale also includes a verified analyzer that checks for leakage and side channels.Chen et al. [18] embed a simple Hoare logic in Coq, which they use to verify the "core part" of a Curve25519 implementation written in the qhasm language, which is very close to assembly language. Also, their analysis is tied to the LLVM compiler's code-generation strategy, whereas ours is not.Myreen et al. [58] apply common proofs across similar pieces of code for multiple architectures by decompiling the assembly language code to a common format. The authors are grateful to Andrew Baumann and Andrew Ferraiuolo for their significant contributions to the ARM semantics, and to Santiago Zanella-Beguelin, Brian Milnes, and the anonymous reviewers for their helpful comments and suggestions.