Existing works primarily focus on simple attacks by randomly setting user locations, which can easily trigger a routing instruction that contradicts with the physical road condition (i.e., easily noticeable). Our key idea is to slightly shift the GPS location so that the fake navigation route matches the shape of the actual roads and trigger physically possible instructions. We perform extensive evaluations using a trace-driven simulation (600 taxi traces in Manhattan and Boston), and then validate the complete attack via real-world driving tests (attacking our own car). Other works have examined GPS spoofing attacks on systems in the open environment (e.g., open air/water) such as drones and ships [28,46] where a simple GPS change could (stealthily) steer their navigation.So far, it is still an open question regarding whether attackers can manipulate the road navigation systems by spoofing the GPS inputs. To these ends, if an attacker identifies an attacking route that mimics the shape of the route displayed on the map, then it is possible to trigger navigation instructions that are consistent with the physical environment (e.g., triggering the "turning right" prompt only when there is an actual right-turn ahead) to avoid alerting users.To understand the attack feasibility, we take four key steps 1 . The results provide key insights into how common driving habits make users vulnerable.We hope the results can help to raise the attention in the community to develop practically deployable defense mechanisms (e.g., location verification, signal authentication, sensor fusion) to protect the massive GPS device users and emerging GPS-enabled autonomous systems. Third, we have carefully tested the GPS signal strength at the edge of the parking lot to make sure the signals did not affect the outside areas.Our measurement focuses on two possible attacking cases to spoof the GPS device in a moving car (Figure 2). Second, if the spoofer cannot be attached to the victim's car, then the attacker may tailgate the victim's car by driving or flying a drone that carries the spoofer.Same-Car Setting.In the same car setting, we place the smartphone (XIAOMI MIX2 with Android 8.0) as the victim GPS device in the dashboard area. Once the fake signal is locked in, the connection can sustain throughout the attack.Two-Car Setting.Then we test to place the spoofer and the smartphone in two different cars, and examine the impact of distance d. The attacker creates false GPS signals to set the GPS location to a nearby "ghost" location B. To cope with the false location drift, the navigation system will recalculate a new route between B and D. Depending on the purpose of the attack, the attacker may pre-define the target destination C or simply aims to divert the victim from arriving the original destination D.In practice, when the attacker changed the GPS information from A to B, it may or may not trigger the "recalculating" voice prompt in the navigation system. Our user study (Section 7) shows that users often encounter inaccurate GPS positioning (e.g., urban canyon effect in big cities) and don't treat the one-time "recalculating" as an anomaly.Symbol Definition G A geographic area. Road segments are inter-connected through connection points. Given a starting point and a destination point, a navigation route Γ is calculated by the navigation system represented by road segments: Γ = (r 1 , r 2 , ..., r n ). In practice, navigation systems typically tell people to keep driving along the road crossing multiple segments before a turn is required. This will trigger the navigation system to recalculate a new route from Loc g to D as the ghost route Γ g = (S g 1 , S g 2 , ..., S g m ). (2) Speed scale factor constraint Ω speed that limits the ghost speed v g within a reasonable range, i.e., |(v g − v a )|/v a ≤ Ω speed . In practice, attackers may obtain D from different channels, such as the target user's social media location check-ins, destination broadcasting in taxi-hailing services, and identifying the checkpoints that the user must traverse (e.g., the Lincoln Tunnel entrance when traveling between New Jersey and Manhattan). By iteratively applying the basic attack algorithm, the attack performance can be significantly improved since partially matched victim-ghost routes can be used forInput: G, D, Ω dri f tDis , Ω speed , O 0 , I, attack goal Output: O i , where i = 1, 2, ..., I − 1 1: Initialization: carryover Γ v ← / 0, carryover Γ g ← / 0, O i ← / 0, i = 1, 2, ..., I 2: for i = 1 to I − 1 do 3:if attack goal has been achieved then4: return 5: end if 6: U 1 ,U 2 , ...,U m ← O i−1 7: for j = 1 to m do 8: if U j = / 0 then 9: break 10: end if 11:for u in U j do 12:Γ g u ← O i−1 [u] 13:for k = start j to end j do 14:Appendbasic attack(G, D, Γ g u [k]) to O i 15: Append Γ g u [: k] to carryover Γ g [u] 16: Append Γ vu [: ˆ k] to carryover Γ v [u]17: end for 18: end for 19: end for 20: Save (O i , carryover Γ v , carryover Γ g ) 21: end for 22: return ALGORITHM 2: Iterative attack algorithmsearching new routes as the victim moves. On average, about 40% of the trips can be diverted 500 meters away.One specific goal of the Deviating Attack could be delaying the victim's trip by leading the victim to loop routes. As shown in Figure 5b and Figure 5c, the smaller grid size helps Boston to reduce the hit rate deficit against Manhattan, since the dense road segments in Boston allow us to divert the victim to more precise destinations. Note that the attack covers the takeover phase when the phone loses the GPS signal for a while and then jumps to a new location.To help the participants to get familiar with the driving simulator, we spend about 5-10 minutes to let the partic-ipants play with the simulator before the real tests. This means, our attack may not be applicable to familiar area since people don't rely on GPS.Users are more likely to rely on the voice prompt and visual instructions than the textual information. The Chinese participant (user#5, m, 26-35, driving <3 years) recognized the attack during the first round (rainy night), alerted by the "highway and local way" inconsistency.During the driving task, we observe that almost all the participants noticed when the GPS signals are lost during the takeover phase (about 30 seconds), but still kept driving on the road. Overall, the results show that our attacks are highly effective even when human drivers are [12,27,36,49,50] High High High High GPS receiver hardware [24,31,35,40,47,73] Medium High High High GPS receiver software [32,35,47,48,55,63,65 in the loop. In the following, we discuss key directions of countermeasures.In Table 3, we classify different methods based on whether (or how much) they require modifications to the existing GPS. However, this approach is extremely difficult to prevail in a short term, given the massive number of civilian GPS devices already shipped and deployed in the short term.Second, trusted ground infrastructures to help GPS devices to verify the location and related techniques include trusted verifiers, distance bounding protocols [12,49], multilateration [50], multi-receiver crowdsourcing [27] and physical-layer feature checks [36]. However, this method in general suffers from accumulative IMU sensor errors and becomes ineffective as the time drifts.Computer Vision based Location Verification.We believe a promising defense direction is to use computer vision techniques to automatically cross-examine the physical-world landmarks and street signs with the digital maps. To date, researchers and hackers have successfully spoofed GPS devices in moving trucks [62], ships [46], drones [28] and mobile platforms [25,61] using off-the-shelf GPS signal simulator [62] or software defined radios [25,28,46,61]. Ranging from map applications (e.g., Google Maps, Waze) to taxi sharing platforms (e.g., Uber, Lyft), these services depend on accurate and reliable GPS inputs. Recently, GPS systems also start to play a major role in navigating autonomous vehicles, with a key impact on the driving safety [11]. As shown in Figure 4, a geographic area G is represented by a set of road segments and connection points. R is a set of road segments, and C = {c i = (r i , r i+1 )} is a set of connection points. The iterative algorithm (iteration i = 2) identified many more victim routes (3,507 routes per trip). As previously stated, the attack focuses on people who drive in the unfamiliar locations because they would be more likely to rely on the GPS navigation (instead of their own knowledge of the roads). Figure 7b and Figure 7c show the side-by-side companion of the game view (of a 3:1 map) and the actual street view (from Google Street View) at the same location. The participants will drive to deliver packages to a given destination following the navigation of Google Maps. In addition, users do not understand how GPS spoofing works, Among the 40 participants, only eight users can explain GPS spoofing correctly.We encourage the participants to comment on the differences between using the simulator and real-world driving. In addition, a navigation system may cross-check the GPS locations with dead reckoning results based on inertial measurement unit (IMU) sensors (e.g., accelerometer, gyroscope, magnetometer) [19,57]. Note that even with 20% hit rate in 2000m range, if the attacker provides three candidate target destination grids, the success rate will be higher 1 − (1 − 0.2) 3 = 48.8%. The goal of the real-world driving tests is to examine if the spoofer can trigger the fake navigation instruction in real-time right before users need to make a navigation decision.Similar as early measurements, we obtained a legal permission from the local radio regulation authority, and conducted the experiments exclusively in China. The attacker aims to guide the victim into a dangerous situation, for example, entering the wrong way on a highway.In our threat model, the attacker has no access to the internal software/hardware of the target GPS device or those of the navigation service. The attacker can terminate the searching algorithm earlier once a victim route hits the destination grid. The study takes about 50 minutes and we compensate each participant $10.Pre-study Survey.The survey asks two questions: (1) how often do you use GPS navigation services when driving in familiar locations (e.g., home and work) and unfamiliar locations (e.g., visiting a new city). During the real test, we encourage the participants to thinkaloud and record the audio.Post-study Interview.In the interview, we first debrief the participants about the real purpose of the study. For example, when a user drives in a very familiar area (e.g., commuting from home to work), the user is not necessarily relying on GPS information to navigate. In addition, the ghost location B should be close to A so that there will not be an obvious location change on the navigation map screen.In the following, we describe our attack objectives and constraints. At some point, an attacker launches the spoofing attack to change the victim's GPS from its actual location Loc a to a nearby ghost location Loc g . This means, beyond two meters away from the car, the signal strength is already very weak (about -127.41 dBm), which cannot take the lock of any GPS devices.In total, we tested on two different routes as shown in Figure 6. It can be simply a rough area (e.g., financial district, hotel zone) or a location checkpoint (e.g., main bridges, tunnels, highway entrances) that the victim will bypass. To minimize the impact of the spoofing signals, we reduce the transmit power of the spoofer to the minimum (-40 dBm) and then use attenuators (30 dB) to reduce the signal strength after locking in. In practice, attacker can use a larger grid if he can tolerate some inaccuracy of the target destination i.e, the victim is led to a nearby area instead of the exact target location. For the tailgating model, the victim is within the sight of the attacker, and thus Loc a is known.Regarding the victim's destination D, it is not necessarily the final destination. Our interview later shows most users have experienced malfunctioned GPS before, which is not enough to alert them.User Perceptions to the Attack.During the interview, we find that most users have experienced GPS malfunction in real life. By controlling the Raspberry Pi, we can inject the real-time GPS location information either manually or using scripts. Next, we evaluate the proposed algorithms using both trace-driven simulations and real-world driving test. The