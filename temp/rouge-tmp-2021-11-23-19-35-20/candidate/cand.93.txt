Mobile application security has been one of the major areas of security research in the last decade. This popularity of mobile devices is driven by the millions of diverse, feature-rich, third-party applications or "apps" they support.However, in fulfilling their functionality, apps often require access to security and privacy-sensitive resources on the device (e.g., GPS location, security settings). Applications can neither be trusted to be well-written or benign, and to prevent misuse of such access through malicious or vulnerable apps [59,44,98,80,35,87,32], it is imperative to understand the challenges in securing mobile apps.Security analysis of third-party apps has been one of the dominant areas of smartphone security research in the last decade, resulting in tools and frameworks with diverse security goals. We propose a semiautomated methodology to analyze the uncaught mutants, resolve them to flaws in the tool, and confirm the flaws experimentally.We demonstrate the effectiveness of µSE by evaluating static analysis research tools that detect data leaks in Android apps (e.g., FlowDroid [13], IccTA [55]). Thus, µSE not only helps researchers, tool designers, and analysts uncover undocumented flaws and unsound choices in soundy security tools, but may also provide immediate benefits by discovering easily fixable, but evasive, flaws.This paper makes the following contributions:• We introduce the novel paradigm of Mutationbased Soundness Evaluation, which provides a systematic methodology for discovering flaws in static analysis tools for Android, leveraging the well-understood practice of mutation analysis. Our analysis leads to the documentation of unsound assumptions, and immediate security fixes in some cases.Threat Model: µSE is designed to help security researchers evaluate tools that detect vulnerabilities (e.g., SSl misuse), and more importantly, tools that detect malicious or suspicious behavior (e.g., data leaks). Consider the following motivating example of a prominent static analysis tool, FlowDroid [13]:FlowDroid [13] is a highly popular static analysis framework for detecting private data leaks in Android apps by performing a data flow analysis. We discovered that FlowDroid (i.e., v1.5, latest as of 10/10/17) does not support "Android fragments" [10], which are app modules that are widely used in most Android apps (i.e., in more than 90% of the top 240 Android apps per category on Google Play, see Appendix A). However, we have confirmed that FlowDroid v2.5 [88] still fails to detect leaks in fragments, and are working with developers to resolve this issue.Through this example, we demonstrate that unsound assumptions in security-focused static analysis tools for Android are not only detrimental to the validity of their own analysis, but may also inadvertently propagate to future research. As of today, aside from a handful of manually curated testing toolkits (e.g., DroidBench [13]) with hard-coded (but useful) checks, to the best of our knowledge, there has been no prior effort at methodologically discovering problems related to soundiness in Android static analysis tools and frameworks. This section provides an overview of µSE ( Figure 1) and its design goals.As shown in Figure 1, we take an Android static analysis tool to be evaluated (e.g., FlowDroid [13] or MalloDroid [35]) as input. Similarly, while soundness may be a distant ideal for security tools, we assert that it should be feasible to articulate the boundaries of a tool's sound core. Security operators must be instantiated in a way that is sensitive to the context or purpose (e.g., data leak identification) of the tool being evaluated. Hence, we must ensure that µSE is efficient so as to to promote a wide-scale deployment and community-based use of µSE. In Step 1, we specify the security operators and mutation schemes that are relevant to the security goals of the tool being evaluated (e.g., data leak detection), as well as certain unique abstractions of Android that separately motivate this analysis. In Step 3, we apply the security tool under investigation to analyze the mutated app, leading it to detect some or all of the mutants as anomalies.We perform a methodological manual analysis of the undetected mutants, which may lead to documentation of flaws, and software patches.Note that tools sharing a security goal (e.g., FlowDroid [13], Argus [39], HornDroid [20] and BlueSeal [84] all detect data leaks) can be analyzed using the same security operators and mutation schemes, and hence the mutated apps, significantly reducing the overall cost of operating µSE (Goal G4). That is, the requirements are practically orthogonal for these two use cases, rendering a generic operator useless, while precisely designing tool-specific operators may not scale.In µSE, we take a balanced approach to solve this problem: instead of tying a security operator to a specific tool, we define it in terms of the security goal of the concerned tool (Goal G1). Moreover, security operators generalize to other security goals as well; a simple operator for evaluating tools that detect vulnerable SSL use (e.g., MalloDroid) could add a TrustManager with a vulnerable isServerTrusted method that returns true, which, when combined with our expressive mutation schemes (Section 4.2), would generate a diverse set of mutants.To derive security operators at the granularity of the security goal, we must examine the claims made by existing tools; i.e., security tools must certainly detect the unwanted behavior that they claim to detect, unless affected by some unsound design choice that hinders detection. 2) Open source tool documentation: Due to space limitations or tool evolution over time, research papers may not always have the most complete or up-to-date information considering what security flaws a tool can actually address. Note that while mutation schemes using the first two factors may be generally applied to any type of static analysis tool (e.g., SSL vulnerability and malware detectors), the third factor, as the description suggests, will only apply to a specific security goal, which in the light of this paper, is data leak detection.We describe each factor independently, as a mutation scheme, in the context of the following running example described previously in Section 2:Recall that FlowDroid [13], the target of our analysis in Section 2, detects data leaks in Android apps. Based on our domain knowledge of Android and its security, we choose the following features as a starting point in a mutation scheme that models unique aspects of Android, and more importantly, tests the ability of analysis tools to detect unwanted behavior placed within these features (Goal G2): 1) Activity and Fragment lifecycle: Android apps are organized into a number of activity components, which form the user interface (UI) of the app. We design our mutation scheme to 1 final Button button = findViewById(R.id.button_id); 2 button.setOnClickListener(new View.OnClickListener() {public void onClick(View v) {// Code here executes on main thread after user presses button}});Listing 2: Dynamically created onClick callback place mutants within methods of fragments and activities where applicable, so as to test a tool's ability to model the activity and fragment lifecycles. The objective behind this simple, but important, mutation scheme is to exercise the reachability analysis of the tool being evaluated. While the previous schemes add methods to the app (e.g., new callbacks), this scheme simply verifies if the app successfully models the bare minimum. µSE allows the analyst to dynamically implement such rules, as long as the input and output are both strings, and the rule complicates the path between them by sending the input through an arbitrary set of transformations.In a traditional mutation analysis setting, the mutation placement strategy would seek to minimize the number of non-compilable mutants. Once the mutated apps are cre- ated, for a feasible analysis, we pass them through a dynamic filter that removes the mutants that cannot be executed, ensuring that the mutants that each security tool is evaluated against are all executable. µSE reduces manual effort by filtering out mutants whose security flaws are not verified by dynamic analysis (Goal G3). As described in Figure 2, for any given mutated app, we use a dynamic filter (i.e., the Execution Engine (EE), described in Section 5) to purge non-executable leaks. This is aided by dynamic information from the EE so that an analyst can examine the order of execution of detected data leaks to infer the propagation of leaks through different call chains. For each of the identified call sequences invoking a given undetected data leak's source and sink, an analyst then attempts to synthesize a minimal example by recreating the call sequence using only the required Android APIs or method calls from the mutated app. This section provides the implementation details of µSE: (1) ME for mutating apps, and (2) EE for exercising mutants to filter out non-executing ones. We have made µSE available for use by the wider security research community [89], along with the data generated or used in our experiments (e.g., operators, flaws) and code samples. The MIP is derived through one of two types of analysis: (i) text-based parsing and matching of xml files in the case of app resources; or (ii) using Abstract Syntax Tree (AST) based analysis for identifying potential injection points in code. Execution Engine (EE): To facilitate a feasible manual analysis of the mutants that are undetected by a security analysis tool, µSE uses the EE to dynamically analyze target apps, verifying whether or not injected mutants can be executed in practice. In the second experiment (Section 6.3), we perform an in-depth analysis of FlowDroid by applying our systematic manual analysis methodology (Section 4.3) on the output of µSE for FlowDroid.Finally, our third experiment (Section 6.4) measures the propagation and prevalence of the flaws found in FlowDroid, in tools from our dataset apart from FlowDroid, and two newer versions of FlowDroid.These experiments are motivated by the following research questions: RQ1 Can µSE find security problems in static analysis tools for Android, and help resolve them to flaws/ unsound choices? In fact, we developed patches to correctly implement Fragment support (i.e., flaw 13 in Table 2), which were accepted by developers.To gain insight about the practical challenges faced by static analysis tools, and their design flaws, we further categorize the discovered flaws into the following flaw classes: FC1: Missing Callbacks: The security tool (e.g., FlowDroid) does not recognize some callback method(s), and will not find leaks placed within them. Additionally, some of these flaws may not be resolved even after adding the callback to the list; e.g.,PhoneStateListener and SQLiteOpen- FlowDroid does not recognize the onDataConnectionStateChanged() callback for classes extending the PhoneStateListener abstract class from the telephony package. FlowDroid misses the onReceive() callback of a BroadcastReceiver implemented programmatically and registered within another programmatically defined and registered BroadcastReceiver's onReceive() callback. Methodology: We check if the two newer release versions of FlowDroid (i.e., v2.5, and v2.5.1), as well as 6 other tools (i.e., Argus, DroidSafe, IccTA, BlueSeal, HornDroid, and DidFail), are susceptible to any of the flaws discussed previously in FlowDroid v2.0, by using the tools to analyze the minimal example APKs generated during the in-depth analysis of FlowDroid. X X X x X X x x X PhoneStateListener X X X x X X x x X NavigationView X X X - X - X - X SQLiteOpenHelper X X X x X X X x X Fragments X X X X X X X - X RunOnUIThread X X X x X X X x X ExecutorService X X X x X X X x X ButtonOnClickToDialogOnClick X X X x X x x X X BroadcastReceiver X X X x X x x x X LocationListenerTaint X X X x X x x x X NSDManager X X X x X x X x X ListViewCallbackSequential X X X x X x x x X ThreadTaint X X X x X x x x Xof FlowDroid are susceptible to the flaws discovered from our analysis of FlowDroid v2.0. More importantly, even in those cases where the tool does not directly inherit the code-base, unsound choices may still propagate at the conceptual level and result in real flaws. For instance, prior work on formally verifying apps often requires the monitor to be rewritten in a new language or use verification-specific programming constructs (e.g., verifying reference monitors [41,91], information flows in apps [67,68,95]), which poses practical concerns for tools based on numerous legacy codebases (e.g., FlowDroid [13], CHEX [62]). Recently, Acar et al. have systematized Android security research [9], and we discuss work that introduces static analysis-based countermeasures for Android security issues according to Acar et al.'s categorization.Perhaps the most prevalent area of research in Android security has concerned the permissions system that mediates access to privileged hardware and software resources. However, as described in Section 6.2, µSE possesses enhancements that mitigate the manual effort by dynamically eliminating non-executable mutants, that would otherwise impose a burden on the analyst examining undetected mutants. That is, we analyzed 240 top apps from every category on Google Play (i.e., a total of 8,664 apps collected as of June 2017 after removing duplicates), and observed that at least 4,273 apps (49.3%) used fragments in their main application code, while an additional 3,587 (41.4%) used fragments in packaged libraries. That is, we analyzed 240 top apps from every category on Google Play (i.e., a total of 8,664 apps collected as of June 2017 after removing duplicates), and observed that at least 4,273 apps (49.3%) used fragments in their main application code, while an additional 3,587 (41.4%) used fragments in packaged libraries.