(3) We demonstrate the security impact of debloating by eliminating over 71% of reusable code gadgets from the coreutils suite, and show that unused code that contains real-world vulnerabilities can also be successfully eliminated without adverse effects on the program. As a typical example, shared libraries are designed to contain the union of all functionality required by its users.Static dead-code-elimination -a static analysis technique used to identify unused code paths and remove them from the final binary -employed during compilation is an effective means to reduce bloat. As a direct impact, our solution significantly increases the effectiveness of current software defense by drastically reducing the amount of code they must analyze and protect.We identify and remove unused code by introducing a piece-wise compiler that not only compiles code modules (executables, shared and static objects), but also generates a dependency graph that retains all compiler knowledge on which function depends on what other function(s). Here, and in the rest of this paper, we use the generalized term "code module" to signify a shared library, static library or an executable and "loader" to signify both loader and dynamic linker.CFI vs Piece-wise. In essence, we recursively traversed through all dependent code modules of a program and gathered all the function-level dependencies.On average, only 10.22% of functions in the top 15 most used shared libraries are used by programs (full results in Appendix A). For example, libc provides subroutines for memory management (e.g., malloc, calloc, free), file I/O (e.g., fopen, fclose, printf, scanf), string manipulation (e.g., strcpy, toupper, tolower), etc. If available, the dynamic linker will bind the symbol names to the strong definitions, rendering the weak definitions redundant; the unused weak implementation remains in memory and contributes to bloating.For example, glibc 2.19 hosts 610 (29%) functions that are marked as weak symbols including popular memory management functions like calloc. However, like in the static case, this design is not ideal for usability since each focused shared library is likely to be much smaller than the usual 4k page size granularity. Specifically, (1) we develop a piece-wise compiler that maintains intra-modular (piece-wise) dependencies between each individual functionality (i.e., entry point) and all dependent functions that are necessary to satisfy execution, and (2) we develop a piece-wise loader that examines the dependencies of an executable and generates an inter-modular fullprogram dependency graph. For a given code module, the piece-wise compiler has two main tasks: generate a function-level dependency graph with zero false negatives (we do not want to miss any legitimate dependency), and write this dependency graph to the binary. Below, we detail the treatment of such cases to ensure complete dependency recovery.Two factors can have a significant effect on the accuracy of a call graph: code pointers and jump tables, and hand-written assembly (this includes pure-assembly functions and inlined assembly). To see why, we separate the problem into two cases -function pointers associated with symbols and those that are not associated with symbols.Function pointers that target symbols can be directly identified as long as the target is internal to the module being compiled. References through composite structures are not uncommon, yet hard to detect.1 struct _IO_FILE { 2 ...Additionally, function pointers are used to implement callback functions, and are passed as arguments during callback registrations (e.g., arguments to signal, qsort). For example, in libc, a 'FILE' struct with a set of function pointers is created for every IO operation.In order to obtain a complete set of code pointer references within a module, we perform code-pointer anal-ysis (function pointer analysis + jump table recovery) to recover all potential code references either to functions or to code snippets (e.g., targets in switch statement). This is unlike the full-module scan where comp is marked as required for the entire module.1 ... 2 int comp ( int a , int b ) {...} 3 int foo () { ... /* foo is a global symbol */ 4 sort ( arr , len , & comp ) ; } 5 ... First, use-def chains are constructed for all IR instructions. We extract four types of constraints that were first proposed by Hardekopf and Lin [16] based on semantics of the pointer reference. For a variable v, pts(v) represents v's points-to set and loc(v) represents the memory location denoted by v. Meaninga = &b a ⊇ {b} loc(b) ∈ pts(a) a = b a ⊇ b pts(a) ⊇ pts(b) a = * b a ⊇ * b ∀v ∈ pts(b) : pts(a) ⊇ pts(v) * a = b * a ⊇ b ∀v ∈ pts(a) : pts(v) ⊇ pts(b)constraints are then fed into a constraint solver to extract concrete pointer values/value sets at different codepointer reference points within functions. Compilers do not optimize hand-written and inline assembly code and, as such, interdependencies involving assembly code are handled separately.Dependencies in assembly code: We perform a single pass through assembly code to identify all function calls and update the callgraph accordingly. From our experiments, we find that this simple approach is sufficient to capture all the higher-level (e.g., C/C++) function dependencies for code originating from assembly.Dependencies on assembly code: Identifying assembly code dependencies for high-level functions is more difficult since function boundaries in optimized code is sometimes blurred due to code reuse. Our compiler inserts two types of information to assist the loader with identifying dead code: dependency relationships between functions (i.e. the dependency graph) that comprises of functions and a list of dependencies, and function-specific data that includes location and size in bytes for all the functions in the dependency graph. To address this, our loader pre-loads all shared libraries.First, the piece-wise loader recursively traverses all shared objects and their dependencies (by looking at DT NEEDED entries of the dynamic section of the ELF file of the program executable) to construct the list of shared objects that the main program needs. At load time, the piece-wise loader will interpret it, pre-load those libraries, and retain only the functions that dlsym invokes.We found that only 64/2226 (2.9%) programs in our study dynamically compute module names. In our test set, all library name computations are straightforward: library names are hard-coded or generated using format string.For example, if (var) sprintf(name, "lib%s v1.so", basename) else sprintf(name, "lib%s v2.so", basename). Therefore, all dependencies for a program are known before it begins execution.To determine which functions are not required at runtime, i.e., the ones that must be removed, we rely on symbol resolution and the dependency graph embedded in the . During symbol resolution, the loader binds an undefined symbol to the first available definition for the symbol in the load order which allows our loader to identify which library functions the program imports.At the end of symbol resolution, all symbols in the global symbol table are fully resolved and reflect the runtime necessities of the program. We divide our evaluation into three main parts: debloating correctness (sections 6.2.1 and 6.2.2), performance overhead (section 6.3), and impact of debloating on security (section 6.4). The difference in functionality between glibc and musl-libc does not affect the feasibility and capability of the piece-wise toolchain.To get a sense of how much glibc can be debloated, we extracted 30 different features and the functions within each feature from the glibc software development manual [4], and mapped them to analogous symbols in musl-libc. Our results show that, among the three approaches for handling code pointers, localized code pointer scan and pointer analysis achieve the best debloating result (79% and 78% respectively) while full-module debloats the least, 58%. In the best case, 86% attack space reduction was achieved with localized scan and pointer analysis, and in the worst case, 60% code reduction was achieved for full-module pointer scan.While on average, pointer analysis and localized code pointer scan yield the same attack space reduction results, for some cases in the SPEC CPU 2006 benchmarks, we observe that one outperformed the other. On the one hand, the localized scan approach provides better debloating results when it allows removing functions that will not have address taken at runtime because all referring functions Table 4: Gadget reduction in coreutils 8.2 and SPEC CPU 2006 benchmarks for 6 different types of security sensitive gadgets: syscall, stack pointer update (SPU), call-oriented programming (COP), call-site/call preceded gadgets(CS), jump-oriented programming (JOP), and entry-point (EP). While static linking provides optimal debloating benefits, its use in practice is limited due to the following reasons:• Requires recompilation of binaries with every library or software update. • Risks transferring bugs in a shared library to the binary.Since piece-wise aims to bring dead code elimination benefits from static linking to dynamic linking, in table 8, we compare whole-program code reduction achieved by static linking with late-stage debloating using piece-wise toolchain. Compile-time overhead.We measured execution time added by our LLVM pass for each of the three approaches (full-module scan, localized scan and inclusion-based points-to analysis) by inserting timing code at the beginning and end of pass' main logic. On average, the code piece-wise loader that performs debloating added 20 milliseconds to the each process load time across all coreutils programs.Second, because piece-wise loader writes to code pages that contain the copies of shared libraries, copyon-write is triggered, which results in additional load time overhead. Table 4, we show overall gadget reduction as well as reduction security-sensitive gadgets that have been extensively used in previously published work such as syscall [34], stack-pointer update (SPU) [35,15], call-oriented programming (COP) [11], call-site/call preceded (CS) [15,11] , jump-oriented programming (JOP) [9], and entry-point (EP) [15] gadgets. If the assumption is violated, strdup will read beyond buffers' boundaries, allowing an attacker to crash the program by triggering a segmentation fault or, in the worst case scenario, perform an out-of-bound memory read. To make matters worse, after duplication, it fails to update the pointer to point to the new buffer which can trigger illegal use of freed memory if original object has been freed.Our evaluation shows that debloating libcurl when it is used with programs like curl or cmake completely removes the affected functions and therefore the bug can no longer be exploited to perform a memory disclosure or a denial-of-service attack as part of an exploit payload such as through a return-to-libc attack. Piece-wise compilation and loading is independent of, yet complements CFIbased approaches.Feature-based Software Customization.Unlike C/C++, managed programing languages whose execution is monitored by Runtime Virtual Machine suffers from significant runtime overhead or bloating due to the extra logic added to manage an execution environment.