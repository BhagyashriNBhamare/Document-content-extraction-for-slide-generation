These leakage tests are a valuable tool for security analysts to determine the severity and exploitability of a leak.We implement DATA in a fully automated evaluation tool that allows analyzing large software stacks, including initialization operations, such as key loading and parsing, as well as cryptographic operations. For instance, attacks exploiting the different memory access times to CPU caches (aka cache attacks) range from timing-based attacks [11] to more fine-grained attacks that infer accesses to specific memory locations [61,64,87]. While a zero leakage bound guarantees absence of address-based side channels, a non-zero leakage bound could become rather imprecise (false positives) due to abstractions made on the data of the program. DATA analyzes a program binary P with respect to address leakage of secret input k. Let P(k) denote the execution of a program with controllable secret input k. A deterministic program P is leakage free if and only if no differences show up for any pair of secret inputs (k i , k j ):∀k i , k j : diff(trace(P(k i )), trace(P(k j ))) = ∅ (1) Data leakage is characterized by one and the same instruction (ip) accessing different memory locations (d). Execution with two different keys key A = [10,11,12] and key B = [16, 17, 18] yields two address traces t A = trace(P(key A )) and t B = trace(P(key B )), with differences marked bold: 0 p r o g r a m e n t r y : c a l l p r o c e s s w i t h u s e r -i n p u t 1 u n s i g n e d char LUT [ 1 6 ] = { 0 x52 , 2 0 x19 , . . . 16 0 x37 } ; 17 i n t t r a n s f o r m ( i n t k v a l ) { r e t u r n LUT[ k v a l %16]; } 18 i n t p r o c e s s ( i n t key [ 3 ] ) { 19 i n t v a l = t r a n s f o r m ( 0 ) ; 20 v a l += t r a n s f o r m ( key [ 0 ] ) ; 21 v a l += t r a n s f o r m ( key [ 1 ] ) ; 22 v a l += t r a n s f o r m ( key [ 2 ] ) ; 23 r e t u r n v a l ; } Listing 1: Table look-up causing data leak.Since the base address of LUT is 1, this operation leaks memory address kval + 1. The differences occur due to the if in line 3 which branches to line 4 or 5, depending on the key bit b, and causes operations in line 7 and 9 to be done either on the intermediate variable r or a temporary variable t. If the two branches are significantly asymmetric in length, we might match multiple shorter loop iterations against one longer iteration, thus introducing an artificial control-flow leak (false positive) when one branch leaves the loop while the other does not. Such a leak would occur, if the secret permutes the addresses in the evidence traces, e.g., [r 1 , r 2 ] and [r 2 , r 1 ], while the length of the evidence traces as well as the number of accesses per address remains the same. ev 0 = [r 1 , r 2 ], ev 1 = [r 3 , r 3 , r 2 , r 3 , r 1 ], ev 2 = [r 2 , r 1 , r 2 ] We compile the evidence traces into two histograms, namely H fix addr and H fix pos for fixed secret inputs, and H rnd addr and H rnd pos for random inputs. It links the test statistic to a certain confidence level and is defined asQ st (λ ) = 2 ∞ ∑ i=1 4i 2 λ 2 − 1 e −2i 2 λ 2 . The leakage classification phase is based on a specific leakage test, which tests for linear and non-linear relations between the secret input and the evidences of information leaks. M ev pos stores the position of each address in the evidence trace.If an address does not occur in a trace, the matrix entry is set to '-1'. After adding the data, we obtain:M ev addr =   1 1 1 1 1 2 0 3 0   , M ev pos =   0 4 1 1 2 1 -1 1 -1   The transformation of the input is called leakage model. The RDC detects linear and non-linear relations between random variables, its test statistic R is defined between 0 and 1, with R = 1 showing perfect dependency and R = 0 stating statistical independence. We precompute the significance threshold R st for a given confidence level α by generating a sufficiently large number (≥ 10 4 ) of statistically independent sequences of length n (the same length as the rows in M ev addr , M ev pos , and M in L ) and estimating the distribution of R. We analyzed Curve25519 in NaCl [13] as well as the corresponding Diffie-Hellman variant of OpenSSL (X25519) and found no addressbased information leakage (apart from OpenSSL's key parsing), approving their side-channel security. Indeed, Table 2 shows that the leakage detection phase confirms all differences as leaks.To evaluate DATA's accuracy on non-deterministic programs, we tested OpenSSL asymmetric ciphers and collected up to 30 traces, as shown in Figure 4. Running all three phases on RSA takes 233.8 CPU minutes with a RAM utilization of less than 4.5 GB (single core). Analyzing PyCrypto yields large address traces due to the interpreter (1GB and more), nevertheless DATA handles such large traces without hassle: The first phase discards all non-leaking instructions, stripping down trace sizes of the subsequent phases to kilobytes (see Appendix B). However, when using OpenSSL inside SGX enclaves (cf. Intel's SGX SSL library [40]), the attacker can trigger arbitrarily many program executions, making single-event leakage practically relevant, as demonstrated by the RSA key recovery attack in [82]. After using DATA to identify address-based information leaks in cryptographic software implementations, the following approaches could be applied as mitigation. We would like to thank the anonymous reviewers, as well as Mario Werner and our shepherd Stephen McCamant for their valuable feedback and insightful discussions that helped improve this work.This work was partially supported by the TU Graz LEAD project "Dependable Internet of Things in Adverse Environments", by the Austrian Research Promotion Agency (FFG) via the K-project DeSSnet, which is funded in the context of COMET -Competence Centers for Excellent Technologies by BMVIT, BMWFW, Styria and Carinthia, as well as the European Research Council (ERC) under the European Unions Horizon 2020 research and innovation programme (grant agreement No 681402). Blowfish leaks at BF encrypt, Camellia leaks the LCamellia SBOX at Camellia Ekeygen and x86 64 Camellia encrypt, CAST leaks the CAST S table0 to 7 at CAST set key as well as CAST encrypt, DES leaks the des skb at DES set key unchecked as well as DES SPtrans at DES encrypt2.OpenSSL (Asymmetric Primitives). This is a programming bug: the so-called constant-time flag is set for p and q in function rsa ossl mod exp but not propagated to temporary working copies inside BN MONT CTX set, as shown in Listing 3, since the function BN copy in line 3 does not propagate the consttimeflag from mod to mont->N. We implement the difference detection as well as the generic and the specific leakage tests in Python scripts, which condense all findings into human-readable leakage reports in XML format, structuring information leaks by libraries, functions, and call stacks. While the address differences found in the difference detection phase do not settle within 30 traces (introducing false negatives), an important finding is that the majority of these differences are due to statistically independent program activity, e.g., RSA base blinding. This clearly shows that the tedious and errorprone task of implementing countermeasures should be backed by appropriate tools such as DATA to detect and appropriately fix vulnerabilities as early as possible.We found issues in loading and parsing cryptographic keys as well as initialization routines. This avoids wrong assumptions about attackers, e.g., only observing memory accesses at cache-line granularity [24,41,80], which were disproved by more advanced attacks [1,88]. We define an address trace t = [a 0 , a 1 , a 2 , a 3 ...] as a sequence of executed instructions, augmented with memory addresses. From a side-channel perspective, this is desirable since those native libraries could be tightened against side-channel attacks, independently of the used interpreter. Among several expected leaks in symmetric ciphers (AES, Blowfish, Camellia, CAST, Triple DES, ARC4), DATA also reveals known and previously unknown leaks in asymmetric primitives (RSA, DSA, ECDSA) and identifies erroneous bug fixes of supposedly resolved vulnerabilities. Among those, we found two constant-time vulnerabilities in RSA and DSA, respectively, which bypass constant-time implementations in favor of vulnerable implementations. Practicality: Report information leaks (i) fully automated, i.e., without requiring manual intervention, (ii) using only the program binary, i.e., without requiring the source code, and (iii) efficiently in terms of performance. The significance threshold is then derived from Φ −1 (x), which is the inverse cumulative distribution function of the standard normal distribution, as follows:R st = µ + σ · Φ −1 (α) . Our diff algorithm would report:diff(t A ,t B ) = {(3, [0], {[4, (7, R), (8, P), (9, R)],[5, (7, T ), (8, P), (9, T )]} )} We execute the program on a dynamic binary instrumentation (DBI) framework, namely Intel Pin [54], and store the accessed code and data addresses in an address trace. We also transform the secret inputs according to the chosen leakage model L and store the results in the input matrix M in L . Analysts using DATA should therefore add traces until the test results stabilize and no new leaks are detected. In contrast to the HW, the key bit model is more fine-grained and thus targets very specific leaks only, e.g., it reveals leaks that occur when the private key is parsed. The first step of the test is to derive the empirical distribution functions F X (x) and F Y (x) asF X (x) = 1 n X · n X ∑ i=1 I [X i ,∞] (x) . Nevertheless, we found that in practice few traces already suffice, e.g., ≤ 10 for asymmetric algorithms, and ≤ 3 for symmetric algorithms, due to the high diffusion provided by these algorithms. Xu et al. [86] demonstrated a new class of attacks on shielded execution environments like Intel SGX, called controlled-channel attacks. The Kuiper statistic V is then computed asV = sup x [F X (x) − F Y (x)] + sup x [F Y (x) − F X (x)] . Evidence traces contain all essential information exploited in practical attacks, such as how often an address is accessed [11,45] and also when, i.e., at which position an address is accessed in the trace [87]. The differences in the traces-marked bold-reveal key dependencies.To accurately report data leakage and to distinguish non-leaking cases (line 19) from leaking cases (line 20-22), we take the call stack into account. As shown in Figure 1, we repeat this multiple times with varying inputs, causing address leaks to show up as differences in the address traces.The concept of DATA is agnostic to concrete recording tools and, hence, could also rely on other tools [71] or hardware acceleration like Intel Processor Trace (IPT) [39]. This is a strong attacker model that covers many side-channel attacks targeting the processor microarchitecture (e.g., branch prediction) and the memory hierarchy (e.g., various CPU caches, prefetching, DRAM). By exploiting parallelism, the actual execution time can be significantly reduced, e.g., from 55 min to approximately 250 s for the first phase of RSA. The leakage classification phase helps in rating its severity, however, an accurate judgment often demands significant effort in assembling and improving concrete attacks [12]. The majority of leaks reported by the HW model are indicating that the length of the key or of intermediate values leaks (as the HW usually correlates with the length). Similar to the evidence matrices, every input gets assigned a column in M in L . We used Pin version 3.2-81205 for instrumentation and compiled glibc 2.24 as well as OpenSSL 1.1.0f 2 in a default configuration with additional debug information, using GCC version 6.3.0. Many of these software-based attacks exploit addressbased information leakage to recover cryptographic keys of symmetric [6,36] or asymmetric [28,87] primitives.Various countermeasures against address-based information leakage have been proposed on an architectural level [52,62,81]. The low number of traces results from the high diffusion and the regular design of symmetric ciphers, which yields a Figure 4: Dismissed non-deterministic differences and discovered leaks for OpenSSL RSA as stacked plot.high probability for quickly hitting all variations in the program execution. Coppens et al. [21] proposed compiler transformations to eliminate keydependent control-flow dependencies. Rather than pinpointing the leakage origin, CacheAudit accumulates potential leakage into a single metric, which represents an upper-bound on the maximum leakage possible. The first call to transform (line 19) with kval = 0 results in a 1 = (17, 1). In this work, we present DATA, a differential address trace analysis framework that detects address-based side-channel leaks in program binaries. Scatter-gather prevents data leaks on RSA exponentiation by interleaving data in memory such that cache lines are accessed irrespective of the used index. These techniques measure the execution time of implementations for different classes of inputs and rely on statistical tests to infer whether or not the implementation leaks information [23]. Such relations are formulated as so-called leakage models, e.g., the Hamming weight model. We use statistical tests 