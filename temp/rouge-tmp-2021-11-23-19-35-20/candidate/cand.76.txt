In particular, we identify eight factors in OS design and implementation that could cause behavioral divergences under attack, ranging from syscall semantics (more obvious) to heap object metadata structure (more subtle) and further show how they can thwart attackers from finding bugs, exploiting bugs, or performing malicious activities. Systemwide dependencies such as graphics libraries [23] are also on attackers' radar.The continued exploitation of AAR along with the ubiquity of the PDF format makes maldoc detection a pressing problem, and many solutions have been proposed in recent years to detect documents bearing malicious payloads. AV products also exhibit problems providing protection against zero-day attacks, due to the lack of attack procedures and runtime traces.In this paper, we propose PLATPAL, a maldoc detection scheme that analyzes the behavioral discrepancies of malicious document files on different platforms (e.g., Windows or Macintosh (Mac)). Unlike the static and dynamic detection schemes that rely on existing malware samples to construct heuristics, PLATPAL is based on a completely different set of insights: 1) a benign document behaves the same (in a certain level) across platforms, while 2) a malicious document causes diverged behaviors when launching exploits on different platforms.The first assumption can be empirically verified by opening many benign samples that use a variety of PDF features across platforms. Consensus in execution traces and outputs indicates the health of the document, while divergences signal an attack.Although the process sounds simple and intuitive, two practical questions need to be addressed to make PLATPAL work: 1) what "behaviors" could be potentially different on different platforms? For a collection of 320 maldoc samples exploiting 16 different CVEs, PLATPAL can detect divergences in 209 of them with an additional 34 samples crashing both AAR instances. Existing maldoc detection methods can be classified broadly into two categories: 1) dynamic analysis, in which malicious code is executed and examined in a specially instrumented environment; and 2) static analysis, in which the detection is carried out without code execution. During execution, if the memory access sequences match a known malicious pattern (e.g., ROP, critical syscalls or function calls, etc), the script is considered malicious.Although these techniques are accurate in detecting malicious payload, they suffer from a common problem: an incompatible scripting environment. Certain attacks might also exploit the memory layout knowledge such as the presence of ROP gadgets or functions available in AAR and its dependent libraries, which is hard to emulate in an external analysis environment.Instead of emulating the JavaScript execution environment, Liu et al. [29] instruments the PDF document with context monitoring code and uses AAR's own runtime to execute JavaScript code and hence is not affected by the incompatibility problem. However, the instrumented code only monitors common and known patterns of malicious behavior such as network accesses, heap-spraying, and DLL-injection, etc, which are not fully generic and have to be extended when new anti-detection measures of malicious code come up. This is in contrast with traditional sandboxed malware analysis such as Cuckoo [44] or CWSandbox [63], which executes the malware and examines its behavior and influence on the host operating system during runtime. We design PLATPAL to: 1) share the same view of the document as the intended interpreter (i.e., AAR in this paper); 2) use simple heuristics that do not rely on machine learning; 3) detect zero-day attacks without prior knowledge; 4) capture the maldoc's influence on the host system; and 5) be complementary to the surveyed techniques to further raise the bar for maldoc attackers. However, when we opened the same sample with the Mac version of AAR 10.1.4, the attack failed and no malicious activities were observed.In fact, in the malware history, Windows has drawn more attraction from attackers than Mac, and the same applies to maldocs. Therefore, it is reasonable to expect that the majority of maldocs target primarily the Windows platform, as cross-platform exploits are much harder to develop due to the factors discussed later.The mindset of maldoc attackers and the discrepancy in reacting to malicious payload among different platforms inspire us to use platform diversity as the heuristic for maldoc detection: a benign document "behaves" the same when opened on different platforms while a maldoc could have different "behaviors" when launching exploits on different platforms. The different sets of libraries loaded by AAR block two types of exploits: 1) exploits that depend on the existence of vulnerabilities in the loaded libraries, e.g., graphics libraries, font manager, or libc, as they are all implemented differently on Windows and Mac platforms; and 2) exploits that depend on the existence of certain functions in the loaded libraries, e.g., LoadLibraryA, or dlopen. Although "fat binaries" that can run on multiple CPU architectures exist, we are not aware of an executable format (or any wrapper tools) that is capable of running on multiple platforms. This is heavily relied upon by the dropper or phishing type of maldocs, for example, dropping a malformed MS Office document that exploits MS Office bugs, or redirecting the user to a malicious website that attacks the Internet Explorer browser. However, these gadgets and their addresses in memory can be easily distorted by the discrepancies in loaded libraries and memory layouts.On the other hand, exploiting features that are naturally cross-platform supported, e.g., JavaScript hidden API attacks or abusing the structure of PDF document to obfuscate malicious payload, are not subject to the intricacies of runtime memory contents and are more likely to succeed.Finally, even if an attacker succeeds in the first two steps, the attack can be detected while the maldoc is performing malicious activities, such as executing a syscall, loading a PE-format executable on Mac platforms, or accessing a file that exists only on Windows platforms. In other words, maldocs that exploit bugs in dependent libraries will surely fail on other platforms.Another source of bugs comes from the AAR implementation itself, and we also found a few cases where the implementation of the same function can be vulnerable on one platform but safe on the other. 1 var t = {}; 2 t.__defineSetter__('doc', app.beginPriv); 3 t.__defineSetter__('user', app.trustedFunction); 4 t.__defineSetter__('settings', function() { throw 1; }); 5 t.__proto__ = app; 6 try { Besides being simple to construct, these attacks are generally available on both Windows and Mac platforms because of the cross-platform support of the JavaScript. By repeatedly allocating the attack payload and NOP sled in heap [13], an attacker is alleviated from using precise memory locations for control-flow hijacking; instead, an attacker only needs to ensure that control-flow is redirected to the sprayed area. The key idea is to find operations that are meaningful in one platform and NOP on the other and use these operations to jump to different code for platform-specific activities.Although these operations can succeed on both platforms, attacks using these techniques can still be detected by platform diversity. For example, heap manipulation can succeed but the resulting memory layout might not be suitable for both platforms to land the critical data in attacker-controlled memory because of the discrepancies in heap management, while ployglot shellcode trampolines can run without crashing AAR, but the attack can still be detected by the malicious activities performed. The internal behaviors, however, all show the same thing: execution of JavaScript code stops at the same place.The most compelling reason to have an internal behavior tracer is to defeat platform probing attempts, without which PLATPAL can be easily evaded by launching platform-aware attacks, as described in ยง3.5. Note that displaying content to screen is a platform-dependent procedure and hence, will not be hooked by PLATPAL, but the callbacks (e.g., an object is rendered) are platform-independent and will be traced.In addition, for AAR, when the rendering engine performs a JavaScript action or draws a JavaScript-embedded form, the whole block of JavaScript code is executed. Another difference is that the summary generated by Cuckoo and CWSandbox usually requires manual interpretation to judge maliciousness, while the summary from PLATPAL requires no human effort in comparing behaviors across platforms. We prototype PLATPAL to work on recent Windows (versions 7, 8 and 10) and Mac (versions Yosemite, El Capitan, and Sierra) platforms, and is compatible with all AAR versions from Adobe Reader X 10.0 to the latest version of Adobe Acrobat DC. The AAR plugin provides a few nice features that suit PLATPAL's needs: 1) Its cross-platform support abstracts the platform-specific operations to a higher level; 2) It uses the internal logic of AAR in PDF processing and summarizes the logic into 782 functions and callbacks (nicely categorized and labeled), which enables PLATPAL to both passively monitor the execution of these functions and actively drive the document, including executing JavaScript code and rendering elements; 3) It is stable across AAR versions (only two functions are added since version 10, which are not used by PLATPAL); 4) Since the AAR plugin is in the form of a loadable module, it shortens the total document analysis time to an average of 24 seconds.In recording behaviors discussed in ยง4.2, the COS objects and PD hierarchical information are extracted using the enumeration methods provided by the CosDoc, PDDoc, and PDF_Consultant classes. Syscalls of both threads are traced and compared.To compare file paths, PLATPAL further aggregates and labels filesystem operation traces into a few categories that have mappings on both platforms, including AAR program logic, AAR support file, AAR working caches, system library/framework dependencies, system fonts, and temporary files. For PLATPAL, the purpose of having an automated execution sandbox is twofold: 1) to confine the malicious activities within a proper boundary and 2) to provide a clean execution environment for each document examination that is free from side effects by prior executions.The virtual machine (VM) is initialized with a clean-slate operating system and subsequently provisioned with the necessary tools and settings, including AAR, the plugin, and the syscall tracer. For any sample submitted to PLATPAL, only three outcomes are possible: 1) Malicious: At least one behavioral discrepancy is observed, including the case in which AAR crashes on both platforms but the internal behavior is different, i.e., they crash at different PDF processing stages.2) Suspicious: AAR crashes on both platforms but no difference is observed in internal behaviors. In particular, we observed two CVE-2013-3353 samples attempted to connect to a C&C server in JavaScript but did nothing afterwards because of the lack of responses, which results in no divergences in execution trace.In the end, for the rest of the samples classified as benign (20 in total), we are unable to confirm a reason why no behavioral discrepancies are observed. Similarly, PLATPAL cannot detect attacks that intentionally delay their execution (e.g., start exploitation two minutes after document open). If a maldoc targets a specific version of AAR, its behaviors in PLATPAL will likely be either crashing both AAR instances (i.e., exploited the bug but used the wrong payload), or the document is rendered and closed gracefully because of error correction by AAR.In the latter case, PLATPAL will not be able to detect a behavioral discrepancy. Our current implementation uses 60GB disk space to host the snapshots for six versions of AAR and 2GB memory per each running VM.To this end, we believe that PLATPAL is best suited for cloud storage providers (e.g., Dropbox, Google Docs, Facebook, etc.) which can use PLATPAL to periodically scan for maldocs among existing files or new uploads. For example, Frost [60] instruments a program with complementary scheduling algorithms to survive concurrency errors; Crane et al. [16] applies dynamic control-flow diversity and noise injection to thwart cache side-channel attacks; Tightlip [68] and Capizzi et al. [10] randomize sensitive data in program variants to mitigate privacy leaks; Mx [24] uses multiple versions of the same program to survive update bugs; Cocktail [66] uses multiple web browser implementations to survive vendor-specific attacks; and Nvariant [15], Replicae [8], and GHUMVEE [61] run program variants in disjoint memory layouts to mitigate code reuse attacks. Both internal and external traces are compared, and the only heuristic to detect maldoc is based on the observation that a benign document behaves the same across platforms, while a maldoc behaves differently during exploitation, because of the diversified implementations of syscalls, memory management, etc. across platforms.