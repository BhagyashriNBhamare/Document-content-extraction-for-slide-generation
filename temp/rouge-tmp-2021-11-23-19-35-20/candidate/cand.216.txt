Typically, these architectures modify the cache organization in order to minimize interference between different processes, either by breaking the trivial link between memory address and cache index [22,55,67,69,70] or by providing exclusive access to cache partitions for critical code [53,57,69]. Nevertheless, the runtime performance of software on SCATTERCACHE is highly competitive and, on certain workloads, even outperforms cache designs implemented in commodity CPUs.SCATTERCACHE constitutes a comparably simple extension to cache and processor architectures with minimal hardware cost: SCATTERCACHE essentially only adds additional index derivation logic, i.e., a lightweight cryptographic primitive, and an index decoder for each scattered cache way. This cache hierarchy typically consists of 2 to 4 layers, where the offset set [idx+2] set [idx-2] set [idx-1] set [idx+1] way 0 way 1 way 2 way 3 index tag Figure 1: Indexing cache sets in a 4-way set-associative cache. While optimized addressing logic can lead to efficient implementations, these designs differ significantly from conventional architectures.Time-Secure Caches [67] is based on standard setassociative caches that are indexed with a keyed function that takes cache line address and Process ID (PID) as an input. SCATTER-CACHE can be seen as a generalization of this approach with higher entropy in the indexing of cache lines.CEASER [55] as well uses standard set-associative caches with keyed indexing, which, however, does not include the PID. Between software defined security domains (e.g., different processes or users on the same machine, different VMs, . . . ), even for exactly the same physical addresses, cache lines should only be shared if cross-context coherency is required (i.e., writable shared memory). This means that all addresses mapping to the same cache set are congruent and enables PRIME+PROBE-style attacks.In SCATTERCACHE, on the other hand, the cache set for a particular access is a pseudorandom selection of arbitrary n ways cache lines from all available lines. This IDF effectively randomizes the mapping from addresses to cache sets as well as the composition of the cache set itself.Instead, as shown at the bottom of Figure 2, at best, partially overlapping cache sets can be found (cf. Section 4.3), which makes exploitation tremendously hard in practice. Instead, as shown in Figure 4, each index addresses a separate memory, i.e., an independent cache way.On the one hand, this change is counter-intuitive as it decreases the number of possible cache sets from n ways ·2 b indices +n ways −1 n ways to 2 b indices ·n ways . This effectively precludes the introduction of systematic biases for potentially "weak" address-key-SDID combinations that map to fewer than n ways cache lines.In terms of cache-replacement policy, SCATTERCACHE uses simple random replacement to ensure that no systematic bias is introduced when writing to the cache and to simplify the security analysis. Following Kerckhoffs's principle, even for attackers which know every detail except the key, three properties are expected from the IDF: (1) Given perfect control over the public inputs of the function (i.e., the physical address and SDID) constructing colliding outputs (i.e., the indices) should be hard. (3) Recovering the key should be infeasible given input and output for the function.Existing Building Blocks: Cryptographic primitives like (tweakable) block ciphers, Message Authentication Codes (MACs), and hash functions are designed to provide these kind of security properties (e.g., indistinguishability of encryptions, existential unforgeability, pre-image and collision resistance). Using such cryptographic primitives, we define the following two variants of building IDFs:Hashing Variant (SCv1): The idea of SCv1 is to combine all IDF inputs using a single cryptographic primitive with pseudo random output. Interestingly, finding cryptographic primitives for SCv1 IDFs is comparably simple given that the block sizes do not have to match perfectly and the output can be truncated as needed.However, there are also disadvantages when selecting the indices pseudo randomly, like in the case of SCv1. Using a tag dependent permutation of the input index mitigates this problem by design since permutations are bijections that, for a specific tag, cannot yield colliding mappings.Like in the hashing variant, a tweakable block cipher can be used to compute the permutation. However, we are certain that, even with the already existing and well-studied cryptographic primitives, SCATTERCACHE implementations are feasible for common computing platforms, ranging from Internet of Things (IoT) devices to desktop computers and servers.Note further that we expect that, due to the limited observability of the IDF output, weakened (i.e., round reduced) variants of general purpose primitives are sufficient to achieve the desired security level. Note, however, that the interval between key changes should not be too small as each key change corresponds to a full cache flush.On the other hand, in a cache with write-back policy, the key has to be kept constant as long as dirty cache lines reside in the cache. Considering that this number is even lower than the time it takes to check the L1 and L2 caches on recent processors (e.g., 3 ns on a 4 GHz Intel Kabylake [2], 9 ns on an ARM Cortex-A57 in an AMD Opteron A1170 [1]), implementing IDFs without notable latency seems feasible. For example, a security domain can be a chunk of the address space (e.g., SGX enclaves), a whole process (e.g., TrustZone application), a group of processes in a common container (e.g., Docker, LXC), or even a full virtual machine (e.g., cloud scenario). In more detail, one or more bits can be embedded into each PTE that select from a list, via one level of indirection, which SDID should be used when accessing the respective page.Both ARM and Intel processors already support a similar mechanism to describe memory attributes of a memory mapping. In particular, SCATTERCACHE maintains a separate copy of shared read-only memory in cache for each security domain, i.e., the cache lines belonging to the same shared memory region are not being shared in cache across security domains anymore. In total, the expected number of memory accesses required to construct an eviction set of t colliding addresses hence is E(n accesses ) = n ways 2 · 2 b indices · t.The number of memory addresses t needs to be chosen according to the desired eviction probability for the victim address with the given set. As a result, the expected number of memory accesses required to build an eviction set of t colliding addresses for EVICT+RELOAD is E(n accesses ) = n ways · 2 b indices · t.For an 8-way SCATTERCACHE with 2 11 lines per way, constructing an EVICT+RELOAD eviction set of 275 addresses (i.e., 99 % eviction probability) requires profiling with roughly 8 · 2 11 · 275 = 2 22 memory addresses. This is complicated further by the fact that any one set of addresses is essentially single-use, as the addresses will be cached in a non-colliding cache line with a probability of 1 − n ways −1 after only 1 access, where they cannot be used to detect victim accesses anymore until they themselves are evicted again. While this approach requires many more target accesses, it has the advantage of a shorter profiling phase.These two methods require different amounts of memory, profiling time and accesses to the target, but they can also be combined to tailor the attack to the target. For example, achieving a 99 % detection probability in a 2 MB Cache with 8 ways requires 35 target accesses and 9870 profiled addresses in 308 MB of memory for variant 1 if we use an eviction set for every probe step. While this significantly increases an attackers profiling effort, they may be able to use clustering techniques to prune the eviction set prior to performing an actual attack.Random noise, on the other hand, stems from arbitrary processes accessing the cache simultaneously or as they are scheduled in between. For instance, when building eviction sets an attacker can try to observe the same cache collision multiple times for a specific candidate address to be certain about its cache collision with the victim.Random noise distributes in SCATTERCACHE according to Equation 1 and hence quickly occupies large parts of the cache. Consequently, for a cache with n lines = 2 b indices lines per way and n noise lines being occupied by noise in each way, the probability of sampling random noise when probing an eviction set address is p(Noise) ≈ n ways − 1 n ways n noise n lines . However, in practice multiple cache ways are profiled simultaneously, which results in a high chance of finding a collision in any of the cache ways independent of the address index bits, i.e., the n ways indices for a certain memory address will very likely be scattered over the whole index range. As a consequence, a sparse, but strongly aligned memory access pattern such as in lat_mem_rd, which in a standard BIP LRU Rand SCv1 SCv2 Skewed set-associative caches only uses every 4 th cache index, gives high cache hit rates and low read latencies for larger memory ranges due to less cache conflicts. Specifically, instead of generating pseudo random indices from the cache line address, tag dependent permutations of the input index are calculated.The reason for preferring a permutation over pseudo random index generation is to counteract the effect of birthdaybound index collisions, as present in SCv1. The x86 Instruction-Set Architecture (ISA), for example, features the WBINVD instruction that can be used for that purpose.If desired, also more complex rekeying schemes, like waywise or cache-wide dynamic remapping [55], can be implemented. By encoding the SDID via a separate list indexed by PTE bits, all processes, as well as the OS, use the same SDID, i.e., the SDID stored as first element of the list (assuming all corresponding PTE bits are '0' by default). In particular, even if AES would only perform a single attacker-chosen memory access (instead of 160 to the T-tables alone, plus additional code and data accesses), which would be ideal for the attacker in the profiling during step 1, we would need to observe 33.5 million encryptions. Finding and exploiting addresses that are congruent in the cache should be as hard as possible (i.e., we want to "break" the direct link between the accessed physical address and the resulting cache set index for adversaries). In particular, we used the CPU model TimingSimpleCPU together with a cache architecture such as commonly used in ARM Cortex-A9 CPUs: the cache line size was chosen to be 32 bytes, the 4-way L1 data and instruction caches are each sized 32 kB, and the 8-way L2 cache is 512 kB large. Besides SCATTERCACHE in both variants (1) SCv1 and (2) SCv2 and standard set-associative caches with (3) LRU, (4) BIP, and (5) random replacement, we also evaluated (6) skewed associative caches [63] with random replacement as we expect them to have similar performance characteristics as SCv1 and SCv2.On the software side, we used the Poky Linux distribution from Yocto 2.5 (Sumo) with kernel version 4.14.67 after applying patches to run within gem5. Finally, there is always the option to develop custom IDF primitives [55] that demand even less resources.For comparison, in the BROOM chip [16], the SRAM macros in the 1 MB L2 cache already consume roughly 50 % of the 4.86 mm 2 chip area. Second, which exact n ways cache lines form a cache set in a n ways -way associative cache should not be fixed, but depend on the currently used key and security domain too. Performing n accesses independent accesses to this cache way increases the odds of eviction to a certain confidence level α.α = 1 − (1 − n −1lines ) n accesses Equivalently, to reach a certain confidence α in evicting the specific cache line, attackers have to perform E(n accesses ) = log(1 − α) log(1 − n −1 lines ) independent accesses to this cache way, which amounts to their attack complexity. A cache miss takes around 50 ns, hence, the full cache eviction will take at least 3.6 ms. Consequently, with 33.5 million tests required to generate the eviction set and a runtime of 4.1 ms per test, the total runtime to generate the eviction set is 38 hours.This number still only considers the theoretical setting of a completely noise-free and idle system. To overcome these issues, attackers may profile a system to construct eviction sets for specific memory addresses of the victim, i.e., they try to find a set of addresses that map to cache sets that partially overlap with the cache set corresponding to the victim address. However, in some individual benchmarks (e.g., qsort in small, jpeg in large), skewed cache architectures like SCAT-TERCACHE outmatch the fixed set appraoches.In summary, our evaluations with gem5 in full system simulation mode show that the performance of SCATTERCACHE, in terms of hit rate, is basically identical to contemporary fixed set-associative caches with random replacement policy. Only if the OS specifies SDIDs in the list, and sets the corresponding PTE bits to use a certain index, SCATTERCACHE provides its strong security properties.Implementation Example. However, as the cache component itself is shared, cache attacks such as PRIME+PROBE remain possible.As our analysis shows, SCATTERCACHE prevents a wide range of cache attacks that exploit the sharing of cache lines across security boundaries. Our security analysis reveals that even in the strongest possible attacker model (noise-free), the construction of a reliable eviction set for PRIME+PROBE in an 8-way SCATTERCACHE with 16384 lines requires observation of at least 33.5 million victim memory accesses as compared to fewer than 103 on commodity caches. These recent examples highlight the importance of finding practical approaches to thwart cache attacks.To cope with cache attacks, there has been much research on ways to identify information leaks in a software's memory access pattern, such as static code [19,20,41,45] and dynamic program analysis [34,71,74,77]. (1) By continuously removing (i.e., evicting or flushing) a cache line from the cache and measuring the access latency, an attacker can determine whether this cache line has been accessed by another process. Furthermore, by reusing the SDID of the OS, also shared memory between user space processes can easily be implemented without security impact.Interestingly, SCATTERCACHE fully preserves the capability of the OS to share read-only pages (i.e., libraries) also across security domains as no cache lines will be shared. In the actual design we propose for SCATTERCACHE, the indices (i.e., IDF output) do not address into one huge joint cache array. Hence, and as our security analysis shows, the construction of a reliable eviction set for PRIME+PROBE in an 8-way SCATTERCACHE with 16384 lines requires observation of at least 33.5 million victim memory accesses as compared to fewer than 103 on commodity caches, rendering these attacks impractical on real systems with noise.Additionally, SCATTERCACHE effectively prevents FLUSH+RELOAD-based cache attacks, e.g., on shared libraries, as well. This benchmark shows an interesting advantage of the skewed cache architectures over the fixedset architectures, independent of the replacement policy, of approximately 10 pp for the total hit rate. Detecting non-repeating events is made essentially impossible; to measure any access with confidence requires either the knowledge that the victim process repeats the same access pattern for long periods of time or control of the victim in a way that allows for repeated measurements. Even when the SDIDs are known, it prevents attackers from systematically constructing eviction sets for specific physical addresses and thwarts the calculation of addresses from collision information. Namely, on real systems cache attacks will suffer from both systematic and random noise, which reduces the effectiveness of profiling and the actual attack.Systematic noise is introduced, for example, by the victim as it executes longer code sequences in between the attacker's prime and probe steps. For example, the 8-way SCv1 SCATTERCACHE with 512 kB that is simulated in the following section, uses two parallel instances of QARMA-64 with 5 rounds as IDF. Finally, by selecting the cache size and the number of associative ways, 