At the core of Polisis is a privacy-centric language model, built with 130K privacy policies, and a novel hierarchy of neural-network classifiers that accounts for both high-level aspects and fine-grained details of privacy practices. Using an MTurk user study with 700 participants, we show that at least one of PriBot's top-3 answers is relevant to users for 89% of the test questions. The problem lies in stakeholders lacking the usable and scalable tools to deal with the breadth and depth of privacy policies.Several proposals have aimed at alternative methods and UIs for presenting privacy notices [8], including machine-readable formats [13], nutrition labels [14], privacy icons (recently recommended by the EU [15]), and short notices [16]. Polisis uses these classes to enable scalable, dynamic, and multi-dimensional queries on privacy policies, in a way not possible with prior approaches.At the core of Polisis is a novel hierarchy of neuralnetwork classifiers that involve 10 high-level and 122 fine-grained privacy classes for privacy-policy segments. We further seed these classifiers with a custom, privacy-specific language model that we generated using our corpus of more than 130,000 privacy policies from websites and mobile apps.Polisis provides the underlying intelligence for researchers and regulators to focus their efforts on merely designing a set of queries that power their applications. We demonstrate and evaluate the modularity and utility of Polisis with two robust applications that support structured and free-form querying of privacy policies.The structured querying application involves extracting short notices in the form of privacy icons from privacy policies. • We make Polisis publicly available by providing three web services demonstrating our applications: a service giving a visual overview of the different aspects of each privacy policy, a chatbot for answering user questions in real time, and a privacy-labels interface for privacy policies. Each of the resulting segments can be independently consumed by both the humans and programming interfaces.Machine Learning Layer (Sec. 4): In order to enable a multitude of applications to be built around Polisis, the ML layer is responsible for producing rich and fine-grained annotations of the data segments. The Data Layer requires no information other than the link to the privacy policy. Policy Extraction: Given the URL of a privacy policy, the segmenter employs Google Chrome in headless mode (without UI) to scrape the policy's webFurther useful privacy and security related materials can be found through Google's policies and principles pages, including: o Information about our technologies and principles, which includes, among other things, more information on • how Google uses cookies. For example, when the user expands a collapsible paragraph, a local JavaScript exposes an offline HTML snippet; no further downloading takes place.We confirmed this with the privacy policies of the top 200 global websites from Alexa.com. This section describes the components of Polisis' Machine Learning Layer in two stages: (1) an unsupervised stage, in which we build domain-specific word vectors (i.e., word embeddings) for privacy policies from unlabeled data, and (2) a supervised stage, in which we train a novel hierarchy of privacy-text classifiers, based on neural networks, that leverages the word vectors. For example, replacing the word "erase" by the word "delete" can significantly change the classification result if "delete" was not in the classifier's training set.Word embeddings solve this issue by extracting generic word vectors from a large corpus, in an unsupervised manner, and enabling their use in new classification problems (a technique termed Transfer Learning). This allows the text classifier to account for words outside the training set, as long as they are part of the large corpus used to train the word vectors.While general-purpose pre-trained embeddings, such as Word2vec [24] and GloVe [25] do exist, domainspecific embeddings result in better classification accuracy [26]. To account for the multiple granularity levels in the policies' text, we build a hierarchy of classifiers that are individually trained on handling specific parts of the problem.At the top level, a classifier predicts one or more highlevel categories of the input segment x (categories are the top-level, shaded boxes of Fig. 3). Each classifier produces the probabilities p(v j |x) for the values v j ∈ V (b) of a single attribute b. For example, given the attribute b=information type, the corresponding classifier outputs the probabilities for elements in V (b): {financial, location, user profile, health, demographics, cookies, contact information, generic personal information, unspecified, . . . }. • financial • health • contact • location • … Information Type • opt-in • opt-out • opt-out-link • … Choice Type • advertising • marketing • analytics • legal requirement • … Purpose • stated period • limited • indefinitely • unspecified • other Retention PeriodAn important consequence of this hierarchy is that interpreting the output of the attribute-level classifier depends on the categories' probabilities. Second, CNNs recognize when a certain set of tokens are a good indicator of the class, in a way that is invariant to their position within the input segment.We use a similar CNN architecture for classifiers on both levels as shown in Fig. 4. Next, the word vectors pass through a Convolutional layer, whose main role is applying a nonlinear function (a Rectified Linear Unit (ReLU)) over windows of k words. In addition to the precision, recall and F1 scores (macro-averaged per label 3 ), we also show the top-1 precision metric, representing the fraction of segments where the top predicted category label oc- curs in the annotators' ground-truth labels. A structured query is a combination of first-order logic predicates over the predicted privacy classes and the policy segments, such as: ∃s (s ∈ policy ∧ information type(s)=location ∧ purpose(s) = marketing ∧ user choice(s)=opt-out). The response to a query is the set of segments satisfying the predicates in the case of a structured query or matching the user's question in the case of a free-form query. A user can build on Polisis' output to automatically quantify the privacy utility of a certain policy.For example, such a privacy metric could be a combination of positive scores describing privacy-protecting features (e.g., policy containing a segment with the label: retention period: stated period ) and negative scores describing privacy-infringing features (e.g., policy containing a segment with the label: retention period: unlimited ). For example, with Polisis, policies can be ranked according to an automated ambiguity metric by using the information type attribute and differentiating between the label generic personal information and other labels specifying the type of data collected. ⎫ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎬ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎭Yellow: All segments in S have category: user-choice-control andchoice-type ∈ [opt-in, opt-out-link, opt-out-via-contacting-company] Green: S = φ Red: Otherwise Expected Collec- tionDiscloses whether it allows other companies like ad providers and analytics firms to track users on the site?Red: Yes, w/o choice to opt-out. The database powering these icons originated from TRUSTe (re-branded later as TrustArc), a privacy compliance company, which carried out the task of manually analyzing and labeling privacy policies.In what follows, we first establish the accuracy of Polisis' automatic assignment of privacy icons, using the Disconnect icons as a proof-of-concept. Hence, this represents our best effort to reproduce the icons, but these rules could easily be adapted as needed.To evaluate the efficacy of automatically selecting appropriate privacy icons, we compare the icons produced with Polisis' automatic labels to the icons produced based on the law students' annotations from the OPP-115 dataset [11]. In 2000, the FTC conducted a study on privacy seals, including those of TRUSTe, and found that, of the 27 sites with a privacy seal, approximately only half implemented, at least in part, all four of the fair information practice principles and that only 63% implemented Notice and Choice. To answer this question, we designed an experiment to compare the icons extracted by Polisis' automatic labels to the icons assigned by Disconnect on real policies.One obstacle we faced is that the Disconnect icons have been announced in June 2014 [41]; many privacy policies have likely been updated since then. We automatically assign the icons for these sites by passing their policy contents into Polisis and applying the rules in Table 2 on the generated automatic labels. This is because Polisis already predicts a comprehensive set of labels, covering a wide variety of rules.Furthermore, by automatically generating icons, we do not intend to push humans completely out of the loop, especially in situations where legal liability issues might arise. To support these new forms of services and the emerging need for automated customer support in this domain [43], we present PriBot as an intuitive and userfriendly method to communicate privacy information. This measure is derived from the entropy of the normalized probability distribution (p n ) of the predicted categories:cer(a) = 1 − (− ∑ (p n (c i |a) × ln(p n (c i |a))) / ln(|C |))(1) Akin to a dot product between two vectors, we compute the score s(q, a) as:s(q, a) = ∑ i (β i × min(β i , α i )) ∑ i β 2 i × cer(a)(2)As answers are typically longer than the question and involve a higher number of significant features, this score prioritizes the answers containing significant features that are also significant in the question. The first segment has a ranking score of 0.63:"Personal information will not be used or disclosed for purposes other than those for which it was collected, except with the consent of the individual or as required by law. . . "The second has a ranking score of 0: "All personal information collected by the TTC will be protected by using appropriate safeguards against loss, theft and unauthorized access, disclosure, copying, use or modification. Check out our Privacy Policy here: http://bit.ly/1tauyfh."As we wanted to evaluate the answers to these questions with a user study, our estimates of an adequatelysized study led us to randomly sample 120 tweets out of the tweets which both annotators labeled as valid questions. We henceforth refer to them as the Twitter QA Dataset. We compare PriBot's QA model against three baseline approaches that we developed: (1) Retrieval reflects the state-of-the-art in term-matching retrieval algorithms, (2) SemVec representing a single neural network classifier, and (3) Random as a control approach where questions are answered with random policy segments.Our first baseline, Retrieval, builds on the BM25 algorithm [48], which is the state-of-the-art in ranking models employing term-matching. This score depends on the presence of distinctive words that link a user's question to an answer.Our second baseline, SemVec employs a single classifier trained to distinguish among all the (mandatory) attribute-values (with > 20 annotations) from the OPP-115 dataset (81 classes in total). We obtain a micro-average precision of 0.56 (i.e., the classifier is, on average, predicting the right label across the 81 classes in 56% of the cases -compared to 3.6% precision for a random classifier). This result is not entirely surprising since we seeded Retrieval with a large corpus of 130K unsupervised policies, thus improving its performance on answers with matching terms.Policy Length We now assess the impact of the policy length on PriBot's accuracy. Also, it is not biased by the length of the policy. This indicates that PriBot is poised to perform better in a system where low values of k matter the most.Second, to further focus on the effect of policy length, we categorize the policy lengths (#segments) into short, medium, and high, based on the 33rd and the 66th percentiles (i.e., corresponding to #segments of 28 and 46). (3)) of incorrect answers predicted by PriBot (mean=0.37, variance=0.04) with the confidence of correct answers (mean=0.49, variance =0.05) shows that PriBot places lower confidence in the answers that turn out to be incorrect. The third variant is WP, with the subword mode disabled, thus satisfying neither property; we call it WPNoSub. Thus, we assess the utility of 360 answers to 120 questions per approach.Study Design: We used a between-subject design by constructing four surveys, each corresponding to a different evaluation condition. Additionally, we enforce a minimum duration of 15 seconds for the respondent to evaluate each QA pair, with no maximum duration enforced.We include an open-ended Cloze reading comprehension test [55]; we used the test to weed out the responses with a low score, indicating a poor reading skill. Across all respondents, the average age is 34 years (std=10.5), 62% are males, 38% are females, more than 82% are from North America, more than 87% have some level of college education, and more than 88% reported being employed. Following the trend of automation in legal advice [56], insurance claim resolution [57], and privacy policy presentation [58,16], third parties, such as automated legal services firms or regulators, can deploy Polisis as a solution for their users. It allows transitioning from labeling of policies with a few practices (e.g., the works by Zimmeck and Bellovin [16] and Sathyendra et al. [17]) to a much more fine-grained annotation (up to 10 high-level and 122 fine-grained classes), thus enabling a richer set of applications. Automated Question Answering: Our QA system, PriBot, is focused on non-factoid questions, which are usually complex and open-ended. We present the classification results at the category level for the Segment Classifier and at 15 selected attribute levels, using the hyperparameters of This research was partially funded by the Wisconsin Alumni Research Foundation and the US National Science Foundation under grant agreements CNS-1330596 and CNS-1646130.