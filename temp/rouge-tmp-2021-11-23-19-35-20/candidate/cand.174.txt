The malware compromised Windows computers accessible from the university's main network during off-hours, infecting computers that were powered on and propagated through the network overnight. Most current ransomware falls under one of two general categories: lockers/blockers, which focuses on disabling resources such as denying access to the device, and crypto, which encrypts data files on the infected device and withholds access to the decryption key. Our main contributions are: (1) analysis of the technological, productivity, and personal and social impact of ransomware attacks, including previously unaccounted secondary costs, (2) strategies for the development of a comprehensive cyber-response that include human factors and highlights the importance of communication, and (3) a refined Ransomware Process for Organizations diagram summarizing the additional contributing factors beyond individual infections. Several proactive or preventative techniques have recently been been proposed, such as UNVEIL [20], ShieldFS [8], CryptoDrop [34], and PayBreak [22] which operate at the operating system and filesystem levels to detect and correct suspicious activity, or FlashGuard [16], which uses the firmware-level recovery properties of solid state drives (SSD) to recover without explicit backups. Among others, some have worked on improving detection by devising new techniques for identifying obfuscated binaries [26] and for automated behavioral analysis to extract footprints [7] to identify ransomware and other malware.Organizational Considerations: If the malware is correctly implemented, recovery once systems have been infected is largely a matter of re-imaging and restoring from backups [35] since decryption is infeasible. Luo and Liao [23] recommend that prevention of ransomware threats in organizations should focus on awareness education for both upper management and employees.In a personal account of dealing with ransomware [3], Ali defined a "ransomware process" that starts with infection and the victim recognizing the problem through the loss of functionality/data. It reconstructed and retroactively assessed participants' thoughts, emotions and behaviours during the attack; their post-and pre-attack security practices; and their impressions on how the university managed the situation and how its emergency protocols for cyber-attacks can be improved. Codes were identified based on an inductive approach where the meaning of the codes are strongly linked to the data [30]. For example, Round-1 of coding of a question about prominent feelings during the attack generated 19 codes, which were later reduced to 15 after Round-2. In total, 31% (n = 47) of respondents said they experienced some type of data loss during the attack, which 25% (n = 37) are personal or work related: 16% (n = 24) were able to recover it through backups and 15% (n = 23) experienced permanent data loss. In the weeks following the attack, the level of concern dropped but respondents remained wary or unsure, pointing to the lingering effects of such incidents.Likelihood of compromise: We first asked about the likelihood of compromise for various services, data, and computers, on a scale of 1 = very unlikely to 5 = very likely. The two resources not managed by the university, mobile devices and personal computers, were considered least vulnerable, suggesting that respondents attributed the increased risk directly to the organization's resources as opposed to generally increasing their wariness.Prior work on users' computer security behaviour in an organizational context suggests that users' behaviour relating to secure choices is based on users' perception of the risk [4,28]. The implication of the perceived negligible risk to individual users suggests that large-scale cyber-attacks on organizations may not significantly change end-users' security behaviour in the long term. Confidence in security measures: Respondents' confidence in the university's ability to protect their data on the university network was somewhat confident before the attack (M = 3.8, SD = 1.1), doubtful during the attack (M = 2.5, SD = 1.2), and nearly neutral (M = 2.8, SD = 1.3) post-attack. Respondents' primary security practices prior to the attack were backing-up files (n = 56) manually or automatically (e.g., saving on a network drive backed up by the university daily), avoiding clicking on suspicious links or files (n = 36), using security software such as an antivirus (n = 34), using strong passwords (n = 26), and periodically changing passwords (n = 23). For context, we note that all university-managed computers run antivirus software, but some groups opt to manage their own systems, and individuals may also use their own computers on campus. Figure 4 shows the most common actions were disconnecting from the wireless network (n = 111), avoiding university services (n = 101), turning off Windows computers (n = 95), changing passwords (n = 94), disconnecting from the wired network (n = 78), and backing-up data (n = 56). The information did not help respondents understand what they should do (M = 2.6, SD = 1.3), or inform them of preventive steps they should take in the future (M = 2.3, SD = 1.2). Respondents reported in-person communication (n = 35), email (n = 27), phone calls (n = 41), and leaving voice messages (n = 19). To access official details, respondents checked the university's website (n = 81), read emails from computing services (n = 70), received updates from their departments (n = 67), and checked internal IT websites (n = 16). Within internal communication, respondents wanted clear details about the problem (n = 31), specific and consistent instructions about what to do (n = 21), more frequent updates (n = 15), and overall improvements to the emergency notification system (n = 15). Lastly, the information received from the the university was significantly more confusing to non-technical users than those with technical backgrounds (t(70) = âˆ’2.56, p < 0.05). The strong negative feelings described by our respondents suggest that the personal and social implications of such incidents are as significant and noteworthy as technological ones.Our respondents' risk perception before, during, and after the attack suggests that an attack on an organization increases users' perceptions of risk relating to the organization during the attack, yet it has marginal effects on the perceived risk of personal resources/computers. Our results suggest that most users are unlikely to change their computer security behaviour in the long-term because they believe cyber-security attacks on organizations are out of individual users' control.In the event of a cyber-attack, our respondents identified that communication is paramount to an effective cyber-attack response. A student added, "first, I needed the Internet to enter the database of the library to work on my paper. For example, infected computers were re-imaged and restored from the university's network backups, but "the stuff stored on the network. . . was about a month old. . . ", said a graduate student. Eventually, the colleague was able to recover through Dropbox.Participants also described losses of valuable productivity tools and resources, including "all desktop shortcuts" (S1), "400 bookmarks" (S11), and carefully drafted email templates: "I've been working on [my email templates] for two years", a staff said, "I had a reply for almost everything a student could ask. In other words, many interviewees re-called their emotional response as "severe in feelings"', but that the attack was "not severe in reality" because it did not affect their personal data or computers (U6). Users faced emotional costs at being isolated from their social support network and were additionally stressed by indirect financial costs.Another emotional impact was the fear of being penalized for missing deadlines. Interviewees shifted between talking about technological effects, to describing incidental effects like loss of productivity, then to talking about the emotional toll. Our data suggests that effects of cyber-attacks on users are complex, multifaceted, and difficult to measure.A sense of belonging to a community: The attack caused resentment and damaged users' relationship with the university. We noted many common misconceptions about security best practices, suggesting a need for more proactive cybersecurity training geared towards the university community and customized to the needs of different users.As an example, we highlight discussion about backing up data, which was particularly relevant to this incident. A student recounted: U4: On the first day when I walked into the library and there was a sign saying, "Don't use the WI-FI -Don't use the computers"; it didn't say why. I think if they had known it was because of malware they definitely wouldn't have wanted to use it. . . Maybe they didn't want people to panic or to worry, but if people are going to listen I think it's important to give them that knowledge so they understand why they don't want you to use it.These accounts highlight the necessity of informing people about the risks and vulnerabilities when instructing people what to do. Not having the information made people "very cautious", and they kept their computers shut-off longer than required (S10), adding to the loss of productivity.While informing users about cyber-attacks, interviewees identified that users should be provided with "a standard set of procedures" (S12) to follow, and actionable instructions about what they should do. A staff explained: S7: if you had a high reliability that if you paid you would get your stuff back, then it becomes simply a cost: the cost of paying to get it back directly versus the cost of the money and energy that has been spent in the interim trying to bring things back and to fix things. Yes, you are paying domestic terrorists; yes, you are giving in to it, but when you look at the amount of money that you spent on getting this research done -the amount of money you put into the research, the amount of money in grants that the university has worked hard to get, and that they've lost all that data and all of that research. Beyond these, we identified other costs that may not receive as much attention but that can be equally damaging.Emotional toll: Users experience stress and anxiety, and this may extend well beyond the immediate aftermath of an attack since it may take weeks (or longer) for users to catch up, recreate lost data, or deal with the consequences of the attack (e.g., delays in graduating due to lost research data, missed publication deadlines impacting promotion/tenure dossiers, increased workload as a result of lost templates). This was particularly apparent with students who rely on the university infrastructure as their primary internet access point, but also among staff unable to reach colleagues.Indirect financial costs: End-users may incur indirect financial costs, such as additional mobile data, costs relating to working off-campus (e.g., overage charges on home internet accounts), or purchasing additional resources (e.g., a new backup drive). There are obviously other factors at play when determining a cybersecurity response, and not all of these were lacking in this particular incident, but we believe that these insights could help devise a comprehensive plan.Share the plan: An explicit cyber-response plan should be shared with the broader community before an incident happens. Decades of literature on warnings and crisis communication for other types of emergencies, such as natural disasters, offer comprehensive strategies and assessments of best practices (e.g., [25]; much of their approaches may be transferable to cyber-attacks. They wanted to discuss their experience, be heard, and have their insight and suggestions taken into account.Practice user-centric security: A common response to attacks is to tighten the security policy, increasing the burden on end-users. Security policies that are too restrictive (e.g., disabling access to commonly used services), cumbersome (e.g., making it more difficult to accomplish tasks), or that make unrealistic demands on users (e.g., frequent password changes) will be bypassed by users, either intentionally so that they can accomplish their primary tasks [14,44] or accidentally by making errors. It may be tempting to dismiss this as 'the user's fault'; however, in many cases users had legitimate reasons for their decisions: the official storage options did not provide the functionality they needed, the functionality was awkward/difficult to use, or users misinterpreted the 'safest' options. Most participants recognized that attacks happen, but they expressed an important need for clear and timely communication within the organization about the incident, and a need for a voice in the recovery process.