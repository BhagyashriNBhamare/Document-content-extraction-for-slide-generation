Researchers have previously explored methods to restrict access to device sensors based on the state of the user interface that elicited the user input or based on the set of cooperating programs, but the former approach does not consider cooperating programs and the latter approach has been found to be too restrictive for many cases. Modern operating systems, such as Android OS, Apple iOS, Windows Phone OS, and Chrome OS, support a programming abstraction that enables programs to cooperate to perform user commands via input event delegations. Indeed, an emergent property of modern operating systems is that system services are relatively simple, provide a specific functionality, and often rely on the cooperation with other programs to perform tasks.For instance, modern operating systems now ship with voice-controlled personal assistants that may enlist apps and other system services to fulfill user requests, reaching for a new horizon in human-computer interaction.Unfortunately, system services are valuable targets for adversaries because they often have more permissions than normal apps. In this incident, whenever users asked their voice assistant "Siri, I need a ride", the assistant enlisted the ridesharing app to process the request, which then leveraged other system services to record the users' device screens, even while running in the background. Our insight to simplify the problem is that while DIFC methods govern information flows comprehensively to prevent the leakage of sensitive data available to programs, users instead want to prevent programs from abusing sensor access to obtain sensitive data in the first place.In addition, prior work has also investigated the use of machine learning classifiers to analyze the contextuality behind user decisions to grant access to sensors automatically [14,15]. Therefore, we firmly believe that additional effort is necessary in improving user decision making before the user decisions can be used to train a classifier.In this work, we propose the EnTrust authorization system to prevent malicious programs from exploiting cooperating system services to obtain unauthorized access to device sensors. At a high-level, our insight is to combine techniques that regulate IPC communications of programs of different privilege levels with techniques that enable users to be aware of the permissions associated with an input event and decide whether to grant such permissions for the identified flow context. In EnTrust, we construct delegation graphs that associate input events with their resulting sensor operations across IPCs to authorize operations in other programs.Second, multiple, concurrent input events and IPCs may create ambiguity in tracking delegations across processes that must be resolved to ensure correct enforcement. EnTrust leverages the insights that input events are relatively infrequent, processed much more quickly than users can generate distinct events, and are higher priority than other processing. In a field study involving 9 human subjects, we found that -in the worst scenarios seenprograms required no more than four additional manual authorizations from users, compared to the less secure first-use authorization approach; which is far below the threshold that is considered at risk for user annoyance and habituation [33]. • We propose EnTrust, an authorization system that generates delegation paths to enable users to authorize sensor operations, resulting from input events, and reuse such authorizations for repeated requests. • We implement the EnTrust prototype and test its effectiveness with a laboratory study, the users' authorization effort with a field study, and performance and memory overhead via benchmarks. Currently, there are over 250 voice assistants available to the public on Google Play with over 1 million installs, many by little known or unknown developers.Trojan Horse -Second, a program trusted by the user may delegate the processing of an input event to an untrusted program able to perform the requested task. However, the camera app may be a Trojan horse app that takes a picture, but also records a short audio via the microphone, and the user location via GPS (e.g., a spy app 2 installed by a jealous boyfriend stalking on his girlfriend). We performed an analysis of system services and applications distributed via the Android Open Source Project (AOSP), and found that 10 system programs out of a total of 69 (14%) use implicit intents.Man-In-The-Middle -Third, a request generated by a program trusted by the user may be intercepted by a malicious program, which can behave as a man-inthe-middle in serving the input event in the attempt to obtain access to unauthorized data (right side of Fig- ure 1). To achieve the security guarantee above, we require a mechanism that accurately tracks the delegations leading from input events to resulting sensor operations, as well as a mechanism to authorize sensor operations to collect sensitive data given input events and delegations.Regarding tracking delegations, a problem is that determining whether an IPC derives from an input event or receipt of a prior IPC depends on the data flows produced by the program implementations in general. Instead, we aim to explore solutions that ensure all sensor operations resulting from an input event are detected (i.e., we overapproximate flows) without heavyweight analysis or program modifications.Authorizing sensor operations to collect sensitive data, given an input event and one or more delegations, depends on determining the parties involved in the delegation as well as the user's intent when generating the event. Decentralized information flow control [23,24] (DIFC) prevents information leakage while allowing some privileged programs to make flexible security decisions to determine when to permit communications that are normally unauthorized, which has been applied to mobile systems [20,13]. To address this problem more directly, researchers have explored techniques that enable users to express the intent of their input events to authorize sensor operations, binding this intent to the context in which the input event was elicited, such as the graphical user interface (GUI) context [9,10,11]. We aim to explore methods for eliciting user authorizations for sensor operations using contextual information related to the tracking of input events and subsequent delegations.Further, researchers have explored learning methods to predict permissions for sensor operation based on prior user decisions [14,15]. Trust Model -We assume that the system (e.g., Linux kernel, operating system, system services, and device drivers) is booted securely, runs approved code from device vendors, and is free of malice; user-level programs (e.g., applications) are isolated from each other via the sandboxing mechanism using separated processes [35,36]; and, by default, user-level programs have no direct access to sensors due to the use of a Mandatory Access Control (MAC) policy [37,38] enforced from boot time. In the first three steps, EnTrust mediates and records input events, inter-process communication events (handoff events), and sensor operation requests, respectively, to construct a delegation graph connecting input events to their handoff events and sensor operation requests. First, for each input event received via a sensor s for a program p i , EnTrust creates an input event tuple e = (c, s, p i ,t 0 ), where c is the user interface context captured at the moment the input event occurred; s is the sensor through which the event was generated; p i is the program displaying its graphical user interface on the screen and receiving the input event e; and t 0 is the time of the input event (step 1 in Figure 2). EnTrust mediates handoff events by intercepting spawned intents and messages exchanged between programs [43] and models them as tuples h = (p i , p j ,t i ), where p i is the program delegating the input event, p j is the program receiving the event, and t i is the time the event delegation occurred (step 2 in Figure 2). Third, when the program p j generates a request r for an operation o targeting a sensor d, EnTrust models the request as a tuple r = (p j , o, d,t j ), where p j is the program requesting the sensor operation, o is the type of sensor operation requested, d is the destination sensor, and t j is the time the sensor operation request occurred (step 3 in Figure 2). If every input event results in an operation request before the user can even produce another distinct input event, then there will be only one input event (edge) e from a source sensor (node) s to program (node) p i , which received such input event. Thus, we propose to set a time limit for each input event, such that the difference between the time t 0 at which an input event e is generated and the time t j for any sensor operation request r -based on that input event -must be below that limit for the event to be processed. EnTrust, instead, presents the delegation path that led to the sensor operation, which includes the GUI context (c in the input event) and the handoffs and sensor operations. As a result, EnTrust ensures that all the programs receiving sensor data are clearly identified and reported in the authorization request presented to the user, along with the input event, handoff events, and the resulting sensor operation.To reduce users' authorization effort, EnTrust caches authorized delegation paths for reuse. First, if a new delegation path is identified for an input event that already has a cached delegation path, then EnTrust evicts the cached authorization and requires a new user authorization for the newly constructed delegation path, before associating it to such an input event and caching it. We used a background service, automatically relaunched at boot time, to log participants' responses to system messages and alerts, input events generated by participants while interacting with the testing programs, as well as system events and inter-process communications between programs. On the other hand, to assess the impact of priming, subjects in Group-FR-P and Group-EN-P were informed that attacks targeting sensors (e.g., camera, microphone, and GPS receiver) were possible during the interaction with programs involved in the experimental tasks, but without specifying what program performed the attacks or what attacks were performed.Experimental Procedures: For our experiment, we used a test assistant developed in our research lab called Smart Assistant, which provides basic virtual assistant functionality, such as voice search, message composition, and note keeping. Furthermore, this preliminary phase enabled capturing how malicious programs may leverage pre-authorized operations in the first-use approach to then perform operations not expected by the users; a malicious behavior that is instead prevented by EnTrust via the construction of perdelegation authorizations. During the attack phase, instead, the participants performed the three tasks described in Table 1. Our focus was to study the effectiveness of EnTrust in reducing the success rate of attacks when compared to the first-use approach. This explains the lower percentage of subjects prompted, with an authorization request, in the first-use groups.TASK A : The analysis of subjects' responses revealed that 9 subjects from Group-FR-U and 8 subjects from Group-FR-P interacted with Smart Assistant during the preliminary phase, or during another task, to "take a screenshot" and granted the app permission to capture their screen; thus, they were not prompted once again with an authorization message during this task, as per default in first-use permissions. TASK B : The analysis of subjects' responses revealed that 9 subjects from Group-FR-U and 7 subjects from Group-FR-P interacted with Basic Camera to take a picture or record a video, either during the preliminary phase or during another task, and authorized it to capture pictures, audio, and access the device's location. At the end of the experiment, among all the subjects, when asked why they authorized access to the GPS receiver, the majority said that they expected a camera app to access location to create geo-tag metadata when taking a picture. In contrast, the subjects who denied access stated not feeling comfortable sharing their location when taking a selfie.TASK C : The analysis of subjects' responses revealed that 8 subjects from Group-FR-U and 8 subjects from Group-FR-P interacted with Basic Camera, either during the preliminary phase or during another task, and authorized the app to capture pictures. EnTrust performed slightly better than first-use authorization in terms of explicit authorizations (explicit allows in Table 1); which suggests that the additional information provided by EnTrust in authorization messages (i.e., programs' name and identity mark as well as delegation information, as shown in Figure 6) may be helpful to users in avoiding unexpected program behaviors. We also measured the number of authorizations handled by EnTrust via the cache mechanism that, transparently to users, granted authorized operations.Experimental Procedures: Participants met with one of our researchers to set up the loaner device, an LG Nexus 5X smartphone running a modified version of the Android OS integrating the EnTrust authorization framework. The eviction instead required a base overhead of 57 µs with an additional 2.5 µs for each 512-byte increment.Delegation Graph Enforcement -Our third micro-benchmark was designed to compare the unmodified version of the Android Nougat build for control measurement with a modified build integrating our EnTrust features for the delegation graph enforcement during authorization. The time window for the construction of each delegation path was set to 150 ms. We generated 15,000 input events with gaps randomly selected in the range [140-1,500] 12 ms. The time window and the gaps were selected based on data reported in Appendix B. The results indicated a total of 256 delayed events (1.15% of the total events), with a maximum recorded delay of 9 ms. Thus, the performance overhead introduced is negligible.Memory Requirement -We also recorded the average cache size required by EnTrust to store both event mappings and authorized delegation graphs to be about 5.5 megabytes, for up to 1,000 programs. Evaluating mechanisms that prevent abuse of sensitive sensors while trading off privacy and usability is chal-lenging. However, to improve the effectiveness of such mechanisms, further laboratory studies will be necessary to examine how to present audit results (or other new approaches) to help users to investigate and resolve mistaken authorizations.Study Scenarios -In this project, we focused on whether users would be able to deny attack scenarios effectively. Our field study (Section 6.3) shows that our approach is comparable to first-use in terms of the number of times users are prompted, and the number of explicit authorizations from users is far below the 8 additional explicit authorizations used in prior work, which are considered likely not to introduce significant risk of habituation or annoyance [33]. EnTrust demonstrates that it is possible to prevent programs from abusing the collaborative model -in the attempt to perform delegated confused deputy, delegated Trojan horse, or delegated man-in-the-middle attacks -by binding together, input event, handoff events, and sensor operation requests made by programs, and by requiring an explicit user authorization for the constructed delegation path. sAppendix A -Study Demographics: In total, from the 69 recruited subjects that completed our study, 34 (49%) were female; 36 (52%) were in the 18-25 years old range, 27 (39%) in the 26-50 range, and 6 (9%) were in above the 51 range; 33 (48%) were students from our Institution, 9 of them (13%) were undergraduate and 24 (35%) were graduate students, 2 (3%) were Computer Science Majors; 11 (16%) worked in Public Administration, 9 (13%) worked in Hospitality, 6 (9%) in Human Services, 6 (9%) in Manufacturing, and 4 (6%) worked in Science or Engineering. EnTrust retrieves programs' identity by accessing the AndroidManifest.xml, which must contain a unique name and a unique identity mark (e.g., icon) for the program package. EnTrust verifies programs' identity via the crypto-checksum 16 of the program's binary signed with the developer's private key and verifiable with the developer's public key [46], similarly to what proposed in prior work [47,11]. 17 EnTrust authenticates input events by leveraging sixteen mediation hooks placed inside the stock Android Input Manager and six mediation hooks placed inside the System Voice Actions module.Appendix E -Handoff Event Mediation: Programs communicate with each other via InterComponent Communication (ICC) that, in Android, is implemented as part of the Binder IPC mechanisms. For instance, MacOS and iOS adopt the Segue mechanism, while Chrome OS supports Web Intents, thus EnTrust can be also implemented for other modern systems supporting the cooperating program abstraction.Appendix F -Sensor Operation Mediation: Android uses the Hardware Abstraction Layer (HAL) interface to allow only system services and privileged processes to access system sensors indirectly via a welldefined API exposed by the kernel. From the measurements, we observed: (1) the minimum gap between subsequent input events targeting the same program (211 ms) is an order of magnitude larger than the maximum lag required by the program to serve each incoming event (22 ms); and (2) the minimum gap (171 ms) between subsequent handoff events targeting the same program is an order of magnitude larger than the maximum lag required by the program to serve incoming requests (15 ms). For instance, MacOS and iOS adopt the Segue mechanism, while Chrome OS supports Web Intents, thus EnTrust can be also implemented for other modern systems supporting the cooperating program abstraction.Appendix F -Sensor Operation Mediation: Android uses the Hardware Abstraction Layer (HAL) interface to allow only system services and privileged processes to access system sensors indirectly via a welldefined API exposed by the kernel.