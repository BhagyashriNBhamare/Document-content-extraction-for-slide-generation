However, due to the challenges of widely deployed exploit mitigations, pitfalls along an exploit path, and ill-suited primitives, it is difficult to even manually craft an exploit with a control-flow hijacking primitive for an off-the-shelf modern Linux kernel. However, in order to generate working exploit for a controlflow hijacking primitive, there remains to be the following three challenges in the process of exploit primitive evaluation which limits the capability of automatic exploit generation techniques to target a complex real-world system such as the Linux kernel.Challenge 1, exploit mitigation. As a consequence, many kernel exploit techniques are no longer effective [36] [61] [41] [39] [77], despite the fact that heavier enforcement such as control-flow integrity (CFI) [2] [16] [79] [78] is still not widely-adopted by major Linux releases perhaps due to performance concerns.Challenge 2, exploit path pitfall. Although some strong primitives have been proven exploitable and even Turing complete [35], there is still a gap between ill-suited exploit primitive and the requirement of mounting a certain exploit technique.Considering the three challenges, it could be quite difficult to even manually craft an exploit with a control flow hijack primitive. To highlight the effectiveness of KEPLER, we compare KEPLER with existing exploit hardening/generation tools (e.g., Q [60], fuze [75]) and KEPLER outperforms all of them in terms of generating effective kernel exploits under modern mitigation settings in Linux kernel.This research work makes the following contribution:• Kernel single-shot exploitation. In the context of symbolic analysis, a control-flow hijacking primitive is usually identified by applying a heuristic which queries the backend constraint solver to check whether the number of possible control flow jump target is beyond a threshold when the control flow jump target contains symbolic bytes. To efficiently explore state space for exploit primitives in Linux kernel, Wu et al. propose an automatic technique that utilizes undercontext fuzzing along with partial symbolic execution to explore CFHP and memory write primitive for UAF bugs [75]. Our work addresses the problem of ROP bootstrapping without stack pivoting gadget and is orthogonal to automatic ROP chaining techniques [33] [60] [66] [24] [57] because we do not tackle the problem of ROP payload construction.With the facilitation of forward and backward taint analysis, Mothe et al. devise a technical approach to craft working exploits for simple vulnerabilities in user-mode applications [48]. To facilitate primitive evaluation of kernel Use-After-Free exploitation, Xu et al. propose two memory collision mechanisms [77] to unleash CFHPs.Recently, some research works take CFI into consideration for primitive evaluation [29] [8] [59] [23] [31] [32] [35]. First, without assuming a perfect ex-ploit primitive (e.g., unlimited number of invocations of an arbitrary memory write primitive), we can faciliate exploit primitive evaluation for those usually ignored exploit primitive (e.g., ill-suited primitives and primitive that can only be triggered once). However, with a kernel patch applied, these physmap pages are no longer executable.To enforce CFI policy for the kernel, several kernel CFI solutions [16] [70] [26] have been proposed, however, these mitigations are not broadly adopted by major Linux release version such as CentOS, Ubuntu and Debian.Data-only kernel exploit techniques directly use a memory write primitive to modify sensitive kernel data objects such as process credentials, page tables and virtual dynamic shared object (vdso) [36]. We assume the CFHP is already identified with the PoC through either manual analysis or dynamic analysis such as symbolic tracing, thus finding exploit primitives is orthogonal to our work and we can focus on evaluating the CFHP. Under the threat model, the content in arbitrary memory address such as the stack canary value of arbitrary kernel thread usually remains secret because the coarse kernel memory layout information does not reveal the stack canary value of a kernel stack. We illustrate the challenges in evaluating a CFHP on x86-64 with CVE-2017-8890 [50], a recent vulnerability in the Linux kernel.1 void ip_mc_drop_socket(struct sock *sk){ 2 struct inet_sock *inet = inet_sk(sk); 3 struct ip_mc_socklist *iml; 4 // inet->mc_list is a dangling pointer 5 while ((iml = inet->mc_list) ! Function rcu_do_batch handles the previously queued callback when the CPU gets a chance to process the rcu callback list, thus triggers another UAF access to the ip_mc_socklist object in rcu_reclaim(). To be specific, by manipulating the value in iml->rcu_head through a proper heap spray, a security analyst can get a CFHP later in rcu_reclaim() because function kfree_rcu() (line 9) is designed to queue a rcu callback denoted by iml->rcu_head. With the write-protection over sensitive data such as process credential and page table , it is not possible to direct overwrite these data to escalate priviledge by converting the CFHP into a memory write primitive.A security analyst may think of the "cr4-flipping" attack which usually requires two CFHPs: one for flipping the cr4 register and the other to launch ret2user/pivot2usr. As is shown in Figure 1, after using the CFHP in rcu_reclaim to disable SMAP protection by invoking the function native_write_cr4() to zero the corresponding bits in cr4 register, an attacker encounters an unexpected termination: in previous execution, the loop from line 5 to line 10 in Table 1b queues another rcu callback denoted by head' (iml->next_rcu ->rcu) which is not under our control and causes a kernel panic.This kernel panic attributes to an invalid memory access. To get multiple CFHPs for a UAF vulnerability, an attacker may need to do multiple rounds of heap spraying and trigger a vulnerability multiple times, which could dramastically decrease the success ratio of the entire exploitation.Even if two control-flow hijack primitive is available to the attacker, it could still be very difficult for him to bypass the mitigation combination of SMAP as well as virtualizationbased hypervisor, because the attempt to modify cr4 register (in order to turn off SMAP and pivot kernel stack to userspace) could be easily prevented. Given a kernel state snapshot representing the CFHP, KEPLER enhances its power to construct a kernel stack-overflow by symbolically stitching several types of candidate gadget identified by static analysis on the kernel binary image.As is mentioned before, our basic idea is to bootstrap a traditional ROP attack with a CFHP in Linux kernel. Fig- ure 4 illustates a practice of reusing I/O functions to construct kernel stack overflow by first leaking kernel stack canary with copy_to_user and then smashing kernel stack with copy_from_user.Second, "single-shot" exploitation can be achieved through stitching various kernel function gadgets. We present stack-smashing gadgets which relies on functions that serve as data channel between user-space and kernel- The kernel code fragment of an stack-smashing gadget that could smash kernel stack with carefully crafted payload.space. Once the copy is finished, instruction CLAC is executed to re-enable SMAP.As is specified in Linux kernel implementation, the function copy_from_user() takes as input three arguments -dst, src and length -which indicate the destination, source and length of the data that need to be copied from the user to kernel space.From the perspective of an attacker, a kernel stack overflow could be caused if he lets the CFHP jump to the site right before the invocation of copy_from_user (line 2 in Table 2b) and the machine state satisfies the following three requirements:  parameter dst (e.g., rdi) points to current kernel stack,  parameter src (e.g., rsi) points to any user-space address so that its content is controllable by an attacker,  parameter length (e.g., rdx) is greater than the size of current stack frame to cause a kernel stack overflow.An interesting observation is that most (91% in Linux 4.15) invocations of this function set destination dst to address of a variable on kernel stack and thus will copy user data into a kernel stack. Among all these invocation sites, more than 99% contain the fault handling implementation.The insight of prioritizing short return path after stack smash is to prevent un-expected kernel panic as well as avoid the complexity of resolving extra data dependency in an errorprone and long normal return path of the function containing tens of basic blocks.To take a short return path, copy_from_user must return a non-zero value as is shown in Table 2a. When the function attempts to copy the last byte, it failes to access the content at p2 and triggers a page fault because the page p2 is not mapped into the memory. Then content of current stack frame is copied to user-space by copy_to_user, a page fault is triggered to force non-zero return value of copy_to_user, as result short return path is taken in y. Before the function returns, stack canary sanity check is performed z, because the auxiliary function put a valid stack canary in current stack frame, the canary check is successfully passed and return to the caller of auxiliary function. Assume we have a CFHP with 1 void regcache_mark_dirty(struct regmap *map) { 2 map->lock(map->lock_arg); // the 1st control-flow hijack 3 map->cache_dirty = true; 4 map->no_sync_defaults = true; 5 map->unlock(map->lock_arg); // the 2nd control-flow hijack 6 } Figure 7: Memory layout after using physmap spray [39] to allocate physmap pages with data under our control.control over rdi, we can get an augmented CFHP which controls rdi, rsi, and rdx at the same time at line 3 in Table 3. We use bridging gadget -a family of kernel functions with multiple controllable indirect calls -to spawns two CFHPs and combine canary leak and stack smash into a single shot.For example, function regcache_mark_dirty shown in Table 4 is such a bridging gadget which contains two indirect calls, map->lock in line 2 and map->unlock in line 5. As is shown in Figure 7, assume the data carefully crafted in the spots of A and B represent the address of the auxiliary gadget together with a disclosure gadget responsible for leaking stack canary as well as the entry address of the gadget pertaining to stack smashing respectively. While previous sections have discussed the basic building blocks to perform an "single-shot" exploitation, the exploitation chain could not be determined once and for all with static analysis because uniqueness of each CFHP and different gadget combinations bring about the variation of the exploitation context. For example, the consecutive exploitation gadgets might no longer obtain the control over related registers with a different initial CFHP.To address this problem, we developed our tool to assess each of the gadget chains potentially useful for kernel exploitation. In this way, KEPLER could terminate the memory-intensive process every time the constraint solving is completed and thus free the memory for consecutive computation.As is described in Section 6.1, the payload smashed to the stack contains the stack canary disclosed as well as a sequence of addresses indicating an ROP chain that performs actual exploitation. In this work, we evaluate our tool KEPLER by using this single Linux kernel, and demonstrate the effectiveness of "single-shot" exploitation by launching exploitations against the inserted vulnerabilities.As is summarized in Table 5, the vulnerabilities inserted cover various types such as Use-After-Free and Out-OfBound (OOB) read/write etc. To some extent, this implies existing exploitation approaches highly rely upon the quality of the target vulnerability and corresponding CFHP, whereas our approach KEPLER could utilize prevalent kernel function and gadgets to explore exploitable machine states and thus escalate the exploitability for a CFHP. Given that some commercial security products pinpoint kernel exploita-tion by using the patterns of exploits, the ability to diversify exploitation has the potential to assist an adversary to bypass the detection of commercial security products.From Table 5, we also observe that, for different vulnerabilities, KEPLER generates different number of gadget chains useful for exploitation. This can be attributed to the following fact. As we can observe, KEPLER could quickly output an useful exploitation chain in less than about 50 wall-clock minutes (and the corresponding CPU-core time is roughly 1400 minutes given the prototype system uses 28 concurrent workers). To defend against the exploit chain mentioned above, one straightforward reaction is to eliminate the gadgets that must be used in kernel exploitation. In comparison with previous automatic exploit generation and exploit hardening techniques, we show that KEPLER outperforms other exploit techniques and is able to generate thousands of exploit chains for a control-flow hijacking primitive in Linux kernel despite the challenges of widely-deployed security mitigations, exploit path pitfalls and ill-suited exploit primitives. We release the source code of KEPLER, a kernel embeded with vulnerabilities and generated gadget chains for research and education purposes [76].