The median is a robust statistical method used to represent a "typical" value from a data set, e.g., insurance companies use the median life expectancy to adjust insurance premiums.Previous work on DP median computation either require a large number of users to be accurate [27,34,63], rely on a trusted third party [51,58], or cannot scale to large universe or data set sizes [14,30,59]. In summary, our contribution is a protocol for securely computing the differentially private median• with high accuracy even for small data sets (few users) and large universe sizes (see Section 3.4 for our theoretical errors bounds, Appendix F for a comparison of that bound to related work, and Section 5.3 for empirical comparison to related work),• that is efficient (practical running time for millions of users) and scalable (sublinear in the data universe size) (Sections 4, 5),• secure in the semi-honest model with an extension to the malicious model (Section 4.6) and outputs the differentially private median according to the exponential mechanism by McSherry and Talwar [52],• evaluated using an implementation in the SCALE-MAMBA framework [6], for 1 million users using 3 semi-honest computation parties with a running time of seconds in a LAN, and 3 minutes in a WAN with 100 ms network delay, 100 Mbits/s bandwidth (Section 5). In the following, we introduce preliminaries for differential privacy and secure multi-party computation.We consider a set of input parties P = {P 1 , . . . , P n }, where party P i holds a datum d i , and D denotes their combined data set. A mechanism M satisfies ε-differential privacy, where ε ≥ 0, if for all neighboring data sets D D , i.e., data sets differing in a single entry, and all sets S ⊆ Range(M )Pr[M (D) ∈ S] ≤ exp(ε) · Pr M (D ) ∈ S ,where Range(M ) denotes the set of all possible outputs of mechanism M . Given a function f : U n → R with sensitivity max ∀DD | f (D) − f (D )|, privacyparameter ε, and a database D, the Laplace mechanism releases f (D) + r, where r is drawn from the Laplace distribution (centered at 0) with density ε2∆ f e −ε ∆ f . The mechanism is exponentially more likely to select "good" results where "good" is quantified via a utility function u(D, r) which takes as input a database D ∈ U n , and a potential output r ∈ R from a fixed set of arbitrary outputs R . Trusted Serverd 1 d n M ( f (d 1 , . . . , d n )) (a) Central Model C 1 . . . Untrusted Serverr 1 =M (d 1 ) r n =M (d n ) f (r 1 , . . . , r n ) (b) Local Model C 1 . . . Shuffler Untrusted Serverr 1 =M (d 1 ) r n =M (d n ) r π(1) . . . r π(n) f r π(1) , . . . , r π(n)(c) Shuffle Model with permutation π Figure 1: Models for DP mechanism M . Recently, an intermediate shuffle model ( Figure 1c) was introduced [15,18]: A trusted party is added between client and server in the local model, the shuffler, who does not collude with anyone.The shuffler permutes and forwards the randomized client values. Secure multi-party computation (MPC) [36] allows a set of three or more parties P = {P 1 , . . . , P n }, where party P i holds sensitive input d i , to jointly compute a function y = f (d 1 , . . . , d n ) while protecting their inputs. (i) the running time complexity is linear in the size of the data universe, |U|, as selection probabilities for all possible outputs in U are computed,(ii) the general mechanism is too inefficient for general secure computation as selection probability computation requires |U| exponentiations over floating-point numbers.We solve these challenges by (i) recursively dividing the data universe into subranges to achieve sublinear running time in |U|, and (ii) focusing on utility functions which allow efficient selection probability computation. Each subrange selection increases the overall privacy loss ε, and we enable users to select a trade-off between running time, privacy loss and accuracy by presenting three protocols to compute unnormalized selection probabilities, which we call weights, w.r.t. ε:• Weights ln(2) fixes ε = ln(2) to compute exp(εy) as 2 y ,• Weights ln(2)/2 d allows ε = ln(2) 2 d for some integer d > 0, • Weights * supports arbitrary ε.On a high-level, we have three phases in each iteration:1. To combine local utility scores per party into a global score for all, we require utility functions to be decomposable: Convex optimization: find x that minimizes ∑ n i=1 l(x, d i ) with convex loss function l defined over D; e.g., empirical risk minimization in machine learning [10,63], and integer partitions (password frequency lists) [16] − ∑ n i=1 l(x, d i )Unlimited supply auction: find price x maximizing revenue x ∑ i b i (x), where bidder demand curve b i indicates how many goods bidder i will buy at price x; e.g., digital goods [52] x ∑ i b i (x)Frequency: select x based on its frequency in D; e.g., mode [48] ∑ n i=1 1 x=d iRank-based statistics: select x based on its rank in sorted D; e.g., k th -ranked element [48] See Section 3.2 Table 1: Applications with decomposable utility functions.Definition 4 (Decomposability). We call a function u : (U n × R ) → R decomposable w.r.t. function u : (U n × R ) → R if u(D, x) = ∑ n i=1 u (d i , x) for x ∈ R and D = {d 1 , . . . , d n }. The additional communication stemming from our secure median computation can be shifted to few parties who are not network resource constrained, e.g., mobile phones on WiFi networks.To be sublinear in the size of the universe we consider decomposability w.r.t. ranges instead of elements: parties only report one utility score per range, instead of one score per element. The median utility function u µ : (U n ×U) → Z gives a utility score for a rangeR = [r l , r u ) where r l , r u ∈ U w.r.t. D ∈ U n as u µ (D, R) = − min rank D (r l )≤ j≤rank D (r u ) j − n 2 . As a worst-case example, consider a data set with universe U = {0, 1, . . . , 10 9 } containing only an equal number of duplicates for 0 and 10 9 . Note that |R | is k if we select among k subranges or |U| if we output elements directly.For our accuracy proofs we structure the universe as a tree: we set U as the root of a tree of height log b |U|, for some base b, with k child nodes per parent. Thus, we use a heuristic in our evaluation: larger subranges, that hold exponentially more elements, receive exponentially smaller portions ε j of the privacy budget (see Section 5 for details). Output / FunctionalityRec(a) a, reconstructed from a Add(a, b) a + b Sub(a, b) a − b Mul(a, b) a · b Mod2m(a, b) a mod 2 b ,where b is public Trunc(a, b) a/2 b , where b is public Rand(b) r with uniform random b-bit value r Choose(a, b, c) a if bit c = 1 otherwise b LT(a, b) 1 if a < b else 0 Int2FL(a)converts integer a to secret shared float In the following, we describe details of our protocol EM * , which implements ideal functionality F EM * , analyse its running time and security. Output: Differentially private median of D.1: r l , r u ← 0, |U| 2: for j ← 1 to s do 3:r # ← max{1, r u −r l k } 4:k ← min{k, r u − r l } Define array W of size k if ε j = ln(2)/2 d for some integer d then 7: sively divided into k subranges until the last subrange, after at most log k |U| iterations, contains only one element: the differentially private median 7 . Formally, one draws r ∈ (0, 1] at uniform random and outputs the first R j ∈ R with ∑W FL ← Weights ln(2)/2 d (r l , r u , r # , k, n, d) //j−1 i=1 Pr[EM ε u (D, R ) = R i ] ≤ r < ∑ j i=1 Pr[EM ε u (D, R ) = R i ]. We implement Weights ln(2) as a special case of our approach Weights ln(2)/2 d in Algorithm 3 (with d = 0 in line 16). The complexity of the integer-based solution is linear in the bit-length of u, however, this is not sufficient for us: Recall, that the utility is based on ranks, i.e., counts of data elements, thus u can be roughly as large as the size of the data. We use the representation of floating point numbers as a 4-tuple to construct a new float to represent 2 u as (2, u, 0, 0), where sign and zero bit are unset, as 2 u cannot be negative or zero. To illustrate our approach, we implement Weights ln(2)/2 d in Algorithm 3 for d = 1, and describe the approach for any integer d: Recall, our goal is to compute the weight exp(εu) with efficient MPC protocols. Output: List of weights.1: Define arrays R of size k + 1, W of size k; initialize R with zeros 2: for p ← 1 to m do //Get input from each party for j ← 1 to k do //Divide range into k subranges 4:i l ← r l + ( j − 1) · r # 5: R[ j] ← IntAdd(R[ j], rank D p (U[i l ])) 6:end for 7:R[k + 1] ← IntAdd(R[k + 1], rank D p (U[r u ])) 8: end for 9: for j ← 1 to k do 10: u u ← IntSub(R[ j + 1], n 2 )11:u l ← IntSub( n 2 , R[ j]) 12: c u ← IntLT(R[ j + 1], n 2 )13:c l ← IntLT( n 2 , R[ j]) 14: t ← IntChoose(u u , 0, c u ) 15:u ← IntChoose(u l , t, c l )16: if d = 0 then 17: W [ j] FL ← (2, u, 0, 0) //float 2 u 18:else 19:t ← IntTrunc(u, d) 20:e FL ← (2, t, 0, 0) c ← IntMod2m(u, d)22: s FL ← FLChoose(1 FL , √ 2 FL , c) 23: W [ j] FL ← FLMul(e FL , We implement Weights * in Algorithm 4. However, log n rounds suffice to combine the inputs by building a tree of pairwise multiplications with 2 i multiplications at level i [5]. We support universe sizes of more than 5 orders of magnitude larger with comparable running times: They compute weights per elements and require around 42 seconds for |U| = 5, whereas our protocol EM * using Weights ln(2) / Weights ln(2)/2 d / Weights * runs in approx. 11 / 33 / 64 seconds for |U| = 10 5 . The choice of weight computation enables a trade-off between faster running times, i.e., Weights ln(2) with fixed ε, and smaller privacy loss ε, i.e, Weights * , with Weights ln(2)/2 d positioned in the middle (faster running time than Weights * with smaller ε compared to Weights ln (2) ). Larger k leads to larger running times, as the number of costly secure computations depends on the number of ranges times the number of selection steps (k · log k |U|), which increases proportionally to k. However, smaller values for k require more selection steps (log k |U|), which lead to an increase in the privacy budget. Therefore, we empirically evaluated the different approaches closest to ours, i.e., supporting more than 2 parties, on real-world data sets [42,64,67] as well as the normal distribution in Figure 6 8 for 100 averaged runs with 95%-confidence intervals. The 8 "Small" data is the most challenging regime for DP [15,56], thus, we use small data sets to better illustrate the accuracy differences. Nissim et al. [58] (SS in Figure 6) compute instance-specific additive noise, requiring full data access, and achieve good accuracy, however, the exponential mechanism can provide better accuracy for low ε. To minimize the error from clipping range [c l , c u ], we choose c l = 0.49 thpercentile, c u = 0.51 th -percentile, i.e., we presume to already know a tight range for the actual median. Next, we describe related work for secure computation of the exponential mechanism, DP median and decomposability.Secure Exponential Mechanism: Alhadidi et al.[4] present a secure 2-party protocol for the exponential mechanism for max utility functions. Pettai and Laud [59] compute the DP median as noisy average of 100 values closest to the median within a clipping range, which limits accuracy, especially, if the data contains outliers or large gaps (see Section 5.3). For the DP median, the exponential mechanism provides better accuracy for low epsilon and can be efficiently computed, whereas computation of smooth sensitivity requires full data access in clear or the error increases (see Section 2.1.2). For the median, the exponential mechanism provides the best utility vs. privacy trade-off for low ε in our evaluations of related work in the central model.We optimize our protocol for decomposable functions (allowing efficient MPC on distributed data), and use efficient alternatives to exponentiations for floating-point numbers. The following definition from [30] fits our setting, where VIEW p Π (D) denotes the view of party p during the execution of protocol Π on input D, including all exchanged messages and internal state, and λ is a security parameter:Definition 7 (Distributed Differential Privacy). A randomized protocol Π implemented among m computation parties P = {P 1 , . . . , P m }, achieves distributed differential privacy w.r.t. a coalition C ⊂ P of semi-honest computation parties of size t, if the following condition holds: for any neighbors D, D and any possible set S of views for protocol Π,Pr VIEW C Π (D) ∈ S ≤ exp(ε)·Pr VIEW C Π (D ) ∈ S +negl(λ). Table 3 lists the complexities for MPC protocols typically measured in the number of rounds and interactive operations, where rounds describes the count of sequential interactive operations, and interactive operations (e.g., reconstruct sharing, multiplications) require each party to send messages to all other parties. Note that Choose(a, b, c) is implemented with one multiplication and two additions (b + (a − b) · c), and that IntRand uses correlated randomness already exchanged in the offline phase (hence zero interaction and rounds).