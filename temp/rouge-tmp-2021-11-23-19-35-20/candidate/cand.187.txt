In fact, recently the Fuzzing Ex Machina (FExM) [49] project managed to reduce the overhead of running fuzzers to a degree where they managed to fuzz the top 500 packages from the Arch Linux User Repository with no manual effort in seed selection or similar issues. It stands to reason that this kind of indiscriminate, dragnet-style searching for software bugs will become more prevalent in the future.While the developers of a software system should typically thoroughly fuzz test every type of software, in practice they may want to maintain an asymmetric cost advantage. Our evaluation with several different programs shows that with a negligible performance overhead, ANTIFUZZ hardens a target binary executable such that none of the tested fuzzers are able to find any bugs.To foster research on this topic, we release our implementation and the data sets used as part of the evaluation at https://github.com/RUB-SysSec/antifuzz. Two approaches were commonly applied: mutational fuzzing and generational fuzzing.Mutational fuzzers require a good corpus of inputs to mutate. The second approach is generational fuzzing: fuzzers which employ this technique need a formal specification to define the input format. It effectively relies on pure chance for finding crashing inputs, while a coverage-guided fuzzer could mutate the same input file iteratively to increase the code coverage and thus get closer to new regions where a crash could happen. These fuzzers use multiple ways to obtain coverage feedback:Static Instrumentation: One of the fastest methods for obtaining code coverage is static compile time coverage (widely used by tools such as AFL, ANGORA, LIBFUZZER, and HONGGFUZZ). From a defender's point of view, this kind of instrumentation is not relevant, as we assume that the attackers do not have access to the source code.Dynamic Binary Instrumentation (DBI): If only a binary executable is available, fuzzer typically use dynamic binary instrumentation (DBI) to obtain coverage information. Examples of this approach are VUZZER and STEELIX [39], which both use PIN-based [40] instrumentation, and AFL which has multiple forks using QEMU, PIN, DYNAMORIO, or DYNINST for DBI. Fuzzers like DRILLER [48] and T-FUZZ use AFL under the hood and typically rely on the QEMU-based instrumentation.Hardware Supported Tracing: Modern CPUs support various forms of hardware tracing. It is worth to mention that this drastically increases the number of entries in the bitmap, and therefore ANGORA might need a bigger bitmap.Listing 1: A sample code which illustrates the differences between AFL and ANGORA on distinguishing coverage information1 b o o l cmp ( char * a , char * b ) { 2 i f ( a [ 0 ] = = b [ 0 ] ) { 3 i f ( a [ 1 ] = = b [ 1 ] ) { 4r e t u r n t r u e ; 5 } 6 } 7 r e t u r n f a l s e ; 8 } 9 . . . . 10 i f ( cmp ( i n p u t , " f o " ) ) { 11 i f ( cmp ( i n p u t +2 , " ba " ) ) { 12. . . . VUZZER then uses an evolutionary algorithm to produce new mutations: inputs with a high fitness value produce more offspring. However, to achieve better performance in modern fuzzers, additional assumptions were made in the past years, as we discuss next.To evade not only current but also future bug finding methods, we analyze under which core assumptions all (or at least most) of the current tools operate. This means that the internal representation of the state of the symbolic/concolic execution engine has to be small enough to store and the resulting constraints set has to be solvable by current solvers to avoid problems related to state explosion.Summary We compiled a list of 19 different bug finding tools and systematically check which assumptions they rely on. For example, recent binaryonly fuzzing techniques paired with hardware acceleration technologies such as Intel PT have drastically reduced the performance gap between binary and source fuzzing. Although many relevant software projects are open source, a large part of all commercial software used in practice is not available in source code format (e.g., Windows, iOS and the vast majority of the embedded space). These less well-known pieces of software are still used by many users and they might profit significantly from raising the bar against fuzzing (e.g., industrial controllers such as PLCs [6,37] or other types of proprietary software). To undermine this assumption, we modify the program which we want to defend against fuzzing by adding irrelevant code in such a way that its coverage information drowns out the actual signal. We create this fake code by creating random trees of nested conditions with conditions on the input ranging from simple to complicated.Evasion Overall, the attack on the code-coverage assumption consists of a combination of these two techniques to fool the fuzzer into believing that most inputs lead to new code coverage and thus they are classified as "interesting". The three most common ways are (i) observing the exit status, (ii) catching the crashing signal by overwriting the signal handler, and (iii) using the operating system (OS) level debugging interfaces such as ptrace. This way, if an outside entity is observing crashes that we try to mask, it will always observe a crash for each and every input. Our third countermeasure attacks this assumption, without reducing the overall performance of the protected program, as follows: we check whether the input is a well-formed input; if and only if we detect a malformed input, we enforce an artificial slowdown of the application. However, to harden this technique against automated code analysis and patching tools, one can add a computationallyheavy task (e.g., encryption, hash calculation, or even cryptocurrency mining) to the protected program such that the resulting solution is necessary to continue the execution.Evasion Most applications expect some kind of structure for their input files and have the ability to tell if the input adheres to this structure. However this technique has one weakness: If a seed file is provided that contains the correct value, a concolic execution engine might still be able to continue solving other branches.As a second technique, we can encrypt and then decrypted the input with a block cipher. Evasion By sending the input data through a strong block cipher and replacing direct comparisons of input data to magic bytes by hash operations, symbolic, concolic, and taint-based execution engines are significantly slowed down and hampered in their abilities to construct valid inputs. Depending on the configurable number of constraints and the size of the input file, every byte could be part of multiple constraints and constant comparisons.Implementation-wise, although it is possible to generate code for ANTIFUZZ dynamically at runtime, this might cause problems for fuzzers relying on static code instrumentation (i.e., they might not be able to "see" code introduced by ANTI-FUZZ). Thus, our template engine, implemented in 300 lines of Python code, generates a C file containing all randomly chosen constraints and constants, and further provides the ability to set configuration values (e.g., number of fake basic blocks). As detailed in Section 4.2, it is necessary to overwrite the crash signal handlers, as well as prevent it from being observed with ptrace.In the former case, ANTIFUZZ first checks whether overwriting signals is possible: we register a custom signal handler and deliberately crash the application. If the application survives the crash, evidently, signal overwriting is possible.ANTIFUZZ then installs custom signal handlers for all common crash signals and overwrites these with either a timeout or a graceful exit (depending on the configuration). There are two main parts to our countermeasures against symbolic/concolic execution and taint analysis engines: replacing constant comparisons with comparisons of their respective cryptographic hashes, and putting the input through a cryptographic block cipher before usage.The first part is implemented via the SHA-512 hash function. Due to the nature of cryptographic hashes, two hash values can only be checked for equality, and not whether one is larger or smaller than the other.To encrypt and decrypt the input buffer, we use the AES-256 encryption function in ECB mode. However, since ANTIFUZZ installed a custom signal handler, it receives the signal and checks whether it is the fake crash or not. , we demonstrate that modifying a custom dummy application (which is illustrated in Listing 2) using the state-of-the-art obfuscation tool TIGRESS [15] does not yield a satisfying level of protection against current fuzzers.Following the answer to RQ 1. , we evaluate ANTIFUZZ on binary executables from binutils to show the difference in test coverage in a protected and unprotected application. After applying our techniques, there were zero bugs found by the tested tools within a period of 24 hours.In the last step, we measure the overhead introduced by ANTIFUZZ using the SPEC CPU2006 benchmarking suite to answer RQ 5. â€¢ Overloading Symbolic Execution Engines: Important comparisons for equivalence were replaced with SHA-512 hash comparisons and the input data was encrypted and decrypted via AES-256 in ECB mode.If the fuzzer supported both binary instrumentation and compile-time instrumentation, we used the compile-time instrumentation. Thus, obfuscating the control flow via common techniques such as control flow flattening or virtual machine based obfuscation [21] might impact coverage-guided fuzzers.Experiment To demonstrate that obfuscation techniques alone do not protect an application from automatic bug finding tools, we obfuscated a dummy application (see Listing 2) with TIGRESS 2.2 [15] and let different fuzzers find the correct crashing input. Note that VUZZER was excluded because (1) VUZZER is based on the IDA Pro disassembler, which is thwarted by obfuscation before the fuzzing process even begins, and (2) Tigress had trouble compiling non-64bit executables while VUZZER (at the time of the experiment) was not working on 64-bit binaries. We modified the elf parser to include an additional one-byte check of a field in ELF64 that guards the crash.Every possible combination of fuzzer and ANTIFUZZ configuration ran for a period of 24 hours. ZZUF was able to crash the target because there were only 256 different inputs to try.As expected, KLEE was not able to find the correct input once countermeasures against symbolic execution were activated. Coverage Crash Speed Symbolic Execution All base64AFL (#28) (#24) Honggfuzz (#48) (#48) QSYM (#48) Vuzzer (#47) (#33) zzuf (#1) (#1) (#1) uniq AFL (#14) (#13) Honggfuzz (#29) (#29) QSYM (#14) Vuzzer (#26) (#15) zzuf (#1) (#1) (#1) who AFL (#194) (#95) Honggfuzz (#72) (#72) QSYM (#1926) Vuzzer (#266) (#260) zzuf (#1) (#1) (#1) md5sum AFL - - - - - - Honggfuzz (#57) (#55) QSYM (#34) Vuzzer (#25) (#22) zzuf - - - - - -inserted. Note that in all cases, when ANTIFUZZ was activated, even after 24 hours the fuzzers could only reach coverage that would have been reached in the first few minutes without ANTIFUZZ.We performed a statistical analysis on the resulting data, the results are shown in Table 3. The 95th percentile of coverage was less than 13% of the code that the fuzzers found when targeting an unprotected program. The remaining benchmarks ran for three iterations each and were averaged over ten runs with the geometric mean.Result The impact of ANTIFUZZ for each benchmark was insignificant enough to bear little to no observable overhead (see Table 5): most applications show small negative overheads (with the outlier being gcc with -3.80%), but the positive overheads also never reach 1%. For a more complete protection, we recommend to use a combination of both ANTIFUZZ as well as traditional anti-analysis/-patching techniques.The delay-inducing technique should not be applied to any kind of public-facing server software, as this would drastically weaken the server against Denial-of-Service attacks. We explicitly decided not to use self-modifying code since such techniques have the tendency of making exploitation easier by using memory pages with read/write/execute privileges and potentially raising alerts in anti-virus products.Furthermore, ANTIFUZZ in its current form requires developer involvement which is not optimal from a usability perspective. Similarly to modern obfuscation tools, usage of anti-fuzzing defenses will most likely remain cheap.As we cannot evaluate against techniques not yet invented, some of our techniques could be attacked by smarter fuzzers. The large number of crashes found might draw attention and common analysis techniques for bug triage (such as AFLs bug exploration mode) will greatly simplify weeding out the fake bugs.In contrast, our approach is much more low key. Additionally, since in our approach no proper test coverage is achieved, no analysis of the produced fuzzing data will be able to uncover any bugs. Additionally, as we demonstrated in our evaluation, our approach is effective across different fuzzers and does not attack a specific implementation.Finally, a master thesis by GÃ¶ransson and Edholm has introduced the idea of masking crashes and actively detecting if the program is being fuzzed, e.g., by detecting specific AFL environment variables [30]. This work was supported by the German Federal Ministry of Education and Research (BMBF Grant 16KIS0592K HWSec) and the German Research Foundation (DFG) within the framework of the Excellence Strategy of the Federal Government and the States -EXC 2092 CASA.