We demonstrate the attacks in our classification tree through practical proofs-of-concept with vulnerable code patterns evaluated on CPUs of Intel, ARM, and AMD. In the ISA, this state includes, for instance, data in registers or main memory after a successful computation. However, in the final phase of the attack, unauthorized transient computation results are recovered at the receiving end of the covert channel, e.g., by timing memory accesses to deduce the secret-dependent loads from the transient instructions. Where the former relies on dedicated control or data flow prediction machinery, the latter merely exploits that data from a faulting instruction is forwarded to instructions ahead Table 1: Spectre-type attacks and the microarchitectural element they exploit ( ), partially target ( ), or not affect ( ). Attack Element BTB BHB PHT RSB STLSpectre-PHT (Variant 1) [50] Spectre-PHT (Variant 1.1) [48] Spectre-BTB (Variant 2) [50] Spectre-RSB (ret2spec) [52,59] Spectre-STL (Variant 4) [29] Glossary: Branch Target Buffer (BTB), Branch History Buffer (BHB), Pattern History Table (PHT), Return Stack Buffer (RSB), Store To Load (STL). Essentially, the different root cause of the trigger instruction (Spectre-type misprediction vs. Meltdown-type fault) determines the nature of the subsequent unauthorized transient computations and hence the scope of the attack.That is, in the case of Spectre, transient instructions can only compute on data which the application is also allowed to access architecturally. Overall, mitigating Spectre requires careful hardware-software co-design, whereas merely replacing the data of a faulting instruction with a dummy value suffices to block Meltdown-type leakage in silicon, e.g., as it is done in AMD processors, or with the Rogue Data Cache Load resistance (RDCL_NO) feature advertised in recent Intel CPUs from Whiskey Lake onwards [40]. in-place/ same-addressspace out-of-place/ same-addressspace Victim branch Congruent branch Figure 3: A branch can be mistrained either by the victim process (same-address-space) or by an attacker-controlled process (cross-address-space). As the first level of our classification tree, we categorize Spectre attacks based on the microarchitectural root cause that triggers the misprediction leading to the transient execution:• Spectre-PHT [48,50] exploits the Pattern History Table (PHT) that predicts the outcome of conditional branches. Depending on the underlying microarchitecture, the PHT is accessed based on a combination of virtual address bits of the branch instruction plus a hidden Branch History Buffer (BHB) that accumulates global behavior for the last N branches on the same physical core [18,19] Reading Out-of-Bounds. S p e c t r e -P H T S p e c t r e -B T B S p e c t r e -R S B S p e c t r e -S T L Intel intra-process in-place [48,50] [59][29] out-of-place[13] [52,59] cross-process in-place [13,50] [52, 59] out-of-place [50] [52]ARM intra-process in-place [48,50] [6][6] out-of-place [6] cross-process in-place [6,50] out-of-place AMD intra-process in-place [50] [29] out-of-place cross-process in-place [50] out-of-placeSymbols indicate whether an attack is possible and known ( ), not possible and known ( ), possible and previously unknown or not shown ( ), or tested and did not work and previously unknown or not shown ( ). Ultimately, when repurposing traditional techniques from return-oriented programming [75] attacks, adversaries may even gain arbitrary code execution in the transient domain by overwriting return addresses or code pointers. Our novel outof-place PHT poisoning strategy, on the other hand, allows us to perform the training phase entirely outside the enclave on the same physical core by repeatedly executing a congruent branch in the untrusted enclave host process (cf. Figure 3). Adopting established techniques from return-oriented programming (ROP) attacks [75], but abusing BTB poisoning instead of application-level vulnerabilities, selected code "gadgets" found in the victim address space may be chained together to construct arbitrary transient instruction sequences. When encountering a ret instruction, the CPU pops the topmost element from the RSB to predict the return flow. This may allow untrusted code executing in a sandbox to transiently divert return control flow to interesting code gadgets outside of the sandboxed environment.Due to the fixed-size nature of the RSB, a special case of misspeculation occurs for deeply nested function calls [52,59]. However, even before the addresses of all prior stores in the pipeline are known, the CPUs' memory disambiguator [3,33,44] may predict which loads can already be executed speculatively.When the disambiguator predicts that a load does not have a dependency on a prior store, the load reads data from the L1 data cache. However, if this offset is a valid physical address, any cached memory at that location leaks to an unprivileged Foreshadow-OS attacker.Even worse is the Foreshadow-VMM variant, which allows an untrusted virtual machine, controlling guest-physical addresses, to extract the host machine's entire L1 data cache (including data belonging to the hypervisor or other virtual machines). The first FPU instruction issued after the FPU was marked as "not available" causes a device-not-available (#NM) exception, allowing the OS to save the FPU state of previous execution context before marking the FPU as available again.Stecklina and Prescher [78] propose an attack on the above lazy state switch mechanism. The observation by Dong et al. [16] indeed does not shed light on the #BR exception as the root cause for the MPX bounds check bypass, and they do not consider IA32 bound protection at all. Although supervisor mode access prevention (SMAP) raises a page fault (#PF) when accessing user-space memory from the kernel, it seems to be free of any Meltdown effect in our experiments. Guarnieri et al. [25] mention that oo7 would still flag code locations that were patched with Speculative Load Hardening [12] as it would still match the vulnerable pattern.Another approach, called Spectector [25], uses symbolic execution to detect Spectre-PHT gadgets. This provides further evidence that patching Spectre-PHT gadgets in real-world software is an ongoing effort and that automated detection methods and gadget classification pose an important research challenge. Likewise, Chen et al. [13] analyzed various trusted enclave runtimes for Intel SGX and found several instances of vulnerable branches with attacker-controlled input registers, plus numerous exploitable gadgets to which transient control flow may be directed to leak unauthorized enclave memory. We opted for an in-depth analysis of one specific piece of software instead of a breadthfirst approach where we do a shallow analysis of multiple pieces of software. This allowed us to analyse historical data (i.e., code locations the kernel developers deemed necessary to protect) that led to the second tier classification discussed in Section 5.1. The reason behind that is that multiple arrays are indexed with the same masked index and that there are multiple branches on a value that was loaded with a potential malicious index. Our analysis also shows that more dangerous gadgets that either allow more than 1-bit leakage or even arbitrary code execution are not frequently occurring. Second, we consider Meltdown and Spectre as two problems with different root causes, leading to a A defense considers the microarchitectural element ( ), partially considers it or same technique possible for it ( ) or does not consider it at all ( ). Third, it helped uncover problems that were not clear with the previous classification.We categorize Spectre-type defenses into three categories: C1: Mitigating or reducing the accuracy of covert channels used to extract the secret data. While their prototype implementation protects only caches (and the TLB), other channels, e.g., DRAM buffers [69], or execution unit congestion [1,9,56], remain open.Yan et al. [91] proposed InvisiSpec, a method to make transient loads invisible in the cache hierarchy. The above code snippet features an explicit example of a "leak gadget" that may act as a microarchitectural covert channel: depending on the out-of-bounds value being read, the transient Table 2: Spectre-type attacks performed in-place, out-of-place, same-address-space (i.e., intra-process), or cross-addressspace (i.e., cross-process). Our systematization uncovers 6 (new) transient execution attacks that have been overlooked and not been investigated so far: 2 new exploitable Meltdown effects: Meltdown-PK (Protection Key Bypass) on Intel, and Meltdown-BND (Bounds Check Bypass) on Intel and AMD; and 4 new Spectre mistraining strategies. We also debunk implicit assumptions including that AMD or the latest Intel CPUs are completely immune to Meltdown-type effects, or that serializing instructions mitigate Spectre Variant 1 on any CPU.In this paper, we present a systematization of transient execution attacks, i.e., Spectre, Meltdown, Foreshadow, and related attacks. If the victim used the cache line, accessing it will be fast; otherwise, it will be slow.Covert channels are a special use case of side-channel attacks, where the attacker controls both the sender and the receiver. Furthermore, as illustrated in Figure 3, when only a subset of the virtual address is used in the prediction, mistraining can be achieved using a branch instruction at a congruent virtual address. As explained further, depending on the adversary's capabilities (e.g., in-process, sandboxed, remote, enclave, etc.) these previously unknown mistraining strategies may lead to new attacks and/or bypass existing defenses. Leaks M e m o r y C a c h e R e g i s t e r C r o s s -C P L Meltdown-US (Meltdown) [56] Meltdown-P (Foreshadow-NG) [90] Meltdown-P (Foreshadow-SGX) [85] Meltdown-GP (Variant 3a) [8] Meltdown-NM (Lazy FP) [78] Meltdown-RW (Variant 1.2) [48] Meltdown-PK Meltdown-BR Symbols indicate whether an attack crosses a processor privilege level () or not (), whether it can leak secrets from a buffer ( ), only with additional steps ( ), or not at all ( ). Any data present in L1 and tagged with that physical address will now be forwarded to the transient execution, regardless of access permissions.Although Meltdown-P-type leakage is restricted to the L1 data cache, the original Foreshadow [85] attack showed how SGX's secure page swapping mechanism might first be abused to prefetch arbitrary enclave pages into the L1 cache, including even CPU registers stored on interrupt. The ability to transiently overwrite read-only data within the current privilege level can bypass software-based sandboxes which rely on hardware enforcement of read-only memory.Confusingly, the above Meltdown-RW attack was originally named "Spectre Variant 1.2" [48] as the authors followed a Spectre-centric naming scheme. This, for instance, includes powering up the AVX functional units, instruction cache fills, and iTLB fills which still leak data.Evtyushkin et al. [18] propose a similar method to serializing instructions, where a developer annotates potentially leaking branches. For example, consider the following code snippet for bounds checking [50]:if (x < len(array1)) { y = array2[array1[x] * 4096]; }At the architectural level, this program clearly ensures that the index variable x always lies within the bounds of the fixedlength buffer array1. Much like Spectre-PHT, such same-address-space in-place BTB (Spectre-BTB-SA-IP) poisoning abuses the victim's own execution to mistrain the underlying branch target predictor. A building blocks for some variants of Spectre is branch poisoning (an attacker mistrains a prediction mechanism, cf. Section 3). This allows the CPU to execute µOPs not only in the sequential order provided by the instruction stream but to dispatch them in parallel, utilizing the CPU's execution units as much as possible and, thus, improving the overall performance. For example, a victim that repeatedly executes a virtual function call with an object of TypeA may inadvertently mistrain the branch target predictor to cause misspeculation when finally executing the virtual function call with an object of another TypeB. We deliberately oriented our attack tree (cf. Figure 1) on the microarchitectural root causes of the transient computation, abstracting away from the underlying covert channel and/or code gadgets required to carry out the attack successfully. However, transient instructions may still leave traces in the CPU's microarchitectural state, which can subsequently be exploited to partially recover unauthorized results [50,56,85]. • Single Thread Indirect Branch Prediction (STIBP) restricts sharing of branch prediction mechanisms among code executing across hyperthreads. While extraction rates are significantly higher when the kernel data resides in the CPU cache, Meltdown has even been shown to successfully extract uncached data from memory [56]. • Spectre-STL [29] exploits memory disambiguation for predicting Store To Load (STL) data dependencies. Where the above attacks [8,56,78,85] focussed on stealing information across privilege levels, Kiriansky and Waldspurger [48] presented the first Meltdown-type attack that bypasses page-table based access rights within the current privilege level. Similar to previous Meltdown-type attacks, however, the attack exploits that the transient execution following the faulting instruction can still compute on the unauthorized data, and leak the system register contents through a microarchitectural covert channel (e.g., Flush+Reload). This creates a transient buffer overflow, allowing the attacker to bypass both type and memory safety. All tests performed without defenses enabled.recent defensive work by Dong et al. [16] highlights the need to introduce a memory lfence after MPX bounds check instructions. Specifically, Intel's analysis [40] only briefly mentions MPX-based bounds check bypass as a possibility, and M D -N M [ 7 8 ] M D -R W [ 4 8 ] M D -P K M D -B R M D -D E M D -A C M D -U D M D -S S M D -X D M D -S M Intel ARM AMDSymbols indicate whether at least one CPU model is vulnerable (filled) vs. no CPU is known to be vulnerable (empty). For Broadwell and older architectures, Intel [39] provided a microcode update to make the ret instruction predictable, enabling retpoline to be a robust defense against Spectre-BTB. Our systematization revealed, however, that the transient cause exploited above is a #PF exception. We suspect that, due to the simplistic IA32 segmentation design, segment limits are validated early-on, and immediately raise a #GP or #SS (stack-segment fault) exception, without sending the offending instruction to the ROB. Given the versatility of Spectre variants in a variety of adversary models, we propose a novel two-level taxonomy based on the preparatory phases of the abstract transient execution attack flow in Figure 2. These Spectre variants first go through a preparatory phase (cf. Figure 2) where the microarchitectural branch predictor state is "poisoned" to cause intentional misspeculation of a particular victim branch. The microarchitecture then describes how the ISA is implemented in a processor in the form of pipeline depth, interconnection of elements, execution units, cache, branch prediction. As an academic contribution, plausible hardware mitigations have furthermore been proposed [48] to prevent transient computations on out-of-bounds writes (Spectre-PHT). Our systematic analysis furthermore resulted in the first demonstration of exploitable Meltdown-type delayed exception handling effects on AMD CPUs. For sandboxed adversaries (e.g., Spectre-PHT [50]), on the other hand, much of the gadget functionality has to be provided by "confused deputy" code executing in the victim domain. A common type of Store To Load (STL) dependencies require that a memory load shall not be executed before all preceding stores that write to the same location have completed. The microarchitectural state includes, for instance, entries in the cache and the translation lookaside buffer (TLB), or the usage of the execution units. This does not only require changes to the cache and adaptions to the coherence protocol but also enforces the correct management of these domains in software.Kocher et al. [50] proposed to limit data from entering covert channels through a variation of taint tracking. It tries to formally prove that a program does not contain any gadgets by tracking all memory accesses and jump targets during execution along all different program paths. Hence, to keep the pipeline full at all times, it is essential to predict the control flow, dat