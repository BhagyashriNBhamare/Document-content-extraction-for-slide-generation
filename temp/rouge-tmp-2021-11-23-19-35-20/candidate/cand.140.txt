While these examples provide legitimate usages of private information, some apps may also misuse such information, such as stealing users' call history without their knowledge.That said, an app needs to justify an access to users' private information with sufficient semantics available to users. While intuitively simple, the challenge of FlowCog lies in how to extract such context, i.e., FlowCog needs to establish a relationship between semantics embedded deeply in an app with each information flow.The key insight of FlowCog is that flow contexts are embedded in these Android GUIs, such as views, which have direct control over the flow. This flow, from the phone number to the Internet, is positive, because the app provides sufficient semantics, such as keywords "Phone Number" and "mobile number", so that the app user can acknowledge and authorize the flow.What FlowCog does is to extract contexts for each information flow found by existing static or dynamic analysis and classify the flow as either positive or negative based on the extracted contexts. Specifically, such process, shown in Figure 2, can be broken down into four steps: (i) finding information flows of an Android App, (ii) finding special statements called activation event and guarding condition via control dependency and associated views (called view dependency) for each information flow, (iii) finding and extracting contexts, e.g., texts and images, from the aforementioned two special statements via data dependency, and (iv) determining the correlation between the flow and the contexts via Natural Language Processing (NLP) technique. Lastly, we introduce an optional dynamic analysis component in Section 3.5. (Activation Event) Given a data flow, we define an event callback p e as an activation event if there exists a path p e··· p k in the call graph of the target app where p k is a statement in the flow's call path (p src··· p k··· p sink ). Similarly, FlowCog finds lifecycle event callbacks by looking at subclasses of corresponding lifecycle related classes, such as Activity, and finding overridden lifecycle callbacks, such as onCreate.Then, FlowCog generates call paths for a given data flow, e.g., the call path in Figure 4 for the data flow in Figure 3, and performs Algorithm 1 to find its activation events. (Guarding Condition) Given a data flow n source··· n k··· n sink , for any n k , we define a conditional statement c e -at least one branch of which does not contain n k -as a guarding condition if either of the following is satisfied:(1) c e and n k are in the same basic block, or connected in the interprocedural Control Flow Graph (iCFG);(2) c e controls the activation events of the data flow via view dependency, i.e., c e and the activation event are in the same view.Based on the definition, there are naturally two phases to find all guarding condition statements. If none of the following are satisfied, i.e., the method of curStmt is a callback method, FlowCog searches the statements that can reach curStmt in the program's inter-procedure control flow 11:else if isInvokeStmt(prevStmt) and method == getInvokedMethod(prevStmt) then f indGCHel per(curStmt, method.getFirstStmt(), iC f g, rs)13:else 14:f indGCHel per(curStmt, null, iC f g, rs)15:end if end if 17: end for 18: return rs graph ( Line 13-14). If a view's attribute values (e.g., EditText.getText() or CheckBox.isChecked()) could change the conditional result in guarding conditions of the given data flow, we consider such dependency exists.The view dependency problem can be formalized into another data flow analysis. Again, in most cases, i.e., 94%, such values can be resolved statically; otherwise, FlowCog relies on the optional dynamic analysis to resolve values.Second, besides the depended view, semantics from other adjacent views in the same layout may also be flow contexts, because a user-visible screen may contain multiple views from the same layout. After that, resource filter will filter those less-informative pairs generated from API doc and feed all the remaining ones into two classifiers, one learning-based and the other learning-free, and FlowCog will calculate a score based on the results from these two classifiers using logistic regression. The prediction results including confidence scores from these two ML modules are combined by another logistic regression module.On the other hand, the learning-free classifier, i.e., the similarity one, measures the similarity between the action-resource pair lists from the flow's API documents and the extracted text-based semantics. Then, FlowCog transforms each actionresource pair in both lists to a vector through Word2Vec model [26], one of the most popular predictive model for learning word embedding from raw texts. The semantics extraction part, such as finding views, activation events and guarding conditions, contains ∼12,000 LoC, the part about correlating semantics and flows, i.e., multiple classifiers, contains ∼3,000 LoC, our dynamic analysis ∼1,000 and others ∼500. FlowDroid with its default setting, i.e., flow-and context-sensitive, is used as the existing static analysis tool to extract information flows-we run FlowDroid on each app for 20 mins and then terminate it if no results are outputted. We instruct the student to install Android apps, look at app descriptions and each information flow in the context of the app, and then infer whether the information flow as positive or negative based on their own knowledge. Precision is defined as T P/(T P + FP), recall as (T P/(T P + FN), and accuracy as (T P + T N)/(T P + T N + FP + FN). Our manual analysis shows that many of those are caused by inefficient training set.We further break down the overall accuracy of FlowCog based on the used permissions, e.g., Location and SMS, and then calculate each permission category's accuracy. Particularly, we compare FlowCog with approaches that takes (i) only apps' descriptions, (ii) only flow contexts, (iii) apps' description and all the flow's contexts, and (iv) apps' description and the context for only the target flow (i.e., FlowCog). The results show that flow contexts provide more information than the app descriptions, and at the same time app descriptions provide a background for flow contexts-therefore, the combination of these two provides a good result for FlowCog. Specifically, we want to compare the followings: (i) learning-based model vs. learning-free model vs. the hybrid model combining learning-based and learning-free, (ii) gradient boosting (GB) plus linear support vector machine (SVM) vs. other learning models, and (iii) NLP-based vs. keyword-based. Therefore, we choose a hybrid approach for the design of FlowCog in the end.Second, we would like to justify the two learning algorithms, i.e., Gradient Boosting (GB) and linear Support Vector Machine (SVM), used in FlowCog's learningbased approach. Note that one takeaway here is that classical efficient classification algorithms, e.g., LR, DT and NB, do not work well for our problem.Lastly, we want to justify why we want to use NLP- based approach rather than a simple keyword-based one. We manually generate 10 keywords for each category listed in Table 3. Next, we compute the similarity score of this word list and the keyword list, using the Word2Vec similarity model discussed in Section A.4, and then make a classification decision based on the score.We evaluate the keyword-based, keyword plus simple NLP, and FlowCog using the same testing set. We manually inspect 68 flows, i.e., these from ten benign apps in Google Play and ten malicious apps in Drebin dataset. Next, we decompile the apps using apktool [8] to find the classes that each statements in call path resides and map the semantics that we see to the corresponding text blocks or non-text items in the apps. FlowCog does support multiple languages: before feeding texts to classifiers, if any texts are not recognized as English, FlowCog will use a Python library called mtranslate [2] to translate them into English.Second, the remaining 18 texts that FlowCog fails to extract are caused by the limitations of static value analysis: completely solving value analysis is still a funda- mental challenges suffered by all static analysis tools.FlowCog adopts a bunch of heuristic rules to try our best to resolve those non-constant string values, but there are still 7 cases that we cannot resolve. Next, Table 7 shows the accuracy of FlowCog in extracting information from informative non-text items: (i) images with texts, (ii) images without texts, such as mail icons, and (iii) non-image fragments, such as ads and maps. In this section, we perform a case study on a variety of data flows in different types of apps and discuss whether the app provides enough semantics for the flow, i.e. classified as positive or negative by FlowCog. FlowCog can successfully extract flow contexts, such as "location of Home of Ocarina" and a Google map fragment, thus classifying the flow as positive. FlowCog marks this flow as negative because FlowCog only extracts "Set Alarm", "Text clock on Widget", "Change Color Theme", "-:-", "ON", "OFF" and "Designed by Thalion" from the app for the flow. None of the aforementioned texts are related to geo-location or device ID, and thus FlowCog cannot correlate the flow with the texts. Specifically, this app is a trojan, which pretends to be a gaming app, but hijacks the user's phone and leaks out confidential data while the user is playing the game. Specifically, FlowCog successfully finds that all these flows are triggered by an onCreate() callback of an activity in the app and then extract semantics, which only include gaming tips, such as "Move the box to the target empty position ...", and app control information, such as "Are you sure you would like to exit?" Even if they are defined dynamically in a rare case, FlowCog also relies on an optional dynamic analysis component to resolve the values.Second, we discuss how clickjacking attacks, or in general UI redress attacks, influence our results. It is context-, flow-, field-and object-sensitive while still very efficient: FlowDroid transforms taint analysis's information flow problem into an IFDS problem, and then uses an efficient IFDS solver to find the solution. As a comparison, FlowCog goes beyond app's execution contexts, i.e., activation events and guarding conditions, to find Android views and extract semantics related to these views.Third, NLP techniques are also used in Android privacy. Zimmeck et al. [37] propose another NLP system that extracts the semantics from app's privacy requirements and predicts whether an app is compliant with its privacy requirement. Here are the details.First, FlowCog's NLP module preprocesses all the raw input texts by annotating special nouns, such as email, abbreviation, IP address and ellipsis, by regular expressions. The Stanford Parser breaks down the sentence into multiple triples, each of which contains the name of the relation, the governor and the dependent, and outputs a grammar hierarchical tree.Third, FlowCog converts the grammar hierarchical tree into a list of action-resource pairs, i.e., preserving the verb phrase with governor-dependent relationship from the Stanford parser. Particularly, FlowCog performs the following steps: (i) removing stopwords without sufficient semantic information, such as "are" and "the", (ii) replacing names, such as people and location, with general names by Stanford Named Entity Recognizer [16], and (iii) normalizing and lemmatizing all words, e.g., converting all letters to lowercase and plural subjects to singular. (iii) FlowCog uses logistic regression to calculate a combined score.First, FlowCog uses a variation of bag-of-words to convert action-resource pairs to a text vector, and then adopts term-frequency inverse document-frequency (TF-IDF) model to convert the text vector into a numeric one. t f id f (t, d) = t f (t, d) * id f (t) = 1 + N 1 + d f (d,t)(1)where the parameter t refers to the target element, the parameter d refers to the text vector, t f is the element's frequency, i.e., the number of times a term occurs in a given word pair list, id f is the element's inverse documentfrequency, N is the number of text lists in our training set, and d f (dt) returns the number of text lists that contain the target element t. Meanwhile, FlowCog adopts linear SVM in soft-margin version, which allows some points to be misclassified but each instance will impose a penalty to the target function.Lastly, FlowCog relies on Linear Regression to combine results from GB and SVM into a single result that lies in between zero and one, where one means correlated and zero not. For example, cosine function, which will be defined later in this section, is frequently used as a measure of similarity, so cos( v contact , v connection ) larger than cos( v contact , v rocket ) means the word "contact" is more related to "connection" than "rocket" in the specific model. A "null" action will map to an zero vector, and if the resource contains more than one word, FlowCog will find the vector for each word and add them together.Third, FlowCog calculates the similarity score between two vector lists corresponding to Android API documents and texts extracted by the Android app. So the most related texts contribute the most to the overall similarity scores.w i j = w(s i j · h(s i j )) = µ k , (0 < µ < 1)where k is kth element in desc_sorted({x|s i j · h(s i j ), iεM, jεN}).