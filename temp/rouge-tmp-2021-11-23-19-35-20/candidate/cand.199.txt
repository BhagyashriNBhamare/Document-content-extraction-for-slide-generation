MOPT utilizes a customized Particle Swarm Optimization (PSO) algorithm to find the optimal selection probability distribution of operators with respect to fuzzing effectiveness, and provides a pacemaker fuzzing mode to accelerate the convergence speed of PSO. selection strategy [4,5,6,7,8], the ones that improve the testing speed and code coverage [9,10,11,12], and the ones that integrate other techniques with fuzzing [13,14,15]. A large number of wellrecognized fuzzers, e.g., AFL [16] and its descendants, libFuzzer [17], honggfuzz [18] and VUzzer [6], usually predefine a set of mutation operators to characterize where to mutate (e.g., which bytes) and how to mutate (e.g., add, delete or replace bytes). Thus, fuzzers that select mutation operators with the uniform distribution are likely to spend unnecessary computing power on inefficient operators and decrease the overall fuzzing efficiency.One operator's efficiency varies with target programs. Inspired by the well-known optimization algorithm Particle Swarm Optimization (PSO) [19], MOPT dynamically evaluates the efficiency of candidate mutation operators, and adjusts their selection probability towards the optimum distribution.MOPT models each mutation operator as a particle moving along the probability space [x min , x max ], where x min and x max are the pre-defined minimal and maximal probability, respectively. The fuzzer (1) maintains a queue of seed test cases, which can be updated at runtime; (2) selects some seeds from the queue in certain order; (3) mutates the seeds in various ways; (4) tests target programs with the newly generated test cases, and reports vulnerabilities or updates the seed queue if necessary; then (5) goes back to step (2). Each time, AFL selects a series of R o mutation operators following the uniform distribution, and applies them on the seed to generate one test case. These new test cases will be fed to the havoc stage scheduler, rather than the program being tested, to generate new test cases.The mutation scheduler in the first stage is deterministic and slow, while the one in the last stage is rarely used. More specifically, we aim at finding an optimal probability distribution, following which the scheduler could select better mutation operators and improve the fuzzing efficiency. Some are better than others at generating the test cases, denoted as interesting test cases, that can trigger new paths or crashes.To verify our hypothesis, we conducted an experiment on AFL to evaluate each operator's efficiency. Then, based on those optimal probabilities, we could obtain a global optimal probability distribution of mutation operators.The Particle Swarm Optimization (PSO) algorithm can be leveraged to find the optimal distribution of the operators and we detail the modification of PSO in our setting as follows. Specifically, the movement of a particle P is calculated as follows:v now (P) ← w × v now (P)+r × (L best (P) − x now (P)) +r × (G best − x now (P)). MOPT employs a particle per operator, and tries to explore an optimal position for each operator in a predefined probability space [x min , x max ], where 0 < x min < x max ≤ 1. Similar to PSO, MOPT also appoints the best position that a particle has ever found as its local best position.For a given particle, a position x 1 is better than x 2 , if and only if, its corresponding operator yields more interesting test cases (with a same amount of invocations) in the former position than the latter. Hereby we also evaluate each particle's efficiency from a global perspective, denoted as global efficiency global e f f , by evaluating multiple swarms of particles at a time.More specifically, we measure the number of interesting test cases contributed by each operator till now in all swarms, and use it as the particle's global efficiency global e f f . The proportion of each particle's global e f f in this distribution is used as its global best position G best . More specifically, for a particle P j in a swarm S i , we update its position as follows.v now [S i ][P j ] ←w × v now [S i ][P j ] +r × (L best [S i ][P j ] − x now [S i ][P j ]) +r × (G best [P j ] − x now [S i ][P j ]). As shown in Fig. 8, MOPT consists of four core modules, i.e., the PSO initialization and updating modules, as well as the pilot fuzzing and core fuzzing modules.The PSO initialization module is executed once and used for setting the initial parameters of the PSO algorithm. Hence, each particle's global efficiency (i.e., global best position) could be evaluated.With this iteration loop, the fuzzer could utilize the PSO to find an optimal probability distribution to select mutation operators, and gradually improve the fuzzing efficiency.Note that, MOPT's workflow is independent from the target fuzzer, as long as the fuzzer's mutation scheduler uses a probability distribution to select operators. More specifically, MOPT (1) sets the initial location x now of each particle in each swarm with a random value, and normalizes the sum of x now of all the particles in one swarm to 1; (2) sets the displacement of particle movement v now of each particle in each swarm to 0.1; (3) sets the initial local efficiency e f f now of each particle in each swarm to 0; (4) sets the initial local best position L best of each particle in each swarm to 0.5; and (5) sets the initial global best position G best of each particle across swarms to 0.5. During fuzzing, the module will measure three measurements: (1) the number of interesting test cases contributed by a specific particle (i.e., operator), (2) the number of invocations of a specific particle, (3) the number of interesting test cases found by this swarm, by instrumenting target programs.The local efficiency of each particle (in current swarm) is the first measurement divided by the second measurement. Then we could calculate the distribution between particles, and locate each particle's global best position.Note that, if we only use one swarm in the pilot module, then the core module could be merged with the pilot module. MOPT therefore provides an optimization to AFL-based fuzzers, denoted as pacemaker fuzzing mode, which selectively avoids the time-consuming deterministic stage.Specifically, when MOPT finishes mutating one seed test case, if it has not discovered any new unique crash or path for a long time, i.e., T that is set by users, it will selectively disable the deterministic stage for the following test cases. This mode selectively disables this stage only after the efficiency slows down, and thus benefits from this stage while avoiding wasting much time on it.More specifically, MOPT provides two types of pacemaker fuzzing modes for AFL, based on whether the deterministic stage will be re-enabled or not: (1) MOPT-AFL-tmp, which will re-enable the deterministic stage again when the number of new interesting test cases exceeds a predefined threshold; (2) MOPT-AFL-ever, which will never re-enable the deterministic stage in the following fuzzing process. All the experiments run on a virtual machine configured with 1 CPU core of 2.40GHz E5-2640 V4, 4.5GB RAM and the OS of 64-bit Ubuntu 16.04 LTS.Initial seed sets. Since coverage-based fuzzers such as AFLFast [5] and VUzzer [6] consider that exploring more unique paths leads to more unique crashes, the second evaluation metric is the number of unique paths discovered by each fuzzer. In total, MOPT-AFL-tmp and MOPT-AFL-ever discover 2,195 and 2,334 more unique crashes than AFL on the 13 programs. • When considering the pacemaker fuzzing mode, MOPT-AFL-tmp and MOPT-AFL-ever discover the most unique crashes on 8 and 6 programs, respectively, while MOPT-AFL-ever discovers more crashes in total. Since the main difference between the two fuzzers is whether using the deterministic stage later, it may be an interesting future work to figure out how to employ the deterministic stage properly. For instance, MOPT-AFL-tmp finds 45 more security CVEs than AFL; MOPT-AFL-ever finds 23 more unreported CVEs than AFL; Our fuzzers find 81 security CVEs with 66 new CVE IDs assigned on 11 programs. Since the vulnerabilities happened in the tiff2bw command-line program and the CVE assignment team thinks that sam2p is a UNIX command line program rather than a library, they cannot assign CVE IDs for the vulnerabilities on tiff2bw and sam2p. Because it is hard to randomly generate a particular value, the operators in the deterministic stage, such as flipping the bits one by one (bitflip) and replacing the bytes with interesting values (interesting values), are better than the ones in the havoc stage to pass the magic byte checks and to test deeper execution paths. However, since the deterministic stage performs multiple kinds of operators on each bit/byte of the test cases, it takes a lot of time to finish all the operations on each test case in the fuzzing queue, leading to the low efficiency. MOPT again exhibits good compatibility and can be integrated with general mutation-based fuzzers. To provide statistical evidences of our improvements, we measure the performance of MOPT-AFL-ever, AFL, Angora [9] and VUzzer [6] on five programs including mp3gain, pdfimages, objdump, jhead and infotocap (the detail of each program is shown in Table 2). To eliminate the effect of randomness, we run each testing for 30 times.To investigate the influence of the initial seed set on the performance of MOPT, we consider using various initial seed sets in our experiments such as an empty seed, or the seeds with different coverage, which are widely used in previous works [1,5,9,21]. In the third group, Angora is skipped since it reports errors to fuzz pdfimages when given 200 seed PDF files.To obtain the seed inputs, we first download more than necessary (e.g., 1,700) input files with correct formats from the Internet. In particular, p1 is the p value yielded from the difference between the performance of MOPT-AFL-ever and AFL, p2 is the p value yielded from the difference between the performance of MOPT-AFL-ever and Angora, and p3 is the p value generated from the difference between the performance of MOPT-AFL-ever and VUzzer.We further validate the reliability of our p value analysis leveraging the Benjamini-Hochberg (BH) procedure [31]. In these 11 evaluations, p1, p2 and p3 are smaller than 10 −5 , meaning that the distribution of the number of unique crashes discovered by MOPT-AFL-ever and the other fuzzers is widely different, which demonstrates a significant statistical evidence for MOPT's improvement. For instance, the minimum number of unique bugs discovered by MOPT-AFLever among the 30 runs is more than the maximum number of that discovered by other fuzzers when fuzzing objdump and jead with 20 files as the initial seed set. This reminds us the motivation of generationbased fuzzers and shows that: although fuzzers like AFL may perform better with an empty seed, they cannot discover more crashes on the programs that require complex input formats when using an empty seed. To validate the effectiveness of MOPT main framework and the pacemaker fuzzing mode, we implement MOPT-AFL-off (that is based on MOPT-AFL-ever while disabling the pacemaker fuzzing mode) and AFL-ever (that is based on AFL and only implements the pacemaker fuzzing mode). As a conclusion, both two comparison groups demonstrate that the MOPT scheme without the pacemaker fuzzing mode can also improve the performance of AFL on exploring unique crashes and paths, but a better performance can be achieved if integrating the pacemaker fuzzing mode.Pacemaker Fuzzing Mode. As a conclusion, the experiments demonstrate that the pacemaker fuzzing mode can help fuzzers find much more unique crashes and paths.In summary, both the MOPT main framework and pacemaker fuzzing mode can improve the fuzzing performance significantly, while the combination of both parts would result in an even better performance (corresponding to MOPT-AFL-ever). To further clarify this point, we use the number of unique crashes discovered by MOPT-AFL-ever as the baseline and observe the approximate fuzzing performance From the results, the improvement of the pacemaker fuzzing mode is relatively limited for fuzzing; however, without the pacemaker fuzzing mode, MOPT cannot converge fast to the proper selection probability distribution, which on the other hand limits the fuzzing performance either. Each experiment runs on a virtual machine configured with four CPU cores of 2.40Ghz E5-2640 V4, 4.5 GB RAM and the OS of 64-bit Ubuntu 16.04 LTS. By leveraging MOPT as an optimal strategy for selecting mutation operators, we believe the performance of these systems can be further enhanced.In our evaluation, we consider 13 real world programs and several seed selection strategies, which are still a limited number of scenarios. Taking the advantage of its compatibility, it can be combined with most of the aforementioned fuzzers.Although in this paper we focus on using MOPT to improve mutation-based fuzzers, it can also be implemented in other kinds of fuzzers, such as generation-based fuzzers and kernel fuzzers, if they have the issues to select proper operators to generate test cases. By using MOPT to search the optimal selection distribution for mutation operators and leveraging the pacemaker fuzzing mode to further accelerate the convergence speed of searching, MOPT can efficiently and effectively determine the proper distribution for selecting mutation operators.