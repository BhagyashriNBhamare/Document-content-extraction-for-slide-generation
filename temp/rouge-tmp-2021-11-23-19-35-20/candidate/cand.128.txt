The proliferation of the Internet of Things has increased reliance on voice-controlled devices to perform everyday tasks. In this work, we conduct an empirical analysis of interpretation errors made by Amazon Alexa, the speech-recognition engine that powers the Amazon Echo family of devices. Voice interfaces can be used to perform a wide array of tasks, such as calling a cab [11], initiating a bank transfer [2], or changing the temperature inside a home [8]. The NSP corpus provides speech samples of 188 words from 60 speakers located in six distinct "dialect-regions" in the United States.We find that for this dataset of 11,460 utterances, Alexa has an aggregate accuracy rate of 68.9% on single-word queries. Unlike existing work, which focuses on crafting adversarial audio input to inject voice commands [15,39,42,48,49], our attack exploits intrinsic error within the opaque natural language processing layer of speech-recognition systems and requires an adversary to only register a public skill. In recent years, voice interfaces have become a general purpose means of interacting with computers, largely due to the proliferation of the Internet of Things. Figure 2: User-skill interaction in Alexa -A typical user interaction with an Alexa skill, using an Echo device. In order to add extensibility to the platform, Amazon allows the development of third-party applications, called "skills", that leverage Alexa voice services. For example, users can now request rides through the Lyft skill ( Figure 1) and conduct everyday banking tasks with the American Express skill [4]. Up until April of 2017, Alexa required users to enable a skill to their account, in a manner similar to downloading a mobile application onto a personal device. In order to enable text-based analysis of English speech, the Advanced Research Projects Agency (ARPA) developed ARPAbet, a set of phonetic transcription codes that represent phonemes of General American English using distinct sequences of ASCII characters [30]. the word "pronounce" using the ARPAbet transcription codes is P R AH N AW N S. For the scope of this work, we define the phonetic spelling of a word as its ARPAbet phonetic representation, with each ARPAbet character representing a single phoneme. In order to use Alexa as a transcription service, we built an Alexa skill (called "Record this") that records the raw transcript of input speech. NSP The Nationwide Speech Project (NSP) is an effort led by Ohio State University to provide structured speech data from a range of speakers across the United States [19]. In particular, five male and five female speakers from each region provide a set of 188 single-word recordings, 76 of which are single-syllable words (e.g. "mice", "dome", "bait") and 112 are multi-syllable words (e.g. "alfalfa", "nectarine"). These single-word files provide a total of 11,460 speech samples for further analysis and serve as our primary source of speech data. In addition, NSP provides metadata on each speaker, including gender, age, race, and hometown.Forvo We also collect speech samples from the Forvo website [6], which is a crowdsourced collection of pronunciations of English words. First, we observe that Alexa does not consistently return the same transcription when processing the same speech sample. We used a thirdparty aggregation database [1] to gather a list of all the skill names that were publicly available on the Alexa skills store. We use public datasets and ensure our usage is in line with their provider's terms of service. For all attacks presented in this paper, we test them only in a controlled, developer environment. We have disclosed these attacks to Amazon and will work with them through the standard disclosure process. Table 2 characterizes these extremes by showing the top 10 misinterpreted words as well as the top 10 correctly interpreted words in our dataset. We find that words with the lowest accuracy tend to be small, single-syllable words, such as "bean", "calm", and "coal". Words with the highest Table 2: Words with Highest and Lowest Accuracy -The best and worst interpretation accuracies for individual words are shown here. The median number of misinterpretations is 15, but with a heavy tail.In investigating the distributions of misinterpretations per word, we observe that, for each of the 188 words, there are one or two interpretations that Alexa outputs more frequently than the others. These are words that are Alexa misunderstands both frequently Word MCE Word Phonemes MCE Phonemes Table 3: Phonetic Structure of Systematic Errors -We show the underlying phonetic structure of the ten systematic errors that seem to appear due to Alexa confusing certain phonemes with others. There are 24 (12.8%) such words in our dataset.rip rap R IH P R AE P lung lang L AH NG L AE NG wet what W EH T W AH T dime time D AY M T AY M bean been B IY N B IH N dull doll D AH L D AA L coal call K OW L K AO L luck lock L AH K L AA K loud louder L AW D L AW D ER sweeten Sweden S W IY T AH N S W IY D AH N We now have a classification for interpretation errors from our dataset. We next investigate how an adversary can leverage these errors to cause harm to users in the Alexa ecosystem. The core idea is simple -given a systematic error from one word to another, an adversary constructs a malicious skill that has a high likelihood of confusion with a target skill on the Alexa skills store. We next investigate whether these errors can be exploited in a skill invocation environment, to redirect the processing of an Alexa query to an attacker-controlled skill server.Our testing process is as follows: given a model of predictable errors, we build pairs of skills with names that are frequently confused by Alexa. We are able to successfully squat 25 (92.6%) of the skills at least one time, demonstrating the feasibility of the attack.They will instead be routed to the Boyle skill.In order to demonstrate that our attack will work on speakers we have not previously seen, we use two-fold cross validation over the 60 speakers in our dataset. As an ethical consideration, we test our attack by registering our skills in a developer environment and not on the public Alexa skills store, to avoid the possibility of regular users inadvertently triggering them. However, because louder is a native Alexa command which causes Alexa to increase the volume on the end-user device, when the target is misinterpreted, it is instead used to perform a native Alexa function. We speculate that this is a result of a smaller solution space when Alexa is choosing between skills as opposed to when it is transcribing arbitrary speech within a skill. We next investigate how an adversary can craft maliciously named skills targeting existing skills in the Alexa skills store, by leveraging the squattable words we identified in Section 4. To this goal, we utilize our dataset of Alexa skill names described in Section 3. Considering that many popular skill names make use of novel words (e.g., WeMo) or words that appear less frequently in discourse (e.g., Uber), acquiring such a speech corpus may prove prohibitively costly and, in some cases, infeasible. We consider unambiguous cases to be where a single phoneme of the input: a) occurs between two already mapped pairs of phonemes or is the first or the last phoneme of the input, and b) was either omitted (maps to an empty phoneme) or confused with one or two other phonemes in the output. Taking an example from our tests, when the input word "consume" (K AH N S UW M) is confused by Alexa as "film" (F IH L M), the word error may have happened for reasons unrelated to phoneme misinterpretations and it is not clear how to align input and output except for the final M phoneme in both of the words. We next investigate whether the interpretation errors for each demographic are systematic and, as a result, can be used by an adversary to launch a spear skill squatting attack.To identify squattable words based on region, we first split our speakers into their respective dialect-region. An attacker can leverage any of these in order to target speakers from one specific region.We then apply the same technique to find squattable words based on speaker gender and observe a similar result -there are squattable words that only affect speakers based on their gender. Although our phoneme model extends our observed misinterpretation results to new words, it is also confined by just the errors that appeared from querying the NSP dataset.Another limitation of our work is that we rely on the key assumption that triggering skills in a development environment works similarly to triggering publicly available skills. These checks seem not to be currently in place on Alexa, as we found 381 pairs of skills with different names, but likely to be squatted on the store (Section 5.4). Although this is a benign example, it demonstrates that some best practices from other third-party app store environments have not made their way to Alexa yet.Attacks against targeted user populations based on their demographic information are harder to defend against, as they require a deeper understanding of why such errors occur and how they may appear in the future. We suspect that with a larger set of words and speakers, we would not only be able to quantify other systematic errors in Alexa, but also draw stronger conclusions about the role of demographics in speech recognition systems.Measuring the Harms of Skill Squatting. In initial testing, we successfully built phishing attacks on top of skill squatting (for example, against the American Express skill) 1 . Our work builds on research from a number of disciplines, including linguistics, the human aspects of security and targeted audio attacks on voice-controlled systems.Dialects in Speech. Our work also draws on analysis of attack vectors that are beyond simply making mistakes -Kintis et al. studied the longitudinal effects of "combosquatting" attacks, which are variants of typosquatting [29]. If a user embellished their voice command with naturalistic speech, e.g.,"Alexa, open Sleep Sounds please" instead of "Alexa, open Sleep Sounds," an attacker may be able to register a skill named Sleep Sounds please in order to squat on the user's intended skill.