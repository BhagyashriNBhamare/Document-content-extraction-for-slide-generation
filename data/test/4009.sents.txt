The goal of searchable encryption (SE) is to enable a client to execute searches over encrypted files stored on an untrusted server while ensuring some measure of privacy for both the encrypted files and the search queries.
Most recent research has focused on developing efficient SE schemes at the expense of allowing some small, well-characterized "(information) leakage" to the server about the files and/or the queries.
The practical impact of this leakage, however, remains unclear.
We thoroughly study file-injection attacks-in which the server sends files to the client that the client then encrypts and stores-on the query privacy of single-keyword and conjunctive SE schemes.
We show such attacks can reveal the client's queries in their entirety using very few injected files, even for SE schemes having low leakage.
We also demonstrate that natural countermeasures for preventing file-injection attacks can be easily circumvented.
Our attacks outperform prior work significantly in terms of their effectiveness as well as in terms of their assumptions about the attacker's prior knowledge.
The goal of searchable encryption (SE) is to enable a client to perform keyword searches over encrypted files stored on an untrusted server while still guaranteeing some measure of privacy for both the files themselves as well as the client's queries.
In principle, solutions that leak no information to the server can be constructed based on powerful techniques such as secure * two-party computation, fully-homomorphic encryption, and/or oblivious RAM.
Such systems, however, would be prohibitively expensive and completely impractical [15].
In light of the above, researchers have focused on the development of novel SE schemes that are much more efficient, at the expense of allowing some information to "leak" to the server [19,9,8,11,6,16,12,20,13,5].
The situation is summarized, e.g., by Cash et al. [6]:The premise of [our] work is that in order to provide truly practical SSE solutions one needs to accept a certain level of leakage; therefore, the aim is to achieve an acceptable balance between leakage and performance.The question then becomes: what sort of leakage is acceptable?
Roughly speaking, and focusing on singlekeyword search for simplicity, current state-of-the-art schemes leak mainly two things: the query pattern (i.e., when a query is repeated) and the file-access pattern (namely, which files are returned in response to each query); these are collectively called L1 leakage in [4].
The prevailing argument is that L1 leakage is inconsequential in practice, and so represents a reasonable sacrifice for obtaining an efficient SE scheme.In truth, the ramifications of different types of leakage are poorly understood; indeed, characterizing the real-world consequences of the leakage of existing SE schemes was highlighted as an important open question in [6].
Recently, several groups have shown that even seemingly minor leakage can be exploited to learn sensitive information, especially if the attacker has significant prior knowledge about the client's files or the keywords they contain.
Islam et al. [10] (IKK12), who initiated this line of work, showed that if the server knows (almost) all the contents of the client's files, then it can determine the client's queries from L1 leakage.
Cash et al. [4] (CGPR15) gave an improved attack that works for larger keyword universes while assuming (slightly) less knowledge about the files of the client.
They also ex-plored the effects of even greater leakage, and showed how query-recovery attacks could serve as a springboard for learning further information about the client's files.A different attack for query recovery was given by Liu et al. [14].
The attack assumes a known distribution on the keywords being searched by the client, and works only after the client issues a large number of queries.
In this paper, we further investigate the consequences of leakage in SE schemes through the lens of file-injection attacks.
In such attacks, the server sends files of its choice to the client, who then encrypts and uploads them as dictated by the SE scheme.
This attack was introduced by Cash et al. [4], who called it a known-document attack.
As argued by those authors, it would be quite easy to carry out such attacks: for example, if a client is using an SE scheme for searching email (e.g., Pmail [2]), with incoming emails processed automatically, then the server can inject files by simply sending email to the client (from a spoofed email address, if it wishes to avoid suspicion).
We stress that the server otherwise behaves entirely in an "honest-but-curious" fashion.We show that file-injection attacks are devastating for query privacy: that is, a server can learn a very high fraction of the keywords searched by the client, by injecting a relatively small number of files.
Compared to prior work [10,4], our attacks are both more effective in terms of the fraction of queries recovered and far less demanding in terms of the prior information the server knows.
Our attacks differ in that the server must inject files, but as argued above this is easy to carry out in practice.We consider both adaptive and non-adaptive attacks, where adaptivity refers (in part) to whether the server injects files before or after the client's query is made.
In particular, a non-adaptive attack injects files that can be used to break all future queries; An adaptive attack crafts the injected files using leakage of previously-observed queries.
Our adaptive attacks are more effective, but assume the SE scheme does not satisfy forward privacy [7,20].
(Forward privacy means that the server cannot tell if a newly inserted file matches previous search queries.
With the exception of [7,20], however, all efficient SE schemes supporting updates do not have forward privacy.)
Our work thus highlights the importance of forward privacy in any real-world deployment.
We begin by showing a simple, binary-search attack that allows the server to learn 100% of the client's queries with no prior knowledge about the client's files.
We then propose an easy countermeasure: limiting the number of keywords that are indexed per file.
(We show that this idea is viable insofar as it has limited effect on the utility of searchable encryption.)
However, our attacks can be suitably modified to defeat this countermeasure, either using a larger number of injected files (but still no prior knowledge about the client's files) or based on limited knowledge-as low as 10%-of the client's files.
Our attacks still outperform prior work [10,4], having a significantly higher recovery rate and requiring a lower fraction of the client's files to be known.We additionally investigate the effectiveness of padding files with random keywords (suggested in [10,4]) as another countermeasure against our attacks.
We show that the performance of our attacks degrades only slightly when such padding is used, in contrast to prior attacks that fail completely.Finally, we initiate a study of the implications of leakage on conjunctive queries, and show how to extend our attacks to this setting.
Our attacks work against SE schemes having "ideal" leakage, but are even more effective against the scheme of Cash et al. [6] (the most efficient SE scheme allowing conjunctive queries), which suffers from larger leakage.
For the purposes of this paper, only minimal background about searchable encryption (SE) is needed.
At a high level, an SE scheme allows a client to store encrypted versions of its files on a server, such that at a later point in time the client can retrieve all files containing a certain keyword (or collection of keywords).
We assume a set of keywords K = {k 0 , k 1 ,.
.
.}
known to an attacker, and for simplicity view a file as an unordered set of keywords.
(Although the order and multiplicity of the keywords matter, and a file may contain non-keywords as well, these details are irrelevant for our purposes.)
We assume an SE scheme in which searching for some keyword k is done via the following process (all efficient SE schemes work in this way): first, the client deterministically computes a token t corresponding to k and sends t to the server; using t, the server then computes and sends back the file identifiers of all files containing keyword k. (These file identifiers need not be "actual" filenames; they can instead simply be pointers to the appropriate encrypted files residing at the server.)
The client then downloads the appropriate files.Because the token is generated deterministically from the keyword, the server can tell when queries repeat and thus learn the query pattern; the returned file identifiers reveal the file-access pattern.
Our attacks rely only on knowledge of the file-access pattern, though we additionally assume that the server can identify when a specific file identifier corresponds to some particular file injected k0 k1 k2 k3 k4 k5 k6 k7File 1: k0 k1 k2 k3 k4 k5 k6 k7File 2: k0 k1 k2 k3 k4 k5 k6 k7 If file 2 is returned in response to some token, but files 1 and 3 are not, the keyword corresponding to that token is k 2 .
by the server.
(The same assumption is made by Cash et al. [4].)
This is reasonable to assume, even if file identifiers are chosen randomly by the client, for several reasons: (1) the server can identify the file returned based on its length (even if padding is used to mitigate this, it is impractical to pad every file to the maximum file length); (2) in SE schemes supporting updates, the server can inject a file F and then identify F with the next (encrypted) file uploaded by the client; (3) if the server can influence the queries of the client, or even if it knows some of the client's queries, then the server can use that information to identify specific injected files with particular file identifiers.
We postpone further discussion to Section 8.
In this paper, we focus only on query-recovery attacks where the server observes various tokens sent by the client followed the file identifiers returned, and the server's goal is to determine the keywords corresponding to those tokens.
This violates query privacy, which is important in its own right, and-as noted by Cash et al. [4]-can also be leveraged to violate file privacy since it reveals (some of) the keywords contained in (some of) the files.
Our attacks show that the leakage of SE schemes should be analyzed carefully when SE is used as part of a larger system.
In this section, we present a basic query-recovery attack that we call the binary-search attack.
This attack does not require the server to have any knowledge about the client's files, and recovers all the keywords being searched by the client with 100% accuracy.
The basic observation is that if the server injects a file F containing exactly half the keywords from the keyword universe K, then by observing whether the token t sent by the client matches that file (i.e., whether F is returned in response to that token), the server learns one bit of information about the keyword corresponding to t. Using a standard non-adaptive version of binary search, the server can thus use 񮽙log |K|| injected files to determine the keyword exactly.
The idea is illustrated in Figure 1 for |K| = 8.
The attack is described more formally in the pseudocode of Figure 2.
We assume for simplicity that |K| is a power of 2, and identify K with the set {0,.
.
.
,|K| − 1} written in binary.
The attack begins by having the server generate a set F of log |K| files to be injected, where the ith file contains exactly those keywords whose ith mostsignificant bit is equal to 1.
At some point, 1 the server learns, for each injected file, whether it is returned in response to some token t.
We let R = r 1 r 2 ·· · denote the search results on the injected files, where r i = 1 if and only if the ith file is returned in response to the token.
For this attack, the server can deduce that the keyword corresponding to t is precisely R.Algorithm F ← Inject Files(K) 1: for i = 1,.
.
.
,log |K| do 2:Generate a file F i that contains exactly the keywords in K whose ith bit is 1.3: Output F = {F 1 ,.
.
.
,F log |K| }.
Algorithm k ← Recover(R, K)1: Return R as the keyword from universe K associated with the token.
The binary-search attack.
R denotes the search results for the token to be recovered on the injected files.We highlight again that for this attack, the files are generated non-adaptively and independent of the token t.
We note further that the same injected files can be used to recover the keywords corresponding to any number of tokens, i.e., once these files are injected, the server can recover the keywords corresponding to any future tokens sent by the client.
The number of injected files needed for this attack is quite reasonable; with a 10,000-keyword universe, a server who sends only one email per day to the client can inject the necessary files in just 2 weeks.Small keyword universe.
For completeness and future reference, we note that the binary-search attack can be optimized if the hidden keyword is known to lie in some smaller universe of keywords, or if the server only cares about keywords lying in some subset of the entire keyword universe (and gives up on learning the keyword if it lies outside this subset).
Specifically, the server can carry out the binary-search attack from Figure 2 based on any subset K 񮽙 ⊂ K of the keyword universe using only log |K 񮽙 | injected files.
A prominent feature of the binary-search attack is that the files that need to be injected for the attack each contain a large number of keywords, i.e., |K|/2 keywords per file.
We observe, then, that one possible countermeasure to our attack is to modify the SE scheme so as to limit the number of keywords per indexed file to some threshold T 񮽙 |K|/2.
This could be done either by simply not indexing files containing more than T keywords (possibly caching such files at the client), or by choosing at most T keywords to index from any file containing more than T keywords.The threshold T can be set to some reasonably small value while not significantly impacting the utility of the SE scheme.
For example, in the Enron email dataset [1] with roughly 5,000 keywords (see Section 5 for further details), the average number of keywords per email is 90; only 3% of the emails contain more than 200 keywords.
Using the threshold countermeasure with T = 200 would thus affect only 3% of the honest client's files, but would require the server to inject many more files in order to carry out a naive variant of the binary-search attack.
Specifically, the server could replace each file F i (that contains |K|/2 keywords) in the basic attack with a sequence of |K|/2T files F i,1 ,.
.
.
,F i,|K|/2T each containing T keywords, such that ∪ j F i, j = F i .
If any of these files is returned, this is equivalent to the original file F i being returned in the basic attack.
Note, however, that the server must now inject |K|/2T · log |K| files.
Unfortunately, as we explore in detail in the following section, the threshold countermeasure can be defeated using fewer injected files via more-sophisticated attacks.Note also that the threshold countermeasure does not affect the binary-search attack with small keyword universe K 񮽙 ⊂ K, as long as |K 񮽙 | ≤ 2T .
In this section, we present more-sophisticated attacks for when the threshold countermeasure introduced in the previous section is used.
In Section 4.1 we show an attack that uses fewer injected files than a naive modification of the binary-search attack, still without any knowledge of the client's files.
Then, in the following section, we show attacks that reduce the number of injected files even further, but based on the assumption that the server has information about some fraction of the client's files.
We noted earlier that the threshold countermeasure does not affect the binary-search attack with small keyword universe K 񮽙 ⊂ K if |K 񮽙 | ≤ 2T .
We can leverage this to learn keywords in the entire universe using what we call a hierarchical search attack.
This attack works by first partitioning the keyword universe into 񮽙|K|/T 񮽙 subsets containing T keywords each.
The server injects files containing the keywords in each subset to learn which subset the client's keyword lies in.
In addition, it uses the smalluniverse, binary-search attack on adjacent pairs of these subsets to determine the keyword exactly.
The algorithm is presented in Figure 3.
Algorithm F ← Inject Files hierarchical(K) 1: Partition the universe into w = 񮽙|K|/T 񮽙 sub- sets K 1 ,.
.
.
,K w of T keywords each.
2: for i = 1, 2,.
.
.
,w do 3:Generate F i containing every keyword k ∈ K i .4: for i = 1, 2,.
.
.
,w/2 do 5:F i ← Inject Files(K 2i−1 ∪ K 2i ).
6: Output F = {F 1 ,.
.
.
,F w , F 1 ,.
.
.
,F w/2 }.
Algorithm k ← Recover hierarchical(R, K) 1: Parse the search result R as R = {r 1 ,.
.
.
,r w , R 1 ,.
.
.
,R w/2 } ,corresponding to the results on the files in F described above.
2: Using the {r i }, identify the subset K 2x−1 ∪ K 2x the unknown keyword lies in.
We now calculate the number of injected files required by this attack.
In Step 3 of Inject Files hierarchical, the server injects 񮽙|K|/T 񮽙 files, and in Step 5 it injects 񮽙|K|/2T 񮽙 · ·log 2T 񮽙 files.
The total number of injected files is therefore at most3: k ← Recover(R x , K 2x−1 ∪ K 2x ).񮽙
|K|/2T 񮽙 · (񮽙log 2T 񮽙 + 2) .
In fact, for each i the first file in the set F i generated by Inject files(K 2i−1 ∪ K 2i ) is the same as F 2i−1 and the server does not need to inject it again.
Also, the server does not need to generate F w in Step 3 because if the keyword is not in F 1 ,.
.
.
,F w−1 then the server knows it must be in F w .
So the total number of injected files can be improved to񮽙|K|/2T 񮽙 · (񮽙log 2T 񮽙 + 1) − 1 .
When the size of the keyword universe is |K| = 5, 000 and the threshold is T = 200, the server needs to inject only 131 files, and the number of injected files grows linearly with the size of the keyword universe.
We highlight again that the same injected files can be used to recover the keywords corresponding to any number of tokens; i.e., once these files are injected, the server can recover the keywords of any future searches made by the client.We remark that an adaptive version of the above attack is also possible.
Here, the attacker would first inject 񮽙|K|/T 񮽙 − 1 files to learn what subset the unknown keyword lies in, and then carry out the small-universe, binary-search attack on a subset of size T .
This requires only 񮽙|K|/T 񮽙 + log T − 1 injected files, but has the disadvantage of being adaptive and hence requires the SE scheme to not satisfy forward privacy.
This version of the attack also has the disadvantage of targeting one particular search query of the client; additional files may need to be injected to learn the keyword used in some subsequent search query.
With the goal of further decreasing the number of injected files required to recover a token in presence of the threshold countermeasure, we now explore additional attacks that leverage prior information that the server might have about some of the client's files; we refer to the files known to the server as leaked files.
2 A similar assumption is used in prior work showing attacks on SE schemes [10,4]; previous attacks, however, require the server to know about 90% of the client's files to be effective (see Section 5), whereas our attacks work well even when the server knows a much smaller fraction of the client's files.Our attacks utilize the frequency of occurrence of the tokens and keywords in the client's files.
We define the frequency of a token (resp., keyword) as the fraction of the client's files containing this token (resp., keyword).
Similarly, we define the joint frequency of two tokens (resp., keywords) as the fraction of files containing both tokens (resp., keywords).
The server learns the exact frequency (resp., joint frequency) of a token (resp., pair of tokens) based on the observed search results.
The server obtains an estimate of the frequencies (resp., joint frequencies) of all the keywords based on the client's files that it knows.
We let f (t) denote the exact (observed) frequency of token t, and let f (t 1 ,t 2 ) be the joint frequency 2 We stress that our attacks only rely on the content of these leaked files; we do not assume the server can identify the file identifiers corresponding to the leaked files after they have been uploaded to the server.Algorithm k ← Inject Files Single(t, K)1: Let K 񮽙 be the set of 2T keywords with estimated frequencies closest to f (t).
of tokens t 1 ,t 2 .
We use f * (k) to denote the estimated frequency of keyword k, and define f * (k 1 , k 2 ) analogously.
Our attacks use the observation that if the leaked files are representative of all the client's files, then f (t) and f * (k) are close when t is the token corresponding to keyword k.2: F ← Inject Files(K 񮽙 ).
Algorithm k ← Recover Single(R, K 񮽙 ) 1: If R contains all 0s, output ⊥.
2: Else k ← Recover(R, K 񮽙 ).
Say the server obtains a token t sent by the client, having observed frequency f (t).
The server first constructs a candidate universe K 񮽙 for the keyword corresponding to t consisting of the 2T keywords whose estimated frequencies are closest to f (t).
The server then uses the small-universe, binary-search attack to recover the keyword exactly.
In this way, the number of injected files is only 񮽙log 2T 񮽙.
The attack is presented in detail in Fig- ure 4.
Differences from attacks in previous sections.
The attack just described is adaptive, in that it targets a particular token t and injects files whose contents depend on the results of a search using t.
This means the attack only applies to SE schemes that do not satisfy forward privacy.
It also means that the attack needs to be carried out again in order to learn the keyword corresponding to some other token.Another difference from our previous attacks is that this attack does not work with certainty.
In particular, if the observed and estimated frequencies are far apart, or the number of keywords whose estimated frequencies are close to the observed frequency is larger than 2T , the server may fail to recover the keyword corresponding to the token.
On the other hand, the server can tell whether the attack succeeds or not, so will never associate an incorrect keyword with a token.
This also means that if the attack fails, the attacker can re-run the attack with a different candidate universe, or switch to using one of our earlier attacks, in order to learn the correct keyword.
(We rely on this feature to design an attack for multiple tokens in the following section.)
This is in contrast to earlier attacks [10,4], where the attacker cannot always tell whether the keyword was recovered correctly.
To learn the keywords corresponding to m tokens, the server can repeat the attack above for each token, but then the number of injected files will be (in the worst case) m · ·log 2T 񮽙.
A natural way to attempt to reduce the number of injected files is for the server to determine a candidate universe of size 2T for each token and then use the union of those candidate universes when injecting the files.
In that case, however, the union would almost surely contain more than 2T keywords, in which case the number of keywords in the files produce by the binarysearch attack will exceed the threshold T .
A second approach would be for the server to make the size of the candidate universe for each token 2T /m, so the size of their union cannot exceed 2T keywords.
Here, however, if m is large then the candidate universe for each token is very small and so the probability of the corresponding keyword not lying in its candidate universe increases substantially.
Therefore, the recovery rate of this attack would be low.Instead, we propose a more-complex attack that recovers multiple tokens by taking into account the joint frequencies for tokens and keywords.
Our attack has two main steps (see Figure 5):1.
First, we recover the keywords corresponding to a subset of the tokens, namely the n 񮽙 m tokens with the highest observed frequencies.
We recover the keywords using the second approach sketched above, which works (with few injected files) because n is small.
This gives us as a set of tokens and their associated keywords as "ground truth.
"2.
Given the ground truth, we recover the keyword associated with some other token t 񮽙 using the following observation: if k 񮽙 is the keyword corresponding to t 񮽙 , then the observed joint frequency f (t,t 񮽙 ) should be "close" to the estimated joint frequency f * (k, k 񮽙 ) for all pairs (t, k) in our ground-truth set, where "closeness" is determined by a parameter δ .
By discarding candidate keywords that do not satisfy this property, we are left with a small set K 񮽙 of candidate keywords for t 񮽙 .
If the candidate universe of keywords for each token is small enough, then even their union will be small.
We then use a small-universe, binary-search attack to recover the corresponding keywords exactly.Note that in the above attack the ability to tell whether a token is recovered correctly when building the ground truth is crucial-otherwise the ground-truth set could contain many incorrect associations.Parameter selection.
Our attack has two parameters: n and δ .
A larger value of n means that the ground-truth set can potentially be larger, but if n is too large then there is a risk that the candidate universe K t (comprising the 2T /n keywords with estimated frequencies closest to f (t)) will not contain the true keyword corresponding to t.
In our experiments, we set n heuristically to a value that achieves good performance.
The value of δ is chosen based on statisticalestimation theory.
The estimated joint frequency is an empirical average computed from a collection of leaked files assumed to be sampled uniformly from the set of all files.
Thus, we set δ such that if keywords k, k 񮽙 correspond to tokens t,t 񮽙 , respectively, then the estimated joint frequency f * (k, k 񮽙 ) is within ±δ · f * (k, k 񮽙 ) of the true value f (t,t 񮽙 ) at least 99% of the time.Ground-truth set selection.
When building the groundtruth set, we recover the keywords associated with those tokens having the highest observed frequencies.
We do so because those keywords can be recovered correctly with higher probability, as we explain next.If the leaked files are chosen uniformly from the set of all files, then using statistical-estimation theory as above the attacker can compute a value δ such that at least 99% of the time it holds that | f * (k) − f (t)| ≤ ε · f * (k), where k denotes the (unknown) keyword corresponding to t. Thus, if the attacker sets the candidate universe K t to be the set of all keywords whose estimated frequencies are within distance ε · f * (k) of f (t), the candidate universe will include the keyword corresponding to t at least 99% of the time.
The problem with taking this approach is that the set K t constructed this way may be too large.If we assume a Zipfian distribution [3] for the keyword frequencies, however, then the size of K t as constructed above is smallest when f (t) is largest.
(This is a consequence of the fact that the Zipfian distribution places high probability on a few items and low probability on many items.)
In particular, then, the set of 2T /n keywords with estimated frequencies closest to f (t) (as chosen by our algorithm), will "cover" all keywords within distance ε · f * (k) of f (t) from f (t) -or, equivalently, the candidate universe will contain the true keyword k -with high probability.
We simulate the attacks from Section 4.
(We do not run any simulations for the binary-search attack described in Section 3, since this attack succeeds with probability 1, injecting a fixed number of emails.)
We compare our attacks to our own implementation of the attacks by Cash t = {t 1 ,.
.
.
,t m } is the set of m tokens whose keywords we wish to recover.
Algorithm k ← Attack Multiple Tokens(t, K) Build ground truth set G.1: Sort tokens in t according to their exact frequencies f (t).
Let t 1 denote the n tokens with highest observed frequencies.
2: for each token t in t 1 do 3: Set its candidate universe K t as the set of 2T n keywords with estimated frequencies f * (k) nearest to f (t).
4: Define K 񮽙 = ∪ t∈t 1 K t and inject files generated by F 1 ← Inject Files(K 񮽙 ).
5: for each token t in t 1 do Let R t be the search result of token t on files F 1 .
if R t is not all 0s then 8:k t ← Recover(R t , K 񮽙 ).
9: Add (t, k t ) to G.Recover the remaining tokens, let t 2 be the set of unrecovered tokens.10: for each token t 񮽙 ∈ t 2 do 11: Set its candidate universe K t 񮽙 as the set of 2T keywords with estimated frequencies f * (k) nearest to f (t 񮽙 ).
for each keyword k 񮽙 ∈ K t 񮽙 do 13: for each token/keyword pair (t, k) ∈ G do 14: If | f (t,t 񮽙 ) − f * (k, k 񮽙 )| > δ · f * (k, k 񮽙 ), For our experiments we use the Enron email dataset [1], consisting of 30,109 emails from the "sent mail" folder of 150 employees of the Enron corporation that were sent between 2000-2002.
We extracted keywords from this dataset as in CGPR15: words were first stemmed using the standard Porter stemming algorithm [18], and we then removed 200 stop words such as "to," "a," etc.
Doing so results in approximately 77,000 keywords in total.In our experiments, we chose the top 5,000 most frequent keywords as our keyword universe (as in CGPR15).
We assumed the threshold countermeasure with T = 200.
As discussed earlier, only 3% of the files contained more than this many keywords.We could not find real-world query datasets for email.
Therefore, in our experiments we choose the client's queries uniformly from the keyword universe, as in CGPR15.
(However, our attacks do not use any information about the distribution of the queries.)
Leaked files are chosen uniformly from the base set of 30,109 emails, and the percentage of leaked files was varied from 1% to 100%.
For each value of the file-leakage percentage, we repeat the attack on 100 uniform sets of queries (containing either one token or 100 tokens) and 10 uniformly sampled sets of leaked files of the appropriate size; we report the average.
We do not include error bars in our figures, but have observed that the standard deviation in our experiments is very small (less than 3% of the average).
The performance of our attack for recovering the keyword associated with a single token (described in Section 4.2.1) is displayed in Figure 6.
The server only needs to inject 񮽙log 2T 񮽙 = 9 files in order to carry out the attack.
It can be observed that our attack performs quite well even with only a small fraction of leaked files, e.g., recovering the keyword about 70% of the time once only 20% of the files are leaked, and achieving 30% recovery rate even when given only 1% of the files.Neither the IKK12 attack nor the CGPR15 attack applies when the server is given the search results of only a single token.
To provide a comparison with our results, we run the CGPR15 attack by giving it the search results of 100 tokens (corresponding to uniformly chosen keywords) and then measure the fraction of keywords recovered.
As shown in Figure 6, the CGPR15 attack recovers a keyword with probability less than 20% even when 95% of the client's files are leaked.
Of course, our attack model is stronger than the one considered in CGPR15.
We have also implemented our attack from Section 4.2.2 which can be used to recover the keywords corresponding to multiple tokens.
In our experiments, we target the recovery of the keywords associated with m = 100 tokens; we choose n = 10, and set δ as described in Section 4.2.2.
Figure 7a tabulates the fraction of keywords recovered by our attack, and compares it to the fraction recovered by the CGPR15 attack.
(As noted in the previous section, the CGPR15 attack inherently requires search results for multiple tokens; this explains why the results for the CGPR15 attack in Figure 7a are almost identical to the results for their attack in Figure 6.)
Both attacks do well when the fraction of leaked files is large, however the recovery rate of the CFPR15 attack drops dramatically as the fraction of leaked files decreases.
In contrast, our attack continues to perform well, recovering 65% of the keywords given access to 50% of the client's files, and still recovering 20% of the keywords when only 10% of the client's files have been leaked.
We stress that in our attack the server knows which keywords have been recovered correctly and which have not, something that is not the case for prior attacks.
Figure 7b shows the number of files that need to be injected in order to carry out our attack.
The number of files injected never exceeds 40, and in many cases it is even less than that.
We also highlight that the number of files injected to recover the keywords associated with 100 tokens is more than an order-of-magnitude smaller than 100× the number of files injected to recover the keyword associated with a single token in the previous section.The number of files injected by our attack first increases with the fraction of leaked files, and then decreases; we briefly explain why.
The number of files injected in step 1 of our attack is independent of the fraction of leaked files.
The number of files injected in step 2 of the attack depends on both the number of unrecovered tokens (i.e., the size of t 2 ) and the average size of the candidate universe for each unrecovered token t 񮽙 (i.e., the size of K t 񮽙 ).
When the fraction of leaked files is very small, the estimated joint frequencies are far from the true frequencies and, in particular, most estimated joint frequencies are 0; thus, many keywords are removed from K t 񮽙 and hence the size of K t 񮽙 is low.
The net result is that the recovery rate is small, but so is the number of injected files.
As the fraction of leaked files increases, more keywords are included in K t 񮽙 , leading to higher recovery rate but also more injected files.
When the fraction of leaked files becomes very high, however, the estimated frequencies are very close to the true frequencies and so more keywords are recovered in step 1 of the attack.
This leaves fewer unrecovered tokens in step 2, leading to fewer injected files overall even as the recovery rate remains high.
Prior work [10,4] suggests keyword padding as another potential countermeasure for attacks that exploit the fileaccess pattern.
The basic idea is to distort the real frequency of each keyword k by randomly associating files that do not contain that keyword with k; this is done at setup time, when the client uploads its encrypted files to the server.
One version of the countermeasure [4] ensures that the number of files returned in response to any search result is a multiple of an integer λ .
A stronger version of the countermeasure [10] involves performing the padding in such a way that for any keyword k there are at least α − 1 other keywords having the same frequency.
These countermeasures defeat the attacks in prior work, but we show that they have little effect on our attacks.We remark that keyword padding seems difficult to apply in the dynamic setting, where new files are uploaded after the initial setup done by the client.
The dynamic case is not discussed in [10,4].
Even when keyword padding is used, our binary-search and hierarchical-search attacks will recover the keyword k corresponding to some token t unless one of the injected files that does not contain k is returned in response to the search using t.
We show that the probability of this bad event is small, focusing on the binarysearch attack for concreteness.
Say 񮽙 of the files contain k and that, after keyword padding, an additional β · 񮽙 random and independently chosen files (in expectation) that do not contain k are returned in response to the search using t. (By setting parameters appropriately, this roughly encompasses both the countermeasures described above.)
Now consider some file injected as part of the binary-search attack that does not contain k.
The probability that this file is chosen as one of the spurious files returned in response to the search using t is β 񮽙/(F − 񮽙), where F is the total number of files (including the injected files).
Since 񮽙log |K|| files are injected, the overall probability that the bad event occurs is at most1 − 񮽙 1 − β 񮽙 (F − 񮽙) 񮽙 񮽙log |K|| .
In fact, this is an over-estimate since if k is uniform then on average only half the injected files contain k.For the Enron dataset with |K| = 5, 000, F = 30, 109, 񮽙 = 560, and β = 0.6, and assuming half the injected files contain the keyword in question, the probability that the binary-search attack succeeds is 0.93.
(In fact, β = 0.6 is quite high, as this means that more than 1/3 of the files returned in response to a query do not actually contain the searched keyword.)
With β = 0.6 the IKK12 and CGPR15 attacks recover no keywords at all.
Although our attacks with partial file leakage use information about keyword frequencies and joint frequencies, they are still not significantly affected by the padding countermeasures.
The reason is that although the padding ensures that a given frequency no longer suffices to uniquely identity a keyword, the frequency of any particular keyword doesn't change very much.
Thus, the exact frequency and the estimated frequency of any keyword remain close even after the padding is done, and the underlying keyword is still likely to be included in the candidate universe of a target token.
As long as this occurs, the search step recovers the token with high probability as discussed in the previous section.
This is even more so the case with regard to joint frequencies, since these do not change unless two keywords are both associated with the same random file that contains neither of those keywords, something that happens with low probability.To validate our argument, we implement the padding countermeasure proposed in [4] and repeat the experiments using our attacks.
As shown in Figures 8 and 9, the recovery rate of our attacks degrades only slightly when keyword padding is used.
Figure 10 compares the effectiveness of our attack to the CGPR15 attack when keyword padding is used.
The recovery rate of the CGPR15 attack drops dramatically in the presence of this countermeasure.
In particular, it recovers only 57% of the tokens even with 100% file leakage when β = 0.2, and recovers nothing even with 100% file leakage when β = 0.6.
In contrast, our attack still recovers almost the same number of keywords as when no padding is used.
SE schemes supporting conjunctive queries allow the client to request all files containing some collection of keywords k 1 , k 2 ,.
.
.
,k d .
The naive way to support conjunctive queries is to simply have the client issue queries for each of these keywords individually; the server can compute the set of file identifiers S i containing each keyword k i and then take their intersection to give the final result.
Such an approach leaks more information than necessary: specifically, it leaks each of S 1 ,.
.
.
,S d rather than the final result ∩S i alone.
We refer to ∩S i as the ideal access-pattern leakage for a conjunctive query, and show attacks based only on such ideal leakage.
We remark, however, that no known efficient SE scheme achieves ideal leakage.
For example, the scheme by Cash et al. [6] leaks S 1 , S 1 ∩ S 2 , S 1 ∩ S 3 ,.
.
.
,S 1 ∩ S d .
Such additional leakage can only benefit our attacks.Throughout this section, we assume the threshold countermeasure is not used and so injected files can contain any number of keywords.
(Our attacks here could be generalized as done previously in case the threshold countermeasure is used.)
We first present a non-adaptive attack to recover the keywords used in a conjunctive query involving two keywords.
As in the non-adaptive attacks in prior sections, the attacker can recover the keywords corresponding to any future queries after injecting some initial set of files.The idea is the following.
Say the conjunctive search query involves keywords k 1 and k 2 , and we can partition the universe of keywords into two sets K 1 and K 2 with k 1 ∈ K 1 and k 2 ∈ K 2 .
We can then use a variant of the binary-search attack in which we inject files generated by Inject Files(K 1 ), where we additionally include all keywords in K 2 .
Since these files always contain k 2 , the search results of the conjunctive query on these injected files is exactly the same as the search results of k 1 on these files, and we can thus recover k 1 as before.
We can proceed analogously to recover k 2 .
The problem with the above is that we do not know, a priori, how to partition K into sets K 1 , K 2 as required.
Instead, we generate a sequence of log |K| partitions {(K i 1 , K i 2 )} such that for some partition i it holds that k 1 ∈ K i 1 and k 2 ∈ K i 2 .
This is done by simply letting K i 1 be the set of all keywords whose ith bit is 0, and K i 2 be the complement.
Since k 1 and k 2 are distinct, they must differ on at least one position, say i, and satisfy the desired separation property on the ith partition.
By repeating the attack described earlier for each partition, we obtain an attack using log 2 |K| + log |K| injected files (after removing duplicates).
The attack is described in detail in Fig- ure 11.
Given ideal access-pattern leakage, the above attack above only works for conjunctive queries involving two keywords.
For conjunctive searches using the SE scheme of Cash et al. [6], though, the above attack can be extended to work for conjunctive queries involving any number of keywords since the pairwise intersections are leaked as described earlier.
The attack in Section 7.1 only works for conjunctive queries involving two keywords, and uses O(log 2 |K|) injected files.
Here we present a non-adaptive attack that can recover conjunctive queries involving any number of keywords using only O(log |K|) injected files, and still assuming only ideal access-pattern leakage.
In contrast Let q be a conjunctive query with two keywords.Algorithm F ← Inject Files Disjoint(K 1 , K 2 ) 1: F ← Inject Files(K 1 ).2: Include all keywords in K 2 in every file in F. Algorithm F ← Inject Files Conjunctive(K)1: for i = 1, 2,.
.
.
,log |K| do 2:Let K i 1 contain keywords whose ith bit is 0, and let K i 2 = K \ K i 1 .
Generate file F i 1 that contains all keywords in K i 1 and file F i 2 that contains all keywords in K i 2 .4:F i 1 ← Inject Files Disjoint(K i 1 , K i 2 ).5:F i 2 ← Inject Files Disjoint(K i 2 , K i 1 ).
6: Output F = {F i 1 , F i 2 , F i 1 , F i 2 , for all i}.
Algorithm k ← Recover Conjunctive(q, K, F) 1: Let R q = {r i 1 , r i 2 , R i 1 , R i 2 } for i = 1,...,log |K| be the search result of query q on the files F described above.
2: Find i such that neither F i 1 nor F i 2 is in the search result (i.e., to the previous attack, however, this attack does not always succeed.r i 1 = r i 2 = 0).
3: k 1 ← Recover(R i 1 , K i 1 ).
4: k 2 ← Recover(R i 2 , K i 2 ).
5: Output (k 1 , k 2 ).
Consider a conjunctive query q involving d keywords.
The basic idea is to inject n files, each containing L keywords selected uniformly and independently from the keyword universe.
If parameters are set appropriately, the search result on q will include some of the injected files with high probability.
By definition, each of those files contains all d keywords involved in the query, and hence the intersection of those files also contains all those keywords.
We claim that when parameters are set appropriately, the intersection contains no additional keywords.
Thus, the server recovers precisely the d keywords involved in the query by simply taking the intersection of the injected files returned in response to the query.
The following theorem formalizes this idea.
Proof.
Fix some conjunctive query q involving d keywords.
The probability that any particular injected file matches the query is approximately (L/|K|) d = 1/2 since each of the d keywords is included in the file with probability roughly L/|K|.
Since each file is generated independently, the expected number of files that match the query is n/2; moreover, the number n 񮽙 of files that match the query follows a binomial distribution and so the Chernoff bound impliesPr 񮽙 񮽙 񮽙 񮽙n 񮽙 − n 2 񮽙 񮽙 񮽙 ≥ θ √ n 2 񮽙 ≤ e −θ 2 /2 .
Setting θ = ε √ n 2(2+ε) , we have Pr 񮽙 n 񮽙 ≤ 񮽙 1 + ε 4 񮽙 d log |K| 񮽙 ≤ e − θ 2 2 .
Thus, n 񮽙 > (1 + ε 4 )d log |K| with overwhelming probability.The probability that any other keyword is in all these n 񮽙 files is extremely low.
Specifically, for any fixed keyword not involved in the query, the probability that it lies in all n 񮽙 files is (L/|K|) n 񮽙 .
Thus, the probability that no other keyword lies in all n 񮽙 files is񮽙 1 − 񮽙 L |K| 񮽙 n 񮽙 񮽙 |K|−d ≈ 񮽙 1 − 1 |K| 1+ε/4 񮽙 |K| (assuming d 񮽙 |K|).
The above simplifies to e −1/|K| ε/4 .
Note that for any ε > 0 the bound given by the theorem approaches 1 as |K| tends to infinity.
We experimentally verified the bound in the theorem for |K| = 5, 000 and d = 3.
For example, setting ε = 1 we obtain an attack in which the server injects n = 110 files with L = 3, 969 keywords each, and recovers all keywords involved in the conjunctive query with probability 0.97.
For completeness, we remark that the server can tell whether it correctly recovers all the keywords or not, assuming d is known.
We can further reduce the number of injected files using an adaptive attack.
The idea is to recover the keywords involved in the query one-by-one, starting with the lexicographically largest, using an adaptive binary search for each keyword.
The server first injects a file containing the first |K|/2 keywords.
There are two possibilities:1.
If this file is in the search result for the query, the server learns that all the keywords involved in the query have index at most |K|/2.
It will next inject a file containing the first |K|/4 keywords.2.
If this file is not in the search result for the query, the server learns that at least one keyword involved in the query has index greater than |K|/2.
It will next inject a file containing the first 3|K|/4 keywords.Proceeding in this way, the server learns the lexicographically largest keyword using log |K| injected files.
Once that keyword k d is recovered, the server repeats this attack but with k d always included in the injected files to learn the next keyword, and so on.
See Figure 12.
Let q be a conjunctive query with keyword k 1 ,.
.
.
,k d .
Algorithm k ← Attack Conjunctive(q, K)1: Initialize k = / 0.
2: for i = d,.
.
.
,1 do 3: Set K i = K \ k, set b = |K i |/2.
for j = 2,.
.
.
,log |K i | do Inject F that contains the first b keywords in K i and all keywords in k. Let R q be the search result of query q on F. if R q = 1 then 8:b = b − |K i |/2 j .
9:else 10:b = b + |K i |/2 j .
11:Inject F that contains the first b keywords in K i and all keywords in k. Let R q be the search result of query q on F. if R q = 1 then 14:Recover k i as the bth keyword in K i .
The number of injected files is d log |K|.
We remark that d need not be known in advance, since the attacker can determine d during the course of the attack.
It is also worth observing that the number of injected files is essentially optimal for a deterministic attack with success probability 1, because the search results on d log |K| files contain at most d log |K| bits of information, which is roughly the entropy of a conjunctive search involving d keywords from a universe of size |K|.
In this section, we briefly discuss some other potential countermeasures against our attacks.Semantic filtering.
One may be tempted to think that the files injected by our attacks will not "look like" normal English text, and can therefore be filtered easily by the client.
We argue that such an approach is unlikely to prevent our attacks.
First, although as described our attacks inject files containing arbitrary sets of keywords, the server actually has some flexibility in the choice of keywords; e.g., the binary-search attack could be modified to group sets of keywords that appear naturally together.
Second, within each injected file, the server can decide the order and number of occurrences of the keywords, can choose variants of the keywords (adding "-ed" or "-s," for example), and can freely include non-keywords ("a," "the," etc.) There are several tools (e.g., [21]) that can potentially be adapted to generate grammatically correct text from a given set of keywords by ordering keywords based on n-grams trained from leaked files and simple grammatical rules.
A detailed exploration is beyond the scope of our paper.Batching updates.
As mentioned in Section 2, even if the client shuffles the file identifiers and pads all files to the same length, the server can identify an injected file based on the time at which it is inserted by the client.
This suggests a (partial) countermeasure that can be used in dynamic SE schemes that support updates: rather than uploading each new file as it arrives, the client should wait until there are several (say, B) new files and then upload this "batch" of B files at once.
Assuming only one of those files was injected by the server, this means the server only learns that the injected file corresponds to one of B possibilities.
This countermeasure can be trivially circumvented if the server can inject B files before any other new files arrive.
(If the server additionally has the ability to mount chosen-query attacks-something we have not otherwise considered in this paper-then the total number of injected files remains the same.)
Even if the server can inject only B 񮽙 < B identical 3 files into a single "batch," the server knows that if fewer than B 񮽙 files from this batch are returned in response to some query, then the injected files do not match that query.
Finally, even if the server can only inject a single file per "batch," the server can inject the same file repeatedly and with high confidence determine based on the search results whether the file matches some query.
We leave a more complete analysis of this countermeasure for future work.
Our paper shows that file-injection attacks are devastating for query privacy in searchable encryption schemes that leak file-access patterns.
This calls into question the utility of searchable encryption, and raises doubts as to whether existing SE schemes represent a satisfactory tradeoff between their efficiency and the leakage they allow.
Nevertheless, we briefly argue that searchable encryption may still be useful in scenarios where file-injection attacks are not a concern, and then suggest directions for future research.We have argued that file-injection attacks would be easy to carry out in the context of searching email.
But in "closed systems," where a client is searching over records generated via some other process, file-injection attacks may not be possible or may be much more difficult to carry out.
Additionally, there may be settingse.g., when all files have the same length because they share some particular format-where even though the server can inject files, it may not be able to associate file identifiers with specific files it has injected.
It is worth noting also that there may be applications of SE in which the server is trusted (and so, in particular, can be assumed not to carry out file-injection attacks), and the threat being defended against is an external attacker who compromises the server.
4 Our work and previous work [10,4] demonstrate that leaking file-access patterns in their entirety is dangerous, and can be exploited by an attacker to learn a significant amount of sensitive information.
We suggest, therefore, that future research on searchable encryption focus on reducing or eliminating this leakage rather than accepting it as the default.
Our work also highlights the need to design efficient schemes satisfying forward privacy.
Addressing these challenges may require exploring new directions, such as interactive protocols [17] or multiple servers.
It would also be of interest to explore lower bounds on the efficiency that searchable encryption can achieve as a function of how much about the file-access pattern is leaked.
