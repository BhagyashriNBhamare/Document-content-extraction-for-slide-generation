While kernel drivers have long been know to poses huge security risks, due to their privileged access and lower code quality, bug-finding tools for drivers are still greatly lacking both in quantity and effectiveness.
This is because the pointer-heavy code in these drivers present some of the hardest challenges to static analysis, and their tight coupling with the hardware make dynamic analysis infeasible in most cases.
In this work, we present DR. CHECKER, a soundy (i.e., mostly sound) bug-finding tool for Linux kernel drivers that is based on well-known program analysis techniques.
We are able to overcome many of the inherent limitations of static analysis by scoping our analysis to only the most bug-prone parts of the kernel (i.e., the drivers), and by only sacrificing soundness in very few cases to ensure that our technique is both scalable and precise.
DR. CHECKER is a fully-automated static analysis tool capable of performing general bug finding using both pointer and taint analyses that are flow-sensitive, context-sensitive, and field-sensitive on kernel drivers.
To demonstrate the scala-bility and efficacy of DR. CHECKER, we analyzed the drivers of nine production Linux kernels (3.1 million LOC), where it correctly identified 158 critical zero-day bugs with an overall precision of 78%.
Bugs in kernel-level code can be particularly problematic in practice, as they can lead to severe vulnerabilities, which can compromise the security of the entire computing system (e.g., Dirty COW [5]).
This fact has not been overlooked by the security community, and a significant amount of effort has been placed on verifying the security of this critical code by means of manual inspection and both static and dynamic analysis techniques.
While manual inspection has yielded the best results historically, it can be extremely time consuming, and is quickly becoming intractable as the complexity and volume of kernel-level code increase.
Low-level code, such as kernel drivers, introduce a variety of hard problems that must be overcome by dynamic analysis tools (e.g., handling hardware peripherals).
While some kernel-level dynamic analysis techniques have been proposed [23,25,29,46], they are ill-suited for bug-finding as they were implemented as kernel monitors, not code verification tools.
Thus, static source code analysis has long prevailed as the most promising technique for kernel code verification and bug-finding, since it only requires access to the source code, which is typically available.Unfortunately, kernel code is a worst-case scenario for static analysis because of the liberal use of pointers (i.e., both function and arguments are frequently passed as pointers).
As a result, tool builders must make the tradeoff between precision (i.e., reporting too many false positives) and soundness (i.e., reporting all true positives).
In practice, precise static analysis techniques have struggled because they are either computationally infeasible (i.e., because of the state explosion problem), or too specific (i.e., they only identify a very specific type of bug).
Similarly, sound static analysis techniques, while capable of reporting all bugs, suffer from extremely high false-positive rates.
This has forced researchers to make variety of assumptions in order to implement practical analysis techniques.
One empirical study [14] found that users would ignore a tool if its false positive rate was higher than 30%, and would similarly discredit the analysis if it did not yield valuable results early in its use (e.g., within the first three warnings).
Nevertheless, numerous successful tools have been developed (e.g., Coverity [14], Linux Driver Verification [36], APISan [64]), and have provided invaluable insights into both the types and locations of bugs that exist in critical kernel code.
These tools range from precise, unsound, tools capable of detecting very specific classes of bugs (e.g., data leakages [32], proper fprintf usage [22], user pointer deferences [16]) to sound, im-precise, techniques that detect large classes of bugs (e.g., finding all usages of strcpy [55]).
One notable finding early on was that a disproportionate number of errors in the kernel were found in the drivers, or modules.
It was shown that drivers accounted for seven times more bugs than core code in Linux [19] and 85% of the crashes in Windows XP [49].
These staggering numbers were attributed to lower overall code quality in drivers and improper implementations of the complex interactions with the kernel core by the third party supplying the driver.In 2011, Palix et al. [39] analyzed the Linux kernel again and showed that while drivers still accounted for the greatest number of bugs, which is likely because drivers make up 57% of the total code, the fault rates for drivers where no longer the highest.
Our recent analysis of main line linux kernel commit messages found that 28% of CVE patches to the linux repository in the past year involved kernel drivers (19% since 2005), which is in line with previous studies [17].
Meanwhile, the mobile domain has seen an explosion of new devices, and thus new drivers, introduced in recent years.
The lack of attention being paid to these drivers, and their potential danger to the security of the devices, has also not gone unnoticed [47].
Recent studies even purport that mobile kernel drivers are, again, the source of up to 85% of the reported bugs in the Android [48] kernel.
Yet, we are unaware of any large-scale analysis of these drivers.In this work, we present DR. CHECKER, a fullyautomated static-analysis tool capable of identifying numerous classes of bugs in Linux kernel drivers.
DR. CHECKER is implemented as a completely modular framework, where both the types of analyses (e.g., points-to or taint) and the bug detectors (e.g., integer overflow or memory corruption detection) can be easily augmented.
Our tool is based on well-known program analysis techniques and is capable of performing both pointer and taint analysis that is flow-, context-, and field-sensitive.
DR. CHECKER employs a soundy [31] approach, which means that our technique is mostly sound, aside from a few well-defined assumptions that violate soundness in order to achieve a higher precision.
DR. CHECKER, is the first (self-proclaimed) soundy static-analysis-based bug-finding tool, and, similarly, the first static analysis tool capable of large-scale analysis of general classes of bugs in driver code.
We evaluated DR. CHECKER by analyzing nine popular mobile device kernels, 3.1 million lines of code (LOC), where it correctly reported 3,973 flaws and resulted the discovery of 158 [6][7][8][9][10] previously unknown bugs.
We also compared DR. CHECKER against four other popular static analysis tools, where it significantly outperformed all of them both in detection rates and total bugs identified.
Our results show that DR. CHECKER not only produces useful results, but does so with extremely high precision (78%).
In summary, we claim the following contributions:• We present the first soundy static-analysis technique for pointer and taint analysis capable of large-scale analysis of Linux kernel drivers.
• We show that our technique is capable of flowsensitive, context-sensitive, and field-sensitive analysis in a pluggable and general way that can easily be adapted to new classes of bugs.
• We evaluated our tool by analyzing the drivers of nine modern mobile devices, which resulted in the discovery of 158 zero-day bugs.
• We compare our tool to the existing state-of-theart tools and show that we are capable of detecting more bugs with significantly higher precision, and with high-fidelity warnings.
• We are releasing DR. CHECKER as an open-source tool at github.com/ucsb-seclab/dr_checker.
Kernel bug-finding tools have been continuously evolving as both the complexity and sheer volume of code in the world increases.
While manual analysis and grep may have been sufficient for fortifying the early versions of the Linux kernel, these techniques are neither scalable nor rigorous enough to protect the kernels that are on our systems today.
Ultimately, all of these tools are developed to raise warnings, which are then examined by a human analyst.
Most of the initial, and more successful bug-finding tools were based on grep-like functionality and pattern matching [45,55,57].
These tools evolved to reduce user interaction (i.e., removing the need for manual annotation of source code) by using machine learning and complex data structures to automatically identify potential dangerous portions of code [41,[59][60][61][62][63].
While these tools have been shown to return useful results, identifying a number of critical bugs, most of them are developed based on empirical observation, without strong formal guarantees.
Model checkers (e.g., SLAM [13], BLAST [27], MOPS [18]) provide much more context and were able to provide more formalization, resulting in the detection of more interesting flaws.
However, these techniques soon evolved into more rigorous tools, capable of more complex analyses (e.g., path-sensitive ESP [22]) and the more recent tools are capable of extracting far more information about the programs being analyzed to perform even more in-depth analysis (e.g., taint analysis [61]).
While some have been implemented on top of custom tools and data structures (e.g., Joern [59][60][61][62]), others have been implemented as compiler-level optimizations on top of popular open-source projects (e.g., LLVM [32]).
In all cases, these tools are operating on abstract representations of the program, such as the abstract syntax tree (AST) or the control flow graph (CFG), which permit a more rigorous formal analysis of the properties of the program.Motivation.
Before delving into the details of DR. CHECKER, we first present a motivating example in the form of a bug that was discovered by DR. CHECKER.In this bug, which is presented in Listing 1, a tainted structure is copied in from userspace using copy from user.
A size field of this structure is then multiplied by the size of another driver structure (flow p.cnt * sizeof(struct bst traffic flow prop)), which is vulnerable to an integer overflow.
This bug results in a much smaller buffer being allocated that would actually be required for the data.
This overflow would not be particularly problematic if it wasn't for the fact that the originally tainted length (i.e., the very large number) is later used to determine how much data will be copied in Listing 1: An integer overflow in Huawei's Bastet driver that was discovered by DR. CHECKER 1 s t r u c t b s t t r a f f i c f l o w p k g { 2 u i n t 3 2 t c n t ; the buffer (adjust traffic flow by pkg(buf, flow p.cnt)), resulting in memory corruption.There are many notable quirks in this bug that make it prohibitively difficult for na¨ıvena¨ıve static analysis techniques.
First, the bug arises from tainted-data (i.e., argp) propagating through multiple usages into a dangerous function, which is only detectable by a flowsensitive analysis.
Second, the integer overflow occurs because of a specific field in the user-provided struct, not the entire buffer.
Thus, any analysis that is not field sensitive would over-approximate this and incorrectly identify flow p as the culprit.
Finally, the memory corruption in a different function (i.e., adjust traffic flow by pkg), which means that that the analysis must be able to handle inter-procedural calls in a context-sensitive way to precisely report the origin of the tainted data.
Thus, this bug is likely only possible to detect and report concisely with an analysis that is flow-, context-, and field-sensitive.
Moreover, the fact that this bug exists in the driver of a popular mobile device, shows that it evaded both expert analysts and possibly existing bug-finding tools.
DR. CHECKER uses a modular interface for its analyses.
This is done by performing a general analysis pass over the code, and invoking analysis clients at specific points throughout the analysis.
These analysis clients all share the same global state, and benefit from each other's results.
Once the analysis clients have run and updated the global state of the analysis, we then employ numerous vulnerability detectors, which identify specific properties of known bugs and raise warnings (e.g., a tainted pointer was used as input to a dangerous function).
The general architecture of DR. CHECKER is depicted in Figure 1, and the details of our analysis and vulnerability detectors are outlined in the following sections.Below we briefly outline a few of our core assumptions that contribute to our soundy analysis design: Assumption 1.
We assume that all of the code in the mainline Linux core is implemented perfectly, and we do not perform any inter-procedural analysis on any kernel application program interface (API) calls.Assumption 2.
We only perform the number of traversals required for a reach-def analysis in loops, which could result in our points-to analysis being unsound.Assumption 3.
Each call instruction will be traversed only once, even in the case of loops.
This is to avoid creating additional contexts and limit false positives, which may result in our analysis being unsound.
26th USENIX Security Symposium 1009 In this section we define the various terms and concepts that we use in the description of our analysis.Definition 3.1.
A control flow graph (CFG) of a function is a directed graph where each node represents a basic block (i.e., a contiguous sequence of non-branch instructions) and the edges of the graph represent possible control flow between the basic blocks.
of a graph is a sub-graph, where there exists a bidirectional path between any pair of nodes (e.g., a loop).
Definition 3.3.
Topological sort or ordering of nodes in a directed graph is an ordering of nodes such that, for every edge from node v to u, v is traversed before u.
While this is well-defined for acyclic graphs, it is less straightforward for cyclic graphs (e.g., a CFG with loops).
Thus, when performing a topological sort on a CFG, we employ Tarjan's algorithm [50], which instead topologically sorts the SCCs.Definition 3.4.
An entry function, ε, is a function that is called with at least one of its arguments containing tainted data (e.g., an ioctl call).
τ :v → {I 1 , I 2 , I 3 , ...} if TAINTED v → / 0 otherwise Definition 3.7.
An alias object, ˆ a = {ρ,t}, is a tuple that consists of a map (ρ) between offsets into that object, n, and the other corresponding alias objects that those offsets can point to, as well as a local taint map (t) for each offset.
For example, this can be used to represent a structure stored in a static location, representing an alias object, which contains pointers at given offsets (i.e., offsets into that object) to other locations on the stack (i.e., their alias objects).
More precisely, ρ :n → { ˆ a 1 , ˆ a 2 , ˆ a 3 , ...} and t : n → {I 1 , I 2 , I 3 , ...}.
We use bothâbothˆbothâ(n) and ρ(n) interchangeably, to indicate that we are fetching all of the alias objects that could be pointed to by a field at offset n.
We usê a t to refer to the taint map of locationâlocationˆlocationâ, and similarlyâsimilarlyˆsimilarlyâ t (n) to refer to taint at a specific offset.
These maps allow us to differentiate between different fields of a structure to provide field-sensitivity in our analysis.The following types of locations are traced by our analysis:1.
Function local variables (or stack locations): We maintain an alias object for each local variable.2.
Dynamically allocated variables (or heap locations): These are the locations that are dynamically allocated on the program heap (e.g., as retrieved by malloc or get page).
We similarly create one alias object for each allocation site.3.
Global variables: Each global variable is assigned a unique alias object.Stack and heap locations are both context-sensitive (i.e., multiple invocations of a function with different contexts will have different alias objects).
Furthermore, because of our context propagation, heap locations are call-site sensitive (i.e., for a given context, one object will be created for each call site of an allocation function).
Definition 3.8.
Our points-to map, φ , is the map between a value and all of the possible locations that it can point to, represented as a set of tuples containing alias objects and offsets into those objects.φ : v → {(n 1 , ˆ a 1 ), (n 1 , ˆ a 2 ), (n 2 , ˆ a 3 ), ...}For example, consider the instruction val1 = &info->dirmap, where info represents a structure on the stack and member dirmap is at offset 8.
This instruction would result in the value (val1) pointing to the offset 8 within the alias object info (i.e., φ (val1) = {(8, info)}).
Definition 3.9.
The Global State, S, of our analysis contains all of the information computed for every function, at every context.
We define it asS = {φ c , τ c },where φ c : ∆ → φ is the map between a context and the corresponding points-to map, and τ c : ∆ → τ is the map between a context and corresponding taint trace map.
While most of the existing static analysis techniques [13,28] run their abstract analysis until it reaches a fixedpoint before performing bug detection, this can be problematic when running multiple analyses, as the different analyses may not have the same precision.
Thus, by performing analysis on the post-completion results, these tools are fundamentally limiting the precision of all of their analyses to the precision of the least precise analysis.
To avoid this, and ensure the highest precision for all of our analysis modules, we perform a flow-sensitive and context-sensitive traversal of the driver starting from an entry point.
Our specific analysis modules (i.e., taint and points-to) are implemented as clients in this framework, and are invoked with the corresponding context and current global state as the code is being traversed.
This also allows all of the analyses, or clients, to consume each other's results whenever the results are needed, and without loss of precision.
Moreover, this allows us to perform a single traversal of the program for all of the underlying clients.It is important to note that some of the client analyses may actually need more traversals through the CFG than others to reach a fixed point.
For example, a pointsto analysis might need more traversals through a loop to reach a fixed point than a taint analysis.
However, our code exploration is analysis-agnostic, which means we must ensure that we always perform the maximum number of traversals required by all of our analyses.
To ensure this property, we use reach-def analysis [38] as a baseline (i.e., we traverse the basic blocks such that a reaching definition analysis will reach a fixed point).
This ensures that all of the writes that can reach an instruction directly will be reached.
This means that our points-to analysis may not converge, as it would likely require far more iterations.
However, in the worst case, points-to analysis could potentially grow unconstrained,Algorithm 1: Soundy driver traversal analysis function SDTraversal((S, ∆, F)) sccs ← topo sort(CFG(F)) forall the scc ∈ sccs do if is loop(scc) then HANDLELOOP(S, ∆, scc) else VISITSCC(S, ∆, scc) end end function VisitSCC((S, ∆, scc)) forall the bb ∈ scc do forall the I ∈ bb do if is call(I) then HANDLECALL(S, ∆, I) else if is ret(I) then S ← S ∪ {φ ∆ (ret val), τ ∆ (ret val)} else DISPATCHCLIENTS(S, ∆, I) end end end end function HandleLoop((S, ∆, scc)) num runs ← LongestUseDe fChain(scc) while num runs = 0 do VISITSCC(S, ∆, scc) num runs ← num runs − 1 end function HandleCall((S, ∆, I)) if ¬is visited(S, ∆, I) then targets ← resolve call(I) forall the f ∈ targets do ∆ new ← ∆||I φ new ← (∆ new → (φ c (∆)(args), φ c (∆)(globals))) τ new ← (∆ new → (τ c (∆)(args), τ c (∆)(globals))) S new ← {φ new , τ new } SDTRAVERSAL(S new , ∆ new , f ) end mark visited(S, ∆, I) endresulting in everything pointing to everything.
Thus, we make this necessary sacrifice to soundness to ensure convergence and a practical implementation.Loops.
When handling loops, we must ensure that we iterate over the loop enough times to ensure that every possible assignment of every variable has been exercised.
Thus, we must compute the number of iterations needed for a reach-def analysis to reach a fix-point on the loop and then perform the corresponding number of iterations on all the basic blocks in the loop.
Note that, the number of iterations to converge on a loop for a standard reach-def analysis is upper-bounded by the longest usedef chain in the loop (i.e., the longest number of instructions between the assignment and usage of a variable).
The intuition behind this is that, in the worst case, every instruction could potentially depend on the variable in the use-def chain, such that their potential values could update in each loop.
However, this can only happen as many times as their are instructions, since an assignment can only happen once per instruction.Function calls.
If a function call is a direct invocation and the target function is within the code that we are analyzing (i.e., it is part of the driver), it will be traversed with a new context (∆ new ), and the state will be both updated with a new points-to map (ρ new ) and a new taint trace map (τ new ), which contains information about both the function arguments and the global variables.
For indirect function calls (i.e., functions that are invoked via a pointer), we use type-based target resolution.
That is, given a function pointer of type a = (rettype)(arg1Type, arg2Type,.
.)
, we find all of the matching functions in the same driver that are referenced in a non-call instruction (e.g., void *ptr = &fn).
This is implemented as the function resolve call in Algorithm 1.
Each call site or call instruction will be analyzed only once per context.
We do not employ any special handlers for recursive functions, as recursion is rarely used in kernel drivers.The complete algorithm, SDTraversal, is depicted in Algorithm 1.
We start by topologically sorting the CFG of the function to get an ordered list of SCCs.
Then, each SCC is handled differently, depending on whether it is a loop or not.
Every SCC is traversed at the basic-block level, where every instruction in the basic block is provided to all of the possible clients (i.e., taint and pointsto), along with the context and global state.
The client analyses can collect and maintain any required information in the global state, making the information immediately available to each other.To analyze a driver entry point ε, we first create an initial state: S start = {φ start , / 0}, where φ start contains the points-to map for all of the global variables.
We then traverse all of the .
init functions of the driver (i.e., the functions responsible for driver initialization [44]), which is where drivers will initialize most of their global objects.
The resulting initialized state (S init ) is then appended with the taint map for any tainted arguments (S init = S init ∪ τ init ).
We describe how we determine these tainted arguments in Section 5.3.
Finally, we invoke our traversal on this function, SDTraversal(S init , ∆ init , ε), where the context ∆ init = {e}.
We use the low-level virtual machine (LLVM) intermediate representation (IR), Bitcode [30], as our IR for analysis.
Bitcode is a typed, static single assignment (SSA) IR, and well-suited for low-level languages like C.
The analysis clients interact with our soundy driver traversal (SDT) analysis by implementing visitors, or transfer functions, for specific LLVM IR instructions, which enables them to both use and update the information in the global state of the analysis.
The instructions that we define transfer functions for in the IR are:1.
Alloca (v = alloca typename) allocates a stack variable with the size of the type typename and assigns the location to v (e.g., %1 = alloca i32).
SDT uses the instruction location to reference the newly allocated instruction.
Since SDT is contextsensitive, the instruction location is a combination of the current context and the instruction offset within the function bitcode.Algorithm 2: Points-to analysis transfer functionsfunction updatePtoAlloca (φ c , τ c , δ , I, v, loc x ) map pt ← φ c (δ ) loc x ← (x, / 0, / 0) map pt (v) ← (0, loc x ) function updatePtoBinOp (φ c , τ c , δ , I, v, op 1 , op 2 ) map pt ← φ c (δ ) pto 1 ← map pt (op 1 ) pto 2 ← map pt (op 2 ) set 1 ← {(0, ob) | ∀( , ob) ∈ pto 1 } set 2 ← {(0, ob) | ∀( , ob) ∈ pto 2 } map pt (v) ← map pt (v) ∪ set 1 ∪ set 2 function updatePtoLoad (φ c , τ c , δ , I, v, op) map pt ← φ c (δ ) pto op ← map pt (op) set 1 ← {ob(n) | ∀(n, ob) ∈ pto op } set 2 ← {(0, ob) | ∀ob ∈ set 1 } map pt (v) ← map pt (v) ∪ set 2 function updatePtoStore (φ c , τ c , δ , I, v, op) map pt ← φ c (δ ) pto op ← map pt (op) pto v ← map pt (v) set v ← {ob | ∀( , ob) ∈ pto v } ∀(n, ob) ∈ pto op do ob(n) ← ob(n) ∪ set v function updatePtoGEP (φ c , τ c , δ , I, v, op, o f f ) map pt ← φ c (δ ) pto op ← map pt (op) set op ← {ob(n) | ∀(n, ob) ∈ pto op } set v ← {(o f f , ob) | ∀ob ∈ set op } map pt (v) ← map pt (v) ∪ set v The result of our points-to analysis is a list of values and the set of all of the possible objects, and offsets, that they can point to.
Because of the way in which we constructed our alias location objects and transfer functions, we are able to ensure that our points-to results are fieldsensitive.
That is, we can distinguish between objects that are pointed to by different fields of the same object (e.g., different elements in a struct).
Thus, as implemented in SDT, we are able to obtain points-to results that are flow-, context-, and field-sensitive.
Dynamic allocation.
To handle dynamic allocation in our points-to analysis, we maintain a list of kernel functions that are used to allocate memory on the heap (e.g., kmalloc, kmem cache alloc, get free page).
For each call-site to these functions, we create a unique alias object.
Thus, for a given context of a function, each allocation instruction has a single alias location, regardless of the number of times that it is visited.
For example, if there is a call to kmalloc in the basic block of a loop, we will only create one alias location for it.
function updateTaintAlloca (φ c , τ c , δ , I, v, loc x )Nothing to dofunction updateTaintBinOp (φ c , τ c , δ , I, v, op 1 , op 2 ) map t ← τ c (δ ) set v ← map t (op 1 ) ∪ map t (op 2 ) map t (v) ← set v ||I function updateTaintLoad (φ c , τ c , δ , I, v, op) map pt ← φ c (δ ) pto op ← map pt (op) set op ← {ob t (n)||I | ∀(n, ob) ∈ pto op } map t ← τ c (δ ) map t (v) ← map t (v) ∪ set op function updateTaintStore (φ c , τ c , δ , I, v, op) map pt ← φ c (δ ) pto op ← map pt (op) map t ← τ c (δ ) tr v ← map t (v) ∀(n, ob) ∈ pto op do ob t (n) ← ob t (n) ∪ (tr v ||I) function updateTaintGEP (φ c , τ c , δ , I, v, op, o f f ) UPDATETAINTBINOP(φ c , τ c , δ , I, v, op, o f f )Internal kernel functions.
Except for few kernel API functions, whose effects can be easily handled (e.g., memcpy, strcpy, memset), we ignore all of the other kernel APIs and core kernel functions.
For example, if the target of a call instruction is the function i2c master send, which is part of the core kernel, we do not follow the call.
Contrary to the other works, which check for valid usage of kernel API functions [12,64], we assume that all usages of these functions are valid, as we are only concerned with analyzing the more error-prone driver code.
Thus, we do no follow any function calls into the core kernel code.
While, we may miss some points-to information because of this, again sacrificing soundness, this assumption allows us to be more precise within the driver and scale our analysis.The update points-to transfer functions (updatePto*) for the various instructions are as shown in Algorithm 2.
Taint analysis is a critical component of our system, as almost all of our bug detectors use its results.
Similar to our points-to analysis, the results of our taint analysis are flow-, context-, and field-sensitive.
The taint sources in our analysis are the arguments of the entry functions.
Section 5.3 explains the different types of entry functions and their correspondingly tainted arguments.
We also consider special kernel functions that copy data from user space (e.g., copy from user, simple write to buffer) as taint sources and taint all of the fields in the alias locations of the points-to map for Listing 2: A buffer overflow bug detected in Mediatek's Accdet driver by ITDUD where buf is assumed to be a single character but the use of "%s" will continue reading the buffer until a null-byte is found.
2 . . . 3 s t a t i c s s i z e t 4 a c c d e t s t o r e c a l l s t a t e 5 ( s t r u c t d e v i c e d r i v e r * d d r i , 6 c o n s t c h a r * b u f , s i z e t c o u n t ) 7 { 8 / / * * I m p r o p e r u s e o f t a i n t e d d a t a * * 9/ / b u f can c o n t a i n more t h a n one c h a r !
10 i n t r e t = s s c a n f ( b u f , "%s " , & c a l l s t a t u s ) ; the destination operands of these functions.
Our taint propagators are implemented as various transformation functions (updateTaint* in Algorithm 3).
Similar to our points-to analysis, we do not propagate taint for any core kernel function calls, aside from a few exceptions (e.g., memcpy).
The taint sinks in our analysis are dependent on the vulnerability detectors, as every detector has its own taint policy.
These detectors will raise warnings if any tainted data violates a specified policy (e.g., if a tainted value is used as the length in a memcpy).
This section describes the various vulnerability detectors that were used in our analysis.
These detectors are highly configurable and are able to act on the results from both our points-to and taint analysis.
They are implemented as plugins that are run continuously as the code is being analyzed, and operate on the results from our analysis clients (i.e., taint and points-to analysis).
Our architecture enables us to very quickly implement new analyses to explore new classes of vulnerabilities.
In fact, in the process of analyzing our results for this paper, we were able to create the Global Variable Race Detector (GVRD) detector and deploy it in less than 30 minutes.Almost all of the detectors use taint analysis results to verify a vulnerable condition and produce a taint trace with all of their emitted warnings.
The warnings also provide the line numbers associated with the trace for ease of triaging.
The various bug detectors used by DR. CHECKER in our analysis are explained below:Improper Tainted-Data Use Detector (ITDUD) checks for tainted data that is used in risky functions (i.e., strc*, strt*, sscanf, kstrto, and simple strto Listing 3: A zero-day vulnerability discovered by DR. CHECKER in Mediatek's mlog driver using our TAD and TLBD analysis.
First TAD identified an integer overflow bug (len -MLOG STR LEN).
TLBD then identified that this tainted length was being used as a bound condition for the while loop where data is being copied into kernel space.
family functions).
An example of a previously unknown buffer overflow, detected via ITDUD, is shown in Listing 2.
Tainted Arithmetic Detector (TAD) checks for tainted data that is used in operations that could cause an overflow or underflow (e.g., add, sub, or mul).
An example of a zero-day detected by TAD is shown in Listing 3.
Invalid Cast Detector (ICD) keeps tracks of allocation sizes of objects and checks for any casts into an object of a different size.
Tainted Loop Bound Detector (TLBD) checks for tainted data that is used as a loop bound (i.e., a loop guard in which at least one of the values is tainted).
These bugs could lead to a denial of service or even an arbitrary memory write.
The example in Listing 3 shows this in a real-world bug, which also triggered on TAD.Listing 4: An information leak bug via padded fields detected by our ULD in Mediatek's FM driver where a struct's memory is not sanitized before being copied back to user space leaking kernel stack data.
Tainted Pointer Dereference Detector (TPDD) detects pointers that are tainted and directly dereferenced.
This bug arises when a user-specified index into a kernel structure is used without checking.
Tainted Size Detector (TSD) checks for tainted data that is used as a size argument in any of the copy to or copy from functions.
These types of bugs can result in information leaks or buffer overflows since the tainted size is used to control the number of copied bytes.Uninit Leak Detector (ULD) keeps tracks of which objects are initialized, and will raise a warning if any src pointer for a userspace copy function (e.g., copy to user) can point to any uninitialized objects.
It also detects structures with padding [40] and will raise a warning if memset or kzalloc has not been called on the corresponding objects, as this can lead to an information leak.
An example of a previously unknown bug detected by this detector is as shown in Listing 4Global Variable Race Detector (GVRD) checks for global variables that are accessed without a mutex.
Since the kernel is reentrant, accessing globals without syncronization can result in race conditions that could lead to time of check to time of use (TOCTOU) bugs.
DR. CHECKER is built on top of LLVM 3.8 [30].
LLVM was chosen because of its flexibility in writing analyses, applicability to different architectures, and excellent community support.
We used integer range analysis as implemented by Rodrigues et al. [42].
This analysis is used by our vulnerability detectors to verify certain properties (e.g., checking for an invalid cast).
We implemented DR. CHECKER as an LLVM module pass, which consumes: a bitcode file, an entry function name, and an entry function type.
It then runs our SDT analysis, employing the various analysis engines and vulnerability detectors.
Depending on the entry function type, certain arguments to the entry functions are tainted before invoking the SDT (See Section 5.3).
Because our analysis operates on LLVM bitcode, we must first identify and build all of the driver's bitcode files for a given kernel (Section 5.1).
Similarly, we must identify all of the entry points in these drivers (Section 5.2) in order to pass them to our SDT analysis.
To analyze the drivers independently, we must first differentiate driver source code files from that of the core kernel code.
Unfortunately, there is no standard location in the various kernel source trees for driver code.
Making the problem even harder, a number of the driver source files omit vendor copyright information, and some vendors even modify the existing sources directly to implement their own functionality.
Thus, we employ a combination of techniques to identify the locations of the vendor drivers in the source tree.
First, we perform a diff against the mainline sources, and compare those files with a referenced vendor's configuration options to search for file names containing the vendor's name.
Luckily, each vendor has a code-name that is used in all of their options and most of their files (e.g., Qualcomm configuration options contain the string MSM, Mediatek is MTK, and Huawei is either HISI or HUAWEI), which helps us identify the various vendor options and file names.
We do this for all of the vendors, and save the locations of the drivers relative to the source tree.Once the driver files are identified, we compile them using clang [51] into both Advanced RISC Machine (ARM) 32 bit and 64 bit bitcode files.
This necessitated a few non-trivial modifications to clang, as there are numerous GNU C Compiler (GCC) compiler options used by the Linux kernel that are not supported by clang (e.g., the -fno-var-tracking-assignments and -Wno-unused-but-set-variable options used by various Android vendors).
We also added additional compiler options to clang (e.g., -target) to aid our analysis.
In fact, building the Linux kernel using LLVM is an ongoing project [52], suggesting that considerable effort is still needed.Finally, for each driver, we link all of the dependent vendor files into a single bitcode file using llvm-link, resulting in a self-contained bitcode file for each driver.
Linux kernel drivers have various ways to interact with the userspace programs, categorized by 3 operations: file [20], attribute [35], and socket [37].
File operations are the most common way of interacting with userspace.
In this case, the driver exposes a file under a known directory (e.g., /dev, /sys, or /proc) that is used for communication.
During initialization, the driver specifies the functions to be invoked for various operations by populating function pointers in a structure, which will be used to handle specific operations (e.g., read, write, or ioctl).
The structure used for initialization can be different for each driver type.
In fact, there are at least 86 different types of structures in Android kernels (e.g., struct snd pcm ops, struct file operations, or struct watchdog ops [3]).
Even worse, the entry functions can be at different offset in each of these structures.
For example, the ioctl function pointer is at field 2 in struct snd pcm ops, and at field 8 in struct file operations.
Even for the same structure, different kernels may implement the fields differently, which results in the location of the entry function being different for each kernel.
For example, struct file operations on Mediatek's mt8163 kernel has its ioctl function at field 11, whereas on Huawei, it appears at field 9 in the structure.To handle these eccentricities in an automated way, we used c2xml [11] to parse the header files of each kernel and find the offsets for possible entry function fields (e.g., read or write) in these structures.
Later, given a bitcode file for a driver, we locate the different file operation structures being initialized, and identify the functions used to initialize the different entry functions.
These serve as our entry points for the corresponding operations.
For example, given the initialization as shown in Listing 5, and the knowledge that read entry function is at offset 2 (zero indexed), we mark the function mlog read as a read entry function.Attribute operations are operations usually exposed by a driver to read or write certain attributes of that driver.The maximum size of data read or written is limited to a single page in memory.Sockets operations are exposed by drivers as a socket file, typically a UNIX socket, which is used to communicate with userspace via various socket operations (e.g., send, recv, or ioctl).
There are also other drivers in which the kernel implements a main wrapper function, which performs initial verification of the user parameters and partially sanitizes them before calling the corresponding driver function(s).
An example of this can be seen in the V4L2 Framework [66], which is used for video drivers.
For our implementation we consider only struct v4l2 ioctl ops, which can be invoked by userspace via the wrapper function video ioctl2.
An entry point argument can contain either directly tainted data (i.e., the argument is passed directly by userspace and never checked) or indirectly tainted data (i.e., the argument points to a kernel location, which contains the tainted data).
All of the tainted entry point functions can be categorized in six categories, which are shown in Table 1, along with the type of taint data that their arguments represent.An explicit example of directly tainted data is shown in Listing 6.
In this snippet, tc client ioctl is an ioctl entry function, so argument 2 (arg) is directly tainted.
Thus, the statement char c=(char*)arg would be dereferencing tainted data and is flagged as a warning.
Alternatively, argument 2 (ctrl) in iris s ext ctrls is a V4Ioctl and is indirectly tainted.
As such, the dereference (data = (ctrl>controls [0]).
string) is safe, but it would taint data.
Because of the DR. CHECKER's soundy nature, it cannot find all the vulnerabilities in all drivers.
Specifically, it will miss following types of vulnerabilities:• State dependent bugs: Since DR. CHECKER is a stateless system, it treats each entry point independently (i.e., taint does not propagate between multiple entry points).
As a result, we will miss any bugs that occur because of the interaction between multiple entry points (e.g., CVE-2016-2068 [4]).
• Improper API usage: DR. CHECKER assumes that all the kernel API functions are safe and correctly used (Assumption 1 in Section 3).
Bugs that occur because of improper kernel API usage will be missed by DR. CHECKER.
However, other tools (e.g., APISan [64]) have been developed for finding these specific types of bugs and could be used to complement DR. CHECKER.
• Non-input-validation bugs: DR. CHECKER specifically targets input validation vulnerabilities.
As such, non-input validation vulnerabilities (e..
g, side channels or access control bugs) cannot be detected.
To evaluate the efficacy of DR. CHECKER, we performed a large-scale analysis of the following nine popular mobile device kernels and their associated drivers (437 in total).
The kernel drivers in these devices range from very small components (31 LOC), to much more complex pieces of code (240,000 LOC), with an average of 7,000 LOC per driver.
In total, these drivers contained over 3.1 million lines of code.
However, many of these kernels re-use the same code, which could result in analyzing the same entry point twice, and inflate our results.
Thus, we have grouped the various kernels based on their underlying chipset, and only report our results based on these groupings: [34], and Sparse [54]).
We briefly describe our interactions with each below, and a summary of the number of warnings raised by each is shown in Table 2.
Flawfinder & RATs Both Flawfinder and RATs are pattern-matching-based tool used to identify potentially dangerous portions of C code.
In our experience, the installation and usage of each was quite easy; they both installed without any configuration and used a simple command-line interface.
However, the criteria that they used for their warnings tended to be very simplistic, missed complex bugs, and where overly general, which resulted in an extremely high number of warnings (64,823 from Flawfinder and 13,117 from RATs).
For example, Flawfinder flagged a line of code with the warning, High: fixed size local buffer.
However, after manual investigation it was clear this code was unreachable, as it was inside of an #if 0 definition.
We also found numerous cases where the stringmatching algorithm was overly general.
For example, Flawfinder raised a critical warning ( [4] (shell) system), incorrectly reporting that system was being invoked for the following define: #define system cluster(system, clusterid).
- - - √ Inter-procedural - - - - √ Handles pointers - - - - √ Kernel Specific - - - √ √ No Manual Annotations √ √ √ - √ Requires compilable sources √ - - √ √ Sound - - - - - Traceable Warnings - - - √ √Ultimately, the tools seemed reasonable for basic code review passes, and perhaps for less-security minded programs, as they do offer informational warning messages:Flawfinder: Statically-sized arrays can be improperly restricted, leading to potential overflows or other issues (CWE-119:CWE-120).
Perform bounds checking, use functions that limit length, or ensure that the size is larger than the maximum possible length.RATs: Check buffer boundaries if calling this function in a loop and make sure you are not in danger of writing past the allocated space Sparse Sparse was developed by Linus Torvalds and is specifically targeted to analyze kernel code.
It is implemented as a compiler front end (enabled by the flag C=2 during compilation) that raises warnings about known problems, and even allows developers to provide static type annotations (e.g., user and kernel).
The tool was also relatively easily to use.
Although, Sparse is good at finding annotation mis-matches like unsafe user pointer dereferences [16].
Its main drawback was the sheer number of warnings (64,823 in total) it generated, where most of the warnings generated were regarding non-compliance to good kernel code practices.
For example, warnings like, "warning: Using plain integer as NULL pointer" and "warning: symbol 'htc smem ram addr' was not declared.
Should it be static?
," were extremely common.cppcheck Cppcheck was the most complicated to use of the tools that we evaluated, as it required manual identification of all of the includes, configurations, etc. in the source code.
However, this knowledge of the source code structure did result in much more concise results.
While the project is open-source, their analysis techniques are not well-documented.
Nevertheless, it is clear that the tool can handle more complex interactions (e.g., macros, globals, and loops) than the other three.
For example, in one of the raised warnings it reported an out-of-bounds index in an array lookup.
Unfortunately, after manual investigation there was a guard condition protecting the array access, but this was still a much more valuable warning that those returned by other tools.
It was also able to identify an interesting use of snprintf on overlapped objects, which exhibits undefined behavior, and appeared generally useful.
It also has a configurable engine, which allows users to specify additional types of vulnerability patterns to identify.
Despite this functionality, it still failed to detect any of the complex bugs that DR. CHECKER was able to help us discover.To summarize our experience, we provide a sideby-side feature comparison of the evaluated tools and DR. CHECKER in Table 3.
Note that cppcheck and DR. CHECKER where the only two with an extensible framework that can be used to add vulnerability detectors.
Similarly, every tool aside from Sparse, which needs manual annotations, was more-or-less completely automated.
As previously mentioned, Sparse's annotations are used to find unsafe user pointer dereferences, and while these annotations are used rigorously in the mainline kernel code, they are not always used in the vendor drivers.
Moreover, typecasting is frequently used in Linux kernel making Sparse less effective.
Patternbased tools like flawfinder and RATS do not require compilable source code, which results in spurious warnings because of pre-processor directives making them unusable.
Of the evaluated features, traceability of the warnings is potentially the most important for kernel bugfinding tools [26], as these warnings will ultimately be analyzed by a human.
We consider a warning to be traceable if it includes all of the information required to understand how a user input can result in the warning.
In DR. CHECKER, we use the debug information embedded in the LLVM bitcode to provide traceable warnings.
An example of a warning produced by DR. CHECKER is as shown in Listing 7.
The summarized results of all of the warnings that were reported by DR. CHECKER are presented in Table 4.
In this table, we consider a warning as correct if the report and trace were in fact true (e.g., a tainted variable was be- ing used by a dangerous function).
All of these warnings were manually verified by the authors, and those that are marked as a bug were confirmed to be critical zero-day bugs, which we are currently in the process of disclosing to the appropriate vendors.
In fact, 7 of the 158 identified zero-days have already been issued Common Vulnerabilities and Exposures (CVE) identifiers [6][7][8][9][10].
Of these, Sparse correctly identified 1, flawfinder correctly identified 3, RATs identified 1 of the same ones as flawfinder, and cppcheck failed to identify any of them.
These bugs ranged from simple data leakages to arbitrary code execution within the kernel.
We find these results very promising, as 3,973 out of the 5,071 were confirmed, giving us a precision of 78%, which is easily within the acceptable 30% range [14].
While the overall detection rate of DR. CHECKER is quite good (e.g., KernelUninitMemoryLeakDetector raised 24 warnings, which resulted in 11 zero-day bugs), there a few notable lessons learned.
First, because our vulnerability detectors are stateless, they raise a warning for every occurrence of the vulnerable condition, which results in a lot of correlated warnings.
For example, the code i = tainted+2; j = i+1; will raise two IntegerOverflowDetector warnings, once for each vulnerable condition.
This was the main contributor to the huge gap between our confirmed warnings and the actual bugs as each bug was the result of multiple warnings.
The over-reporting problem was amplified by our contextsensitive analysis.
For example, if a function with a vulnerable condition is called multiple times from different contexts, DR. CHECKER will raise one warning for each context.GlobalVariableRaceDetector suffered from numerous false positives because of granularity of the LLVM instructions.
As a result, the detector would raise a warning for any access to a global variable outside of a critical section.
However, there are cases where the mutex object is stored in a structure field (e.g., mutex lock(&global->obj)).
This results in a false positive because our detector will raise a warning on the access to the global structure, despite the fact that it is completely safe, because the field inside of it is actually a mutex.TaintedPointerDerefenceDetectors similarly struggled with the precision of its warnings.
For example, on Huawei drivers (row 2, column 1), it raised 552 warnings, yet only 155 were true positives.
This was due to the over-approximation of our points-to analysis.
In fact, 327 of these are attributed to only two entry points rpmsg hisi write and hifi misc ioctl, where our analysis over-approximated a single field that was then repeatedly used in the function.
A similar case happened for entry point sc v4l2 s crop in Samsung, which resulted in 21 false warnings.
The same overapproximation of points-to affected InvalidCastDetector, with 2 entry points (picolcd debug flash read and picolcd debug flash write) resulting in 66 (80%) false positives in Huawei and a single entry point (touchkey fw update.419) accounting for a majority of the false positives in Samsung.
IntegerOverflowDetector also suffered from over-approximation at times, with 30 false warnings in a single entry point hifi misc ioctl for Hauwei.One notable takeaway from our evaluation was that while we expected to find numerous integer overflow bugs, we found them to be far more prevalent in 32 bit architectures than 64 bites, which is contrary to previously held beliefs [58].
Additionally, DR. CHECKER was able to correctly identify the critical class of Boomerang [33] bugs that were recently discovered.
DR. CHECKER in total analyzed 1207 entry points and 90% of the entry points took less than 100 seconds to complete.
DR. CHECKER's practicality and scalability are made possible by our soundy assumptions.
Specifically, not analyzing core kernel functions and not waiting for loops to converge to a fixed-point.
In this section, we evaluate how these assumptions affected both our precision (i.e., practicality) and runtime (i.e., scalability).
This analysis was done by randomly selecting 25 entry points from each of our codebases (i.e., Huawei, Qualcomm, Mediatek, and Samsung), resulting 100 randomly selected driver entry points.
We then removed our two soundy assumptions, resulting in a "sound" analysis, and ran our analysis again.
Our assumption that all kernel functions are bug free and correctly implemented is critical for the efficacy of DR. CHECKER for two reasons.
First, the state explosion that results from analyzing all of the core kernel code makes much of our analysis computationally infeasible.
Second, as previously mentioned, compiling the Linux kernel for ARM with LLVM is still an ongoing project, and thus would require a significant engineering effort [52].
In fact, in our evaluation we compiled the 100 randomly chosen entry with best-effort compilation using LLVM, where we created a consolidated bitcode file for each entry point with all the required kernel API functions, caveat those that LLVM failed to compile.
We ran our "sound" analysis with these compiled API functions and evaluated all loops until both our points-to and taint analysis reached a fixed point, and increased our timeout window to four hours per entry point.
Even with the potentially missing kernel API function definitions, only 18 of these 100 entry points finished within the 4 hours.
The first row (Sound) in Table 5 shows the distribution of time over these 18 entry points.
Moreover, these 18 entry points produced 63 warnings and took a total of 52 minutes to evaluate, compared to 9 warnings and less than 1 minute of evaluation time using our soundy analysis.Fixed-point Loop Analysis Since we were unable to truly evaluate a sound analysis, we also evaluated our second assumption (i.e., using a reach-def loop analysis instead of a fixed-point analysis) in isolation to examine its impact on DR. CHECKER.
In this experiment, we ignored the kernel API functions (i.e., assume correct implementation), but evaluated all loops until they reached a fixed point on the same 100 entry points.
In this case, all of the entry points were successfully analyzed within our four hour timeout window.
The second row (No API) in Table 5 shows the distribution of evaluation times across these entry points.
Note that this approach takes 3× more time than the DR. CHECKER approach to analyze an entry point on average.
Similarly, our soundy analysis returned significantly fewer warnings, 210 compared to the 474 warnings that were raised by this approach.
A summary of the execution times (i.e., sound, fixedpoint loops, and DR. CHECKER) can be found in Table 5, which shows that ignoring kernel API functions is the main contributor of the DR. CHECKER's scalability.
This is not surprising because almost all the kernel drivers themselves are written as kernel modules [2], which are small (7.3K lines of code on average in the analyzed kernels) and self-contained.
Although DR. CHECKER is designed for Linux kernel drivers, the underlying techniques are generic enough to be applied to other code bases.
Specifically, as shown in Section 7.1, ignoring external API functions (i.e., kernel functions) is the major contributor to the feasibility of DR. CHECKER on the kernel drivers.
DR. CHECKER in principle can be applied to any code base, which is modular and has well-defined entry points (e.g., ImageMagick [1]).
While our techniques are portable, some engineering effort is likely needed to change the detectors and setup the LLVM build environment.
Specifically, to apply DR. CHECKER, one needs to:1.
Identify the source files of the module, and compile them in to a consolidated bitcode file.2.
Identify the function names, which will serve as entry points.3.
Identify how the arguments to these functions are tainted.We provided more in-depth documentation of how this would be done in practice on our website.
Zakharov et al.[65] discuss many of the existing tools and propose a pluggable interface for future staticanalysis techniques, many of which are employed in DR. CHECKER.
A few different works looked into the API-misuse problem in kernel drivers.
APISan [64] is [12] similarly identified API-misuse using static data-flow analysis.
However, these techniques are contrary to DR. CHECKER, as we explicitly assume that the kernel APIs are implemented properly.
SymDrive [43] uses symbolic execution to verify properties of kernel drivers.
However, it requires developers to annotate their code and relies heavily on the bug finder to implement proper checkers.
Johnson et al. [28] proposed a sound CQUAL-based [24] tool, which is context-sensitive, field-sensitive, and precise taint-based analysis; however, this tool also requires user annotations of the source code, which DR. CHECKER does not.KINT [56] uses taint analysis to find integer errors in the kernel.
While KINT is sound, their techniques are specialized to integer errors, whereas DR. CHECKER attempts to find general input validation errors by compromising soundness.Linux Driver Verification (LDV) [36] is a tool based on BLAST [27] that offers precise pointer analysis; however, it is still a model-checker-based tool, whereas we built our analysis on well-known static analysis techniques.
Yamaguchi et al. have done a significant amount of work in this area, based on Joern [59][60][61][62], where they use static analysis to parse source code into novel data structures and find known vulnerable signatures.
However, their tool is similar to a pattern-matching modelchecking type approach, whereas we are performing general taint and points-to analysis with pluggable vulnerability detectors.
VCCFinder [41] also used a similar pattern-matching approach, but automatically constructed their signatures by training on previously known vulnerabilities to create models that could be used to detect future bugs.MECA [63] is a static-analysis framework, capable of taint analysis, that will report violations based on user annotations in the source code, and similarly aims to reduce false positives by sacrificing soundness.
ESP [22] is also capable of fully path-sensitive partial analysis using "property simulation," wherein they combine data-flow analysis with a property graph.
However, this approach is not as robust as our more general approach.Boyd-Wickizer et al. [15] proposed a potential defense against driver vulnerabilities that leverages x86 hardware features; however, these are unlikely to be easily ported to ARM-based mobile devices.
Nooks [49] is a similar defense; however, this too has been neglected in both the mainline and mobile deployments thus far, due to similar hardware constraints.
We have presented DR. CHECKER, a fully-automated static analysis bug-finding tool for Linux kernels that is capable of general context-, path-, and flow-sensitive points-to and taint analysis.
DR. CHECKER is based on well-known static analysis techniques and employs a soundy analysis, which enables it to return precise results, without completely sacrificing soundness.
We have implemented DR. CHECKER in a modular way, which enables both analyses and bug detectors to be easily adapted for real-world bug finding.
In fact, during the writing of this paper, we identified a new class of bugs and were able to quickly augment DR. CHECKER to identify them, which resulted in the discovery 63 zero-day bugs.
In total, DR. CHECKER discovered 158 previously undiscovered zero-day bugs in nine popular mobile Linux kernels.
All of the details and disclosures for these bugs can be found online at github.
com/ucsb-seclab/dr_checker.
While these results are promising, DR. CHECKER still suffers from overapproximation as a result of being soundy, and we have identified areas for future work.
Nevertheless, we feel that DR. CHECKER exhibits the importance of analyzing Linux kernel drivers and provides a useful framework for adequately handling this complex code.
We would like to thank the anonymous reviewers and our shepherd Stelios Sidiroglou-Douskos for their valuable comments and input to improve our paper.
This material is based on research sponsored by the Office of Naval Research under grant number N00014-15-1-2948 and by DARPA under agreement number FA8750-15-2-0084.
The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon.This work is also sponsored by a gift from Google's Anti-Abuse group.The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of DARPA or the U.S. Government.
