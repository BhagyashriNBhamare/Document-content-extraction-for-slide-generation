The k-Nearest Neighbor Search (k-NNS) is the backbone of several cloud-based services such as recommender systems, face recognition, and database search on text and images.
In these services, the client sends the query to the cloud server and receives the response in which case the query and response are revealed to the service provider.
Such data disclosures are unacceptable in several scenarios due to the sensitivity of data and/or privacy laws.
In this paper, we introduce SANNS, a system for secure k-NNS that keeps client's query and the search result confidential.
SANNS comprises two protocols: an optimized linear scan and a protocol based on a novel sublinear time clustering-based algorithm.
We prove the security of both protocols in the standard semi-honest model.
The protocols are built upon several state-of-the-art cryptographic primitives such as lattice-based additively homomorphic encryption, distributed oblivious RAM, and garbled circuits.
We provide several contributions to each of these primitives which are applicable to other secure computation tasks.
Both of our protocols rely on a new circuit for the approximate top-k selection from n numbers that is built from O(n + k 2) comparators.
We have implemented our proposed system and performed extensive experimental results on four datasets in two different computation environments, demonstrating more than 18 − 31× faster response time compared to optimally implemented protocols from the prior work.
Moreover, SANNS is the first work that scales to the database of 10 million entries, pushing the limit by more than two orders of magnitude.
The k-Nearest Neighbor Search problem (k-NNS) is defined as follows.
For a given n-point dataset X ⊂ R d , and a query point q ∈ R d , find (IDs of) k data points closest (with respect to the Euclidean distance) to the query.
The k-NNS has many applications in modern data analysis: one typically starts with a dataset (images, text, etc.) and, using domain expertise together with machine learning, produces its feature vector representation.
Then, similarity search queries ("find k objects most similar to the query") directly translate to k-NNS queries in the feature space.
Even though some applications of k-NNS benefit from non-Euclidean distances [6], the overwhelming majority of applications (see [7] and the references therein) utilize Euclidean distance or cosine similarity, which can be modeled as Euclidean distance on a unit sphere.When it comes to applications dealing with sensitive information, such as medical, biological or financial data, the privacy of both the dataset and the queries needs to be ensured.
Therefore, the "trivial solution" where the server sends the entire dataset to the client or the client sends the plaintext query to the server would not work, since we would like to protect the input from both sides.
Such settings include: face recognition [30,60], biometric identification [9,23,31], patient data search in a hospital [6,62] and many others.
One can pose the Secure k-NNS problem, which has the same functionality as the k-NNS problem, and at the same time preserves the privacy of the input: the server-who holds the datasetshould learn nothing about the query or the result, while the client-who has the query-should not learn anything about the dataset besides the k-NNS result.Secure k-NNS is a heavily studied problem in a variety of settings (see Section 1.2 for the related work).
In this paper, we consider one of the most conservative security requirements of secure two-party computation [32], where the protocol is not allowed to reveal anything beyond the output of the respective plaintext k-NNS algorithm.
Note that we do not rely on a trusted third party (which is hardly practical) or trusted hardware such as Intel SGX 1 (which is known to have major security issues: see, e.g., [66]).
In this paper, we describe SANNS: a system for fast processing of secure k-NNS queries that works in the two-party secure computation setting.
The two main contributions underlying SANNS are the following.
First, we provide an improved secure protocol for the top-k selection.
Second, we design a new k-NNS algorithm tailored to secure computation, which is implemented using a combination of Homomorphic Encryption (HE), Garbled Circuits (GC) and Distributed Oblivious RAM (DORAM) as well as the above top-k protocol.
Extensive experiments on real-world image and text data show that SANNS achieves a speed-up of up to 31× compared to (carefully implemented and heavily optimized) algorithms from the prior work.Trust model We prove simulation-based security of SANNS in the semi-honest model, where both parties follow the protocol specification while trying to infer information about the input of the other party from the received messages.
This is an appropriate model for parties that in general trust each other (e.g., two companies or hospitals) but need to run a secure protocol due to legal restrictions.
Most of the instances of secure multi-party computation deployed in the real world operate in the semi-honest model: computing gender pay gap [15], sugar beets auctions [17], and others.
Our protocol yields a substantial improvement over prior works under the same trust model.
Besides, any semi-honest protocol can be reinforced to be maliciously secure (when parties are allowed to tamper actively with the sent messages), though it incurs a significant performance overhead [35].
Underlying SANNS are two new algorithms for the k-NNS problem.
The first one is based on linear scan, where we compute distances to all the points, and then select the k closest ones.
The improvement comes from the new top-k selection protocol.
The second algorithm has sublinear time avoiding computing all the distances.
At a high level, it proceeds by clustering the dataset using the k-means algorithm [47], then, given a query point, we compute several closest clusters, and then compute k closest points within these clusters.
The resulting points are approximately closest; it is known that approximation is necessary for any sublinear-time k-NNS algorithm [57] 2 .
In order to be suitable for secure computation, we introduce a new cluster rebalancing subroutine, see below.
Let us note that among the plaintext k-NNS algorithms, the clustering approach is far from being the best [7], but we find it to be particularly suitable for secure computation.For both algorithms, we use Additive Homomorphic Encryption (AHE) for secure distance computation and garbled circuit for the top-k selection.
In case of our sublinear-time algorithm, we also use DORAM to securely retrieve the clusters closest to the query.
For AHE, we use the SEAL library [52] which implements the Brakerski/Fan-Vercauteren (BFV) scheme [33].
For GC we use our own implementation of Yao's protocol [70] with the standard optimizations [11,12,41,71], and for DORAM we implement Floram [27] in the read-only mode.Our specific contributions can be summarized as follows: • We propose a novel mixed-protocol solution based on AHE, GC, and DORAM that is tailored for secure k-NNS and achieves more than 31× performance improvement compared to prior art with the same security guarantees.
• We design and analyze an improved circuit for approximate top-k selection.
The secure top-k selection protocol within SANNS is obtained by garbling this circuit.
This improvement is likely to be of independent interest for a range of other secure computation tasks.
• We create a clustering-based algorithm that outputs balanced clusters, which significantly reduces the overhead of oblivious RAMs for secure random accesses.
• We build our system and evaluate it on various real-world datasets of text and images.
We run experiments on two computation environments that represent fast and slow network connections in practice.
• We make several optimizations to the AHE, GC, and DORAM cryptographic primitives to improve efficiency of our protocol.
Most notably, in Floram [27], we substitute block cipher for stream cipher, yielding a speed-up by more than an order of magnitude.
To the best of our knowledge, all prior work on the secure k-NNS problem in the secure two-party computation setting is based on the linear scan, where we first compute the distance between the query and all of n database points, and then select k smallest of them.
To contrast, our clustering-based algorithm is sublinear, which leads to a substantial speed-up.
We classify prior works based on the approaches used for distance computation and for top-k selection.Distance computation SANNS computes distances using the BFV scheme [33].
Alternative approaches used in the prior work are: • Paillier scheme [54] used for k-NNS in [9,[29][30][31]60].
Unlike the BFV scheme, Paillier scheme does not support massively vectorized SIMD operations, and, in general, is known to be much slower than the BFV scheme for vector/matrix operations such as a batched Euclidean distance computation: see, e.g., [40].
• OT-based multiplication is used for k-NNS in [23] for k = 1.
Compared to the BFV scheme, OT-based approach requires much more communication, O(n + d) vs. O(nd), respectively, while being slightly less compute-intensive.
In our experiments, we find that the protocol from [53] that is carefully tailored to the matrix operations (and is, thus, significantly faster than the generic one used in [23]) is as fast as AHE on the fast network, but significantly slower on the slow network.Top-k selection SANNS chooses k smallest distances out of n by garbling a new top-k circuit that we develop in this work.
The circuit is built from O(n + k 2 ) comparators.
Alternative approaches in the prior work are:• The naive circuit of size Θ(nk) (c.f. Algorithm 1) was used for k-NNS in [6,61,64].
This gives asymptotically a factor of k slow-down, which is significant even for k = 10 (which is a typical setting used in practice).
• Using homomorphic encryption (HE) for the top-k selection.In the works [62,63], to select k smallest distances, the BGV scheme is used, which is a variant of the BFV scheme we use for distance computations.
Neither of the two schemes are suitable for the top-k selection, which is a highly non-linear operation.
A more suitable HE scheme for this task would have been TFHE [22], however, it is still known to be slower than the garbled circuit approach by at least three orders of magnitude.We can conclude the discussion as follows: our experiments show that for k = 10, even the linear scan version of SANNS is at up to 3.5× faster than all the prior work even if we implement all the components in the prior work using the most modern tools (for larger values of k, the gap would increase).
However, as we move from the linear scan to the sublinear algorithm, this yields additional speed-up up to 12× at a cost of introducing small error in the output (on average, one out of ten reported nearest neighbors is incorrect).
All the prior work described above is in the semi-honest model except [61] (which provides malicious security).
The drawback, however, is efficiency: the algorithm from [61] can process one query for a dataset of size 50 000 in several hours.
Our work yields an algorithm that can handle 10 million data points in a matter of seconds.
All the other prior work deals with datasets of size at most 10 000.
Thus, by designing better algorithms and by carefully implementing and optimizing them, we scale up the datasets one can handle efficiently by more than two orders of magnitude.Other security models Some prior work considered the secure k-NNS problem in settings different from "vanilla" secure two-party computation.
Two examples are the works [58,69].
The work [69] is under the two-server setting, which is known to give much more efficient protocols, but the security relies on the assumption that the servers do not collude.
At the same time, our techniques (e.g., better top-k circuit and the balanced clustering algorithm) should yield improvements for the two-server setting as well.
In the work [58], a very efficient sublinear-time protocol for secure approximate k-NNS is provided that provides a trade-off between privacy and the search quality.
One can tune the privacy parameter to limit the information leakage based on the desired accuracy threshold.
As a result, their protocol can leak more than approximate k-NNS results, i.e., one can estimate the similarity of two data points based on the hash values (see Section 5 of [58] for a formal bound on the information leakage).
SANNS can potentially impact several real-world applications.
At a high-level, our system can provide a an efficient mechanism to retrieve similar elements to a query in any two-party computation model, e.g., database search, recommender systems, medical data analysis, etc. that provably does not leak anything beyond (approximate) answers.
For example, our system can be used to retrieve similar images within a database given a query.
We analyze the efficiency of our system in this scenario using the SIFT dataset which is a standard benchmark in approximate nearest-neighbor search [48].
Additionally, we consider Deep1B which is a dataset of image descriptors [8].
We run SANNS on a database as big as ten million images, whereas the prior work deals with datasets of size at most 50 000.
As another application of secure k-NNS consider privacy-preserving text search, which has been rigorously studied in the past [21,37,50,55,65].
One group of these solutions support (multi)-keyword search [21,50,65]: a client can receive a set of documents which include all (or subset of) keywords queried by the clients.
In a more powerful setting, text similarity search can be performed where all documents that are semantically similar to a given document can be identified while keeping the query and the database private [37,55].
In this context, we evaluate SANNS on the Amazon reviews text database [51].
In this work, we use a combination of secure computation primitives to solve the k-NNS problem.
We connect these primitives via secret sharing, which comes in two forms: an arithmetic secret sharing of a value x ∈ Z t is a pair (x C , x S ) of random values subject to x C + x S ≡ x mod t, whereas a Boolean (or XOR) secret sharing of x ∈ {0, 1} τ is a pair of random strings subject to x C ⊕ x S = x. Previous solutions for secure k-NNS require computing distance between the query point and all points in the database, which is undesirable for large databases.
In order to avoid this linear cost, we utilize a distributed version of oblivious RAM (DORAM).
In this scenario, two parties hold secret shares of an array, and they can perform oblivious read and write operations, with secret-shared indices.
Typically one requires the communication cost to be sublinear in the array size.
There are many known DORAM constructions [27,67,68,72], among which we choose Floram [27] for efficiency reasons.
In this work, we use Floram in read-only mode, and we further enhance its performance through careful optimizations.
At a high level, we implement and use two subroutines:• DORAM.Init(1 λ , DB) → (k A , k B , DB).
This step creates a masked version of the database (DB) from the plaintext version (DB) and outputs two secret keys k A and k B , one to each party.
Here λ is a security parameter.
• DORAM.Read(DB, k A , k B , i A , i B ) → (DB[i] A , DB[i] B ).
This subroutine performs the read operation where address i is secret-shared between two parties as i A ⊕ i B = i. Both parties acquire a XOR-share of DB [i].
In Section 4.3, we describe these subroutines and various optimizations in a greater detail.
A (private-key) additive homomorphic encryption (AHE) scheme is private-key encryption scheme with three additional algorithms Add, CAdd and CMult, which supports adding two ciphertexts, and addition / multiplication by constants.
We require our AHE scheme to satisfy standard IND-CPA security and circuit privacy, which means that a ciphertext generated from Add, CAdd and CMult operations should not leak more information about the operations to the secret key owner, other than the decrypted message.
This is required since in our case the server will input its secret values into CAdd and CMult.
We chose to use the BFV scheme [33], and we achieve circuit privacy through noise flooding [40].
Garbled circuit (GC) is a technique first proposed by Yao in [70] for achieving generic secure two-party computation for arbitrary Boolean circuits.
Many improvements to GC have been proposed in literature, such as free-XOR [41] and half-gates [71].
In addition, we use the fixed-key block cipher optimization for garbling and evaluation [12].
Using Advanced Encryption Standard (AES) as the block cipher, we leverage Intel AES instructions for faster garbling procedure.
One of our algorithms uses the k-means clustering algorithm [47] as a subroutine.
It is a simple heuristic, which finds a clustering X = C 1 ∪C 2 ∪ . . . ∪C k into disjoint subsets C i ⊆ X, and centers c 1 , c 2 , . . . , c k ∈ R d , which approximately minimizes the objective function∑ k i=1 ∑ x∈C i c i − x 2 .
Optimized linear scan Our first algorithm is a heavily optimized implementation of the linear scan: we compute distances from the query point to all the data points, and then (approximately) select k nn data points closest to the query.
At a high level, we will implement distance computation using AHE, while top-k selection is done using GC.Computing top-k naïvely would require a circuit built from O(nk) comparators.
Instead, we propose a new algorithm for an approximate selection of top-k, which allows for a smaller circuit size (see section 3.1) and will help us later when we implement the top-k selection securely using garbled circuit.
Clustering-based algorithm The second algorithm is based on the k-means clustering (see Section 2.5) and, unlike our first algorithm, has sublinear query time.
We now give a simplified version of the algorithm, and in Section 3.3 we explain why this simplified version is inadequate and provide a full description that leads to efficient implementation.At a high level, we first compute k-means clustering of the server's dataset with k = k c clusters.
Each cluster 1 ≤ i ≤ k c is associated with its center c i ∈ R d .
During the query stage, we find 1 ≤ u ≤ k c centers that are closest to the query, where u is a parameter to be chosen.
Then we compute k nn data points from the corresponding u-many centers, and return IDs of these points as a final answer.
In both of our algorithms, we rely extensively on the following top-k selection functionality which we denote by MIN k n (x 1 , x 2 , . . . , x n ): given a list of n numbers x 1 , x 2 , . . . , x n , output k ≤ n smallest list elements in the sorted order.
We can also consider the augmented functionality where each value is associated with an ID, and we output the IDs together with the values of the smallest k elements.
We denote this augmented functionality by MIN k n .
In the RAM model, computing MIN k n is a well-studied problem, and it is by now a standard fact that it can be computed in time O(n + k log k) [16].
However, to perform top-k selection securely, we need to implement it as a Boolean circuit.
Suppose that all the list elements are b-bit integers.
Then the required circuit has bn inputs and bk outputs.
To improve efficiency, it is desirable to design a circuit for MIN k n with as few gates as possible.
The naïve construction A naïve circuit for MIN k n performs O(nk) comparisons and hence consists of O(bnk) gates.
Algorithm 1 gives such a circuit (to be precise, it computes the augmented functionality MIN k n , but can be easily changed to compute only MIN k n ).
Roughly, it keeps a sorted array of the current k minima.
For every x i , it uses a "for" loop to insert x i into its correct location in the array, and discards the largest item to keep it of size k. Sorting networks Another approach is to employ sorting networks (e.g., AKS [1] or the Zig-Zag sort [36]) with O(bn log n) gates, which can be further improved to O(bn log k).
However, these constructions are not known to be practical.
Approximate randomized selection We are not aware of any circuit for MIN k n with O(bn) gates unless k is a constant (O(bn) gates is optimal since the input has bn bits).
Instead,Algorithm 1 Naive Top-k Computation function NAIVETOPK((x 1 , ID 1 ), . . . , (x n , ID n ), k) OPT = [MAXVAL] k idlist = [0] k for i ← 1 . . . n do x ← x i , idx ← ID i for j ← 1 . . . k do b ← (x < OPT [ j]) (OPT [ j], x) = MUX(OPT [ j], x, b) (idlist[ j], idx) = MUX(idlist[ j], idx, b) end for end for return (OPT, idlist) end function function MUX(a 1 , a 2 , b) # Returns (a 1 , a 2 ) for b = 0, and (a 2 , a 1 ) for b = 1 return (a 1 + (a 2 − a 1 ) · b, a 2 + (a 1 − a 2 ) · b) end function Algorithm 2 Approximate top-k selection function APPROXTOPK((x 1 , ID 1 ), . . . , (x n , ID n ), k, l) for i ← 1 . . . l do (M i , ID i ) ← ← MIN({(x (i·n/l+ j) , ID (i·n/l+ j) )} n/l j=1 ) end for return NAIVETOPK((M 1 , ID 1 ), . . . , (M l , ID l ), k) end functionwe propose a randomized construction of a circuit with O(bn) gates.
We start with shuffling the inputs in a uniformly random order.
Namely, instead of x 1 , x 2 , . . . , x n , we consider the list x π(1) , x π(2) , . . . , x π(n) , where π is a uniformly random permutation of {1, 2, . . . , n}.
We require the output to be "approximately correct" (more on the precise definitions later) with high probability over π for every particular list x 1 , x 2 , . . . , x n .
We proceed by partitioning the input list into l ≤ n bins of size n/l as follows:U 1 = {x π(1) , . . . , x π(n/l) }, U 2 = {x π(n/l+1) , . . . , x π(2n/l) }, . . . , U l = {x π((l−1)n/l+1) , . . . , x π(n) }.
Our circuit works in two stages: first, we compute the minimum within each bin M i = min x∈U i x, then we outputMIN k l (M 1 , M 2 , . . . , M l ) as a final result using the naïve circuit for MIN k l .
The circuit size is O(b · (n + kl)), which is O(bn) whenever kl = O(n).
Intuitively, if we set the number of bins l to be large enough, the above circuit should output a high-quality answer with high probability over π.
We state and prove two theorems formalizing this intuition in two different ways.
We defer the proofs to Appendix C. Theorem 1.
Suppose the input list (x 1 , . . . , x n ) is in uniformly random order.
There exists δ 0 > 0 and a positive function k 0 (δ) with the following property.
For every n, 0 < δ < δ 0 , and k ≥ k 0 (δ), one can set the number of bins l = k/δ suchAlgorithm 3 Plaintext linear scan function LINEARSCANKNNS(q, {p i } n i=1, ID) # Uses hyperparameters r p , k nn , l s from Figure 1 Randomly permute the set {p i } for i ← 1, . . . , n dod i ← q − p i 2 d i ← d i 2 rp end for (v 1 , ID 1 ), . . . , (v k nn , ID k nn ) ← APPROXTOPK(d 1 , ID(p 1 ), . . . , (d n , ID(p n ), k nn , l s ) return ID 1 , . . . , ID k nn end functionthat the intersection I of the output of Algorithm 2 withMIN k n (x 1 , x 2 , . . . , x n ) contains at least (1 − δ)k entries in ex- pectation over the choice of π.This bound yields a circuit of sizeO(b · (n + k 2 /δ)).
Theorem 2.
Suppose the input list (x 1 , . . . , x n ) is in uniformly random order.
There exists δ 0 > 0 and a positive function k 0 (δ) with the following property.
For every n, 0 < δ < δ 0 , and k ≥ k 0 (δ), one can set the number of bins l = k 2 /δ such that the output of Algorithm 2 is exactly MIN k n (x 1 , x 2 , . . . , x n ) with probability at least 1 − δ over the choice of π.This yields a circuit of size O(b · (n + k 3 /δ)), which is worse than the previous bound, but the corresponding correctness guarantee is stronger.
To speed up the top-k selection further, instead of exact distances, we will be using approximate distances.
Namely, instead of storing full b-bit distances, we discard r low-order bits, and the overall number of gates in the selection circuit becomes O((b − r) · (n + kl)).
For the clustering-based algorithm, we set r differently depending on whether we select closest cluster centers or closest data points, which allows for a more fine-grained parameter tuning.
To implement the clustering-based k-NNS algorithm securely while avoiding linear cost, we use DORAM for retrieval of clusters.
In order to prevent leaking the size of each cluster, we need to set the memory block size equal to the size of the largest cluster.
This can be very inefficient, if clusters are not very balanced, i.e., the largest cluster is much larger than a typical cluster.
Unfortunately, this is exactly what we observe in our experiments.
Thus, we need a mechanism to mitigate imbalance of clusters.
Below we describe one such approach, which constitutes the actual version of the clustering-based algorithm we securely implement.
With cluster balancing, our experiments achieve 3.3× to 4.95× reduction of maximum cluster sizes for different datasets.We start with specifying the desired largest cluster size 1 ≤ m ≤ n and an auxiliary parameter 0 < α < 1, where n denotes the total number of data points.
Then, we find the smallest k (recall k denotes the number of centers) such that in the clustering of the dataset X found by the k-means algorithm at most α-fraction of the dataset lies in clusters of size more than m.
Then we consider all the points that belong to the said large clusters, which we denote by X , setting n = |X | ≤ αn, and apply the same procedure recursively to X .
Specifically, we find the smallest k such that the k-means clustering of X leaves at most αn points in clusters of size more than m.
We then cluster these points etc.
The algorithm terminates whenever every cluster has size ≤ m.At the end of the algorithm, we have T groups of clusters that correspond to disjoint subsets of the dataset (as a side remark, we note that one always has T ≤ log 1/α n).
We denote the number of clusters in the i-th group by k i c , the clusters themselves byC i 1 ,C i 2 , . . . ,C i k ic ⊆ X and their centers byc i 1 , c i 2 , . . . , c i k i c ∈ R d .
During the query stage, we find u i clusters from the i-th group with the centers closest to the query point, then we retrieve all the data points from the corresponding ∑ T i=1 u i clusters, and finally from these retrieved points we select k nn data points that are closest to the query.We now describe one further optimization that helps to speed up the resulting k-NNS algorithm even more.
Namely, we collapse last several groups into a special set of points, which we call a stash, denoted by S ⊆ X.
In contrast to clusters from the remaining groups, to search the stash, we perform linear scan.
We denote s = |S| the stash size and T ≤ T the number of remaining groups of clusters that are not collapsed.The motivation for introducing the stash is that the last few groups are usually pretty small, so in order for them to contribute to the overall accuracy meaningfully, we need to retrieve most of the clusters from them.
But this means many DORAM accesses which are less efficient than the straightforward linear scan.Note that while the simplified version of Algorithm 3 is well-known and very popular in practice (see, e.g., [38,39]), our modification of the algorithm in this section, to the best of our knowledge, is new.
It is interesting to observe that in the "plaintext world", clustering algorithm is far from being the best for k-NNS (see [7] for the benchmarks), but several of its properties (namely, few non-adaptive memory accesses and that it requires computing many distances at once) make it very appealing for the secure computation.
We now give a high-level summary of our algorithms and in the next section we provide a more detailed description.
For the linear scan, we use the approximate top-k selection to return the k nn IDs after computing distances between query and all points in the database.For the clustering-based algorithm, we use approximate top-k selection for retrieving u i clusters in i-th group for all i ∈ {1, . . . , T }.
Then, we compute the closest k nn points from the query to all the retrieved points using the naive top-k algorithm.
Meanwhile, we compute the approximate top-k with k = k nn among distances between query and the stash.
Finally, we compute and output the k nn closest points from the above 2k nn candidate points.Note that in the clustering-based algorithm, we use exact top-k selection for retrieved points and approximate selection for cluster centers and stash.
The main reason is that the approximate selection requires input values to be shuffled.
The corresponding permutation can be known only by the server and not by the client to ensure that there is no additional leakage when the algorithm is implemented securely.
Jumping ahead to the secure protocol in the next section, the points we retrieve from the clusters will be secret-shared.
Thus, performing approximate selection on retrieved points would require a secure two-party shuffling protocol, which is New Query q Figure 2: Visualization of SANNS clustering-based algorithm.
function CLUSTERINGKNNS(q, C i j , c i j , S, ID) # The algorithm uses hyperparameters in Figure 1 Randomly permute the cluster centers in each group and all points in stashfor i ← 1, . . . , T do for j ← 1, . . . , k i c do d i j ← q − c i j 2 d i j ← d i j 2 rc end for (v 1 , ind i 1 ), . . . , (v u i , ind i u i ) ← ← APPROXTOPK((d i 1 , 1), . . . , (d i k i c , k i c ), u i , l i ) end for C ← 1≤i≤T 1≤ j≤u i C i ind i j for p ∈ C ∪ S do d p ← q − p 2 d p ← d p 2 rp end for (a 1 , ID 1 ), . . . , (a k nn , ID k nn ) ← ← NAIVETOPK({(d p , ID(p))} p∈C , k nn ) (a k nn +1 , ID k nn +1 ), . . . , (a 2k nn , ID 2k ) ← ← APPROXTOPK({(d p , ID(p))} p∈S , k nn , l s ) (v 1 , ID 1 ), . . . , (v k nn , ID k nn )) ← ← NAIVETOPK((a 1 , ID 1 ), . . . , (a 2k nn , ID 2k nn ), k nn ) return ID 1 , . . . , ID k nn end functionexpensive.
Therefore, we garble a naïve circuit for exact computation of top-k for the retrieved points.
Figure 2 visualizes SANNS clustering-based algorithm.
Figure 1 lists the hyperparameters used by our algorithms.
See Figure 5 and Figure 6 for the values that we use for various datasets.
Our plaintext algorithms are presented in Algorithm 3 and Algorithm 4.
Here we describe our secure protocols for k-NNS.
For the security proofs, see Appendix D.
The formal specifications of the protocols are given in Figure 6 and Figure 7.
On a high level, our secure protocols implement plaintext algorithms 3 and 4, which is color-coded for reader's convenience: we implemented the blue parts using AHE, yellow parts using garbled circuit, and red parts using DORAM.
These primitives are connected using secret shares, and we perform share conversions (between arithmetic and Boolean) as needed.
Here we define three ideal functionalities F TOPk , F aTOPk , and F DROM used in our protocol.
We securely implement the first two using garbled circuits, and the third using Floram [27].
Parameters: array size m, modulus t, truncation bit size r, output size k, bit-length of ID b pid Extra parameter: returnVal ∈ { f alse,true} (if set to true, return secret shares of (value, ID) pairs instead of just ID. )
• On input A c and idlist c from the client, store A c .
• On input A s , idlist s from the server, store A s and idlist.
• When both inputs are received, compute A = (A s + A c ) mod t = (a 1 , . . . , a n ) and seta i = [a i /2 r ], idlist = idlist c ⊕ idlist s .
Then, let (b, c) = MIN k n (a 1 , a 2 , .
.
.
, a n , idlist, k).
Sample an array w of size k with random entries in {0, 1} b pid , output c ⊕ w to the client, and w to the server.
If returnVal is true, sample a random array s of size k in Z 2 t , output b − s to client and s to the server.
Parameters: array size m, modulus t, truncation bit size r, output size k, bin size l, ID bit length b pid .
Extra parameter: returnVal ∈ { f alse,true} (if set to true, return (value, ID) instead of just ID. )
• On input A c ∈ Z m t from the client, store A c .
• On input A s ∈ Z m t and idlist from the server, store A s and idlist.
• When both inputs are received, compute A = A s + A c mod t = (a 1 , . . . , a n ).
and set a i = [a i /2 r ].
Let (b, c) = APPROXTOPK(a 1 , . . . , a n , idlist, k, l).
Sample an array w of size k with random entries in {0, 1} b pid .
Output c ⊕ w to the client, and w to the server.
If returnVal is true, sample a random array s of size k, output b − s to client and s to the server.
• Init: on input (Init, DB) from the server, it stores DB.
• Read: on input (Read, i c ) and (Read, i s ) from both client and server, it samples a random R ∈ {0, 1} b .
Then it outputs DB[(i s +i c ) mod n] ⊕ R to client and outputs R to server.
We use the BFV scheme [33] to compute distances.
Compared to [40], which uses BFV for matrix-vector multiplications, our approach avoids expensive ciphertext rotations.
Also, we used the coefficient encoding and a plaintext space modulo a power of two instead of a prime.
This allows us to later avoid a costly addition modulo p inside a garbled circuit.More precisely, SIMD for BFV requires plaintext modulus to be prime p ≡ 1 mod 2N.
However, it turns out our distance computation protocol only requires multiplication between scalars and vectors.
Therefore we can drop the requirement and perform computation modulo powers of two without losing efficiency.
Recall that plaintext space of the BFV scheme is R t := Z t [x]/(x N + 1).
The client encodes each coordinate in to a constant polynomial f i = q [i].
Assume the server points are p 1 , . . . , p N for simplicity.
It encodes these points into d plaintexts, each encoding one coordinate of all points, resulting ing i = ∑ j p j+1 [i]x j .
Note that ∑ d i=1 f i g i = ∑ N j=1 q, p j x j−1 .
The client sends encryption of f i .
Then the server computes an encryption h(x) = ∑ i f i g i , masks h(x) with a random polynomial and sends back to the client, so they hold secret shares of q, p j modulo t. Then, secret shares of Euclidean distances modulo t can be reconstructed via local operations.Note that we need to slightly modify the above routine when computing distances of points retrieved from DORAM.
Since the server does not know these points in the clear, we let client and server secret share the points and their squared Euclidean norms.Public Parameters: coefficient bit length b c , number of items in the database n, dimension d, AHE ring dimension N, plain modulus t, ID bit length b pid , bin size l s .
Inputs: client inputs query q ∈ R d ; server inputs n points and a list idlist of n IDs.1.
Client calls AHE.Keygen to get sk; server randomly permutes its points.
They both quantize their points into q , pi ∈ Z d 2 bc .
2.
Client sends c i = AHE.Enc(sk, q [i]) for 1 ≤ i ≤ d to the server.
3.
Server sets pik = p kN+1 [i] + p kN+2 [i]x + · · · + p (k+1)N [i]x N−1 ,samples random vector r ∈ Z n t and computes for 1 ≤k ≤ n/N f k = d ∑ i=1 AHE.CMult(c i , p ik ) + r[kN : (k + 1)N].
4.
Server sends f k to client who decrypts them to s ∈ Z n t .5.
Client sends −2s + ||q || 2 · (1, 1, . . . , 1) to F aTOPk , server sends idlist and (−2r i +||p i || 2 ) i to F aTOPk , with parameters (k, l s , f alse).
They output [id] c , [id] s ∈ {0, 1} b pid .
Server sends [id] s to client, who outputs id = [id] c ⊕ [id] s .
We briefly explain the functionality of Floram and refer the reader to the original paper [27] for details.
In Floram, both parties hold identical copies of the masked database.
Let the plaintext database be DB, block at address i be DB [i], and the masked database be DB.
We set:DB[i] = DB[i] ⊕ PRF k A (i) ⊕ PRF k B (i),where PRF is a pseudo-random function, k A is a secret key owned by A and k B is similarly owned by B.
At a high level, Floram's retrieval functionality consists of the two main parts: token generation using Functional Secret Sharing (FSS) [34] and data unmasking from the PRFs.
In Floram, FSS is used to securely generate two bit vectors (one for each party) u A and u B such that individually they look random, yet [i], the parties use a garbled circuit to compute the PRFs and XOR to remove the masks.
3 We implemented Floram with a few optimizations described below.u A j ⊕ u B j = 1 iff j = i,Precomputing OT To run FSS, the parties have to execute the GC protocol log 2 n times iteratively which in turn requires log 2 n set of Oblivious Transfers (OTs).
Performing consecutive OTs can significantly slow down the FSS evaluation.
We use Beaver OT precomputation protocol [10] which allows to perform all necessary OTs on random values in the beginning of FSS evaluation with a very small additional communication for each GC invocation.Public Parameters: coefficient bit length b c , number of items in the database n, dimension d, AHE ring dimension N, plain modulus t. Clustering hyperparameters: T , k i c , m, u i , s, l i , l s , b c , r c and r p .
Inputs: client inputs query q ∈ R d ; server inputs T groups of clusters with each cluster of size up to m, and a stash S; server also inputs a list of n IDs idlist, and all cluster centers c i j .
1.
Client calls AHE.Keygen to get sk.
2.
Client and server quantize their points and the cluster centers.
3.
Server sends all clusters with one block per cluster, and each point accompanied by its ID and squared norm, to F DROM .
Init, padding with dummy points if necessary to reach size m for each block.
4.
The server performs two independent random shuffles on the cluster centers and stash points.
5.
For each i ∈ {1, . . . , T },• The client and server use line 3-5 in Figure 6 to compute secret shares of the vector (||q − c i j || 2 2 ) j .
• Client and server send their shares to F aTOPk with k = u i , l = l i and returnVal = false, when server inputs the default idlist = {0, 1, . . . , k i c − 1}.
They obtain secret shares of indices j i 1 , . . . , j i u i .
6.
Client and server input secret shares of all cluster indices {(i, j i c ) :i ∈ [1, T ], c ∈ [1, u i ]} obtained in step 5 into F DROM .
Read, to retrieve Boolean secret shares of tuples (p, ID(p), ||p|| 2 ) of all points in the corresponding clusters.
They convert p and ||p|| 2 to arithmetic secret shares using e.g. the B2A algorithm in [23].
7.
Client and server use line 3-6 in Figure 6 to get secret shares of a distance vector for all points determined in step 6.
Then, they input Kreyvium as PRF Floram implemented PRF using AES.
While computing AES is fast in plaintext due to Intel AES instructions, it requires many gates to be evaluated within a garbled circuit.
We propose a more efficient solution based on Kreyvium [20] which requires significantly fewer number of AND gates (see Appendix B for various related trade-offs).
Evaluating Kreyvium during the initial database masking adds large overhead compared to AES.
To mitigate the overhead, we pack multiple (512 in our case) invocations of Kreyvium and evaluate them simultaneously by using AVX-512 instructions provided by Intel CPUs.Multi-address access In Floram, accessing the database at k different locations requires k log 2 n number of interactions.
In our case, these memory accesses are non-adaptive, hence we can fuse these accesses and reduce the number of rounds to log 2 n which has significant effect in practice.
We implement secure top-k selection using garbled circuit while we made some further optimizations to improve the performance.
First, we truncate distances by simply discarding some lower order bits, which allows us to reduce the circuit size significantly (see Section 3.2).
The second optimization comes from the implementation side.
Recall that existing MPC frameworks such as ABY [23] require storing the entire circuit explicitly with accompanying bloated data structures.
However, our top-k circuit is highly structured, which allows us to work with it looking at one small part at a time.
This means that the memory consumption of the garbling and the evaluation algorithms can be essentially independent of n, which makes them much more cache-efficient.
To accomplish this, we developed our own garbled circuit implementation with most of the standard optimizations [11,12,41,71] 4 , which allows us to save more than an order of magnitude in both time and memory usage compared to ABY.
We perform the evaluation on two Azure F72s_v2 instances (with 72 virtual cores equivalent to that of Intel Xeon Platinum 8168 and 144 GB of RAM each).
We have two sets of experiments: for fast and slow networks.
For the former we use two instances from the "West US 2" availability zone (latency 0.5 ms, throughput from 500 MB/s to 7 GB/s depending on the number of simultaneous network connections), while for the latter we run on instances hosted in "West US 2" and "East US" (latency 34 ms, throughput from 40 MB/s to 2.2 GB/s).
We use g++ 7.3.0, Ubuntu 18.04, SEAL 2.3.1 [52] and libOTe [59] for the OT phase (in the single-thread mode due to unstable behavior when run in several threads).
For networking, we use ZeroMQ.
We implement balanced clustering as described in Section 3.3 using PyTorch and run it on four NVIDIA Tesla V100 GPUs.
It is done once per dataset and takes several hours (with the bottleneck being the vanilla k-means clustering described in Section 2.5).
We evaluate SANNS algorithms as well as baselines on four datasets: SIFT (n = 1 000 000, d = 128) is a standard dataset of image descriptors [48] that can be used to compute similarity between images; Deep1B (n = 1 000 000 000, d = 96) is also a dataset of image descriptors [8], which is built from feature vectors obtained by passing images through a deep neural network (for more details see the original paper [8]), Amazon (n = 2 20 , d = 50) is dataset of reviews [51], where feature vectors are obtained using word embeddings.
We conduct the evaluation on two subsets of Deep1B that consist of the first 1 000 000 and 10 000 000 images, which we label Deep1B-1M and Deep1B-10M, respectively.
For Amazon, we take 2 20 Amazon reviews of the CDs and Vinyls category, and create a vector embedding for each review by processing GloVe word embeddings [56] as in [5].
SIFT comes with 10 000 sample queries which are used for evaluation; for Deep1B-1M, Deep1B-10M and Amazon, a sample of 10 000 data points from the dataset are used as queries.
For all the datasets we use Euclidean distance to measure similarity between points.
Note that the Deep1B-1M and Deep1B-10M datasets are normalized to lie on the unit sphere.Note that all four datasets have been extensively used in nearest neighbors benchmarks and information retrieval tasks.
In particular, SIFT is a part of ANN Benchmarks [7], where a large array of NNS algorithms has been thoroughly evaluated.
Deep1B has been used for evaluation of NNS algorithms in, e.g., [8,39,49].
Various subsets of the Amazon dataset have been used to evaluate the accuracy and the efficiency of k-NN classifiers in, e.g., [28,44].
Accuracy In our experiments, we require the algorithms to return k nn = 10 nearest neighbors and measure accuracy as the average portion of correctly returned points over the set of queries ("10-NN accuracy").
Our algorithms achieve 10-NN accuracy at least 0.9 (9 out of 10 points are correct on average), which is a level of accuracy considered to be acceptable in practice (see, e.g., [43,45]).
Quantization of coordinates For SIFT, coordinates of points and queries are already small integers between 0 and 255, so we leave them as is.
For Deep1B, the coordinates are real numbers, and we quantize them to 8-bit integers uniformly between the minimum and the maximum values of all the coordinates.
For Amazon we do the same but with 9 bits.
For these datasets, quantization barely affects the 10-NN accuracy compared to using the true floating point coordinates.Cluster size balancing As noted in Section 3.3, our cluster balancing algorithm achieves the crucial bound over the maximum cluster size needed for efficient ORAM retrieval of candidate points.
In our experiments, for SIFT, Deep1B-10M, Amazon and Deep1B-1M, the balancing algorithm reduced the maximum cluster size by factors of 4.95×, 3.67×, 3.36× and 3.31×, respectively.Parameter choices We initialized the BFV scheme with parameters N = 2 13 , t = 2 24 for Amazon and t = 2 23 for the other datasets, and a 180-bit modulus q. For the parameters such as standard deviation error and secret key distribution we use SEAL default values.
These parameters allow us to use the noise flooding technique to provide 108 bits of statistical circuit privacy.
5 The LWE estimator 6 by Albrecht et al. [2] suggests 141 bits of computational security.Here is how we set the hyperparameters for our algorithms.
See Figure 1 for the full list of hyperparameters, below we list the ones that affect the performance:• Both algorithms depend on n, d, k nn , which depend on the dataset and our requirements; • The linear scan depends on l s , b c and r p , • The clustering-based algorithm depends on T , k i c , m, u i , s, l i , l s , b c , r c and r p , where 1 ≤ i ≤ T .
We use the total number of AND gates in the top-k and the ORAM circuits as a proxy for both communication and running time during hyperparameter search phase (this is due to the complexity of garbling a circuit depending heavily on the number of AND gates due to the Free-XOR optimization [41]).
Moreover, for simplicity we neglect the FSS part of ORAM, since it does not affect the performance much.
Overall, we search for the hyperparameters that yield 10-NN accuracy at least 0.9 minimizing the total number of ANDgates.
In Figure 5 and Figure 6 of Appendix A, we summarize the parameters we use for both algorithms on each dataset.
Single-thread We run SANNS on the above mentioned four datasets using two algorithms (linear scan and clustering) over fast and slow networks in a single-thread mode, summarizing results in Table 1.
We measure per-client preprocessing of Floram separately and split the query measurements into the OT phase, distance computation, approximate top-k selection and ORAM retrievals.
For each of the components, we report communication and average running time for fast and slow networks.
We make several observations:• On all the datasets, clustering-based algorithm is much faster than linear scan: up to 12× over the fast network and up to 8.2× over the slow network.
• For the clustering algorithm, per-client preprocessing is very efficient.
In fact, even if there is a single query per client, clustering algorithm with preprocessing is faster than the linear scan.
• In terms of communication, distance computation part is negligible, and the bottleneck is formed by the top-k selection and ORAM (which are fairly balanced).
• As a result, when we move from fast to slow network, the time for distance computation stays essentially the same, while the time for top-k and ORAM goes up dramatically.
This makes our new circuit for approximate top-k selection and optimizations to Floram absolutely crucial for the overall efficiency.Multi-thread In Table 2 we summarize how the performance of SANNS depends on the number of threads.
We only measure the query time excluding the OT phase, since libOTe is unstable when used from several threads.
We observe that the speed-ups obtained this way are significant (up to 8.4× for the linear scan and up to 7.1× for clustering), though they are far from being linear in the number of threads.
We attribute it to both of our algorithms being mostly memoryand network-bound.
Overall, the multi-thread mode yields query time under 6 seconds (taking the single-threaded OT phase into account) for our biggest dataset that consists of ten million 96-dimensional vectors.
As we discussed in the Introduction, all the prior work that has security guarantees similar to SANNS implements linear scan.
Thus, in order to provide a detailed comparison, we compare our approaches in terms of distance computation and top-k against the ones used in the prior work.Top-k selection We evaluate the new protocol for the approximate top-k selection via garbling the circuit designed in Section 3.1 and compare it with the naïve circuit obtained by a direct implementation of Algorithm 1.
The latter was used in some of the prior work on the secure k-NNS [6,61,64].
We assume the parties start with arithmetic secret shares of n = 1 000 000 24-bit integers.
We evaluate both of the above approaches for k ∈ {1, 5, 10, 20, 50, 100}.
For the approximate selection, we set the number of bins l such that on average we return (1 − δ) · k entries correctly for δ ∈ {0.01, 0.02, 0.05, 0.1}, using the formula from the proof of Theorem 1.
For each setting, we report average running time over slow and fast networks as well as the total communication.
Table 4 summarizes our experiments.
As expected, the performance of the approximate circuit is essentially independent of k, whereas the performance of the naïve circuit scales linearly as k increases.
Even if we allow the error of only δ = 0.01 (which for k = 100 means we return a single wrong number), the performance improves by a factor up to 25 on the fast network and up to 37 on the slow network.
The works [62,63] used fully-homomorphic encryption (FHE) for the top-k selection.
However, even if we use TFHE [22], which is by far the most efficient FHE approach for highly-nonlinear operations, it will still be several orders of magnitude slower than garbled circuits, since TFHE requires several milliseconds per gate, whereas GC requires less than a microsecond.Distance Computation The most efficient way to compute n Euclidean distances securely, besides using the BFV scheme, is arithmetic MPC [23] based on oblivious transfer (one other alternative used in many prior works [9,[29][30][31]60] is Paillier AHE scheme, which is known to be much less suitable for the task due to the absence of SIMD capabilities [40]).
Let us compare BFV scheme used in SANNS with the OTbased distance computation from [23] with an optimization from [53].
The latter allows to compute n l-bit distances between d-dimensional vectors (l = 24 for Amazon, l = 23 for all the other datasets), using ndl(l + 1)/256 OTs of 128-bit strings.
We perform those OTs using libOTe for each of our datasets and measure time (over fast and slow networks) as well as communication.
The results are summarized in Table 3.
As expected, the communication required by OT-based multiplication is much larger than for AHE (by a factor up to 127×).
As a result, for the slow network, OT-based multiplication is noticeably slower, by a factor up to 7.5×; for the fast network, OT-based approach is no more than 4% faster than AHE.
We have shown that individual components used by SANNS are extremely competitive compared to the ones proposed by the prior work.
Here, we provide the end-to-end performance results on the largest dataset we evaluated SANNS on: Deep1B-10M.
For the fast network, our linear scan requires 395 seconds per query (taking the OT phase into account), and clustering requires 31 seconds; for the slow network, it is 1720 and 194 seconds, respectively (see Table 1).
One issue with a fair comparison with the prior work is that they are done before the recent MPC and HE optimizations became available.
Based on the benchmarks in the previous section, one can definitively conclude that the fastest protocol from the prior work is from [23].
Namely, we compute distances using OT with the optimization from [53], and perform the top-k selection using garbled circuit with the naïve circuit in Algorithm 1.
To estimate the running time of this protocol, we use Table 3 for distances and we run a separate experiment for naïve top-k for n = 10 7 and k = 10.
This gives us the lower bound on the running time of 578 seconds on the fast network and 6040 seconds on the slow network, and the lower bound of 240 GB on the communication.Overall, this indicates that our linear scan obtains a speedup of 1.46× on the fast network and 3.51× on the slow network.
The clustering algorithm yields the speed-up of 18.5× on the fast network and 31.0× on the slow network.
The improvement in communication is 4.1× for the linear scan and 39× for the clustering algorithm.Note that these numbers are based on the lower bounds for the runtime of prior work and several parts of the computation and communication of their end-to-end solution are not included in this comparison.
In particular, just computing distances using the original implementation from [23] on SIFT dataset takes 620 seconds in the fast network, more than 32× higher compared against our assumed lower bound of 19.1 seconds in Table 3.
When scaling their implementation to ten million points, the system runs out of memory (more than 144 GB of RAM is needed).
In conclusion, the speed-up numbers we reported reflect running the best prior algorithm using our Table 4: Comparison of the exact and the approximate top-k selection protocols (selecting from one million values).
Each cell has two timings: for the fast and the slow networks.
We report the speed-ups for fast and slow networks between the approximate algorithm with error rate δ = 0.01 and the exact algorithm.new optimized implementation, which leads to a more fair comparison (SANNS speed-up is significantly higher if the original implementations of prior works are considered).
In this work, we design new secure computation protocols for approximate k-Nearest Neighbors Search between a client holding a query and a server holding a database, with the Euclidean distance metric.
Our solution combines several state-of-the-art cryptographic primitives such as lattice-based AHE, FSS-based distributed ORAM and garbled circuits with various optimizations.
Underlying one of our protocols is a new sublinear-time plaintext approximate k-NNS algorithm tailored to secure computation.
Notably, it is the first sublineartime k-NNS protocol implemented securely.
Our performance results show that our solution scales well to massive datasets consisting of up to ten million points.
We highlight some directions for future work: • Our construction is secure in the semi-honest model, but it would be interesting to extend our protocols to protect against malicious adversaries which can deviate from the protocol.
• One possible future direction is to implement other sublinear k-NNS algorithms securely, most notably Locality-Sensitive Hashing (LSH) [4], which has provable sublinear query time and is widely used in practice.
• It is important to study to what extent k-NNS queries leak information about the dataset and how much approximation in the answers adds to this leakage.
For instance, the client may try to locate individual points in a dataset by asking several queries that are perturbations of each other and checking if the point of interest ends up in the answer.
For low-dimensional datasets there are known strong recovery attacks [42], but for the high-dimensional case-which is the focus of this paperthe possibility of such attacks remains open.
Besides attacks, an interesting research direction is how to restrict the client (in the number of k-NNS queries or the degree of adaptivity) so to minimize the dataset leakage.
That being said, let us state a few simple observations about additional leakage that can happen due to approximation in the results.
There are two sources of approximation: approximate top-k selection and clustering-based k-NNS algorithm.
For the sake of simplicity, let us discuss the effects of these components separately.
For the former, one can show that the probability that the element with rank l > k is included in the output is exponentially small in l − k. For the latter, we can notice the following.
First, we never leak more than the union of the sets of points closest to the query in the clusters whose centers are closest to the query.
Second, if the dataset is clusterable (i.e., can be partitioned into clusters with pairwise distances being significantly larger than the diameters of the clusters) and queries are close to clusters, then the clustering based k-NNS algorithm is exact and there is no additional leakage due to approximation.
In Table 5 and Table 6, we summarize the parameters we use for both of our algorithms on each of the datasets.
In the original Floram construction [25][26][27], the PRF and the PRG used in the read-only process are chosen by the authors to be AES-128.
The implementations of AES are highly optimized, with less than 5000 non-free gates per block [18].
As an alternative to AES, the authors also propose the streams Salsa20 [14] and its variant Chacha20 [13].
However, other symmetric ciphers can be used to obtain an efficient PRF/PRG.
In particular, we looked for a PRF with low number of AND gates in order to decrease the communication between the parties when it is evaluated in GC (in the Free-XOR setting).
Some of the most promising constructions are the block cipher LowMC [3] and the stream cipher Kreyvium [20] (variant of Trivium [19]).
In particular Kreyvium is flexible in terms of input and output size, since there is no fixed block size to respect, and its evaluation is very efficient in terms of AND gates per output bit of stream.
The advantage in using Kreyvium starts showing when the size of the inputs starts growing.
In Table 7 we estimate the number of AND gates that are executed by the different ciphers for 3 dataset sizes.We compute 2 PRFs per input, so the actual number of AND gates in Table 7 should be doubled.
Table 7: Estimates on the number of AND gates for ciphers AES-128, Chacha20 and Kreyvium for different input sizes.
The estimates for Chacha20 refer to a naive implementation of the scheme: we believe that the scheme would be more efficient in terms of non trivial gates in practice, but we did not found such optimal estimates in the literature.
We do not report the number of AND gates for LowMC: they should be comparable to the estimates we have for Kreyvium for an optimal choice of the parameters.While our approach is more efficient in GC with respect to Floram, the plaintext evaluation of Kreyvium is slower than the (highly optimized) hardware implementation of AES.
In order to mitigate this issue, we vertically batch 512 bits and we compute multiple streams in parallel (using AVX-512), so we are able to process several hundreds of Mega Bytes of information per second in single core.
In this section, we give proofs for Theorem 1 and Theorem 2.
Proof of Theorem 1.
First, suppose that we assign a bin for each element uniformly and independently.
For this sampling model, it is not hard to see that the desired expectation of the size of the intersection I is:E [|I |] = l · Pr[U i contains at least one of the top-k elements] = l · 1 − 1 − 1 l k, where the first step follows from the linearity of expectation, and the second step is an immediate calculation.
Suppose that l = k/δ, where δ > 0 is sufficiently small, and suppose that k → ∞.
Then, continuing the calculation,l · 1 − 1 − 1 l k = k δ · 1 − e k·ln(1− δ k ) = k δ 1 − e −δ+O(1/k) = k·(1−e −δ ) δ + O(1) ≥ k· δ− δ 2 2 δ + O(1) = k · 1 − δ 2 + O(1), where the second step uses the Taylor series of ln x, the third step uses the Taylor series of e x and the fourth step uses the inequality e −x ≤ 1 − x + x 2 2 , which holds for small x > 0 .
To argue about the actual sampling process, where instead of uniform and independent assignment we shuffle elements and partition them into l blocks of size n/l, we use the main result of [24].
Namely, it is true that the probability Pr[U i contains at least one of the top-k elements]can change by at most O(1/l) when passing between two sampling processes.
This means that the overall expectation changes by at most O(1), and is thus still at least:k · 1 − δ 2 + O(1).
For a fixed δ, this expression is at least (1 − δ)k, whenever k is sufficiently large.Proof of Theorem 2.
As in the proof of the previous theorem, we start with a simpler sampling model, where bins are assigned independently.
Suppose that δ > 0 is fixed and k tends to infinity.
We set l = k 2 /δ.
In that case, one has:Pr[all top-k elements end up into different bins] = 1 − 1 l · 1 − 2 l · . . . · 1 − k−1 l = 1 − δ k 2 · 1 − 2δ k 2 · . . . · 1 − (k−1)·δ k 2 = exp ln 1 − δ k 2 + ln 1 − 2δ k 2 + . . . + ln 1 − (k−1)·δ k 2 = exp − δ(1+2+...+(k−1)) k 2 + O 1 k = e −δ/2 + O 1 k ≥ 1 − δ 2 + O 1 k, where the fourth step uses the Taylor series of ln x and the sixth step uses the inequality e −x ≥ 1 − x.
The final bound is at least 1 − δ provided that k is large enough.
Now let us prove that for the actual sampling procedure (shuffling and partitioning into l blocks of size n/l), the probability of top-k elements being assigned to different bins can only increase, which implies the desired result.
For the simplified sampling model, each of these conditional probabilities is equal to 1/l due to the independence of c i .
However, for the actual model, they are larger: if we condi-tion on t equalities, then the probability is equal to n l(n−t) .
This implies the required monotonicity result.
We prove simulation-based security for our protocols for approximate k-NNS.
First, we recall the definition (see e.g. [46]) of two party computation and simulation-based security for semi-honest adversaries.
Definition 1.
A two-party functionality is a possibly randomized function f : {0, 1} * × {0, 1} * → {0, 1} * × {0, 1} * , that is, for every pair of inputs x, y ∈ {0, 1} n , the output-pair is a random variable ( f 1 (x, y), f 2 (x, y)).
The first party (with input x) obtains f 1 (x, y) and the second party (with input y) obtains f 2 (x, y).
Let π be a protocol computing the functionality f .
The view of the i-th party during an execution of π on (x, y) and security parameter λ is denoted by View π,i (x, y, λ) and equals the party i's input, its internal randomness, plus all messages it receives during the protocol.Definition 2.
Let f = ( f 1 , f 2 ) be a functionality and let π be a protocol that computes f .
We say that π securely computes f in the presence of static semi-honest adversaries if there exist probabilistic polynomial-time algorithms S 1 and S 2 (often called simulators) such that (S 1 (1 λ , x, f 1 (x, y)), f (x, y)) ≈ (View π,1 (x, y, λ), f (x, y)) and (S 2 (1 λ , y, f 2 (x, y)), f (x, y)) ≈ (View π,2 (x, y, λ), f (x, y)).
Here ≈ means computational indistinguishability.
First, we define the ideal functionalities that our protocol achieves.
Note that the two protocols have slightly different ideal functionalities.
We will denote them by F ANN cl (for clustering) and F ANN ls (for linear scan).
Parameters: number of elements n, dimension d, bits of precision b c .
• Input: client inputs a query q ∈ R d and server inputs database DB = [(p i , ID i )] n i=1 .
Note that points are truncated to b c bits.
• Output: returns output of Algorithm 3 to client.
Proof.
First, we construct a simulator for the client.
The simulator generates a key sk for the AHE scheme and sends sk to the client.
Then, it simulates the server's first message as AHE.Enc(sk, r i ) for random values r i .
From the circuit privacy property of the AHE scheme, this is indistinguishable from the first message in the real protocol.
Next, the simulator simply feeds {r i } to the ideal functionality F aTOPk and forwards the output to the client.
This completes the simulation.Next, we construct a simulator for the server.
The simulator generates a key sk for the AHE scheme.
The first message from the client to the server consists of the encryptions AHE.
Enc(sk, q[i]) in the real protocol.
Instead, the simulator just sends AHE.Enc(sk, 0) for 1 ≤ i ≤ d. Based on the RLWE assumption, these views are indistinguishable.
Finally, the simulator generates random vector R = (r 1 , . . . , r n ) and sends that to the server.
Proof.
Again correctness is easy to verify.
We first describe simulator for the client.
First, the simulator generates a secret key sk for the AHE scheme and sends sk to the client.
Next, the simulator sends blocks of zero to F DROM .
Init.
Then, on receiving the query message from the client, the simulator does the following: for each i, j, it samples random values r i j and generates AHE.Enc(sk, r i j ).
Using a similar argument as in the previous proof, these ciphertexts are indistinguishable from the client's view of the first step of the secure protocol.Then, the simulator forwards the r i j to F aTOPk and gets back it forwards the output to the client.
Since the intermediate values revealed to the client are all independent uniformly random values, the view generated from simulator is indistinguishable from the real view.
Now, the simulator for server works in almost the same fashion, with the difference that in contrast to the real client which sends AHE.Enc(sk, q i ) for 1 ≤ i ≤ d, the simulator simply sends d encryption of zeros.
This is indistinguishable from uniform, based on the RLWE assumption.
We would like to thank the anonymous reviewers for their feedback and helpful comments.
This work was partially done while all the authors visited Microsoft Research Redmond.The second-named author has been supported in part by ERC Advanced Grant ERC-2015-AdG-IMPaCT, by the FWO under an Odysseus project GOH9718N and by the CyberSecurity Research Flanders with reference number VR20192203.
Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the ERC or FWO.
