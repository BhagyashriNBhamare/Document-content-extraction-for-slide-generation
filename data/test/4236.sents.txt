In this work, we consider distributed private learning.
For this purpose, companies collect statistics about telemetry, usage and frequent settings from their users without disclosing individual values.
We focus on rank-based statistics, specifically, the median which is more robust to outliers than the mean.
Local differential privacy, where each user shares locally perturbed data with an untrusted server, is often used in private learning but does not provide the same accuracy as the central model, where noise is applied only once by a trusted server.
Existing solutions to compute the differentially private median provide good accuracy only for large amounts of users (local model), by using a trusted third party (central model), or for a very small data universe (secure multi-party computation).
We present a multi-party computation to efficiently compute the exponential mechanism for the median, which also supports, e.g., general rank-based statistics (e.g., p th-percentile, interquartile range) and convex optimizations for machine learning.
Our approach is efficient (practical running time), scaleable (sublinear in the data universe size) and accurate, i.e., the absolute error is smaller than comparable methods and is independent of the number of users, hence, our protocols can be used even for a small number of users.
In our experiments we were able to compute the differentially private median for 1 million users in 3 minutes using 3 semi-honest computation parties distributed over the Internet.
We consider the problem of distributed private learning.
Specifically, how multiple users can compute rank-based statistics over their sensitive data, with high accuracy, a strong privacy guarantee, and without resorting to trusted third parties.
Rank-based statistics include the median, p th -percentiles, and interquartile ranges, and we present a protocol to compute the differentially private median, which is extensible to any k th ranked element.
We use differential privacy (DP) [25,28], a rigorous privacy notion, restricting what can be inferred about any individual in the data, used by Google [15,31], Apple [1,66], Microsoft [23] and the US Census bureau [2].
The median is a robust statistical method used to represent a "typical" value from a data set, e.g., insurance companies use the median life expectancy to adjust insurance premiums.Previous work on DP median computation either require a large number of users to be accurate [27,34,63], rely on a trusted third party [51,58], or cannot scale to large universe or data set sizes [14,30,59].
We present a novel alternative that is superior in accuracy, requires no trusted party, and is efficiently computable.
Our protocol provides high accuracy even for a small number of users.
Note that small sample size is the most challenging regime for DP [56].
Even Google's large-scale data collection (billions of daily reports via [31]) is insufficient if the statistical value of interest is not a heavy hitter [15], e.g., the median.We present a secure multi-party computation (MPC) of the exponential mechanism [52] for decomposable aggregate functions.
Such functions, as used in MapReduce-style algorithms [22], allow efficient aggregation in parallel over distributed data sets, and application examples include convex loss functions and rank-based statistics.
The exponential mechanism can implement any differentially private algorithm by computing selection probabilities for all possible output elements.
Its computation complexity is linear in the size of the data universe [52] and efficiently sampling it is non-trivial [29].
Also, the exponential mechanism requires exponentiations, increasing the MPC complexity.
However, as it is a universal mechanism, a scalable, secure implementation can be widely applied.
Eigner et al. [30] also implement the exponential mechanism in MPC.
They compute the exponential function with MPC, whereas we provide a more efficient alternative for decomposable functions.
Their approach, while more general, is only practical for a universe size of 5 elements, whereas our protocol is sublinear in the size of the universe and handles billions of elements.
We achieve this via divide-and-conquer and optimizing our protocol for decomposable functions that enable efficient alternatives to expensive secure computation of exponentiations [5,7,20,43].
In summary, our contribution is a protocol for securely computing the differentially private median• with high accuracy even for small data sets (few users) and large universe sizes (see Section 3.4 for our theoretical errors bounds, Appendix F for a comparison of that bound to related work, and Section 5.3 for empirical comparison to related work),• that is efficient (practical running time for millions of users) and scalable (sublinear in the data universe size) (Sections 4, 5),• secure in the semi-honest model with an extension to the malicious model (Section 4.6) and outputs the differentially private median according to the exponential mechanism by McSherry and Talwar [52],• evaluated using an implementation in the SCALE-MAMBA framework [6], for 1 million users using 3 semi-honest computation parties with a running time of seconds in a LAN, and 3 minutes in a WAN with 100 ms network delay, 100 Mbits/s bandwidth (Section 5).
The remainder of this paper is organized as follows: In Section 2 we describe preliminaries for our protocol.
In Section 3 we explain our protocol and introduce definitions.
We present our protocol and implementation details for the secure multi-party computation of the differentially private median in Section 4.
We provide a detailed performance evaluation in Section 5, describe related work in Section 6 and conclude in Section 7.
In the following, we introduce preliminaries for differential privacy and secure multi-party computation.We consider a set of input parties P = {P 1 , . . . , P n }, where party P i holds a datum d i , and D denotes their combined data set.
We model a data set as D = {d 1 , . . . , d n } ∈ U n with underlying data universe U.
We also consider m semi-honest computation parties, e.g., m ∈ {3, 6, 10}, who run the computation on behalf of the input parties.
To simplify presentation, we assume the size n of D to be even, which can be ensured by padding.
Then, the median's position in sorted D is n/2.
Differential privacy (DP), introduced by Dwork et al. [25,28], is a strong privacy guarantee restricting what a mechanism operating on a sensitive data set can output.
Informally, when the input data set changes in a single element, the effect on the output is bounded.
The formal definition is as follows:Definition 1 (Differential Privacy).
A mechanism M satisfies ε-differential privacy, where ε ≥ 0, if for all neighboring data sets D D , i.e., data sets differing in a single entry, and all sets S ⊆ Range(M )Pr[M (D) ∈ S] ≤ exp(ε) · Pr M (D ) ∈ S ,where Range(M ) denotes the set of all possible outputs of mechanism M .
The above definition holds against an unbounded adversary, however, due to our use of cryptography we assume a computationally bounded adversary.
A formal definition is presented in Appendix A based on MPC preliminaries from Section 2.2.
Randomization is essential for differential privacy to hide an individual's inclusion in the data [29].
Noise, added to the function output, is one way to achieve differential privacy, e.g., via the Laplace mechanism [29]:Definition 2 (Laplace Mechanism).
Given a function f : U n → R with sensitivity max ∀DD | f (D) − f (D )|, privacyparameter ε, and a database D, the Laplace mechanism releases f (D) + r, where r is drawn from the Laplace distribution (centered at 0) with density ε2∆ f e −ε ∆ f .
The alternative to additive noise is probabilistic output selection via the exponential mechanism, introduced by McSherry and Talwar [52].
The exponential mechanism expands the application of differential privacy to functions with nonnumerical output, or when the output is not robust to additive noise, e.g., the median function [48].
The mechanism is exponentially more likely to select "good" results where "good" is quantified via a utility function u(D, r) which takes as input a database D ∈ U n , and a potential output r ∈ R from a fixed set of arbitrary outputs R .
Informally, higher utility means the output is more desirable and its selection probability is increased accordingly.Definition 3 (Exponential Mechanism).
For any utility function u : (U n × R ) → R and a privacy parameter ε, the exponential mechanism EM ε u (D) outputs r ∈ R with probability proportional to exp( εu (D,r) 2∆u ), where∆u = max ∀r∈R ,DD u(D, r) − u D , ris the sensitivity of the utility function.
That is,Pr[EM ε u (D) = r] = exp εu(D,r) 2∆u ∑ r ∈R exp εu(D,r ) 2∆u .
(1)We omit u, ε, D, i.e., write EM, if they can be derived from the context.
DP algorithms M can be implemented in different models, visualized in Figure 1.
Next, we describe the models and explain which model we implement. . . .
Trusted Serverd 1 d n M ( f (d 1 , . . . , d n )) (a) Central Model C 1 . . . Untrusted Serverr 1 =M (d 1 ) r n =M (d n ) f (r 1 , . . . , r n ) (b) Local Model C 1 . . . Shuffler Untrusted Serverr 1 =M (d 1 ) r n =M (d n ) r π(1) . . . r π(n) f r π(1) , . . . , r π(n)(c) Shuffle Model with permutation π Figure 1: Models for DP mechanism M .
Client C i sends a message (raw data d i or randomized r i ) to a server, who computes function f over the messages, and releases the result.
In the central model ( Figure 1a) every client sends their unprotected data to a trusted, central server which runs M on the clear data.
The central model provides the highest accuracy as the randomization inherent to DP algorithms, is only applied once.
In the local model (Figure 1b), introduced by [44], clients apply M locally and sent anonymized values to an untrusted server for aggregation.
The accuracy is limited as the randomization is applied multiple times.
Hence, it requires a very large number of users to achieve accuracy comparable to the central model [15,18,40,44,50].
Specifically, an exponential separation between local and central model for accuracy and sample complexity was shown by [44].
Recently, an intermediate shuffle model ( Figure 1c) was introduced [15,18]: A trusted party is added between client and server in the local model, the shuffler, who does not collude with anyone.The shuffler permutes and forwards the randomized client values.
The permutation breaks the mapping between a client and her value, which reduces randomization requirements.
The accuracy of the shuffle model lies between the local and central model, however, in general it is strictly weaker than the central model [9,18].
As our goal is high accuracy without trusted parties even for small number of users, we simulate the central model in a distributed setting via secure multi-party computation (MPC), which is often used in DP literature [26,30,38,59,60,65].
MPC, further described in Section 2.2, is a cryptographic protocol run by clients over their sensitive data that only reveals the computation output without requiring a trusted server.
General MPC incurs high computation and communication overhead which reduce efficiency and scalability [18].
However, MPC combines the respective benefits of the models, namely, high accuracy and strong privacy, i.e., no disclosure of values to a third party, and we present an efficient and scaleable MPC protocol.
Next, we illustrate why the exponential mechanism offers better accuracy than additive noise w.r.t. the DP median.
Recall, the noise depends on the sensitivity of function f and the privacy parameter ε.
The sensitivity is the largest difference a single change in any possible database can have on the function result.
Smooth sensitivity, developed by Nissim et al. [58], additionally analyzes the data to provide instancespecific additive noise that is often much smaller.
(See Appendix F for a formal description.)
However, computation of smooth sensitivity requires access to the entire data set, otherwise the error increases further 1 , which prohibits efficient (secure) computation with high accuracy.
Li et al. [48] note that the Laplace mechanism is ineffective for the median as (smooth) sensitivity can be high.
Additionally, they present a median utility function for the exponential mechanism with low, data-independent sensitivity, which we use in our protocol.
To illustrate that additive noise can be high, we empirically evaluated the absolute error of the Laplace mechanism with smooth sensitivity, the exponential mechanism, and our protocol in Figure 2 on real-world data sets [42,67].
Our protocol uses the exponential mechanism in multiple steps, and while the accuracy is not the same as for (single use of) the exponential mechanism, we do not require a trusted third party.
Overall, we achieve better accuracy than additive noise for low ε (corresponding to high privacy protection) with better scalability than the exponential mechanism.
We provide our accuracy bounds in Section 3.4, further empirical evaluations w.r.t. related work in Section 5.3, and describe related work in Section 6.
Secure multi-party computation (MPC) [36] allows a set of three or more parties P = {P 1 , . . . , P n }, where party P i holds sensitive input d i , to jointly compute a function y = f (d 1 , . . . , d n ) while protecting their inputs.
The computation must be correct, i.e., the correct y is computed, and secret, i.e., only y and nothing else is revealed.
There are two main implementation paradigms for MPC [32,46]: garbled circuits [68] 2 , where the parties construct a (large, encrypted) circuit and evaluate it at once, and secret sharing [12,21,57,62], where the parties interact for each circuit gate.
In general, the former allows for constant number of rounds but requires larger bandwidth (as fewer, but bigger messages are sent), and the latter has low bandwidth (small messages per gate) and high throughput, where the number of rounds depends on the circuit depth.
We will focus on secret-sharing-based MPC as our goal is an efficient implementation in a network with reasonable latency.
Informally, a (t, n)-secret sharing scheme splits a secret s into n shares s i and at least t shares are required to reconstruct the secret.
We use s = (s 1 , . . . , s n ) to denote the sharing of s among n parties (for a formal definition see, e.g., Evans et al. [32]).
Recent works, e.g., SCALE-MAMBA [6], BDOZ [12], SPDZ [21], improve MPC performance by combining a computationally secure offline phase, to exchange correlated randomness (e.g., Beaver triples [11]), with an information-theoretic secure online phase.
The former is generally more efficient since the latter requires asymmetric cryptography [47].
MPC can be implemented in two models with different trust assumptions: in the semi-honest model (passive) adversaries do not deviate from the protocol but gather everything created during the run of the protocol, in the malicious model (active) adversaries can deviate from the protocol (e.g., alter messages).
In this work we consider n input parties with sensitive input, and m (e.g., m ∈ {3, 6, 10}) semi-honest computation parties, i.e., non-colluding untrusted servers.
The input parties create and send shares of their input to the computation parties, which run the secure computation on their behalf.
We assume semi-honest parties but explain how to extend our protocol to malicious parties and implement our protocol with the SCALE-MAMBA framework [6].
(i) the running time complexity is linear in the size of the data universe, |U|, as selection probabilities for all possible outputs in U are computed,(ii) the general mechanism is too inefficient for general secure computation as selection probability computation requires |U| exponentiations over floating-point numbers.We solve these challenges by (i) recursively dividing the data universe into subranges to achieve sublinear running time in |U|, and (ii) focusing on utility functions which allow efficient selection probability computation.
We call such utility functions decomposable, which we formalize in Section 3.1, and give example applications.In the following, we describe an overview of our solution.
We efficiently compute the exponential mechanism with running time complexity sublinear in the size of the data universe U by dividing U into k subranges.
We select the best subrange and also split it into k subranges for the next iteration, until the last subrange is small enough to directly select the final output from it.
After log k |U| iterations the selected subrange contains only one element.
Each subrange selection increases the overall privacy loss ε, and we enable users to select a trade-off between running time, privacy loss and accuracy by presenting three protocols to compute unnormalized selection probabilities, which we call weights, w.r.t. ε:• Weights ln(2) fixes ε = ln(2) to compute exp(εy) as 2 y ,• Weights ln(2)/2 d allows ε = ln(2) 2 d for some integer d > 0, • Weights * supports arbitrary ε.On a high-level, we have three phases in each iteration:1.
Evaluate: Each party locally computes the basis for utility scores for each subrange.2.
Combine: They combine their results into a global result and compute selection probabilities.3.
Select: Finally, they select an output based on its selection probabilities.The results of the evaluation step are computed over sensitive data and might also be sensitive (e.g., utility functions for median and mode leak exact counts [48]).
Therefore, we combine them via MPC to preserve privacy.
To ensure efficient implementation of the combination step we require utility functions to have a certain structure as detailed next.
Recall, each party P i holds a single value d i (we can generalize to data sets D i ).
To combine local utility scores per party into a global score for all, we require utility functions to be decomposable: Convex optimization: find x that minimizes ∑ n i=1 l(x, d i ) with convex loss function l defined over D; e.g., empirical risk minimization in machine learning [10,63], and integer partitions (password frequency lists) [16] − ∑ n i=1 l(x, d i )Unlimited supply auction: find price x maximizing revenue x ∑ i b i (x), where bidder demand curve b i indicates how many goods bidder i will buy at price x; e.g., digital goods [52] x ∑ i b i (x)Frequency: select x based on its frequency in D; e.g., mode [48] ∑ n i=1 1 x=d iRank-based statistics: select x based on its rank in sorted D; e.g., k th -ranked element [48] See Section 3.2 Table 1: Applications with decomposable utility functions.Definition 4 (Decomposability).
We call a function u : (U n × R ) → R decomposable w.r.t. function u : (U n × R ) → R if u(D, x) = ∑ n i=1 u (d i , x) for x ∈ R and D = {d 1 , . . . , d n }.
We use decomposability to easily combine utility scores in Weights ln(2) , Weights ln(2)/2 d , and to avoid secure evaluation of the exponential function in Weights * 3 .
If u is decomposable, users can compute weights locally, and securely combine them via multiplications:∏ i exp(u (d i , x)ε) = exp( ∑ i u (d i , x)ε) = exp(u(D, x)ε).
Decomposability is satisfied by a wide range of selection problems.
Counts are clearly decomposable and so are utility functions that can be expressed as a sum of utility scores.
Applications with decomposable utility functions are listed in Table 1.
One use case for the median is a software company collecting private usage statistics, e.g., number of times a procedure was run or the size of database tables, in a mediumsized installed base.
Reporting the median in addition to the mean allows the collector to detect skew in the distribution.
Another example is private federated learning with network resource constrained parties, e.g., mobile phones on cellular networks.
Gradient compressed federated learning, e.g., signSGD [13], enables to reduce the update message size for these parties, but uses the median instead of the mean to aggregate the gradients.
The additional communication stemming from our secure median computation can be shifted to few parties who are not network resource constrained, e.g., mobile phones on WiFi networks.To be sublinear in the size of the universe we consider decomposability w.r.t. ranges instead of elements: parties only report one utility score per range, instead of one score per element.
Decomposability for elements x ∈ U does not imply decomposability for ranges R ⊂ U 4 .
However, we present a decomposable utility function w.r.t. ranges for rank-based statistics next.
First, we describe the median utility function [48].
Then, we present a reformulation more convenient for secure implementation and show that it is decomposable.Li (x) = |{d | d ∈ D : d < x}|.
Note that for the median we have R = U, which means every universe element is a potential output.
As U can be large, we divide U in k equal-sized ranges, and define utility per range next.Definition 5 (Median Utility Function).
The median utility function u µ : (U n ×U) → Z gives a utility score for a rangeR = [r l , r u ) where r l , r u ∈ U w.r.t. D ∈ U n as u µ (D, R) = − min rank D (r l )≤ j≤rank D (r u ) j − n 2 .
We focus on MPC of the differentially private median with rank n/2 but Definition 5 supports any k th -ranked element.
The sensitivity of u µ is 1/2 since adding an element increases n/2 by 1/2 and j either increases by 1 or remains the same [48].
Thus, the denominator 2∆u in the exponents of (1) equals 1, and we will omit it in the rest of this work.To compute u µ one needs to find rank j minimizing the distance between the median and all range elements by iterating over all j where rank D (r l ) ≤ j ≤ rank D (r u ).
However, a naive implementation of u µ leaks information as the iteration count depends on the number of duplicates in the data.
We adapt u µ next to remove this leakage.
To avoid iterating over range elements observe that the utility for a range R = [r l , r u ) is defined by the element in the range closest to the median µ.
Thus, it suffices to consider three cases: The range is either positioned "before" the median (r u ≤ µ), contains it, or comes "after" it (r l > µ).
This observation leads us to the following definition without iterations:Definition 6 (Simplified Median Utility Function).
The me- dian utility function u c µ : (U n ×U) → Z gives a utility score for a range R = [r l , r u ) of U w.r.t. D ∈ U n as u c µ (D, R) =      rank D (r u ) − n 2 if rank D (r u ) < n 2 n 2 − rank D (r l ) if rank D (r l ) > n 2 0else .
1.
Set s = log k |U| and split privacy budget ε into ε 1 , . . . , ε s 2.
Initialize S = U and repeat below steps s times:(a) Every party p ∈ P divides S into k equal-sized subranges{R i = [r i l , r i u )} k i=1 i. if ε j = ln(2)/2 d in step j (with integer d ≥ 0), input rank D p (r i l ), rank D p (r i u ) k i=1 , d ii.
else input e ε j (rankD p (r i u )−|D p |/2) , e ε j (|Dp|/2−rankD p (r i l )) k i=1 , ε j (b)The functionality combines the inputs (Section 3.2) and outputs S = R i with probability proportional toexp(u c µ (D, R i )ε j ) Figure 3: Ideal functionality F EM * for EM * .
In the following, we generalize from a single value per (input) party, d i , to multiple values, i.e., data set D i , as computation parties operate on data sets later on.
Definition 5 and 6 are equivalent as can be seen by proof by cases (see Appendix B), and u c µ is decomposable w.r.t.:u (D i , R) =      rank D i (r u ) − |D i | 2 if rank D (r u ) < n 2 |D i | 2 − rank D i (r l ) if rank D (r l ) > n 2 0 else , where rank D (r) = ∑ n i=1 rank D i (r)for range endpoints r.
We will use both utility definitions interchangeably.
Specifically, we use u µ to simplify notation in our accuracy proofs (Section 3.4), and u c µ in our implementation (Section 4).
For implementations Weights ln(2) , Weights ln(2)/2 d the parties input ranks for lower and upper range endpoints (as in u above), which we combine (as u c µ ) to efficiently compute weights.
For Weights * we let the parties input weights, i.e., exp(εu ), which we can efficiently combine via multiplication.
In more detail, weights for u are:e ε·u (D i ,R) =        e ε rank D i (r u )− |D i | 2 if e ε(rank D (r u )− n 2 )) < 1 e ε |D i | 2 −rank D i (r l ) if 1 > e ε( n 2 −rank D (r l )) 1 else , where, e.g., e ε(rank D (r)− n 2 )) = ∏ n i=1 e ε rank D i (r)− |D i | 2for range endpoints r. Given these inputs, we are ready to describe an idealized version of our protocol next.
The ideal functionality F EM * in Figure 3 describes our DP median protocol EM * as executed by a trusted third party, which we later replace by implementing F EM * with MPC.
We iteratively select subranges of universe U w.r.t. DP median via the exponential mechanism.
After s = log k |U| steps the last selected subrange contains only the DP median.
We split ε, also called privacy budget, into s parts such that ε = ∑ s j=1 ε j , and consume ε j for each subrange selection.
(We describe the budget composition in Section 3.4 and provide a heuristic in Section 5.)
Overall, F EM * provides ε-differential privacy: Theorem 1.
F EM * , with privacy parameter ε j in step j ∈ {1, . . . , s}, is ε-differentially private for ε = ∑ s j=1 ε j .
Proof.
F EM * performs s sequential steps, and each step applies the exponential mechanismEM ε i u c µ .
Since EM ε i u c µ is (2ε i ∆u c µ )-DP [52], with sensitivity ∆u c µ = 1/2 [48], we have ε i -DP per step.
Thus, according to the composition theorem [29], the total privacy budget after all steps is ∑ s j=1 ε j .
We express accuracy as the absolute error between differentially private and actual median.
In more detail, the absolute error is bounded by α with probability at least 1 − β, known as (α, β)-accuracy.
Next, we discuss how the data distribution influences accuracy and present worst-case bounds on the accuracy of the exponential mechanism for median selection.
Accuracy depends on the data distribution, specifically, on gaps d i+1 − d i , and duplicates d i = d j with i = j 5 .
Recall, a DP mechanism bounds the probability that data set D and its neighbor D can be distinguished from the mechanism output.
As neighbor D may contain values from the gaps of D, these gap values must be output with a non-zero probability.
This is why bounds for absolute error depend on such gaps between data elements in this and related work (Appendix F).
As a worst-case example, consider a data set with universe U = {0, 1, . . . , 10 9 } containing only an equal number of duplicates for 0 and 10 9 .
Then, smooth sensitivity is extremely large with 10 9 and the exponential mechanism outputs a value at uniform random.
However, for such pathological, worstcase data even the actual median does not provide much insight.
On the other hand, the number of duplicates in the data can increase accuracy dramatically.
For example, consider a data set where the median has 2c duplicates: d n/2±i = d n/2 for i ∈ {1, . . . , c}.
Then, the probability that the exponential mechanism outputs the median is exp(cε) times higher than for any other element.
Such duplicates also fit the intuition that the median is a "typical" value from the data that represents it well.
In general, the probability to output a "bad" element x decreases exponentially in ∑ c i , where c i ≥ 1 are duplicate counts of "good" elements y i , which are closer to the median than x.
In the following, we show that the output of EM ε u (D, R ) contains an element at most ln(|R |/β) ε positions away from the median in the sorted data.
Note that |R | is k if we select among k subranges or |U| if we output elements directly.For our accuracy proofs we structure the universe as a tree: we set U as the root of a tree of height log b |U|, for some base b, with k child nodes per parent.
The child nodes are equal-sized subranges of the parent node and R j i denotes the i th subrange in level j. R = {R j 1 , . . . , R j k } of data universe U. Then, output of EM ε u (D, R )contains an element at most ln(k/β) ε positions away from median position n 2 with probability at least 1 − β.
Our proof uses Corollary 3.12 from [29], which we restate as the following Lemma:Lemma 1 (Accuracy of the Exponential Mechanism).
Fixing a database D, and let OPT = max r∈R u(D, r) denote the maximum utility score of any element r ∈ R , we havePr u(D, EM ε u (D, R )) ≤ OPT − 2∆u ε (ln |R | + t) ≤ exp(−t).
Proof of Theorem 2.
First, we bound the utility difference between optimal and selected output.
Then, we translate this to a bound on the output's rank.
The complementary of Lemma 1 with ∆u = 1 2 isPr OPT − u(D, EM ε u (D, R )) < ln |R | + t ε > 1 − exp(−t).
Let R j i = [r l , r u ) be the output of EM ε u (D, R ).
Recall, thatfor median utility OPT = 0, then,OPT − u(D, EM ε u (D, R )) = 0 − u(D, R j i ) = min rank D (r l )≤ j≤rank D (r u ) j − n 2 .
Next, we consider different cases for R j i to bound the rank difference between the selected range and the range that contains the median.
Assume median µ / ∈ R j i , as otherwise the bound holds trivially, and let d denote the utility differenceOPT − u(D, EM ε u (D, R )).
For r u < µ we have d = |rank D (r u ) − n 2 | = n 2 − rank D (r u ) from which we obtain rank D (r u ) > n 2 − ln |R |+t εwith probability at least 1 − exp(−t).
Analog, for r l > µ we have d = rank D (r l ) − n 2 , and obtain rank D (r l ) < n 2 + ln |R |+t ε with the same probability.
Altogether, R j i is at most ln |R |+t ε rank positions away from median rank n/2 with probability at least 1 − exp(−t).
We have k = |R | and setting β = exp(−t) concludes the proof.To obtain an absolute error with regards to data elements, consider universe elements instead of subranges as the output of the exponential mechanism.Corollary 1 (Median Accuracy).
Fixing a sorted database D of size n, let µ be the median of D, and µ the output of EM ε u (D,U).
Then, absolute error |µ − µ| is at mostmax i∈{+1,−1}· ln(|U|/β) ε d n 2 +i − d n 2with probability at least 1 − β.The proof follows directly from Theorem 2 with |R | = |U|.
Note that it is more likely to select a "good" subrange as it is to directly select a "good" element from the entire universe (as k |U|).
However, sequential (subrange) selections consumes ε j per selection step j which adds up to a total privacy budget of ε = ∑ j ε j as described in Section 3.3.
We now show how to choose ε j to select the subrange containing the median in each iteration step with probability at least 1 − β.Theorem 3 (Choice of ε).
Let R = {R j 1 , . . . , R j k },where R j i = [r l , r u ) contains the median, and ni j = min{|rank D (µ) − rank D (r l )|, |rank D (r u + 1) − rank D (µ + 1)|} is the minimum count of data elements in R j i smaller resp.
larger than the median.
Then, EM ε u (D, R ) selects R j i with probability at least 1 − β if ε j ≥ ln(k/β) n i j .
Proof.
Ranges R j h without the median have a rank at least n i j positions away from median rank.
More formally,OPT − u(D, R j h ) ≥ n 2 ± n i j − n 2 = n i j .
According to Lemma 1 we have Pr n i j ≥ ln |R |+t ε j ≤ exp(−t).
Thus, for ε j ≥ ln |R |+t n i j the probability that any range R j h is selected is at most exp(−t).
We have k = |R | and setting β = exp(−t) concludes the proof.Parameter ε j is undefined for n i j = 0, i.e., when the median is a range endpoint 6 .
Note that the exact value of n i j is datadependent.
E.g., for the uniform distribution n i j ≈ |D|/k j .
A differentially private n i j can be efficiently computed by distributed sum protocols [26,38,60,65] as it is just a count of data elements.
However, a differentially private count also consumes a portion of the privacy parameter.
For low epsilon (e.g., ε = 0.1) we want to use the entire privacy budget on the actual median selection to achieve high accuracy.
Thus, we use a heuristic in our evaluation: larger subranges, that hold exponentially more elements, receive exponentially smaller portions ε j of the privacy budget (see Section 5 for details).
Output / FunctionalityRec(a) a, reconstructed from a Add(a, b) a + b Sub(a, b) a − b Mul(a, b) a · b Mod2m(a, b) a mod 2 b ,where b is public Trunc(a, b) a/2 b , where b is public Rand(b) r with uniform random b-bit value r Choose(a, b, c) a if bit c = 1 otherwise b LT(a, b) 1 if a < b else 0 Int2FL(a)converts integer a to secret shared float In the following, we describe details of our protocol EM * , which implements ideal functionality F EM * , analyse its running time and security.
On a high-level, our protocol recursively selects the best subrange until the DP median is found: First, each party locally evaluates a utility score (or weight) for each subrange.
They combine their results into a global result.
Then, they select a subrange based on the combined result.
We use upper case letters to denote arrays in our protocol, and A[ j] denotes the j th element in array A.
Our protocol uses integers as well as floating point numbers.
We adopt the notation from Aliasgari et al. [5] and represent a floating-point number f as (1 − 2s)(1 − z) · v · 2 x with sign bit s set when the value is negative, zero bit z only set when the value is zero, l v -bit significand v, and l x -bit exponent x.
The sharing of a floating point value f is a 4-tuple (v, x, s, z), which we abbreviate as f FL .
To refer to, e.g., the significand v of f we will write f.v. (Privacy violations and mitigations w.r.t. limited machine precision are discussed in Appendix D.) The basic MPC protocols used in our protocol are listed in Table 2.
We prefix MPC protocols for integers with Int and floating point versions with FL.
On a high level, protocol EM * , implemented in Algorithm 1, computes selection weights for possible outputs (via Algorithm 2) and selects an output according to these weights (via Algorithm 3 or 4).
We assume that the universe U and combined data size n are known to all parties (note that the latter can be hidden via padding [3]).
Recall, that efficient weight computation and selection are the main challenges for our secure exponential mechanism.
Straightforward selection over all universe elements is linear in the size of U. To achieve a running time sublinear in the size of U we selects subranges instead: Algorithm 1 selects one of k subranges based on their median utility.
The selected subrange is recurAlgorithm 1 Algorithm EM * .
Input: Number of subranges k, size n of combined data D, number of selection steps s ∈ [1, log k |U|], and (ε 1 , . . . , ε s ).
Data universe U is known to all parties.
Output: Differentially private median of D.1: r l , r u ← 0, |U| 2: for j ← 1 to s do 3:r # ← max{1, r u −r l k } 4:k ← min{k, r u − r l } Define array W of size k if ε j = ln(2)/2 d for some integer d then 7: sively divided into k subranges until the last subrange, after at most log k |U| iterations, contains only one element: the differentially private median 7 .
Alternatively, one can use fewer selection steps s and select an element from the last subrange at uniform random (line 15 in Algorithm 1).
We discuss the running time vs. accuracy trade-offs of reduced selection steps in Section 5.
We implement selection with inverse transform sampling (ITS) via binary search in Algorithm 2 similar to [30].
ITS uses the uniform distribution to realize any distribution based on its cummulative distribution function.
Formally, one draws r ∈ (0, 1] at uniform random and outputs the first R j ∈ R with ∑W FL ← Weights ln(2)/2 d (r l , r u , r # , k, n, d) //j−1 i=1 Pr[EM ε u (D, R ) = R i ] ≤ r < ∑ j i=1 Pr[EM ε u (D, R ) = R i ].
Recall, we compute unnormalized probabilities (weights), which do not require division for normalization, thus, reducing computation complexity.
To use weights instead of probabilities in ITS we only need to multiply r with normalization N = ∑ o∈R exp(u(D, o)ε).
We use decomposable utility functions to combine local evaluations over each party's data into a global utility score for the joint data.
Next, we present three solutions to efficiently compute weights for decomposable utility functions.
We implement Weights ln(2) as a special case of our approach Weights ln(2)/2 d in Algorithm 3 (with d = 0 in line 16).
Here, parties locally compute ranks which are combined into global utility scores.
Weights for these scores use a fixed ε of ln (2) to let us compute 2 u instead of exp(ε · u).
Solutions for secure exponentiation of 2 u exist where u is an integer or a float Algorithm 2 Algorithm Select.Input: List W FL of weights with size k. Output: Index j ∈ [1, k] M[ j] FL ← FLAdd(W [ j] FL , M[ j − 1] FL ) 5: end for 6: t ← IntRand(b) //Bitlength b 7: f FL ← Int2FL(t) 8: x ← IntSub( f.x, b) 9: f FL ← ( f.v, x, f.z, f.s) 10: r FL ← FLMul(M[k] FL , f FL ) 11: i l ← 1; i u ← k 12: while i l < i u do 13: i m ← i l +i u 2 14: c ← FLLT(M[i m ] FL , r FL ) 15:c ← Rec(c) i l ← i m + 1 if c = 1 else i u ← i m 17: end while 18: return i l [5,7,20,43].
When u is an integer (resp.
a float) the result 2 u is an integer (resp.
float) as well.
The complexity of the integer-based solution is linear in the bit-length of u, however, this is not sufficient for us: Recall, that the utility is based on ranks, i.e., counts of data elements, thus u can be roughly as large as the size of the data.
An integer representation of 2 u has bit-length u, which is potentially unbounded.
Eigner et al. [30] use the float-based solution from [5] but we present a more efficient computation in the following.
Although our exponent u is an integer, we do not require the result to be an integer as well.
We use the representation of floating point numbers as a 4-tuple to construct a new float to represent 2 u as (2, u, 0, 0), where sign and zero bit are unset, as 2 u cannot be negative or zero.
Note that we require no interaction as each party can construct such a float with their share of u. Also, a naive approach requires 2k total inputs per party (one per endpoint per k ranges).
However, with half-open ranges [r i l , r i u ) in each step i, they overlap for i > 1: r i−1 u = r i l .
Thus, the parties only input k + 1 ranks (Algorithm 3 lines 5, 7).
Next, we generalize the weight computation to support ε = ln(2)/2 d for integers d ≥ 1.
To illustrate our approach, we implement Weights ln(2)/2 d in Algorithm 3 for d = 1, and describe the approach for any integer d: Recall, our goal is to compute the weight exp(εu) with efficient MPC protocols.
As we can efficiently compute 2 εu if εu is an integer, we approximate the weight by truncating εu to an integer before exponentiation with base 2.
To avoid a loss of precision we correct this approximation with a multiplicative term based on the truncated remainder.
More formally, with ε as above Algorithm 3 Algorithm Weights ln(2)/2 d .
Input: Range [r l , r u ), subrange size r # , number k of subranges, data size n, and parameter d ∈ {0, 1}.
Subrange ranks rank D p (·) are input by each party p ∈ {1, . . . , m}.
Output: List of weights.1: Define arrays R of size k + 1, W of size k; initialize R with zeros 2: for p ← 1 to m do //Get input from each party for j ← 1 to k do //Divide range into k subranges 4:i l ← r l + ( j − 1) · r # 5: R[ j] ← IntAdd(R[ j], rank D p (U[i l ])) 6:end for 7:R[k + 1] ← IntAdd(R[k + 1], rank D p (U[r u ])) 8: end for 9: for j ← 1 to k do 10: u u ← IntSub(R[ j + 1], n 2 )11:u l ← IntSub( n 2 , R[ j]) 12: c u ← IntLT(R[ j + 1], n 2 )13:c l ← IntLT( n 2 , R[ j]) 14: t ← IntChoose(u u , 0, c u ) 15:u ← IntChoose(u l , t, c l )16: if d = 0 then 17: W [ j] FL ← (2, u, 0, 0) //float 2 u 18:else 19:t ← IntTrunc(u, d) 20:e FL ← (2, t, 0, 0) c ← IntMod2m(u, d)22: s FL ← FLChoose(1 FL , √ 2 FL , c) 23: W [ j] FL ← FLMul(e FL , We implement Weights * in Algorithm 4.
To allow arbitrary values for ε we avoid costly secure exponentiation for weight computation altogether: Utility u, decomposable w.r.t. u , allows for efficient combination of local weights for D i , input by the parties, into global weights for D via multiplication (as described in Section 3.2).
We analyse the running time of EM * w.r.t. MPC protocols from for j ← 1 to k do //Divide range into k subranges 4:i l ← r l + ( j − 1) · r # 5: i u ← r u if j = k else r l + j · r # 6: W l [ j] FL ← FLMul(W l [ j] FL , e ε |Dp | 2 −rank Dp (U[i l ]) FL ) 7: W u [ j] FL ← FLMul(W u [ j] FL , e ε rank Dp (U[i u ])− |Dp | 2 | FL )8:end for 9: end for 10: for j ← 1 to k do 11:c u ← FLLT(W u [ j] FL , 1 FL ) 12: c l ← FLLT(W l [ j] FL , 1 FL ) 13: t FL ← FLChoose(W u [ j] FL , 1 FL , c u ) 14: W [ j] FL ← FLChoose(W l [ j] FL , t FL , c l ) 15: end for 16: return W FLand their complexity is given in Appendix C.
We measure the running time of our implementation in Section 5.
Theorem 4.
EM * with Weights ln(2) or Weights ln(2)/2 d requires O(klog k |U|) MPC protocol calls, with Weights * we require O(mklog k |U|).
Note that complexity of these MPC protocols is at most O(l v log l v + l x ) for bit-lengths l v , l x (Appendix C).
Proof.
EM * invokes the weight computation and Select at most log k |U| times.
An invocation of Weights ln(2) or Weights ln(2)/2 d performs k truncations IntTrunc, 2k comparisons IntLT and 2k selections IntChoose.
Additionally, Weights ln(2)/2 d also requires one truncation IntTrunc, modulo IntMod2m, float selection FLChoose and float multiplication FLMul.
Weight computation via Weights * requires 2km float multiplications FLMul, 2k float comparisons FLLT and 2k float selections FLChoose.
Each invocation of Select requires k − 1 float additions FLAdd, only one random draw IntRand, conversion Int2FL and float multiplication FLMul.
Also, Select performs at most log 2 (k) comparisons FLLT and share reconstruction steps during binary search.
We consider the semi-honest model introduced by Goldreich [36] where corrupted protocol participants do not deviate from the protocol but gather everything created during the run of the protocol.
Our protocol consists of multiple subroutines realized with MPC protocols listed in Table 2 (for details and security proof references we refer to [6]).
To analyze the security of the entire protocol we rely on the well-known composition theorem [36, Section 7.3.1].
Basically, MPC protocols using an ideal functionality (a subroutine provided by a trusted third party) remain secure if the ideal functionality is replaced with an MPC protocol implementing the same functionality.
We implement such ideal functionality with the maliciously secure SCALE-MAMBA framework [6] (which was faster than its semi-honest fork in a WAN, as detailed in Appendix E).
Our protocol performs multiple subrange selections and each selection round is maliciously secure.
Overall, we only provide semi-honest security as malicious adversaries can deviate from inputs provided in previous rounds.
We later show how to extend our protocol to malicious adversaries, but first we proof semi-honest security for EM * :Theorem 5.
Protocol EM * realizes F EM * in the presence of semi-honest adversaries.Proof.
To prove semi-honest security we show the existence of a simulator Sim according to Goldreich [36] such that the distributions of the protocol transcript EM * is computationally indistinguishable from simulated transcript using F EM * produced in an "ideal world" with a trusted third party.Note that an adversary in the ideal world learns nothing except the protocol inputs and outputs, hence, if he cannot distinguish simulated transcripts (from ideal world) and actual transcripts (in the real world), he learns nothing in our realworld implementation.
Next, we formalize the ideal and realworld executions, ideal and real, with notation from Evans et al. [32]: Consider a subset of corrupted parties C ⊂ P , and let VIEW i denote the view of party i ∈ C during the execution of EM * implementing ideal functionality F EM * , including all exchanged messages and internal state, and let x i denote the protocol input of party P i and µ the final output of all parties.
The parameters s, k,U are public.
Then, real EM * , on input security parameter κ, C and all x i , runs protocol EM * (where each party P i behaves honestly using its own input x i ) and outputs {VIEW i |i ∈ C}, µ.
And ideal F EM * ,Sim , with the same inputs, computes µ ← F EM * (x 1 , . . . , x m ) and outputs Sim(C, µ, {x i | i ∈ C}), µ.
Now, simulator Sim produces a transcript for real EM * as follows: As we operate on secret shares, which look random to the parties [32], Sim replaces all secret shares with random values to create VIEW i .
Likewise, the secret-shared output of the weight computations (Algorithm 3 and 4) are replaced with randomness.
Sim can simulate Algorithm 2 by recursively splitting U into k subranges, and outputting the subrange containing µ in each selection step.
Finally, Sim outputs a uniform random element from the last subrange (Algorithm 1).
Altogether, a semi-honest adversary cannot learn more than the (ideal-world) simulator as this information is sufficient to produce a transcript of our (real-world) protocol.For malicious adversaries, we need to ensure consistency between rounds based on Aggarwal et al. [3], who securely compute the (non-DP) median via comparison-based pruning rounds.
Informally, we have two consistency constraints: First, valid rank inputs must be monotone within a step.
Second, for consistency between steps, valid inputs are contained in the subrange output in the previous step.
Formally, let {R i 1 , . . . , R i k } denote the set of subranges in the i th step of EM * and let l i j , u i j denote the lower resp.
upper range endpoint ofR i j .
Then, rank D p (l i 1 ) ≤ rank D p (l i 2 ) ≤ · · · ≤ rank D p (l i k ) ≤ rank D p (u ik ) describes monotone input in step i for party p. Consistency between step i and i + 1, if the j th range was selected, is expressed as rankD p (l i+1 1 ) = rank D p (l i j ) and rank D p (u i+1 k ) = rank D p (u i j ).
In other words, the subrange output in the previous step is used in the current step.
Analogously, we can enforce consistency for weights as they are based on rank values.
Recall, we distinguish two sets of parties: Input parties send shares of their input to computation parties which run the secure computation on their behalf.
The latter can be a subset of the input parties or non-colluding untrusted servers (e.g., multiple cloud service providers).
This scales nicely as the number of computation parties is independent of the number of input parties and can be constant, e.g., 3.
In our evaluation (Section 5) m ∈ {3, 6, 10} computation parties perform the computation for 10 6 input parties, each holding a single datum.
Addition suffices for Weights ln(2) and Weights ln(2)/2 d to combine local rank values into a global rank.
Addition is essentially "free" as it requires no interaction between the computation parties.
For Weights * we require multiplication to combine the local weights, which requires interaction during the preprocessing step.
However, log n rounds suffice to combine the inputs by building a tree of pairwise multiplications with 2 i multiplications at level i [5].
Our implementation is realized with the SCALE-MAMBA framework [6] using Shamir secret sharing with a 128-bit modulus and honest majority.
Next, we evaluate the running time, privacy budget and accuracy of our solution and refer to Appendix E for additional evaluations.
We performed our evaluation on t2.medium AWS instances with 2GB RAM, 4 vCPUs [8] and the Open Payments data set from the Centers for Medicare & Medicaid Services (CMS) [33].
Our evaluation uses 10 6 records from the Open Payments data set, however, our approach scales to any data set size as we consider universe subranges.
We used the maximum number of selection steps, i.e., s = log k |U|, with k = 10 ranges per step.
We evaluated the average running time of 20 runs of the entire protocol EM * , i.e., offline as well as online phase (see Appendix E), in a LAN and a WAN.
LAN: We measured our running time for 3 parties in a LAN with 1 Gbits/s bandwidth to compare it to Eigner et al. [30] who only report LAN running times.
We support universe sizes of more than 5 orders of magnitude larger with comparable running times: They compute weights per elements and require around 42 seconds for |U| = 5, whereas our protocol EM * using Weights ln(2) / Weights ln(2)/2 d / Weights * runs in approx. 11 / 33 / 64 seconds for |U| = 10 5 .
For detailed measurements see Table 4 in Appendix E.WAN: We consider m computation parties, which already received and combined secret-shared inputs from 10 6 users (Section 4.7), and report the average running time of our protocol.
We split the m parties into two regions, Ohio (us-east-2) and Frankfurt (eu-central-1), and measured an inter-region round time trip (RTT) of approx. 100 ms with 100 Mbits/s bandwidth.
We evaluated all weight computation subroutines in Figure 4 for m ∈ {3, 6, 10} computation parties and |U| ∈ {10 5 , 10 6 , 10 7 }.
The results are very stable, as the 95% confidence intervals deviate by less than 0.5% on average.
Weights ln (2) (Figure 4a) is the fastest with running times around 3 minutes for 3 parties, whereas Weights ln(2)/2 d (Fig- ure 4b) and Weights * (Figure 4c) require around 13 and 14 minutes respectively.
However, we consider large universe sizes (billions of elements) in a real-world network with large latency.
The choice of weight computation enables a trade-off between faster running times, i.e., Weights ln(2) with fixed ε, and smaller privacy loss ε, i.e, Weights * , with Weights ln(2)/2 d positioned in the middle (faster running time than Weights * with smaller ε compared to Weights ln (2) ).
The number k of subranges allow a similar trade-off, as discussed next.
The privacy budget is the sum of privacy parameters consumed per step, i.e., the overall privacy loss.
how the privacy budget and the running time are affected by the number k of subranges.
Larger k leads to larger running times, as the number of costly secure computations depends on the number of ranges times the number of selection steps (k · log k |U|), which increases proportionally to k. However, smaller values for k require more selection steps (log k |U|), which lead to an increase in the privacy budget.
Overall, for k = 10 subranges, as used in our evaluation, the consumed privacy budget is small with an acceptable running time.
EM * performs multiple selection steps s, each consume a portion ε i of the overall privacy budget ε = ∑ s i=1 ε i .
How to optimally split ε (optimal composition) is #P-complete [55].
Thus, we use the following heuristic to divide ε among the selection steps: Initial steps cover exponentially larger subranges, and require exponentially less of the privacy budget.
After a while an equal split is more advantageous, as the subranges become smaller and contain fewer elements.
Altogether, we use ε i = ε/2 s−i+1 if i ≤ s/2 and ε i = ε /(s − s/2) else, where ε is the remaining privacy budget.
We used s = log k |U|−1 for our accuracy evaluation.
We found in our experiments that performing one selection step less increases accuracy, as the privacy budget can be better divided among the other remaining steps and the last subrange is already small enough (at most k elements).
Related work computing DP median in the central model shows a strong data dependence which makes straightforward comparison difficult (Appendix F).
Therefore, we empirically evaluated the different approaches closest to ours, i.e., supporting more than 2 parties, on real-world data sets [42,64,67] as well as the normal distribution in Figure 6 8 for 100 averaged runs with 95%-confidence intervals.
Low ε (as evaluated) is desirable as it provides more privacy or allows the remaining privacy budget to be spend on additional queries.
The 8 "Small" data is the most challenging regime for DP [15,56], thus, we use small data sets to better illustrate the accuracy differences.
evaluation for smooth sensitivity [58] and exponential mechanism per element assume a trusted party with full access to the data set, whereas our approach and [59] use MPC instead of a trusted party.
Nissim et al. [58] (SS in Figure 6) compute instance-specific additive noise, requiring full data access, and achieve good accuracy, however, the exponential mechanism can provide better accuracy for low ε.
Pettai & Laud [59] (SA in Figure 6) securely compute the noisy average of the 100 values closest to the median within a clipping range.
Recall, the median is the 0.5 th -percentile.
To minimize the error from clipping range [c l , c u ], we choose c l = 0.49 thpercentile, c u = 0.51 th -percentile, i.e., we presume to already know a tight range for the actual median.
Nonetheless, in our experiments the absolute error of SA is the largest.
Overall, no solution is optimal for all ε and data sets.
However, the exponential mechanism EM, and our protocol EM * , provide the best accuracy for low ε, i.e., high privacy, compared to additive noise approaches [58,59].
Next, we describe related work for secure computation of the exponential mechanism, DP median and decomposability.Secure Exponential Mechanism: Alhadidi et al.[4] present a secure 2-party protocol for the exponential mechanism for max utility functions.
It uses garbled circuits and oblivious polynomial evaluation to compute Taylor series for the exponential function.
Our work is more general as we support more parties and a broader class of utility functions, including max utility functions.
Eigner et al. [30] present a carefully designed secure exponential mechanism in the multiparty setting.
Their work is more general, supporting arbitrary utility functions and malicious parties, but they are linear in the size of the universe, and securely compute the exponential function.
We provide a sublinear solution without costly secure exponentiation, supporting at least 5 orders of magnitude more elements than them.
Böhler and Kerschbaum [14] also securely compute the DP median with the exponential mechanism.
They optimize their protocol for the 2-party setting, compute the utility over (sorted) data, and provide DP for small data (sublinear in the size of the universe).
They initially prune large data sets via [3] (who securely compute the exact median), requiring a relaxation of DP [39], to achieve running time sublinear in the universe size.
We consider the multi-party setting and provide pure differential privacy.DP Median: Pettai and Laud [59] securely compute DP statistics, including the DP median, via sample-and-aggregate [58].
Their implementation is based on secret sharing in a 3-party setting.
Pettai and Laud [59] compute the DP median as noisy average of 100 values closest to the median within a clipping range, which limits accuracy, especially, if the data contains outliers or large gaps (see Section 5.3).
Dwork and Lei [27] consider robust privacy-preserving statistics with a trusted third party where data samples are known to be drawn i.i.d. from a distribution.
They present the first DP median algorithm that does not require bounds for the data but aborts if the data are not from a "nice" distribution with small sensitivity.
Their DP median algorithm first estimates scale s via DP interquartile range and the noise magnitude sn −1/3 can be large.
Nissim et al. [58] present smooth sensitivity, which analyzes the data to provide instance-specific noise.
For the DP median, the exponential mechanism provides better accuracy for low epsilon and can be efficiently computed, whereas computation of smooth sensitivity requires full data access in clear or the error increases (see Section 2.1.2).
PINQ, a DP query framework developed by McSherry [51], also computes the DP median via the exponential mechanism, however, they rely on a trusted third party with access to the data in clear.
Cryptε [19] employs two non-colluding untrusted servers and cryptographic primitives to compute noisy histograms (Laplace mechanism) for SQL queries (e.g., count, distinct count) in the central model, which can be extended to compute the median.
However, we show that the exponential mechanism is more accurate for the median with low ε.
Also, Cryptε has a running time linear in the data size, whereas our work is independent of the data size.
Smith et al. [63] and Gaboardi et al. [34] consider the restrictive non-interactive local model, where at most one message is sent from client to server, and achieve optimal local model error.
However, local DP requires more samples to achieve the same accuracy as central DP.
(No non-interactive LDP-protocol [34,63] can achieve asymptotically better sample complexity than O(ε −2 α −2 ) for error α [24].)
We, on the other hand, are interested in high accuracy, as in the central model, even for small sample sizes.
We give accuracy bounds for related work for the DP median in the central model in Appendix F.
As these data-dependent bounds are hard to compare we provide an empirical comparison in Section 5.3.
Decomposability: MapReduce is a programming paradigm for distributed data aggregation where a mapper produces intermediary results (e.g., partial sums) that a reducer combines into a result (e.g., total sum).
Airavat [61] provide a Hadoop-based MapReduce programming platform for DP statistics based on additive noise (Laplace mechanism) with an untrusted mapper but trusted reducer.
We consider decomposable utility functions for the exponential mechanism without any trusted parties.
The secure exponential mechanisms [4,30] use decomposable utility functions (max and counts), but do not classify nor provide optimizations for such functions.
Blocki et al. [16] minimize cummulative error for DP password frequency lists employing (decomposability of) frequencies for their dynamic programming, which has access to all the data in the clear.
We use decomposable aggregate functions to efficiently and securely combine inputs.
We presented a novel alternative for differentially private median computation with high accuracy (even for small number of users), without a trusted party, that is efficiently computable (practical running time) and scaleable (sublinear in the size of the universe).
Our semi-honest multi-party protocol implements the exponential mechanism for decomposable aggregate functions (e.g., rank-based statistics) as used in MapRedue-style algorithms, and can be extended to malicious parties.
For the median, the exponential mechanism provides the best utility vs. privacy trade-off for low ε in our evaluations of related work in the central model.We optimize our protocol for decomposable functions (allowing efficient MPC on distributed data), and use efficient alternatives to exponentiations for floating-point numbers.
We implemented our protocol in the SCALE-MAMBA framework [6], and evaluated it for 1 million users using 3 semihonest computation parties achieving a running time of seconds in a LAN, and 3 minutes in a WAN (100 ms latency, 100 Mbits/s bandwidth).
The original definition of Differential Privacy considers the central model with unbounded adversaries [25,28] (see Definition 1), later work expanded it to a distributed setting [26,44], and considered computationally-bounded parties [54].
We consider multiple computationally-bounded, semihonest parties performing a joint secure computation realized with (t, m)-secret sharing.
The following definition from [30] fits our setting, where VIEW p Π (D) denotes the view of party p during the execution of protocol Π on input D, including all exchanged messages and internal state, and λ is a security parameter:Definition 7 (Distributed Differential Privacy).
A randomized protocol Π implemented among m computation parties P = {P 1 , . . . , P m }, achieves distributed differential privacy w.r.t. a coalition C ⊂ P of semi-honest computation parties of size t, if the following condition holds: for any neighbors D, D and any possible set S of views for protocol Π,Pr VIEW C Π (D) ∈ S ≤ exp(ε)·Pr VIEW C Π (D ) ∈ S +negl(λ).
The definition can be expanded to a malicious setting by replacing the semi-honest parties P and semi-honestly secure protocol Π with malicious parties and a maliciously secure protocol.
Note that the negligible function negl(λ) can be omitted for protocols providing information-theoretic security (such as standard secret sharing), however, our implementation in SCALE-MAMBA provides computational security (due to the online phase as described in Section 2.2).
Table 3: Complexity of MPC protocols for b-bit integers, t-bit truncation modulus, and floats with v-bit significand and x-bit exponent [5,6,17,30].
We show equality of Definitions 5 and 6 with proof by cases.
Consider range R = [r l , r u ) and its position relative to the median µ for Definition 5: Case i) For r u < µ we have rank D (r u ) < n/2, thus, u µ = −|rank D (r u ) − n/2| = rank D (r u )−n/2.
Case ii) For r l > µ we have rank D (r l ) > n/2, thus, u µ = n/2−rank D (r l ).
Case iii) Otherwise, the range contains the median, i.e., u µ = 0.
Note that it suffices to look at r l in case i) (resp., r u in case ii)), as rank D (r l ) ≤ rank D (r u ) and the range endpoint closest to µ defines the utility for the range.
Definition 6 uses the same cases and is an alternative way to express Definition 5.
Table 3 lists the complexities for MPC protocols typically measured in the number of rounds and interactive operations, where rounds describes the count of sequential interactive operations, and interactive operations (e.g., reconstruct sharing, multiplications) require each party to send messages to all other parties.
We omit integer addition/subtraction as these operations are non-interactive and the parties can perform them locally.
Share reconstruction is denoted with Rec.
Note that Choose(a, b, c) is implemented with one multiplication and two additions (b + (a − b) · c), and that IntRand uses correlated randomness already exchanged in the offline phase (hence zero interaction and rounds).
In general, DP mechanisms operate on reals, whereas actual implementations are limited to the precision of physical machines.
However, limited precision can lead to privacy violations: As shown by Mironov [53], the Laplace mechanism is vulnerable to finite precision as the set of possible outcomes can differ between neighboring databases due to irregularities caused by floating point implementations.
Their proposed mitigation is to perform "snapping", roughly, they clamp the noisy result to a fixed range and ensure that they output is evenly spaced.
Recent work by Ilvento [41] extend this line of study to the exponential mechanism, which is also vulnerable to finite precision.
The suggested mitigation is switching from base e to base 2 to perform precise arithmetic by, e.g., for integer utility functions, approximating ε as η = − log 2 (x/2 y ) for integers x, y such that x/2 y ≤ 1.
Interestingly, their mitigation is similar to our efficient secure computation.
Our implementation is based on an integer utility function and Weights ln(2) uses base 2 for efficiency reasons and is not vulnerable to such attacks.
We can strengthen Weights ln(2)/2 d , with ε = ln(2)/2 d , by using randomized rounding for non-interger utilities as described in [41, Section 3.2.2] if we omit 1/2 d from ε and include it as a factor in the utility definition (making the utility nonintegers).
For Weights * , which supports arbitrary ε, careful choices for ε as described above mitigate attacks on limited precision.Implementation Note: SCALA-MAMBA's floating point numbers (sfloat) are associated with a statistical security parameter κ satisfying κ < b − 2 · l v where b is the bit-length of the modulus and l v is the bit-length of the significand.
Security with κ = 40 is the default for b = 128 and we use l v = 40 in our evaluation, to support large utility values.
The online and offline phase are integrated in newer versions of SCALE-MAMBA, thus, we only provide measurements for the total protocol, i.e., offline as well as online phase.Running time in a LAN: We compare our running time to This work has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 825333 (MOSAICrOWN).
nWe list theoretical accuracy bounds for related work, i.e., computation of the DP median in the central model supporting many parties, in Table 6.
Note that the table entries, except for this work, are the sensitivity of the method multiplied by factor γ 9 (and with an additional error term for [59]).
Hence, the first entry is the definition of smooth sensitivity for the median (multiplied by γ).
For an empirical comparison of this work with related work we refer to Section 5.3.
We list theoretical accuracy bounds for related work, i.e., computation of the DP median in the central model supporting many parties, in Table 6.
Note that the table entries, except for this work, are the sensitivity of the method multiplied by factor γ 9 (and with an additional error term for [59]).
Hence, the first entry is the definition of smooth sensitivity for the median (multiplied by γ).
For an empirical comparison of this work with related work we refer to Section 5.3.
