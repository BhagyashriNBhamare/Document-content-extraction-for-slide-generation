The emergence of camera-based assistive technologies has empowered people with visual impairments (VIP) to obtain independence in their daily lives.
Popular services feature volunteers who answer questions about photos or videos (e.g., to identify a medical prescription).
However, people with VIPs can (inadvertently) reveal sensitive information to these volunteers.
To better understand the privacy concerns regarding the disclosure of background objects to different types of human assistants (friends, family, and others), we conducted an online survey with 155 visually impaired participants.
In general, our participants had varying concerns depending on the type of assistants and the kind of information.
We found that our participants were more concerned about the privacy of bystanders than their own when capturing people in images.
We also found that participants were concerned about self-presentation and were more comfortable sharing embarrassing information with family than with their friends.
Our findings suggest directions for future work in the development of human-assisted question-answering systems.
Specifically, we discuss how humanizing these systems can give people a greater sense of personal security.
Sighted people can often take for granted the ease with which they can engage in routine activities, such as driving to the grocery store, paying bills, taking medications, using mobile devices and computers, and more.
For people with impairments, these activities can be a challenge.
In this paper, we focus on people with visual impairments (VIPs), i.e., people who live with impairments ranging from complete blindness to an inability to read a book when wearing corrective lenses [60].
Today, it is estimated that four percent of the global population lives with visual impairments (about 285 million people) [73], and depending on the severity of their visual impairments, engaging in routine and mundane activities may require the assistance of others.
For example, people with VIPs often rely on friends and family to help them accomplish daily practices, such as traveling to the market and paying bills, such that they can maintain the practices of daily life [6,38].
However, there may be cases where people with VIPs do not have access to people who provide this kind of support, or they may have intermittent access to people who can assist them.
As a means of addressing this issue, technological advances are leading to the rapid development of assistive technologies for people with visual impairments.
With the rise of mobile cameras and advances in computer vision, 'visually aware' assistive applications are now becoming a reality for people with visual impairments.
These camera-based assistive technologies simplify a wide range of everyday tasks such as navigating social spaces, 1 identifying objects or color, 2 recognizing familiar faces or facial expressions, 3 and reading documents.
4 In contrast to automated systems, which use computer vision and machine learning, 3 human-powered systems leverage human assistants (volunteers, professional agents, or friends and family members) to answer questions about photos (or live video) taken by people with VIPs [1,2,16].
5 Since automated systems are not yet reliable [9] -e.g., the user may want to know the number of calories in a can of food, but the system might simply identify the food as a "tuna can," or the system may not be able to assess whether a pair of shoes matches one's clothing -people with VIPs still find human-assisted systems more accurate and trustworthy [9].
Indeed, more than 100,000 users with VIPs are currently using human-powered assistive systems such as 'Be My Eyes' [2] and 'Aira' [1].
Despite their advantages, human-powered, camera-based assistive applications can pose serious privacy risks.
For example, people with VIPs may inadvertently share sensitive information with a human assistant both intentionally (e.g., asking to read a credit card number) or unintentionally (e.g., a credit card may be present in the background).
Such sharing can sometimes have serious consequences, e.g., sharing a credit card may lead to identity theft.
Although these risks have been acknowledged in prior work [8,18,21,34], they have focused mostly on identifying the kinds of sensitive content shared with volunteers.
The privacy concerns of people with VIPs in the context of revealing sensitive information with different kinds of human agents, which can vary with context, is not yet well understood.
A deeper understanding of these concerns can provide insight into how AI and human assistance can be leveraged to provide both trustworthy and privacy aware visual assistance to people with VIPs.In this paper, we report on the privacy concerns of people with VIPs when using human-powered, camera-based assistive systems.
We considered the privacy risks of objects both in the foreground (the objects people ask questions about) and background (other objects present in the image not directly associated with the question), and explored privacy concerns when sharing photos or video with three types of human assistants: friends, family members, and crowdworkers (professional agents, mechanical turk workers, and volunteers).
We also explored the concerns of people with visual impairments in three common contexts: in the office, in a restaurant, and at home.
Specifically, we focus on the following research questions:R1: What are the privacy concerns of people with visual impairments in the context of background objects that are inadvertently captured and included in photos sent to human assistants?R2: While using such technologies, how do their privacy concerns vary for different classes of background objects and the type of human assistants (friends, family, volunteers or crowd-workers)?
To answer these research questions, we conducted an online survey with 155 visually impaired participants examining three everyday scenarios in the context of three different types of human assistants.
Participants were assigned to a between-subjects survey instrument based on the type of assistant (friend, family member, and crowd-worker).
The scenarios were studied within subjects (home, office, and restaurant).
We conduct a quantitative analysis of their privacy preferences as well as a qualitative analysis of the reasons participants provided for their preferences.Our participants reported significant privacy and security concerns for information captured in the background.
Their information-disclosing behaviors depended on the nature of the background objects present in the image as well as the types of human assistants.
For example, participants were more concerned about maintaining a good impression with their friends compared to family.
Participants, however, also reported being more concerned about sharing personally identifiable information with crowd workers compared to their friends or family members.
Interestingly, participants were also more concerned about the privacy of other people compared to their own.
Our findings have important implications for the design of camera based assistive devices.
Despite their potential for 'good', such technologies can also violate the security and privacy of the very people being assisted.
We discuss how such systems need to be 'humanized' so as to assist, and not harm, their users.
In this section, we present related work on camera-based assistive solutions and their privacy issues.
We focus on two primary design paradigms for camerabased assistive technologies: automated assistive systems and human-powered assistive systems.
Various kinds of camera-based assistive technologies have been developed to assist people with VIPs in their daily tasks.
Such technologies include object identifiers 6 [45] and barcode readers, 7 [52] text readers, 4 color readers, 2 money readers, 8 and crowd-sourced visual question-answering systems [1,2] for multiple purposes such as identifying objects, reading prescriptions, and answering subjective questions.
Camerabased assistive solutions also assist people with VIPs in their social interactions by recognizing faces and facial attributes of people in the vicinity [25,43,50].
Since the hands-free nature of wearable cameras offers improved accessibility [75], researchers have also developed various camera-assisted prototypes [23,51,62] for people with VIPs on wearable and augmented reality devices.
Although people with VIPs are quickly adopting automated systems, most applications work best with high-quality photos and ample lighting, rightly angled compositions, and fully captured subjects [45].
Capturing such photos, however, is particularly challenging for people with VIPs.
Therefore, several camera-based applications have been proposed to assist people with VIPs in taking photos.
To capture a high-quality picture, these applications automatically guide users to improve the focus, lighting, or composition [5,44,72].
Unfortunately, automated systems have their limitations; systems sometimes provide inaccurate answers and may lack detailed descriptions when expected [9].
For example, the user may want to know the temperature on a thermostat whereas the automated application may just respond "thermostat."
Because of the limited capabilities of automatic systems, users find communicating with a human more reliable [12].
To address issues with automated assistive technologies, crowd based systems are becoming more popular among people with VIPs.
Visual Question Answering (VQA) seeks to automatically answer visual questions from a given image and the user's question using computer vision and natural language processing [11,32].
Currently, most models are trained on images taken by sighted people that are not representative of those taken in assistive systems for people with VIPs.
Hence, no such VQA systems have been developed yet to assist people with VIPs.
As an alternative, people with VIPs get nearly real-time visual assistance with their visual questions with the help of a human assistant [1,2,16].
Such applications allow visually impaired users to send pictures or make video calls for getting answers to their visual questions from a sighted crowd-worker or volunteer.
Currently, among the two popular human-sourced services, Be My Eyes [2] connects blind persons with untrained volunteers through a free service.
In contrast, Aira [1] connects visually impaired users with paid, trained professional agents.
To provide greater support to visually impaired users, VizWiz Social [20] expands the initial VizWiz application by including friend-sourced answers (using Twitter, Facebook, or email from their known contacts) along with crowd-sourced answers (Mechanical Turk, IQ Engines).
Friendsourcing removes the financial cost of the crowd-sourced service and helps to improve the quality and trustworthiness of the answers received [59].
Friends and family may be able to answer questions better because they know the question asker.
However, 'friendsourcing' has a social cost as the users might feel they appear less independent or may want to avoid feeling like a burden on their friends and family.
To address this problem, Brady et al. [18] introduce the idea of social microvolunteering, a type of intermediate friendsourcing in which a volunteer who participates ask his networks of friends to answer a visual question on behalf of a visually impaired person.
It also provides faster responses than friendsourcing.
In our work, we consider three different types of human assistants (friends, family members, and volunteers or crowd-workers) and focus on better understanding the preferences of people with VIPs while seeking help from various types of human assistants.
We now discuss related work on privacy in the context of assistive technologies in general, camera based assistive technologies, and human assistant based assistive technologies.
As people with VIPs continue to leverage assistive technologies in their routine lives, this leads to the question of what privacy issues emerge and how we, as designers, can best design for the privacy of this particularly vulnerable population.
Several studies report that people with VIPs have concerns about aural and visual eavesdropping when using screen readers and screen magnifiers [6,13,46].
They often use headphones and screen occlusion software to protect themselves from other people eavesdropping on their devices [8,13].
Prior work also discussed how simply possessing assistive devices may invite privacy-invading questions (e.g., "how did you lose your sight?")
or unwanted attention [68].
Ahmed et al. explored the privacy and security concerns of people with VIPs that are not solved by current technology and suggested new directions for improving camera-based assistive systems [6].
Other works also investigated the physical safety concerns of individuals with VIPs [8,21].
Researchers also focused on the privacy challenges people with VIPs face while using digital finance technologies such as ATMs [24,69].
More specific to video based assistive technology, camerabased assistive devices can collect rich visual information and create additional privacy risks for both the device user and bystanders.
Such risks might have a much higher impact on visually impaired people because they cannot review the content of photos before sharing [6] or they might be less aware of when such situations might occur [8,21].
Malicious parties can use malware to record photos or video of private spaces and blackmail the device owner [71].
Computer vision-based technologies for assistive purposes may also impose serious privacy risks for the bystanders while recognizing faces for people with VIPs.
Face recognition may lead to identity theft [4] and issues of bias related to race [26] and age [10].
Ahmed et al. investigated the concerns of bystanders while information about them is shared through camera-based assistive technologies to a visually impaired person [7].
We address the concerns people with VIPs have while sharing information about themselves and bystanders through camera-based assistive technologies.
We are also interested in learning how concerned people with VIPs are about the privacy of others (i.e., the bystanders).
Privacy issues with human-assisted solutions.
In real time crowd-sourced assistive systems, users are limited in the amount of time to review the content they are sharing and might capture and share sensitive information mistakenly [15,53].
Such incidents potentially put the user at risk of identity theft, blackmail, and other information-based attacks.
Lasecki et al. have demonstrated the risks of trusting crowd workers with sensitive information [54].
They showed that workers can be engaged in potentially malicious tasks for personal gain, such as copying a credit card number from another task.
Branham et al. described an incident when a visually impaired user was threatened by the volunteer who asked for her location [21].
Several works reported situations when a visually impaired user inadvertently shared images containing private information with a crowd-worker, sometimes without understanding either the risk or that sensitive information is being captured [8,33,34].
Our work addresses the latter risk when the visually impaired person unintentionally captures sensitive information and shares it with a human assistant.
The images must contain the foreground objects for the human assistant to answer the question and are deliberately chosen while understanding some of the privacy risks.
However, background objects (or people) can pose a much greater privacy risk since they were not intended to be shared with the volunteer.
Moreover, our work provides insight into what should be shared (or not) as background objects depending on the human-sourced assistive technologies with the goal of better understanding their privacy concerns and, therefore, providing design recommendations to develop assistive devices for avoiding inadvertent sharing of private visual information.
We now describe our survey and data analysis procedures.
To answer our research questions, we conducted an online survey on the privacy and security concerns of people with VIPs who share images using camera-based assistive technologies.
In the survey, we considered three different human-sourced assistive technologies by varying the type of human assistant (a family member, a friend, and a volunteer or crowd-worker) and conducted a between-subjects survey through random assignment based on these three types of assistants.
Each of these surveys had three within-subjects (randomly ordered) scenarios (home, office, and restaurant) with each having questions about possible foreground and background objects in the image.
Participants took approximately 20-30 minutes to complete the survey.
Our surveys captured peoples' concerns related to sharing information across three different scenarios: in home (located within a residential space), office (located at the place of employment), and restaurant (located at a dining establishment) settings.
These scenarios were grounded in prior studies.
Church and Oliver found that more than 70 percent of mobile information seeking was performed in familiar contexts such as at home or the office [27].
Abdolrahmani et al. reported the use of mobile devices and assistive applications by people with VIPs in restaurants, home, and office scenarios [3].
These scenarios are representative of real-life engagements for people with VIPs in private, semi-private, and public places respectively.
Each participant was presented all three scenarios (within-subjects) in random order.
In the survey, we referred to the objects that users ask the question about as "foreground" objects (primary objects) and the objects which are present in the photo but not primary objects as "background" objects.
To determine the list of foreground and background objects included in the survey, we first explored the VizWiz dataset [34].
This dataset is derived from a natural visual question answering system where visually impaired users took images and recorded spoken questions and sent them to crowd workers.
Since most camera-assisted technologies follow a similar approach, the publicly available VizWiz dataset illustrated common privacy issues that may arise while using such a service.The dataset comprises 20,000 publicly available images and the associated questions (as text) about the images.
This dataset was cleaned and released by the authors so as to remove any images with sensitive information.
To reduce bias in our selection of objects, we contacted the authors and obtained these sensitive images (200).
These images had the sensitive portions redacted but contained enough information about the type of object (e.g., faces were blurred).
We randomly selected 1,000 images from the publicly available images along with the 200 sensitive images.
Two researchers individually categorized the images into groups.
They then met and came to consensus on a representative set of groups.
After analyzing the dataset, we observed five major privacy violations as foreground objects or background objects in the images: address information (e.g., on envelopes), prescription labels, credit card information, contents of digital screens (e.g., computer screen), and the presence of the face or other body parts of the user (as well as of bystanders).
Our selected foreground and background objects are thus representative of the objects and questions asked by people with VIPs as also observed in prior studies [19,33].
In each scenario, we assumed only one foreground object in the image, since that is the typical use case when asking questions in such systems.
We included objects that are the combination of sensitive, personally identifiable, financial, and miscellaneous objects that people asked questions about in the VizWiz application.
Later, we listed 10 background objects that could possibly be present in the image along with the foreground object in that given scenario.
The selection of the background objects for each scenario varied slightly; six objects were common to all scenarios whereas the rest were specific to the scenario description.
For example, we added 'restaurant bill' for the restaurant scenario but did not include that in the other two scenarios.
Table 1 describes background and foreground objects used in the three scenarios.
We asked the following three questions (paraphrased) for each scenario (see Appendix A for our survey instrument):Q1.
How comfortable would you feel asking for help (about a foreground object) from a sighted assistant by sharing an image?
This question varied slightly based on the scenario.
Participants were asked to select from a 5-point Likert scale: (1) extremely uncomfortable (2) somewhat uncomfortable (3) neither uncomfortable nor comfortable (4) somewhat comfortable (5) extremely comfortable.Q2.
How comfortable would you feel if the following background objects were present in the image?
This question varied slightly based on the foreground object and the scenario.
The question used the same Likert scale mentioned above.Q3.
Please briefly explain your selection above.
This was an open-form question.
Participants were asked to explain their selections for feeling comfortable or uncomfortable while sharing photos or videos with a human assistant.
The survey consisted of 32 questions in both open-ended and close-ended form.
The survey instrument was organized as follows (see Appendix A for the survey instrument):• Consent form.
• Questions about which (if any) electronic devices and assistive technologies the participant uses, how frequently they use the camera and share images online, and questions on their level and duration of visual impairments.
• Questions about the kind of help they seek from sighted people, whether they shared images or made video calls to a sighted person for seeking help, and what questions they usually ask.
• Three scenarios, presented in random order (within subjects), each with three questions about the foreground object, background objects (in random order), and an explanation for their selections.
Note that each participant was assigned to a single assistive technology (type of human assistant), and these questions were asked in the context of one kind of human assistant.
• Questions about whether they had ever shared a photo containing sensitive information and their most recent experience sharing an image with a sighted person.
• Five demographic questions (age, gender, race or nationality, education, and occupation).
The survey was conducted on Qualtrics (an accessible survey platform) over a period of one month between August and September 2018.
We shared our recruitment sign-up form through email lists of various organizations including the National Federation of the Blind (NFB) and the American Council of the Blind (ACB).
We asked visually impaired assistive technology users to sign-up through a form provided if they met the following criteria: participants had to be (1) living in the United States for at least five years to help control for cultural variability [48]; (2) 18 years of age or older; and (3) visually impaired.
Researchers screened the qualified participants and personally emailed each participant a unique survey link.
The link was not reusable, and each participant could participate in the survey only once.
The survey was shared only with a curated list of VIPs managed by reputable organizations.
NFB and ACB reviewed our study information for relevance and then forwarded our recruitment email to their mailing lists.
Based on organization membership and list curation our recruitment email went to only those people who had VIPs.
Next, one researcher interacted with each individual participant and inquired about their level of visual impairment and blindness.
Additionally, we recruited (or retained the data of) only those participants who sufficiently described their level of VIPs in their free-text responses in our survey and sign-up instruments.
Finally, our compensation structure (see Section 3.1.7) was chosen in part to provide high-quality responses.
We recruited the participants from different organizations and could not anticipate the number of participants before initiating the survey.
Therefore, we picked a random-drawing approach as opposed to a straight payment, and the participants were told upfront about the compensation in the recruitment email as well as the consent form.
A raffle-based approach is also less likely to invite abuse and instead stimulate voluntary participation and high-quality answers [17].
After collecting 155 responses, we performed the random drawing, selected 15 (10%) participants, and sent $20 Amazon e-gift certificates to each of them.
We emailed them the link of the e-gift certificates within three days of performing the random drawing.
The study and compensation scheme was approved by our institution's ethics review board (IRB).
We conducted an in-person online survey and a follow-up interview with four male individuals to identify any accessibility issues with our survey instrument.
Three of the pilot Three participants participated in the survey using computers and one from a mobile phone.
They used Jaws and Google's TalkBack as screen readers.
We requested them to point out any accessibility issues they faced while participating in the survey.
We also requested that they suggest improvements to our survey.
The pilot study took around 40-60 minutes for each participant.
Participants were compensated with $20 cash for participating in the pilot.
We conducted the pilot study in two phases, interviewing two participants at each phase.
We identified any accessibility issues in the first phase and conducted the second phase with the revised version.
In the first phase, participants reported varying levels of accessibility issues they faced in the survey, such as difficulties in navigating through the text fields, not having a progress bar, and minor confusion about the wording of some questions.
We addressed the issues mentioned by the participants after the first phase and conducted the second phase one week later.
At this phase, the participants did not raise any accessibility issues and thus we finalized the survey.
During the follow-up interview, participants also suggested the modification of the list of objects based on the scenario, and we modified the existing objects based on their suggestions.
We now describe our quantitative and qualitative analysis procedures.
We used non-parametric versions for all of our statistical tests as our data do not meet the assumptions of parametric tests, such as normality and equal variance of errors.
We have one dependent variable (comfort level for sharing information) and several independent variables (human assistants, scenarios, objects).
To analyze our data, we conducted an overall Kruskal-Wallis test (for multiple groups and between subjects), a Wilcoxon rank sum test (for two groups and between subjects), a Friedman rank sum test (for multiple groups and within subjects), and a Wilcoxon signed rank test (two groups within subjects) across all conditions to see if there was any significant difference in the measured variables among the conditions.
We followed the Kruskal-Wallis tests with a Dunn's post hoc test with a Benjamini-Hochberg correction, where we compared specific pairs.
For the Friedman rank sum test, we performed a pairwise Wilcoxon signed rank test as the post hoc test.
We performed a power analysis to estimate the sample size required to produce statistically significant findings.
The analysis showed that 50 participants per condition would provide enough statistical power to detect 0.25 ('small') sized effects (α = 0.05,1 − β = 0.90).
All qualitative answers were independently coded in a bottom up approach by two researchers.
The researchers met weekly to iteratively and redundantly code a subset of open-ended responses from the survey.
Each subset comprised of a combination of the audience and scenario.
The researchers coded each response into one of seven reasons for their information sharing practices: 'burden' (does not want to bother family or friends), 'impression' (does not want to feel embarrassed or awkward), 'indifferent' (does not mind if information is shared), 'relevance' (does not want to share any unnecessary information), 'professionalism' (does not want to share with volunteers), 'trust' (has more faith in friends or family members), and 'security' (does not want identity to be compromised).
The researchers computed Cohen's Kappa among two raters for each subset, and discussed disagreements after coding a subset of qualitative data.
After two rounds of redundant coding, the researchers reached an acceptable average pairwise Cohen's Kappa score of 0.8 or greater for each subset combination of audience and scenario.
We now present our quantitative findings based on our statistical analyses.
We first report our participants' demographics relative to their technology usage.
Next we present findings about the types of content participants were selectively disclosing and concerns related to disclosure behavior.
We then present findings about the audiences participants were selectively disclosing to and emergent issues related to audience and disclosure.
Finally we present additional factors that affect information disclosure.
A total of 165 people participated in our survey, although some participants did not complete the survey.
After removing the incomplete responses, our final sample for the study comprised 155 participants with visual impairments.
Of these participants, 54 received the 'friends' condition, 50 received the 'family' condition, and 51 received the 'volunteer or crowd-workers' condition.
Of these 155 participants, 92 (59.4%) identified themselves as female and 63 (40.6%) as male.
Among our participants, 44 (29.3%) were between 18-to-34 years old, 50 (33.3%) participants were between 35-to-54 years old, and 56 (37.4%) of the participants were 55 years or older.
As for their professional background, 56 (37.6%) participants reported being employed full-time, 31 (20.8%) as retired, 26 (17.4%) as unemployed and looking for work, 24 (16.1%) as employed part-time, and 12 (8.1%) as a student.
Among the participants, 101 (61.2%) were totally blind, whereas 64 (38.8%) live with different levels of VIP such as 'low vision' and 'blind in one eye and low vision in the other.'
More than half of the participants, 96 (60.4%), were visually impaired since birth, whereas the rest became visually impaired afterward: 34 (21.4%) since childhood, 15 (9.4%) since early adulthood (18-40 years old), 11 (6.9%) since middle adulthood (41-60 years old), and 3 (1.9%) since late adulthood (61+ years old).
Participants also reported their use of various camera-based assistive technologies and their assistance-seeking behaviors.
Some of the most popular assistive technologies used by the participants were Seeing AI (80%), TapTapSee (70.3%), BeMyEyes (69.6%), and KNFB Reader (65.8%).
Almost all participants, 144 (96%), reported using assistive technologies for more than a year.
To explore the role of human assistance in their lives, participants were asked whom they usually asked for help and their purposes of seeking help from them.
The primary sighted supporters for people with VIPs are family and friends (133, 80%), although a majority of participants reported receiving help from volunteers or crowd-workers as well (100, 65%).
Only four (2.4%) participants reported never seeking help from anyone, and we excluded their data from the analysis.
Participants also reported how they sought help from sighted people: 122 (81.8%) for reading documents , 101 (67.7%) for identifying objects, 95 (63.7%) for identifying color, and 46 (30.8%) for seeking subjective opinions (e.g. how the participant looked in new clothing).
To understand whether the type of background content has any effect on the sharing preference of users, we analyzed the mean comfort-level scores for two different types of content within images: 1) background objects and 2) people inadvertently captured in images (i.e., bystanders).
Next, we will discuss the concerns of people with VIPs in relation to different types of objects and people in the background of images.
9 We categorized the background objects in our survey into four types: (1) Personally Identifiable Information or PII (credit card numbers, bills, mail showing one's address, and official documents) [55], (2) objects affecting one's impression management (mess, medical prescriptions), 10 (3) general objects (food, books), and (4) laptop screens.
Figure 1 illustrates participants' comfort levels for various classes of objects.
As expected, we found that participants are least comfortable sharing their PII and most comfortable sharing general objects.
People also show a higher concern about the objects that may impact their impression management.
We conducted an overall Friedman rank-sum test and detected that at least one statistically significant difference exists between attributes (χ 2 (1) = 169.2, p < 0.0001).
Next, we conducted pairwise Wilcoxon Signed-Rank tests with a BH correction to detect any significant differences for background objects.
For all comparisons, pairwise tests reveal significant differences.
Figure 1 Overall, we can see that participants were uncomfortable with PII and impression management-related objects in the background.
They were somewhat comfortable with laptop To understand the concerns with sharing photos that capture people in the background, we considered two types of content pertaining to people: 'self-disclosure' (e.g., reflection of the participant's face on the laptop screen, capturing the participant's face or body part, or a photo frame with a picture of the participant) and 'bystanders' in the photo (e.g., other people in a restaurant or the face or body part of a colleague).
Figure 2 shows the comfort levels for the two types of people captured in the background.
Surprisingly, our analysis found that participants were more comfortable revealing themselves (µ = 3.6,σ = 1.31,95% CI [3.5,3.7]) than bystanders (µ = 3.0,σ = 1.4,95% CI [2.9,3.2]) to human assistants.
A Wilcoxon signed rank test showed that this difference was statistically significant (V = 4722, p < 0.001).
To explore the effect of the social relationship on participants' information sharing preferences, we analyzed the interaction between the different types of background information with the type of human assistant.
We first conducted the Kruskal-Wallis test appropriate for between-subjects data to test for overall differences by type of human assistant.
The test revealed the information-sharing preferences of our participants significantly differ for the three different human assistants (χ 2 (1) = 14.338, p < 0.001).
Next, we conducted Dunn's post-hoc pairwise tests with BH correction to detect any significant differences in information-sharing preferences for human assistants.
Pairwise Dunn's tests showed that they were all statistically different from each other except for the difference between friends and crowd workers, meaning that participants had similar privacy concerns for friends and crowd workers.
The significant difference between family and other forms of human-assistants indicates higher trust for family members in general.
Figure 3 shows the comfort levels for three types of human-assistants.
The .
Overall, participants are slightly more comfortable if family members see sensitive objects compared to other assistants.
To understand how sharing preferences for audience might differ based on the type of person captured, we conducted an overall Kruskal-Wallis test and detected significant differences in comfort when sharing images with different human assistants (χ 2 (1) = 8.2813, p < 0.05).
These differences are illustrated in Figure 4.
A Dunn's post-hoc analysis similarly showed the non-significant relationship between friends and volunteers, and a slightly (and significantly) higher comfort level with family compared to the other two assistants.
Looking specifically at the person categories, this difference was significant for self-information (Kruskal-Wallis ).
Overall, participants were slightly more comfortable sharing images with themselves in the background with family members than with others.
With bystanders, however, the type of audience did not appear to matter.
Although a larger sample may have detected a difference, we expect this difference to be small.
Next we study whether sharing preferences for audience might differ based on the type of object captured in the background.
We found a significant association between the sharing preference of different background objects and the type of human assistant (see Figure 5).
We conducted an overall KruskalWallis test and observed significant differences in the sharing preference with audiences for PII, impression management, and general objects (PII: χ 2 (1) = 26.07, p < 0.001, impression management: χ 2 (1) = 12.627, p < 0.001, general: χ 2 (1) = 13.181, p < 0.001).
No significant relationship was found for sharing laptop screens with audiences.Next, for all groups of objects (other than laptop screens) we conducted Dunn's post-hoc pairwise tests with BH correction to detect any significant differences for different audiences.
For PII, we observed significant differences (p < 0.0001) between all pairs but family and friends, with participants being much more uncomfortable with volunteers as compared to friends and family.
For impression management, we found a statistically significant difference (p < 0.001) only between family and friends.
For the general objects, we found significant differences (p < 0.01) between friends and crowd workers, and also between family and crowd workers.
Overall, participants were less comfortable with volunteers when it came to inadvertent disclosures with PII, which would make sense in the context of worries about identity theft.
However, in the case of impression management, they were more concerned with sharing these with friends, likely because impression management is less concerning with family and anonymous volunteers, and people might be least comfortable with friends when it came to one's living conditions or medications.
In this section, we will report on how demographic factors such as age, gender, and severity of visual impairments impact our participants' information disclosure practices.
We provided an open-text option to collect the gender of the participants in the survey.
After coding the responses, we found all the participants identified themselves as either male or female.
Overall, our female participants were slightly less comfortable (µ = 3.1,σ = 1.5,95% CI [3.0,3.1]) than the male participants (µ = 3.3,σ = 1.4,95% CI [3.
2,3.4]) in sharing information with human assistants.
We conducted an overall Wilcoxon rank sum test (between subject, two groups) and found the difference is statistically significant (W = 1984000, p < 0.001).
We also analyzed the effect of gender on the sharing preference for each group of objects.
The differences in disclosing different background objects for male and female participants does not reveal any statistically significant differences except for impression management (W = 87438, p < 0.0001).
Female participants were less comfortable (µ = 2.6,σ = 1.3,95% CI [2.
5,2.7]) to share information that may affect their impression (e.g., mess and medical prescription) as compared to male participants (µ = 3.2,σ = 1.4,95% CI [3.0,3.3]).
Overall female participants were slightly less comfortable in disclosing background information compared to male participants, although the difference was mainly attributable to information related to impression management, in which case the difference was sizeable.
To simplify the analysis, we categorized the participants into three age groups: 18-34, 35-54, and 55 and older.
Our findings suggest that the participants aged 18-34 have the least concerns about sharing background information and the group 55 to older are the most concerned.
We conducted a Kruskal Wallis test (between subject, three groups), and the result shows that the concerns of disclosing background information with different audiences differs for the three age groups (χ 2 (1) = 39.534, p < 0.0001).
We conducted Dunn's post-hoc pairwise tests with BH correction to detect the significant differences in information sharing preferences among the age groups.
We observed that the participants from age group 18-34 (µ = 3.4,σ = 1.52,95% CI We explored the interaction of age and type of background object and found a significant difference (p < 0.005) for PII, self, and general objects.
For all three groups, we observed the participants aged 55 or older are more concerned about disclosing information to human-assistants compared to the participants aged 18-34.
Findings indicate younger participants have less privacy concerns compared to older ones.
We provided an open-text option to collect the level of visual impairments of participants in the survey and combined responses into two groups: totally blind and low vision.
We conducted an overall Wilcoxon rank sum test, and the result shows that participants with low vision (µ = 3.0,σ = 1.51,95% CI [2.9,3.0]) are significantly more concerned (W = 19865004, p < 0.0001) than the totally blind (µ = 3.3,σ = 1.44,95% CI [3.2,3.3]) participants.To observe the relation between different levels of VIP and the sharing preference of different objects, we conducted Wilcoxon rank sum test for each group of objects and found significant differences (p < 0.001) for PII and self-disclosure.
The result indicates that participants who are low vision (µ = 2.0,σ = 1.37,95% CI [1.9,2.2]) were much more concerned than totally blind (µ = 2.6,σ = 1.51,95% CI [2.5,2.7]) participants for disclosing information related to PII.Similarly, for self-disclosure, low-vision (µ = 3.3,σ = 1.4,95% CI [3.2,3.5]) participants were more concerned than totally blind (µ = 3.7,σ = 1.23,95% CI [3.6,3.8]) participants.
We also performed another overall Wilcoxon rank sum test to observe the differences between participants who have been visually impaired since birth versus participants who became visually impaired later in their lives.
We observed no statistical significance (p>0.05) between the two groups.
We now present the results of our qualitative analysis, which shed light on the reasons behind our quantitative findings.
Participants expressed privacy and security concerns about the unintended sharing of background information with humanassistants.
One participant summed it up, saying, "I am uncomfortable sharing what I cannot see" (P102).
A majority of the concerns (56.4%, N=83) related to sharing sensitive and personally identifiable information about the participants and the people around them.
In light of these concerns, a common defensive strategy was to physically clear the exposed areas and remove the sensitive contents before using the cameras: "I would need to keep in mind who I was asking for assistance, I would also check the area to make sure it was clear of clutter and other objects.
[P48]"Thus, it was clear that participants were greatly concerned about their privacy in the context of background objects and went as far as to clear the background in some instances.
We highlight interesting cases such as 'impersonal trust' and anonymous interaction in the following sections.
We first present findings of the reasoning for the participants to selectively disclose the background contents present in images.
We then report their reasons for selectively disclosing certain types of behavior with different audiences.
In analyzing the qualitative reasons for privacy concerns, identity theft emerged as a dominant concern among people with VIPs.
Participants were largely uncomfortable with sharing their PII with human-assistants.
Interestingly, however, participants (18.4%, N=27) also expressed strong concerns about being judged negatively for sharing the messiness of their surroundings.
Participants mentioned feeling embarrassed, and preferred to avoid sharing a messy area: "I'm very picky about being messy, I wouldn't want people to get the wrong impression of me by watching other people's mess!"
[P144]Prior studies reported that computer screens are one of lifeloggers' major privacy concerns as people spend a considerable amount of time in front of devices that display private information [42,49].
Our participants reported mixed reactions about laptop screens in the background that varied based on what might be displayed on the laptop screen.
They would be more uncomfortable if it showed any private information.
"A laptop screen is seldom an issue for me, unless it provides information that can be used in identity theft."
[P114]We sought to understand the disclosure behavior of the participants and found that participants considered sharing the image of bystanders without their consent to be a violation of their privacy.
"I have no problem having parts of myself visible, even my face, depending on the app in question.
I would want camera-based technology to be discreet so I wouldn't take pictures of people at other tables, in case they would be uncomfortable."
[P34]While participants were comfortable sharing background objects with family member, they preferred not to compromise the privacy of bystanders, even with their family.
"I have a close relationship with family, I generally don't care what they see.
However, I worry about what would happen if certain data, such as other people's whereabouts, is compromised."
[P82] In our qualitative data, we found several concerns raised by the participants for their information disclosure with humanassistants, which we describe next.
Our participants shared extreme privacy and security concerns about volunteers and agents that varied based on impersonal trust and the anonymous nature of the interaction.
Privacy and security concerns: Participants expressed strong privacy and security concerns while seeking help from the volunteer or agent-based assistive systems.
They were concerned about identity theft, misuse of their information, or criminal behavior.
They were not comfortable revealing private information with a total stranger whereas they were comfortable with general objects such as food items.
"I would feel extremely uncomfortable with the visibility of all the items which are personal to me or to a coworker because they could be potentially misused by the stranger who is looking at the picture.
Anything that has information that discloses someone's identity or contains confidential information should not be shared so that makes me extremely uneasy.
Food items are common and not personal to me so I am somewhat comfortable with them being visible in the picture."
[P100]Impersonal trust: Prior research shows that 'impersonal trust' (where trust is not based on immediate personal relationships) can influence interactions between people and institutions [36,65].
In our study, we also observed impersonal trust as participants mentioned trusting an agent from a professional organization more than a random volunteer.
A few of our participants (6.1%, N=9) indicated relying more on a paid professional agent 11 with their sensitive information rather than a volunteer.
"I try to only share what's relevant to my question and would never intentionally share private info with a volunteer, only a paid and traceable professional."
[P140]Participants believed that their privacy and security will be more protected with the professional agents as the organization has a privacy policy and trained agents.
"The service I use most has agents who are background checked, highly trained, and who are obligated to follow a clearly defined privacy policy.
I would not allow a volunteer to see my credit card, for example, while I would let the trained agent do so without a second thought."
[P154]Anonymous interaction: We found that participants are more comfortable sharing general objects with volunteers rather than their family members.
Due to the anonymity of interactions with volunteers, participants were less concerned about sharing information, such as messy surroundings and body parts, and anticipated volunteers to be less judgmental.
"I am very comfortable with who I am and if I use such assistance I understand that the other person is there to help and not to judge my appearance or surroundings."
[P142] Participants reported family as the most reliable source for seeking support.
However, the anxieties of being a burden to the family often limited them from soliciting aid from family.Trust and reliance: We found that family is one of the most trusted support systems for people with VIPs, and they are comfortable sharing almost any kind of information with them when seeking support.
According to our participants, family members often know them and understand their requirements, hence they do not hide much from them.
"I trust my parents who I would be asking for assistance, I don't care or feel uncomfortable about them seeing anything else around me.
Not like I am hiding anything or doing anything wrong."
[P61] "Considering that this is my family, I am already comfortable with them assisting me with my needs.
They assist me quite frequently, and are knowledgeable and understanding to my needs."
[P73]Social costs of burden: Previous research has shown that people can be reluctant to ask for help from their known networks to balance social costs [63].
People with disabilities have enhanced concerns about appearing dependent and helpless in front of their social groups [20].
We found a similar concern in our study while seeking help from family and friends.
Despite trusting their family most, participants sometimes preferred not to disturb their family members.
They would avoid asking help from family if could manage issues on their own or from other sources.
"I trust my family and friends but don't like to bother them if I can help it."
[P47]Some participants felt that asking for help from family members may prove their dependency and helplessness and would prefer alternatives.
"I don't want to have to rely on my family members to tell me what things are, but that's because doing that takes away my independence."
[P59]"I do not ask family members.
I use ScripTalk for medical prescriptions.
I ask Aira or BeMyEyes.
I am concerned that most of these questions assume one has family around or that we'd always be comfortable asking them things.
Families can often want to control things but if we use assistive technologies and agents, it's better, I think."
[P79] We noted concerns related to trust and impression management when disclosing information with friends.
Privacy and trust: Several participants indicated trusting their friends with all types of information.
They believed that friends would protect their information.
"I have complete trust in my friends, and in their reliability and keeping confidential data safe."
[P32] However, participants also expressed they might want to avoid sharing some personal information with their friends in order to protect their privacy.
"I wouldn't mind showing food or maybe myself but any private info depending who I was talking to especially a credit card with all the scams going on I wouldn't really like, though I would try to make sure that I didn't show that stuff."
[P27]Unwanted exposure and impression management: Participants may experience unwanted exposures while sharing information with their friends.
Several participants were concerned about the situations when the image can be leaked or disclosed to a wrong person other than the intended audience.
"I wouldn't really want my friends to see financial or medical information.
Also, if they have a picture on their phone that contains personal info about me, this creates an opportunity for someone other than my friend to see the picture on my friend's phone (e.g., friend's family members, romantic partner), which would jeopardize the privacy and security of the information."
[P30]He additionally expressed concerns about his identity at risk of being leaked on social media and is aware of possible security risks.
"The info in the picture could be posted on social media or used against me in some malicious way.
I am very distrustful of social media."
[P30] We first summarize and contextualize our key findings and then discuss broader implications for more 'humanizing' designs of assistive technologies.
Our results show that the information disclosure behaviors of people with VIPs depends on the types of objects and human assistants.
Hayes et al. recently 'shadowed' people with visual impairments and studied how they obtain help from their allies in face-to-face (offline) interactions [38].
Although they studied only five participants, they observed the general theme of people with VIPs being careful when selecting an ally to provide assistance, highlighting the importance to study privacy in assistive applications.
In the context of image sharing by 'lifeloggers,' Hoyle et al. [41,42] did not study specific audiences, but they also found that participants were concerned about private information (such as screens and other objects with textual information), impression management, and the presence of bystanders in their photos.
Unlike their work, however, our participants were more concerned about the privacy of bystanders than their own when it came to capturing people in images.In the context of information sharing with specific audiences, our participants shared strong concerns about sharing personally identifiable information with crowdworkers because of concerns about identity theft.
This finding is consistent with prior work showing people are more willing to share private information with stronger social ties [74].
We also found that participants were more comfortable sharing concerns about self-presentation with family than with friends.
However, we also found some evidence 12 that participants were more comfortable with with crowd workers (weaker ties) than with friends (stronger ties).
In the same vein, Dosono et al. found that college Reserve Officers' Training Corps (ROTC) students were more comfortable sharing personal crises related to impression management (e.g., physical injuries) with family and counselors instead of their ROTC peers [28].
In general, anonymous interactions have been shown to help in overcoming social stigma and may be more appropriate for private exchanges where more openness is desired [28,47].
Consistent with prior work [7,40,66], women were more concerned about their privacy than men.
Female participants were more concerned than male participants when it came to objects related to impression management.
Although prior work has found that older adults can show both extremes of privacy concerns [57,67] with younger populations being more pragmatic [67], our older participants were more concerned about sharing background objects than the younger participants.
In the context of level of impairment, prior work has found coping strategies such as 'acceptance' where people with visual impairments (especially the totally blind) felt they "had very little choice other than to accept the risks" [8].
One might therefore expect people who are totally blind to be more concerned about or interested in protecting their privacy.
Interestingly, however our totally blind participants were less concerned about their privacy than the low-vision participants.
It may be that people who are totally blind are less aware of the possible privacy risks than people with low vision or are more willing to compromise their privacy because they have become accustomed to a higher need for assistance and 'acceptance' of less privacy in general.Finally, prior work has found that people may have more trust in volunteers compared to paid workers because of a stronger perception of altruism and sincerity of the volunteer [39].
Qualitative analysis showed that some participants trusted paid crowd workers more than volunteers with their private information.
The role of 'impersonal trust' in such systems needs additional investigation, and how more trust may be derived from volunteers or paid agents.
12 The statistical significance was marginal at p = 0.054.
Although there is a growing body of work exploring the needs of people with VIPs [16,61,62], our study yielded novel privacy and security concerns of people with VIPs related to their sharing of information with crowd workers and human assistants using camera-based assistive systems.
Many of these concerns were related to how camera-based assistive systems were creating a lack of security in people's daily lives -that is, these systems were serving to further marginalize their identities.Broadly speaking, when populations are marginalized based on their identities, they are placed at the edge, beyond boundaries, or on the outside of what is considered normative, and individuals and groups can be marginalized on various intersections of their identity, such as their race, gender, sexual orientation, socioeconomic status, or perceived ability [64].
Recent work has explored the ways in which algorithmic systems can marginalize people's identities.
Systems like facial recognition software can serve to further marginalize people with gender-fluid identities, as these systems serve as gender reduction mechanisms and may misidentify people who have changed genders or who do not choose a gender [35].
In our study, the marginalization and subsequent lack of security manifested in the relationship between the systems and people's identities for people with VIPs.
Our identity defines us as an individual; it is the sense of self that we refer to and that others see us as, giving us security in our daily lives [22,31].
At their root, camera-based assistive technologies give people with VIPs the chance to regain security.
Giddens defines security as a stable mental state derived from the continuity and predictability of routines, that is, a person achieves a sense of trust and safety in their life through the enactment and habitualization of routines [30].
For example, the ability to pay bills or take a prescription generates a sense of reliability in a person's life; it is this sense of stability that provides one with a sense of security about their existence.In this context, we found that camera-based assistive technology can create insecurity.
That is, through their use of these systems, our participants were concerned about identity theft and people finding out where they lived.
Moreover, people were also concerned with issues related to self-concept, such as if friends caught a glimpse of their "messy" home environments.
Thus, we argue that in order to create more private and secure assistive technologies, we must begin to humanize assistive technology; that is, we must train computer vision algorithms to better understand what kinds of objects people might want others to (not) see, as well as be cognizant of where we need to enforce human assistance as opposed to algorithmic assistance.
As a means of generating ways in which this can be operationalized at the system's design and implementation level, to humanize assistive technology means that we must pay more attention to context.
Humanizing security as humanizing context.
The way in which scholarship has defined context has gone through various transformations over time.
Context has often been viewed, from a positivist perspective, as the setting where action unfolds, where the setting is believed to be a static entity, stable and separate from the activities taking place therein [29].
Early on, however, Suchman's [70] formative work illustrated that context incorporates the activities of humans, and people's activities are neither stable nor predetermined.
In building on this notion of context, Dourish [29] argues that the determination of context cannot be made a priori, that is, context is an emergent property of interaction.
In this view, context is actively produced throughout the course of interaction; it is determined by the people who are present and in how they generate, together, the rules and norms for their interaction.
For example, if only one person is present in their home (i.e., a homeowner), they may feel free to engage in actions that they may otherwise feel uncomfortable with others present, such as taking a shower with the door open.
When others are present, such as guests, the context shifts and the rules and norms also change, and this same person may not feel comfortable engaging in these same behaviors.The continual shaping of context is related to impression management [31], where people are trying to control how they present themselves to others.
In the context of social media, people's ability to engage in impression management is a burden as people tend to collapse multiple audiences into a single context [58].
This process of impression management is increasingly complex for people with VIPs as how in some cases people with VIPs present themselves to others is invisible to them.
In this view, systems should be designed such that they make context visible.
Technical solutions should therefore not just focus on finding PII in images, but also look for situations that may affect one's social standing.
One such implication is that people (as bystanders) who may be concerned about being captured by assistive devices can be made aware that other people will be removed through face detection (for example) from assistive devices.
As we found, people with VIPs are highly concerned about the privacy of bystanders, and Ahmed et al. study 'up to [what] limit' bystanders are willing to be captured in such circumstances [7].
Given that camera-based assistive technologies utilize digital images to communicate with audiences, photos often collapse several contexts together (i.e., a home environment, driver's license photo, prescription drug labels, and more).
Given that some of this information was not appropriate for certain audiences, computer vision algorithms should be designed more empathetically such that they detect content deemed inappropriate for certain audiences and blur them, redact them, or generate other novel solutions that are context aware and thus sensitive to the desires of those who are using camera-based assistive technologies.
For example, Li et al. [56] and Hasan et al. [37,56] have been studying privacy transforms that are also visually appealing to the viewer.
For assistive applications, further research is needed to understand how the quality of assistance might degrade with obfuscating transforms.
Technologies should help to decide the appropriate audience for the type of question and take appropriate measures for detecting privacy violations for that audience, or, conversely, pick the right audience based on all subject matter in the photo (and not just the foreground object).
People should be informed if PII, in particular, is present while using crowd-sourced technology whereas they should know if prescription medications are visible when seeking assistance from friends.Finally, given that our study focused on camera-based assistive technologies, we believe that technical systems, more broadly, might be creating differential forms of insecurity in the daily lives of people with VIPs.
This leads to a 'security paradox' whereby, on the one hand, these systems are being used by people with VIPs since they serve an important need in enabling them to maintain their routines, yet they are also generating insecurity as they expose them to additional vulnerabilities.
Thus, we need to continue to understand where systems are creating insecurity through additional explorations of a broad range of assistive technologies amongst the visually impaired, while also uncovering new values that can drive future design.
We note several limitations of our study, which could be addressed in future work.
Our participant sample was small, limited to a few national blind foundations, and restricted to those who chose to respond to an ad about camera-based assistive technology, so it is difficult to know how well our findings generalize to the greater population.
However, we also note the challenges in reaching this population, and compared to other recent studies of privacy concerns for the visually impaired, our sample size is relatively large [7,14,75].
We considered only three types of human assistants; however, other social groups may have an impact on the information sharing behaviors of people with VIPs, such as co-workers and specific categories of friends (close, distant).
Our qualitative data also showed a distinction between professional crowd agents versus volunteers and should be explored in future work.
In this study, we considered only the effect of background content and audiences on a user's sharing preferences.
There may be other factors that affect people's preferences as well, such as the sharing context and purpose.
Future research should study the privacy needs of people with VIPs for other social groups in varying situations.
To better understand the privacy concerns of people with visual impairments in the context of photo-based, humanassisted question-answering systems we conducted an online survey with 155 visually impaired people.
We found that while people with visual impairments have privacy and security concerns about revealing background objects, their information disclosure preferences vary according to the types of objects and human assistants.
Our findings, in some cases, were often counter-intuitive.
For example, participants were more concerned with the privacy of bystanders than their own privacy and they were more comfortable sharing concerns about self-presentation with family (and possibly crowd workers) as opposed to friends.
Moreover, we believe that the ways in which these systems are designed can create a lack of personal security in the lives of the people we are trying to assist.
Although assistive technologies have great potential for social good, they can also potentially harm people.
As designers and builders of sociotechnical systems, we must continue to understand the more positive aspects as well as the moral and ethical dilemmas that may arise when our systems are used.
In doing so, we hope these systems will continue to take on more humanistic, empathetic qualities, and achieve our goals of assisting as opposed to harming others.
This material is based upon work supported in part by the US National Science Foundation under awards CNS-1408730, CNS-1252697, and IIS-1657429.
We thank Jeffrey P. Bigham and the VizWiz team for sharing their data with us.
We thank our participants, as well as Sharon Lovering from the American Council of the Blind and Lou Ann Blake from the National Federation of the Blind, for helping recruit participants.
x A The SurveyDisplay the consent form.
Then display screening questions.
Q1.
What is your level of visual impairment?
(Open text)Q2.
Since when do you have your visual impairment?
-Since Birth -Since Childhood -Early Adulthood (When I was 18-40 years old) -Middle Adulthood (When I was 41-60 years old) -Late adulthood (when I was 61+ old) Q3.
What types of devices do you regularly use?
Please select all that apply?
-Laptop or notebook computer -Smart phone -Tablet computer -Desktop computer -Smart watch -Fitness tracker -Wearable devices -Smart glasses (e.g. Google glass, Hololens) -Other (Open text) Q4.
How frequently do you use camera on your smartphone?
-Never -Almost never -Occasionally sometimes -Almost every time -Frequently Q5.
How frequently do you share photos online?
-Never -Rarely -Sometimes -Often -Always Q6.
When you need the help of a sighted person (for example, to identify an object), whom do you typically ask for help?
Please select all that apply.
-I ask my friends -I ask my family members -I ask random strangers -I ask professional agents or crowd workers or volunteers through assistive technology -I don't ask anyone Q7.Which of the following assistive technologies have you used so far?
Please select all that apply.
-To identify an object -For reading documents or screens or labels -To get a general description of a scene -To get the friend's opinion on something (e.g.
How do you look like?)
-Identify the color of a dress or any object -Other (Open text) Q12.
What types of questions would you ask to your friends if you were to ask them?
Please select all that apply.-To identify an object -For reading documents or screens or labels -To get a general description of a scene -To get the friend's opinion on something (e.g.
How do you look like?)
-Identify the color of a dress or any object -Other (Open text) Scenarios: Suppose there is an assistive technology where you can seek help from your friends by taking a photo of the object, recording the question and sending it to them.
You can also make video calls to your friends to seek help.
Now we would like to ask you about your comfort levels when using such platforms in various situations.
In particular, we would like to understand how you would like to use such technologies to get help from your friends.Q13.
Suppose you went to a restaurant and were served a can of soda.
You want to know the type of the soda but there is no one around to ask.
If there was an assistive technology where you could ask your friends to identify the soda can by taking a picture of it, how comfortable would you feel asking them for help?
We used a 5-point Likert scale (1: extremely uncomfortable, 5: extremely comfortable) Q14.
Suppose while taking the picture there were some other objects captured along with the soda can.
How comfortable would you feel if the following were present in the photo and visible to your friends along with the soda can?
We used same 5-point Likert scale described in Q13 for each of the following options.
Q15.
Can you please briefly explain your selections above?
(Open text) Q16.
Suppose you are at your workplace and need to take your prescription medicine.
But there are two similarly sized bottles of medicine, and you need to differentiate between them.
You don't want to ask any of your coworkers to identify the bottles for you.
If there was an assistive technology where you could ask your friends to identify the medicine bottles by taking a picture of the medicines, how comfortable would you feel asking them for help?
We used a 5-point Likert scale (1: extremely uncomfortable, 5: extremely comfortable) Q17.
Suppose, while taking the picture of medicine bottles there were some other objects captured along with the medicines.
How comfortable would you feel if the following were present in the photo and visible to your friends along with the medicine bottles?
We used same 5-point Likert scale described in Q16 for each of the following options.
Q18.
Can you please briefly explain your selection above?
(Open text) Q19.
Suppose you are preparing to attend a party and thinking of wearing the new dress/suit you just bought.
Now you want to wear a scarf/tie with it but cannot decide which one will match best.
There is no one around to help.
If there is an assistive technology where you can ask for the opinion of your friends by taking a picture of you wearing the dress/suit and the scarf/tie, how comfortable would you feel asking them for help?
We used a 5-point Likert scale (1: extremely uncomfortable, 5: extremely comfortable) Q20.
Suppose, while taking the picture of the dress/suit and scarf/tie, there were some other objects captured along with the dress.
How comfortable would you feel if the following were present in the photo and visible to your friends along with the dress/suit?
We used same 5-point Likert scale described in Q19 for each of the following options.
Display the consent form.
Then display screening questions.
Q2.
Since when do you have your visual impairment?
-Since Birth -Since Childhood -Early Adulthood (When I was 18-40 years old) -Middle Adulthood (When I was 41-60 years old) -Late adulthood (when I was 61+ old) Q3.
What types of devices do you regularly use?
Please select all that apply?
-Laptop or notebook computer -Smart phone -Tablet computer -Desktop computer -Smart watch -Fitness tracker -Wearable devices -Smart glasses (e.g. Google glass, Hololens) -Other (Open text) Q4.
How frequently do you use camera on your smartphone?
-Never -Almost never -Occasionally sometimes -Almost every time -Frequently Q5.
How frequently do you share photos online?
-Never -Rarely -Sometimes -Often -Always Q6.
When you need the help of a sighted person (for example, to identify an object), whom do you typically ask for help?
Please select all that apply.
-I ask my friends -I ask my family members -I ask random strangers -I ask professional agents or crowd workers or volunteers through assistive technology -I don't ask anyone Q7.Which of the following assistive technologies have you used so far?
Please select all that apply.
-To identify an object -For reading documents or screens or labels -To get a general description of a scene -To get the friend's opinion on something (e.g.
How do you look like?)
-Identify the color of a dress or any object -Other (Open text) Q12.
What types of questions would you ask to your friends if you were to ask them?
Please select all that apply.-To identify an object -For reading documents or screens or labels -To get a general description of a scene -To get the friend's opinion on something (e.g.
How do you look like?)
-Identify the color of a dress or any object -Other (Open text) Scenarios: Suppose there is an assistive technology where you can seek help from your friends by taking a photo of the object, recording the question and sending it to them.
You can also make video calls to your friends to seek help.
Now we would like to ask you about your comfort levels when using such platforms in various situations.
In particular, we would like to understand how you would like to use such technologies to get help from your friends.Q13.
Suppose you went to a restaurant and were served a can of soda.
You want to know the type of the soda but there is no one around to ask.
If there was an assistive technology where you could ask your friends to identify the soda can by taking a picture of it, how comfortable would you feel asking them for help?
We used a 5-point Likert scale (1: extremely uncomfortable, 5: extremely comfortable) Q14.
Suppose while taking the picture there were some other objects captured along with the soda can.
How comfortable would you feel if the following were present in the photo and visible to your friends along with the soda can?
We used same 5-point Likert scale described in Q13 for each of the following options.
Q15.
Can you please briefly explain your selections above?
(Open text) Q16.
Suppose you are at your workplace and need to take your prescription medicine.
But there are two similarly sized bottles of medicine, and you need to differentiate between them.
You don't want to ask any of your coworkers to identify the bottles for you.
If there was an assistive technology where you could ask your friends to identify the medicine bottles by taking a picture of the medicines, how comfortable would you feel asking them for help?
We used a 5-point Likert scale (1: extremely uncomfortable, 5: extremely comfortable) Q17.
Suppose, while taking the picture of medicine bottles there were some other objects captured along with the medicines.
How comfortable would you feel if the following were present in the photo and visible to your friends along with the medicine bottles?
We used same 5-point Likert scale described in Q16 for each of the following options.
Q18.
Can you please briefly explain your selection above?
(Open text) Q19.
Suppose you are preparing to attend a party and thinking of wearing the new dress/suit you just bought.
Now you want to wear a scarf/tie with it but cannot decide which one will match best.
There is no one around to help.
If there is an assistive technology where you can ask for the opinion of your friends by taking a picture of you wearing the dress/suit and the scarf/tie, how comfortable would you feel asking them for help?
We used a 5-point Likert scale (1: extremely uncomfortable, 5: extremely comfortable) Q20.
Suppose, while taking the picture of the dress/suit and scarf/tie, there were some other objects captured along with the dress.
How comfortable would you feel if the following were present in the photo and visible to your friends along with the dress/suit?
We used same 5-point Likert scale described in Q19 for each of the following options.
