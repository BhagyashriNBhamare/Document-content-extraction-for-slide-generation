We study the degree to which small fluctuations in costs in well-studied potential games can impact the result of natural best-response and improved-response dynamics.
We call this the Price of Uncertainty and study it in a wide variety of potential games (includ-ing fair cost-sharing games, set-cover games, routing games, and job-scheduling games), finding a number of surprising results.
In particular, we show that in certain cases, even extremely small fluctuations can cause these dynamics to spin out of control and move to states of much higher social cost, whereas in other cases these dynamics are much more stable even to large degrees of fluctuation.
We also consider the resilience of these dynamics to a small number of Byzantine players about which no assumptions are made.
We show again a contrast between different games.
In certain cases (e.g., fair cost-sharing, set-covering, job-scheduling) even a single Byzantine player can cause best-response dynamics to transition to states of substantially higher cost, whereas in others (e.g., the class of β-nice games which includes routing, market-sharing and many others) these dynamics are much more resilient.
It is widely accepted that rational agents in competitive environments can be viewed as utility maximizers.
Economic theory has gone to great lengths to justify this assumption, and deriving it from basic plausible axioms.
Major milestones in this line of research include von-Neumann and Morgenstein [23], de Finetti [9] and Savage [19].
In essence, these results connect between agents' preferences, likelihoods of events, and utility functions.
(We should remark that there is a line of work in behavioral economics which challenges this approach, for example the well known works of Kahneman and Tversky [21].)
In this work we explore how small fluctuations or uncertainties about agents' own utilities can substantially affect social welfare when players follow natural dynamics.In many cases we can view the agents' utility functions as being based on measurements of some physical quantities.
For example in job scheduling, the speed of each machine is a physical quantity which determines the load on each machine.
An agent has to approximate this speed from its observation, where the simplest way is to consider the ratio of output quantity and time.
Even if the output quantity is given, different agents might have (slightly) different measurements of time, which will cause them to compute slightly different machine speeds.
Even the same agent might hypothesize different speeds for the same machine at different times, due to imperfection in its clock.
We can model this phenomenon as follows.
We assume that each machine has an absolute speed s, and at each time t each agent i observes a speed s t i ∈ [s/(1 + ǫ), s(1 + ǫ)], for some uncertainty parameter ǫ > 0.
This modeling of uncertainty is reminiscent of the statistical query learning model of Kearns [12].
In other situations, even without uncertainty in measurement, the underlying game itself may exhibit small fluctuations in cost.
For example, consider a transportation problem where each agent selects a route.
We might model edges as having delay functions that are, say, linear in the amount of traffic on them, but in reality delays may also depend on external environmental factors which have been abstracted out of the model.
Therefore delays would not be exactly identical at two different times even if the amount of traffic at those times is the same.
We can again view this similarly: at each time t, resource j has cost c t j ∈ [cj /(1 + ǫ), cj (1 + ǫ)] where cj is the "base" cost of that resource, and ǫ is a degree-of-fluctuation parameter.
In fact, this same issue of fluctuations in actual (in addition to perceived) costs may occur in job scheduling as well.The question we are interested in is: can these fluctuations (in either perceived or actual costs) cause best-response and improvedresponse dynamics to spin out of control and move from highquality states to states of much worse social welfare?
What values of ǫ can different well-studied games tolerate?
We focus on potential games, where such dynamics are especially natural, and define a new measure we call the Price of Uncertainty (PoU), that models the effect these perturbations can cause.
To define the PoU we assume at each step t an agent does a best (or improved) response to the cost function at time t.
The PoU of a given game bounds the ratio of the initial social welfare to the social welfare of any state that can be reached in such a dynamic.
1 A small PoU implies that the system can not deteriorate due to such perturbations in costs, and provides a certain degree of robustness to the system; a large PoU means that deterioration could be severe.
Note that all the games we consider have only a small gap between potential and cost, so without any fluctuations, these dynamics would never cause social welfare to deteriorate substantially.
In addition, all the games we consider have near-optimal equilibria (their price of stability is low), and they continue to do so even after perturbation: thus, the effect we are studying is not that the system moves to a poor state because good equilibria no longer exist, but rather whether small perturbations can lead natural dynamics astray.
Our Results: We analyze a number of well-studied potential games from this perspective, including cost-sharing [2], matroid games [1], job-scheduling [13,8], and the class of β-nice games [3], proving both upper and lower bounds on how resilient they are to such perturbations under both best-response and improved-response dynamics.
Our analysis shows a number of surprising distinctions between these games, as well as between these two dynamics.
In some cases, we show even exponentially small perturbations can result in drastic increases in cost; in others, polynomially-small perturbations are sufficient to ensure good behavior, and finally some are resilient even to constant-sized fluctuations.
For example, in fair cost-sharing games with many players of each type, we show that with best-response dynamics, the Price of Uncertainty is constant even for constant ǫ > 0.
However, with improved-response dynamics, even exponentially small fluctuations can cause an exponentially large increase in the cost of the system.
On the other hand, with few players of each type, the game becomes less resilient, and constant-size fluctuations can cause even best-response dynamics to incur a PoU of Ω(n), where n is the number of players, moving from an equilibrium of cost O(OPT) to one of cost Ω(n · OPT), matching the Price of Anarchy of the game.
For set-covering games, a natural special case of fair cost-sharing studied by [6] where players must choose which set to belong to and split the cost with others making the same choice, we show both best-response and improved-response dynamics have a logarithmic Price of Uncertainty for ǫ = O(1/(mn)).
However, for matroid games (a broad class that generalizes set-covering and many other games), while best-response dynamics continues to exhibit good behavior, improved-response dynamics again has exponentially large PoU even for exponentially small ǫ (exponential in the rank of the matroid).
We also give a technically intricate lower bound of Ω(ǫ √ n/ log(1/ǫ)) on the PoU of best-response dynamics for set-covering games, showing that ǫ < polylog(n)/ √ n is necessary for polylogarithmic PoU.
Finally, for the class of β-nice games, which for constant β includes congestion games with linear (or constant-degree polynomial) latency functions, market-sharing games, and many others [3], we show that for random order bestresponse dynamics, the price of uncertainty is˜Ois˜ is˜O(β).
However, again for improved-response dynamics the PoU can be exponential.
We also present results for job scheduling on unrelated machines and consensus games.
We also explore a different kind of robustness, which is a robustness to adversarial (Byzantine) players.
This can be viewed as a fault-tolerance of the system to a few misbehaved agents.
For our lower bounds, we concentrate on the case of a single adversarial (Byzantine) player, and measure to what degree can such a player can cause the system's social welfare to deteriorate.
We show agent's behavior is the same.
Also, in general we assume that the initial state is arbitrary.
It could be an equilibrium, in which case the PoU can be viewed as studying the stability of the equilibrium.
Alternatively, the initial state might result from a change in the system (adding or removing a link in routing, or adding or removing a machine in job scheduling).
In such a case the agents dynamics start from a more arbitrary state.
that for set cover games, a single Byzantine player can cause bestresponse dynamics to move from an equilibrium of cost O(OPT) to one of cost Ω(n · OPT).
(This is as bad a situation as possible since the Price of Anarchy in such games is O(n).)
For job scheduling on two unrelated machines we show that a single Byzantine player can induce a dynamic where the cost increases from 1 to Ω(n), and that the same is true for consensus games.
For our positive results, we allow any number of Byzantine players.
We show that for job scheduling on identical machines the effect of Byzantine players is very limited.
For β-nice games, under additional assumptions on the impact the Byzantine players can have on the social cost of any given state, and assuming random-order bestresponse dynamics, we can show that at any time t, the expected social cost can not be above 6β · OPT · GAP,where GAP bounds the ratio between potential and cost for the game (e.g., for fair cost sharing games GAP = O(log n)).
Our work can be thought of as asking what kinds of fault-tolerance properties we can guarantee in multi-agent environments.
That is, if the system is currently in a low-cost equilibrium state, when can we expect it to remain so even in the presence of slight perturbations in costs or in the presence of a small number of misbehaving (Byzantine) players.
Our analysis also points out a fragility in standard potential-function arguments in cases where the underlying model is not quite perfect.
Related Work: Recent work on the "Price of Malice" and related notions have also considered the effect that Byzantine players can have in several natural games [4,18,15].
The focus of that work has been on the effect of such players on the quality of the worst Nash or coarse-correlated equilibria.
In contrast, we are interested in the effect of such players on an initial state that may be much better than the worst equilibrium, for a wide class of potential games with a low gap between potential and cost (so that without any perturbations or Byzantine players, behavior would never degrade substantially).
A game is denoted by a tuple G = N, (Si), (costi) where N is a set of n players, Si is the finite action space of player i ∈ N , and costi is the cost function of player i.
The joint action space of the players is S = S1 × . . . × Sn.
For a joint action S ∈ S we denote by S−i the actions of players j 񮽙 = i, i.e., S−i = (s1, ..., si−1, si−1, ..., sn).
Furthermore we denote by S ⊕ s ′ i the state (s1, ..., si−1, s ′ i , si−1, ..., sn).
The cost function of player i maps a joint action S ∈ S to a real non-negative number, i.e., costi : S → R + .
Every game has associated a social cost function cost : S → R that maps a joint action to a real value.
In the cases discussed in this paper the social cost is a simple function of the costs of the players.
In particular, we discuss the sum, i.e., cost(S) = P n i=1 costi(S), and the max, i.e., cost(S) = max n i=1 costi(S).
(In the context of load balancing games we call the maximum social function the makespan social cost function.)
The optimal social cost of a game G is OPT(G) = minS∈S cost(S).
We sometimes overload notation and use OPT for a joint action S that achieves cost OPT(G).
Given a joint action S, the Best Response (BR) of player i is the set of actions BRi(S) that minimizes its cost, given the other players actions S−i, i.e., BRi(S−i) = arg mins∈S i costi (s, S−i).
Given a joint action S, the Improved Response (IR) of player i is the set of actions IRi(S) that have lower cost than its current action, i.e., IRi(S) = {s ∈ Si|costi(s, S−i) ≤ cost(S)}.
A joint action S ∈ S is a pure Nash Equilibrium (NE) if no player i ∈ N can benefit from unilaterally deviating to another action, namely, every player is playing a best response action in S, i.e., si ∈ BRi(S−i) for every i ∈ N .
A best (improved) response dynamics is a process in which at each time step, some player which is not playing a best response switches its action to a best (improved) response action, given the current joint action.
In this paper we will concentrate on games in which any best (improved) response dynamics converges to a pure Nash equilibrium (which are equivalent to the class of ordinal potential games [14,17]).
Throughout the paper we denote by GAP(G, n) the maximum ratio between the cost of a given joint action and the value of the potential function for it, where G is a game of n players.Let N (G) be the set of Nash equilibria of the game G.
The Price of Anarchy (PoA) is defined as the ratio between the maximum cost of a Nash equilibrium and the social optimum, i.e., (max S∈N (G) cost(S))/ OPT(G).
The Price of Stability (PoS) is the ratio between the minimum cost of a Nash equilibrium and the social optimum, i.e., (min S∈N (G) cost(S))/OPT(G).
In this paper we introduce and study the Price of Uncertainty (PoU).
We consider three different variations.
Adversarial Model: Consider a game G, from a given class of games G, where the agents start at some given initial configuration S0 (which might be a Nash equilibrium or not).
Now we progress in phases, where in phase t the following occurs.
First, at time t, the adversary perturbs the costs of G by a small multiplicative factor from their initial values, so that for any S and j we havecost t j (S) ∈ [costj(S)/(1 + ǫ), (1 + ǫ)costj (S)].
2Then the adversary picks an agent i who performs a best (improved) response, and the new configuration is St.Our main concern is to upper bound cost(St)/cost(S0) as a function of ǫ and the class of games G.
More precisely, let us define P oUBR(ǫ, G) = max cost(St)/cost(S0), where the max operator is over the initial configuration S0, the number of time steps t, and a dynamics of t time steps which includes the selection of a player i ∈ N and the selection of its best response at each time step.
For a class of games G, let P oUBR(ǫ, G) be maxG∈G P oUBR(ǫ, G).
We define similarly P oUIR for improved response.
Random Order Model: This model is similar to the adversarial Model, except that at each time step a random agent i ∈ N is selected.
We now care about the expected cost at time t.
We remark that although the player is selected at random, its action is selected as an adversarial best (improved) response to an adversarially selected perturbation of its cost.
In this case we denote the price of uncertainty by P oU R BR .
3 Byzantine Model: In this model, rather than perturbing costs, the adversary instead has control over a small number of Byzantine agents.
At each time step t, the adversary moves the Byzantine agents arbitrarily, and then an agent i ∈ N is selected (either adversarially or at random), who then performs a best-response.
Thus, while in the other models the adversary can perturb all costs by a small amount, in this model the adversary can influence only a few players, but for those players it has full control.
This implies that the adversary can typically influence the costs of only a few resources at a time (those used by the Byzantine players) by an amount that depends on the game and the current joint action of the players.One can view the adversarial model as a directed graph, where the nodes are the possible joint actions.
There is a directed edge from S to S ′ if they differ in the action of only one player i, and the adversary can cause player i to move from its action in S to its action in S ′ : for improved response dynamics, this means perturbing costs so that cost t i (S ′ ) ≤ cost t i (S), and for best response dynamics this means cost t i (S ′ ) is the minimum cost of any state player i can reach unilaterally from S. Given this graph, for each joint action S let V (S) be the set of nodes reachable from it.
The PoU then bounds the ratio between the social cost in S and the maximum social cost of any joint action reachable from S, i.e., maxS max v∈V (S) cost(v)/cost(S).
In this paper we extensively study congestion games and important sub-classes of them.
A congestion game G is defined by a tuple (N, R, (Si), (di)), where N is the set of n players, R is the set of m resources, the action of player i is Si ⊆ 2 R , and the goal of player i is to play a strategy Si that minimizes its individual cost costi.
The cost costi(S) of player i is given by P r∈S i dr (nr(S)), where nr(S) is the number of players sharing resource r in state S and dr : N → N is a delay function associated with resource r. Rosenthal [17] shows that every congestion game possesses at least one Nash equilibrium by considering the potential functionΦ(S) = P r∈R P nr (S) i=1dr(i).
We call a congestion game symmetric if all the players share the same set of strategies, otherwise we call it asymmetric.
Specific classes of congestion games that we study in this work are cost-sharing games, matroid congestion games, β-nice games, and consensus games.
We define all these in their corresponding sections, namely Sections 4.1, 4.2, 5.1 and 4.3.
For games with Φ(S) ≥ cost(S) we define GAP(G, n) as maxS Φ(S)/cost(S).
More generally, for games such that Φ(S) ∈ [c1cost(S), c2cost(S)] we define GAP(G, n) = c2/c1, where we assume c1 ≤ 1 ≤ c2.Another class of games we study are load balancing games (see [16]) which we define in Section 4.4.
We start with a few simple observations regarding the price of uncertainty in general, and for congestion games in particular.
First, note that for ǫ = 0 we get the "standard" best (improved) response dynamics.
In this case the PoU is simply asking by how much can the social welfare deteriorate, assuming that all the players are implementing best (improved) response dynamics (even this can be higher than the PoA, see Theorem 3.1).
Our first observation is that even for ǫ = 0 the P oU is at least the Price of Stability.
This follows since we can start at S0 as the social optimal configuration, and any best response dynamics will reach some equilibrium St.FACT 3.1.
For any ǫ ≥ 0 we have:P oUIR(ǫ, G) ≥ P oUBR(ǫ, G) ≥ P oUBR(0, G) ≥ P oS(G).
For fair cost-sharing games, Fact 3.1 implies an Ω(log n) bound, due to the price of stability results [2].
Second, one should expect the ratio to also depend on the magnitude of ǫ.
For example, for any given game, for sufficiently small ǫ, the perturbations of the adversary would have no real effect, and the agents would simply follow some best (improved) response dynamics from the initial configuration.
More specifically:FACT 3.2.
For any game class G there is an ǫ0 > 0 such that for any ǫ < ǫ0, P oUIR(ǫ, G) = P oUIR(0, G) and P oUBR(ǫ, G) = P oUBR(0, G)Again, for fair cost sharing games, since the social cost of any configuration S is at most a logarithmic factor from the value of the potential function [2], this would give an O(log n) upper bound for ǫ = 0, i.e., P oUIR(0, F CSG) = O(log n).
In exact potential games, an immediate observation is:FACT 3.3.
In any exact potential game after t steps the potential function increases by at most (1 + ǫ) 2t .
Clearly, Fact 3.3 implies that the potential function increases by at most (1 + ǫ) 2L , where L is the number of configurations of players; for congestion games, since players choose subsets of resources, L ≤ 2 mn .
It is interesting to note that there exists G such that P oUBR (0, G) is larger by a multiplicative Ω(log n) factor than P oA(G).
In particular we can show the following.
THEOREM 3.1.
Let G be the class of market-sharing games.
Then P oA(G) = 2 while P oUBR(0, G) = Θ(log n).
PROOF.
The bound on the PoA is from [22].
For the lower bound on PoU, consider players {2, . . . , n} where player i can select between a dedicated site si with benefit 1/i and a shared site s1 with benefit 1.
Initially, each player i uses its dedicated site si, and the social welfare benefit is ln n.
Now let the players perform best response in an increasing order of the indices.
Player i has a benefit of 1/i, and the benefit from moving to s1 is 1/(i − 1), so it prefers to move to s1.
This implies that at the end of the sequence the social welfare benefit is 1.
The upper bound follows immediately from the fact that the gap between potential and cost in this game satisfies GAP = O(log n).
Note that in such cases we are willing to lose the log n factor, and we are interested in for what values of ǫ the value of P oUBR(ǫ, G) is not much larger than P oUBR(0, G).
Finally, we point out a simple relationship between the perturbation and Byzantine models.
Consider a class of games G such that a single player cannot change the cost of any given state S to any player i by more than a factor of α, and whose effect is monotone (for example, for fair cost-sharing, a new player can reduce the cost of a given state S to a player by at most a factor of 2, and in any state it cannot increase the total cost of the other players).
Then, an adversary with ǫ = √ α − 1 can simulate the effect of aByzantine player on best-response (or improved-response) dynamics.
This implies that any lower bound for a single Byzantine player (such as in Theorems 6.2, 6.3 and 6.5) translates to a lower bound on P oUBR( √ α − 1, G).
In this section we present our results in the adversarial model and give upper and lower bound on P oUBR and P oUIR for a number of well-studied classes of games.
We begin by considering set-cover games, a natural type of cost-sharing game studied in [6], showing that both best-response and improved-response dynamics are resilient to polynomially-small fluctuations (Theorem 4.1), but that even for best-response this resilience breaks down for ǫ ≥ p 2/n (Theorem 4.2).
We then consider two generalizations of these games: fair cost sharing in general directed graphs [2], and matroid games [1].
In both cases, we show that even exponentially small fluctuations can cause improved-response dynamics to move to high cost states (Lemma 4.2 and Theorems 4.5 and 4.8); however, best-response dynamics remains resilient to polynomiallysmall fluctuations (Theorems 4.3, 4.4, and 4.7).
We also present results for job-scheduling and consensus games.
In this section we consider fair cost sharing games (FCSG), a class of congestion games defined as follows.
We are given a graph G = (V, E), which can be directed or undirected, where each edge e ∈ E has a nonnegative cost we ≥ 0.
There is a set N = {1, ..., n} of n players, where player i is associated with a source si and a sink ti.
The strategy set of player i is the set Si of si − ti paths.
In an outcome of the game, each player i chooses a single path Pi ∈ Si.
Given an outcome S = (P1, ..., Pn), let ne(S) be the number of agents whose path contains edge e.
In the fair cost sharing game the cost to agent i is costi(S) = P e∈P i we ne (S) and the goal of each agent is to connect its terminals with minimum total cost.
The social cost is defined to be Pe∈∪ i P iwe.
It is well known that the price of anarchy in these games is Θ(n) while the price of stability is H(n) [2], where H(n) = P n i=1 1/i = Θ(log n).
A well known characterization of the potential function [17] of these games [2] is the following.LEMMA 4.1.
In fair cost sharing, for any joint action S ∈ S, we have: cost(S) ≤ Φ(S) ≤ H(n) · cost(S).
Set-cover games (SCG) were considered in [6].
In a set-cover game, there are n players, and m subsets over the players.
The cost associated with set i is wi.
Each player j has to choose one of the sets i that contains him and gets to split the cost of the set with other players who choose the same set.
Set-cover games are a special case of fair cost sharing games.
We begin with an upper bound for improved-response dynamics.
THEOREM 4.1.
In the set covering game, for any ǫ > 0 we have,P oUIR(ǫ, SCG) ≤ (1 + ǫ) 2mn log n. Therefore, for ǫ = O( 1 nm ), we have P oUIR(ǫ, SCG) = O(log n).
PROOF.
Suppose the initial configuration S0 has ki players using set/edge i of cost wi.
Think of this as a stack of ki chips, where we label each chip with the name of its initial set and its position in the stack.
So the bottom chip for set i is labeled (i, 1), then the one above it is labeled (i, 2), and so on.
We will give chip (i, j) a value of wi/j.
So, the sum of values of the chips equals the potential function of the initial configuration, which according to Lemma 4.1 is at most a factor of log n larger than the original cost, i.e, cost(S0) · log n. Now, when a player moves from some set i1 to some set i2, we move the top chip from stack i1 to stack i2.
The claim is that we maintain the invariant that if chip (i, j) is currently at some position j ′ on some stack i ′ , then it must be the case thatw i ′ /j ′ ≤ (wi/j) · (1 + ǫ) 2mn .
This will imply what we want, because it means that we can pay for any new set that gets taken using the bottom chip on its stack.
(We are using here the fact that a chip can only be in one stack.)
The argument for the invariant is that there are at most m · n different positions a given chip can be in (m stacks, n positions per stack) so if you consider the path a chip takes from its initial location to its current location, this path has length at most m · n (you can remove loops in this configuration space).
Since players follow an improved response dynamics, each step in this move causes the ratio of cost of the current stack to position in the stack to increase by at most a factor (1+ǫ) 2 .
So, overall, the total increase is at most a factor of (1+ǫ) 2mn .
So, cost(St) ≤ (1+ǫ) 2mn cost(S0) log n for all t, as desired.We now give a lower bound, showing that for ǫ ≫ log(n)/ √ n, the price of uncertainty can get large even for best-response dynamics.THEOREM 4.2.
In the set covering game we have P oUBR(ǫ, SCG) = Ω( ǫ √ n log( 1/ǫ) ).
The proof builds on a construction in Section 6 giving a lower bound in the presence of a single Byzantine player, but adding in an extra "gadget" of Θ( √ n/ǫ+1/ǫ 2 ) players that allows the adversary to simulate the effect of a Byzantine player even via quite small fluctuations.
The construction in this lower bound is fairly intricate so we defer the proof to Appendix A.
We now consider fair cost sharing games in general directed graphs.
We show here that so long as the number of players ni of each type (i.e., associated to each (si, ti) pair) is large, then the game is stable even for large values of ǫ under best-response dynamics.
Specifically, so long as ni = Ω(m) for all i, we have a constant price of uncertainty.
On the other hand, for improvedresponse dynamics, then costs can grow exponentially even for exponentially small values of ǫ, even for the symmetric (single source, single sink) case.
P oUBR(ǫ, F CSG) ≤ " 1 + (1+ǫ) 2 n min " m , where nmin = mini ni.This implies that for nmin = Ω(m), we have P oUBR(ǫ, F CSG) = O(1).
PROOF.
Call an edge "marked" if it is ever used throughout the best-response process, including those used in the initial state S0, and let c * be the total cost of all marked edges.
So, c * is an upper bound on the cost of the current state.
Any time a best-response path for some (si, ti) pair uses an unmarked edge, the total cost of the unmarked edges used is at most(c * /ni) · (1 + ǫ) 2 , because (c * /ni)(1 + ǫ)is an upper bound on the perturbed average cost of players of type (si, ti) and therefore is an upper-bound on the perturbed cost of the best-response path for any such player.
This in turn is within a (1 + ǫ) factor of the actual cost of this path.
Thus, c * increases by at most a multiplicative (1 + (1 + ǫ) 2 /ni) factor.
We can mark new edges at most m times, so the final cost is at most cost(S0)(1 + (1 + ǫ) 2 /nmin) m , where nmin = mini ni.
This implies that as long as nmin = Ω(m) we have cost(St) = O(cost(S0)), for all t, as desired.For symmetric fair cost sharing games (SCFCSG) we can get a low price of uncertainty even when the number of players is much smaller than the number of edges, i.e., n ≪ m. THEOREM 4.4.
For symmetric fair cost sharing games, where the edge costs are in the range [wmin, wmax], we have P oUBR(ǫ, SF CSG) = O(log n), for ǫ < w min 4wmax 1 mn(n−1) log n .
PROOF.
We start with some notation.
We say that at time t, the best-response player jt moves from path Pt to path P ′ t , creating state St. We will say that a time t is "interesting" if Pt+1 񮽙 = P ′ t : that is, if the next player moves from a path different from the one the current player moved to.
Let us index the interesting times as t1, t2, . . ..
The argument now proceeds in two steps: we first show an upper bound on the number of interesting time steps ofU = O( 1 α log n) for α = w min 8wmax 1 n(n−1)m.
We then prove that the potential of the final state ST satisfies Φ(ST ) ≤ (1 + ǫ) 2U Φ(S0).
Using the fact that ǫ < w min 4wmax 1 mn(n−1) log n and the O(log n) gap between potential and cost in these games, we get the desired result.Let R k denote the true (unperturbed) cost of the path P ′ t k at time t k ; that is, R k = costj t k (St k ).
We now claim thatR k ≤ " R k−1 − wmin n(n − 1) « (1 + ǫ) 2 .
(4.1)Specifically, note that because P ′ .
In particular, w min n(n−1) is a lower bound on the savings produced by having one more player on the edges in which P ′ t k−1 and Pt k−1 +1 differ (which implies the desired statement for t k = t k−1 +1) and each player jt k−1 +2, . . . , jt k could have moved to path Pt k−1 +1 reverting the system to state St k−1 (which extends the statement to the case t k > t k−1 + 1).
Therefore, since player jt k is performing best response to the perturbed costs, the true costR k of P ′ t kis at most a factor (1 + ǫ) 2 larger than R k−1 − w min n(n−1) .
For our given values of α and ǫ, and using the fact that R k−1 ≤ wmax · m, inequality (4.1) implies that R k ≤ R k−1 (1 − α).
Since R1 ≤ OPT(1 + ǫ) 2 and by definition of OPT it must be that Rt ≥ OPT/n, we get that the number of interesting time steps is at most U = O( 1 α log n).
We now bound the potential in terms of the number of interesting time steps.
Specifically, note that player jt k could have moved to path Pt k−1 +1, which would revert the system to state St k−1 becauseP ′ t k−1 +1 = Pt k−1 +2, . . . , P ′ t k −1 = Pt k .
Becauseplayer jt k chose path P ′ t k instead, which was best-response to the perturbed costs, this means Φ(St k ) ≤ Φ(St k−1 )(1 + ǫ) 2 .
Therefore, the fi- nal state ST satisfies Φ(ST ) ≤ Φ(S0)(1 + ǫ) 2U , completing the argument.Improved response The above results give upper bounds for best response in fair cost sharing games.
In contrast, we now show that for improved-response dynamics, the price of uncertainty is exponentially large even for exponentially-small values of ǫ, even for symmetric fair cost sharing games.
LEMMA 4.2.
For symmetric fair cost sharing, for a single player (i.e., n = 1), the price of uncertainty for improved-response dynamics satisfies P oUIR(ǫ, SF CSG) ≥ 1 + 2(2 m/2 − 1)ǫ/m.
PROOF.
The graph consists of a line of parallel edges arranged as follows.
We have two parallel edges from s = v0 to vertex v1 of cost 1 and 1 + ǫ respectively, then two parallel edges from v1 to vertex v2 of costs 1 and 1 + 2ǫ, then two parallel edges from v2 to v3 of costs 1 and 1 + 4ǫ, and in general from vi to vi+1 of costs 1 and 1 + 2 i ǫ.
Finally we let sink t = v m/2 so we have a total of m edges.
The player begins on the cheapest path, of cost m/2.
We can describe a path from s to t by a binary number b = b m/2−1 . . . b2b1b0, where bit bi = 0 if the path uses the edge of cost 1 from vi to vi+1 and bi = 1 if the path instead uses the edge of cost 1 + 2 i ǫ.
Thus, path b has cost exactly m/2 + bǫ, and the player begins at path 0.
We now claim that using a series of perturbations and improvedresponse moves, one can cause the player to repeatedly increment, moving from path b to path b + 1 until the player finally reaches path 2 m/2 − 1, achieving the desired bound.
Specifically, since the difference in true cost between path b + 1 and path b is exactly ǫ, it is sufficient to choose some arbitrary edge in path b that is not in path b + 1 and increase its cost by a multiplicative factor 1 + ǫ to cause b + 1 to be an improvement over b (and we can similarly decrease the cost of an edge in b + 1 that is not in b to make it a strict improvement).
The generalization for multiple players is straightforward.
THEOREM 4.5.
For symmetric for cost sharing, for any number of players n, the price of uncertainty for improved-response dynamics satisfies P oUIR(ǫ, SF CSG) ≥ 1 + 2(2 m/2 − 1)ǫ/m.
We can use Lemma 4.2 to imply a bound also for routing games [16] with linear (or even constant) latency functions, since for the case of a single player these games are identical.
THEOREM 4.6.
For routing with linear latency functions, the price of uncertainty for improved-response dynamics satisfies P oUIR(ǫ, ROU T IN G) ≥ 1 + 2(2 m/2 − 1)ǫ/m.
We now analyze matroid congestion games, a broad class of games considered in [1].
Before we give a formal definition of such games, we briefly introduce a few standard facts about matroids; for a detailed discussion, we refer the reader to [20].
DEFINITION 4.1.
A tuple M := (R, I) is a matroid if R is a finite set of resources and I is a nonempty family of subsets of R such that if I ∈ I and J ⊆ I, then J ∈ I, and if I, J ∈ I and |J| ≤ |I|, then there exists an i ∈ I such that J ∪ {i} ∈ I.Let M := (R, I) be a matroid.
Let I ⊂ R; if I ∈ I then we call I independent, otherwise we call it dependent.
It is well known that all maximal independent sets of I have the same size, which is denoted by the rank rk(M ) of the matroid.
A maximal independent set of M is called a basis of M .
It is well known that such a basis can be found by a greedy algorithm.
In the following we state two additional useful properties of the matroids.
We denote by B the set of bases of a matroid, and assume that B1, B2 ∈ B.LEMMA 4.3.
Let r2 ∈ B2 \ B1, then there exists r1 ∈ B1 \ B2 such that B1 ∪ {r2} \ {r1} ∈ B.We denote by G(B1 △ B2) the bipartite graph (V, E) with V = (B1 \ B2) ∪ (B2 \ B1) and E = {{r1, r2}|r1 ∈ B1 \ B2, r2 ∈ B2 \ B1, B1 ∪ {r2} \ {r1} ∈ B}.
Then it is known that [20].
We are now ready to define matroid congestion games.
A congestion game is a matroid congestion game if for every player i ∈ N we have that Mi := (R, Ii) with Ii = {I ⊆ S|S ∈ Si} is a matroid and Si is the set of bases of Mi.
We denote by rk(M ) = maxi∈N rk(Mi) the rank of the matroid congestion game M .
For example, set-cover games are matroid games of rank 1 and marketsharing games with uniform costs are matroid games [11] (though even symmetric fair cost sharing need not be a matroid game).
We now show that for best-response dynamics, matroid games have similar resilience to fluctuations as set-cover games; however, for improved response we give an exponential lower bound.
THEOREM 4.7.
In a matroid game, P oUBR(ǫ, M atroid) ≤ (1 +ǫ) 2mn GAP(M atroid, n).
This implies that for ǫ = O(1/(n· m)), we have P oUBR(ǫ, M atroid) = O(GAP(M atroid, n)).
PROOF.
The proof proceeds as in Theorem 4.1.
However, we initially have P i∈N rk(Mi) ≤ n · rk(M ) chips and the cost(S0) is within a GAP(M atroid, n) factor from the sum of the values of the chips.Let S be a state of the matroid congestion game M and let s * i be a best response of player i to S according to the perturbed cost˜drcost˜ cost˜dr.
Consider the bipartite graph G(s * i △ si) which contains a perfect matching PM according to Lemma 4.4.
Let S * = S ⊕ s * i , and observe that for every edge (r, r * ) ∈ PM with r * ∈ s * i \ si and r ∈ si \ s * i , ˜ dr * (nr * (S * )) ≤ ˜ dr (nr(S * ) + 1) ≤ ˜ dr (nr(S)) since otherwise s * i is not a best response of player i with respect tõtõ dr.When a player does a best response we now move rk(G) chips (corresponding to at most rk(G) resources), and each movement sets up an inequality of the typed i ′ (j ′ ) ≤ di(j) · (1 + ǫ) 2 .
The claim is that we maintain the invariant that if chip (i, j) is currently at some position j ′ on some stack i ′ , then it must be the case thatd i ′ (j ′ ) ≤ di(j) · (1 + ǫ) 2mn .
The argument is the same as in Theorem 4.1: there are at most m·n different positions a given chip can be in (m stacks, n positions per stack) so if you look at the path a chip takes from its initial location to its current location, this path has length at most m·n (you can remove loops in this configuration space).
4 So, for all t we have Φ(St) ≤ (1 + ǫ) 2mn Φ(S0), which implies cost(St) ≤ (1 + ǫ) 2mn cost(S0) · GAP(M atroid, n), which completes the proof.Note: As opposed to the set-covering result (Theorem 4.1), this result holds for best response dynamics only.
We can in fact show that improved response is not sufficient in these games, even if ǫ is exponentially small in the rank of the matroid.
In particular, even though symmetric cost-sharing is not a matroid game, the proof of Lemma 4.2 applies equally well to improved-response dynamics if we replace the graph structure with a uniform matroid having m resources and with rank r = m/2.
We therefore have the following: THEOREM 4.8.
There exists a matroid game of rank r = m/2 such that the price of uncertainty for improved-response dynamics satisfies P oUIR(ǫ, M atroid) ≥ 1 + 2(2 m/2 − 1)ǫ/m.
Consensus games [7] are played by users viewed as vertices in a connected, undirected simple graph G = (N, E) with n vertices, where N = {1, ..., n}.
Each player i has two actions r or b, i.e., Si = {r, b}.
A player has cost 1 for each incident edge on which he disagrees with his neighbor.
costi(S) = P (i,j)∈E I (s i 񮽙 =s j ) .
The overall social cost is the sum of the costs of all the users, plus 1, i.e., cost(S) = 1+ P i∈N costi(S).
It is straightforward to show that these games are congestion games [14] and that the potential function can be rewritten as be Φ(S) = (cost(S) − 1)/2.
The two social optimum solutions in a consensus game are "all blue" and "all red", both of which are also a Nash equilibrium (so the Price of Stability is 1).
On the other hand, there are Nash equilibria with cost Ω(n 2 ).
The above describes unweighted consensus games; in weightedconsensus, the edges have non-negative weights and the cost to a player is the total weight of edges on which it disagrees with its neighbors.
In our model, we can show the following (for proofs, see the full version [5]): THEOREM 4.9.
For any unweighted consensus game (UCG), for any ǫ, we have P oUBR(ǫ, U CG) ≥ (n−1)ǫ+1 .
For ǫ > √ 2−1 we can show P oUBR(ǫ, U CG) = Ω(n 2 ).
For a weighted consensus game we can show an exponential lower bound.
THEOREM 4.10.
For any weighted consensus game (WCG), for any ǫ, we have P oUBR(ǫ, W CG) ≥ (1 + ǫ) n .
In this section we consider job scheduling on unrelated machines (JSUM) (see [16]) defined by (N, M, c) as follows.
The set N is a set of n jobs, and M is the set of m machines.
Each player is associated with a job, so have n players.
Every job can impose a load on one of the machines, so for every player j its set of feasible actions is to assign job j to some machine i ∈ M .
Each job j ∈ N has associated a cost ci,j for running on machine i ∈ M .
Given an assignment of jobs to machines, the load of machine i is the sum of the costs of the jobs that are assigned to that machine, i.e., Li(S) = P j∈B i (S) ci,j where Bi(S) is the set of jobs assigned to machine i, i.e., Bi(S) = {j : Sj = i}.
The cost of a player j is the load on the machine that player j selected, i.e., costj(s) = Ls j (S).
For the social cost we use the makespan, which is the load on the most loaded machine, i.e., cost(S) = maxi Li(S).
The price of stability in these games is 1, since there is always a pure Nash equilibrium which is also socially optimal [10].
The Price of Uncertainty in these games can be exponentially large, even for two machines, when ǫ is large compared to 1/n.
(For proofs, see the full version [5]): THEOREM 4.11.
For job scheduling on unrelated machines, for M = 2 machines and any ǫ > 2/n, we have P oUBR(ǫ, JSU M )≥ (1 + ǫ) n/2 ˆ 1 − 2 ǫñ ǫñ + 2 ǫn = Ω((1 + ǫ) n/2 ).
For job scheduling on identical machines (JSIM) we have a simple upper bound, even for large perturbations.
We now consider the effect of perturbations on random order best-response dynamics (for improved-response dynamics, random and adversarial order are equivalent since the adversary can simply choose not to cause a player to move).
Our main result is that for the broad class of β-nice games introduced by [3], which for constant β includes congestion games with linear (or constant-degree polynomial) latency functions, market-sharing games, and many others, these dynamics are resilient to fluctuations even for constant ǫ > 0.
On the other hand, we give lower bounds showing that job-scheduling and consensus games can still behave poorly.
Let us consider an exact potential game.
Let S be a profile of the players and let S i denote the configuration produced by a bestresponse move by player i according to costi.
For each player i define ∆i(S) = costi(S) − costi(S i ) and ∆(S) = P i ∆i(S).
DEFINITION 5.1.
An exact potential game with a potential function Φ is β −nice iff for any state S we have cost(S) ≤ βOPT+ 2∆(S).
As shown in [3] number of important games are β-nice, for β equal to the price of anarchy of the game.Here we show that β-nice games additionally have the property that the expected price of uncertainty in the random order model is only O(β · GAP) even for constant ǫ > 0.
We start by showing that if the true (unperturbed) cost of the current configuration S is greater than 2β · OPT, then no matter how the adversary adjusts the costs, the expected drop in potential is at least cost(S)(1/4 − 4ǫ)/n. For ǫ < 1/16, this is Ω(cost(S)/n).
That is, the adversary may make the cost exceed 2βcost(S0) but only temporarily.
5 LEMMA 5.1.
For ǫ < 1/32, if cost(St) ≥ 2βOPT then E[Φ(St+1) − Φ(St)] ≤ −cost(St)/(8n).
PROOF.
As above, let S i denote the configuration produced by a best-response move by player i according to costi, and let˜Slet˜ let˜S i denote the configuration produced by a best-response move by player i according to the perturbed cost function cost t i .
So, costi(S i ) ≤ costi( ˜ S i ) and cost t i ( ˜ S i ) ≤ cost t i (S i ).
Recall that ∆i(S) = costi(S) − costi(S i ) and ∆(S) = P i ∆i(S).
We will also need the following two quantities: 5 This implies that with high probability the cost will drop to below 2βOPT within a polynomial number of steps.1.
˜ ∆i(S) = cost t i (S) − cost t i ( ˜ S i )is the improvement in perturbed cost of player i due to a best-response by player i in the perturbed game, with˜∆with˜ with˜∆(S) = P i ˜ ∆i(S), and 2.
ˆ ∆i(S) = costi(S) − costi( ˜ S i ) is the improvement in unperturbed cost of player i due to a best-response by player i in the perturbed game, withˆ∆withˆ withˆ∆(S) = P i ˆ ∆i(S).
Now, suppose cost(S) > 2βOPT.
Then by definition of β-nice we have ∆(S) > cost(S)/4.
Now we want to use this to show thatˆ∆thatˆ thatˆ∆(S) must be large as well.
Specifically, for each i, since the improvement in perturbed cost of the best-response to the perturbed game is at least the improvement in perturbed costs of the best response to the unperturbed game, we have:˜ ∆i(S) ≥ cost t i (S) − cost t i (S i ) ≥ (1 − ǫ)costi(S) − (1 + ǫ)costi(S i ) ≥ ∆i(S) − 2ǫcosti(S).
(5.2)Now, summing over all i we have:˜ ∆(S) ≥ ∆(S) − 2ǫcost(S) ≥ cost(S)(1/4 − 2ǫ).
This means that when a random player moves to his "best perturbed response", we haveEi[ ˜ ∆i(S)] ≥ cost(S)[1/4 − 2ǫ]/n.Now, by a similar argument to that equation (5.2) we have:ˆ ∆i(S) = costi(S) − costi( ˜ S i ) ≥ cost t i (S) − ǫcosti(S) − cost t i ( ˜ S i ) − ǫcosti( ˜ S i ) = ˜ ∆i(S) − 2ǫcosti(S) + ǫ ˆ ∆i(S).
So, ˆ ∆i(S) ≥ ( ˜ ∆i(S)−2ǫcosti(S))/(1−ǫ).
Putting this together with the above and using the fact that Ei[costi(S)] = cost(S)/n gives usEi[ ˆ ∆i(S)] ≥ cost(S)[1/4 − 4ǫ]/nwhich is the expected drop in the potential Φ for the unperturbed game caused by a random best-response move in the perturbed game.
If ǫ < 1/32, we then get the desired result.So, Lemma 5.1 shows if the true (unperturbed) cost of current configuration S is greater than 2β · OPT, then no matter how the adversary adjusts the costs, the expected drop in potential is at least cost(S)(1/4 − 4ǫ)/n.
A Chernoff bound argument can then be used to say that with high probability the sum of drops in potential will be close to their expectation.
Note that we do not show that once cost is low it will necessarily stay there forever -just that if the adversary is ever able to make the cost go above 2βOPT then with high probability it will have to drop back below it in a small number of steps.In the following we show a bound on the expectation that holds for all time steps.
To do so, we use the following additional lemma:LEMMA 5.2.
For any value of cost(St), E[Φ(St+1) − Φ(St)] ≤ 2ǫcost(S)/(n(1 − ǫ)).
PROOF.
This just follows from the statement thatˆ∆ithatˆ thatˆ∆i(S) ≥ ( ˜ ∆i(S) − 2ǫcosti(S))/(1 − ǫ), and using the fact that˜∆ithat˜ that˜∆i(S) is always non-negative.
Assume ǫ < 1/32.
We can now use these lemmas to prove that for β-nice games the expected price of uncertainty in the random order model is only O(β · GAP) even for constant ǫ > 0.
Recall that we define GAP = c2/c1 where c1 ≤ 1 ≤ c2 are values such that for any state S we have Φ(S) ∈ [c1cost(S), c2cost(S)].
THEOREM 5.1.
For any t > 0, we have )].
This will be sufficient because Lemma 5.2 implies that the expectation can never increase by too much.
In particular, even if E[cost(St)] ≤ 4βOPT, by Lemma 5.2 we still haveE[Φ(St)] ≤ max[5c2βOPT, c2cost(S0)] ≤ 5c2βcost(S0).
Therefore, E[cost(St)] ≤ 5βcost(S0) · GAP.
PROOF.
We will show that if E[cost(St)] ≥ 4βOPT then E[Φ(St+1)] ≤ E[Φ(StE[Φ(St+1)] − E[Φ(St)] ≤ 4ǫβOPT/(n(1 − ǫ)) < βOPT ≤ c2βOPT.Specifically, suppose E[cost(St)] ≥ 4βOPT.
Let pt be the probability that cost(St) ≥ 2βOPT.
Therefore, we have:E[cost(St)] = ptE[cost(St)|cost(St) ≥ 2βOPT] +(1 − pt)E[cost(St)|cost(St) ≤ 2βOPT] ≤ ptE[cost(St)|cost(St) ≥ 2βOPT] + 2βOPT, so we have E[cost(St)|cost(St) ≥ 2βOPT] ≥ 2βOPT/pt.
Now, using Lemmas 5.1 and 5.2, we can write:E[Φ(St+1) − Φ(St)] ≤ " − pt 8n " E[cost(St)|cost(St) ≥ 2βOPT] + 2ǫ(1 − pt) n(1 − ǫ) E[cost(St)|cost(St) < 2βOPT] ≤ 2βOPT/(−8n) + 2βOPT 2ǫ n(1 − ǫ) ≤ 0.
Thus, as desired, if E[cost(St)] ≥ 4βOPT then E[Φ(St+1)] ≤ E[Φ(St)], proving the claim.As shown in [3], a number of common games are β-nice for constant β, including congestion games with linear latency functions, both unweighted (β = 2.5) and weighted (β ≈ 2.618), congestion games with polynomial latency functions of constant degree d (β = d d(1−o(1)) ), and market-sharing games (β = 2).
Note: Interestingly, the guarantee in Lemma 5.1 breaks down in the adversarial-order setting: for example, for market-sharing games, which are β-nice for β = 2, we have price of uncertainty Ω(log n) even for ǫ = 0, as shown in Theorem 3.1.
For job scheduling we can show (see full version [5] for proofs):THEOREM 5.2.
For M = 2 machines, for any ǫ > 2/n, we have that P oU R BR (ǫ, JSU M ) ≥ ǫn/8.
We can similarly adapt our lower bounds for consensus games to the random order model.
For a weighted consensus game we can show an exponential lower bound.
THEOREM 5.3.
For any weighted consensus game (WCG), for any ǫ, we have P oU R BR (ǫ, W CG) ≥ (1 + ǫ) n/2−1 .
We now consider the case that, rather than perturbing weights, the adversary instead controls a certain number of Byzantine players who can move arbitrarily between best-response moves by the ordinary (non-Byzantine) players.
Our main results in this model are an upper bound for β-nice games, showing that random-order best-response dynamics is resilient to Byzantine players, and a lower bound for set-covering games, showing that in these games an adversary can increase the cost of the normal players by a factor of Ω(n) even with just one Byzantine player.
We also give results for job-scheduling and consensus games as well.
Earlier, we showed that β-nice games are resilient to cost perturbations in the random order model.
Here we show they are also resilient to the addition of Byzantine players.
For this, we make two additional reasonable assumptions about the game and the number of Byzantine players: Assumption 1 (monotonicity): We assume that adding new players into the game can only increase the cost incurred by any given player (e.g., as in linear congestion games).
Assumption 2 (low direct impact of Byzantine players): configuration S, the social cost of S with Byzantine players removed is at least 7/8 of the social cost of S with Byzantine players included.
In other words, the Byzantine players cannot change the cost of any given state by more than a small constant factor.We will consider random best-response dynamics.
Recall that in this model, Byzantine players may move arbitrarily between two moves of the normal (non-Byzantine) players.
The key to the analysis is that we will track the cost and potential of the configuration minus the Byzantine players, viewing the Byzantine players as merely perturbations to the perceived costs of the normal players, causing them to act in an unusual way.
We then will follow the main steps of the analysis of β-nice games in Section 5.1.
However, note that now the Byzantine players can affect the perceived cost of any given normal player substantially, even though by Assumption 2 they cannot change the aggregate cost by too much.Specifically, let players 1, . . . , n be the normal players, and we will index the Byzantine players as n + 1, . . . , n + k. Given a configuration S at time t, define cost(S) to be the social cost of S with Byzantine players removed, and define cost t (S) to be the social cost of S with Byzantine players included.
Similarly, define costi(S) and cost t i (S) to be the cost incurred by player i with Byzantine players removed or included, respectively.
So, cost(S) = P n i=1 costi(S) and cost t (S) = P n+k i=1 cost t i (S).
Also, by Assumptions 1 and 2 we have cost t (S) ≥ cost(S) ≥ 7 8 cost t (S).
Define the potential Φ(S) to be the standard potential function for configuration S but with Byzantine players removed, and let St denote the state at time t (counting each move of a non-Byzantine player as one time step).
We now prove the following lemma.LEMMA 6.1.
If cost t (St) ≥ 2βOPT then we have E[Φ(St+1) − Φ(St)] ≤ −cost t (St)/(8n).
PROOF.
Given configuration S, let S i denote the configuration resulting from player i performing best-response to the perceived costs (i.e., with Byzantine players included).
Letˆ∆Letˆ Letˆ∆ = P n i=1 [costi(S) − costi(S i )].
In other words, ˆ ∆/n is the expected drop in the potential Φ caused by a random non-Byzantine player performing best-response to the costs with Byzantine players included.Let˜∆Letˆ Letˆ∆ = P n i=1 [costi(S) − costi(S i )].
This is a somewhat strange quantity since the Byzantine players are not actually performing best response.
Nonetheless, by the definition of β-nice, if cost t (S) ≥ 2βOPT then we have˜∆have˜ have˜∆(S) ≥ cost t (S)/4.
This impliesP n+k i=1 cost t i (S i ) ≤ 3 4cost t (S), and therefore surelyP n i=1 cost t i (S i ) ≤ 3 4 cost t (S)as well.
Putting this together, we now have:ˆ ∆(S) = cost(S) − n X i=1 costi(S i ) ≥ cost(S) − n X i=1 cost t i (S i ) ≥ cost(S) − 3 4 cost t (S) ≥ 7 8 cost t (S) − 3 4 cost t (S) ≥ cost t (S)/8,where the first inequality follows by monotonicity and the second to last follows by Assumption 2.
Sincê ∆/n is the expected drop in Φ, this concludes the proof.To analyze the expected costs, we now need an analog of Lemma 5.2, showing that even if cost t (St) is low, the expected value of the potential will not increase too quickly.LEMMA 6.2.
For any value of cost t (St), we have E[Φ(St+1)− Φ(St)] ≤ cost t (St)/(8n).
PROOF.
Let S = St. Using the notation from the proof of Lemma 6.1 we havêhavê ∆(S) = cost(S) − n X i=1 costi(S i ) ≥ 7 8 cost t (S) − n X i=1 costi(S i ) ≥ 7 8 cost t (S) − n+k X i=1 cost t i (S i ) = ˜ ∆(S) − 1 8 cost t (S).
This is at least − 1 8 cost t (S) as desired.Putting these together we can now show the following analog of Theorem 5.1, for β-nice games satisfying Assumptions 1 and 2.
THEOREM 6.1.
For any t > 0, E[Φ(St)] ≤ max[6βOPT, cost(S0)] ≤ 6βcost(S0).
Finally, note that if there is a bounded value GAP = maxS [cost t (S)/Φ(S)] then the above result implies that for all t > 0, E[cost t (St)] ≤ max[6βOPT, cost t (S0)] · GAP.
We now consider set-cover games and give a construction showing that just one Byzantine player can cause best-response dynamics to move from an equilibrium of cost O(OPT) to an equilibrium of cost Ω(n · OPT).
Note that this is the largest gap possible since the Price of Anarchy for this game is n. THEOREM 6.2.
For set-cover games, a single Byzantine player can cause best-response dynamics to move from a Nash equilibrium of cost O(n) to a Nash equilibrium of cost Ω(n 2 ).
PROOF.
Consider n players of type I, where each player i has two sets to choose from: a common set s * of cost n, and a set si of cost n − 1.
There are additionally n − 2 players of type II, such that player k of type II may either choose any of the sets si or else its own set f k of cost n/k, for k ∈ {2, . . . , n − 1}.
In addition, we have one Byzantine player who may choose any of the sets, for a total of 2n − 1 players total.
The initial state is all players of type I in set s * and all players of type II in set s1, for a total cost O(n).
The Byzantine player and type-II players will now slowly lure all type-I players into the sets si, increasing the cost of the system to n(n − 1).
First the Byzantine player moves to set s1 causing player 1 of type I to move from s * (whose cost to the player is 1) to s1 (whose cost to the player is (n − 1)/n).
The Byzantine player then sequentially moves to each set fn−1, fn−2, . . . , f2, causing the players of type II to move to their sets f k in that order.
Specifically, at the time player k of type II moves, the set s1 has a cost to it of (n − 1)/k, whereas set f k has cost (with the Byzantine player) of n/(2k).
Now the Byzantine player moves to set s2, causing the players k of type II for k = 2, 3, . . . , n − 2 to move one after the other to s2 as well.
Specifically, at the time player k moves, set s2 has cost (n − 1)/k which is lower than the cost n/k of f k .
At the end of this step we have the same configuration of type-II players as in the initial state, except with s2 rather than s1.
The entire process then repeats for player 2 of type I, and so on, until each player i of type I is on its own set si.
Finally, since s * is now empty, none of the type-I players wish to move so we are at an equilibrium.As pointed out in Section 3, Theorem 6.2 immediately implies that in the perturbation model we have P oUBR( √ 2 − 1, SCG) = Ω(n).
Note that in Theorem 4.2 we extend this construction to the more delicate case of small values of ǫ as low as p 2/n.
We begin with a simple lower bound for job scheduling in the presence of a single Byzantine job.
THEOREM 6.3.
For two machines and one Byzantine job, the cost can increase from 2 to Ω(n), even in the random-order model.
PROOF.
Consider two machines and 2n + 1 good jobs, n of type I with cost (1/n, 1) and n of type II with cost (1, 1/n), and one Byzantine job with cost (1, 1).
Initially, jobs of type I are on machine 1 and jobs of type 2 are on machine 2, this is the optimal assignment for the good jobs.
The Byzantine job goes to machine 1, then a job of type I moves to machine 2, since this is its best response.
Now, the Byzantine job moves to machine 2 (note that the Byzantine job increased its load).
Then, a job of type II moves from 2 to 1.
This way we increase the cost from 2 to n + 1.
As in Theorem 5.2, this construction extends immediately to the random order model, with just a constant factor loss in the ratio, by analyzing the Markov chain produced as a result of the above adversary strategy.
Specifically, so long as the system has more jobs with cost 1/n on their current machine than jobs with cost 1 on their current machine, the system is more likely to transition in the forward direction (increasing the number of high-cost jobs) than in the reverse direction.
Thus, in O(n) steps, with high probability the system reaches a state of cost Ω(n).
On the other hand, for job scheduling on identical machines, unless the Byzantine players by themselves have substantial weight, they cannot cause the system to reach a high-cost state.
PROOF.
Let W b be the weight of the Byzantine players and Wg the weight of the good players.
Each time a good player i moves it has a best response whose cost is at most (Wg + W b )/m + wi, where wi is the good job cost.
Note that OP T ≥ max{W/m, wi} and thus the result follows.We end with a simple observation that for unweighted consensus, a single Byzantine player can cause cost to increase by a factor Ω(n).
THEOREM 6.5.
For the unweighted consensus game, a single Byzantine player can increase cost from 1 to Ω(n).
PROOF.
The network is simply a line network v1, . . . , vn.
The Byzantine player is the player v1 at one end of the line.
Assume we start with all players being R and then the Byzantine player switches to B. Player v2 is indifferent between R and B so it switches to B, and then player v1 switches back to R. Then, player v3 switches to B, player v2 switches to R and player v1 switches to B.
In phase k, we start with v1, . . . , v k alternating between R and B, such that v k plays B.
During phase k, first v k+1 switches to B, and then players v k , . . . v1 switch their action.
At the end we have all players alternating between R and B, at cost Ω(n).
In terms of specific open questions, it would be interesting to close some of the gaps that remain in the adversarial order model.
For example, can one extend the upper bound of Theorem 4.4 to non-symmetric cost-sharing games or extend the lower bound of Theorem 4.2 to symmetric cost sharing games?
In the Byzantine model, can one get better upper-bounds for set-cover and fair costsharing games if we assume random order dynamics?
More generally, for all the classes of games studied, can one get better upper bounds in the random order model in the case where the perturbations are not completely adversarial, but instead chosen from some distribution of bounded magnitude?
APPENDIX A. SET COVERING GAMES Theorem 4.2 In the set covering game we have P oUBR(ǫ, SCG) = Ω( ǫ √ n log(1/ǫ) ) for ǫ ≥ 2/ √ n.PROOF.
The construction 6 builds on that in the proof of Theorem 6.2.
Let N = n/4.
Consider N players of Type I, indexed by pairs (i, j) for 1 ≤ i, j ≤ √ n. Type-I player (i, j) has three sets to choose from: a set s * i of cost N , a set sactive,j of cost N , and a private set si,j of cost N .
Initially, all Type-I players begin on the sets s * i for a total cost of N √ N .
We also have N + √ N − 2 players of Type II as follows.
For k = 3, . . . , N , we have a Type-II player who may choose any of the sets sactive,j (for 1 ≤ j ≤ √ N ) or else its own set f k .
For k = 2 we have √ N Type-II players indexed by pairs (2, j) for 1 ≤ j ≤ √ N who may choose only the set sactive,j or their own set f2,j .
The sets f k and f k,j have costs as follows: for k ∈ [2, 1/ǫ], the set has cost 1 ǫ N/k; for k > 1/ǫ, the set has cost N/k.
However, for k ∈ [2, 1/ǫ], we have 1/ǫ − 1 "helper" players in set f k (or set f k,j ) whose alternative options will be described in more detail below.
Thus, with helper-players included, cost of each set f k (or f k,j ) to type-II player k (or (k, j)) is N/k.
The Type-II players begin in their sets f k (or f k,j ).
As in the proof of Theorem 6.2, the Type-II players will now slowly lure all Type-I players into the private sets si,j, increasing their overall cost from N √ N to N 2 .
Specifically, for i = 1, 2, . . . , √ N , the following occurs.
First, for each j = 1, 2, . . . , √ N in sequence, Type-I player (i, j) is lured onto sactive,j as follows.
First, Type-II player (2, j) is moved to set sactive,j by having its helper-players temporarily raise the effective cost of f2,j from N/2 to N (using a process described in the paragraph below) so that the adversary can cause it to move to sactive,j with an arbitrarily small additional perturbation.
Next, Type-II players k = 3, 4, . . . are made to follow along to sactive,j.
In the case of k = 3, . . . , 1/ǫ, this is done by having the helper-players again temporarily raise the effective cost of f k from N/k to 2N/k, making the player prefer sactive,j to f k .
In the case of k > 1/ǫ, this can be done without helper players, since the ratio of the cost of sactive,j to the cost of f k is k/(k − 1) ≤ 1 + ǫ, so perturbations are sufficient.
(Note that Type-II player (2, j) would have preferred s active,j ′ for j ′ < j to sactive,j because that set already has a Type-I player on it, but that is not one of its allowed sets; Type-II player k = 3 is indifferent (so can be made to move as desired with arbitrarily small perturbations) and Type-II players k > 3 will strictly prefer sactive,j to s active,j ′ for j ′ < j.) Now, player (i, j) of Type I moves from s * i (whose cost to the player is at least √ N to sactive j (whose cost to the player is 1).
Finally, the players of Type II, in order from k = N down to 2, sequentially move back to their sets f k (or f k,j ).
In particular, at the time player k of type II moves, the set sactive j has a cost to it of N/k, which is equal to the cost of set f k (so with arbitrarily small perturbations, the adversary can easily cause these players to move).
After the above process has been completed for all j = 1, 2, . . . , √ N (so that s * i is now empty for the current value of i), the Type-I players (i, j) are now indifferent between all sets to which they are eligible.
So, they can each be made to move to their private sets si,j via arbitrarily small perturbations.
We then increment i and repeat the entire process above.To finish the argument, we need to describe how the helperplayers raise the effective cost of f k (or f k,j ).
This proceeds as follows.
For each k, the jth helper-player has a private set of cost N k (1−jǫ) .
By perturbing costs, adversary can cause these players for j = 1, 2, . . . , 1/(2ǫ) to move in order to their private sets.
Specifically, at the time the jth player is to move, the ratio of the cost of its private set to the cost of f k is N k(1−jǫ) Once player k of type II has moved off of set f k , the helper players return back to f k in the order j = 1/(2ǫ), . . . , 2, 1 (they are now indifferent between the two sets, so the adversary can cause them to move via arbitrarily small perturbations) bringing f k back to its initial state.
This completes the construction.The total number of players is upper bounded by 2N + 1ǫ ( √ N + 1 ǫ).
For ǫ ≥ 1/ √ N and N = n/4, this is at most n.
The total cost of the initial state is O(N 3/2 + N 3/2 /ǫ + (N/ǫ) log(1/ǫ)) and the final state has cost Ω(N 2 ), giving the ratio desired.
