In this paper, we propose a new semantic clone detection technique by comparing programs' abstract memory states, which are computed by a semantic-based static analyzer.
Our experimental study using three large-scale open source projects shows that our technique can detect semantic clones that existing syntactic-or semantic-based clone detectors miss.
Our technique can help developers identify inconsistent clone changes, find refactoring candidates, and understand software evolution related to semantic clones.
Basically, clones are code pairs or groups that have the same or similar functionality [31,29].
Some code clones are syntactically similar, but some are different.Based on syntactic similarity, Roy et al. [29] classify clones into four types:• Type-1 (Exact clones): Identical code fragments except for variations in whitespace, layout, and comments.
• Type-2 (Renamed clones): Syntactically identical fragments except for variations in identifiers, literals, and variable types in addition to Type-1's variations.
• Type-3 (Gapped clones): Copied fragments with further modifications such as changed, added, or deleted statements in addition to Type-2's variations.
• Type-4 (Semantic clones): Code fragments that perform similar functionality but are implemented by different syntactic variants.These definitions are widely used in the literature [31,30,15], and we also use them in this paper.The definitions of Type-1 and Type-2 clones are straightforward.
Mostly, they are copies (from other code) that remain unchanged (Type-1) or have a small variance (Type-2).
These clones can be easily detected by comparing syntactic features such as tokens in source code [18].
On the other hand, Type-4 (semantic) clones are syntactically different.
Since there is no clear consensus on Type-4 clones, some researchers define subtypes of Type-4 clones such as statement reordering, control replacement, and unrelated statement insertion [31,9,24].
Similarly, we define subtypes of Type-4 clones as follows:• Control replacement with semantically equivalent control structures (Refer to Figure 5.)
• Statement reordering without modifying the semantics (Refer to Figure 6.)
• Statement insertion without changing computation (Refer to Figure 8.)
• Statement modification with preserving memory behavior (Refer to Figure 7.)
Like Type-4 clones, there is no consensus on Type-3 clones.
Stefan Bellon et al. [1] define Type-3 clones as all clones that are neither Type-1 nor Type-2.
Similarly, in this paper, we define Type-3 clones as all clones that are not Type-1, Type-2, and Type-4 clones.This paper proposes an abstract memory comparison-based clone detector, which can identify all four clones discussed in this section.
Our goal is to detect clones by comparing the functionality of code fragments regardless of their syntactic similarity.
A naive way to achieve this goal is to perform exhaustive testing on a given set of clone candidates (programs).
We may determine semantic similarities of programs by generating all possible inputs for programs, observing all possible executions using the inputs, and comparing their execution results.
However, such exhaustive testing is often infeasible, since there might be infinitive many numbers of inputs and/or execution paths.For this reason, we use semantic-based static analysis [3,4,35,17,16] to determine semantic similarities of given programs, because static analysis soundly and finitely estimates the dynamic semantics of programs.
In our case, we use a path-sensitive semantic-based static analyzer that symbolically estimates the memory effects of procedures.Our overall approach is shown in Figure 1.
We compute abstract memory states from given programs via static analysis.
Then we compare the abstract memory states to determine code clones.
Figure 1: Our clone detection approach: abstract memory states for each clone candidate are computed by a path-sensitive semantic-based static analyzer.
These abstract memory states are compared for detecting code clonesWe build a semantic-based static analyzer on top of commercialized analyzer Sparrow [17,16], which can summarize each procedure after analyzing the procedure based on the abstract interpretation framework [3], and these procedural summaries have been carefully tuned to capture all memory-related behaviors in real-world C programs [17].
However, Sparrow does not support path-sensitive analysis.
We extend Sparrow to be path-sensitive like [35] by adding guards and guarded values to the abstract domain.The path-sensitivity is crucial for semantic code clone detection.
A path-insensitive analyzer loses the relation between condition expressions and corresponding statements.
For example, a path-insensitive analyzer considers the fol- lowing two different if-else codes as the same, since it does not know which statements are belonging to which condition expressions.
This insensitivity leads to detecting false positive clones.M ∈ Mem = Addr fin −→ GV GV ∈ GV = 2 Guard×Value g ∈ Guard = Value × Rel × Value + Guard ∧ Guard + Guard ∨ Guard v ∈ Value = N + Addr + (Uop × Value) + (Value × Bop × Value) + x, α, ∈ Addr = Var + Symbol + AllocSite + Addr × Field Var = Global + Param + Local"if(a > 0) A else B" = "if(a > 0) B else A" We compute abstract memory states at every program point of a given procedure by the conventional fixpoint iteration over abstract semantics (` a la abstract interpretation [3]).
Memory State Representation Our abstract domains for memory states are presented in Figure 2.
Our analysis is flow-and path-sensitive; it summarizes possible abstract memory states for each program point and all execution paths to the point.
An abstract memory state (M in Figure 2) is a finite mapping from abstract (symbolic) addresses to guarded values.
A guarded value (GV in Figure 2) is a set of pairs of a guard and a symbolic value, where the guard is the accumulated symbolic condition that leads to the accompanying value.
The set of all variables (Var ) consists of three disjoint sets, all global variables (Global ), all parameters (Param), and all local variables (Local ) except procedure parameters.
This partitioning enables us to define three equivalence classes for variables when defining equivalent addresses in Section 3.2.
Symbols (Symbol ) are used to indicate symbolic values or symbolic addresses in global input memories of the current procedure.
Allocated addresses (AllocSite) denote all addresses allocated (including arrays) at each allocation site (a static call program point for allocations).
Field addresses (Addr × Field ) represent field variables of structures.A symbolic value can be a number (N ), an address (Addr ), a binary value (Value × Bop × Value), or a unary value (Uop ×Value).
Bop and Uop denote a set of binary and unary operation symbols respectively.
A guard (Guard ) can be generated from the relations between values (Value × Rel × Value), where Rel denotes the set of comparison operators (e.g., =, ≤).
Some guards can also be connected by logical operators (conjunction ∧ and disjunction ∨).
The next step is estimating the semantics of the program as elements in this domain.Abstract Semantics Our analysis starts from the entry point of a procedure without knowing the input memory states.
The unknown input memory states are constructed by observing which locations and values are accessed by the procedure [17].
Abstract memory states are updated by evaluating each statement in the procedure, and the updates are decided by the predefined abstract semantics of each statement.
For example, one abstract semantics of the assignment statement is defined as follows:M e1 : {(g, x)} M e2 : {(gi, vi)}i M * e1 := e2 : M x → {(g ∧ gi, vi)}iM e : GV denotes that expression e evaluates to a guarded value GV given the memory state M.
This abstract semantics illustrates the destructive update case, in which the previous guarded values of the updated address is overwritten.
The rule indicates the destructive update can happen only when the address value of e1 is a single variable (note that the singleton set for the value in M e1 : {(g, x)}).
As a result, the value of variable x is updated by the value of e2 in memory M.
The guards for the new values are the conjunctions of guard g of the address and guards gi of the values.
1 int* foo(list *a,a {{true, α} α.len {{true, β} b {(true, γ)} {{β > 5 ∧ γ > 0, , res ((β ≤ 5)∨ (β > 5 ∧ γ ≤ 0)), 0 }The procedural summary of bar x > 0 return alloc x ≤ 0 return 0Figure 3: Procedure bar with its procedural summary and procedure foo with its abstract memory state at the exit point (line 6).
Consider the procedure foo in Figure 3.
The abstract memory state at the exit point (line 6) is presented on the right side.
At line 3, variable res has guarded value {{true, 0} which means variable res always has the value zero at the program point.
Parameter a is accessed in the condition expression at line 4, however the value of parameter a is unknown.
Hence a new symbol α is created to represent the value of parameter a. For the field value of a->len which is also unknown, new symbol β is created.
From the condition expression, guards β > 5 and β ≤ 5 are kept for true and false branches respectively.Inter-procedural Analysis The procedural summary information enables the analyzer to capture the semantics of procedure calls without analyzing the procedures again.
At line 5, procedure bar is called.
According to the procedural summary, the procedure returns an allocated address when the value of parameter x is greater than 0, otherwise it returns 0.
The procedural summary keeps conditions (as extended from [17]) for memory behaviors of procedure.
This procedural summary is instantiated with the abstract memory state at the call site (line 5).
At line 5, the value of formal parameter x in procedure bar is instantiated with γ (the value of actual parameter b).
With this instantiation of the procedural summary, we obtain the result memory state of the procedure call.
Now, variable res points to the result guarded value, {{β > 5 ∧ γ > 0, , β > 5 ∧ γ ≤ 0, 0}.
Here guard β > 5 comes from the condition on true branch at line 4 and guards γ > 0 and γ ≤ 0 come from the procedural summary of bar.
At line 6, the abstract memory states on both true and false branches are joined.
Variable res points to a guarded value {{β ≤ 5, 0} in the memory state from the false branch.
The joined memory state at the return point of foo (line 6) is shown as the table in Figure 3.
The procedural summary of procedure foo is automatically generated from this abstract memory state [17].
Handling Loops The termination of the fixpoint iterations is guaranteed by a widening operator [3].
Without the widening operator, fixpoint iterations may diverge because the heights of the number domain N and the symbolic-value domain Value×Bop×Value are infinite.
After five iterations (delayed widening [2]), changing values go into the special value (indicating an unknown value).
When we compare memory states, the unknown values are considered as not equivalent.
Hence our clone detection may miss some clones.Example for Comparison The abstract memory states at the exit point of procedures are compared for code clone detection.
As an example, procedure foo2 in Figure 4 is a semantic clone of procedure foo in Figure 3.
If we disregard the names of variables, symbols, field variables, and variable types then two memories are equivalent.
Note that two guards β ≤ 5 ∨ γ ≤ 0 and β ≤ 5 ∨ (β > 5 ∧ γ ≤ 0) are equivalent.
This equivalence is attained by function simple [5] presented in Section 3.2.1 int* foo2(list2 *x, 2 int y){ 3 int ret = 0; 4 if (x->val>5 && y>0) 5 ret = malloc(y); 6 return ret; 7 } Abstract memory state (line 6) x {{true, α} α.val {{true, β} y {(true, γ)} {{β > 5 ∧ γ > 0, , ret β ≤ 5 ∨ γ ≤ 0, 0}Figure 4: Procedure foo2 with its abstract memory state at the exit point (line 6).
Given estimated abstract memory states, we need to quantify their similarities.
Algorithm 1 presents the quantification steps.
First, we calculate the similarities between guarded value pairs of all possible combinations on the given memories M1 and M2 (line 2 to 8).
We compare addresses using the equivalence relation L = on addresses (as defined below).
If addresses are equivalent, then we calculate the similarity of two guarded values by function simGV (GV 1 , GV 2 ) (line 4).
If addresses are not equivalent, the similarity is zero (line 5).
For all combinations, the similarities of pairs are recorded in map S (line 6).
Then the find best matching(S ) function finds a subset of S that exclusively spans the two memories such that the total similarities of matched pairsAlgorithm 1: simM(M1, M2)Input: abstract memory states M1 and M2 Output: similarity value of M1 and M2 1 S := {}; 2 foreach address a1 ∈ dom(M1) do 3 foreach address a2 ∈ dom(M2) do 4 if a1L = a2 then v := simGV (M1(a1), M(a2)); 5else v := 0; 6 S := S{(a1, a2) → v}; 7 end 8 end 9 best = find best matching(S); 10 if | dom(M1) | + | dom(M2) |= 0 then return 0;11 return 2 · best | dom(M1) | + | dom(M2) |becomes the biggest (line 9).
Finally, the algorithm returns the ratio of similarity to the total size of memories.
If both memories are empty (the denominator becomes zero), then the similarity is zero (line 10 to 11).
Equivalent Addresses Two addresses are equivalent with the relation L = if one of the following conditions is satisfied:x L = y if x, y ∈ Global ∨ x, y ∈ Param ∨ x, y ∈ Local L = if , ∈ AllocSite a.f L = a .
f if a L = a α L = β if origin(α) L = origin(β)When two variables are compared, the names and types of the variables are ignored (Var).
We only check if both variables are parameters, global variables, or non-parameter local variables.
All dynamically allocated addresses are considered as equivalent regardless of their allocation sites (AllocSite).
For field addresses (Addr × F ield), the names of field variables are ignored and only structural equivalences are considered.
For example, x.val L = x.len holds even if the address uses different field names.
However, (x.next).
len L = x.len is not true because the former one has an additional field dereference.
All symbolic addresses are equivalent only when their origins are the same (Symbol).
The origin address origin(α) is the address pointing to symbolic address α.
As an example, the following origin(α) = a and origin(β) = α.len hold in Figure 3.
Similarity Between Guarded Values A guarded value GV is a set of pairs which consist of a guard and a value.
Function simGV (GV 1 , GV 2 ) compares all guards and values in GV 1 with those in GV 2 , and then counts the number of matched pairs n. Finally, the similarity of two guarded values is computed as follows:simGV (GV 1 , GV 2 ) = 2 · n | GV 1 | + | GV 2 | n = maximum of |M | s.t. M ⊆ S and∀∀(g1, v1), (g2, v2) ∈ M, (g1, v1) and (g2, v2) appear only onceS = {{(g1, v1), (g2, v2) | g1 G = g2 ∧ v1 V = v2} ∀(g1, v1) ∈ GV 1 and ∀(g2, v2) ∈ GV 2The similarity is the ratio of the number of matched pairs to the total size of two guarded values.
We seek for the maximum number of matched pairs trying to match all possible combinations GV 1 × GV 2 .
Equivalent values that simplifies guards so that they do not contain any redundant sub-formulas using a decision procedure [7].
Furthermore, we want to assume x > 5 and z > 5 are equivalent if x L = z holds.
This process is done by unification algorithm unify, which is widely used in type systems [25].
The algorithm returns true if there exists a substitution which makes two different structures the same while preserving relationsn1 V = n2 if n1 = n2 v1 ⊕ v2 V = v3 ⊕ v4 if v1 V = v3 ∧ (⊕ = ⊕ ) ∧ v2 V = v4 v1 V = v2 if v1 V = v2 ∧ = V = if L = Equivalencev1 ∼ v2 G = v3 ∼ v4 if v1 V = v3 ∧ (∼=∼ ) ∧ v2 V = v4 g1 G = g2 ifL = and V =.
Best Matching Function find best matching(S ) at line 9 in Algorithm 1 finds the best matching (i.e. the matching that maximizes the sum of similarities), and then returns the maximum sum of similarities.
Consider this similarity table as an example.X X X X X X X M2 M1(a 1 1 , GV 1 1 ) (a 2 1 , GV 2 1 ) (a 3 1 , GV 3 1 ) (a 4 1 , GV 4 1 ) (a 1 2 , GV 1 2 ) 0.8 1 0.1 0.5 0.6 (a 2 2 , GV 2 2 ) 0.7 0.7 2 0.6 0.5 (a 3 2 , GV 3 2 ) 0.6 0.5 0.6 3 0.4The boxed ones represent the best matching, since it maximizes the sum of similarities.
Suppose our matching function finds this best matching.
The value of best at line 9 in Algorithm 1 is the sum of similarities, 2.1 = 0.8+0.7+0.6 of all matched pairs.
Hence the similarity, 0.6 = 2 · 2.1/(4 + 3) of these two memories is returned at line 11 in Algorithm 1.
We develop a lightweight greedy algorithm to heuristically try finding the best matching which runs in O(n 2 ), where n is the number of elements.
After calculating the similarities of all pairs, the pair which has the maximum similarity is chosen as a matched one.
Then the algorithm continues to choose another maximum pair among the remaining pairs until all addresses in either M1 or M2 are matched.
The order of choices for the above table is annotated over the boxes.
The algorithm is not guaranteed to find the best matching, but has the advantage of the running time.
There is a combinatorial optimization algorithm called the Hungarian method [22] which is guaranteed to find the best matching but runs in O(n 3 ), much slower than ours.
In our experiments, we found that our algorithm yields the same results as the Hungarian method.
This is because similarities of pairs are usually near 1 or 0.
We allow parametrization by MinEntry to filter small clones such as a procedure containing just one line as its body.
Though the similarity function simM(M1, M2) gives high values to similar memories, this function does not reflect the size of memories.
So we give a penalty to small size memories.
Note that the value of the similarity function ranges over [0,1].
simM(M1, M2) log MinEntry log(| dom(M1) | + | dom(M2) |)The above formula is proportional to the size of memories and inversely proportional to MinEntry.
Log function is used to smoothen the amount of the penalty.
Here parameter MinEntry is given by users depending on target program size.
The parameter is similar to parameter minT which determines the minimum number of tokens for clone candidates in Deckard [12].
We evaluate similarities for all possible pairs of abstract memories.
There is a high probability that procedures with high similarity are true clones.
Hence we sort all pairs according to their similarities.
We allow another parameter Similarity, which determines the threshold of similarities of clones to be reported.
If Similarity is set to 80% then pairs with similarity less than 0.8 are not reported.Sometimes the similarity of two memories M1 and M2 never exceeds the given Similarity if there are a big difference in the entry numbers of the two memories.
Hence we can skip the comparison of two memories where,2 × min(| dom(M1) |, | dom(M2) |) | dom(M1) | + | dom(M2) | ≤ Similarity.This strategy significantly reduces the memory comparison time.Users can choose parameters MinEntry and Similarity to pick thresholds to determine clones.
One could set MinEntry high, if one wants to ignore small clones.
One could set Similarity high, if one wants less false positives.
In this section, we evaluate our code clone detector MeCC.
We apply MeCC to detect clones in large-scale open source projects, Python, Apache, and PostgreSQL as shown in Ta We apply MeCC to detect clones to evaluate the detectability.
In our experiments, we set Similarity=80% and MinEntry =50.
Then the detected clones by MeCC are manually inspected and categorized into four clone types as discussed in Section 2 by one author who has experience with C/C++ development in industry more than eight years.
The other two authors review and confirm the inspected clones.
The numbers of detected and classified clones are shown in Table 2.
MeCC can detect all four types of clones.
Type-4 (semantic) and some Type-3 (gapped) clones in Table 2 have noticeable syntactic differences.
Nevertheless, MeCC can detect these clones because it only compares abstract memory states.
MeCC also detects Type-1 (exact) and Type-2 (renamed) clones since syntactic similarity is usually accompanied by semantic similarity.
Figure 5 shows one Type-4 clone detected by MeCC.
This is a typical example of control replacement.
The if-else statements in Figure 5(a) are replaced by semantically equivalent statement using the ternary conditional '?
:'operator in Figure 5(b).
MeCC detects this clone, since their functionalities are the same and thus the abstract memory states are the same.
A more complex Type-4 clone detected by MeCC is presented in Figure 6.
The clone has two syntactic differences.
One difference is statement reordering.
Two statements from line 4 to 7 in Figure 6(a) are reordered into the statements from line 3 to 6 in Figure 6(b).
The second difference comes from using intermediate variables.
The local variable sconf is introduced at line 3 in Figure 6(a) and then used as a parameter of the ap_get_module_config function call at line 5.
The local variable proto is introduced at line 7 in Fig- ure 6(b).
The return value of the apr_pstrdup function call at line 11 in Figure 6(b) is assigned to this variable.
This value is assigned to a field address at line 13 via the local variable.
These syntactic changes make it difficult for textual-based clone detectors to identify such clones [18].
Understanding the semantics of procedure calls is one advantage of MeCC.
An interesting Type-4 clone detected by MeCC in Figure 7 highlights this strength.
The major syntactic difference between the two procedures is that the assignment statement at line 6 in Figure 7(a) is substituted by the procedure memcpy call at line 7 Figure 7(b).
Most previous clone detection techniques cannot capture this semantic similarity between a procedure call and similar assignment statements.
The next question is how accurately MeCC can detect clones.
We manually inspected the detected clones and identified false positives, which are not real clones, but are detected as clones by MeCC.
Table 3 presents the false positive clones and their ratio from three subjects (when Similarity=80% and MinEntry=50).
In Python, the total number of found clones is 264, the number of false positive clones is 39, and hence the false positive ratio is around 14.7%.
Similarly, the false positive ratio for Apache is 12.5%, and for PostgreSQL is around 16.9%.
The most common case of false positive clones is data structure initialization.
In those clones, a structure is allocated and then field variables are initialized according to the structure type.
Some of them can be viewed as clones, but we scrupulously mark these initialization code pairs as false positives.These false positive ratios look slightly higher than previous approaches [18,12,9].
However, one could set Similarity higher to reduce the false positive ratio.
As an example, the false positive ratio is only 3% for Python when we set Similarity=90%.
In the next step, we measure the ratio of false negative clones -real clones, but missed by MeCC.
For this experiment, since we need an oracle clone set, we use the benchmark provided by Roy et al. [31].
This benchmark includes three Type-1, four Type-2, five Type-3, and four Type-4 clones.
We apply MeCC on the benchmark with Similarity=80%.
Since the sizes of procedures in the benchmark are small, we set MinEntry=2.
[31].
MeCC misses only one clone in Type-3.
Table 4 shows that MeCC has almost no false negatives.
MeCC misses only one Type-3 clone, which has an insertion of an if statement that is related to a procedure call, and it changes the memory state.
However, MeCC detects this clone if we set Similarity=79%.
Overall, our experimental results in this section show that MeCC can detect clones accurately, with almost no false negatives and with a reasonable false positive ratio.
In this section, we measure scalability of MeCC.
We already showed that MeCC can detect clones in large-scale open source projects accurately in Section 4.1 and Section 4.2.
We measure the time spent to detect the clones for three subjects.
Our experiments were conducted on an Ubuntu 64-bit machine with a 2.4 GHz Intel Core 2 Quad CPU and 8 GB RAM.
Table 5: Time spent for the detection process.
Table 5 shows the results.
Static analysis took about 63 minutes for Python and 422 minutes for PostgreSQL.
Since our static analysis includes preprocessing, summarization/instantiation of procedural summaries, and fixpoint iterations for collecting memory states, it is computationally expensive.
However, this is usually one-time cost.
When software changes, we can incrementally recompute memory states of the changed parts including impacted parts according to the call relationship.
If the changed part in a procedure does not cause observable changes to memory behaviors of the procedure, then callers of the procedure do not need to be re-analyzed.
Though the dependency can, in the worst case, expand to all the procedures, such situation (a procedure's change in memory effects, combined with that procedure as a hub in the call-graph) would not be that common.
Section 4.1 shows that MeCC can detect all four types of clones including Type-3 (gapped) and Type-4 (semantic) clones.
In this section, we discuss if other clone detectors can also identify these clones.
Apache PostgreSQLType-3 [9].
For the comparison, we use two publicly available syntactic clone detectors, Deckard, a AST-based detector, and CCFinder, a token-based detector.
We also use a result set from a PDG-based semantic clone detector [9].
For Deckard, we set the options as used in [12], mint=30 (minimum token size), stride=2 (size of the sliding window), and Similarity=0.9.
For CCFinder, we also use the default options, Minimum Clone Length=30, Minimum TKS=12 (token set size), and Shaper Level=Soft shaper.
For the PDG-based detector [9], we directly used the clone detection results provided by the authors of the detector, since the tool is not publicly available at the time of this writing.
Table 6 compares Type-3 and Type-4 clone detectability of Deckard, CCFinder, the PDG-based detector.
We assume these detectors can detect all Type-1 and Type-2 clones, since these clones are syntactically almost the same.CCFinder is a scalable and fast tool which detects Type-1 and Type-2 clones accurately.
However, CCFinder could not identify any Type-3 and Type-4 clones.
The main reason is that CCFinder extracts and compares syntactic tokens, but usually Type-3 and Type-4 clones are significantly different in the token level.Deckard detects about 24% of Type-3 clones.
Since Deckard uses the characteristic vectors of AST, it can detect clones with small syntactic variations.
Surprisingly, Deckard identifies two Type-4 clones in PostgreSQL.
The two detected Type-4 clones are classified as the statement reordering subtype shown in Figure 6.
Since Deckard extracts characteristic vectors of these reordered ASTs, the vector only captures the number of elements in AST.
However, Deckard still misses a large portion of Type-3 and Type-4 clones.The PDG-based detector identifies about 12% of Type-3 clones.
Only one Type-4 clone is identified in each Python and PostgreSQL.
The detected Type-4 clones are statement reordering.
Since PDGs capture program semantics using data dependency and control flows, the PDG-based detector can detect some Type-4 clones like statement reordered ones.However, these PDG-based approaches [9,21,24] have some limitations.
(1) First, inter-procedural semantics via procedure calls cannot be supported, which means that semantic clones that differ in respect to procedure calls (e.g., function inlining) are missed.
MeCC captures memory behavior of procedure calls by procedural summaries as described in Section 3.
(2) Second, PDGs cannot be completely free from changes on syntactic structures, while our technique reliably determines the semantic similarity of code because we use purely semantic information (path-sensitive abstract memory effects) of programs.Overall, the comparison results in this section suggest that MeCC, an abstract memory-based clone detector is effective in detecting all four types (including Type-3 and Type-4) of clones.
We discuss potential applications and limitations of our approach.
We also identify threats to validity of our experimental results.
Detecting code clones is useful for software development and maintenance tasks such as finding inconsistencies [15,14] and identifying potential bugs or code smells [10].
We used MeCC to identify potential bugs and code smells caused by inconsistencies.
Figure 8 shows one example of Type-4 clones identified by MeCC.
This clone was not detected by other clone detectors (e.g. [18,12,9]).
It clearly shows an inconsistency: the procedure PQparameterStatus in Figure 8 (b) checks whether parameter paramName is not null, but the procedure GetVariable in (a) does not check.
This inconsistency shows an exploitable bug, which manifests when null is passed as the second parameter, name.
We manually inspected all Type-3 and Type-4 clones identified by MeCC to check if they were caused by inconsistencies, and if these inconsistencies lead to potential problems.
When we identified problems caused by inconsistencies, we classified them in two categories, exploitable bugs and code smells: A bug is exploitable if it causes unexpected behaviors, for example when a particular variable is used as procedure input as shown in Figure 8 (a).
Conversely, a code smell occurs when an inconsistency has no demonstrated unexpected behaviors, but refactorings or consistent changes (with other clone pairs) are highly recommended.
Table 7 shows the manual inspection results 1 .
Among 278 Type-3 and Type-4 clones, 55 exploitable bugs and 70 code smells were found.
About 45% of Type-3 and Type-4 clones are either exploitable bugs or code smells.
These bugs and code smells would be missed by previous approaches (e.g. [18,12,9]), since most of these Type-3 and Type-4 clones were not detected by them as discussed in Section 4.4.
Overall, Table 7 implies that MeCC and its identified Type-3 and Type-4 clones are very useful for detecting inconsistencies, exploitable bugs, and code smells.MeCC can be used for plagiarism detection and common bug pattern identification.
Syntactic plagiarism detection tools (e.g. Moss [33] and JPlag [28]) cannot detect plagiarism if code is copied and intentionally changed with some syntactic obfuscations.
MeCC is able to detect plagiarism as long as the semantics of the copied code remains similar regardless of its syntactic changes.
Similarly, MeCC can help identify common bug patterns.
Kim et al. proposed Bug- Mem [20], which identifies common bug fix patterns and locates similar bugs in other code.
However, they only capture syntactic bug patterns using tokens of code.
MeCC can improve their work by identifying common semantic bug patterns.
Since our current implementation compares abstract memory states at the exit points of procedures, MeCC detects only procedure-level clones.
However it is possible to extend MeCC to find clones with a finer granularity such as basic blocks adapting a code fragments generation technique [13] to prepare code clone candidates of finer granularity.
Then we can calculate every abstract memory state for each candidate and compare them to identify clones.Collecting abstract memory states from programs is a computationally expensive task in both time and memory.
Analyzing the semantics of programs takes longer than syn-tactic comparison.
However, the current implementation of MeCC showed that MeCC scales to detect clones in PostgreSQL, which is around 1M LOC.Similar abstract memory states do not always imply similar concrete behaviors, which may cause false positives.
In the abstract interpretation framework [3], one element in an abstract domain can represent several concrete elements.
Procedural summaries record memory related behaviors [17], but do not capture all concrete procedure behaviors.
This limitation is inevitable since determining semantic equivalence between two programs is generally undecidable [8].
We identify the following threats to validity to our work:Open source projects may not be representative.
The three projects used in this paper are all open source and not representative of all software systems, and hence we cannot currently generalize the results of our study across all projects.
However, these projects are chosen because they are commonly used in other code clone related research.Manually inspected and classified clones.
One author manually inspected and classified clones, and they are used to evaluate MeCC.
Since there is no consensus about Type-3 and Type-4 clones, there is ambiguity in the classified clones.
However, two other authors confirmed the classified clones, and we made these data publicly available.Default options are used.
Deckard, CCFinder, and the PDG-based detector have various options to tune their clone detectability.
In this paper, we use their default options.
However, careful option tuning may allow these tools to detect more Type-3 or Type-4 clones.
Most clone detection techniques are syntactic clone detectors ones [31,29,12,18,23,32,9,30,1] leveraging line-based [32], token-based [18,23], or tree-based [12] approaches.
These detectors are good at identifying Type-1 and Type-2 clones, but they miss most of the Type-4 and some of the Type-3 clones as discussed in Section 4.4.
Existing semantic clone detectors have limitations.
For example, as we discussed in Section 4.4, PDG-based detectors [9,21,24] miss some semantic clones due to, for example, ignorance of inter-procedural semantics.
A PDG-based technique [9] maps slices of PDGs to syntax subtrees and applies DECKARD [12] to detect similar subtrees.
Although slicing enables one to detect more gapped clones, clones in each clone cluster still need to be syntactically similar.
Jiang et al. [13] proposed a clone detector using random testing techniques.
They conclude two code fragments are clones when their outputs are the same just for a number of randomly generated inputs.
Since random testing cannot cover all program paths or inputs -usually around up to 60 ∼ 70% [26,27,34], false positives are inevitable.
Furthermore, the inter-procedural behaviors are not considered in their approach.
We proposed an abstract memory-based code clone detection technique, presented its implementation, MeCC, and discussed its applications.
Since MeCC compares abstract semantics (as embodied in abstract memory states), its clone detection ability is independent of syntactic similarity.
Our empirical study shows that MeCC can accurately detect all four types of code clones.
We also show that most of Type-4 and some of Type-3 clones identified by MeCC cannot be detected by previous approaches [18,12,9].
We anticipate that MeCC will allow developers to find inconsistencies as shown in Section 5.1, identify refactoring candidates, and understand software evolution related to semantic clones which would be neglected by previous approaches.Overall, we expect that future clone detection approaches will exploit more deep semantics of code via static analysis program logic, and/or other program verification technologies.
MeCC is one step forward in this direction.
