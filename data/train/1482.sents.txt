Although many people still think that it is difficult or even impossible to implement OS kernels in a strictly typed programming language, we dispelled the myth in our previous works by designing and implementing a typed assembly language which is flexible enough to implement essential functionalities of OS kernels (e.g., memory and multi-thread management facilities).
Taking a step further, in this paper, we show an extended typed assembly language which supports SMP/multi-core environments with CPU hardware interrupts and illustrate how to implement synchronization primitives, which are essential for implementing OS kernels in the environments.
It has been considered difficult to implement system software (e.g., OS kernels) in strictly typed languages.
This is because conventional strictly typed languages were not expressive enough to implement fundamental components of system software, such as memory management and multi-thread management facilities.
Several previous works tried to implement OS kernels in strictly typed programming languages, but the fundamental components were out of their scope [2,10] or rely on other verification approaches [20].
On the other hand, we have been working on implementation of an OS kernel in Typed Assembly Language (TAL) [16].
TAL is an ordinary assembly language except for being strictly typed and its memory safety (programs perform no illegal memory accesses) and controlflow safety (programs perform no illegal code execution) can be verified through its type checking.
In fact, we designed and implemented a variant of TAL which is expressive enough to implement OS kernels and implemented a simple OS kernel (including the memory and multi-thread management facilities) in it [14,13,15].
However, there exists one problem; our previous works did not support SMP/multi-core environments with interrupts where programs run physically concurrently and asynchronously.To solve the problem, this paper shows an extension of our previous TAL that supports the SMP/multi-core environments with interrupts.
More precisely, this paper shows how to extend the type system for implementing synchronization primitives themselves that are essential for OS kernels in the SMP/multi-core environments.There are two issues to be addressed for supporting the SMP/multi-core environments: safety of shared memory (that is, memory regions that may be accessed simultaneously by several programs) and its memory consistency model.
This paper mainly focuses on the safety of shared memory, and discusses the consistency model briefly.The rest of this paper is organized as follows.
First, Sec. 2 shows problems for ensuring the safety of shared memory.
Then, Sec. 3 describes our approach to the problems and Sec. 4 presents our extended TAL based on our approach.
Next, Sec. 5 argues about the memory consistency model briefly.
Finally, Sec. 6 discusses related work and Sec. 7 concludes the paper.
In the SMP/multi-core environments, one memory region can be accessed simultaneously by several programs.
In order to achieve TAL which is able to ensure safety of shared memory and yet expressive enough to implement system software, we have to deal with memory updates that may alter the types of memory regions (we call them strong updates in this paper) and track pointer aliases between multiple threads.
In typical and conventional strictly typed languages, the problem of strong updates does not apply simply because they are not allowed (the types of memory regions are invariant).
Therefore, the memory safety is not violated even if the memory regions are updated simultaneously (as long as the updates are atomic).
However, in order to implement memory and multithread management facilities, it is necessary to allow programs to perform strong updates.
For example, typical implementation of memory management (e.g., malloc/free) requires to handle allocation and release of memory regions, that is, a memory region which is allocated as a certain type may be released and reused (reallocated) as a different type from the original one.In order to achieve type-safe strong updates in singlecore environments, we designed and implemented a TAL [14] whose type system is integrated with alias types [18] and dependent types [19].
More precisely, illegal memory accesses are prevented by tracking pointer aliases with the type system.
We also implemented the memory and multi-thread management facilities for the single-core environments in the extended TAL.However, in order to adapt the language for the multicore environments, it is necessary to address another problem described in the next section.
In order to adapt the extended TAL mentioned in Sec. 1 for the multi-core environments, we need to track pointer aliases between multiple threads.Conventional programming languages are equipped with synchronization mechanisms as language primitives.
Therefore, pointer aliases are analyzed by utilizing the synchronization primitives as a hint.
For example, let us consider the situation where a program accesses a shared memory region.
We are able to know whether multiple threads access the shared memory region simultaneously by checking whether the synchronization lock associated to the memory region is always held.However, our goal is to design a TAL which permits implementation of synchronization primitives themselves.
That is, it cannot have such language primitives and only atomic instructions provided by CPU (e.g., atomic swap and/or compare-and-swap instructions) are available.
Thus, we have to track pointer aliases between multiple threads only with the atomic instructions.
This section describes our approach to the problems shown in Sec. 2.
The key idea is to allow strong updates only in atomic memory operations and ensure the types of memory regions do not change before and after executing each atomic memory operation.
Here, one atomic ... memory operation consists of one atomic instruction of CPU whose runtime effects on one processor are all visible or all invisible to others, and pseudo instructions that only affect types and have no runtime effects.
In our approach, for example, spin locks can be implemented as in Fig. 1.
In the figure, line 1 to 4 and line 13 to 17 represents label types, which are given to all the labels and represent the conditions that should be satisfied when a control reaches the labels.
For example, line 1 to 3 represents the heap type which represents the memory state when a control reaches to the label lock and line 4 represents the state of registers.
More concretely, line 1 to 4 indicates that the register r1 holds a certain integer value p (line 4) and there exists data at the address p (line 1) (Please note that p, q and i are singleton integer types [19,14]).
Here, we assume that the data is shared between threads.
The data has the existential type whose base is the tuple consists of two integer values (i and q) and there exists data of the type data at the address q only if i is 0 (line 2 and 3).
The first element of the tuple (i) represents a lock and the second element (q) represents a pointer to the data guarded by the lock which is inaccessible unless unpacking the existential type [18,14].
Type checking of lock acquisition (lock) is performed as follows.
First, the unpack pseudo instruction (line 7) unpacks the existential type of the data in the address p.
The heap type becomes as follows:{ p -> (i, q), q -> data if [i == 0]}Here, the type of the memory region at the address p is modified, but it passes the type check because unpack is a pseudo instruction.Next, xchg (line 8) atomically exchanges the content of the address which is specified by the register r1 and that of the register r2.
Then, the register r2 has the singleton type i and the heap type becomes as follows:{ p -> (1, q), q -> data if [i == 0]}Here, because we assume that xchg is atomic, it is unnecessary to revert the heap type to the original one.Then, the pack pseudo instruction modified the heap type as follows (please note that the heap type { q -> data if [i == 0] } is not encapsulated because we know that i is not equal to 0):{ p -> exists(i).
{ q -> data if [i == 0]}.
(i, q) q -> data if [i == 0] }Here, the type of the memory region at the address p is reverted to the original one.
These instructions of line 7 to 9 make up one atomic operation.Next, the bne instruction loops back to the label lock if i is not equal to 0 or jumps to the label unlock if i is equal to 0.
This means that it tries to acquire the lock again if the lock is already acquired, or releases the lock otherwise.
In this example, the lock is immediately released after acquisition but in fact the memory region at the address q can be accessed before releasing the lock.
More concretely, when jumping to the label lock, the condition specified in its label type is satisfied because i 񮽙 = 0 and the heap type is equal to as follows:{ p -> exists(i).
{ q -> data if [i == 0]}.
(i, q) } In addition, when jumping to the label unlock, the condition specified in its label type is also satisfied because i = 0 and the heap type is equal to as follows:{ p -> exists(i).
{ q -> data if [i == 0]}.
(i, q) q -> data }On the other hand, type checking of lock release (unlock) is performed as follows.
First, the unpack pseudo instruction (line 19) unpacks the existential type and modifies the heap type as follows (please note that the heap type { q -> data if [i == 0] } is merged with { q -> data } because the former is a subset of the latter.)
:{ p -> (i, q), q -> data}Next, mov (line 20) modifies the heap type as follows:1: { p -> exists(i).
2: { q -> data if [i == 0]}.
3:(i, q) } 4: ( r1 : p ) 5: lock: 6: mov r2 <-1 7: unpack r1 8:mov r3 <-[r1] 9:mov [r1] <-r2 10: mov r2 <-r3 11: pack r1 12:bne r2, 0, lock 13: jmp unlock 14:... { p -> (0, q), q -> data}Finally, the pack pseudo instruction (line 21) modifies the heap type as follows:{ p -> exists(i).
{ q -> data if [i == 0]}.
(i, q) } Please note again that the type of the memory region at the address p is reverted to the original one and the memory region at the address q is no longer accessible because it is packed to the existential type, unless reacquiring the lock.
These instructions of line 19 to 21 make up one atomic memory operation.Thus, we can express the spin locks that are memory safe even if they are used in the environments where multiple threads run concurrently.Here, let us consider the slightly modified example as shown in Fig. 2.
More specifically, the xchg instruction in Fig. 1 is replaced with the three mov instructions, that is, one atomic memory operation is divided into three atomic memory operations (line 7 to 8, line 9, and line 10 to 11).
In this case, after the mov instruction at line 9, the heap type becomes as follows:{ p -> (i, q), q -> data if [i == 0]}At this point, the type checking fails because the type of the memory region at the address p is not reverted to the original existential type after the atomic operation.In fact, the program of Fig. 2 is wrong because race conditions may occur between line 8 and 9.
This section explains the details of our TAL based on the approach of Sec. 3.
The syntax of the abstract machine is shown in Fig. 3, and that of the types is shown in Fig. 4.
(In fact, our TAL is a bit more complicated but this paper explains the simplified one for the sake of brevity and space limitation.)
The type system of our TAL ensures the memory safety and control-flow safety even in the SMP/multi-core environments with interrupts.
(register) r ::= r 1 | r 2 | . . . | r n | sp (operand) o ::= d | r | [r + d] (inst.)
ι ::= mov o ← o | bcc o, o, o | jmp o | push o | pop o | ret | cli | sti | pushf | popf | iret | block | unblock | pack [¯ c|Ψ] o as τ | unpack o with ∆ (insts) I ::= · | ι ; I (tuple) t ::= d, . . . , d | pack [¯ c|Ψ] .
t (value) v ::= t | ∀∆.
C.Φ.i.i.I (heap) H ::= · | {d → v}H (registers) R ::= {r 1 → d, . . . , r n → d} (stack) s ::= · | d :: s (processor) P ::= (R, s, d pc , d ipc , d if ) (state) M ::= (H, P , d g )One difference between our TAL and conventional TALs is that the state of the abstract machine (M ) of our TAL consists of the heap (H), the states of processors (P ), and the atomic flag (d g ).
The state of the processor (P ) consists of the register file (R), the stack (s), the program counter (d pc ), the address of an interrupt handler (d ipc ), and the interrupt flag (d if ).
The atomic flag is just an integer value which indicates which processor performs an atomic memory operation.
If there exists a process which performs an atomic memory operation, the flag is set to the processor ID of the processor (the processor ID is a unique number which is assigned statically to each processor).
On the other hand, if there is no such processor, the flag is set to 0.
The atomic flag is manipulated by the block and unblock instructions.
They indicate the beginning and the end of an atomic memory operation, respectively.The reason why we introduced block and unblock , which do not exist in typical CPUs, is to uniformly deal with the atomic instructions of the various CPUs.For example, the xchg instruction of the Intel architecture [11] can be expressed with a combination of block , unblock and memory operations, as follows: block ; mov r tmp ← [r d ]; mov [r d ] ← r s ; mov r s ← r tmp ; unblockblock ; beq r a , [r d ], cmpxchg eq; mov r a ← [r d ]; jmp cmpxchg end (* cmpxchg eq *) mov [r d ] ← r s ; jmp cmpxchg end (* cmpxchg end *) unblockOne of the benefits of the above representations is that they can be used for implementing wait-free data structures, as pointed out in [9].
The interrupt handler is an instruction sequence which is executed for handling interrupts.
When an interrupt occurs, the program counter and the interrupt flag are pushed onto the stack and the interrupt handler runs.The interrupt flag controls interrupts.
More concretely, interrupts are disabled when the flag is set to 0.
On the other hand, interrupts are enabled when the flag is set to a non-zero value even if the interrupt handler is executed.The cli and sti instructions set and clear the interrupt flag, respectively.
The pushf instruction pushes the interrupt flag to the stack, while the popf instruction pops a value from the stack and sets the interrupt flag to the value.
We can achieve nested interrupt disabling and enabling with these instructions.
The iret instruction is the instruction for returning from the interrupt handler; it sets the interrupt flag to the value stored in the stack and jumps to the address also stored in the stack.
The pack and unpack instructions are pseudo instructions for introducing and eliminating existential types, respectively.The other instructions are the same as ordinary assembly languages.
Please note that arithmetic instructions are omitted in this paper for brevity.
They can be formalized without large modification to the type system.The types of our TAL are shown in Fig. 4.
In the same ways as our previous works [14,13,15], they consist of the heap type for typing the heaps, the registers type(H, (. . . , P i , . . .), d g ) → M (H ′ , (. . . , P ′ i , . . .), d ′ g ) where (H, P i , d g ) → P,i (H ′ , P ′ i , d ′ g ) i = d g (if d g 񮽙 = 0)any processor ID (otherwise)Figure 5: Operational semantics: the abstract machine(H, (R, s, d pc , d ipc , d if ), d g ) → P,pid L ′ L ′ = (H, P ′ , d g ) where P ′ = (R, s ′ , d ipc , d ipc , 0) s ′ = d pc :: d if :: s (if d g = 0 ∧ d if 񮽙 = 0)Figure 6: Operational semantics: interrupts for typing the register files, and the stack type for typing the stacks.
Please note that the types for representing variable length arrays [14] are omitted in this paper.
They differ from our previous works in two points.
First, the integer types i that represent the atomic flag and the interrupt flag are added to the label type which represents the address of instructions (∀∆.
C.Φ.i.i).
Second, the constraints C can be specified to each element of the heap type which represents the heap.
For example, the heap type {i → τ if i 񮽙 = 0} indicates that there exists a memory region at the address i and its type is τ only if i 񮽙 = 0.
If it is unnecessary to specify any constraint, we can omit the constraints as {i → τ }.
The operational semantics of our TAL is defined in Fig. 5, 6, 7 and 8.
Fig. 9 defines the auxiliary functions.The operational semantics of the whole abstract machine is define in Fig. 5.
If the atomic flag is 0, one of the processors of the abstract machine takes a step.
On the other hand, if the atomic flag is non-zero, the processor whose ID is equal to the atomic flag takes a step.
That is, if one processor performs an atomic memory operation, the other processors do not execute instructions.
From the viewpoint of memory consistency, this means that the abstract machine satisfies sequential consistency [1].
Sec. 5 discusses more relaxed memory consistency.Although the operational semantics of the processor follows conventional typed assembly languages, it differs in handling the interrupt flag.
More concretely, if the atomic flag (d g ) is 0 and the interrupt flag (d if ) is nonzero, then the interrupt handler (d ipc ) can be executed anytime (Fig. 6).
Before executing the interrupt handler, the interrupt flag is set to 0, that is, the interrupts are disabled.
In addition, the program counter (d pc ) and the interrupt flag (d if ) are pushed to the stack.The operational semantics of the instructions is de- fined in Fig. 7 and 8.
The block instruction sets the atomic flag to the self processor ID, while the unblock instruction clears the atomic flag to 0.
The cli and sti instructions set the interrupt flag to 0 and 1, respectively.
pushf pushes the interrupt flag to the stack, while popf pops the value from the stack and sets the interrupt flag to the value.
The iret pops the stored program counter and the stored interrupt flag from the stack, sets the interrupt flag to the stored interrupt flag, and jumps to the stored program counter.
The other instructions are the same as our previous TALs [13,15].
(H, (R, s, d pc , d ipc , d if ), d g ) → P,pid L ′ if H[d pc ] = then L ′ = mov o 1 ← o 2 (H ′ , (R ′ , s ′ , d ′ pc , d ipc , d if ), d g ) where S = (H, R, s) d = get (S, o 1 ) (H ′ , R ′ , s ′ ) = update(S, o 2 , d) jmp o (H, (R, s, d, d ipc , d if ), d g ) where d = get((H, R, s), o) bcc o 1 , o 2 , o 3 (H, (R, s, d, d ipc , d if ), d g ) where S = (H, R, s) if d 1 cc d 2 then d = get(S, o 3 ) else d = d ′ pc d 1 = get(S, o 1 ) d 2 = get(S, o 2 ) push o (H, (R, s ′ , d ′ pc , d ipc , d if ), d g ) where S = (H, R, s) s ′ = d :: s d = get (S, o) pop o (H ′ , (R ′ , s ′′ , d ′ pc , d ipc , d if ), d g ) where s = d :: s ′ S = (H, R, s ′ ) (H ′ , R ′ , s ′′ ) = update(S, o, d) ret (H, (R, s ′ , d, d ipc , d if ), d g ) where s = d :: s ′ where d ′ pc = d pc + 1 The selected typing rules are shown in Fig. 10, 11, 13, 14 and 15.
get type and update type are auxiliary functions for obtaining and updating the types of operands according to the specified heap and registers types, respectively (Fig. 12).
The typing rules are decidable if the integer constraint solving ∆, C |= C is decidable.
There are two key points in the typing rules.
First is that they statically keep track of the atomic and interrupt flags as the singleton integer types.Second is that the shared memory regions, that is, the memory regions shared between the processors, and the interrupt handler and the interrupted program, are handled specially as the heap types Ψ s and Ψ b , respectively.
The two heap types are introduced in order to achieve memory safe strong updates, which are essential for implementing the memory and multi-thread management facilities, as mentioned in Sec. 2.1.
The idea of tracking the heap types of the shared memory regions is to temporarily allow the strong updates only while an atomic memory operation is performed or the interrupts are disabled, as described in Sec. 3.
(H, (R, s, d pc , d ipc , d if ), d g ) → P,pid L ′ if H[d pc ] = then L ′ = cli (H, (R, s, d ′ pc , d ipc , 0), d g ) sti (H, (R, s, d ′ pc , d ipc , 1), d g ) pushf (H, (R, s ′ , d ′ pc , d ipc , d if ), d g ) where s ′ = d if :: s popf (H, (R, s ′ , d ′ pc , d ipc , d ′ if ), d g ) where s = d ′ if :: s ′ iret (H, (R, s ′ , d, d ipc , d ′ if ), d g ) where s = d :: d ′ if :: s ′ pack [¯ c|Ψ] o as τ (H ′ , (R, s, d ′ pc , d ipc , d if ), d g ) where H ′ = H{d → t ′ } d = get((H, R, s), o) t ′ = pack [¯ c|Ψ] .
H(d) unpack o with ∆ (H ′ , (R, s, d ′ pc , d ipc , d if ), d g ) where H ′ = H{d → t ′ } d = get((H, R, s), o) H(d) = pack [¯ c|Ψ] .
t ′ block (H, (R, s, d ′ pc , d ipc , d if ), pid ) unblock (H, (R, s, d ′ pc , d ipc , d if ), 0) where d ′ pc = d pc + 1For example, the typing rule MOV indicates that the heap type of the shared memory between processors (Ψ s ) has to be included in that of the heaps updated with the mov instruction (denoted as ∆, C ⊢ Φ ′ → Ψ s ) if the atomic flag may have the value 0.
In addition, the rule also indicates that the heap type of the shared memory between the interrupt handler and the interrupted program (Ψ b ) has to be included in that of the updated heaps (∆, C ⊢ Φ ′ → Ψ b ) if the interrupt flag may be non-zero.
The typing rule UNBLOCK indicates that the heap type of the shared memory (Ψ s ) has to be included in that of the whole heaps because unblock clears the atomic flag, that is, finishes an atomic memory operation and the other processors may access the shared memory.
In other words, the strong updates are allowed after an atomic memory operation begins with block , but the heap types updated with the strong updates have to be reverted before the atomic memory operation finishes with unblock .
Please note that the number of addresses is fixed in the shared memory (Ψ s ), but an arbitrary number of memory regions can be handled by packing them to existentials.get((H, R, s), o) = d (if o is d) R(r) (if o is r) H(R(r))[c] (if o is [r + c]) s[c] (if o is [sp + c]) update((H, R, s), o, d) = H, R{r → d}, s (if o is r) H{R(r) → v ′ }, R, s (if o is [r + c])where Brief descriptions of each typing rule are as follows.
The rule STATE checks whether the heaps and the processors of the abstract machine state are well-typed.
In addition, it also checks whether a part of the heaps satisfies the heap type of the shared memory between the processors (Ψ s ) if the atomic flag is 0.
The rule PROCES-SOR checks whether the registers, the stack, the instruction sequence (H(d pc )) pointed by the program counter d pc , and the interrupt handler (H(d ipc )) are well-typed.
In addition, it also checks whether a part of the heaps satisfies the heap type of the shared memory between the interrupt handler and the interrupted program (Ψ b ) if the interrupt flag d if is non-zero.
The rule HEAP checks whether each element of the heap can be typed as a tuple or an instruction sequence, the rule REGISTER checks whether each register is well-typed, and the rule STACK checks whether each element of the stack is well-typed.
v = H(R(r)) v ′ = v[c → d] H, R, s[c → d] (if o is [sp + c])The rule MOV updates the type of the operand o 1 with that of the operand o 2 and checks the following instructions I.
In addition, as described above, it checks whether the heap type of the shared memory between the processors (Ψ s ) is included in the updated store type if it cannot be proved that the type of the atomic flag (i g ) is non-zero, and the heap type of the shared memory between the interrupt handler and the interrupt program (Ψ b ) is included in the updated store type if it cannot be proved that the type of the interrupt flag (i i ) is 0.
Thus, the heap type of the shared memory is preserved even if other processors manipulate it or the interrupts occur.The rule JMP checks whether the operand o has a label type and the store type Φ satisfies the store type Φ ′ specified in the label type (denoted as ∆, C ⊢ Φ ≤ Φ ′ ).
In addition, it checks whether the constraints C ′ can be satisfied and the types of the atomic flag and the interrupt flag specified in the label type is consistent with the current state (∆, C |= i i = i ′ i ∧ i g = i ′ g).
The rule BCC first checks whether the operands o 1 and o 2 have integer types and the operand o 3 has a label type.
Next, it performs the same check as the rule JMP under the assumption that the branch is taken (C ∧ i 1 cc i 2 ).
Finally, it checks the following instructions under the assumption that the branch is not taken (C ∧ ¬(i 1 cc i 2 )).
H ≡ H 1 . . . H n Ψ ≡ Ψ 1 . . . Ψ n ⊢ H i : Ψ i Ψ i ⊢ H P i : Γ i , σ i , d g d g = 0 ⇒⊢ H s : Ψ s where H s ⊆ H ⊢ (H, P , d g ) : (Ψ, (Γ, σ)) (STATE) ⊢ H(d pc ) : ·.
(Ψ, Γ, σ).
d if .
d g Ψ ⊢ s : σ ∆ ≡ α, ¯ γ, ǫ, ρ Ψ ′ ≡ Ψ b ǫ Γ ′ ≡ {r i → γ i } Φ ′ ≡ (Ψ ′ , Γ ′ , ρ) ⊢ H(d ipc ) : ∀∆.
· .
(Ψ ′ , Γ ′ , Φ ′ .
α.0 :: α :: ρ).0.0 d if 񮽙 = 0 ⇒⊢ H b : Ψ b where H b ⊆ H Ψ ⊢ H (R, s, d pc , d ipc , d if ) : Γ, σ, d g (PROCESSOR) ∀d ∈ Dom(H).
if H(d) = t then ⊢ t : Ψ(d) else if H(d) = ∀∆.
C.Φ.i i .
i g .
I then Ψ(d) = ∀∆, C, Φ, i i , i g ∆, C, Φ, i i , i g ⊢ I ⊢ H : Ψ (HEAP) ⊢ Γ ∀r i ∈ Dom(Γ).
Ψ ⊢ R(r i ) : Γ(r i ) Ψ ⊢ R : Γ (REGISTER) Ψ ⊢ d i : w i Ψ ⊢ dThe rule PUSH concatenates the type of the operand o to the stack type σ and checks the following instructions with the updated stack type.
Unlike the rule MOV, it is unnecessary to check the heap type of the shared memory because the stacks are not included in the shared memory and push does not modify the heap type.
The rule POP removes the word type w from the top of the stack type w :: σ.
In addition, it modifies the store type with respect to the operand o and checks the following instructions with the modified store type (Φ ′ ).
Unlike the rule PUSH, because pop may modify the heap type, it performs the same check as the rule MOV on the heap type of the shared memory.
The rule RET removes the word type from the top of the stack type and checks whether it is a label type and the conditions specified in the label type are satisfied by the store type, the constraints, and the interrupt flag of the current state.
As the rule PUSH, it is unnecessary to check the type of the shared memory because ret does not modify the heap type.The rule BLOCK checks the following instructions under the assumption that the atomic flag type is 1.
The rule UNBLOCK checks the following instructions under the assumption that the atomic flag type is 0.
It alsow ≡ get type(∆, C, Φ, o 2 ) Φ ′ ≡ update type(∆, C, Φ, o 1 , w) ∆, C |= i i = 0 ⇒ ∆, C ⊢ Φ ′ → Ψ b ∆, C |= i g 񮽙 = 0 ⇒ ∆, C ⊢ Φ ′ → Ψ s ∆, C, Φ ′ , i i , i g ⊢ I ∆, C, Φ, i i , i g ⊢ mov o 1 , o 2 ; I (MOV) C ′ .
Φ ′ .
i ′ i .
i ′ g ≡ get type(∆, C, Φ, o) ∆, C ⊢ Φ ≤ Φ ′ ∆, C |= C ′ ∆, C |= i i = i ′ i ∧ i g = i ′ g ∆, C, Φ, i i , i g ⊢ jmp o (JMP) i 1 ≡ get type(∆, C, Φ, o 1 ) i 2 ≡ get type(∆, C, Φ, o 2 ) C ′ .
Φ ′ .
i ′ i .
i ′ g ≡ get type(∆, C, Φ, o 3 ) ∆, C ∧ (i 1 cc i 2 ) ⊢ Φ ≤ Φ ′ ∆, C ∧ (i 1 cc i 2 ) |= C ′ ∆, C ∧ (i 1 cc i 2 ) |= i i = i ′ i ∧ i g = i ′ t ∆, C ∧ ¬(i 1 cc i 2 ), Φ, i i , i g ⊢ I ∆, C, Φ, i i , i g ⊢ bcc o 1 , o 2 , o 3 ; I (BCC) w ≡ get type(∆, C, (Ψ, Γ, σ), o) ∆, C, (Ψ, Γ, w :: σ), i i , i g ⊢ I ∆, C, (Ψ, Γ, σ), i i , i g ⊢ push o; I (PUSH) Φ ′ ≡ update type(∆, C, (Ψ, Γ, σ), o, w) ∆, C |= i i = 0 ⇒ ∆, C ⊢ Φ ′ → Ψ b ∆, C |= i g 񮽙 = 0 ⇒ ∆, C ⊢ Φ ′ → Ψ s ∆, C, Φ ′ , i i , i g ⊢ I ∆, C, (Ψ, Γ, w :: σ), i i , i g ⊢ pop o; I (POP) ∆, C ⊢ (Ψ, Γ, σ) ≤ Φ ∆, C |= C ′ ∆, C |= i i = i ′ i ∧ i g = i ′ g ∆, C, (Ψ, Γ, C ′ .
Φ.i ′ i .
i ′ g :: σ), i i , i g ⊢ ret (RET)Figure 11: Typing rules for the ordinary instructions checks whether the heap type of the shared memory (Ψ s ) is included in the store type Φ because other processors may access the shared memory after unblock .
The rule CLI checks the following instructions under the assumption that the interrupt flag type is equal to 0.
The rule STI checks the following instructions under the assumption that the interrupt flag type is equal to 1.
In addition, it also checks whether the heap type of the shared memory between the interrupt handler and the interrupted program (Ψ b ) is included in the store type Φ because interrupts may occur after sti .
The rule PUSHF concatenates the interrupt flag type i i to the stack type and checks the following instructions with the stack type.
As the rule PUSH, it is unnecessary to check the heap type of the shared memory Ψ b because pushf does not modify the heap type.
The rule POPF removes the word type from the top of the stack type and checks the following instructions under the assumptionget type(∆, C, (Ψ, Γ, σ), o) = d (if o is d) Γ(r) (if o is r) w d where ∆, C |= i = Γ(r) ∆, C |= C ′ ∆, C ⊢ Ψ = {i → . . . , w d , . . . if C ′ }Ψ ′ (if o is [r + d]) w dwhere σ = . . . ::w d :: . . . (if o is [sp + d]) update type(∆, C, (Ψ, Γ, σ), o, w) = (Ψ, Γ ′ , σ) where Γ ′ = Γ{r → w} (if o is r) (Ψ ′′ , Γ, σ) where ∆, C |= i = Γ(r) ∆, C |= C ′ ∆, C ⊢ Ψ = {i → . . . , w d , . . . if C ′ }Ψ ′ Ψ ′′ ≡ {i → . . . , w, . . . if C ′ }Ψ ′ (if o is [r + d]) (Ψ, Γ, σ ′ ) where σ = . . . :: w d :: . . . σ ′ = . . . :: w :: . . . (if o is [sp + d])Figure 12: Auxiliary functions for typing rules∆, C, Φ, i i , 1 ⊢ I ∆, C, Φ, i i , i g ⊢ block ; I (BLOCK) ∆, C ⊢ Φ → Ψ s ∆, C, Φ, i i , 0 ⊢ I ∆, C, Φ, i i , i g ⊢ unblock ; I (UNBLOCK)Figure 13: Typing rules for atomic memory operations that the interrupt flag set is set to the removed word type.
Unlike pop, popf does not modify the heap type.
However, it is necessary to check whether the heap type of the shared memory between the interrupt handler and the interrupted program Ψ b is included in the heap type Ψ if it cannot be proved that the interrupt flag type is equal to 0 because popf updates the interrupt flag.
The rule IRET is basically a combination of the rule RET and POPF.
The rule PACK first checks whether the type of the operand o is equal to the type which is instantiated from the existential type specified in pack by substituting the type variables (∆ ′ ) with the types ¯ c. Next, it checks whether the heap type Ψ 1 specified in the instruction is included in the heap type Ψ.
Finally, it checks the following instructions with the store type which excludes Ψ 1 under the assumption that the operand o has the specified existential type.
The rule UNPACK first checks whether the operand o has an existential type.
Then, it unpacks the constraints, the heap type and the tuple type, and checks the following instructions with them.
Although the formalization of Sec. 4 contains the notion of atomic memory operations, it does not consider mem- ∆, C, Φ, 0, i g ⊢ I ∆, C, Φ, i i , i g ⊢ cli ; I (CLI) ∆, C ⊢ Φ → Ψ b ∆, C, Φ, 1, i g ⊢ I ∆, C, Φ, i i , i g ⊢ sti; I (STI) ∆, C, (Ψ, Γ, i i :: σ), i i , i g ⊢ I ∆, C, (Ψ, Γ, σ), i i , i g ⊢ pushf ; I (PUSHF) ∆, C, (Ψ, Γ, σ), i ′ , i g ⊢ I ∆, C |= i ′ = 0 ⇒ ∆, C ⊢ Ψ ⊇ Ψ b ∆, C, (Ψ, Γ, i ′ :: σ), i i , i g ⊢ Ψs popf ; I (POPF) ∆, C ⊢ (Ψ, Γ, σ) ≤ Φ ∆, C |= i 1 = 0 ⇒ ∆, C ⊢ Ψ ⊇ Ψ b ∆, C |= C ′ ∆, C |= i 1 = i 2 ∧ i g = i ′ g ∆, C, (Ψ, Γ, (C ′ , Φ, i 2 , i ′ g ) :: i 1 :: σ), i i , i g ⊢ iret (IRET)Φ ≡ (Ψ, Γ, σ) τ ≡ ∃∆ ′ .
C ′ .
Ψ ′ .
τ ′ ∆, C ⊢ Ψ = Ψ 1 Ψ 2 ∆, C ⊢ Ψ 1 = Ψ ′ [¯ c/∆ ′ ] i ≡ get type(∆, C, (Ψ, Γ, σ), o) ∆, C ⊢ Ψ 2 = {i → τ ′ [¯ c/∆ ′ ]}Ψ ′ 2 Φ ′ ≡ ({i → τ }Ψ ′ 2 , Γ, σ) ∆, C |= C ′ [¯ c/∆ ′ ] ∆, C, Φ ′ , i i , i g ⊢ I ∆, C, Φ, i i , i g ⊢ pack [¯ c|Ψ1] o as τ ; I (PACK) Φ ≡ (Ψ, Γ, σ) i ≡ get type(∆, C, Φ, o) ∆, C ⊢ Ψ = {i → ∃∆ ′ .
C ′ .
Ψ ′ .
τ ′ }Ψ ′′ Ψ 1 ≡ {i → τ ′′ }Ψ ′′ C ′′ ≡ C ′ [∆ ′′ /∆ ′ ] Ψ 2 ≡ Ψ ′ [∆ ′′ /∆ ′ ] τ ′′ ≡ τ ′ [∆ ′′ /∆ ′ ] ∆∆ ′′ , C ∧ C ′′ , (Ψ 1 Ψ 2 , Γ, σ) ⊢ I ∆, C, Φ, i i , i g ⊢ unpack o with ∆ ′′ ; I (UNPACK)Figure 15: Typing rules related to the existential types ory consistency (except for the sequential consistency).
Roughly speaking, in the relaxed consistency models, effects of memory operations performed by one processor can be observed in a different order by the other processors.
Thus, memory barrier operations have to be used explicitly for ensuring consistency of shared memory.
For example, the release consistency model, which is adopted by the many recent CPUs, is equipped with two barriers: acquire, which ensures that all the processors do not observe effects of all its succeeding operations, and release, which ensures that all the processors observe effects of all its preceding operations [1].
From the viewpoint of the release consistency, all we have to do is to figure out when the two barriers are necessary.
More specifically, acquire has to be performed when the unpack operation extracts memory regions from existential types in shared memory, and release has to be performed when the pack operation encapsulates them to shared memory.
For example, in Fig. 1, acquire is necessary between line 7 and 8, and release is necessary between line 20 and 21.
Please note that the barriers are unnecessary at line 9 and 19 because no memory regions are encapsulated or extracted.
In addition, please also note that the acquire and xchg operations, and the release and mov operations can be performed atomically in the recent CPUs (e.g., the Intel Architecture [11]).
Although there exist several works [6,12,8,7] that deal with synchronization mechanisms at the level of highlevel programming languages, their main goal is to prevent race conditions, deadlocks and so on, and they assume the synchronization mechanisms as language primitives.
Therefore, they cannot be used for implementing the synchronization mechanisms themselves, while our TAL can be used to implement the mechanisms only relying on atomic instructions of CPU.
Cyclone introduced a swap operation for pointers as a language primitive in order to keep track of aliases by ensuring uniqueness of pointers [9].
Our TAL is more expressive in the sense that the swap operation can be implemented as a combination of block , unblock and memory operations.Vasconcelos et al. presented a variant of TAL for supporting synchronization locks in the SMP/multi-core environments [17].
However, their TAL treats the locks and the lock operations as the language primitives, so it cannot be used for implementing the locks themselves and ensuring their memory safety.
On the other hand, our TAL is expressive enough to directly implement the locks and their lock operations as shown in Sec. 3.
Moreover, in their TAL, thread cloning is also provided as the language primitives, while we are able to implement the multi-thread management facility in our TAL (by incorporating our previous works [14,15]).
Feng et al. [4] showed an approach of manually verifying properties of synchronization primitives under the existence of the interrupts by using a proof assistant.
While our approach verifies simple type safety (the memory safety and the control-flow safety) mechanically through type checking, their approach can be applied to verification of a more wide range of properties.
However, SMP is not considered explicitly in their approach.
This paper presented a typed assembly language which is expressive enough to implement synchronization primitives in the SMP/multi-core environments with the CPU hardware interrupts.
This paper also illustrated how to implement the spin locks, which are essential for implementing OS kernels.
Our future work is to formalize memory consistency models (by utilizing, e.g., [3,5]) and implement more complex synchronization primitives (e.g., readers-writer locks and read-copy-update).
