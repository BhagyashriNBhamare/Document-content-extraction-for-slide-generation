New and unseen polymorphic malware, zero-day attacks, or other types of advanced persistent threats are usually not detected by signature-based security devices, fire-walls, or anti-viruses.
This represents a challenge to the network security industry as the amount and variability of incidents has been increasing.
Consequently, this complicates the design of learning-based detection systems relying on features extracted from network data.
The problem is caused by different joint distribution of observation (features) and labels in the training and testing data sets.
This paper proposes a classification system designed to detect both known as well as previously-unseen security threats.
The classifiers use statistical feature representation computed from the network traffic and learn to recognize malicious behavior.
The representation is designed and optimized to be invariant to the most common changes of malware behaviors.
This is achieved in part by a feature histogram constructed for each group of HTTP flows (proxy log records) of a user visiting a particular hostname and in part by a feature self-similarity matrix computed for each group.
The parameters of the representation (histogram bins) are optimized and learned based on the training samples along with the classifiers.
The proposed classification system was deployed on large corporate networks, where it detected 2,090 new and unseen variants of malware samples with 90% precision (9 of 10 alerts were malicious), which is a considerable improvement when compared to the current flow-based approaches or existing signature-based web security devices.
Current network security devices classify large amounts of the malicious network traffic and report the results in many individually-identified incidents, some of which are false alerts.
On the other hand, a lot of malicious traffic remains undetected due to the increasing variability of malware attacks.
As a result, security analysts might miss severe complex attacks because the incidents are not correctly prioritized or reported.The network traffic can be classified at different levels of detail.
Approaches based on packet inspection and signature matching [15] rely on a database of known malware samples.
These techniques are able to achieve results with high precision (low number of false alerts), but their detection ability is limited only to the known samples and patterns included in the database (limited recall).
Moreover, due to the continuous improvements of network bandwidth, analyzing individual packets is becoming intractable on high-speed network links.
It is more efficient to classify network traffic based on flows representing groups of packets (e.g. NetFlow [1] or proxy logs [26]).
While this approach has typically lower precision, it uses statistical modeling and behavioral analysis [8] to find new and previously unseen malicious threats (higher recall).
Statistical features calculated from flows can be used for unsupervised anomaly detection, or in supervised classification to train data-driven classifiers of malicious traffic.
While the former approach is typically used to detect new threats, it suffers from lower precision which limits its practical usefulness due to large amount of false alerts.
Data-driven classifiers trained on known malicious samples achieve better efficacy results, but the results are directly dependent on the samples used in the training.
Once a malware changes the behavior, the system needs to be retrained.
With continuously rising number of malware variants, this becomes a major bottleneck in modern malware detection systems.
Therefore, the robustness and invariance of features extracted from raw data plays the key role when classifying new malware.The problem of changing malware behavior can be formalized by recognizing that a joint distribution of the malware samples (or features) differs for already known training (source) and yet unseen testing (target) data.This can happen as a result of target evolving after the initial classifier or detector has been trained.
In supervised learning, this problem is solved by domain adaptation.
Under the assumption that the source and target distributions do not change arbitrarily, the goal of the domain adaptation is to leverage the knowledge in the source domain and transfer it to the target domain.
In this work, we focus on the case where the conditional distribution of the observation given labels is different, also called a conditional shift.The domain adaptation (or knowledge transfer) can be achieved by adapting the detector using importance weighting such that training instances from the source distribution match the target distribution [37].
Another approach is to transform the training instances to the domain of the testing data or to create a new data representation with the same joint distribution of observation and labels [4].
The challenging part is to design a meaningful transformation that transfers the knowledge from the source domain and improves the robustness of the detector on the target domain.In this paper, we present a new optimized invariant representation of network traffic data that enables domain adaptation under conditional shift.
The representation is computed for bags of samples, each of which consists of features computed from network traffic logs.
The bags are constructed for each user and contain all network communication with a particular hostname/domain.
The representation is designed to be invariant under shifting and scaling of the feature values and under permutation and size changes of the bags.
This is achieved by combining bag histograms with an invariant self similarity matrix for each bag.
All parameters of the representation are learned automatically for the training data using the proposed optimization approach.The proposed invariant representation is applied to detect malicious HTTP traffic.
We will show that the classifier trained on malware samples from one category can successfully detect new samples from a different category.
This way, the knowledge of the malware behavior is correctly transferred to the new domain.
Compared to the baseline flow-based representation or widely-used security device, the proposed approach shows considerable improvements and correctly classifies new types of network threats that were not part of the training data.This paper has the following major contributions:• Classifying new malware categories -we propose a supervised method that is able to detect new types of malware categories from a limited amount of training samples.
Unlike classifying each category separately, which limits the robustness, we propose an invariant training from malware samples of multiple categories.
• Bag representation of samples -Instead of classifying flows individually, we propose to group flows into bags, where each bag contains flows that are related to each other (e.g. having the same user and target domain).
Even though the concept of grouping flows together has been already introduced in the previously published work (e.g. in [32]), these approaches rely on a sequence of flow-based features rather than on more complex representation.
• Features describing the dynamics of the samples -To enforce the invariant properties of the representation, we propose to use a novel approach, where the features are derived from the self-similarity of flows within a bag.
These features describe the dynamics of each bag and have many invariant properties that are useful when finding new malware variants and categories.
• Learning the representation from the training data -To optimize the parameters of the representation, we propose a novel method that combines the process of learning the representation with the process of learning the classifier.
The resulting representation ensures easier separation of malicious and legitimate communication and at the same time controls the complexity of the classifier.
• Large scale evaluation -We evaluated the proposed representation on real network traffic of multiple companies.
Unlike most of the previously published work, we performed the evaluation on highly imbalanced datasets as they appear in practice (considering the number of malicious samples), with most of the traffic being legitimate, to show the potential of the approach in practice.
This makes the classification problem much harder.
We provided a comparison with state-of-the-art approaches and a widely-used signature-based web security device to show the advantages of the proposed approach.
Network perimeter can be secured by a large variety of network security devices and mechanisms, such as host-based or network-based Intrusion Detection Systems (IDS) [36].
We briefly review both systems, focusing our discussion on network-based IDS, which are the most relevant to the presented work.Host-based IDS systems analyze malicious code and processes and system calls related to OS information.
Traditional and widely-used anti-virus software or spyware scanners can be easily evaded by simple transformations of malware code.
To address this weakness, methods of static analysis [30], [38] were proposed.
Static analysis, relying on semantic signatures, concentrates on pure investigation of code snippets without actually executing them.
These methods are more resilient to changes in malware codes, however they can be easily evaded by obfuscation techniques.
Methods of dynamic analysis [29], [34], [42] were proposed to deal with the weaknesses of static analysis, focusing on obtaining reliable information on execution of malicious programs.
The downside of the dynamic analysis is the necessity to run the codes in a restricted environment which may influence malware behavior or difficulty of the analysis and tracing the problem back to the exact code location.
Recently, a combination of static and dynamic analysis was used to analyze malicious browser extensions [20].
Network-based IDS systems are typically deployed on the key points of the network infrastructure and monitor incoming and outgoing network traffic by using static signature matching [15] or dynamic anomaly detection methods [8].
Signature-based IDS systems evaluate each network connection according to the predefined malware signatures regardless of the context.
They are capable of detecting well-known attacks, but with limited amount of detected novel intrusions.
On the other hand, anomalybased IDS systems are designed to detect wide range of network anomalies including yet undiscovered attacks, but at the expense of higher false alarm rates [8].
Network-based approaches are designed to detect malicious communication by processing network packets or logs.
An overview of the existing state-of-the-art approaches is shown in Table 1.
The focus has been on the traffic classification from packet traces [5], [28], [39], [41], as this source provides detailed information about the underlying network communication.
Due to the still increasing demands for larger bandwidth, analyzing individual packets is becoming intractable on high-speed network links.
Moreover, some environments with highly confidential data transfers such as banks or government organizations do not allow deployment of packet inspection devices due to the legal or privacy reasons.
The alternative approach is the classification based on network traffic logs, e.g. NetFlow [1], DNS records, or proxy logs.
The logs are extracted at the transport layer and contain information only from packet headers.Methods introduced in [12] and [23] apply features extracted from NetFlow data to classify network traffic into general classes, such as P2P, IMAP, FTP, POP3, DNS, IRC, etc.
A comparison and evaluation of these approaches can be found in a comprehensive survey [24].
A combination of host-based statistics with SNORT rules to detect botnets was introduced in [16].
The authors showed that it is possible to detect malicious traffic using statistical features computed from NetFlow data, which motivated further research in this field.
An alternative approach for classification of botnets from NetFlow features was proposed in [6].
The authors of [33] have used normalized NetFlow features to cluster flow-based samples of network traffic into four predefined categories.
As opposed to our approach, the normalization was performed to be able to compare individual features with each other.
In our approach, we extended this idea and use normalization to be able to compare various malware categories.
While all these approaches represent relevant state-of-the-art, network threats evolve so rapidly that these methods are becoming less effective due to the choice of features and the way they are used.One of the largest changes in the network security landscape is the fact that HTTP(S) traffic is being used not only for web browsing, but also for other types of services and applications (TOR, multimedia streaming, remote desktop) including lots of malicious attacks.
According to recent analysis [18], majority of malware samples communicate via HTTP.
This change has drawn more attention to classifying malware from web traffic.
In [25], the authors proposed an anomaly detection system composed of several techniques to detect attacks against web servers.
They divide URIs into groups, where each group contains URIs with the same resource path.
URIs without a query string or with return code outside of interval [200,300] are considered as irrelevant.
The system showed the ability to detect unseen malware samples and the recall will be compared with our proposed approach in Section 8.
In [40], the authors introduced a method for predicting compromised websites using features extracted from page content and Alexa Web Information Service.Having sufficient amount of labeled malware samples at disposal, numerous approaches proposed supervised learning methods to achieve better efficacy.
Clasifying DGA malware from DNS records based on connections to non-existent domains (NXDomains) was proposed in [2].
Even though several other data sources were used to detect malware (such as malware executions [3] or JavaScript analysis [22]), the most relevant work to our approach uses proxy logs [9], [17], [27], [44], [32].
In all these methods, proxy log features are extracted from real legitimate and malicious samples to train a data-driven classifier, which is used to find new malicious samples from the testing set.
There are five core differences between these approaches and our approach: (1) we do not classify individual flows (in our case proxy log records), but sets of related flows called bags, (2) we propose a novel representation based on features describing the dynamics of each bag, (3) the features are computed from the bags and are invariant against various changes an attacker could implement to evade detection, (4) parameters of the proposed representation are learned automatically from the input data to maximize the detection performance, (5) the proposed classification system Table 1: Overview of the existing state-of-the-art approaches focusing on classification of malicious traffic (U = unsupervised, S = supervised).
In contrast to the existing work, our approach proposes novel and optimized representation of bags, describing the dynamics of each legitimate or malicious sample.
The approach is evaluated on latest real datasets with a realistic ratio of malicious and background flows (proxy log records).
was deployed on corporate networks and evaluated on imbalanced datasets (see Table 1) as they appear in practice to show the expected efficacy on these networks.
The paper deals with the problem of creating a robust representation of network communication that would be invariant against modifications an attacker can implement to evade the detection systems.
The representation is used to classify network traffic into positive (malicious) or negative (legitimate) category.
The labels for positive and negative samples are often very expensive to obtain.
Moreover, sample distribution typically evolves in time, so the probability distribution of training data differs from the probability distribution of test data.
This complicates the training of classifiers which assume that the distributions are the same.
In the following, the problem is described in more detail.
Each sample is represented as an n-dimensional feature vector x ∈ R n .
Samples are grouped into bags, with every bag represented as a matrix X = (x 1 ,.
.
.
,x m ) ∈ R n×m , where m is the number of samples in the bag and n is the number of features.
The bags may have different number of samples.
A single category y i can be assigned to each bag from the set Y = {y 1 ,.
.
.
,y N }.
Only a few categories are included in the training set.
The probability distribution on training and testing bags for category y j will be denoted as P L (X|y j ) and P T (X|y j ), respectively.
Moreover, the probability distribution of the training data differs from the probability distribution of the testing data, i.e. there is a domain adaptation problem [7] (also called a conditional shift [43]):P L (X|y j ) 񮽙 = P T (X|y j ), ∀y j ∈ Y .
(1)The purpose of the domain adaptation is to apply knowledge acquired from the training (source) domain into test (target) domain.
The relation between P L (X|y i ) and P T (X|y i ) is not arbitrary, otherwise it would not be possible to transfer any knowledge.
Therefore there is a transformation τ, which transforms the feature values of the bags onto a representation, in which P L (τ(X)|y i ) ≈ P T (τ(X)|y i ).
The goal is to find this representation, allowing to classify individual bag represented as X into categories Y = {y 1 ,.
.
.
,y N } under the above mentioned conditional shift.Numerous methods for transfer learning have been proposed (since the traditional machine learning methods cannot be used effectively in this case), including kernel mean matching [14], kernel learning approaches [11], maximum mean discrepancy [19], or boosting [10].
These methods try to solve a general data transfer with relaxed conditions on the similarity of the distributions during the transfer.
The downside of these methods is the necessity to specify the target loss function and availability of large amount of labeled data.This paper proposes an effective invariant representation that solves the classification problem with a covariate shift (see Equation 1).
Once the data are transformed, the new feature values do not rely on the original distribution and they are not influenced by the shift.
The parameters of the representation are learned automatically from the data together with the classifier as a joint optimization process.
The advantage of this approach is that the parameters are optimally chosen during training to achieve the best classification efficacy for the given classifier, data, and representation.
The problem of domain adaptation outlined in the previous section is addressed by the proposed representation of bags.
The new representation is calculated with a transformation that consists of three steps to ensure that the new representation will be invariant under scaling and shifting of the feature values and under permutation and size changes of the bags.
As stated in Section 3, the probability distribution of bags from the training set can be different from the test set.
In the first step, the representation of bags is transformed to be invariant under scaling of the feature values.
The traditional representation X of a bag that consists of a set of m samples {x 1 ,.
.
.
,x m } can be written in a form of a matrix:X =    x 1 . . . x m    =    x 11 x 12 ... x 1n .
.
.
x m1 x m2 ... x mn    ,(2)where x lk denotes k-th feature value of l-th sample.
This form of representation of samples and bags is widely used in the research community, as it is straightforward to use and easy to compute.
It is a reasonable choice in many applications with a negligible shift in the source and target probability distributions.
However, in the network security domain, the dynamics of the network environment causes changes in the feature values and the shift becomes more prominent.
As a result, the performance of the classification algorithms using the traditional representation is decreased.
In the first step, the representation is improved by making the matrix X to be invariant under scaling of the feature values.
Scale invariance guarantees that even if some original feature values of all samples in a bag are multiplied by a common factor, the values in the new representation remain unchanged.
To guarantee the scale invariance, the matrix X is scaled locally onto the interval [0,1] as follows:˜ X =    ˜ x 11 ... ˜ x 1n . . . ˜ x m1 ... ˜ x mn    ˜ x lk = x lk − min l (x lk ) max l (x lk ) − min l (x lk ) (3) In the second step, the representation is transformed to be invariant against shifting.
Shift invariance guaranties that even if some original feature values of all samples in a bag are increased/decreased by a given amount, the values in the new representation remain unchanged.
Let us define a translation invariant distance function d : R× R → R for which the following holds:d(u, v) = d(u + a, v + a).
Let x pk , x qk be k-th feature values of p-th and q-th sample from bag matrix X.
Then the distance between these two values will be denoted as d(x pk , x qk ) = s k pq .
The distance d(x pk , x qk ) is computed for pairs of k-th feature value for all sample pairs, ultimately forming a so called self-similarity matrix S k .
Self-similarity matrix is a symmetric positive semidefinite matrix, where rows and columns represent individual samples and (i, j)-th element corresponds to the distance between i-th and jth sample.
Self-similarity matrix has been already used thanks to its properties in several applications (e.g. in object recognition [21] or music recording [31]).
However, only a single self-similarity matrix for each bag has been used in these approaches.
This paper proposes to compute a set of similarity matrices, one for every feature.
More specifically, a per-feature set of self-similarity matrices S = {S 1 , S 2 ,.
.
.
,S n } is computed for each bag, whereS k =    s k 11 s k 12 ... s k 1m . . . s k m1 s k m2 ... s k mm    .
(4)The element s k pq = d(x pk , x qk ) is a distance between feature values x pk and x qk of k-th feature.
This means that the bag matrix X with m samples and n features will be represented with n self-similarity matrices of size m × m.
The matrices are further normalized by local feature scaling described in Section 4.1 to produce a set of matrices˜S matrices˜ matrices˜S .
The shift invariance makes the representation robust to the changes where the feature values are modified by adding or subtracting a fixed value.
For example, the length of a malicious URL would change by including an additional subdirectory in the URL path.
Or, the number of transfered bytes would increase when an additional data structure is included in the communication exchange.
Representing bags with scaled matrices { ˜ X} and sets of locally-scaled self-similarity matrices { ˜ S } achieves the scale and shift invariance.
Size invariance ensures that the representation is invariant against the size of the bag.
In highly dynamic environments, the samples may occur in a variable ordering.
Permutation invariance ensures that the representation should also be invariant against any reordering of rows and columns of the matrices.
The final step of the proposed transformation is the transition from the scaled matrices˜Xmatrices˜ matrices˜X, ˜ S (introduced in Sec- z = (z 1 ,.
.
.
,z d ) ∈ R d is a function φ : R d × R b+1 → R b parametrized by edges of b bins θ = (θ 0 ,.
.
.
,θ b ) ∈ R b+1 such that φ (z; θ ) = (φ (z; θ 0 , θ 1 ),.
.
.
,φ (z; θ b−1 , θ b )) where φ (z, θ i , θ i+1 ) = 1 d d ∑ j=1 [[z j ∈ [θ i−1 , θ i )]]is the value of the i-th bin corresponding to a portion of components of z falling to the interval[θ i−1 , θ i ).
Each column k of matrix˜Xmatrix˜ matrix˜X (i.e. all bag values of k-th feature) is transformed into a histogram φ (z X k , θ X k )with predefined number of b bins and θ X k bin edges.
Such histograms created from the columns of matrix˜Xmatrix˜ matrix˜X will be denoted as feature values histograms, because they carry information about the distribution of bag feature values.
On the other hand, histogram φ (z S k , θ S k ) created from values of self-similarity matrix˜Smatrix˜ matrix˜S j ∈ ˜ S will be called feature differences histograms, as they capture inner feature variability within bag samples.Overall, each bag is represented as a concatenated feature map φ ( ˜ X; ˜ S ; θ ) : R n×(m+r) → R 2·n·b as follows:񮽙 φ (z X 1 , θ X 1 ),...,φ (z X n , θ X n ), φ (z S 1 , θ S 1 ),...,φ (z S n , θ S n ) 񮽙 (5)where n is the number of the original flow-based features, m is the number of flows in the bag, and b is the number of bins.
The whole transformation from input network flows to the final feature vector is depicted in Figure 1.
As you can see, two types of invariant histograms are created from values of each flow-based feature.
At the end, both histograms are concatenated into the final bag representation φ ( ˜ X; ˜ S ; θ ).
The bag representation φ ( ˜ X; ˜ S ; θ ) proposed in Section 4 has the invariant properties, however it heavily depends on the number of bins b and their edges θ defining the width of the histogram bins.
These parameters that were manually predefined in Section 4 C influence the classification performance.
Incorrectly chosen parameters b and θ leads to suboptimal efficacy results.
To define the parameters optimally, we propose a novel approach of learning these parameters automatically from the training data in such a way to maximize the classification separability between positive and negative samples.When creating histograms in Section 4 C, the input instances are vectors z X k and z S k , where k ∈ {1,.
.
.
,n}.
The algorithm transforms the input instances into a concatenated histogram φ ( ˜ X; ˜ S ; θ ).
To keep the notation simple and concise, we will denote the input instances simply asz = (z 1 ,.
.
.
,z n ) ∈ R n×m (instead of z = (z X 1 ,.
.
.
,z X n , z S 1 ,.
.
.
,z S n )), which is a sequence of n vectors each of dimension m.The input instance z is represented via a feature map φ : R n×m → R n·b defined as a concatenation of the normalized histograms of all vectors in that sequence, that is, φ (z; θ ) = (φ (z 1 ; θ 1 ),.
.
.
,θ (z n ; θ n )), where θ = (θ 1 ,.
.
.
,θ n ) denotes bin edges of all normalized histograms stacked to a single vector.We aim at designing a classifier h : R n×m × R n+1 × R n(b+1) → {−1, +1} working on top of the histogram representation, that ish(z; w, w 0 , θ ) = sign(񮽙φ (z, w)񮽙 + w 0 ) = sign 񮽙 n ∑ i=1 b ∑ j=1 φ (z i , θ i, j−1 , θ i, j )w i, j + w 0 񮽙 .
(6)The classifier (6) is linear in the parameters (w, w 0 ) but non-linear in θ and z.
We are going to show how to learn parameters (w, w 0 ) and implicitly also θ via a convex optimization.Assume we are given a training set of examples {(z 1 , y 1 ),.
.
.
,(z m , y m )} ∈ (R n×m × {+1, −1}) m .
We fix the representation φ such that the number of bins b is sufficiently large and the bin edges θ are equally spaced.
We find the weights (w, w 0 ) by solvingmin w∈R b·p ,w 0 ∈R 񮽙 γ n ∑ i=1 b−1 ∑ j=1 |w i, j − w i, j+1 | + 1 m m ∑ i=1 max 񮽙 0, 1 − y i 񮽙φ (z i ; θ ), w񮽙} 񮽙 .
(7)The objective is a sum of two convex terms.
The second term is the standard hinge-loss surrogate of the training classification error.
The first term is a regularization encouraging weights of neighboring bins to be similar.
If it happens that j-th and j + 1 bin of the i-the histogram have the same weight, w i, j = w i, j+1 = w, then these bins can be effectively merged to a single bin becausew i, j φ (z i ; θ i, j−1 , θ i, j ) + w i, j+1 φ (z i ; θ i, j , θ i, j+1 ) = 2wφ (z i ; θ i, j−1 , θ i, j+1 ) .
(8)The trade-off constant γ > 0 can be used to control the number of merged bins.
A large value of γ will result in massive merging and consequently in a small number of resulting bins.
Hence the objective of the problem (7) is to minimize the training error and to simultaneously control the number of resulting bins.
The number of bins influences the expressive power of the classifier and thus also the generalization of the classifier.
The optimal setting of λ is found by tuning its value on a validation set.Once the problem (7) is solved, we use the resulting weights w * to construct a new set of bin edges θ * such that we merge the original bins if the neighboring weights have the same sign (i.e. if w * i, j w * i, j+1 > 0).
This implies that the new bin edges θ * are a subset of the original bin edges θ , however, their number can be significantly reduced (depending on γ) and they have different widths unlike the original bins.
Having the new bins defined, we learn a new set of weights by the standard SVM algorithm min w∈R n ,w 0 ∈R 񮽙 λ 2 񮽙w񮽙 2 + 1 m m ∑ i=1 max 񮽙 0, 1 − y i 񮽙φ (z i ; θ * ),(z S k , θ S k ).
Since φ (z X k , θ X k ) is not invariant against shift, you can see that half of the values of φ (z X k , θ X k ) are different.
Still, φ (z X k , θ X k )values may play an important role when separating malware samples from other legitimate traffic.Note that we could add the quadratic regularizer λ 2 񮽙w񮽙 2 to the objective of (7) and learn the weights and the representation in a single stage.
However, this would require tuning two regularization parameters (λ and γ) simultaneously which would be order of magnitude more expensive than tuning them separately in the two stage approach.
This Section illustrates how the proposed representation (nonoptimized version) is calculated for two real-world examples of malicious behavior.
Namely, two versions of a polymorphic malware Sality are compared.
Sality [13] is a malware family that has become a dynamic and complex form of malicious infection.
It utilizes polymorphic techniques to infect files of Widows machines.
Signature-based systems or classifiers trained on a specific malware type often struggles with detecting new variants of this kind of malware.
Note that most of the conclusions to the discussion that follows can be drawn for many other malware threats.
To enhance the robustness of the flow-based features, the proposed approach computes histograms of feature values φ (z X k , θ X k ) and feature differences φ (z S k , θ S k ) (3) as described in Section 4.3.
To make the illustration simple, only four bins for each histogram were used.
Finally, all histograms are concatenated into the final feature vector (4).
It can be seen that even though the malware samples are from two different versions, they have the same histogram of feature differencesφ (z S k , θ S k ).
Since the histogram of feature values φ (z X k , θ X k ) is not invariant against shift, half of the values of φ (z X k , θ X k ) are different.The number of histogram bins and their sizes are then learned from the data by the proposed algorithm (see Section 5).
The proposed representation describes inner dynamics of flows from each bag, which is a robust indicator of malware samples, as we will show in the analysis of various malware families in Section 8.
In contrast to the existing methods that use flow-based features or general statistics such as mean or standard deviation, the proposed representation reflects properties that are much more difficult for an attacker to evade detection.
This section discusses evasion options for an attacker when trying to evade a learning-based classification system.
According to the recent work [35], the essential components for an evasion are: (1) the set of features used by the classifier, (2) the training dataset used for training, (3) the classification algorithm with its parameters.
Without the knowledge of the features, the attacker is faced with major challenges and there is not any known technique for addressing them [35].
Acquire knowledge of classification algorithm with its parameters or the training data is hard if not impossible.
Therefore, in the following analysis, we assume that only the features are known to the attacker.
When classifying HTTP traffic from proxy logs, it is actually not difficult to create a set of common features widely used in practice.
These features are the baseline flow-based features, such as those described in Table 3.
When the attacker performs a mimicry attack, selected features of malicious flows are modified to mimic legitimate traffic (or flows marked as benign by the classifier).
In the following, we will analyze the case when the attacker performs a mimicry attack to evade detection by modifying flow attributes, such as URLs, bytes, and inter-arrival times.
Other flow attributes can be altered in a similar way with analogical results.
All modifications are divided into two groups, depending on whether the proposed representation is invariant against them.The proposed representation is invariant to the following changes.
• Malicious code, payload, or obfuscation -The advantage of all network-based security approaches is that they extract features from headers of network communication rather than from the content.
As a result, any changes to the payload including the usage of pluggable transports designed to bypass Deep Packet Inspection (DPI) devices will have no effect on the features.
Some pluggable transports (e.g. ScrambleSuit) are able to change its network fingerprint (packet length distribution, number of bytes, inter-arrival times, etc.).
Since the proposed representation mainly relies on the dynamics of URLs of flows in the bag, such changes will not negatively impact the efficacy, which is a great advantage against DPI devices.
• Server or hostname -The representation operates at the level of bags, where each bag is a set of flows with the same user and hostname/domain.
If an attacker changes an IP address or a hostname of the remote server (because the current one has been blacklisted), the representation will create a new bag with similar feature values as in the previous bag with the original IP address or hostname, which is a great advantage against feeds and blacklists that need to be updated daily and are always behind.
• URL path or filename -Straightforward and easy way of evading existing classifiers using flow-based features or URL patterns is the change in path or filename from sample to sample.
Since the variability of these features remains constant within each bag, these changes will also have no effect on the proposed representation.
• Number of URL parameters, their names or values -This is an alternative to URL path changes.
• Encoded URL content -Hiding information in the URL string represents another way to exfiltrate sensitive data.
When the URL is encrypted and encoded (e.g. with base64), it changes the URL length and may globally influence other features as well.As the proposed representation is invariant against shifting, changing the URL length will not change the histograms of feature differences.
• Number of flows -Another option for an attacker to hide in the background traffic is increasing or reducing the number of flows related to the attack.
Such modification of the attack does not affect the representation, as long as there are enough flows to create the feature vectors.
• Time intervals between flows -This feature has been used in many previous approaches for its descriptive properties.
It is an alternative way to the proposed representation how to model a relationship between individual flows.
Our analysis revealed that current malware samples frequently modify the inter-arrival time to remain hidden in the background traffic -see Figure 3 for details.
Therefore, we do not rely on this unstable feature that can be also influenced by network delays or failures.
• Ordering of flows -An attacker can easily change the ordering of flows to evade detection based on patterns or predefined sequences of flows.
For the proposed representation the ordering of flows does not matter.The proposed representation is not invariant to the following changes.
• Static behavior -The representation does not model malware behaviors, where all flows associated with a malware are identical.
Such behavior has no dynamics and can be classified with flowbased approaches with comparable results.
In our dataset, only 10% of flows were removed because of this constrain.
• Multiple behaviors in a bag -In case more behaviors are associated with a bag, such as when a target hostname is compromised and communicates with a user with legitimate and malicious flows at once, the representation does not guarantee the invariance against the attacker's changes.
Such bags contain a mixture of legitimate and malicious flows and their combination could lead to a different representation.
Note that there wasn't any malware sample in our data that would satisfy this condition, since the legitimate traffic has to be authentic (not artificially injected) to confuse the representation.
• of flow-based features can be used, which reduces the discriminative properties of the representation.
However, majority of malware communication is still over HTTP protocol, because switching to HTTPS would harm the cyber-criminals' revenues due to problems with signed certificates [18].
• Real-time changes and evolution -In case a malware sample for a given user and hostname would start changing its behavior dynamically and frequently, the bag representation will vary in time.
Such inconsistency would decrease the efficacy results and enlarge the time to detect.
However, creating such highly dynamic malware behavior requires a considerable effort, therefore we do not see such samples very often in the real network traffic.We conclude our analysis with the observation, that attackers change flow features very frequently (see Fig- ure 3).
The goal of the proposed representation is to be invariant against most of the changes to successfully detect new, previously unseen malware variants.
The proposed approach was deployed on the top of proxy logs exporters in companies of various types and sizes to detect unseen malware samples.
The system architecture is shown in Figure 4.
Collector connected to a proxy server stores incoming and outgoing network traffic in form of proxy log records.
The proxy logs represent information about individual HTTP/HTTPS connections or flows.
Each 5-minute interval, the proxy logs are sent to the detection engine, where the proposed method detects the malicious behaviors.
Report created from the malicious behaviors is then displayed on a console to an operator.
The next section provides the specification of datasets and malware categories, followed by the results from the experimental evaluation.
Next section provides the specification of datasets and malware categories, followed by the results from the experimental evaluation.
The data was obtained from several months (JanuaryJuly 2015) of real network traffic of 80 international Figure 4: Overview of the system architecture.
Collector connected to a proxy server stores incoming and outgoing network traffic in form of proxy log records.
Each 5-minute interval, the proxy logs are sent to the detection engine and the results are displayed to an operator on the reporting console.companies of various sizes in form of proxy logs [26].
The logs contain HTTP/HTTPS flows, where one flow is one connection defined as a group of packets from a single host and source port with a single server IP address, port, and protocol.
Summary of the datasets used in the evaluation is described in Table 2.
Malware samples will be referred as positive bags, where one positive bag is a set of records (connections) with the same source towards the same destination.
The bags not labeled as malicious are considered as legitimate/negative.
Each bag should contain at least 5 flows to be able to compute a meaningful histogram representation.
Training dataset contains 5k malicious (8 malware families) and 27k legitimate bags, while testing dataset is consist of 2k malicious (񮽙 32 malware families) and 241k legitimate bags (more than 15 million flows).
Positive samples for training were acquired using many types of publicly available feeds, services, and blacklists, while the results on the testing data were analyzed manually by security experts.
Each HTTP flow consists of the following fields: user name, srcIP, dstIP, srcPort, dstPort, protocol, number of bytes, duration, timestamp, user agent, and URL.
From these flow fields, we extracted 115 flowbased features typically used in the prior art (Table 3).
This means that training and testing data are composed of completely different malware bags from different malware families, which makes the classification problem much harder.
This scenario simulates the fact that new types of threats are created to evade detection.
The benchmarking signature-based network security device (widely used in many companies) was able to detect only 2% of the malicious bags from the testing set.
Training a classifier for each category separately is an easier task, however such classifiers are typically overfitted to a single category and cannot detect further variations without retraining.
This shows that training a classifier with the proposed representation will achieve higher recall with comparable precision.Features applied on URL, path, query, filename length; digit ratio lower/upper case ratio; ratio of digits vowel changes ratio ratio of a character with max occurrence has a special character max length of consonant/vowel/digit stream number of non-base64 characters has repetition of parameters Other Features number of bytes from client to server number of bytes from server to client length of referer/file extension number of parameters in query number of '/' in path/query/referer Table 3: List of selected flow-based features extracted from proxy logs.
We consider these features as baseline (as some features were used in previously published work), and compare it with the proposed representation.
Table 4 from Appendix A describes an important fact about the URLs from individual malicious bags.
As you can see, URLs within each malicious bag are similar to each other (as opposed to most of legitimate bags).
This small non-zero variability of flow-based feature values is captured by the proposed representation using both types of histograms.
The variability is very general but also descriptive feature, which increases the robustness of the representation to further malware changes and variants.
This section shows the benefits of the proposed approach of learning the invariant representation for two-class classification problem in network security.
Feature vectors described in Section 8.1 correspond to input feature vectors {x 1 ,.
.
.
,x m } defined in Section 3.
These vectors are transformed into the proposed representation of histograms φ ( ˜ X; ˜ S ; θ ), as described in Section 4.
We have evaluated two types of invariant representations.
One with predefined number of equidistant bins (e.g. 16, 32, etc.) computed as described in Section 4, and one when the representation is learned together with the classifier to maximize the separability between malicious and legitimate traffic (combination of Section 4 and 5).
For the representation learning, we used 256 bins as initial (and most detailed) partitioning of the histograms.
During the learning phase, the bins were merged together, creating 12.7 bins per histogram on average.Both approaches are compared with the baseline flowbased representation used in previously published work, where each sample corresponds to a feature vector computed from one flow.
Results of a widely used signaturebased security device are also provided (see Table 2) to demonstrate that the positive samples included in the evaluation pose a real security risk, as majority of them was not detected.
Maximum number of flows for each bag was 100, which ensures that the computational cost is controlled and does not exceed predefined limits.Two-dimensional projection of the feature vectors for the flow-based and the proposed representation is illustrated in Figures 5 and 6 respectively.
Bags from 32 malicious categories are displayed with red circles, while the legitimate bags are denoted with green circles.
The projections show that the flow-based representation is suitable for training classifiers specialized on a single malware category.
In case of the proposed representation, malicious bags from various categories are grouped together and far from the legitimate traffic, which means that the classifiers will have higher recall and comparable precision with the flow-based classifiers.Next, we will show the properties of the proposed method of learning the representation to maximize the separation between positive and negative samples (see Section 5 for details).
Figure 8 shows the weights and the derived bins for a standard SVM which has no incentive to have similar weights.
The histogram derived from the SVM weights reduces the number of bins from 256 to 130.
Figure 9 shows the results for the proposed method which enforces the similar weights for neighboring bins.
In this case, the weights exhibit a clear structure and the derived histogram has only 18 bins.
The decision boundary is in this case smoother and the classifier trained from this representation will be more robust.Next, a two-class SVM classifier was evaluated on five representations: baseline flow-based, per-feature histograms of values φ (z X k , θ X k ) (bag mean), per-feature histograms of feature differences φ (z S k , θ S k ) (bag variance), the combination of both (bag combined), and the combination of both with bin optimization (optimized bag combined).
The training and testing datasets were composed of bags described in Table 2.
The results on testing data are depicted in Figure 10.
Note that positive bags in the testing set are from different malware categories than bags from the training set, which makes the classification problem much harder.
The purpose of this evaluation is to compare flow-based representation, which is used in most of previously published work, with the proposed invariant representation.
Flow-based representation shows very unsatisfactory results, mainly due to the fact that the classifier was based only on the values of flow-based features that are not robust across different malware categories (as shown in Section 7).
The classifier based on combined bag representation performed significantly better.
These results were further exceeded when the parameters of the invariant representation were learned automatically from the training data (optimized bag combined), which is shown in Figure 10 with logarithmic scale.Precision-recall curve is depicted in Figure 11 to compare the efficacy results of classifiers based on the proposed representation with predefined number of bins per feature (8,16,64,128, and 256 bins) with the same representation, but when the parameters are learned from the training data (using bin optimization from Section 5).
Overall, the results show the importance of combining both types of histograms introduced in Section 4 together, allowing the representation to be more descriptive and precise without sacrificing recall.
But most importantly, when the parameters of the representation are trained to maximize the separability between malicious and legitimate samples, the resulting classifier performs in order of a magnitude better than a classifier with manually predefined parameters.
This paper proposes a robust representation suitable for classifying evolving malware behaviors.
It groups sets of network flows into bags and represents them using a the combination of invariant histograms of feature values and feature differences.
The representation is designed to be invariant under shifting and scaling of the feature values and under permutation and size changes of the bags.
The proposed optimization method learns the parameters of the representation automatically from the training data, allowing the classifiers to create robust models of malicious behaviors capable of detecting previously unseen malware variants and behavior changes.The proposed representation was deployed on corporate networks and evaluated on real HTTP network traffic with more than 43k malicious samples and more than 15M samples overall.
The comparison with a baseline flow-based approach and a widely-used signature-based web security device showed several key advantages of the proposed representation.
First, the invariant properties of the representation result in the detection of new types of malware.
More specifically, the proposed classifier trained on the optimized representation achieved 90% precision (9 of 10 alerts were malicious) and detected 67% of malware samples of previously unseen types and variants.
Second, multiple malware behaviors can be represented in the same feature space while current flow-based approaches necessitate training a separate detector for each malware family.
This way, the proposed system considerably increases the capability of detecting new variants of threats.
Table 4: Example URLs of flows from several malicious bags and from two legitimate bags.
The URLs within each malicious bag are similar to each other while the URLs within legitimate bags differ.
The small non-zero variability of flow-based feature values is captured by the proposed representation using histograms of features and feature selfsimilarity matrices.
Such transformation of the feature values makes the representation robust to malware changes and unseen variants.
