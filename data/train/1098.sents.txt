In this paper, we address an optimization problem that arises in context of cache placement in sensor networks.
In particular, we consider the cache placement problem where the goal is to determine a set of nodes in the network to cache/store the given data item, such that the overall communication cost incurred in accessing the item is minimized, under the constraint that the total communication cost in updating the selected caches is less than a given constant.
In our network model, there is a single server (containing the original copy of the data item) and multiple client nodes (that wish to access the data item).
For various settings of the problem, we design optimal, near-optimal, heuristic-based, and distributed algorithms, and evaluate their performance through simulations on randomly generated sensor networks.
Advances in embedded processing and wireless networking have made possible creation of sensor networks [1,9].
A sensor network consists of sensor nodes with short-range radios and limited on-board processing capability, forming a multi-hop network of irregular topology.
Sensor nodes must be powered by small batteries, making energy efficiency a critical design goal.
There has been a significant interest in designing algorithms, applications, and network protocols to reduce energy usage of sensors.
Examples include energy-aware routing [13], energy-efficient information processing [8,9], and energy-optimal topology construction [21].
In this article, we focus on designing techniques to conserve energy in the network by caching data items at selected sensor nodes in a sensor network.
The techniques developed in this paper are orthogonal to some of the other mentioned approaches, and can be used in combination with them to conserve energy.Existing sensor networks assume that the sensors are preprogrammed and send data to a sink node where the data is aggregated and stored for offline querying and analysis.
Thus, sensor networks provide a simple sample-and-gather service, possibly with some in-network processing to minimize communication cost and energy consumption.
However, this view of sensor network architecture is quite limited.
With the rise in embedded processing technology, sensor networks are set to become a more general-purpose, heterogeneous, distributed databases that generate and process time-varying data.
As energy and storage limitations will always remain an issue -as much of it comes from pure physical limitations -new techniques for efficient data handling, storage, and dissemination must be developed.
In this article, we take a general view of the sensor network where a subset of sensor nodes (called servers) generate data and another subset of nodes (called clients) consume this data.
The data generation and consumption may not be synchronous with each other, and hence, the overall communication cost can be optimized by caching generated data at appropriately selected intermediate nodes.
In particular, the data-centric sensor network applications which require efficient data dissemination [4,6] will benefit from effective data caching strategies.In our model of the sensor network, there is a single data item at a given server node, and many client nodes.
(See Section 6 for a discussion on multiple data items and servers.)
The server is essentially the data item producer and maintains the original copy of the item.
All the nodes in the network cooperate to reduce the overall communication cost of accessing the data via a caching mechanism, wherein any node in the network can serve as a cache.
A natural objective in the above context could be to select cache nodes such that the sum of the overall access and update cost is minimized.
However, such an objective does not guarantee anything about the general distribution of enery usage across the sensor network.
In particular, the updates always originate from the server node, and hence, the server node and the surrounding nodes bear most of the communication cost incurred in updating.
Hence, there is a need to constrain the total update cost incurred in the network, to prolong the lifetime of the server node and the nodes around it -and hence, possibly of the sensor network.
Thus, in this article, we address the cache placement problem to minimize the total access cost under an update cost constraint.
More formally, we address the problem of selecting nodes in the network to serve as caches in order to minimize the total access cost (communication cost incurred in accessing the data item by all the clients), under the constraint that the total update cost (communication cost incurred in updating the cache nodes using an optimal Steiner tree over the cache nodes and the server) is less than a given constant.
Note that since we are considering only a single data item, we do not need to consider memory constraints of a node.Paper Outline.
We start with formulating the problem addressed in this article and a discussion on related work in Section 2.
For the cache placement problem under an update cost constraint, we consider a tree topology and a general graph topology of the sensor network.
For the tree topology, we design an optimal dynamic programming algorithm in Section 3.
The optimal algorithm for the tree topology can be applied to the general graph topology by extracting an appropriate tree from the given network graph.
For the general graph topology, we consider a simplified multiple-unicast update cost model, and design a constantfactor approximation algorithm in Section 4.1.
In Section 4.2, we present an efficient heuristic for the general cache placement problem under an update cost constraint, i.e., for a general update cost model in general graph topology.
In Sec-tion 4.3, we present an efficient distributed implementation.
Finally, we present simulation results in Section 5, and give concluding remarks in Section 6.
In this section, we formulate the problem addressed in this article.
We start with describing the sensor network model.
Sensor Network Model.
A sensor network consists of a large number of sensor nodes distributed randomly in a geographical region.
Each sensor node has a unique identifier (ID).
Each sensor node has a radio interface and can communicate directly with some of the sensor nodes around it.
For brevity, we sometimes just use node to refer to a sensor node.
The sensor network can be modeled as an undirected weighted graph G = (V, E), where V is the set of nodes, and E is the set of edges formed by pairs of nodes that can directly communicate with each other.
The communication distance between any two nodes i and j is the number of hops d ij between the two nodes.
The network has a data item, which is stored at a unique node called a server, and is updated at a certain update frequency.
Each sensor node could be a client node.
A client node i requests the data item with an access frequency a i .
The cost of accessing a data item (access cost) by a node i from a node j (the server or a cache) is a i d ij , where d ij is the number of hops from node i to node j.Problem.
Informally, our article addresses the following cache placement problem in sensor networks.
Select a set of nodes to store copies of the data item such that the total access cost is minimized under a given update cost constraint.
The total access cost is the sum of all individual access costs over all clients for accessing the data item from the nearest node (either a cache or the server) having a copy of the data item.
The update cost incurred in updating a set of caches M is modeled as the cost of the optimal Steiner tree [10] spanning the server and the set of caches.
This problem is obviously NP-hard, as even the Steiner tree problem is known to be NP-hard [3].
In this article, we look at the above problem in various stages -a tree topology, a graph topology with a simplified update cost model, a graph topology with the general update cost model -and present optimal, approximation, and heuristic-based algorithms respectively.More formally, given a sensor network graph G = (V, E), a server r with the data item, and an update cost ∆, select a set of cache nodes M ⊆ V (r ∈ M ) to store the data item such that the total access costτ (G, M ) = 񮽙 i∈V a i × min j∈M d ijis minimum, under the constraint that the total update cost µ(M ) is less than a given constant ∆, where µ(M ) is the cost of the minimum Steiner tree over the set of nodes M .
Note that in the above definition all network nodes are considered as potential clients.
If some node i is not a client, the corresponding a i would be zero.Related Work.
The general problem of determining optimal cache placements in an arbitrary network topology has similarity to two problems widely studied in graph theory viz., facility location problem and the k-median problem.
Both the problems consider only a single facility type (data item) in the network.
In the facility-location problem, setting up a cache at a node incurs a certain fixed cost, and the goal is to minimize the sum of total access cost and the settingup costs for all the caches, without any constraint.
On the other hand, the k-median problem minimizes the total access cost under the number constraint, i.e., that at most k nodes can be selected as caches.
Both problems are NP-hard, and a number of constant-factor approximation algorithms have been developed for each of the problems [7,15], under the assumption that the edge costs in the graph satisfy the triangular inequality.
Without the triangular inequality assumption, either problem is as hard as approximating the set cover [14], and therefore cannot be approximated better than O(log |V |) unless NP ⊆ ˜ P. Here, |V | is the size of the network.Several papers in the literature circumvent the hardness of the facility-location and k-median problems by assuming that the network has a tree topology [19,22].
In particular, Li et al. [19] address the optimal placement of web proxies in a tree topology, essentially designing an O(n 3 k 2 ) time dynamic programming algorithm to solve the k-median problem optimally in a tree of n nodes.
In other related works on cache placement in trees, Xu et al. [22] discuss placement of "transparent" caches to minimize the sum of reads and writes, Krishnan et al. [18] consider a cost model based on cache misses, and Kalpakis et al. [16] consider a cost model involving reads, writes, and storage.
In sensor networks, which consist of a large number of energy-constrained nodes, the constraint on the number of cache nodes is of little relevance.Relatively less work has been done for caching in sensor networks.
Intanagonwiwat et al. [6] propose directed diffusion, a data dissemination paradigm for sensor networks, which adopts a data centric approach and enables diffusion to achieve energy savings by selecting empirically good paths and by caching/processing data in-network.
Bhattacharya et al. [4] develop a distributed framework that improve energy consumption by application layer data caching and asynchronous update multicast.
In this article, we consider cache placement in sensor network under update cost constraint.
As mentioned before, the update cost is typically mostly borne by the server and the surrounding nodes, and hence, is a critical constraint.
To the best of our knowledge, we are not aware of any prior work that considers the cache placement problem under an update cost constraint.
In this subsection, we address the cache placement problem under the update cost constraint in a tree network.
The motivation of considering a tree topology (as opposed to a general graph model which we consider in the next section) is two fold.
Firstly, data dissemination or gathering in sensor networks is typically done over an appropriately constructed network tree.
Secondly, for the tree topol- ogy, we can actually design polynomial time optimal algorithms.
Thus, we can apply such optimal algorithms for the tree topology to the general graph topology by extracting an appropriate tree (e.g., shortest-path tree or near-optimal Steiner tree connecting the clients) from the general graph.
In Section 5, we show through extensive simulations that such a strategy of applying an optimal tree algorithm to a general graph topology yields heuristics that deliver near-optimal cache placement solutions.Consider an ad hoc network tree T rooted at the node r.
Since the communication edges are bidirectional, any node in the network could be designated as the root; thus, we assume that the root node r is also the server for the data item.
The cache placement problem under update cost constraint in a tree topology can be formally defined as follows.Given the tree network T rooted at r, a data item whose server is r, and an update cost constraint ∆, find a set of cache nodes M ⊆ T (r ∈ M ) for storing copies of the data item, such that the total access cost τ (T, M ) = 񮽙 i∈T a i × min j∈M d ij is minimized under the constraint that the total update cost µ(M ) is less than ∆, where µ(M ) is the cost of minimum cost Steiner tree over M .
Note that the minimum cost Steiner tree spanning over a set of nodes M is simply the smallest subtree connecting the root r to all the nodes in M .
In this subsection, we present an optimal dynamic programming algorithm for the above described cache placement problem under the update cost constraint in a tree topology.
We first start with some subtree notations [19] that are needed to describe our dynamic programming algorithm.Subtree Notations.
Consider the network tree T rooted at r.
We use T u to denote the subtree rooted at u in the tree T with respect to the root r (i.e., the subtree rooted at u not containing r); the tree T r represents the entire tree T .
For ease of presentation, we use T u to also represent the set of nodes in the subtree T u .
We use p(i) to denote the parent node of a node i in the tree T r .
Let π(i, j) denote the unique path from node i to node j in T r , and d k,π(i,j) denote the distance of a node k to the closest node on π(i, j).
Consider two nodes v and u in the network tree, where v in an ancestor of u in T r .
See Figure 1(a).
Let L v,u be the subgraph induced by the set of nodes on the left of and excluding the path π(v, u) in the subtree T v , and R v,u be the subgraph induced by the set of nodes on the right of and including the path π(v, u), as shown in Figure 1(a).
It is easy to see T v can be divided into three distinct subgraphs, viz., L v,u , T u , and R v,u .
DP Algorithm.
Consider a subtree T v and a node x on the leftmost branch of T v .
Let us assume that all the nodes on the path π(v, x) (including v and x) have already been selected as caches.
Let τ (T v , x, δ) denote the optimal access cost for all the nodes in the subtree T v under the additional update cost constraint δ, where we do not include the cost of updating the already selected caches on the path π(v, x).
Below, we derive a recursive equation to compute τ (T v , x, δ), which would essentially yield a dynamic programming algorithm to compute τ (T r , r, ∆) -the minimum value of the total access cost for the entire network tree T r under the update cost constraint ∆.
Let O v be an optimal set (not including and in addition to π(v, x)) of cache nodes in T v that minimizes the total access time under the additional update cost constraint δ.
Let u be the leftmost deepest node of O v in T v , i.e., the node u is such that π(v, x).
Based on the definition of u and possible cache placements, a node in L v,u will access the data item from either the nearest node on π(v, u) or the nearest node on π(v, x).
In addition, any node in T u will access the data item from the cache node u, while all other nodes (i.e., the nodes in R v,u ) will choose one of the cache nodes in R v,u to access the data item.
See Figure 1(b).
Thus, the optimal access cost τ (T v , x, δ) can be recursively defined in terms of τ (R v,u , p(u), δ − d u,π(v,x) ) as shown below.
Below, the quantity d u,π(v,x) denotes the shortest distance in T v from u to a node on the path π(v, x) and hence, is the additional update cost incurred in updating the caches on the path π(v, u).
We first define S(T v , x, δ) as the set of nodes u such that the cost of updating u is less than δ, the additional update cost constraint.L v,u ∩ O v = ∅ and T u ∩ O v = {u}.
That is, S(T v , x, δ) = {u|u ∈ T v ∧ (δ > d u,π(v,x) )}.
Now, the recursive equation can be defined as follows.τ (T v , x, δ) = ⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ 񮽙 i∈Tv a i × d i,π(v,x) if S(T v , x, δ) = ∅ min u∈S(Tv,x,δ) ⎛ ⎝ 񮽙 i∈Lv,u a i × min(d i,π(v,u) , d i,π(v,x) ) + 񮽙 i∈Tu a i d iu +τ (R v,u , p(u), δ − d u,π(v,x) ) ⎞ ⎠In the above recursive equation, the first case corresponds to the situation when the additional update constraint δ is not sufficient to cache the data item at any more nodes (other than already selected cache nodes on π (v, x)).
For the second case, we compute the total (and minimum possible) access cost for each possible value of u, the leftmost deepest additional cache node, and pick the value of u that yields the minimum total access cost.
In particular, for a fixed u, the first term corresponds to the total access cost of the nodes in L v,u .
Note that for a node in L v,u the closest cache node is either on the path π v,x or π v,u .
The second and third terms correspond to the total access time of nodes in T u and R v,u respectively.
Since the tree T u is devoid of any cache nodes, the cache node closest to any node in T u is u.
The minimum total access cost of all the nodes in R v,u can be represented as (v,x) ) is the update cost used up by the cache node u.
The overall time complexity of the above dynamic programming algorithm can be shown to be O(n 4 + n 3 ∆) by careful precomutation.τ (R v,u , p(u), δ − d u,π(v,x) ), since the remaining available update cost is δ − d u,π(v,x) where d u,π The tree topology assumption makes it possible to design a polynomial-time optimal algorithm for the cache placement problem under update cost constraint.
In this subsection, we address the cache placement problem in a general graph topology.
In the general graph topology, the cache placement problem becomes NP-hard.
Thus, our focus here is on designing polynomial-time algorithms with some performance guarantee on the quality of the solution.As defined before, the total update cost incurred by a set of caches nodes is the minimum cost of an optimal Steiner tree over the set of cache nodes and the server; we refer to this update cost model as the Steiner tree update cost model.
Since the minimum-cost Steiner tree problem is NP-hard in general graphs, we solve the cache placement problem in two steps.
First, we consider a simplified multiple-unicast update cost model and present a greedy algorithm with a provable performance guarantee for the simplified model.
Then, we improve our greedy algorithm based upon the more efficient Steiner tree update cost model.
In this section, we consider the cache placement problem for general network graph under a simplified update cost model.
In particular, we consider the multiple-unicast update cost model, wherein we model the total update cost incurred in updating a set of caches as the sum of the individual shortest path lengths from the server to each cache node.
More formally, the total update cost of a set M of cache nodes is µ(M ) = 񮽙 i∈M d si , where s is the server.
Using this simplified update cost model, the cache placement problem in general graphs for update cost constraint can be formulated as follows.Problem Under Multiple-Unicast Model.
Given an ad hoc network graph G = (V, E), a server s with the data item, and an update cost ∆, select a set of cache nodes M ⊆ V (s ∈ M ) to store the data item such that the total access cost τ (G, M ) = 񮽙 i∈V a i × min j∈M d ij is minimum, under the constraint that the total update cost µ(M ) = 񮽙 i∈M d si < ∆.
The cache placement problem with the above simplified update cost model is still NP-hard, as can be easily shown by a reduction from the k-median problem.
A number of constant-factor approximation algorithms have been proposed [7,15] for the k-median problem which can also be used to solve the above cache placement problem.
However, all the constant-factor approximation algorithms are based on the assumption that the edge costs in the network graph satisfy the triangular inequality.
Moreover, the proposed approximation algorithms for k-median problem cannot be easily extended to the more efficient Steiner tree update cost model.
Below, we present a greedy algorithm that returns a solution whose "access benefit" is at least 63% of the optimal benefit, where access benefit is defined as the reduction in total access cost due to cache placements.Greedy Algorithm.
In this section, we present a greedy approximation algorithm for the cache placement problem under the multiple-unicast update cost constraint in general graphs, and show that it returns a solution with nearoptimal reduction in access cost.
We start with defining the concept of a benefit of a set of nodes which is important for the description of the algorithm.
A be an arbitrary set of nodes in the sensor network.
The benefit of A with respect to an already selected set of cache nodes M , denoted as β(A, M ), is the decrease in total access cost resulting due to the selection of A as cache nodes.
More formally,β(A, M ) = τ (G, M ) − τ (G, M ∪ A),where τ (G, M ), as defined before, is the total access cost of the network graph G when the set of nodes M have been selected as caches.
The absolute benefit of A denoted by β(A) is the benefit of A with respect to an empty set, i.e.,β(A) = β(A, ∅).
The benefit per unit update cost of A with respect to M is β(A, M )/µ(A), where µ(A) is the total update cost of the set A under the multiple-unicast update cost model. 񮽙
Our proposed Greedy Algorithm works as follows.
Let M be the set of caches selected at any stage.
Initially, M is empty.
At each stage of the Greedy Algorithm, we add to M the node A that has the highest benefit per unit update cost with respect to M at that stage.
This process continues until the update cost of M reaches the allowed update cost constraint.
The algorithm is formally presented below.
Input: A sensor network graph V = (G, E).
Update cost constraint ∆.
Output: A set of cache nodes M .
BEGIN M = ∅; while (µ(M ) < ∆)Let A be the node with maximum β(A, M )/µ(A).
M = M ∪ {A}; end while; RETURN M ; END.
♦The running time of the above greedy algorithm is O(kn 2 ), where k is the number of iterations and n is the number of nodes in the network.
Note that the number of iterations k is bounded by n.Performance Guarantee of the Greedy Algorithm.
The Greedy Algorithm returns a solution that has a benefit at least 63% of that of the optimal solution.
The proof techniques used here are similar to the techniques used in [11] for the closed related view-selection problem in a data warehouse.
Due to the space limitation, we omit the proof here.Theorem 1 Greedy Algorithm (Algorithm 1) returns a solution M whose absolute benefit is of at least (1−1/e) times the absolute benefit of an optimal solution having the update cost (under the multiple-unicast model) of at most that of M .
Recall that the constant factor performance guarantee of the Greedy Algorithm described in previous section is based on the multiple-unicast update cost model, wherein whenever the data item in a cache nodes needs to be updated, the updated information is transmitted along the individual shortest path between the server and the cache node.
However, the more efficient method of updating a set of caches from the server is by using the optimal (minimum-cost) Steiner tree over the selected cache nodes and the server.
In this section, we improve the performance of our Greedy Algorithm by using the more efficient Steiner tree update cost model, wherein the total update cost incurred for a set of cache nodes is the cost of the optimal Steiner tree over the set of nodes M and the server of the data item.Since the minimum-cost Steiner tree problem is NP-hard, we adopt the simple 2-approximation algorithm [10] for the Steiner tree construction, which constructs a Steiner tree over a set of nodes L by first computing a minimum spanning tree in the "distance graph" of the set of nodes L.
We use the term 2-approximate Steiner tree to refer to the solution returned by the 2-approximation Steiner tree approximation algorithm.
Based on the notion of 2-approximate Steiner tree, we define the following update cost terms.
Cost) The Steiner update cost for a set M of cache nodes, denoted by µ 񮽙 (M ), is defined as the cost of a 2-approximate Steiner tree over the set of nodes M and the server s.The incremental Steiner update cost for a set A of nodes with respect to a set of nodes M is denoted by µ 񮽙 (A, M ) and is defined as the increase in the cost of the 2-approximate Steiner tree due to addition of A to M , i.e.,µ 񮽙 (A, M ) = µ 񮽙 (A ∪ M ) − µ 񮽙 (M ).񮽙
Based on the above definitions, we describe the Greedy-Steiner Algorithm which uses the more efficient Steiner tree update cost model as follows.
Same as Algorithm 1 except µ is changed to µ 񮽙 .
♦ Unfortunately, there is no performance guarantee of the solution delivered by the Greedy-Steiner Algorithm.
However, as we show in Section 5, the GreedySteiner Algorithm performs the best among all our designed algorithms for the cache placement problem under an update cost constraint.
In this subsection, we design a distributed version of the centralized GreedySteiner Algorithm (Algorithm 2).
Using similar ideas as presented in this section, we can also design a distributed version of the centralized Greedy Algorithm (Algorithm 1).
However, since the centralized Greedy-Steiner Algorithm outperformed the centralized Greedy Algorithm for all ranges of parameter values in our simulations, we present only the distributed version of Greedy-Steiner Algorithm.
As in the case of centralized Greedy-Steiner Algorithm, we cannot prove any performance guarantee for the presented distributed version.
However, we observe in our simulations that solution delivered by the distributed version is very close to that delivered by the centralized Greedy-Steiner Algorithm.
Here, we assume the presence of an underlying routing protocol in the sensor network.
Due to limited memory resources at each sensor node, a proactive routing protocol [20] that builds routing tables at each node is unlikely to be feasible.
In such a case, a location-aided routing protocol such as GPSR [17] is sufficient for our purposes, if each node is aware of its location (either through GPS [12] or other localization techniques [2,5]).
Distributed Greedy-Steiner Algorithm.
The distributed version of the centralized Greedy-Steiner Algorithm consists of rounds.
During a round, each noncache node A estimates its benefit per unit update cost, i.e., β(A, M )/µ 񮽙 (A, M ), as described in the next paragraph.
If the estimate at a node A is maximum among all its communication neighbors, then A decides to cache itself.
Thus, during each round, a number of sensor nodes may decide to cache the data item according to the above criteria.
At the end of each round, the server node gathers information from all the newly added cache nodes, and computes the Steiner tree involving all the selected cache nodes till the round.
Then, the remaining update cost (i.e., the given update cost constraint minus the current update cost of the Steiner tree involving the selected cache nodes) is broadcast by the server to the entire network and a new round is initiated.
If there is no remaining update cost, then the server decides to discard some of the recently added caches (to keep the total update cost under the given update cost constraint), and the algorithm terminates.
The algorithm is formally presented below.
Input: A network graph V = (G, E).
Update cost constraint ∆.
Output: The set of cache nodes M .
BEGIN M = ∅; while (µ 񮽙 (M ) < ∆)Let A be the set of nodes each of which (denoted as A) has the maximum β(A, M )/µ 񮽙 (A, M ) among its non-cache neighbors.
M = M ∪ A; end while; RETURN M ; END.
♦ Estimation of µ 񮽙 (A, M ).
Let A be a non-cache node, and T S A be the shortest path tree from the server to the set of communication neighbors of A. Let C ∈ M be the cache node in T S A that is closest to A, and let d be the distance from A to C.
In the above Distributed Greedy-Steiner Algorithm, we estimate the incremental Steiner update cost µ 񮽙 (A, M ) to be d.
The value d can be computed in a distributed manner at the start of each round as follows.
As mentioned before, the server initiates a new round by broadcasting a packet containing the remaining update cost to the entire network.
If we append to this packet all the cache nodes encountered on the way, then each node should get the set of cache nodes on the shortest path from the server to itself.
Now, to compute d, each node only needs to exchange the above information with all its immediate neighbors.Estimation of β(A, M ).
A non-cache node A considers only its "local" traffic to estimate β(A, M ), the benefit with respect to an already selected set of cache nodes M .
The local traffic of A is defined as the data access requests that use A as an intermediate/origin node.
Thus, the local traffic of a node includes its own data requests.
We estimate the benefit of caching the data item at A as β(A, M ) = d × t, where t is the frequency of the local traffic observed at A and d is the distance to the nearest cache from A (which is computed as shown in the previous paragraph).
The local traffic t can be computed if we let the normal network traffic (using only the already selected caches in previous rounds) run for some time between successive rounds.
The data access requests of a node A during normal network traffic between rounds can be directed to the nearest cache in the tree T S A as defined in the previous paragraph.
We empirically evaluate the relative performances of the cache placement algorithms for randomly generated sensor networks of various densities.
As the focus of our work is to optimize access cost, this metric is evaluated for a wide range of parameters such as number of nodes and network and network density, etc.We study various caching schemes (listed below) on a randomly generated sensor network of 2,000 to 5,000 nodes in a square region of 30 × 30.
The distances are in terms of arbitrary units.
We assume all the nodes have the same transmission radius (T r ), and all edges in the network graph have unit weight.
We have varied the number of clients over a wide range.
For clarity, we first present the data for the case where number of clients is 50% of the number of nodes, and then present a specific case with varying number of clients.
All the data presented here are representative of a very large number of experiments we have run.
Each point in a plot represents an average of five runs, in each of which the server is randomly chosen.
The access costs are plotted against number of nodes and transmission radius and several caching schemes are evaluated:-No Caching -serves as a baseline case.
-Greedy Algorithm -greedy algorithm using the multiple-unicast update cost model (Algorithm 1).
-Centralized Greedy-Steiner Algorithm -greedy algorithm using the Steiner tree-based update cost model (Algorithm 2).
-Distributed Greedy-Steiner Algorithm -distributed implementation of the Greedy-Steiner Algorithm (Algorithm 3).
-DP on Shortest Path Tree of Clients -Dynamic Programming algorithm (Section 3.1) on the tree formed by the shortest paths between the clients and the server.
-DP on Steiner Tree of Clients -Dynamic Programming algorithm (Section 3.1) on the 2-approximate Steiner tree over the clients and the server.
Figure 2 shows the effect of the number of nodes; the transmission radius (T r ) is fixed at 2.
Figure 3 shows the effect of T r ; a network of 4,000 nodes is chosen for these experiments and T r is varied from 1 to 4.
The general trend in these two sets of plots is similar.
Aside from the fact that our algorithms offer much less total access cost than the no-caching case, the plots show that (i) the two Steiner tree-based algorithms (DP on Steiner Tree of Clients and Centralized Greedy-Steiner Algorithm) perform equally well and the best among all algorithms except for very sparse graphs; (ii) the Greedy-Steiner Algorithm provides the best overall behavior; (iii) the Distributed Greedy-Steiner Algorithm performs very closely to its centralized version.
We have developed a suite of data caching techniques to support effective data dissemination in sensor networks.
In particular, we have considered update cost constraint and developed efficient algorithms to determine optimal or nearoptimal cache placements to minimize overall access cost.
Minimization of access cost leads to communication cost savings and hence, energy efficiency.
The choice of update constraint also indirectly contributes to resource efficiency.
Two models have been considered -one for a tree topology, where an optimal algorithm based on dynamic programming has been developed, and the other for the general graph topology, which presents a NP-hard problem where a polynomialtime approximation algorithm has been developed.
We also designed efficient distributed implementations of our centralized algorithms, empirically showed that they performs well for random sensor networks.
