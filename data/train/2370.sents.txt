Finally, Table 7 shows timings for a nanobenchmark that measures various system call times.
Because this nanobenchmark is warm-cache, it primarily exercises the VFS layer.
BetrFS is close to being the fastest file system on open, read, and stat.
On chmod, mkdir, and unlink, BetrFS is in the middle of the pack.Our current implementation of the write system call appears to be slow in this benchmark because, as mentioned in Section 5.1, writes in BetrFS issue an upsert to the database, even if the page being written is in cache.
This can be advantageous when a page is not written often, but that is not the case in this benchmark.
The Fractal Tree index implementation in BetrFS includes a cachetable, which caches tree nodes.
Cachetable memory is bounded.
BetrFS triggers background flushing when memory exceeds a low watermark and forces Table 8: BetrFS disk usage, measured in GiB, after writing large incompressible files, deleting half of those files, and flushing B e -tree nodes.is configurable, but we found that additional cachetable memory had little performance impact in our workloads.No single rule governs BetrFS disk usage, as stale data may remain in non-leaf nodes after delete, rename, and overwrite operations.
Background cleaner threads attempt to flush pending data from 5 internal nodes per second.
This creates fluctuation in BetrFS disk usage, but overheads swiftly decline at rest.To evaluate the BetrFS disk footprint, we wrote several large incompressible files, deleted half of those files, and then initiated a B e -tree flush.
After each operation, we calculated the BetrFS disk usage using df on the underlying ext4 partition.Writing new data to BetrFS introduced very little overhead, as seen in Table 8.
For deletes, however, BetrFS issues an upsert for every file block, which had little impact on the BetrFS footprint because stale data is lazily reclaimed.
After flushing, there was less than 3GiB of disk overhead, regardless of the amount of live data.
BetrFS 4913 ± 0.27 67072 ± 25.68 1697 ± 0.12 561 ± 0.01 1076 ± 0.01 47873 ± 7.7 32142 ± 4.35 btrfs 4574 ± 0.27 24805 ± 13.92 1812 ± 0.12 561 ± 0.01 1258 ± 0.01 26131 ± 0.73 3891 ± 0.08 ext4 4970 ± 0.14 41478 ± 18.99 1886 ± 0.13 556 ± 0.01 1167 ± 0.05 16209 ± 0.2 3359 ± 0.04 XFS 5342 ± 0.21 73782 ± 19.27 1757 ± 0.12 1384 ± 0.07 1134 ± 0.02 19124 ± 0.32 9192 ± 0.28 zfs 36449 ± 118.37 171080 ± 307.73 2681 ± 0.08 6467 ± 0.06 1913 ± 0.04 78946 ± 7.37 18382 ± 0.42 Table 7: Average time in cycles to execute a range of common file system calls.
Lower is better.Both the rename and delete tests show the worst-case behavior of BetrFS.
Because BetrFS does not include a layer of indirection from pathname to data, renaming requires copying all data and metadata to new points in the tree.
We also measured large-file renames, and saw similarly large overheads-a function of the number of blocks in the file.
Although there are known solutions to this problem, such as by adding a layer of indirection, we plan to investigate techniques that can preserve the appealing lexicographic locality without sacrificing rename and delete performance.
Finally, Table 7 shows timings for a nanobenchmark that measures various system call times.
Because this nanobenchmark is warm-cache, it primarily exercises the VFS layer.
BetrFS is close to being the fastest file system on open, read, and stat.
On chmod, mkdir, and unlink, BetrFS is in the middle of the pack.Our current implementation of the write system call appears to be slow in this benchmark because, as mentioned in Section 5.1, writes in BetrFS issue an upsert to the database, even if the page being written is in cache.
Table 8: BetrFS disk usage, measured in GiB, after writing large incompressible files, deleting half of those files, and flushing B e -tree nodes.No single rule governs BetrFS disk usage, as stale data may remain in non-leaf nodes after delete, rename, and overwrite operations.
Background cleaner threads attempt to flush pending data from 5 internal nodes per second.
This creates fluctuation in BetrFS disk usage, but overheads swiftly decline at rest.To evaluate the BetrFS disk footprint, we wrote several large incompressible files, deleted half of those files, and then initiated a B e -tree flush.
After each operation, we calculated the BetrFS disk usage using df on the underlying ext4 partition.Writing new data to BetrFS introduced very little over-1
