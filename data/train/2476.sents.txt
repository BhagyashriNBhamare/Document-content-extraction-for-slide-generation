Disk drives are one of the most commonly replaced hardware components and continue to pose challenges for accurate failure prediction.
In this work, we present analysis and findings from one of the largest disk failure prediction studies covering a total of 380,000 hard drives over a period of two months across 64 sites of a large leading data center operator.
Our proposed machine learning based models predict disk failures with 0.95 F-measure and 0.95 Matthews correlation coefficient (MCC) for 10-days prediction horizon on average.
Hard disk drives (HDDs) continue to be a key driving factor behind enabling modern enterprise computing and scientific discovery -residing in large-scale data centers.
Unfortunately, HDDs are not only the most frequently replaced hardware components of a data center; they are also the main reason behind server failures [82].
The failure of HDDs can result in data loss, service unavailability, increases in operational cost and economic loss [42,76].
Consequently, the storage community has invested a significant amount of effort in making disks reliable and, in particular, predicting disk failures [4,9,19,23,24,36,41,51,54,58,59,85,89,92].
Although widely-investigated, effective hard disk failure prediction still remains challenging [83,88] and hence, the storage community benefits from the disk reliability field-studies [8,37,44,53,55,60,65,77,83,88].
Unfortunately, such field studies are not published often enough and are limited in sample size [8,9,28,30,37,60,83,88,89].
To bridge this gap, we perform large-scale disk failure analysis, covering 380,000 hard disks and five disk manufacturers distributed across 10,000 server racks and 64 data center sites over two months, hosted by an enterprise data center operator -one of the largest disk failure analysis studies reported in the literature [4,9,51,83].
For the first time, this paper demonstrates that disk failure predictions can be made highly accurate by combining disk performance and disk location data with disk monitoring data (Self-Monitoring, Analysis, and Reporting Technology -SMART data).
Traditionally, disk failure prediction works have largely focused on using SMART data for predicting disk failures -this is based on in-thefield evidence that SMART attributes (e.g., correctable errors, temperature, disk spin-up time, etc.) are correlated with the disk health and indicative of eventual failure.
While this conventional wisdom holds true as shown by previous works, we found that SMART attributes do not always have the strong predictive capability of making disk failure predictions at longer prediction horizon windows for all disks (i.e, predicting disk failures a few days before the actual failure instead of a few hours).
This is primarily because the value of SMART attributes often does not change frequently enough during the period leading up to the failure, and the change is often noticeable only a few hours before the actual failure, especially in hard-to-predict cases.On the other hand, the value of performance metrics may exhibit more variations much before the actual drive failure.
A small example is shown in Figure 1 and Figure 2.
We observe that the performance metrics of failed disk drives may indeed show distinguishable behavior from healthy disks (Figure 2) while SMART attributes do not (Figure 1).
In Figure 1, the SMART attributes of healthy disks show the same value or similar pattern as failed disks located on the same server until the time of disk failure.
For the performance metrics shown in Figure 2, although the trends of failed disks are close to healthy disks, failed disks may report multiple sharp impulses before they actually fail.
Only a subset of SMART attributes are shown in the plot, but others also show similar behavior (our methodology is Figure 3: Values of SMART attributes before a hard disk failure, collected on an hourly basis, extracted from the open-source Baidu dataset [40].
The legend on the right shows the IDs of disk SMART attributes as defined by the industry standard [3], and "R" represents the raw value of an attribute.covered in Section 2).
We note that this example evidence does not suggest that all failed disk drives show variation in performance metrics leading up to the failure, or that SMART attributes do not change for any failed disks.
Instead, it shows that performance metrics, when combined with a traditional approach of using SMART attributes, may be more powerful than using SMART attributes alone, especially for hard-to-predict failures.One could argue that SMART attributes not exhibiting distinct patterns between healthy and failed disks is specific to this data center under study.
To test this hypothesis, we plotted the normalized value of SMART attributes of failed and healthy disks from a publicly available disk failure dataset released by Baidu in 2016 [40].
Figure 3 shows that the normalized values of 12 SMART attributes of a randomly selected failed disk do not vary noticeably leading up to the failure -477 hours before its actual failure.
This observation is particularly notable, especially, given that the SMART attributes for this dataset are collected at much finer-granularity (one hour) as opposed to traditional per-day granularity (e.g., Backblaze public dataset [46]).
Thus, SMART attributes alone may not be able to predict all disk failures.Intuitively, the addition of performance metrics toward disk failure prediction increases the predictive power because it increases our coverage in capturing the workload characteristics accessing the storage system, beyond what SMART attributes cover.
The nature of workloads running on a system often affects the failure rates of different system components, not only disks.
But, it's much more challenging to obtain and incorporate workload related information due to the businesssensitive nature of data center workloads.
As shown in Section 5, performance metrics can act as a good proxy for workload characteristics for disk failure prediction.Finally, this paper shows that disk failure prediction can be further improved by incorporating the location information of disk drives in the data center -an aspect that has not been explored in the previous disk failure prediction works because typically data center logs do not include location and organization of disks by default.
Intuitively, the addition of location information toward disk failure prediction increases the predictive power because it increases our coverage of the operating conditions of data center disks.Disks in close spatial neighborhoods are more likely to be affected by the same environmental factors, such as relative humidity and temperature, which are responsible for accelerating disk component failures [55,73].
Notably, disks with physical proximity are likely to experience similar vibration levels.
Although vibration is not a part of the SMART attributes or performance metrics, it is known to affect the reliability of disk drives [56,65].
Therefore, adding location information can capture disks operating under similar environmental or operating conditions which can experience similar failure characteristics.
Our evaluation (Section 5) shows that adding location information to SMART attribute information indeed improves the failure prediction quality, although as expected, the effects are not as large as adding performance metrics to SMART.While using the combination of SMART attributes, performance metrics, and location information is likely to improve disk failure prediction quality, the types of attributes, and the raw amount of combined information is almost unmanageable.
It is unclear what attributes should be selected and how they should be used.
Traditional rule-based or analytical models are not likely to exploit the hidden interactions among different attributes of the same type (e.g., SMART) and different types (e.g., performance vs. SMART).
Therefore, to increase the effectiveness of our approach, we take advantage of machine learning (ML) models for leveraging such hidden interactions, as done in several previous disk failure prediction works [9,51,54,65,89].
Our core contributions are not in the development of machine learning based models, built on top of wellunderstood and mature models such as naive Bayes classifier (Bayes) [36], random forest (RF) [52], gradient boosted decision tree (GBDT) [29,91], and long shortterm memory networks (LSTM) [23,38].
Instead, the core usefulness of our study is in providing actionable insights, trade-off lessons learned in applying these models, and assessment of model robustness.
Additionally, we develop and evaluate a new hybrid deep neural networks model, convolutional neural network long short-term memory (CNN-LSTM) [2] for disk failure prediction that achieves close to the best prediction quality in most of the test cases.
This paper presents findings from one of the largest disk failure prediction studies covering 380,000 hard drives over a period of two months across 64 sites of a leading data center operator.
Our disk failure prediction framework and the dataset used in this study including performance, SMART, and location attributes is hosted at http://codegreen.cs.wayne.edu/wizard.
This paper provides experimental evidence to establish that performance and location attributes are effective in improving the disk failure prediction quality.
We show that, as expected, machine learning based models can be useful in predicting disk failures.
But, as we discover and discuss in this paper, there are several trade-offs in the model selection.
We also understand, discuss, and explain the limitations of these models.
This paper provides details of an experimental and evaluation methodology for effective disk failure prediction.Overall, our evaluation shows that no single machine learning model is a winner across all scenarios, although CNN-LSTM is fairly effective across different situations.
We achieve up to 0.95 F-measure [66] and 0.95 MCC (Matthews correlation coefficient) [10,35,43,71] score for a 10-day leadtime prediction horizon (Refer to Section 4 for the definitions of F-measure and MCC).
We show that combining SMART attributes, performance metrics, and location records enables us to do disk failure prediction with long leadtimes, although the prediction quality changes with the lead time window size.
This study covers the disk and server data measured and collected at a large data center.
Over, the dataset spans over 64 data center sites, 10,000 server racks and 380,000 hard disks for roughly 70 days.
This corresponds to roughly 2.6 million device hours [4,9,51,83].
We note that during this period, the data center housed more than two million hard disks, but not all of them are included in our study because we only focus on those disks that have logged data in all three aspects: SMART, performance, and location.
Collection and storage of both performance and SMART data are not enabled for all disks due to performance overhead and businesssensitivity concerns.Next, we assess the types of disk events recorded at the data center sites and describe our definition of disk failure.
Then, we discuss all three types of data collected and analyzed for this study: (1) disk SMART attributes (most commonly used for disk failure prediction by other studies [4,19,79,87], (2) performance data, and (3) spatial location data of disks.
Given the complexity of disk failures, there is no common, agreed-upon universal definition of a disk failure [53].
Latent sector errors (LSEs) are typically considered to be one of the most common disk errors which cause disk failures.
However, a large-scale study of disk failures [75] shows that a small number of LSEs alone do not necessarily indicate that a disk failure has occurred or is imminent, but LSEs may cause performance degradation that could eventually lead to a "failure" -where error messages such as "the system cannot connect to the disk" or "disk operation exceeded the prescribed time limit" are treated as disk failures and warrant disk replacement.
In this paper, we consider a disk to be failed when the production data center operator deems a disk necessary to be replaced.
The IT operators of the production data center we study deem it appropriate for a disk to be replaced or repaired when there is a failed read/write operation and the disk cannot function properly upon restart.
All other disks are considered healthy.
SMART attributes values are produced and logged under the Self-Monitoring, Analysis and Reporting Technology (SMART) monitoring system for hard disks, which detects and reports various indicators of drive reliability [3].
The number of available SMART attributes is more than 50, but not all disks log all of the attributes at all times.
For our study, we select 14 SMART attributes (Table 1) as features for our training models using the method described in Section 3.
More than 97% of our disks reported these attributes, and these attributes also overlap with the widely used attributes for disk failure prediction by other studies [9,51,54,65,89].
In our study, these SMART attributes are collected continuously and reported at per-day granularity during the whole duration of the data collection period, similar to previous works [37,54,54].
As discussed earlier, more frequent SMART reporting did not necessarily improve the prediction quality at the start of this study and hence, once-a-day reporting was employed.In our study, we consider two values corresponding to each SMART attribute in Table 1: (1) raw value of the attribute, and (2) normalized value of the attribute.
Raw values are collected directly by the sensors or in- ternal software in disks, and their interpretation can be specific to the disk manufacturer.
Normalized values are obtained by mapping the related raw value to one byte using vendor-specific methods.
Higher normalized value usually indicates a healthier status, except in the case of head load and unload cycles and temperature.
We note that whether a higher (or lower) raw value is better often depends on the attribute itself.
For example, a higher value of "Reallocated Sectors Count" represents that more failed sectors have been found and reallocated (worse case), while a lower value of "Throughput Performance" indicates a possibility of a disk failure.
In our study, we measure and collect two types of performance metrics maintained by the OS kernel, i.e., disk-level performance metrics and server-level performance metrics.
Disk-level performance metrics include IOQueue size, throughput, latency, the average waiting time for I/O operations, etc.
Server-level performance metrics include CPU activity, page in and out activities, etc.
Performance metrics are reported at per-hour granularity because we found that hourly granularity was effective in improving the prediction quality.
However, the storage overhead of all performance metrics can become significant at scale and over time, and it can incur significant operational costs.
Therefore, as described in Section 3, we use a simple method to down-select the number of metrics used by our ML models to manage prediction quality with low storage overhead.
In our study, we measure and collect 12 disk-level performance metrics in total; all of these metrics are used in this paper.
Table 2 shows the 12 metrics related to individual disks.The distinct value of "DiskStatus" represents different disk working statuses.
For example, 0, 1, 2, 4, 8, 16, 32, 64 and 128 indicate healthy, initial, busy, error, hang, only read, shutdown, repair, and complete repair states, respectively.
"IOQueueSize" shows the number of items in the IO worker queue.
"NormalFile/TempFile_WriteSuccess_Throughput" represents the throughput of normal/temp files successfully written to disks.
"NormalFile/TempFile_WriteWorkItem_ SuccessQps" and "ReadWorkItem_SuccessQps" stand for the number of normal/temp files successfully written/read by the disk per second.
Similarly, "NormalFile_WriteWorkItem_QueueTime" indicates the average waiting time for disks to write.
"ReadSuccess_Throughput," "ReadWorkItem_ProcessTime," and "ReadWorkItem_QueueTime" indicate the throughput, process time, and the average waiting time through the reading process of disks.
As to the server-level metrics, we have 154 metrics categorized into 54 categories; each category has a different number of metrics.
We first extract the most common pairs of category-metrics and make sure that more than 97% of servers have these server-level metrics.
We down-select the number of metrics to 18 that we feed to our machine learning model to manage prediction quality vs. storage overhead via a simple method described in Section 3.
Table 3 lists the 18 server-level performance metrics and their corresponding categories.
"Tcp_outsegs" displays the total number of the disk storage segments that have been sent, including those on current connections but excluding those containing only retransmitted octets.
Similarly, "tcp_insegs" shows the total number of disk storage segments received, and "tcp_currestab" represents the number of TCP connections for which the current state is either established or close-wait.
"Udp_outdatagrams" displays the total number of the disk storage UDP datagrams that have been sent.
"Page_in" represents the number of transferring data from a disk to the memory per second.
Similarly, "page_out" occurs when the data is transferred from the memory to a disk.
Packets per second (PPS) is a measure of throughput for network devices.
Hence, "net_pps_receive" and "net_pps_transmit" indicate the rate of successfully receiving and transmitting messages over a communication channel, respectively.
Note that the performance data also includes network-related (TCP/UDP) metrics some of which appear in the selected server-level performance metrics; this suggests that network-and disk-activity might be correlated and may be predictive of disk failures when combined.
As noted in Table 4, our disks are spread over more than 50 sites and 10,000 racks.
All disks are directly attached to a server.
Each disk has four levels of location markers associated with it: site, room, rack, and server.
One server may host multiple disks.
Multiple servers could be on the same rack.
A room has multiple racks, and a site may host several rooms.
Location markers are used for both healthy and failed disks.
Note that these location markers do not explicitly indicate the actual physical proximity between two disks, since the physical distance between two sites or rooms is not captured by our location coordinates, and they do not indicate the physical proximity within a room.
Our disk failure prediction study is carefully designed to ensure that it is not prone to experimental pitfalls.
For example, we verified that the disk failure rate is roughly similar over time across all 64 sites because if most disk failures happen during the same week it can skew the prediction quality.
Similarly, we ensured that the concentration of disk failures in space is not skewed.
Although failures in space have non-uniform distribution, we have verified that the density of failures in space changes over time.
Our annual disk failure rate of ≈1.36% is consistent with failure rates observed at other data centers [47][48][49].
We note that missing SMART or performance data is a possibility and can itself be indicative of the system's health.
For example, if failed disks observe a higher degree of missing data than healthy disks and the failed disks have been missing data continuously for a long period (e.g., more than the prediction horizon), then this feature alone could predict disk failure with high success rate.
However, in our case, we observed that healthy and failed disks do not have an imbalance in terms of missing data.
Furthermore, the length of continuous missing data is less than one day in most cases because we have multiple types of data: performance and SMART.
The likelihood of missing all samples from both groups simultaneously is low -and if data is missing, it often points to an abrupt disk/server failure or other infrastructure-related issues.We also ensure that disk failures are not concentrated on a particular manufacturer only, or limited to only oldaged drives.
Although our datset has multiple vendors and drives of different ages, we verified that failure prediction does not reduce to trivially knowing the vendor name or age of the disk -although these features are used by our machine learning models to improve the quality of prediction.
We explored training and building vendor-specific ML models, but we found that this leads to multiple problems: (1) overfitting to a particular vendor, (2) lack of portability across sites and vendors, (3) managing multiple models, and (4) lower prediction quality than the approach taken in this paper (normalizing the attributes across vendors and disks as discussed in Section 3).
In this section, we present a simple method to downselect SMART and performance metrics.
These downselected metrics are then fed to our machine learning models as input features.
Unless otherwise noted, we use this method for selecting important features and use the resulting features to present evaluation results.
However, one could argue that machine learning models can automatically infer important features out of all the input features.
The reason for performing this step is to demonstrate that down-selecting features using a simple method does not compromise the prediction quality, as we evaluate in Section 5.
The benefit of this step is the saving in storage overhead.
Although our study needed to store all the features (over 100) to demonstrate the effectiveness of down-selection, in the future, data center operators can use the method to save storage space and reduce processing overhead.
Since the range of values for different attributes across different disks and vendors varies widely, it is hard to perform meaningful comparisons.
Thus, we pre-process the SMART and performance metrics using a min-max normalization to facilitate a fair comparison between them as per equation: x norm = (x − x min )/(x max − x min ).
Here, x is the original value of a feature, x min is the minimum and x max is the maximum value of the feature (over all observations).
We use 0 to represent the NULL value, and we label constant features as 0.
Next, we leverage Youden's J index (also named as J-Index) [27,74] for the down-selection of features.
After features are normalized to the scale of 0-1, we set a series of threshold candidates for each feature with a step of 0.01, starting from 0 until 1.
For each threshold candidate t, we calculate the value of the corresponding J-Index [6].
We define J-Index classification (JIC) as:J-Index = True Positive Rate + True Negative Rate − 1 = TP TP+FN + TN TN+FP − 1Here T and F indicate whether the prediction result is correct; P and N denote the disk is classified as failed (positive) or healthy (negative).
TP denotes the number of actually failed disks that are correctly predicted as failed, and TN denotes the number of healthy disks that are correctly predicted as healthy.
Similarly, FP denotes the number of healthy disks that are falsely predicted as failed, and FN denotes the number of failed disks that are falsely predicted as healthy.More specifically, suppose the input feature is PowerOn Hours, and the distribution looks like Figure 4 for the current threshold candidate t (t = 0.58 as an example here).
We calculate the percentage of failed disks that are distributed on the left-hand part of t, which is 42.11%, i.e., TP = 42.11%.
Similarly, we have FN = 57.89%, FP = 21.30%, and TN = 78.70%.
It is intuitive that we predict a disk is healthy if its value is greater than 0.58 or it is otherwise failed.
We also calculate the corresponding J-Index based on the above definition.
Following this method, for a specific feature, we have a series of threshold candidates and their corresponding J-Indexes.
The range of J-Indexes is 0 to 1.
A higher J-Index means the corresponding threshold candidate is more distinguishable to identify failed disks from healthy disks.
Therefore, the threshold candidate with the highest J-Index is selected as the best (final) threshold for a feature.Intuitively, J-Index classification is a low-overhead and practical method for IT operators to adopt and perform feature selection on their datsets.
Table 5 shows the J-Indexes (greater than 0.1) for SMART attributes.
The fourth and sixth columns (yellow color) represent the percentages of disks that are smaller than the threshold, while the fifth and last columns (blue color) show the percentages of disks that are greater than the threshold.
For each attribute, the first bold font indicates the true positive rate, and the second bold font denotes the true negative rate.
Since failures are not always supposed to be values that are less than the threshold, i.e., there are upper-bound thresholds and lower-bound thresholds for failed disks, the bold values for the true positive rate and true negative rate span multiple columns.
Similar to SMART attribute analysis, we would like to see if performance metrics could be the indicators of disk failures.
Table 6 shows a part of the highest JIndexes for performance metrics following the same formatting guide as Table 5.
By employing the JIC method, we figure out a set of most informative disk-level and server-level performance metrics that are indicative of impending disk failures, i.e., we select the metrics that have the highest J-Indexes (greater than 0.1).
We also present the best (final) thresholds of some of the selected metrics in Table 5 and Table 6.
Contrary to SMART attributes, performance metrics tend to have a higher true positive rate and a lower true negative rate.
We observe that although a single performance metric is not perfect to distinguish failed disks from healthy disks, it has an overall higher J-Index than most of the SMART attributes based on our dataset.
This indicates that performance metrics are likely to be predictive for disk failures.Next, we show that performance metrics of failed disks may show different distinguishing patterns before failure compared to the healthy disks.
Recall that there are 12 disk-level performance metrics in total.
For each server that contains one or more failed disks (failed server), we extract these 12 metrics of each disk within 240 hours before disks are reported to be failed.
If there is only one failed disk on a specific failed server, we keep the raw value of the failed disk (RFD) and calculate the average value of all healthy disks (AHD) for every time point.
Then, we get the difference between RFD and AHD, which indicates the real-time difference between the signatures of failed disks and healthy disks on the same server.
If there are N ( N ≥ 2 ) failed disks, then for each failed disk, we calculate the difference between RFD and AHD for every time point.
Figure 5 shows representative samples of the difference between RFD and AHD curves for different performance attributes on different servers.
To reveal the patterns more intuitively, we use the raw values of metrics to calculate the difference between RFD and AHD rather than the normalized values in Figure 5.
All disks on the same server have the same value of server-level performance metrics, and hence, 18 selected server-level performance metrics are not shown in the plot.
The top two graphs of Figure 5 illustrate that some failed disks have a similar value to healthy disks at first, but then their behavior becomes unstable as the disk nears the impending failure.
The bottom two graphs of Figure 5 show that some failed disks report a sharp impulse before they fail, as opposed to a longer erratic behavior.
These sharp impulses may even repeat multiple times.
We did not find such patterns for SMART attributes so far before the failure of this selected example.
The diversity of patterns demonstrates that disk failure prediction using performance metrics is non-trivial.
Problem Definition.
We formulate the problem of predicting disk failures as a classification problem.
Specifically, we use T = (input i , label i ) n i=1 to represent our training dataset, in which input i ∈ I denotes all input features.
Here, label i ∈ {0, 1} is a binary response variable for each disk i: 0 indicates healthy state and 1 indicates failed state.
Our goal is to employ the best method to learn the function f : I → {0, 1}, which minimizes the loss function (h (input) ; label), a measurement of the difference between the desired output and the actual output of the current model, such that the trained model is able to predict disk failures (label i = 1) over a specific prediction horizon with high accuracy.More specifically, during the training process, assume we only use one attribute a as an input feature.
For each disk, we have multiple readings of the attribute: a 1 , a 2 ,..., a n (j is the time in a j ), and we treat {a 1 , ..., a n } as a sample.
Since the input of a machine learning algorithm should be a fixed length of the observation period for each sample, n should be a fixed number.
Our goal is to predict disk failure in advance, so a j in {a 1 , ..., a n } should be the value of healthy states (of the healthy disks or healthy states prior to failures), i.e., a j in {a 1 , ..., a n } does not contain failed state data.
Note that we aim to predict if the disk will fail and not the exactly when the disk will fail in the next ten days.Effective Measurements.
To evaluate the effectiveness of our prediction approaches, we use Precision, Recall, F-measure, and Matthews correlation coefficient (MCC) to measure the wellness of our prediction approaches.
Precision [22] indicates the proportion of TP among all predicted failures.
Recall that the true positive rate (TPR) [81] represents the proportion of TP within all actually failed disks.
Since our binary classification is largely imbalanced -there are many more healthy disks than failed disks -we also use F-measure [39,69] and MCC [10] as our evaluation metrics.
F-measure is the harmonic average of precision and recall and ranges between 0 and 1 (higher is better).
We use MCC because it is a more balanced measure than F-measure, especially suitable for imbalanced data.
It ranges from 1 (perfect prediction) to -1 (inverse prediction).
These metrics are defined as:Precision = TP TP+FP Recall (TPR) = TP TP+FN F-measure = 2 * Precision * Recall Precision+Recall MCC = TP×TN−FP×FN √ (TP+FN)(TP+FP)(TN+FP)(TN+FN))Prior ML Models and Our Models.
Previous works have focused on leveraging fundamental classification and regression techniques for disk failure prediction [4,9,51].
These methods include naive Bayes classifier (Bayes) [69], random forests (RF) [52], gradient boosted decision trees (GBDT) [29,91] and long shortterm memory networks (LSTM) [23,38].
Bayes is a family of probabilistic classifiers based on applying Bayes' theorem.
RF and GBDT are types of traditional machine learning (ML) ensemble methods, while LSTM is a class of deep neural networks (DNNs).
Since previous works have not considered performance and location features for disk failure prediction, we implement and tune Bayes, RF, GBDT, and LSTM models to use them as a proxy for prior learning based disk failure prediction models.
In addition, we consider a convolutional neural network with long short-term memory (CNN-LSTM) based model [72].
We implement our models in Python, using TensorFlow 1.5.0 [1], Keras 2.1.5 [34], and Scikit-learn libraries [64] for model building.Brief Model Background and Intuitions.
Bayes [69] is a probabilistic machine learning model used for classification tasks.
RF [52] and GBDT [29,91] are both ensemble methods that are constructed by a multitude of individual trees (called base learners or weak learners) and consider the conclusions of all trees to make accurate predictions through averaging or max voting.The difference between RF and GBDT is that RF generates trees in a parallel manner (bagging algorithm) [52], while GBDT grows tress sequentially (boosting algorithms) [29,91].
More specifically, the bagging algorithm randomly takes data samples with replacement from the original dataset to train every weak learner, which means that the training stage of generating multiple learners is parallel (i.e., each learner is built independently).
Boosting algorithm, however, uses all data to train each learner and builds the new learner in a sequential manner, and it assigns more weight to the misclassified samples to pay more attention to improving their predictability them during the training phase.On the other hand, LSTM [23,38] is capable of addressing the long-term back-propagation problem (iteratively adjusting the weights of network connections to reduce the value of the loss function).
LSTM includes a memory cell which tends to preserve information for a relatively long time.
Hence, LSTM is effective for sequential data modeling, and employing LSTM to predict disk failure has been explored previously [23].
To further improve the performance of LSTM in the disk failure prediction, we integrate CNN and LSTM as a unified CNN-LSTM model (a CNN at the front and an LSTM network at the rear), since CNN and LSTM are complementary in the modeling capabilities -CNN offers advantages in selecting better features, while LSTM is effective at learning sequential data [2].
The choice of combining CNN and LSTM is inspired by the analysis presented by Pascanu et al. [63] -suggesting that the performance of LSTM could be further improved by taking better features as the input, which could be provided by CNN through dimensionality reduction [68].
Therefore, we include the CNN-LSTM approach to explore its effectiveness in the field of disk failure prediction.Model Training and Testing Methodology.
We use 5-fold cross-validation [50], which is a validation technique to assess the predictive performance of machine learning models, judge how models perform to an unseen dataset (testing dataset) [70] and avoid the overfitting issue.
More specifically, our dataset is randomly partitioned into five equal-sized sub-samples.
We take one sub-sample as the testing dataset at a time and take the remaining four sub-samples as the training dataset.
We fit a model on the training dataset, evaluate it on the testing dataset, and calculate the evaluation scores.
After that, we retain the evaluation scores and discard the current model.
The process is then repeated five times with different combinations of sub-samples, and we use the average of the five evaluation scores as the final result for each method.Tuning Hyperparameters of Models.
We search for the best values of hyperparameters for all models using the hold-out method [45], which splits our original training phase data further into the hyperparameter training dataset (80% of the original training phase data) and the validation dataset (20% of the original training phase data).
The biggest difference between the hold-out method and k-fold cross-validation approach (k refers to the number of sub-samples) is that the training and validation process of the hold-out approach only needs to be run once, while k-fold cross-validation needs to be run k times.
In the hyperparameter tuning phase, we conduct a grid search to build and evaluate models for each combination of hyperparameters, and the goal is to find the best combination with the highest performance.
For example, for RF and GBDT, we run experiments with different numbers of trees (estimators), and we settle on using 2000 trees in the RF model, and 1000 trees in the GBDT model, since using more than 2000 and 1000 trees, respectively, does not have significant improvements in practice.
Using a similar method, the additive Lidstone smoothing parameter (α) of Bayes [20] was set to 2.
For LSTM-based models, after conducting a grid search on the values of hyperparameters to find the best combinations, we build an LSTM model with four layers and 128 nodes.
For CNN-LSTM, in the CNN sub-module, we employ 1 one-dimensional convolutional layer at the front followed by one max-pooling layer and one flatten layer (shown in Figure 6).
The 1D convolutional layer contains 128 filters which interpret snapshots based on the input.
The max-pooling layer is responsible for consolidating and abstracting the interpretation to get a two-dimensional matrix of features.
The flatten layer transforms the matrix into a vector, which is fed into the next classifier.
The LSTM module consists of two LSTM layers and one dense layer (fully connected layer).
We empirically set the same learning rate of 0.001 for the LSTM and CNN-LSTM models, and we set the drop-out rate to 0.25.
The mean squared error (MSE) and its derivative increases at a prediction horizon beyond 10 days.Avoiding Overfitting of the Models.
As far as LSTM and CNN-LSTM are concerned, one of the most important factors is the epoch [32], which indicates the number of iterations of processing the input dataset during the training process.
A higher epoch value will reduce the error on training data; however, at a crucial tipping point, the network begins to over-fit the training data.
Hence, finding the best value of the epoch is essential to avoid overfitting.
Figure 7(a) shows the change in the value of the training and validation loss functions (the smaller, the better) as the epoch increases.
Initially, the values of the two loss functions are decreasing with increasing epoch values; but after 32 epochs, the value of the validation loss function slowly increases (higher than the training loss), which indicates the over-fitting issue.
Therefore, we choose 32 epochs for LSTM.
Similarly, we choose 200 epochs for CNN-LSTM.
Feature Group Sets.
We consider different input datasets to evaluate the effectiveness of different features: SMART attributes (S), performance metrics (P), and location markers (L).
We construct six groups using different feature combinations: SPL, SL, SP, PL, S, and P. Table 7 shows the input features for these groups.Prediction Horizon Selection.
The first step in evaluating the ML model is to determine how long the prediction horizon should be.
We choose 10 days as our prediction horizon, i.e., we aim to detect if a given disk will fail within the next 10 days, similar to previous studies [4,9].
The 10-day horizon is long enough for IT operators to conduct early countermeasures.
We also conduct a sensitivity study showing the change in the value of mean squared error (MSE) of different metrics for different lengths of prediction horizon, as shown in Figure 7(b) (using "ReadSuccessThroughput" as a representative example), where MSE indicates the average squared difference between the predicted values and the actual values [86].
We note that the derivative of MSE remains low for up to ten days, but it increases after ten days.
This behavior can have slight variations across different features.
Our prediction horizon is 10 days unless otherwise stated in our evaluation.
We also evaluate the models' sensitivity with regard to prediction horizon (Section 5).
In this section, we present and analyze the results of various ML models, their sensitivity toward different feature groups, their limitations, robustness, and portability.
Our discussion includes supporting evidence and reasons to explain observed trends, and implications of observed trends for data centers.
First, we present the key prediction quality measures for all models and feature sets (Figure 8).
We make several interesting observations as following:1.
We observe that the SPL feature group performs the best across all ML models, confirming our hypothesis that performance and location features are critical for improving the effectiveness of disk failure prediction, beyond traditional SMART attribute based approaches.2.
Adding location information improves the prediction quality across models, but the improvement is limited in absolute degree (e.g., less than 10% for CNN-LSTM in terms of MCC score).
Interestingly, the effect of location information is pronounced only in the presence of performance features.
The disk performance metrics are potentially correlated with disks' location information, Therefore, adding location markers may help ML mod- Second, there is a trade-off between FPR and FNR in terms of cost (cost of disk failure vs. replacing healthy disks conservatively).
Depending on the estimated costs of these factors, data center operators could choose between different models.
For example, for the SPL group, GBDT provides lower FPR but higher FNR.
Similarly, Figure 9 also shows that in the S group, such trade-offs exist between the RF and LSTM models.
Finally, we observe a trade-off between models with respect to the different availability of feature sets.
Fig- ure 8 shows that when a data center operator does not collect or have access to the performance features, traditional tree-based ML models (RF and GBDT) can perform roughly as well as complex neural network based models such as CNN-LSTM or LSTM.
In fact, RF and GBDT models may even beat the LSTM model in absence of P and L features -this is similar to what a recent work has also shown which does not consider performance metrics [4].
Our work shows that adding performance and location features leads to a different and new outcome.
Also, we note that the CNN-LSTM model takes much longer to train compared to simple tree-based models (up to four hours in our case for one training progress); therefore, in absence of performance and location features, RF and GBDT models can provide equally accurate predictions, and they might be preferred for building models based on the SMART data only due to the relatively lesser training time.Next, we investigate when and how ML models fail to achieve high prediction accuracy over space and time.
Where do ML models perform relatively poorly and why?
Figure 10 shows that ML models are somewhat less effective at predicting with high accuracy and recall in areas where the concentration of failures is relatively lower.
This is reasonable since ML models are not able to collect enough failed disk samples.
ML models are by definition less effective for cases they have not been trained or situations they have not encountered before.
This observation is important for data center operators as it emphasizes the need for adding location markers in disk failure prediction models.When do ML models fail to predict and why?
To understand the limitations of ML models better, we investigate the false positive (healthy disks predicted as failed) and false negative (failed disks predicted as healthy) predictions.
Figure 11(a) shows the false positives categorized in 20-day windows for the CNN-LSTM model (other models produce similar trends).
The number of false positives is very low initially as it predicts many disks as healthy though they eventually fail in that window -and, this is why the false negatives are high (Fig- ure 11(b)).
This can be explained by the lack of sufficient training data -the ML model does not have enough data and (conservatively) predicts that disks are healthy.
This trend indeed reverses over time.
Although the fraction of false positives appears to be very high toward the last window, we note that the actual number of false positives is quite low (Figure 9).
This observation indicates the need for sufficiently long testing periods before concluding the prediction quality of ML models.
new sites and in some cases, model training at new sites may not be possible due to strict business-sensitivity reasons.
Therefore, we want to test if machine learning based disk failure models are unsuitable to a large degree for porting across data center sites?
One can expect the operating conditions and workload characteristics to change across data center sites and hence, the disk failure prediction model may not work at all.
As expected, this is true if we simply try to train on one data center site and port it to another data center site (i.e., test on another unseen site) -the MCC score can drop significantly.
However, we found that training on multiple data sites before testing on a new unseen data site provides reasonable accuracy.
We tested on two unseen data center sites A and B, while training our model on the rest of the 62 sites (Table 8 shows results for site A; site B has similar results).
Our results show that the prediction quality still remains reasonably high (e.g., >0.90 MCC score for a 10-day prediction horizon using CNN-LSTM model and SPL group features).
We did not find a significant drop in prediction quality for any ML model; however, with some traditional ML models (RF and GBDT) the prediction quality does not remain high (more than 15% drop in some cases).
Data center operators should be careful in porting ML-based prediction models as-is across sites without sufficiently training on multiple sites and should prefer CNN-LSTM models if portability is a requirement.
down with increasing prediction horizon window (the MCC score for a 15-day window is 0.89), but the rate of decrease is not steep for any model -SPL group feature based ML models are effective even at sufficiently large prediction horizons.Does J-Index classification for feature selection degrade the overall prediction accuracy compared to models trained with all features?
Recall that we employed J-Index classification choosing the features (different performance and location metrics) for training our models.
We compared the prediction quality for models using all the features ( Figure 13).
Our results show that manually selecting a subset of features using J-Index provides similar quality results, although it does affect the precision and recall trade-offs slightly.
This notable observation suggests that data center operators can use J-Index to manage the storage overhead of storing attributes from thousands of disks without risking the prediction quality significantly.
To the best of our knowledge, prior works do not consider all three types of data: SMART, performance, and location data for failure prediction.
Instead, previous works rely only on SMART attributes [4,19,36,41,59,79,87].
We analyze large-scale field data collected from one of the biggest e-commerce sites, while most of the previous works propose prediction methods based on the publicly available Backblaze data [4,5,7,9,62,80].
Also, the datasets analyzed were of limited in size, types of vendors, and were often closed-source [8, 9, 24, 28, 30, 31, 36, 37, 41, 51, 53, 58-60, 77, 83, 85, 88, 89, 92].
Much of previous work with disk failure prediction is limited to the detection of incipient failures [9,41,59,67,84,85].
Although Lima et al. [23] proposed an approach to predict disk failures in long-and shortterm, they are also limited to SMART attributes.
Studies by Sandeep et al. [25, 26, 78] enable a qualitative understanding of factors that affect disk drive reliability.
Yang et al. [90] and Gerry Cole [21] both achieve reliability predictions based on accelerated life tests.
In addition, non-parametric statistical tests [58], Markov Models [24,92], and Mahalanobis distance [85] have been proposed to predict disk failures.
Hughes et al. [41] applied the multivariate rank-sum test and achieved a 60% failure detection rate (FDR).
In our study, we focus on HDDs, and some previous works have focused on solid-state drives (SSDs).
Three typical studies of SSDs are based on data collected by Facebook [57], Google [77], and Alibaba Cloud [88].
Furthermore, Grupp et al. [33] examined the reliability of flash memory.
Ouyang et al. [61] studied programmable SSD controllers at a web services company.
A number of studies by Cai et al. [11-18] explored different patterns of Multi-Level Cell (MLC) flash chip failure.
Ma et al. [53] found the accumulation of reallocated sectors would deteriorate disk reliability.
Narayanan et al. [60] proposed machine learning based approaches to answer what, when and why of SSD failures.Overall, few studies have separately employed ML [4,36,54,79] and DNN techniques [4,23] to predict disk failures.
Our work explores and compares three classic ML methods with two DNNs using six feature groups to predict disk failures.
This kind of extensive analysis helps us derive insights such as there is no need to employ complex DNNs when only SMART data are available.
In fact, we are also the first to demonstrate the cross-site portability of different models.
We conducted a field study of HDDs based on a largescale dataset collected from a leading e-commerce production data center, including SMART attributes, performance metrics, and location markers.
We discover that performance metrics are good indicators of disk failures.
We also found that location markers can improve the accuracy of disk failure prediction.
Lastly, we trained machine learning models including neural network models to predict disk failures with 0.95 F-measure and 0.95 MCC for 10 days prediction horizon.
The authors are very thankful to the reviewers and our shepherd, Kimberly Keeton, for their constructive comments and suggestions.
This work is supported in part by the National Science Foundation (NSF) grants CCF-1563728 and 1753840.
