Concurrency libraries can facilitate the development of multi-threaded programs by providing concurrent implementations of familiar data types such as queues or sets.
There exist many optimized algorithms that can achieve superior performance on mul-tiprocessors by allowing concurrent data accesses without using locks.
Unfortunately, such algorithms can harbor subtle concur-rency bugs.
Moreover, they require memory ordering fences to function correctly on relaxed memory models.
To address these difficulties, we propose a verification approach that can exhaustively check all concurrent executions of a given test program on a relaxed memory model and can verify that they are observationally equivalent to a sequential execution.
Our Check-Fence prototype automatically translates the C implementation code and the test program into a SAT formula, hands the latter to a standard SAT solver, and constructs counterexample traces if there exist incorrect executions.
Applying CheckFence to five previously published algorithms, we were able to (1) find several bugs (some not previously known), and (2) determine how to place memory ordering fences for relaxed memory models.
Shared-memory multiprocessors and multi-core chips are now ubiquitous.
Nevertheless, programming such systems remains a challenge [44].
Concurrency libraries such as the java.util.concurrent package JSR-166 [27] or the Intel Threading Building Blocks [22] support the development of safe and efficient multi-threaded programs by providing concurrent data types, that is, concurrent implementations of familiar data abstractions such as queues, sets, or maps.Client programs with threads that execute concurrently on a multiprocessor can benefit from implementations that are optimized for concurrency.
Many sophisticated algorithms that use lock-free synchronization have been proposed for this purpose [17,18,31,33,34,43].
Such implementations are not race-free in the classic sense because they allow concurrent access to shared memory locations without using locks for mutual exclusion.Algorithms with lock-free synchronization are notoriously hard to verify, as witnessed by many formal verification efforts [6,14,46,50] and by bugs found in published algorithms [10,32].
Many more interleavings need to be considered than for implementations that follow a strict locking discipline.
Moreover, the deliberate use of races prohibits the use of classic race-avoiding design methodologies and race-detecting tools [1,12,19,24,36,39,41,49].
To make matters worse, most commonly used multiprocessor architectures use relaxed memory ordering models [2].
For example, a processor may reorder loads and stores by the same thread if they target different addresses, or it may buffer stores in a local queue.
Whereas fully lock-based programs are insensitive to the memory model (because the lock and unlock operations are designed to guarantee the necessary memory ordering), implementations that use lock-free synchronization require explicit memory ordering fences to function correctly on relaxed memory models.
Fences counteract the ordering relaxations by selectively enforcing memory order between preceding and succeeding instructions.
A lack of fences leads to incorrect behavior, whereas an overzealous use of fences impacts performance.
Nevertheless, fence placements are rarely published along with the algorithm.To help designers and implementors develop correct and efficient programs for relaxed models, we present a method that can statically check the consistency of a data type implementation for a given bounded test program and memory model (Fig. 1).
Given the implementation code, a small test program representing the client program, and a choice of memory model, our CheckFence prototype verifies for all concurrent executions of the test that the observed results are consistent with the expected semantics of the data type.
If the check fails, a counterexample trace is presented to the user who can then analyze and fix the problem.We build upon and further automate the general technique described in our prior case study [4].
At the heart of this method is an encoding that represents the executions of the test program as solutions to a propositional formula.
To obtain this formula, we first compile the code for each thread into a bounded sequence of instructions.
Then we separately encode the thread-local program semantics (in the style of CBMC [5]) and the memory model (in axiomatic form).
Once the encoding is complete, we can use a standard SAT solver to solve for erroneous executions.Our method proceeds in two steps.
First, we perform a specification mining: we automatically create a specification for the given test by enumerating the set of correct observations.
An observation is a combination of argument and return values, and it is correct if it is consistent with some atomic interleaving of the operations.
For example, for the test in Fig. 1,(A = 0, B = 1, X = 0, Y = 1) is a correct observation, whereas (A = 0, B = 1, X = 0, Y = 0) is not.After mining the specification, we then check all executions of the test on the chosen memory model to see that the observed values are contained in the specification.
This step is called inclusion check.
If the inclusion check fails, we produce a counterexample trace.
The trace presents the details of the execution to the user, who can then analyze and fix the problem.We implemented this method in a prototype called CheckFence and applied it to five previously published algorithms, writing test programs and C code that closely follows the published pseudocode.
We were thus able to 1.
Reproduce two known bugs in a concurrent deque algorithm known as "snark" [8,10,26].2.
Uncover a not-previously-known bug in a lazy list-based set implementation.
The published pseudocode [18] fails to initialize a field, which was missed by a prior formal verification using the PVS interactive proof system [6].3.
Show numerous failures on architectures with relaxed memory models (the original algorithms assume sequentially consistent architectures), and fix them by inserting appropriate memory ordering fences.
In this section, we describe the parameters of the verification problem (test programs, correctness condition, and memory models) more concretely.
To exercise the implementation code, we use test programs.
A test program specifies a finite sequence of operation calls for each thread.
It may choose to leave the argument values unspecified, which conveniently allows us to cover many scenarios with a single test.
It may also specify initialization code to be performed prior to the concurrent execution of the threads.
The basic idea of our method is to compare the set of concurrent executions with the set of serial executions.
Given a test program T that makes invocations to the operations of some abstract data type, and an implementation I, we define• ET,I,Serial is the set of serial executions.
Serial executions are executions by a single processor that interleaves the threads and treats the operations as atomic, that is, does not switch threads within operations.
• ET,I,Y is the set of multiprocessor executions for memory model Y .
The model Y may use relaxed memory ordering rules.We define these sets more formally below in Section 2.3.1 and proceed first to a description of how they relate to our correctness condition.
For a given execution e we define the observation vector obs(e) to consist of the argument and return values to the operations that occur in e. For test program T and implementation I, we define the observation set asST,I = {obs(e) | e ∈ ET,I,Serial}The observation set S captures the intended behavior of the data type, and serves as a specification in the following sense.
For test T and observation set S, we say that the implementation I satisfies S on memory model Y if and only if ∀e ∈ ET,I,Y : obs(e) ∈ S Because the argument and return values are all that the client program observes, implementations that satisfy the specification are guaranteed to appear to the client program as if they executed the operations atomically.Note that we need not necessarily use the same implementation when extracting the specification S and when performing the inclusion check.
In practice, it is often sensible to write a reference implementation (which need not be concurrent and is thus simple) to construct the observation set.
We currently support two hardware-level memory models.
One is the classic sequential consistency [25], which requires that the loads and stores issued by the individual threads are interleaved in some global, total order.
Sequential consistency is easiest to understand; however, it is not guaranteed by most multiprocessors [2].
The other model is Relaxed [4].
It allows the hardware to relax the ordering and atomicity of memory accesses.
Specifically, it permits (1) reorderings of loads and stores to different addresses, (2) buffering of stores in local queues, (3) forwarding of buffered stores to local loads, (4) reordering of loads to the same address, and (5) reordering of control-or data-dependent instructions.
For a test T with n threads, an implementation I, and a memory model Y , we define the set of executions ET,I,Y to consist of all execution traces e = (w1, . . . , wn) such that (1) each wi is a finite sequence of basic machine instructions (loads, stores, assignments, and fences) within which all instructions are annotated with the execution values, (2) each instruction sequence wi corresponds to a sequential execution (under standard semantics) of the code for thread i as specified by T, I, and (3) the trace e satisfies the conditions of the memory model Y as defined in the next section.
We now present the core of our axiomatic formulations for sequential consistency and Relaxed.
First, we need some common notation.
Let A be a set of addresses, and V be a set of values.
For a given execution trace e = (w1, . . . , wn), let Xe = Le ∪ Se be the set of memory accesses in the trace, with Le being the set of loads and Se being the set of stores.
For an access x ∈ Xe, let a(x) ∈ A be the address of the accessed location, and v(x) ∈ V be the value loaded or stored.
For an address a ∈ A, let i(a) ∈ V be the initial value of the memory location a. Let <p be the program order, that is, a partial order on Xe such that x <p y whenever x precedes y within some sequence wi.
Consistency.
An execution trace e is sequentially consistent if there exists a total order <M over Xe (the memory order) subject to the following conditions.
For each load l ∈ Le, let S(l) be the set of stores that are "visible" to l:S(l) = {s ∈ Se | a(s) = a(l) ∧ (s <M l)}Then the following axioms must be satisfied:1.
if x <p y, then x <M y 2.
if l ∈ Le and S(l) = ∅, then v(l) = i(a)3.
if l ∈ Le and s ∈ S(l) and v(l) = v(s), then there exists a store s ∈ S(l) such that s <M s .
Relaxed.
An execution trace e is allowed by the memory model Relaxed if there exists a total order <M over Xe (the memory order) subject to the following conditions.
For each load l ∈ Le, let S(l) be the set of stores that are "visible" to l:S(l) = {s ∈ Se | a(s) = a(l) ∧ ((s <M l) ∨ (s <p l))}Then the following axioms must be satisfied:1.
if x <p y, a(x) = a(y), and y ∈ Se, then x <M y2.
if l ∈ Le and S(l) = ∅, then v(l) = i(a)3.
if l ∈ Le and s ∈ S(l) and v(l) = v(s), then there exists a store s ∈ S(l) such that s <M s .
The model Relaxed differs from sequential consistency in two places.
For one, axiom 1 has been weakened to allow the memory order to be different from the program order.
Secondly, the set S(l) has been modified to allow forwarding of values from stores sitting in a local store queue to subsequent loads by the same processor: S(l) may contain stores that precede a load in program order (s <p l) but are performed globally only after the load is performed (l <M s).
Seriality.
We can conveniently formalize serial executions (executions that interleave the operations atomically) by defining seriality as a special kind of "memory model" as follows.
Given T, I and an execution trace e, define an equivalence relation ∼ over Xe such that x ∼ y whenever x, y are part of the same operation.
Then, we say e is serial if and only if (1) it is sequentially consistent, and (2) if x ∼ x and y ∼ y , then (x <M y) ⇔ (x <M y ).
Memory models can be compared in terms of the execution traces they allow.
We call a model Y stronger than another model Y if every execution trace that is allowed by model Y is also allowed by Y .
For example, seriality is stronger than sequential consistency, and sequential consistency is stronger than Relaxed.The purpose of Relaxed is to provide a common, conservative approximation of several memory models (Sun SPARC v9 TSO/PSO/RMO [48], Alpha [7], and IBM 370/390/zArchitecture [23]).
All of these models are stronger than Relaxed, which implies that once code runs correctly on Relaxed, it will run correctly on the former.However, Relaxed is not strictly weaker than the official PowerPC [13], IA-64 [21] and IA-32 [20] models because it globally orders all stores (the execution in Fig. 2 illustrates this point).
Even so, Relaxed still captures the most important relaxations of those models and is useful to determine where to place fences.
This limitation is not fundamental to our methodology, and we are activelyInitially, x = y = 0 thread 1 thread 2 thread 3 thread 4 store x, 1 store y, 1 load x, 1 load y, 1 load-load fence load-load fence load y, 0 load x, 0Figure 2.
An execution trace that is not possible on Relaxed, but not ruled out on PPC, IA-32, and IA-64.
On the latter, we represent the load-load fence as follows: (PPC) lwsync, (IA-32) lfence, (IA-64) replace load that precedes the fence with load-acquire.
working on formalizing a weaker version of Relaxed to close the gap.
We now describe how we implemented and applied our method.
See Fig. 3 for a schematic view of the internal structure of the tool.
CheckFence has a front-end that compiles the C code into an intermediate representation.
This intermediate representation uses a custom language called load-store language (LSL) which precisely defines the possible instruction sequences of stores, loads, fences, and synchronization instructions for each thread.The front-end is based on the CIL framework [37] which parses C and provides us with a cleaned-up and somewhat simplified abstract syntax tree.
From there, compilation into LSL is relatively straightforward for most programs.
CheckFence translates concurrent data type implementations of realistic detail precisely and automatically, but it may refute some programs if they contain unsupported features.
We discuss some of the choices we made in the following paragraphs.
See Fig. 4 for the abstract syntax of LSL.C multiprocessor semantics.
The C language does not specify a memory model (standardization efforts for C/C++ are still under way).
Therefore, executing memory-model sensitive C code on a multiprocessor can have unpredictable effects [3].
On the machine language level, however, the memory model is officially defined by the hardware architecture.
It is therefore possible to write C code for relaxed models by exerting direct control over the C compilation process to prevent optimizations that would alter the program semantics.
The details of how to do this (for example, volatile declarations, compiler pragmas, or command line options) are compiler-dependent and beyond the scope of this work.
Here, we simply assume a "vanilla" compilation without optimizations, and we apply the hardware-level memory model to the resulting machine-level program.Values and types.
We found that the types present at C source level can not be relied upon (due to the presence of casts).
Therefore, we chose to keep LSL untyped; however, we do track the type of values at runtime, by distinguishing between undefined, integer, and pointer values.
The back-end also recovers some static type information directly from the untyped code by performing a range analysis (see Section 3.4).
The runtime types help to automatically detect bugs.
For example, we detect if a program uses an undefined value in a computation or a condition.
(number) n ∈ N (value) v ::= undefined | n | [ n ] (register) r (primitive op) f (procedure name) p (block tag) t (statement) s ::= (constant) r = v (primitive op) | r = f (r) (store) | * r = r (load) | r = * r (fence X) | fenceX (atomic block) | atomic { s } (procedure call) | p(r)(r) (labeled block) | t : { s } (leave block) | if (r) break t (repeat block) | if (r) continue t (assertion) | assert (r) (assumption) | assume (r)Pointer C value LSL value &(x) 0x000 [ 0 ] &(x.a) 0x000 [ 0 0 ] &(x.b) 0x008 [ 0 1 ] &(x.b[0]) 0x008 [ 0 1 0 ] &(x.b[1]) 0x00C [ 0 1 1 ] &(x.b[2]) 0x010 [ 0 1 2 ] &(y) 0x014 [ 1 ]Pointer values.
We represent pointer values as a sequence of natural numbers [n1 . . . n k ] where (k ≥ 1), representing the base address n1 and sequence of offsets n2, . . . , n k .
The offsets may be field or array offsets, providing a unified way of handling arrays and structs.
See Fig. 5 for an example of how C pointers can be represented in this manner.
The advantage of keeping the offsets separate from the base address is that we can avoid addition or multiplication when encoding pointer operations in the back-end.
Moreover, our range analysis (Section 3.4) can often determine that large portions of the sequence are statically fixed.Control flow.
To facilitate a minimalistic unrolling of loops in the back end, we retain the nested block structure of the source program.
Conditionals are represented by conditional breaks and continues which can exit or repeat an enclosing block identified by its tag.Fences.
Fences are special machine instructions that guarantee some ordering among the memory accesses that precede and follow it.
We currently support four kinds of memory ordering fences: load-load, load-store, store-load and store-store (as used by the Sparc RMO memory model [48]).
An X-Y fence guarantees that all accesses of type X that appear before the fence will be ordered before all accesses of type Y that appear after the fence.
Fences can guarantee some ordering among the memory accesses without enforcing full sequential consistency.
Synchronization.
We currently model all synchronization in LSL using atomic blocks.
The instructions within an atomic block are guaranteed to execute in program order, and they are never interleaved with instructions in other threads.
See Fig. 6 for a pseudocode example of how we model the compare-and-swap instructions using an atomic block.
Our lock and unlock operations are based on code from the SPARC v9 architecture manual [48] and use a spin loop, an atomic load-store primitive, and partial memory ordering fences (Fig. 7).
To avoid an unbounded unrolling of the spin loop, we use a custom reduction for side-effect free spin loops.C features.
The C language has many features, not all of which are supported by our CheckFence prototype.
We are adding features as needed to handle the implementations we wish to study.
Already supported are pointers, structs, arrays, full integer arithmetic, limited pointer arithmetic, nested loops, limited gotos, and packed structures.
1 The back-end first transforms the test program T and implementation I by inlining the operation calls and unrolling the loops (more on this in Section 3.3).
As a result, the code for each thread is a simple sequence of machine-level instructions comprising only loads, stores, register assignments, fences, and forward branches.
We now encode the possible executions as a propositional formula ΦT,I,Y (Z) over boolean variables Z such that each solution of Φ corresponds to an execution e ∈ ET,I,Y (more on this in Sec-tion 3.2.1).
Once we have Φ thus encoded, we can perform the specification mining and inclusion check using a standard SAT solver as follows.Specification mining.
To construct the observation set ST,I we use the following iterative procedure.
First, we provide the formula ΦT,I,Serial(Z) as an input to the SAT solver.
Next, we run the solver which will return a solution for Z, corresponding to some serial execution e ∈ ET,I,Serial.
Let o1 be the observation of this execution.
Now, we add additional constraints to the solver to exclude executions that have the observation o1 and run the solver again.
If there is another solution, it gives us a new observation o2.
By continuing this process (adding constraints to rule out observations we already saw) until the SAT solver determines insatisfiability (say, after k steps), we obtain the observation set ST,I = {o1, o2, . . . , o k }.
Our practical experience suggests that although the set of serial executions ET,I,Serial can be quite large (due to nondeterministic memory layout and interleavings), the observation set ST,I contains no more than a few thousand elements for the testcases we used.
Therefore, the iterative procedure described above is sufficiently fast, especially when used with a SAT solver that supports incremental solving.Inclusion check.
For a given test T , implementation I, memory model Y , and finite observation set S, we check the inclusion obs(ET,I,Y ) ⊂ S by asking the SAT solver to find a solution for the variables Z subject to the constraintsΦT,I,Y (Z) ∧ ^ o∈S obs(Z) = oIf the SAT solver finds a satisfying assignment, then the corresponding execution is a counterexample because its observation is not equal to any observation in S. On the other hand, if the SAT instance is unsatisfiable, the inclusion check passes.
After inlining I in T and unrolling the loops, the code resembles a machine-level program consisting only of loads, stores, register assignments, fences, and forward branches.
Following the definition of ET,I,Y in Section 2.3.1, we can now encode the possible execution traces e = (w1, . . . , wn) by introducing variables to represent the execution values and writing constraints over these variables to capture the conditions (2) and (3).
To encode the thread-local semantics (condition 2), we use a formula ∆ T,I,k for each thread k. To encode the memory model (condition 3), we use a formula ΘT,I,Y .
The thread-local formulae.
To obtain ∆ T,I,k , we follow a technique similar to the CBMC tool [5]; specifically, we use a register SSA (single static assignment) form that guarantees that for each program point and for each register there is statically known, unique instruction that assigned it last.For each thread k, we introduce a set of variables V k containing one variable for each instruction, representing the LSL value produced by that instruction.
Next, we introduce a set C k of boolean variables containing one variable for each forward branch, representing whether the branch is taken or not.
We now create constraints for each assignment to express the relationship between the consumed and produced values, and for each branch to express how the branch condition depends on the value of some register.
By taking the conjunction of all these constraints we get a formula ∆ T,I,k (V k , C k ) that captures the possible executions of the thread in an unspecified environment (that is, for unspecified values returned by the loads).
The memory model formula.
We construct a formula ΘT,I,Y to represent the memory model.
In our case, Θ is simply the conjunction of the memory model axioms for Y (Section 2.3.2).
If we represent the memory order <M by a variable M (ranging over all total orders of X), we thus get a formula ΘT,I,Y (M, V, C) where V = S k V k and C = S k C k .
This formula depends on the variables in V because the axioms make reference to the addresses and values used by instructions.
It depends on the variables in C because the axioms apply to executed memory accesses only (an access that is skipped over by a branch is not part of the set Xe).
The combined formula.
We combine the thread-local and communication formulae as followsΦT,I,Y (M, V, C) ≡ ΘT,I,Y (M, V, C) ∧ ^ k ∆ T,I,k (V k , C k )Finally, we need to transform Φ down to the level of the SAT solver, which requires conjunctive normal form ΦT,I,Y (Z) for some set of boolean variables Z.
We thus need to replace all quantifiers by finite conjunctions or disjunctions and break M and V down to boolean variables.
During this process we introduce auxiliary variables, as follows.1.
To encode the memory order M , we introduce auxiliary variables {Mxy | x, y ∈ X} such that Mxy represents x <M y.To express antisymmetry, we represent Mxy and Myx by the same SAT variable (adjusting the sign of literals).
To express transitivity, we add explicit clauses.2.
To encode the value variables V , we use bitvectors.
To get a conservative estimate on the required width, we perform a range analysis (Section 3.4).3.
For each pair of values v1, v2 ∈ V , we introduce auxiliary variables to represent the equalities v1 = v2.
We use separate clauses to break the equalities down to the bit level (which we need only do for equality literals that appear in the formula).4.
We use for each l ∈ L an auxiliary variable Init l that represents whether S(l) = ∅, and for each s ∈ S and l ∈ L an auxiliary variable Flow sl that represents whether s is the maximal store in S(l).
The resulting CNF encoding is polynomial: the number of SAT variables and clauses is quadratic and cubic in the size of the unrolled test program, respectively.
For the implementations and tests we studied, all loops are statically bounded.
However, this bound is not necessarily known in advance.
We therefore unroll loops lazily as follows.
For the first run, we unroll each loop exactly once.
We then run our regular checking, but restrict it to executions that stay within the bounds.
If an error is found, a counterexample is produced (the loop bounds are irrelevant in that case).
If no error is found, we run our tool again, solving specifically for executions that exceed the loop bounds.
If none is found, we know the bounds to be sufficient.
If one is found, we increment the bounds for the affected loop instances and repeat the procedure.
To reduce the number of boolean variables, we perform a range analysis before encoding Φ.
Specifically, we use a simple lightweight flow-insensitive analysis to calculate for each SSA register r and each memory location m sets Sr, Sm that conservatively approximate the values that r or m may contain during a valid execution.
We can sketch the basic idea as follows.
First, initialize Sr and Sm to be the empty set.
Then, keep propagating values as follows until a fixpoint is reached: Two-lock queue [33] Queue is represented as a linked list, with two independent locks for the head and tail.
Nonblocking queue [33] Similar, but uses compare-and-swap for synchronization instead of locks ( Fig. 9).
lazylist Lazy list-based set [6,18] Set is represented as a sorted linked list.
Per-node locks are used during insertion and deletion, but the list supports a lock-free membership test.
Nonblocking set [16] Set is represented as a sorted linked list.
Compare-and-swap is used instead of locks.
Nonblocking deque [8,10] Deque is represented as linked list.
Uses double-compare-and-swap.
Table 1.
The implementations we studied.
We use the mnemonics on the left for quick reference.
• constant assignments of the form r = c propagate the value c to the set Sr.• assignments of the form r = f (r1, . . . , r k ) propagate values from the sets Sr 1 , . . . , Sr k to the set Sr (applying the function).
• stores of the form * r = r propagate values from the set Sr to the sets {Sm | m ∈ S r }.
• loads of the form r = * r propagate values from the sets {Sm | m ∈ S r } to the set Sr.This analysis is sound for executions that do not have circular value dependencies.
To ensure termination, we need an additional mechanism.
First, we count the number of assignments in the test that have unbounded range.
That number is finite because we are operating on the unrolled, finite test program.
During the propagation of values, we tag each value with the number of such functions it has traversed.
If that number ever exceeds the total number of such functions in the test, we can discard the value.
We use the sets Sr for four purposes: (1) to determine a bitwidth that is sufficient to encode all integer values that can possibly occur in an execution, (2) to determine a maximal depth of pointers, (3) to fix individual bits of the bitvector representation (such as leading zeros), and (4) to rule out as many aliasing relationships as possible, thus reducing the size of the memory model formula.
We studied the five implementations shown in Table 1.
All of them make deliberate use of data races.
Although the original publications contain detailed pseudocode, they do not indicate where to place memory ordering fences.
Thus, we set out to (1) verify whether the algorithm functions correctly on a sequentially consistent memory model, (2) find out what breaks on the relaxed model and (3) add memory fences to the code as required.First we wrote symbolic tests (Fig. 8).
To keep the counterexamples small, we started with small and simple tests, say, two to four threads with one operation each.
All memory model-related bugs were found on such small testcases.
We then gradually added larger tests until we reached the limits of the tool.
Fig. 10 shows the tests we ran for each implementation.
We found several bugs that are not related to relaxations in the memory model.
The snark algorithm has two known bugs [10,26].
We found the first one quickly on test D0.
The other one requires a fairly deep execution.
We found it with the test Dq, which took about an hour.We also found a not-previously-known bug in the lazy listbased set: the pseudocode fails to properly initialize the 'marked' field when a new node is added to the list.
This simple bug went undetected by a formal correctness proof [6] because the PVS source code did not match the pseudocode in the paper precisely [28].
This confirms the importance of using actual code (rather than pseudocode and manual modeling) for formal verification.
T0 = ( e | d ) Ti2 = e ( ed | de ) T1 = ( e | e | d | d ) Ti3 = e ( de | dde ) Tpc2 = ( ee | dd ) T53 = ( eeee | d | d ) Tpc3 = ( eee | ddd ) T54 = ( eee | e | d | d ) Tpc4 = ( eeee | dddd ) T55 = ( ee | e | e | d | d ) Tpc5 = ( eeeee | ddddd ) T56 = ( e | e | e | e | d | d ) Tpc6 = ( eeeeee | dddddd )Set tests: (a, c, r for add, contains, remove)Sac = ( a | c ) Sar = ( a | r ) Sacr = ( a | c | r ) Saacr = a ( a | c | r ) Sacr2 = aar ( a | c | r ) Saaarr = aaa ( r | rc ) S1 = (a' | a' | c' | c' | r' | r') Sarr = ( a | r | r )Deque tests: (a l , ar, r l , rr for add/remove left/right)D0 = (a l rr | ar r l ) Db = (rr r l | ar | a l ) Da = a l a l (rr rr | r l r l ) Dm = (a l a l a l | r r r r r r | r l | a r ) Dq = (a l | a l | a r | a r | r l | r l | r r | r r )Figure 8.
The tests we used.
We show the invocation sequence for each thread in parentheses, separating the threads by a vertical line.
Some tests include an initialization sequence which appears before the parentheses.
If operations need an input argument, it is chosen nondeterministically out of {0, 1}.
Primed versions of the operations are restricted forms that assume no retries (that is, retry loops are restricted to a single iteration).
As expected, our testcases revealed that all five implementations require extra memory fences to function correctly on relaxed memory models.To give a concrete example, we show the source code for the non-blocking queue with appropriate fences in Fig. 9.
To our knowledge, this is the first published version of Michael and Scott's non-blocking queue that includes memory ordering fences.
We verified that on Relaxed these fences are sufficient and necessary for the tests in Fig. 10.
Of course, our method may miss some fences if the tests do not cover the scenarios for which they are needed.
An interesting observation is that the implementations we studied required only load-load and store-store fences.
On some architectures (such as Sun TSO or IBM zSeries), these fences are automatic and the algorithm therefore works without inserting any fences on these architectures.
Incomplete initialization.
A common failure occurs with code sequences that (1) allocate a new node, (2) set its fields to some value and (3) link it into the list.
On relaxed memory models, the stores to the fields (in step 2) may be delayed past the pointer store [33], with fences added.
It is slightly simplified: the original code stores a counter along with each pointer, which we omit because it is not required in all contexts.
No such modifications were made to the other algorithms.
(in step 3).
If so, operations by other threads can read the node fields before they contain the correct values, with fatal results.
All five implementations showed this behavior.
The fix is the same in all cases: adding a store-store fence between steps (2) and (3).
For example, the store-store barrier on line 29 of Fig. 9 was added for this reason.Reordering of value-dependent instructions.
Some weak architectures (such as Alpha [7]) allow loads to be reordered even if they are value dependent.
For example, the common code sequence (1) read a pointer p to some structure and (2) read a field p->f is (somewhat surprisingly) susceptible to out-of-order execution: the processor may perform the load of p->f before the load of p by speculating on the value of p and then confirming it afterward [30].
We found this behavior to cause problems in all five implementations.
To avoid it, we add a load-load fence between the two instructions.
For example, the load-load fence on line 32 in Fig. 9 was inserted for this reason.Reordering of CAS operations.
We model the compare-andswap operation without any implied fences (Fig. 6).
As a result, two CAS instructions to different addresses may be reordered.
We observed this behavior only for the nonblocking queue, where it causes problems in the dequeue operation ( Fig. 9) if the tail is advanced (line 45) before the node is linked into the list (line 37).
To fix this problem, we added a store-store fence on line 44.
Reordering of load sequences.
The nonblocking queue uses simple load sequences to achieve some synchronization effects.
For example, queue->tail is loaded a first time on line 31; next, tail->next is loaded (line 33); then, queue->tail is loaded a second time (line 35) and the value is compared to the previously loaded value.
If the values are the same, the implementation infers that the values that were loaded for queue->tail and tail->next are consistent (that is, can be considered to have been loaded atomically).
A similar load sequence is used in the enqueue operation (lines 52 and 58).
For this mechanism to work, we found that the loads in the sequence must not be reordered, and we added a number of load-load fences to achieve this effect (lines 32, 34, 53, 55, 57).
The other implementations did not exhibit this behavior.
The performance results confirm that our observation set method provides an efficient way to check bounded executions of concurrent C programs (with up to about 200 memory accesses).
Furthermore, they indicate that for our encoding, the choice of the memory model has no significant impact on the tool execution time.Inclusion check statistics.
To illustrate the character of the inclusion checks, we show statistics and graphs in Fig. 10.
As described in Section 3.2.1, CheckFence encodes the inclusion problem as a CNF formula which is then refuted by the zChaff SAT solver [35] (version 2004/11/15).
To keep the trends visible, we do not include the time required for the lazy loop unrolling because it varies greatly between individual tests and implementations.Specification mining statistics.
We show information about the specification mining in Fig. 11a.
Most observation sets were quite small (less than 200 elements).
The time spent for the specification mining averaged about a third of the total runtime (Fig. 11b).
However, in practice, much less time is spent for observation set enumeration because (1) observation sets need not be recomputed after each change to the implementation, and (2) we can often compute observation sets much more efficiently by using a small, fast reference implementation (as shown by the data points for "refset").
Table 1) and test (listed in Fig. 8), we show (from left to right): the size of the unrolled code, the time required to create the SAT instance, the size of the SAT instance, the resources required by the SAT solver to refute the SAT instance, and the overall time required.
All measurements were taken on a 3 GHz Pentium 4 desktop PC with 1GB of RAM, using zchaff [35] Impact of range analysis.
As described earlier, we perform a range analysis prior to the encoding to obtain data bounds, alias analysis, and range information.
This information is used to improve the encoding by reducing the number of boolean variables.
Fig. 11c shows the effect of the range analysis on runtime.
On average, the performance improvement was about 42%.
On larger testcases (where we are most concerned), the positive impact is more pronounced (the tool finished up to 3× faster).
Relaxed (see Sections 2.3 and 3.2.1).
To find out if the choice of memory model has an effect on the runtime, we separately evaluated the runtime for a sequentially consistent memory model.
The results indicate that on average, performance is about 4% faster for sequential consistency, which is insignificant.
Most prior work on verification of concurrent data types is based on interactive proof construction and assumes a sequentially consistent memory model [6,14,40,46,50].
To our knowledge, analogous proof strategies for relaxed memory models have not been investigated.Specialized algorithms to insert memory fences automatically during compilation have been proposed early on [11,42].
However, these methods are based on a conservative program analysis, which makes them less attractive for highly optimized implementations: fences can have a considerable performance impact [45,47] and should be used sparingly.Most previous work on model checking executions on relaxed memory models has focused on relatively small and handtranslated code snippets (such as spinlocks or litmus tests).
It can be divided into two categories: explicit-state model checking combined with operational memory models [9,38], and constraint solving combined with axiomatic memory models [4,15,51].
We prefer the latter approach for two reasons: (1) axiomatic models can more easily capture official specifications because the latter use an axiomatic style, and (2) constraint-based encodings can leverage the advances in SAT solving technology.When compared to our earlier case study [4], the method presented in this paper differs as follows:• We allow the operations of the implementation to be written as C code (rather than requiring a manual translation).
This improves the degree of automation and the precision, at the expense of a somewhat larger encoding.
• Our observation set method is more automatic and more general, because it does not require commit point specifications.
Implementations such as the lazy list-based set [18] are not known to have commit points [6,46].
• Our observation method is faster.
Fig. 12 shows a direct speed comparison on a logarithmic scale; the diagonal lines show constant speed ratios.
On average, the speedup was about 2.61×, but it approached an order of magnitude on some tests.
Verifying concurrent data type implementations that make deliberate use of data races and memory ordering fences is challenging because of the many interleavings and counterintuitive instruction reorderings that need to be considered.
Conventional verification tools for multithreaded programs are not sufficient because they make assumptions on the programming style (race-free programs) or the memory model (sequential consistency).
Our CheckFence prototype fills this gap and provides a valuable aid to algorithm designers and implementors because it (1) accepts implementations written as C code, (2) supports relaxed memory models, memory ordering fences, and lock-free synchronization and (3) can verify that the implementation behaves correctly for a given bounded test or will produce a counterexample trace if it does not.Future work includes (1) enhancements to the front-end to support more C features and data type implementations from the literature, and (2) the use of SMT solvers and customized decision procedures to improve the efficiency of the back end.
We are also working on applying our method to memory models that are weaker than Relaxed (such as the PowerPC model [13]) or defined at the language level (such as the new Java Memory Model [29]).
