We consider the problem of selecting threshold times to transition a device to low-power sleep states during an idle period.
The two-state case in which there is a single active and a single sleep state is a continuous version of the ski-rental problem.
We consider a generalized version in which there is more than one sleep state, each with its own power consumption rate and transition costs.
We give an algorithm that, given a system, produces a deterministic strategy whose competitive ratio is arbitrarily close to optimal.
We also give an algorithm to produce the optimal online strategy given a system and a probability distribution that generates the length of the idle period.
We also give a simple algorithm that achieves a competitive ratio of 3 + 2 √ 2 ≈ 5.828 for any system.
Suppose you are about to go skiing for the first time in your life.
Naturally, you ask yourself whether to rent skis or to buy them.
Renting skis costs, say, $30, whereas buying skis costs $300.
If you knew how many times you would go skiing in the future (ignoring complicating factors such as inflation, and changing models of skis), then your choice would be clear.
If you knew you would go at least 10 times, you would be financially better off by buying skis right from the beginning, whereas if you knew you would go less than 10 times, you would be better off renting skis every time.
Alas, the future is unclear, and you must make a decision nonetheless.Although the Ski-Rental problem is a very simple abstraction, this basic paradigm arises in many applications in computer systems.
In these situations, there is a system that can reside in either a low-cost or a high-cost state.
Occasionally, it is forced to be in the high-cost state (usually to perform some task).
A period between any two such points in time is called an idle period.The system pays a per time unit cost to reside in the high-cost state.
Alternatively, it can transition to the low-cost state at a fixed one-time cost.
If the idle period is long, it is advantageous to transition to the low cost state immediately; if the idle period is short, it is better to stay in the high-cost state.
An online algorithm which does not know the length of the idle period must balance these two possibilities.This problem has been studied in the context of shared memory multiprocessors in which a thread is waiting for a locked piece of data and must decide whether to spin or block [9,11].
Researchers investigating the interface between IP networks and connection-oriented networks have discovered this same underlying problem in deciding whether to keep a connection open between bursts of packets that must be sent along the connection [12].
Karlin, Kenyon and Randall study the TCP acknowledgment problem and the related Bahncard problem both of which are at heart ski-rental problems [10].
The problem also arises in cache coherency in deciding whether to update or invalidate data that has been changed in a processor's local cache [6,2].
An important application of the ski-rental problem is in minimizing the power consumed by devices that can transition to a low power sleep state when idle.
The sleep state consumes less power; however, one incurs a fixed start-up cost in making the transition to the high-power active state in order to begin work when a new job arrives.
At the architectural level, the technique of eliminating power to a functional component is called clock/power gating.
At a higher level, the powered-down component might be a disk drive or even the whole system (e.g., a laptop that hibernates).
The embedded systems community has invested a great deal of effort into devising policies governing the selection of power states during idle periods (termed Dynamic Power Management in their literature); see, for example, [4] for a survey.
These techniques have been critical to maximizing battery use in mobile systems.
While power is already a first-class parameter in system design, it will become increasingly important in the future since battery capacities are increasing at a much slower rate than power requirements.Most of the previous work on this problem has been concerned with two-state systems which have an active state and a single sleep state.
This paper focuses on finding power-down thresholds for systems that have more than one low-power state.
An example of such a system is the Advanced Configuration and Power Interface (ACPI) included in the BIOS on most newer computers, which has five power states, including a hibernation state and three levels of standby [1].
For the two-state problem, an online algorithm consists of a single threshold T after which time the algorithm will transition from the active to the sleep state.
The input to the problem is the length of the idle period and the cost of an algorithm is the total amount of energy it consumes over a single idle period.
Typically, an online algorithm is evaluated in terms of its competitive ratio -the ratio of the cost of the online algorithm to the cost of the optimal offline algorithm, maximized over all inputs.
When randomized algorithms are considered where the threshold T is chosen at random, we look at the ratio of the expected cost of the online algorithm to the cost of the offline algorithm.
Previous work has also addressed the two-state problem when the idle period is generated by a known probability distribution.
In this case, the online algorithm will choose a threshold which minimizes its expected cost, where the expectation here is taken over the random choice of the idle period.
We call such algorithms probability-based algorithms.The best deterministic online algorithm will stay in the high power state until the total energy spent is equal to the cost to power up from the low power state.
It is known that this algorithm achieves the optimal (deterministic) competitive ratio of 2 [9].
When one considers randomized online algorithms, the best competitive ratio achievable improves to e/(e − 1) [9].
If the idle period is generated by a known probability distribution, then the algorithm that chooses T so as to minimize the expected cost is always within a factor of e/(e − 1) of optimal.
Furthermore, this bound is tight since there is a distribution over the idle period lengths which will force any online algorithm to incur an expected cost that is a factor e/(e − 1) times larger than that incurred by the optimal offline algorithm [9].
Note that in the context of power-down systems, it may not be the case that the power usage in the sleep state is zero or even that the start-up cost in the active state is zero.
In these cases, both the online and the offline algorithm will incur an identical additional cost.
Thus, the ratio of the online to the offline cost will decrease and the optimal competitive ratio will be strictly less than two.
However, these additional costs do not change the optimal online or offline strategy in either the deterministic or the probability-based case, and the optimal competitive ratio that can be achieved for such systems can easily be determined as a function of all the parameters of the system.We denote the problem that involves powering down through k sleep states PD(k).
A formal description of the problem is as follows: we are given a sequence of k + 1 states S = s 0 , ..., s k .
There is also a vector of power-consumption rates K = κ 0 , . . . , κ k , where κ i is the power consumption rate of the system in state s i .
We assume as a convention that the states are ordered so that κ i > κ j for 0 ≤ i < j ≤ k.
So s 0 is the active state, and the system must transition to s 0 (i.e., power up) at the end of the idle period.
There is an associated transition cost d i,j to move from state s i to s j .
A system is described by a pair (K, d).
Note that there can be costs to move from high-power states to low-power states and vice versa.
However, the only power-up costs that are of interest are the costs to transition from a particular state s i to the active state s 0 since the only reason to transition to a higher power state is when a new task arrives.
A schedule or strategy A = (S A , T A ) consists of a sequence of n A + 1 states S A that is a subsequence of S, and a sequence of transition times T A .
Where obvious, we will omit the subscript A.
We require that S(0) = s 0 and T (0) = 0.
We use A(t) to denote the cost of the schedule produced by strategy A for an idle period of length t.
We also consider a generalization of PD(k) that we call PD(k, m) wherein we require that n A ≤ m, where 0 < m ≤ k is some limiting integer constant.
This generalization would be especially useful for engineers who have a large number of sleep state options available in the design phase, but are required to implement at most a fixed number of states in the product that rolls out into the market.The only previous work that examines the multiple-state problem PD(k) (from the perspective of worstcase guarantees) is [7] which considers the special case where the cost to power-down is zero and the algorithm only pays to move from low power states to higher power states.
Note that this also includes the case where the transition costs are additive (d i,j + d j,k = d i,k for i < j < k) since the costs to power down can then be folded into the costs to power up.
[7] gives natural generalizations of the algorithms for the two-state case both for the case when the idle period length is unknown and when it is generated by a known probability distribution.
It is shown that when the transition costs are additive, the generalized deterministic algorithm is 2-competitive and the probability-based algorithm is e/(e − 1)-competitive, thus matching the guarantees in the two-state case.There are two important directions left open by this work.
The first is based on the observation that systems, in general, do not have additive transition costs.
In many scenarios, additional energy is spent in transitioning to lower power states.
Furthermore, there could be overhead in stopping at intermediate states, resulting in non-additive transition costs (see [4] for an example).
The second point is that the known upper bounds are typically not optimal for the system under consideration.
That is, while it is true that there exist systems for which the optimal competitive ratio that can be achieved by any deterministic algorithm is 2 (and e/(e − 1) by any randomized algorithm), it is possible to achieve a better competitive ratio for many systems.
For multi-state systems, the optimal competitive ratio that can be achieved will, in general, be a complicated function of all the parameters of the system (the power consumption rates as well as transition costs).
For probability-based algorithms, the optimal competitive ratio will also depend on the probability distribution generating the length of the idle period.
While it may not be feasible to express the optimal competitive ratio as a function of all these parameters, a system designer would, in general, like to design a power-down strategy that obtains the best possible competitive ratio given the constraints of his or her particular system.
This paper establishes the following results.
• We give an algorithm that takes as input an instance of PD(k) that is described by (K, d), and an error parameter ǫ, and produces a power-down strategy A = (S A , T A ) whose competitive ratio is within an additive ǫ of the best competitive ratio that can be achieved for that system.
The algorithm runs in time O(k 2 (log k) log(1/ǫ)), where k + 1 is the number of states in the system, and also outputs the competitive ratio of A.
The algorithm works via a decision procedure which determines for a system and a constant ρ if there is a ρ-competitive strategy for that system.
This decision procedure also allows us to obtain lower bounds on the competitive ratio achievable by deterministic algorithms for specific systems, which in turn provides a lower bound on the competitive ratio achievable by deterministic algorithms in general.
In particular, we obtain a lower bound of 2.45 on the competitive ratio for deterministic algorithms.
This is the first lower bound known that is greater than 2.
Independently, Damaschke has given a lower bound of 3.618 [5].
• The above approach can be modified to solve the more general version where a bound of m is specified on the number of states allowed in final strategy.
We show how to extend the decision procedure to answer if there is a ρ-competitive strategy for the system that uses at most m power states.
• Experimental results show that there are significant performance gains to be made by estimating the distribution governing the length of an idle period based on recent history and using this estimate to drive a probability-based strategy [8].
We give an algorithm that takes as input a description of a system and a probability distribution generating the idle period length and produces the optimal power-down strategy.
Naturally, the running time of the algorithm will depend on the representation of the distribution.
In practice, this is most likely to be a histogram.
Our algorithm runs in timeO(k 2 (log k + B))where B is the number of bins in the histogram and k + 1 is the number of states.One outcome of the proof is that it also establishes the optimality of the strategy given in [7] for additive systems.
We then generalize this to find the best online algorithm subject to the restriction that at most m states are used, at the expense of an extra factor of m in the running time.
• We give a simple deterministic strategy that achieves a competitive ratio of 3 + 2 √ 2 ≈ 5.8284 for all systems.
This result gives a bound on the competitive ratio achieved by the optimal strategies generated by our algorithms.
Note that 3 + 2 √ 2 also serves as a bound on the ratio of the expected costs of the online and offline algorithms when the input is probabilistically generated.In the remainder of this paper, we use the terms schedule or strategy interchangeably to refer to the choices of states and threshold times for powering down.
The term algorithm will refer to a procedure that produces a schedule or strategy based on a particular system.Azar et al. in [3] consider a related problem which they refer to as Capital Investment.
This problem is a different generalization of the ski rental problem than the power-down problem considered here.
However, a special case of their problem coincides with a special case of our problem.
Specifically, they give a (4 + 2 √ 2)-competitive deterministic algorithm for the special case of the power-down problem in which the cost to transition to each state is the same, regardless of the state from which one is transitioning.
Later Damaschke in [5] improves the upper bound on the competitive ratio for this special case (also in the context of Capital Investment) to 4 for deterministic algorithms and 2.88 for ranomized algorithms.
In addition, Damaschke gives a 3.618 lower bound for any deterministic algorithm which subsumes the lower bound of 2.45 given here.
First we will establish that we can assume without loss of generality that the power-up transition costs are zero.
If this is not the case for some system (K, d), we can define a new system such that for any i < j, the cost to transition from s i to s j is d i,j + d j,0 − d i,0 and the cost to go from s j to s i is 0.
Since there is never any reason to transition to a higher power state unless the system is transitioning to the active state at the arrival of a new task, any set of actions in the original system will incur the same cost in the new system.
Thus, in the sequel we assume that d i,0 = 0 for all i.We also need to establish that we can assume that for all i < j, d i,j < d 0,j .
Recall that we are really usingd i,j to denote d i,j + d j,0 − d i,0 and d 0,j to denote d 0,j + d j,0 .
Thus, the assumption that d i,j < d 0,j really amounts to assuming that d i,j < d i,0 + d 0,j .
If this were not the case, we could just transition from state s i to state s j by first going to s 0 and then down to s j .
LetD(i) denote d 0,i .
Then OPT (t) = min i (D(i) + κ i t).
Let S(t) denote the state which attains the minimum -the optimal state.
The optimal strategy is to transition to state S(t) at time 0, and stay there through time t.
We assume that for every state, there is some idle period length for which the optimal strategy will use that state, i.e., range(S(t)) = {s 0 , . . . , s k }.
None of the online strategies we present will make use of a state that is never used by the optimal offline strategy for any time t. Note that OP T (t) is piecewise linear and S(t) is non-decreasing with t -as the idle period length gets longer, it becomes more worthwhile to pay the extra cost to transition to a lower power state.
Let b i denote the first time instant at which state s i becomes the optimal state, so b(0) = 0 and Figure 1 shows the total energy consumed by OPT as a function of the length of the idle period.
There is a line for each state.
The y-intercept is the transition cost to move to that state from the active state and the slope is the power consumption rate.
The energy consumed by the optimal strategy is the lower envelope of these lines since it will pick the single state which minimizes the cost for a given idle period length.D(i−1)+κ i−1 b i = D(i)+ κ i b i ⇒ b i = D(i)−D(i−1) κ i−1 −κ i .
We have b(0) < b(1) < . . . b(k).
Thus for t ∈ [b i , b i+1 ], OPT (t) = D(i) + κ i t = i−1 j=0 κ j (b j+1 − b j ) + κ i (t − b i )(1)We compare our online strategy with OPT (t) and want to get a strategy A which minimizes the competitive ratio, c A = sup t A(t) OPT (t) where A(t) denotes the total power consumption of A by time t. Let us for the moment assume that for some γ > 1, D(i) ≥ γD(i − 1) for all i = 1, . . . , k.
This is a nontrivial assumption that we will have to handle later.
Consider the strategy, A, which always stays in state S(t), the same state as OPT , at every time t.
The optimal strategy which knows the length of the idle period in advance will just transition to the optimal state.
Strategy A however must "follow" the optimal strategy, making each transition to a new state as the idle period gets longer.
This is the strategy proposed in [7] and shown to be 2-competitive for additive systems.
Note that this strategy is the same as the 2-competitive balance strategy for the two-state case.For t ∈ [b i , b i+1 ] the online cost is, A(t) = i−1 j=0 κ j (b j+1 −b j )+d j,j+1 +κ i (t−b i ).
In comparing this cost to the optimal cost in equation (1), observe that both terms have an additive κ i (t − b i ) which means that the ratio A(t) OPT (t) will be maximized at t = b i .
To bound the cost of A in terms of OPT , we use the fact thatOPT (b i ) ≥ D(i) and OPT (b i ) = i−1 j=0 κ j (b j+1 − b j )both of which come from equation (1).
This last equation is used in line three of the equations below as is the fact that D(i) ≥ γD(i− 1) for all i = 1, . . . , k.A(b i ) = i−1 j=0 κ j (b j+1 − b j ) + d j,j+1 ≤ i−1 j=0 κ j (b j+1 − b j ) + i j=1 D(j) ≤ OPT (b i ) + D(i) i j=1 γ −(i−j) ≤ 1 + γ γ − 1 OPT (b i ) = 2γ − 1 γ − 1 · OPT (b i ).
(2)This holds for any t implying a competitive ratio of 2γ−1 γ−1 .
Now suppose the assumption D(i) ≥ γD(i−1) does not hold.
We consider a new offline strategy OPT ′ that only uses a subset of states S ′ for which the property does hold, and is a γ-approximation of OPT , i.e., OPT ′ (t) ≤ γ · OPT (t).
We now view our problem as specified by just the states in S ′ , and execute strategy A as specified above, emulatingOPT ′ instead of OPT .
We get that A ′ (t) ≤ 2γ−1 γ−1 OPT ′ (t) ≤ γ(2γ−1) γ−1 OPT (t).
Setting γ = 1 + 1 √ 2, we get a competitive ratio of 3 + 2 √ 2 ≈ 5.8284.
We determine OPT ′ as follows.
Let S ′ = {s k } initially.
Consider the states in S in reverse order.
Let s i be the last state added to S ′ .
We find the largest j, 0 ≤ j < i s.t. D(j) ≤ D(i)/γ.
We add s j to S ′ and continue until no such j exists.
Note that s 0 ∈ S ′ since D(0) = 0.
OPT ′ will execute the optimal offline strategy assuming that only the states in S ′ are available.
Consider i, j s.t. s i , s j ∈ S ′ and no s ℓ is in S ′ for i < ℓ < j.
We have OPT ′ (t) = OPT (t) for t ∈ [b i , b i+1 ) and t ∈ [b j , b j+1 ).
For ℓ s.t. i < ℓ < j and time t ∈ [b ℓ , b ℓ+1 ).
OPT ′ (t) = min(D(i) + κ i t, D(j) + κ j t) and OPT (t) = D(ℓ) + κ ℓ t. j was chosen to be the largest value less than i such thatD(j) ≤ D(i)/γ which means that D(ℓ) > D(i)/γ.
Furthermore, since κ i ≤ κ ℓ , we have that OP T ′ (t) ≤ D(i) + κ i t ≤ γ D(ℓ) + κ ℓ t = γOP T (t),and OPT ′ is a γ-approximation to OPT .
2)-competitive strategy for any system.
In this section, we turn our attention to obtaining a near optimal schedule for a particular system.
More precisely, given a system (K, d) with state sequence S for which the optimal online schedule has competitive ratio ρ * , we give an algorithm that returns a (ρ * +ǫ)-competitive online schedule in time O(k 2 log k log(1/ǫ)).
The algorithm is based on a decision procedure which determines whether a ρ-competitive schedule exists for a given value of ρ.
Theorem 1 establishes an upper bound of 3 + 2 √ 2 on the optimal competitive ratio, so we perform a bisection search in the range [1, 3 + 2 √ 2] to find the smallest ρ such that there exists a ρ-competitive schedule.
We also output the resulting schedule.The following lemma shows that the online strategy must eventually get to a sufficiently low-power state.
Lemma 3 allows us to limit our concern to just the transition points in any online schedule.Lemma 2 If A = (S, T ) is a ρ-competitive strategy and s ℓ is the last state in S, then κ ℓ ≤ ρ · κ k .
Proof : For the sake of contradiction, assume that κ ℓ > ρ · κ k .
For A to be ρ-competitive, the function A(t) must lie entirely below ρ · OPT (t).
However the last line of ρ · OPT (t) has slope ρ · κ k and will therefore intersect the last line of A(t) which has a larger slope κ ℓ , after which time A(t) will exceed ρOPT (t).
This is a contradiction.
A has finite competitive ratio, then the earliest time ¯ t > 0 at which A(t) OPT (t) is maximized is a transition point in the strategy A.Proof : Let ρ = max t>0A(t)OPT (t) .
Consider the functions A(t) and ρOPT (t).
The function A(t) never exceeds ρOPT (t), and ¯ t is the earliest point at which these two functions have the same value, not considering the origin.
For the sake of contradiction, assume that ¯ t is not a transition point in A.
So we can find some small ǫ > 0 such that A(t) is linear in ( ¯ t − ǫ, ¯ t + ǫ).
Since A(t) is strictly less than ρOPT (t) in the interval ( ¯ t − ǫ, ¯ t) and A( ¯ t) = ρOPT ( ¯ t), it must be the case that the slope of A(t) is larger than the slope of ρOPT (t) in this interval.
This gives a contradiction, because A(t) has constant slope over ( ¯ t − ǫ, ¯ t + ǫ), and ρOPT (t) is a continuous function with decreasing slope, which means that A(t) > ρOPT (t) for t > ¯ t.We now explore ways to restrict the space of schedules we need to consider in searching for a ρ-competitive schedule.
For a strategy A = (S, T ), we say that a transition at time t ∈ T is ρ-eager (or just eager if ρ is clear from the context) if A(t) = ρOPT (t).
We say that A is a ρ-eager strategy if A(t) = ρOPT (t) for every t ∈ T .
Note that by Lemmas 2 and 3, a ρ-eager strategy that ends at state s such that κ s ≤ ρ · κ k is ρ-competitive.
Lemma 4 If A = (S, T ) is a ρ-competitive strategy, then there exists an eager strategy A ′ = (S, T ′ ) that is also ρ-competitive.
Proof : Figure 2 shows a schematic of the proof.
The jumps in the online cost (the dashed line) are transition costs.
The solid line is ρOPT (t).
The figure shows a transition time t at which the online cost is less than ρOPT (t).
The idea is that we can slide such a transition time earlier until it hits the function ρOPT (t) .
Consider the earliest transition time T which is not eager.
Suppose that A transitions from state s i to state s j at time T .
Let T ′ < T be the time of the immediately preceding transition; if there is no such transition time, then set T ′ = 0.
The function ρOPT (t) − A(t) is continuous in the interval (T ′ , T ) since A does not have any transitions in this open interval, and ρOPT (t) − A(t) is 0 at time T ′ and is strictly greater than d i,j at time T − ǫ for a small enough ǫ.
Let T be the earliest time after T ′ such that ρOPT (t) − A(t) = d i,j , so T < T .
Consider the strategy A ′ that is identical to A except that the transition from s i to s j is moved earlier from T to T .
we need to argue that A ′ is ρ-competitive.
Clearly A ′ (t) = A(t) for t ∈ [T, T ) and A(T ) = ρOPT (T ).
Also A ′ (T ) < A(T ) since A ′ transitions earlier to the low power state s j and hence uses less total energy, and since the strategies behave the same after time T , A ′ will continue to have a lower cost at all times t > T .
To see that A ′ (t) ≤ ρOPT (t) over the interval (T , T ), note that A ′ (t) is linear over this interval since A ′ remains in state s j .
Also ρOPT (t) is a piecewise-linear concave function since its slope is non-increasing over time.
Thus, since the points (T , A ′ (T )) and (T, A ′ (T )) both lie on or below this curve, the straight line connecting them lies under the curve ρOPT (t).
The procedure above can be repeated until all the transitions are eager.
to state s j .
Using the function ρOPT (t), one can compute the earliest ρ-eager transition time ¯ t to state s j in time O(log k).
Proof : Define the line l(t) = κ i t + ρOPT (t i ) − κ i t i + d i,j .
¯ t is the smallest t > t i such that ρOPT (t) = l(t).
If there is no such t, then a ρ-eager transition from s i to s j does not exist.
Since ρOPT (t) is concave we have that if l(t) < ρOPT (t), or if l(t) ≥ ρOPT (t) and the slope of ρOPT (t) is less than or equal to κ i , then ¯ t ≤ t; otherwise ¯ t ≥ t.
These inequalities allow one to do a binary search using the line segments of ρOPT (t) to determine ¯ t if it exists.
Let s ℓ be the optimal state (i.e., state of OPT (t)) at time t i .
Consider the line segments of ρOPT (t) corresponding to states s ℓ and s k .
Recall that b ℓ and b k are respectively the left end-points of these segments -these are the first time instants at which s ℓ and s k become the optimal states respectively.
Using the above inequalities, if we determine that ¯ t ≥ b k , then ¯ t is simply the point of intersection (if it exists) of l(t) with the segment (of ρOPT (t)) corresponding to s k .
Otherwise we have a "low" segment with end-point b ℓ , and a "high" segment with end-point b k .
Now we repeatedly consider the left end-point of the segment that is in the middle of the low and high segments, and use the above inequalities to update the low or high segment and the corresponding end-point accordingly, until the endpoints of the low and high segments correspond respectively to the left and right end-points of a segment of ρOPT (t).
When this happens we can compute ¯ t by finding the intersection point (if it exists) of l(t) and this segment.
The binary search can be implemented in time log k, where k is the number of segments (i.e., number of states).
Lemma 4 immediately gives an algorithm that is exponential in k, the number of states, and determines whether a ρ-competitive strategy exists for the system.
This algorithm enumerates all subsequences of states, and determines the ρ-eager strategy for that subsequence by finding the eager transition to each state based on the eager transitions to the previous states, as described in the proof of Lemma 5.
A ρ-competitive strategy for the system exists if and only if one of these ρ-eager strategies is ρ-competitive (i.e., ends at a state s with κ s ≤ ρ·κ k ).
The remainder of this section presents a way to remove the exponential dependence on k. Let S = s 0 , s 1 , . . . , s k be a sequence of states that form a system.
Define S s i →s j , to be the contiguous subsequence s i , . . . , s j , where s i and s j are elements of S such that i < j. Let Ψ s be the set of subsequences of S s 0 →s that include s 0 and s such that for each ψ ∈ Ψ s , one can find transition times for the state sequence ψ so that in the resulting schedule, each transition up to and including the transition to state s is a ρ-eager transition.
For a state q ∈ ψ, we will use t ψ,q to denote this ρ-eager transition time to q for the sequence ψ.
(Note that ψ uniquely determines the transition times t ψ,q .)
We define the earliest transition time E(s, ρ) of state s for the given system as E(s, ρ) = min ψ∈Ψs t ψ,s , that is, E(s, ρ) is the earliest time at which any online strategy can transition to state s while remaining ρ-eager over all its transitions up to (and including) the transition to state s. Observe that if there is ρ-competitive strategy that uses state s, then by Lemma 4, there is such a ρ-eager strategy, so Ψ s 񮽙 = φ and E(s, ρ) is well defined.
We call a transition to state s ρ-early (or simply early) if it happens at time E(s, ρ).
A strategy that consists entirely of early transitions is called a ρ-early strategy.
If there is a ρ-competitive strategy A = (S, T ), then there is an eager and early ρ-competitive strategy.Proof : Let s be the last state in S. Consider the sequence ψ ∈ Ψ s such that t ψ,s = E(s, ρ) and the strategy π that uses only the states in ψ, transitioning to state q ∈ ψ at time t ψ,q , i.e., π = ψ, {t ψ,q } q∈ψ .
Since A is ρ-competitive, it must be that κ s ≤ ρκ k and since π by definition has all ρ-eager transitions and ends in state s, it is also ρ-competitive.
We now argue that π is an early strategy.
Note that π was chosen so that the transition to state s is ρ-early.
We have to show that the remaining transitions of π are also ρ-early.
Suppose not.
Consider the latest transition that is not ρ-early.
Suppose this happens for state r (񮽙 = s), so T 1 = t ψ,r > E(r, ρ).
Let r ′ be the state just after r in sequence ψ.
Let ψ ′ ∈ Ψ r be the sequence for which t ψ ′ ,r = E(r, ρ) = T 2 .
T 2 is the earliest time that a ρ-eager schedule can transition to state r and the sequence of states in this schedule is given by ψ ′ .
Consider the hybrid strategy π ′ that uses the states in ψ ′ followed by the states in ψ that appear after r, with the transition times being t ψ ′ ,q for q ∈ ψ ′ and t ψ,q for q ∈ ψ r ′ →s .
Strategy π transitions to state r at time T 1 and strategy π ′ transitions to state r at time T 2 < T 1 .
Both of these transitions are eager transitions.
Both strategies are in state r at time T 1 and make the same state transitions thereafter.
Thus, for any t ≥ T 1 , π(t)− π(T 1 ) = π ′ (t)− π ′ (T 1 ).
In particular, both strategies transition to r ′ (the state after r) at time t ψ,r ′ = E(r ′ , ρ) = T ′ .
Using the equation above we have thatπ ′ (T ′ ) = π(T ′ ) − π(T 1 ) − π ′ (T 1 ).
We will show that π ′ (T 1 ) < π(T 1 ) which implies, in particular, that π ′ (T ′ ) < π(T ′ ).
So in π ′ the transition to r ′ is no longer ρ-eager.
Arguing as in Lemma 4 this means that we can shift the transition to r ′ to get an eager transition at an earlier time.
But this contradicts the assumption that the transition to state r ′ at time T ′ was an early transition.We now prove that π ′ (T 1 ) < π(T 1 ).
The transitions to state r in schedules π and π ′ are eager transitions, so both the points (T 2 , π ′ (T 2 )) and (T 1 , π(T 1 )) lie on the ρOPT (t) curve.
Since π(t) < ρOPT (t) for all t, the the slope of ρOPT (t) at time T 1 is at least κ r , the slope of π(t) at time T 1 , and strictly greater since the gap between ρOPT (t) and π(t) must accommodate the transition cost from state r to r ′ at time T ′ .
The concavity of ρOPT (t) implies that its slope is greater than κ r over the interval[T 2 , T 1 ].
ρOPT (t).
So π(T 1 ) = ρOPT (T 1 ) > ρOPT (T 2 ) + κ r (T 1 − T 2 ) = π ′ (T 1 )where the last inequality follows since π ′ stays in state r in the interval [T 2 , T 1 ].
¿From Lemma 6 we can deduce that we only need to consider a specific early and eager schedule, the one that is determined by the E (.
, ρ) values, to determine if a ρ-competitive strategy exists.
We can now define a decision procedure EXISTS that takes a system and a constant ρ and outputs YES if a ρ-competitive strategy exists for the system, and NO otherwise.
The procedure can be modified to also output a ρ-competitive strategy (if it exists).
We employ a dynamic programming approach to calculate E(s i , ρ), for 0 < i ≤ k.
We always start with the high power state and hence E(s 0 , ρ) = 0.
Suppose we have computed E(s j , ρ) for all j = 0, . . . , i − 1.
Let t j be the earliest time at which the system ρ-eagerly transitions from ′ is (T ′ , π ′ (T ′ )).
The idea is to show that at time T , π ′ has a lower cost than π.
s j to s i given that the transition to s j is ρ-eager and occurs at time E(s j , ρ).
If such a transition is not possible, then we assign t j = ∞.
We can compute t j in O(log k) time as described in Lemma 5.
Then, E(s i , ρ) = min j<i t j .
Determining each E(s i , ρ) requires examining j different possibilities, so finding all the early transition times for all states takes time O(k 2 log k).
By Lemma 2, we know that if E(s i , ρ) is finite for some state s i where κ i ≤ ρ · κ k , we know that a ρ-competitive strategy exists.
One can quickly elicit the schedule by starting from state k and retracing the states that minimized the earliest transition time.
We use the procedure EXISTS to do a bisection search in the interval [1, 3 + 2 √ 2] and find a ρ-competitive strategy where ρ ≤ ρ * + ǫ.
The total time taken is O(k 2 log k log(1/ǫ)).
We now turn our attention to adapting this dynamic programming technique to solve PD(k, m) where a bound of m is specified on the number of states that can be used by the online algorithm.
We introduce a new parameter b modifying our function to E(s i , ρ, b), where 0 ≤ b ≤ min(i, m).
The intuition is that function E is now required to return the earliest time when the system can transition to state s i while staying entirely below ρOPT (t) and using at most b + 1 states from s 0 , . . . , s i .
The base case is E(s 0 , ρ, b) = 0 for all b ≥ 0.
Intuitively, E(s i , ρ, b) is determined by the "best" state s j prior to s i such that at most b − 1 states were used to reach s j .
Notice that for any given state s i and fixed ρ, E(s j , ρ, b) is non-increasing as b increases.
Therefore, as above we can write E(s i , ρ, b) = min j<i t ′ j , where t ′ j is the earliest time when the system ρ-eagerly transitions from s j to s i given that the transition to s j was ρ-eager and occurred at E(s j , ρ, b − 1).
The running time increases by a factor of m now and is O(k 2 m(log k) log(1/ǫ)).
Karlin et al. study the two-state case when the length of the idle period is generated by a known probability distribution p [9].
(Although they examined the problem in the context of the spin-block problem, their problem is identical to our two-state case.)
They observed that the expected cost of the online strategy that makes the transition to the sleep state at time T isT 0 p(t)(κ 0 t)dt + ∞ T p(t) κ 0 T + κ 1 (t − T ) + β dt,(3)where κ 0 is the power consumption rate in the active state, κ 1 is the power consumption rate in the sleep state and β is the transition cost between the two states.
The online strategy then should select the transition time T that minimizes this cost.The multi-state case presents two distinct challenges.
The first is to determine the optimal sequence of states through which an online strategy should transition throughout the course of the idle period.
Then once this sequence has been determined, the optimal transition times need to be determined.
Our proof proceeds by establishing that the only transition times that need to be considered are the optimal transition times for two-states systems.
Suppose, for example, that we are considering a sequence of state transitions in which state s i is followed by state s j .
Let T i,j denote the optimal transition time from state s i to s j if these were the only two states in the system (that is, if s i were the active state and s j were the only sleep state).
Note that T i,j can be determined by the expression above.
We establish that regardless of the rest of the sequence, the optimal transition point from state s i to s j is T i,j .
We call the T i,j 's the pairwise-optimal transition times.Lemmas 7 and 8 establish that the pairwise-optimal transition times happen in the right order.
That is for i < k < j, T i,k ≤ T k,j .
If this is not the case, then any subsequence that has s i followed by s k followed by s j can not possibly be the best sequence of states.
Note that the T i,j 's may not necessarily be unique.
In general, we will select the earliest transition time that minimizes the cost for the two state system.Lemma 9 then shows that as long as the pairwise-optimal transition times are in the right order, they give the globally optimal set of transition times for that subsequence.
Our algorithm then uses this fact to find the optimal sequence of states by dynamic programming.
Note that it is not necessary to exhaustively consider all possible subsequences.
Consider a particular subsequence of l+1 states s a 0 , . . . s a l .
In order to avoid the double subscripts, throughout this subsection we will rename our subsequence.
q 0 , q 1 , . . . , q l .
Since the strategy must start in state s 0 , we can assume that q 0 = s 0 .
For i < j, define β i,j to be the cost to transition from state q i to state q j , that is, β i,j = d a i ,a j .
Furthermore, we will refer to the power consumption rate of state q i as α i , that is, α i = κ a i .
We will consider the strategy that transitions through the states in the subsequence q 0 , q 1 , . . . , q l .
Suppose that we use transition time T i to transition from state q i−1 to state q i .
It will be convenient for notation to define T l+1 = ∞ and T 0 = 0.
The cost of the strategy that uses these transition times is:cost(T 1 , . . . , T l ) = l+1 j=1 T j T j−1 p(t)α j−1 (t − T j−1 )dt + l j=1 ∞ T j p(t) α j−1 (T j − T j−1 ) + β j−1,j dt.
(4)The goal is to pick the T 1 , . . . , T l so as to minimize the above cost.
This is the optimal cost for the subsequence q 0 , . . . , q l .
For each i ∈ {1, . . . , l}, letγ i = α i−1 −α i β i−1,i. Lemma 7 Suppose that there is an i < j such that γ i < γ j , then there is a a strict subsequence of q 0 , . . . , q l whose optimal cost is no greater than the optimal cost for q 0 , . . . , q l .
from state q j−2 to state q j−1 and then immediately transitions to state q j at either time ¯1 γ j p(t)dt.Comparing, equations (5) and (6), the expressions are almost identical except for the γ in the last term.
Since γ j−1 < γ j and ¯t j ¯ t j−1 p(t)dt ≥ 0, We have that F j,j − F j−1,j α j−2 − α j−1 ≤ F j−1,j − F j−1,j−1 α j−1 − α j .
Let ω 1 = 1/(α j−2 − α j−1 ) and ω 2 = 1/(α j−1 − α j ).
Note that both ω 1 and ω 2 are at least 0.
Rearranging, we get thatω 1 ω 1 + ω 2 F j,j + ω 2 ω 1 + ω 2 F j−1,j−1 ≤ F j−1,j .
Now suppose that we consider only the two-state system consisting of state q i−1 and state q i .
We will let τ i denote the optimal threshold time if these are the only two states in the system.
We have that τ i is the time T that minimizesT 0 p(t)α i−1 tdt + ∞ T p(t) α i−1 T + α i (t − T ) + β i−1,i dt.Note that the value of T that results in the minimum above may not be unique.
In this case, we take τ to be the smallest value which achieves the minimum.
Also note that by subtracting the term ∞ 0 p(t)α i tdt (which is independent of T ) and dividing by β i−1,i in the above definition, it can be seen that τ i = arg min T f (γ i , T ) wheref (γ, T ) = T 0 p(t)γtdt + ∞ T p(t)(γT + 1)dt.Note that for a two-state system whose active state and sleep states has power consumption rates of γ and 0 respectively and whose transition cost is 1, f (γ, T ) denotes the expected power consumed by an online strategy that transitions to the sleep state at time T .
We will show that for a particular subsequence of states, if we minimize the cost over all choices for the thresholds, the resulting thresholds are those obtained by the pair-wise optimization above.
First, however, we must establish that the τ i values have the correct ordering.
γ i > γ i+1 , then τ i ≤ τ i+1 .
Proof : Intuitively, γ i is the ratio of the additional power cost of being in state q i instead of state q i−1 over the transition costs between the two states.
It stands to reason that the larger this cost, the sooner one would want to transition from state q i−1 to state q i .
We will formalize this argument using a proof by contradiction.
Suppose that we have τ i > τ i+1 and γ i > γ i+1 .
The proof will make use of the definition of f (γ, T ) given above.
τ i is the smallest value for T which attains the minimum of f (γ i , T ).
Since τ i+1 < τ i , we know that f (γ i , τ i+1 ) > f (γ i , τ i ).
By the definition of τ i+1 , we have that f (γ i+1 , τ i ) ≥ f (γ i+1 , τ i+1 ).
Thus, it should be the case thatf (γ i+1 , τ i ) − f (γ i+1 , τ i+1 ) ≥ 0 > f (γ i , τ i ) − f (γ i , τ i+1 ).
(7)Using the definition of f (γ, T ) above, for anyT 1 < T 2 , f (γ, T 2 ) − f (γ, T 1 ) = γ T 2 T 1 p(t)(t − T 1 )dt + ∞ T 2 p(t)(T 2 − T 1 )dt − T 2 T 1 p(t)dt.The quantity inside the square braces above is non-negative.
This implies that the quantity f (γ, T 2 ) − f (γ, T 1 ) is non-decreasing in γ.
This, however, contradicts Inequality 7 and the fact that γ i > γ i+1 .
Finally, we prove the main lemma which states that the transition times are simultaneously optimized at the pairwise-optimal transition points.
For a given subsequence of states q 0 , . . . , q l , if τ i−1 < τ i for all i ∈ {1, . . . , l}, then the minimum total cost is achieved for cost(τ 1 , . . . , τ l ).
The basic idea is that we can interpret cost (T 1 , . . . , T l ) − ∞ 0 p(t)α l tdt as the sum of the power consumed in l two-state systems, where the i th system, (for i = 1, . . . , l), has states whose power consumption rates are (α i−1 − α i ) and 0 and the cost to transition between the two is β i−1,i .
Note that ∞ 0 p(t)α l tdt is a constant, independent of the choice of T i 's.
After rescaling, one can write this expression as a linear combination of the f (γ i , T i ) terms.
Since τ i minimizes f (γ i , T ), and the τ i values have the right ordering, this implies that cost(T 1 , . . . , T l ) is minimized by setting T i = τ i for i = 1, . . . , l.We will establish below that we can rewrite (4) as follows:cost (T 1 , . . . , T l ) = ∞ 0 p(t)α l tdt + l i=1 T i 0 p(t)(α i−1 − α i )tdt + ∞ T i p(t) (α i−1 − α i )T i + β i−1,i dt .
(8)So by rescaling, we get thatcost(T 1 , . . . , T l ) − ∞ 0 p(t)α l tdt = l i=1 β i−1,i f (γ i , T i ).
We want to choose T 1 ≤ · · · ≤ T l to minimize this expression.
Since τ 1 ≤ · · · ≤ τ l and each τ i = arg min T f (γ i , T ) it follows that the minimum is attained by setting T i = τ i for each i.To complete the proof we show the equivalence of (4) The summations over the j indices in (9) telescope to show that the two expressions are identical.
We now present a simple polynomial time algorithm to obtain the optimal state sequence for a given system.
First, for each pair (i, j), 0 ≤ i < j ≤ k, let T i,j denote the optimal transition point if s i and s j were the only two states in the system.
The time complexity of determining a single T i,j depends on the representation of the probability distribution.
In practice, this is most likely to be estimated by a finite histogram with B bins starting at time 0 and sampled at a uniform discrete interval of δ.
It follows that bin i corresponds to time δi.
It is not difficult to generalize this for variable sized bins.
We will also assume that all transition times occur at some δi.
The height of bin i is H(i) and this implies that the probability that the idle time t equals δi is given by H(i) P i H(i) .
In Algorithm 1, we calculate ACC [i] and ACCT [i] values, which are iδ 0 p(t)dt and iδ 0 tp(t)dt and we then use them to evaluate T i,j values.
We can re-write the expression for the cost of a two state system in equation (3) Once the T i,j 's are found, we sweep through them in non-decreasing order, keeping a running tab of the best sub-schedules that we can achieve ending in each state s i at each point in time.
When we encounter a T i,j , we check to see if transitioning from s i to s j can improve the current best sub-schedule ending in s j , and if it does, update our data structure to reflect it.A given strategy divides time into intervals where each interval is the period of time spent in a particular state.
The expected cost for a strategy given in equation (4)
