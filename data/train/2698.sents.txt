The web server's network protocol stack is constantly changing and evolving to tackle technological shifts in networking infrastructure and website complexity.
For example, Cubic to tackle high throughput, SPDY to tackle loss and QUIC to tackle security issues and lower connection setup time.
Accordingly, there are a plethora of protocols and configuration parameters that enable the web server's network protocol stack to address a variety of realistic conditions.
Yet, despite the diversity in end-user networks and devices, today, most content providers have adopted a "one-size-fits-all" approach to configuring user facing web stacks (CDN servers).
In this paper, we illustrate the drawbacks through empirical evidence that this "one-size-fits-all" approach results in sub-optimal performance and argue for a novel framework that extends existing CDN architectures to provide programmatic control over the configuration options of the CDN serving stack.
With the internet entering the zettabyte era and connecting billions of users, there is a huge disparity in the network conditions (bandwidth, latency and loss rates) faced by end-users [5].
To address this disparity and improve quality of experience (QoE), online service providers (OSP) are constantly developing new protocol algorithms and exploring new configuration standards for their content distribution network (CDN).
Over the last several decades, the networking community has developed a broad range of protocols across various layers of the networking stack from New Reno, Vegas, Compound TCP to Cubic, from HTTP1.1, and SPDY to HTTP2.While the community continues to develop new protocols and establish new configuration standards, there is an erroneous assumption that the newest protocols algorithms and configuration standards are strictly better than the older ones.
To simplify the text, in this paper we refer to protocol algorithms and configurations as configuration parameters.
For example, Cubic and HTTP2 are wildly deployed despite proven [31,8,25] evidence that these protocols are sub-optimal under certain conditions ( § 2.1).
The optimal choice of protocol and parameters is contingent on the network infrastructure [31,8,20], website complexity [4,22], and end-user device.
Furthermore, the constant evolution of networking infrastructure, enduser devices, and web complexity results in the constant churn of recommended and default configuration parameters.
Although different regions and ISPs leverage radically different infrastructures and host radically different devices, OSPs continue to employ a "one size fits all" which results in sub-optimal performance in some regions [2].
Motivated by this sub-optimal performance, online service providers are taking drastic steps to educate and motivate their developers to explicitly tackle underlying network and end-user heterogeneity.
For example, Facebook instituted "2G Thursday" -on Thursday all traffic is throttled to 2G speeds forcing developers and network operators to face and, subsequently, tackle issues faced by users on 2G networks [9].
In this paper, we eschew the notion of a "one size fits all" approach to protocol and configuration selection for CDN servers and instead argue for a "curated" approach to tuning and selecting configuration parameters.
In particular, we argue that CDN servers should be configured and setup with the optimal protocol and configuration parameters for serving each connection.
For example, a CDN server serving high loss, low bandwidth connections may employ a lower initial window size than a server serving low loss, high bandwidth connections.To this end, we propose a framework for practically improving end-user performance by introducing heterogeneity into the CDN server's networking configuration in a principled manner.
We argue for introducing a simple but standard interface to the CDN server's network Figure 1: Infrastructure for OSPs (e.g. Facebook [30]).
stack that exposes existing heterogeneity (e.g. TCP versions, HTTP protocol, or Peering link) and enables remote and automated configuration.
Additionally, our framework includes a learning entity that determines the optimal configuration for each end-user based on a combination of emulations and passive measurements.
Together our interface and the learning entity enables a CDN to systematically introduce heterogeneity into the server's network stack and improve end-user performance in a principled manner.This paper takes the first step towards realizing our system, Configtron, for reconfiguring CDN server's networking stacks.
Specifically, we make the following contributions: First, we present a clear demonstration that one configuration, does not fit all network conditions and web site complexities and moreover no one configuration is strictly better than another, thus motivating the case for heterogeneity within the CDN's networking infrastructure.
Second, the design of a framework for systematically learning optimal configurations and practically reconfiguring CDN web servers without loss of functionality.
And lastly, a strawman implementation of our Configtron, demonstrating the feasibility and practicality of our approach.Roadmap.
Next, we present background ( § 2) with a brief overview of motivating studies and related works.
§ 3 analyzes and quantifies the benefits of optimizing the CDN's networking stack.
§ 4 explores the design choice we adopted for Configtron.
§ 5 presents our prototype and § 6 expands on the design challenges.
Finally, § 7 provides concluding remarks.
We broadly define the CDN servers of an online service provider's network (Figure 1) as the user-facing servers that end-users interact with.
Specifically, the online service provider's servers in the points-of-presence (PoPs) and content distribution networks (CDNs) -more commonly referred to as edge servers or CDNs severs.
In this paper, we will use the term CDN or CDN server, interchangeably, to refer to the online service provider's servers located in the PoP and CDN.The CDN's networking stack, Figure 2, consists of the TCP protocol implementations, the web server application (e.g., Apache), and content provider's web application (e.g., PHP or Java code).
Traditional, these CDN servers employ broadly two different networking stacks -one for user facing connections and another for the data center facing connections.
The data center facing connections are often optimized to fully utilize the backhaul links.
Whereas, the user facing connections are often fine-tuned to provide optimal performance in aggregate rather than to provide optimal performance per-client.
To account for differences between a user's local conditions, the edge often deploys special web applications that infer properties of the user's local conditions and adjust multimedia images, html, and javascript to optimize ( Figure 2).
Essentially, the predominant approach is to reconfigure the CDN stack at the content layer.
For example, upon detecting a mobile client, many content providers redirect users to the mobile site.
This paper explores the benefits of extending reconfiguration from the content layer down to the server application and the TCP/IP stack -and presents a system for realizing reconfiguration in a principled manner.
In particular, there is a large space of potential parameters that can be explored from the application to the TCP/IP layers.
To demonstrate the richness of the CDN server's networking parameter space, in Table 1, we present a representative list of these parameters and in Section 3, we explore the impact of reconfiguring a subset of these parameters.
Next, we discuss existing studies that motivate the need for heterogeneity within the CDN's networking stack:Heterogeneity at the congestion layer (TCP): Although Cubic is used as the default congestion avoidance algorithm, the Linux kernel includes over 10 variants of TCP.
Moreover various measurement studies show that different variants are optimal for different networking conditions [27,10].
Orthogonally, others [6,2] have explored the impact of varying configuration parameters.More recently, Google adopted UDP over TCP in their design of QUIC (Quick UDP Internet Connections) [14], thereby introducing more diversity into the stack.
Existing studies of QUIC [20] show that QUIC outperforms [31,8,7,20] provide strong empirical evidence that HTTP/1.1 outperforms SPDY (HTTP/1) under high packet loss rates and complex web-page dependencies, where multiple TCP connections perform better than SPDY's single, multiplexed TCP connection [31].
Finally, we discuss related work on cross layer optimizations, standardizing the interface to the CDN's networking stack, and configuration management.Cross-layer optimizations: The most closely related work [2] explores the impact of cross layer configuration optimization for a limited set of configuration parameters, i.e., initial congestion window, HTTP pipelining, Appropriate Byte Count, and autocorking.
Configtron explores a broader set of parameters (see Ta- ble 2) and presents a framework to systematically tune these parameters in real time.
While Configtron explores the transport and application layers, other have examined making changes at the content layer [26], i.e., changing compression algorithms.
Yet, others have explored the orthogonal space of cross layer optimizations at the lower layers of the wireless and mobile networking stack [11,18,29,17].
Configuration Management: Configtron's configuration management interface is motivated by existing attempts to expose TCP parameters and standardize the management interface for configuring TCP [13,16].
Configtron extends on these approaches by encompassing more parameters and extending the management interface beyond TCP and into the application (HTTP) and networking layers.
Whereas orthogonal approaches [13] directly collect information from the network, Configtron passively infers the state of the network conditions.
Existing approaches to managing server configurations, focus on ensuring correct functionality and detecting misconfiguration [3,28].
These approaches can be used to help improve the manageability of Configtron and debug problems that arise while using Configtron.Takeaway While various measurement studies demonstrate the need for heterogeneous configurations, today's internet employs a "one size fits all strategy" where one set of configurations, suitable for a subset of the population, is used for the entirety of the internet.
We note that unlike these prior studies that explore a single protocol or configuration parameter, in § 3 we present a more holistic exploration across multiple protocols, parameters and layers of the protocol stack.
Furthermore, unlike prior work [2] we present a concrete system ( § 4) to reconfigure and optimize the different protocols and discuss design challenges ( § 6).
To understand and quantify the benefits of reconfiguring the networking stack, we conducted a large scale study on the impact of selecting the optimal configurations over the default configuration parameters across different network conditions and websites.
To ensure reproducible and precise experiments across the different configuration combinations, we leverage MahiMahi [23], a proven network emulator for running and re-running web page load experiments.
MahiMahi allows us to eradicate the variations in page load time (PLT) that may arise due to unpredictable network conditions.
Moreover, MahiMahi includes tools, called shells, that enable us to systematically modify and control network conditions -specifically, loss, bandwidth, and RTTs.
Each page is loaded five times and the mean PLT is computed after filtering outliers.In our experiments, we explore these dimensions: Network conditions: We explore traditional network properties: loss, latency, and bandwidth.
To control these network properties, we use the following MahiMahi shells.
To ground our study, we adjust the network latency, bandwidth, and loss to reflect realistic network conditions from various regions and networking infrastructure [1].
The network conditions tested include bandwidth of {0.3, 1, 5}Mbps, loss rates of {0, 1, 2.5, 5}% and delay of {50, 150, 250, 500}ms. Server Network stack: How inefficient is the "one-size-fits-all" strategy?
We begin by exploring the implications of using a single default configuration.
In Figure 3, we present the difference in PLT between the default and the best configuration.
We observe that in the median case, there is a 10% improvement in performance and in the tail (95th percentile) over a 40% improve in performance.
We note that the tail conditions explored in our experiments are in fact representative of a large fraction of realistic connections (e.g., 2G connections in developing and emerging regions in Africa and Asia): Specifically, 68% of the tail conditions have loss rates greater than 2.5% and bandwidth below 1Mbps.
Moreover, over 40% of the gains are for content rich websites, e.g., msn.com, tmall.com, espn.com and qq.com.
We note that while these networks will eventually get updated with newer infrastructure, the heterogeneity between different networks will always persist due to socioeconomic differences between regions and thus the need for heterogeneity will persist.
Are some configurations strictly better than others?
Figure 4 presents a comparison of the top four configurations from the experiments for www.bbc.com.
The coverage percentage (in circles) represents the percentage of conditions in which the given configuration works better than others, e.g., C1 is optimal for 37.5% of the conditions.
Rectangular box show the PLT for the destination configuration over the source configuration for a specific network condition (bandwidth, loss rate, delay), e.g., C1 is 2.7% better than C2 for condition (1Mb, 1% loss, 50ms).
Figure 4 shows that no configuration is strictly better than others -there is at-least one condition were each configuration is better or worst than the other configurations.
Moreover the differences are staggering.Is it easy to learn the best configuration for a specific network property?
Next, we attempt to answer the following question: "Is it possible to learn a mapping of configuration parameters to network conditions?"
To do this, we start with a simple learning algorithm, specifically, decision trees.
To that end, we built a C4.5 decision tree using the data from our experiments: the leaves of the tree are the configuration parameters in Table 2 and the nodes are the predictive network conditions.
To build the decision tree, we binned the different network conditions based on values.
In Figure 5, we present decision tree for www.youtube.com -a representative decision tree.
We summarized the decision tree and pruned nodes for more predictable configuration parameters: slow start after idle, low latency and autocorking.
Our decision trees demonstrate that it is possible to learn the mapping of "optimal configuration" to network conditions.
We suspect that with a larger configuration and with more dynamic networks, we will need to explore more complex learning algorithms.
In Figure 6, we present the architecture for Configtron, our framework for proactively supporting the reconfigu- ration of CDN server's network stack at large scale.
We illustrate the functionality of the different components by exploring the life cycle of a request.
When a new request arrives, the request router (our Layer 4 load balancer) sends the request to a front-end server.
Unlike traditional, Layer 4 load balancers, the request router contains meta-data mapping IP-prefixes to pools of VMs containing the appropriate configuration (for the specific IP-addresses).
For IP addresses that the request router contains no mappings for, the request router uses the default load balancing rules that sends the request to a pool of "default" servers -which are servers with default configuration.
Requests for IP addresses with known configurations are directed to the appropriate pool of servers with those conditions.
This pool of servers consists of a farm of appropriately configured VMs.
In Configtron, the VM represents the granularity of reconfiguration -the level with which Configtron is able to configure (and reconfigure) the CDN's network stack.
Moreover, configurations are done once, at the beginning of the connection.
We discuss the implications of these design choices in sections 6 and 8.
Configuration Manager: The configuration manager generates a mapping of IP-addresses to optimal configuration parameters.
To ensure scalability, the IP-addresses are aggregated (and clustered) by prefixes with similar network conditions and the configuration parameters are aggregated to N different templates (where N is empirically derived using methodology described in Section 3).
Aggregation along both directions minimizes the state maintained at the configuration manager and minimizes fragmentation of resources while incurring a slight performance inefficiency.Additionally, the configuration manager leverages a realistic emulator to test out different configuration values with different networking conditions and use a learn- ing function to learn the optimal configuration.
The exact details of the learning function are beyond the scope of this work and we merely sketch out the functional requirements.
We expect that the learning function can be implemented using a variety of machine learning techniques, e.g., deep reinforcement learning or decision trees, or more traditional testing techniques, e.g., A-B testing [30].
Abstractly, the learning function takes as input the inferred (measured) RTT, loss rate, bandwidth, and website structure, then explores different configuration parameters, and selects the parameters that optimize web page load times.Finally, the configuration manager maintains a constant pool of "free servers" each configured with the "N"-golden templates.
This pool of "free servers" ensures that new requests do not have to be delayed waiting for a new server to be configured.Config Agent: This runs within the hypervisor of the different physical servers, instantiating VMs with prespecified configurations.
The agent provides the configuration manager with a standard and a uniform interface across different servers regardless of the OS (Linux, Windows) and the web-server application (Apache, NG- inx).
Moreover, the agent collects and reports statistics for each connection (IP address) including the RTTs, loss, bandwidth, and jitter.
To explore the feasibility and viability of Configtron, we have developed an initial prototype and are exploring the implications of deploying it on Amazon AWS.
We have implemented the Config agent in Python in 890 lines of code.
The Config agent provides controls over the configuration parameters discussed in § 3.
In our AWS deployment, the Config Agent runs locally because we do not have access to the hypervisor.
The networking stack for our VMs consist of Ubuntu 16 and Apache.
The Configuration manager uses an offline learning function based on a decision tree generated from our MahiMahi experiments.
Our current prototype provides control over the parameters in Table 2 as well as the HTTP version.
The request router is implemented as an SDN switch running in a VM and acting as a proxy between the clients and front-end VMs.
Our design and prototype explore a single point in the design space.
In this section, we discuss alternate design points and their implications.
Inferring Network Conditions: Our current design infers the client's network conditions based on packets exchanged between servers and the clients; in a similar manner to how TCP learns a client's network conditions.
An alternate and more direct approach is to have the clients explicitly probe, capture and exchange network condition information with the servers.
This can be done by modifying the client software stack [32] to actively collect measurements and inform the CDN server or adding javascript or invisible images into the webpage that enables the webserver to collect client-side statistics [12].
As part of future work, we plan to explore the more accepted approach: embedding javascript or images for performance profiling.
Online Versus Offline Learning: Section 3 demonstrates that we can build decision trees and learn optimal configurations for different network conditions, however, this requires brute force and extensive testing which may be infeasible when we explore the broader space of configuration parameters and explore the more nuanced network conditions that appear in practice.
We plan to explore the use of online learning techniques, e.g., A-B testing [30], and compare the effectiveness of online with against learning techniques.
Configuration Granularity: Our current design reconfigures the stack at the granularity of a VM -with each VM containing a distinct set of configuration parameters.
While heavy weight, VM-level configurations allows us to reuse existing and mature tools while providing full control over all configuration parameters.
Alternatively, we could explore containers (e.g., Docker) as the granularity of control.
However, since containers share the same networking stack, we would need to use userspace TCP/IP protocols to provide control over certain TCP configurations, e.g., TCP version.
As part of future work, we plan to explore a fusion of both extremes.
Namely, leverage VM-level granularity for controlling kernel-level global parameters, e.g., TCP version, and container-level granularity for controlling connectionlevel local parameters, e.g., HTTP protocol version.
Reconfiguration Frequency: Our current design reconfigures the CDN's networking stack at the beginning of each connection.
This limits the flexibly of Configtron and prevents us from adapting to drastic changes in the end-user's networking conditions.
Alternatively, we could reconfigure the stack at finer granularities, i.e., before every packet or before every object.
Although reconfiguration at the finer granularity enables us to react more finely, and ultimately to improve performance, finer granularity introduces several significant challenges, e.g., managing reconfiguration overheads and tackling the implications of reconfiguration on existing state for the connection.
Reconfiguration Overheads: There are some overheads associated with reconfiguring the CDN's networking stack, specifically, VM setup cost (e.g., image transfer and bootup) and kernel reconfiguration (e.g., changing the protocol version).
To tackle these overheads, we plan to explore a combination of approaches to ameliorate this overheads, e.g., maintaining a fleet of preconfigured VMs and proactively scale-up this fleet in respond to fluctuations in demand.
Deployment Scenario: The current design explores a point in the design space that requires content-providers to modify and improve their infrastructure.
Yet, there are also points in the design space; where the contentprovider and the end-user cooperate, these points in the design space enable us to explore a broader range of configuration options including configuration on the enduser client and explicitly exchange of client side information.
Although this approach appears altruistic, this point in the design space can be easily explored by large online service providers, e.g., Facebook and Google.
As part of future work, we plan to explore the additional benefits that arise from leveraging client (end-user) cooperation.
In this paper, we argue that content providers should eschew the "one-size-fits-all" approach to configuring CDN network stacks and instead embrace heterogeneity in CDN network stack configurations.
To support our argument, we perform an empirical evaluation of the implication of configuration and find that heterogeneity can lead to significant improvements.
This paper takes the first step towards realizing heterogeneity by proposing an open but simple interface for configuring the network serving stack and introducing a framework that enables a CDN to practically leverage heterogeneity.
Our framework learns network conditions and enables the use of machine learning techniques to determine the optimal configuration for the different network conditions.
In this paper, we proposed that "one-size-fits-all" approach to tuning/configuring server networking stacks result in sub-par performance for some end-users, especially those users in emerging regions.
Due to the everexpanding nature of internet, all end-users do not face similar network conditions and improvement in underlying protocols do not uniformly benefit all users [31,8].
This argument stands in stark contrast to the traditional setup of server networking stacks where a single network configuration is used for a divergent set of users.Expected Feedback: Our proposal for dynamic reconfiguration of the CDN network stack is grounded on emulations and prototype implementations.
We are looking for feedback on challenges that can arise when deployed in large scale, production environment.
• Management Overheads: Dynamically reconfiguring the CDN protocol stack complicates performance diagnosis and troubleshoot.
We plan to investigate methods for reducing this complexity, e.g., minimizing the number of active configuration combinations.
• QuiC: Google employs QuiC, which utilizes UDP and not TCP.
Yet, QuiC has a number of configuration options thus making the underlying principles of Configtron immediately applicable to QuiC.
• Long-lived Connections: Configtron configures the online service provider's CDN networking stack at the beginning of the connection and this prevents us from dealing with drastic changes in the network which may require reconfiguring existing connections.
Fortunately, TCP's congestion avoidance algorithms are designed to explicitly handle these dynamic situations.
Configtron attacks an orthogonal problem and focuses on improving TCP (and other protocols) by tuning the configuration of their internal algorithms.
• Broader Evaluations and QoE Metrics: As part of ongoing work, we are planning to understand the limits of Configtron by evaluating Configtron across a larger space of configuration parameters; a wide range of network conditions (e.g., mobile networks or buffer-bloat) and dynamics (e.g., time of day effects); and a broader set of web page QoE metrics (e.g. SpeedIndex [15]) and Video QoE metrics.
