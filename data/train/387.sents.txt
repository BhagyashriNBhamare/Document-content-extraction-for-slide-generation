We study the emergent properties of an artificial neural network which combines segmentation by oscillations and biased competition for perceptual processing.
The aim is to progress in image segmentation by mimicking abstractly the way how the cerebral cortex works.
In our model, the neurons associated with features belonging to an object start to oscillate synchronously, while competing objects oscillate with an opposing phase.
The emergent properties of the network are confirmed by experiments with artificial image data.
The success of animals depends on their ability to extract relevant information from their environment.
Since animals have got very good at this during evolution, engineers have a lot to learn from the computational principles underlying the perceptual abilities of animals.In mammals, the cerebral cortex is largely responsible for interpretation and extraction of relevant information.
The perceptual abilities of cerebral cortex include learning to make relevant sensory discriminations, segmentation of objects and attentional selection of relevant objects.In this article, we focus on segmentation.
However, it is important to recognise that segmentation cannot be isolated from the other components.
For example, when segmenting objects in a visual scene, one typically has to be able to recognise the individual objects to know which parts go with which object.
On the other hand, recognition usually requires one to segment out the object first.
It is therefore impossible to achieve good performance by neatly separating the process into two consecutive stages of segmentation and recognition.
Nevertheless, this is what is usually done in machine vision: first segment the object and then recognise it.The cerebral cortex seems to take a different approach: segmentation and recognition are combined into an iterative, dynamical process.
The goal of this article is to study such a process from an engineering perspective.
We combine bottom-up biological inspiration with top-down demands and restrictions of the engineering problem of interpreting and extracting useful information for the environment.The rest of the article is structured as follows.
Section 2 gives a background on segmentation by coupled oscillators and on biased competition model for attention and learning.
In Section 3 we list the desired emergent properties that we would like to have in our model.
We start from high-level phenomena and work our way towards details.
Section 4 gives the definition of a model that has such properties, which is then experimentally confirmed in Section 5, followed by discussion in Section 6.
In this section, we will first introduce Gestalt principles which form the basis for segmentation.
Next, we discuss segmentation by coupled oscillators.
Finally, we introduce biased competition model for attention and learning.
Our goal in this paper is to apply segmentation with coupled oscillators to models which use biased competition for perception and learning.
When we humans see a new object, we may not know its identity but we can nevertheless tell what is part of the object and what is not.
In other words, we are able to segment out an object without having seen it before.In perceptual psychology, the rules of the organisation of perceptual scenes are called Gestalt principles [9].
Psychologists have identified several principles, such as proximity, common fate, similarity, continuity, closure, symmetry and convexity.
The Gestalt principle of continuity is illustrated in Figure 1a, where the human visual system groups some of the line segments to form a circle.What makes the Gestalt principles interesting in the current context is that they can be learnt from data.
In neural terms, the Gestalt principles can be implemented by giving positive connections between certain neurons in one area and some other neurons in an adjacent area.
Learning the connections can be based on simple correlations found in the data.
For example, features responding to lines of certain orientation in one part of the visual field are more probably co-activated with fea- tures of similar orientation in some other part of the visual field.
This mechanism is illustrated in Fig. 1b.
These "neural" Gestalt rules can be learnt from the data and they operate on the level on individual feature-coding neurons.
The principle is therefore applicable to any modality and also between modalities unlike, for example, many segmentation procedures that make use of the spatial structure of visual images.
Moreover, the neural Gestalt rules can be learnt locally and in parallel.
In the visual domain this means that the local correlations found in familiar objects generalise to new objects which have different overall shapes but nevertheless obey the same local correlations.
In the cerebral cortex, the representation of objects is distributed.
For instance, colour and movement are represented in different visual cortical areas in humans and other primates.
Moreover, the brain represents the objects in many levels of abstraction.
For instance, the cerebral cortex can recognise and represent the identity (lion or hammer), category (predator or tool) and emotional significance (dangerous or useful) of objects.Since there are typically multiple objects present in the world, the brain needs to represent which feature belong together.
Von der Malsburg [8] suggested that the brain would achieve this by a temporal code, by synchronising the neural firing of the neurons which represent features belonging together.
Such object-specific synchronisation was found experimentally by Gray and Singer [5] and Eckhorn et al [4].
From an engineering perspective, segmentation by synchronisation of coupled oscillators seems to be an attractive option because it should be able to work in a hierarchical neural network.
Such networks are used in practice when recognising objects.
It should therefore be possible to combine segmentation and recognition into an iterative process that solves both problems at the same time.Modelling work has shown that coupled oscillators are able to synchronise their firing under suitable conditions (for a review, see e.g. [6]).
This property has also been used for segmentation in many models (e.g., [12,1]; for a recent review, see [10]).
Based on psychophysical experiments, contextual (predominantly top-down) biasing of local lateral competition had been proposed as a model of covert attention in humans [3].
Usher and Niebur [11] then suggested a computational model for biased competition that has been shown to replicate many attentional phenomena, for instance both bottom-up and top-down aspects of attention [2].
Deco and Rolls [2] also showed that it is possible to learn the weights for contextual biasing by the mechanism outlined in Sec. 2.1.
In other words, the neural Gestalt rules can be applied in a relatively straight-forward manner to implement selective attention.Yli-Krekola [13] combined biased competition model with competetive learning.
This model not only supports attention but forms a good basis for learning hierarchical feature representations suitable for categorising objects.
The model already includes the lateral connections which can be used for segmentation.
However, the model selects just one object.
This makes it difficult to correctly segment objects if there are features which could belong to more than one object.
For segmentation, it would usually be better that each feature is assigned to the object where it fits best.
Such an assignment is in practice possible only if the model represents several objects at once or sequentially.Yli-Krekola et al [14] added a habituation mechanism to the model.
The purpose was to make the model switch between different objects and thus improve the segmentation capability.
In this paper we further develop the model by replacing the habituation mechanism by oscillators.
Essentially we are combining coupled-oscillator models with biased competition model.
This development is a step towards models which would support learning, segmentation and selection of relevant objects in a hierarchical network.
Our goal is to combine the oscillator ideas (Section 2.2) with the biased competition model (Section 2.3).
Both oscillations and competition are found on cerebral cortex so they should be compatible.The overall structure of our network is such that there are so called areas that correspond to patches in the image.
The areas get bottom-up input from the pixels.
The areas should be connected to each other with local interactions only, that is, there is no hierarchy or global signals.
The different areas should work in the same way, using the same algorithms.We start from four high-level emergent properties and continue with requirements for one area that would lead to those properties.
A1 The network should integrate information from local patches.
When seeing an object, the local features belonging to it should start to oscillate.
The local features strengthen each other if the features are compatible, for instance in the sense that an edge is continuous.
These pairwise connections translate into the gain of the whole population corresponding to the object.
A2 When a scene contains many objects or many different interpretations, the object with globally highest gain emerges.
The attention is thus drawn to the most obvious object.
A3 The oscillations of an object should synchronise internally and completely.Not only should pieces of objects synchronise to each other, but the synchrony should spread to the whole population.
A4 When there are multiple objects in a scene, they should desynchronise between each other.
When using only local connections, this can of course only happen when the objects overlap.
This should not be considered as restrictive as it might first sound.
When building a hierarchical representation of the scene, objects do "overlap" on high-level representations with large receptive fields, even if they do not on the pixel level or on the local feature level.
We hope to accomplish the above emergent high-level properties by incorporating the following low-level properties in a single area.B1 Not many neurons (e.g., less than one percent) should be active at the same time.
This is required for attention (A2).
The activity or oscillation of a single neuron should not grow without limits regardless of the strength of the bottom-up input or lateral support.
B3 Without any lateral support from other areas, the neuron should not start to oscillate clearly.
B4 With constant lateral support, the oscillation should become clearer.
B5 With oscillating lateral support, the neuron should oscillate with the same frequency and phase as the lateral input.
B6 The amplitude of the oscillation should describe the bottom-up activation and the oscillation of the lateral support.
The requirements B2-B6 are the basic requirements for the oscillatory system in general (A1).
B7 As the different neurons in an area compete for their time to become active (as required in B1), their oscillations should become antisynchronised, that is, the phase differences in lateral inputs should become even stronger in the activations.
This should lead into global desynchronisation (A4).
B8 The change from one neuron being active to another being active, should happen quickly and completely.
This should help in finding a clear separation between the segments (A3).
We propose a model that has the above properties.
Since the full model is rather complicated, we start by defining a single oscillator and show how it works, and only then expand it to the full model with several areas each consisting of several neurons.
We start by introducing a single oscillator (or neuron) consisting of a pair of signals, called activity x(t) and inhibition y(t).
The pair works a bit like cos and sin functions that are each other's derivatives with one minus sign: cos ′ (t) = − sin(t) and sin ′ (t) = cos(t).
The system is activated by a bottom-up input u(t) and it has intrinsic Gaussian noise n k (t).
We use a nonlinearity [·] + to keep all the signals positive.
This is important to ensure that the negative terms such as the inhibition −β 1 y(t) cannot activate the system.
Parameters α, β , . . . are positive numbers whose values are given in Table 4.2.
Figure 2 shows how the system responds to a bottom-up input that first activates the oscillator at time after t = 0, and then shuts it down after t = 100.
As required in B3, the oscillation does not have a constant frequency, but it is heavily affected by noise instead.
This will help the system to adapt to other signals when the model is enriched below.
Note also that the response is true to the bottom-up input in the sense that when the input disappears, the activity x(t) diminishes very quickly.x(t + 1) = (1 − α 1 )x(t) − β 1 y(t) + γu(t) + ε 1 n 1 (t) + /δ(1)y(t + 1) = (1 − α 2 )y(t) + β 2 x(t) + ε 2 n 2 (t) + (2) n k (t) ∼ N(0, 1)(3)[x] + = max(0, x) = x + |x| 2(4) In the full model, each neuron i = 1 . . . n has five non-negative signals at time t, the bottom-up input u i (t), the output activity x i (t), the inhibition y i (t), the gain control g i (t), and the lateral support v i (t).
The neurons are organised in areas a = 1 . . . A such that each neuron i belongs to exactly one area a(i).
W is an n × n non-negative weight matrix that has been learned separately.The discrete time dynamics of the signals are as follows:x i (t + 1) = (1 − α 1 )x i (t) − β 1 y i (t) + (ζ 1 v i (t) + γ)u i (t)(5)− η 1 ∑ j∈a(i) x j (t) + ε 1 n 1i (t) + /[g i (t + 1) + δ ] y i (t + 1) = (1 − α 2 )y i (t) + β 2 x i (t) + ζ 2 v i (t)u i (t) (6) − η 2 ∑ j∈a(i) y j (t) − θ ∑ j∈a(i) x j (t) + ε 2 n 2i (t) + g i (t + 1) = (1 − α 3 )g i (t) + α 3 (1 − κ)x i (t) + κ ∑ j∈a(i) x j (t) |a(i)|(7)v i (t) = ∑ j W i j x i (t)(8)n ki (t) ∼ N(0, 1)(9)The nonlinearity [·] + picks the positive part of the input.
The bottom-up input feeds the activity especially if it has lateral support, see the term (ζ 1 v i (t) + γ)u i (t).
A competition of activities within an area (B1) is produced by the term −η 1 ∑ j∈a(i) x j (t).
The activities are saturated (B2) by dividing by the gain control signal plus constant, g i (t) + δ .
The inhibition signal y i (t) has many similar terms as the activity itself.
The gain control signal g i (t) is a running average of the activity of the single neuron and the average activity in the area.
The lateral support signal v i (t) is only an auxiliary variable that collects the activities of other neurons mapped through the weight matrix W. Weights W i j = 0 whenever neurons i and j are in the same area.We used the parameter values given in Table 4.2.
The parameters were found by tuning them by hand in order to achieve the desired properties described in the previous section.
The signals were initialized to zeroes, that is, x i (1) = y i (1) = g i (1) = 0.
Table 1 Values of parameters used in the experiments.α 1 α 2 α 3 β 1 β 2 γ δ ε 1 ε 2 ζ 1 ζ 2 η 1 η 2 θ κ The experimental part includes two examples.
In the first experiment, we show how a single area syncronises to a fixed lateral input.
In the second experiment with artificial image data, we show how the system segments an image.
In the first experiment, we used only a single area a = 1 and three neurons i = 1, 2, 3.
The bottom-up input u i (t) = 1 is a constant 1 for each neuron the whole time.
Instead of modelling the lateral support with Equation (8), we used the signals v i (t) shown in the top-most subfigure of Figure 3, where two neurons get oscillating lateral support, but the third one does not.The resulting signals are shown in Figure 3.
The two neurons with oscillating lateral support start to oscillate strongly, whereas the third neuron only very mildly (see requirements B3-B6).
Note that the active phases in x i (t) are better separated Fig. 3 An experiment with a single area.
Each subplot shows the signals as a function of time t, from top to bottom, lateral support v i (t), output activity x i (t), inhibition y i (t), and the gain control g i (t).
Each colour corresponds to one neuron i. Note that the bottom-up input u i (t) is a constant 1 for all neurons.
than in the lateral support v i (t) (B7).
This is a good property that will help to separate the oscillations of separate object to have separate phases (A4).
We generated artificial data for the image segmentation problem.
Grey scale images of 30 × 30 pixels that each contain one object as shown in Figure 4.
The images were divided into 5 × 5 areas of 10 × 10 pixels each with 5 pixel overlap in each direction.
Because of overlapping areas, the grey scale values were multiplied with a kernel(1 + cos(φ ))/2 in both horizontal and vertical directions where φ goes from −π to π within the 10 pixel segment.
The patches from each area of 10000 examples were pooled into one and 64 features were learned with k-means clustering.
The features looked like 63 different curve segments and one empty feature.We transformed the data into binary activations of the features such that exactly one of the 64 features i got u i (t) = 1 for all t (the nearest prototype vector in kmeans), and the others have u i (t) = 0 for all t.
The empty feature was then dropped out.
Weights were learned by computing the correlation coefficient ρ i j for each feature over the data set and setting W i j = ρ 0.7 i j when ρ i j ≥ 0.06 and W i j = 0 otherwise.
Using sparse connectivity is important for computational efficiency.
Some of the weights are visualized in Figure 4.
For testing the segmentation, we introduced two objects into the same image, as shown in Figure 5.
First we tried to feed the combination on the pixel level (top right subplot) to activate several features in each area.
This led into a problem where a contour from a single object activates more than one feature, which start to compete with each other and oscillate in different phases.
This issue is further discussed in Section 6.
What we did instead, was to go around this problem and find (at most) one active feature for each object in each area, and combine the activations only afterwards (see middle row in Figure 5).
This way we ensured that similar features activated by just one contour do not start to compete with each other.The results are shown in Figure 6.
The activities caused by the two object start to oscillate with opposite phases (A1-A4) and the segmentation happens in just a few wavelengths of the system.
The activities x i (t) at times t = 101 . . .300 were fed into non-negative matrix factorisation [7] in order to represent them compactly as a product of two time series and two sets of features.
The two sets of features are shown in the result figure and they show the two objects well separated.
We have shown preliminary but promising results of a system that combines oscillations for segmentation and biased competition for attention.
The problem of finding the subset of features that best support each other to form objects is a very difficult one.
Instead of making an exhaustive (exponentially difficult) search for 3 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 255 260 265 270 275 280 285 such subsets, our approach solves it by using the emergent properties of oscillators.
Experiments confirm that it takes only a few wave-lengths before the oscillations synchronise to find the objects.
We noticed an important problem in the implementation.
Neurons in the same area that represent correlated features such as edges with only a slight difference in orientation or location, start to compete with each other.
This causes problems since a single object will in general activate many of such features, which causes unwanted competition within a single object.
In the current implementation we eliminated this problem in an artificial manner that cannot be used in a real problem.
We still need to solve this problem by changing the competition mechanism such that it would take into account the correlations within an area.Our current implementation may be excessively complex, for instance, it is very likely that some of the terms in the system dynamics described in Equations (5-9) could be left out by changing the other parameters.
In future, we hope to make it as simple as possible.
We would also like to set the parameter values automatically in order to achieve as fast and accurate segmentation as possible.The computational complexity of the proposed system is very high even though we already use a sparse connection matrix W.
There are many ways to make the system faster.
Firstly, we could skip modelling the activations of neurons that do not get enough bottom-up input.
This way, we would miss the phenomenon of false contours, though.
Secondly, we could change the time-scale of the system such that one would need fewer time points to see the oscillations settle down.
Thirdly, a parallel implementation of the system would be very efficient due to the design of local computations only.A natural extension of the current work is to further bias the competition with connections from other parts of a larger network.
For instance, if the system is looking for food, the food-like objects should draw the attention more easily than others.
