We show how to use a noisy feedback link to yield high-reliability streaming data communications.
We demonstrate a strategy that can maintain the best known reliability function (error exponent) in delay, even when the feedback link is noisy.
Only the capacity of the feedback channel need be sufficiently large for this result to hold.
More detailed characterization of the feedback link, e.g., its error exponent, is not required.
We discuss the architectural implications of our result, which are different from those drawn from block-coding paradigms.
I. INTRODUCTION Many communication applications such as control-over-networks or streaming media have stringent delay requirements.
These application-layer demands are often in conflict with physical-layer requirements for long block-lengths needed to ensure communication reliability.
It has long been known that feedback can help alleviate these tensions and make the trade-off between error probability and delay much more manageable [7] [6] [9] [12].
These studies fall under the rubric of error exponents.
Previous studies have focused on noiseless feedback where the transmitter can "look over the shoulder of the receiver."
In this paper we show how these improved trade-offs can often be maintained even when there is noise on the feedback link.
In Fig. 1 we diagram the end-to-end system issues that motivate this work.
At a high level, data is produced by the application layer at the source, bits are packetized into messages that are encoded into codewords, these packets are enqueued, and then transmitted over the channel.
Once decoded the data is consumed at the destination.
In all there are three sources of delay: packetization (waiting for enough data to form a message), queuing (caused by a backup in the transmission process), and service (the transmission time).
In this paper we focus on the service time delay from transmitter to receiver.
In regimes where the best trade-off between reliability and delay is achieved, service time dominates the end-to-end delay.
We review results for block and variable-length coding before focusing in on streaming data.
Streaming data systems are designed to communicate to the destination a sequence of Many communication applications such as controlover-networks or streaming media have stringent delay requirements.
These application-layer demands are often in conflict with physical-layer requirements for long block-lengths needed to ensure communication reliability.
It has long been known that feedback can help alleviate these tensions and make the trade-off between error probability and delay much more manageable [7] [6] [9] [12].
These studies fall under the rubric of error exponents.
Previous studies have focused on noiseless feedback where the transmitter can "look over the shoulder of the receiver."
In this paper we show how these improved trade-offs can often be maintained even when there is noise on the feedback link.In Fig. 1 we diagram the end-to-end system issues that motivate this work.
At a high level, data is produced by the application layer at the source, bits are packetized into messages that are encoded into codewords, these packets are enqueued, and then transmitted over the channel.
Once decoded the data is consumed at the destination.
In all there are three sources of delay: packetization (waiting for enough data to form a message), queuing (caused by a back-up in the transmission process), and service (the transmission time).
In this paper we focus on the service time delay from transmitter to receiver.
In regimes where the best tradeoff between reliability and delay is achieved, service time dominates the end-to-end delay.
We review results for block and variable-length coding before focusing in on streaming data.
Streaming data systems are de Fig. 1.
End-to-end delay is a fundamental metric of system performance for streaming data systems.packets that can be realized in real time at the source.
We develop a coding strategy that is appropriate for streaming data and show that its reliability function is far larger than the Burnashev exponent, which is the largest exponent achievable by variable-length schemes.
We then show how the same error exponent can be maintained as long as the capacity of the feedback link is larger than the exponent.
We start by summarizing results for block coding without feedback.
When feedback is not available, the duration of transmission must be fixed to ensure that encoder and decoder stay synchronized.
This is the familiar coding paradigm of Shannon [13].
Let W be a stationary discrete memoryless channel (DMC) with input alphabet X and output alphabet Y.Definition 1: A rate-R fixed-length-N block encoderdecoder pair (E N , D N ) is a pair of mapsE N : M = {1, 2, . . . , 2 N R } → X N ,(1)D N : Y N → ˆ M = {1, 2, . . . , 2 N R }.
(2) An error exponent E is said to be achievable at rate R if there exists a family of coding strategies (of increasing length N ) such thatlim →0 − log N ≥ E,(3)where = Pr[ ˆ m = m] is the probability that the message estimatê m ∈ ˆ M is incorrect at the decoding time N and where m ∈ M.The error exponent of this class of codes is upperbounded by the sphere-packing bound:E sp (R) = max P min V :I(P,V )≤R D(V W |P ),(4)where P is the input distribution and V characterizes the channel behavior.
As shown by Dobrushin [3], (4) continues to upper bound the error exponent of fixedlength block-coding over symmetric channels even when feedback is present.
An extension of the bound to arbitrary DMCs with feedback is given in [8].
If feedback is available, and variable-length coding is allowed, a far larger exponent than the sphere-packing bound can be achieved.
Let W be a stationary DMC with input alphabet X , output alphabet Y, and with causal instantaneous noiseless feedback.Definition 2: An average-rate-¯ R variable-length block encoder-decoder pair (E vl , D vl ) is a pair of mapsE vl = {E n : M × Y n−1 → X } n≥1 ,(5)D vl = {D n : Y n → M ∪ {0}} n≥1 ,(6)together with a random decision time t, defined as the first n such that D n (y n ) = 0, that satisfieslog |M| E [t] ≥ ¯ R,(7)and where M = {1, 2, . . . , M } is the set of messages.
An error exponent E is said to be achievable if there exists a family of coding strategies (of increasing message set size |M|) such thatlim →0 − log E [t] ≥ E(8)where = Pr[ ˆ m = m] is the probability that the message is decoded incorrectly at the decision time t.Burnashev [1] shows that an achievable upper bound on the error exponent in this setting isE b ( ¯ R) = C 1 1 − ¯ R C ,(9)where the constant C 1 is defined by the two "most distinguishable" input symbols asC 1 = max xi,xj y W (y|x i ) log W (y|x i ) W (y|x j ) .
Let x i * and x j * denote the two symbols that yield C 1 .
Streaming transmission schemes concern the sending of a sequence of messages m 1 , m 2 , m 3 , . . . wherem j ∈ M j = {1, 2, . . . M j }.
At any time the message estimatê m j ∈ ˆ M j = {0, 1, . . . M j }.
The number of messages that have entered the encoder by channel use n is denoted J enc [n] and the decoder's estimate of this number isˆJisˆ isˆJ enc [n].
The count J enc [n] is also a function of the outputs y n−1 .
We suppress this dependence for notational simplicity.
Let W be a stationary DMC with input alphabet X , output alphabet Y, and with causal instantaneous noiseless feedback.Definition 3: An average-rate-¯ R streaming encoderdecoder pair (E seq , D seq ) is a set of mapsE seq = E n : Jenc[n] j=1 M j × Y n−1 → X n≥1 ,(10)D seq = D n : Y n → ˆ Jenc[n] j=1ˆM j=1ˆ j=1ˆM j n≥1 ,(11)and where with high probability D seq satisfies lim n→∞ˆJenc n→∞ˆ n→∞ˆJenc[n] j=1 1[ ˆ m j = 0] log |M j | n ≥ ¯ R.(12)lim →0 − log j E t j − t j ≥ E for all j,(13)where j = Pr[ ˆ m j = m j ] is the probability that the jth message is decoded incorrectly.In [9], [10] two strategies are given for streaming communications over a binary symmetric channel (BSC) with cross-over probability p.
Their results are encapsulated in the following theorem.Theorem 1: Consider a BSC with cross-over probability p ≤ 0.5.
Then, a streaming encoder/decoder pair exists that can achieve any average-rate and errorexponent pair ( ¯ R, E) that satisfy the following:¯ R < H B (q * p) − H B (p), (14) E < D(q * pp),(15)where 0.5 ≤ q ≤ 1 is a design parameter, and q * p = q(1− p) + (1 − q)p (we use * to denote binary convolution).
Remark: The value q * p = q(1 − p) + (1 − q)p parameterizes the output distribution of a BSC when the input is Bernoulli-q.
While (14)- (15) the rate and exponent pair given in [9], it is a quick exercise to check that the expressions match.
We later give a clear operational interpretation to this form.
In Fig. 2 we compare the error exponents for a binary symmetric channel with cross-over probability 0.1.
The sphere-packing bound is an upper bound on the error exponent (tight at rates close to capacity) of coding without feedback, the Burnashev upper bound is tight at all rates, and the streaming exponent is a lower (achievable) bound on the exponent.There is a clear intuition why the combination of feedback and variable-length codes makes possible a major improvement in the reliability function given by the sphere-packing bound.
The sphere-packing bound (4) tells us the probability, 2 −N D(V W |P ) , that over the block length N the channel displays a behavior V that does not support the communication rate, I(P, V ) < R. With feedback the transmitter can detect when the channel behaves badly, i.e., when I(P, V ) < R.
It can then attempt to signal the decoder to delay decoding until channel behavior improves.
Since bad behavior is exponentially rare, 2 −N D(V W |P ) , decoding is only very rarely delayed.
Therefore huge improvements in reliability can be made at negligible cost in average rate.The reason why streaming achieves a higher exponent than Burnashev is more subtle.
We develop intuition by first understanding how the Burnashev exponent is achieved, and then point out what is missing when that solution is applied to streaming data.Both the coding strategy used by Burnashev, and a later strategy by Yamamoto and Itoh [14] that also achieve the Burnashev exponent, are two phase schemes.
In the first phase a strategy is used to communicate just below capacity at a somewhat small error probability (e.g., in [14] a fixed-length feedback-free block code, per Def.
1, is used).
Via the feedback the source knows the destination's message estimate and also knows when the destination thinks the first phase has ended (if that time is not fixed).
The source then follows up with a confirm/deny signal, the all-x i * or the all-x j * signal, respectively.
If the destination detects a deny, the source retransmits the message and the system ignores the first transmission.
If the destination detects a confirm, the system moves onto the next message.An error can only occur if a deny signal is misdetected as a confirm.
Retransmissions occur either through detected denials or false alarms (detecting a denial when a denial was not sent).
To achieve (9) one skews the binary hypothesis test so that the probability of false alarm is bounded by a small constant while the probability of missed detection is driven as small as possible.
The best exponent is found via an application of Stein's Lemma [2].
Figure 3 diagrams the usage of the forward channel when a Burnashev-type scheme is used to transmit a sequence of messages.
We make two observations.
First, since almost all messages are received correctly in their first transmission, almost all confirm/deny signals are confirms.
Confirm signals are therefore quite predictable and so the degrees-of-freedom corresponding to these channel uses are not used efficiently.
To improve this situation, in Sec.
IV we make confirms implicit and only make denials explicit.
This latter strategy achieves the streaming exponent of Fig. 2.
The second aspect of Fig. 3 to note is an architectural one.
The probability of erroneous decoding given by (9) is 2 −N C1(1− ¯ R/C) .
To make this probability as small as possible, we choose N as large as possible.
However, because many uses of streaming data are delay limited (as opposed to file transfers), the application-layer latency constraint puts an upper bound on N .
We reason that N should be on the order of the latency constraint to minimize error probability while meeting the constraint.
A different principle emerges in the streaming context.
Fig. 3.
Using a Burnashev-type strategy for multiple messages means that almost all confirm/deny messages are confirms.
This is an inefficient use of channel uses.
respectively.
Communication from source to destination is along the forward channel W .
Feedback from destination to source is along the reverse channel W r .
The capacity of the forward channel is C = max P I(P, W ) and that of the reverse channel C r = max Pr I(P r , W r ).
Channel uses are assumed synchronized so that n simultaneously indexes a use of the forward and a use of the reverse channel.As in Def.
3, the source transmits a sequence of messages m 1 , m 2 , m 3 , . . . to the destination wherem j ∈ M j = {1, 2, . . . M j }.
At any time the message estimatêestimatê m j ∈ ˆ M j = {0, 1, . . . M j }.
The number of messages that have entered the encoder by channel use n is denoted J enc [n] and the decoder's estimate isˆJisˆ isˆJ enc [n].
Definition 4: An average-rate-¯ R streaming encoder / feedback-encoder / decoder triplet (E seq , F f b , D seq )with active feedback is a set of mapsE f b = E n : Jenc[n] j=1 M j × Y n−1 r → X n≥1 ,(16)F f b = E n : Y n → X r n≥1 ,(17)D f b = D n : Y n → ˆ Jenc[n] j=1ˆM j=1ˆ j=1ˆM j n≥1 ,(18)and where with high probability D f b satisfieslim n→∞ˆJenc n→∞ˆ n→∞ˆJenc[n] j=1 1[ ˆ m j = 0] log |M j | n ≥ ¯ R. (19) Remark:This definition enlarges on that of Def.
3 though the addition of the feedback encoder (17).
Since the destination decides what to feed back, this is termed "active" feedback.
When the feedback channel is noiseless and such that we can set y r = x r = y , we can return to the "passive" noiseless feedback setting of Def.
3.
The error exponent is defined exactly as in the noiseless case (13).
Our main result demonstrates that the exponent of streaming transmission presented in Thm.
1 can be maintained under noisy feedback.Theorem 2: Let the forward channel be a BSC with cross-over probability p, and the reverse channel be any channel with capacity C r .
Then, a streaming encoder/feedback-encoder/decoder triplet exists that can achieve any average-rate and error-exponent pair ( ¯ R, E) that satisfies the following inequalities:¯ R < H B (q * p) − H B (p), (20) E < min{D(q * pp), C r },(21)where 0.5 ≤ q ≤ 1 is a design parameter, and q * p = q(1 − p) + (1 − q)p.Remark: Contrasting Thm.
2 with Thm.
1 shows that in the streaming context noisy feedback need not lead to any reduction in the error exponent.
There is no loss in the exponent as long as the capacity of the feedback channel exceeds the streaming error exponent of the forward channel.
Note that detailed characteristics of the feedback channel (such as its error exponent) do not enter this theorem.
In this section we build towards our general communication protocol.
We first describe the protocol in the special case of a binary-symmetric forward channel and noiseless output feedback, Def.
3.
In this context the scheme is a version of Kudryashov [10].
Subsequently we generalize to noisy feedback.
The strategy presented in this section achieves the rate/exponent tradeoff given by (14) and (15) The strategy operates across a sequence of "time slots", each comprising N channel uses.
Each time slot is used to transmit a new message, retransmit a message, or to send the denial signal.
The functionality of each time slot is therefore not pre-determined.
At the end of each slot the destination first decides whether the time slot contained a data message or a NAK.
In the former case it makes a tentative decision equal to its maximum likelihood (ML) estimate of the transmitted message.
That tentative decision will be finalized ∆ time slots later if, in the ensuing time, the destination does not detected a NAK.
Therefore, the minimum transmission time of any message is (1 + ∆)N .
Via the feedback link the source monitors the destination's decisions and immediately learns of any decoding errors.
As soon as a tentative decoding error occurs the source starts to transmit the denial signal.
This is a sequence of NAKs of maximum length ∆N .
We discuss below how to design the NAK signal.
A diagram of the protocol is depicted in Fig. 4.
Final decision on msg j+8 (unless detect Nak) msg j j+1 j+2 j+3 j+4 j+8Data blocks, length−n decision delayEmergency signal, Fig. 4.
In a streaming context, there are past messages and future messages.
Unlike in Burnashev, a single message is not considered in isolation from the rest of the system.
In this context it is very advantageous to make confirm signals implicit, and only explicitly send denial (NAK) signals.
By doing this channel uses are more efficiently used, and the error exponent can be boosted massively.We now describe a number of components of the protocol in more detail.
At any time the destination has an estimatê j ≤ ˆ J enc [n] of the packet being transmitted in that time slot.
The source knowsˆjknowsˆknowsˆj because of the noiseless feedback.1) Data is communicated using length-N constant-q composition codes 1 of rate R = H B (q * p) − H B (p) − where 0.5 ≤ q ≤ 1.
The NAK signal is the all-zeros sequence.
2) If the destination does not detect a NAK in a given time slot, it increments its sequence number fromˆj fromˆfromˆj tô j + 1.
3) If, instead, at the end of any time slot, the destination detects a NAK, it interprets this as indicating that one of the last ∆+1 messages was decoded in error.
It decrements its sequence number by ∆ + 1 (fromˆjfromˆfromˆj tô j −∆) and deletes the respective earlier tentative decisions.
Retransmissions take priority over other enqueued messages.
4) When a NAK is detected by the decoder (even if incorrectly), the source backs up the index j ≤ J enc [n] of the message it is transmitting by ∆ + 1 and retransmits.
5) Whenever the destination makes a decoding error the source immediately learns of it via the feedback.
The source then starts transmitting the emergency denial signal.
The source continues to transmit the denial signal until it is detected or up to the maximum denial length of ∆ time slots.
In order for the strategy to work, it is crucial that the denial signal is easily distinguished from any message.
To ensure this property the denial sequence is designed to be far removed from all codewords.
A sense of the geometry is shown in Fig. 5.
Codewords are depicted as being on the surface of the sphere (in the case of the BSC the sphere's surface corresponds to the set of composition-q sequences) while the NAK is the all-zeros sequence, located at the center of the sphere.
The NAK sequence is designed to be distant from any codeword.
The binary hypothesis test-whether the last time slot contained a message or a NAK-is skewed to make the probability of missed detection of a NAK extremely small.
At the same time the decision regions for messages must contain the union of the typical noise spheres of all codewords to keep retransmissions rare.When deciding whether or not the current time slot is a NAK, the destination skews its hypothesis test.
It designs the test to make the probability of missed detection of a NAK extremely small while keeping the probability of false alarm (which just leads to a retransmission) bounded, but small.
This aspect of the design is akin to the skewed hypothesis test in Burnashev.
The difference is that the decision is now between the NAK sequence and any codeword, not between the NAK sequence and a particular confirmation signal.
Fig. 5 gives a sense of this unequal error protection.In addition to achieving a much larger exponent for positive rates, the architectural implications of this strategy are far different from those drawn from Burnashevtype approaches at the end of Sec.
II.
In streaming we choose each time slot to be significantly shorter than the latency constraint so that the denial signal can extend across many time slots.
Information is treated more as a flow (in small chunks) than as blocks (very large chunks).
This shift to shorter block lengths makes it possible to maintain the same exponent even when the feedback channel is noisy.1) Error bound: An error occurs only if a denial signal is missed.
To decide whether a NAK was sent, at the conclusion of each time slot the destination calculates the composition of the N output symbols.
If a data message was transmitted, the expected fraction of ones is q * p = q(1 − p) + (1 − q)p.
If a NAK was sent the expected fraction of ones is p.
The gap between the two output compositions means that the hypothesis test can be biased to make it extremely unlikely to miss a NAK.
The gap is depicted in Fig. 6.
We design the test so that the probability of false alarm (false detection of a NAK) is bounded above by an arbitrarily small constant F A > 0.
This keeps retransmissions rare.
Using Stein's lemma [2, Thm.
12.8.1] we can then say that in the limit of large N the probability of missed detection of a NAK in a single time slot can be upper bounded by 2 −N D(q * pp) .
Since times slots are tested independently and codewords are chosen independently, the probability of missing a NAK in each of the (maximum denial signal length of) ∆ times slots is When a denial signal is messed, the system keeps NAK-ing to correct the missed-NAK decisions made in subsequent time slots.2) Service time bound: There are three events that can lead to the retransmission of a message that has been transmitted.
First, the message itself may be decoded in error.
Second, one of the subsequent ∆−1 messages may be decoded in error so that the message may be caught in one of their NAK windows.
Third, the destination may falsely detect a NAK within one of the subsequent ∆ time slots.
The probability of the union of these events is upper bounded by δ whereδ = M L + (∆ − 1) M L + ∆ F A ,(23)and where M L is the probability of erroneous tentative decoding.
The constant δ can be made arbitrarily small if R < H B (q * p)−H B (p) by choosing N large enough.
To lower bound the average rate, we assume that every NAK signal extends to its maximum duration of ∆ time slots.
Messages received correctly after the first transmission take N channel uses to send.
A message received correctly after k retransmissions takes at most N + k(1 + ∆)N channel uses to send.
The probability of retransmission is upper bounded by δ.
We upper bound the expected number of transmissions of a particular message by the expectation of a geometrically distributed random variable with parameter δ.
This upper bounds the expected number of channel uses dedicated to the transmission of a particular message by N +δ(1+ ∆)N/(1−δ).
Any average transmission rate ¯ R such that¯ R < R 1 + δ 1−δ (1 + ∆)(24)is therefore achievable.To bound the expected transmission delay note that whenever a retransmission event occurs the additional delay (excepting further retransmissions) is upper bounded by 1 + ∆ time slots.
If a message is accepted after a single transmission, the total delay is (1+∆)N .
If k retransmissions occur, the total delay is upper bounded by (1 + k)(1 + ∆)N .
Using the bound on probability of retransmission yields the upper bound on the expected transmission time,E [t] ≤ (1 + ∆)N 1 − δ .
(25)Plugging (22) and (25) into (13) gives the following lower bound on the achievable exponent(1 − δ) ∆ 1 + ∆ D(q * pp).
(26)For long delays ∆ any pair ( ¯ R, E) that satisfies¯ R < H B (q(1 − p) + (1 − q)p) − H B (p), E < D(q(1 − p) + (1 − q)pp),is achievable, where 0.5 ≤ q ≤ 1.
As q approaches 0.5, the upper bound on ¯ R approaches the capacity of this channel C f = 1 − H B (p), and the error exponent approaches 1 2 log 1 4p (1 − p) .
The error exponent as a function of rate is the same as the dash-dotted "streaming exponent" plotted in Figure 2 The limit of error exponents as rate approaches capacity (q → 1/2) is strictly positive.
At lower rates the codebook composition q is biased toward having more ones than zeros.
This increases the distance from the all-zero NAK sequence to any of the codewords.
The challenge posed by the addition of noise to the feedback link is two fold.
First, we need a mechanism by which the source can detect when the destination is in error.
Second, since the source cannot "look over the shoulder" of the destination it cannot automatically keep synchronized.
Thinking in terms of the noiseless strategy, the source does not immediately know whether the destination has detected a NAK or a non-NAK.
To detect decoding errors at the source the destination transmits a hash of its tentative decisions to the source in each time slot.
The hash message is protected with a length-γN block code, per Def.
1.
If the decoded hash matches the hash of the corresponding messages transmitted by the source, data transmission continues, otherwise the system drops into emergency mode.
This is an extension of an idea originally developed in [4] for low-rate noiseless feedback.
The main modification is that the random hash is calculated with respect to the product of the last˜∆last˜ last˜∆ tentative decisions.
The length of this window grows linearly in the decoding delay to balance the probability of hash collision with the probability of a missed detection of a denial signal.To maintain synchronization the destination uses the last (1 − γ)N channel uses in each time slot to indicate to the source whether the binary hypothesis test for the last time slot yielded a NAK or a codeword.
This sequence of single bits of information is protected by an anytime code.
Although not immediately highly reliable, the outcome of the NAK/non-NAK hypothesis test in any particular time slot is learned by the source with increasing reliability over time.
If retransmission opportunities are spaced sufficiently far apart in time, by the time the first opportunity to retransmit the message arises the source knows with high reliability whether or not it needs to retransmit.We implement this method of maintaining synchronization through a round-robin scheduling of time slots among L "users".
(See [11], [5] for earlier variants of this strategy.)
Each message is assigned to a particular user.
After the initial transmission of the message, the user must wait (L − 1)N channel uses for the next time slot in which it can transmit.
In order to determine what to transmit, the source needs to estimate the destination's sequence of NAK or non-NAK decisions.
The operation of the source in estimating these decisions can be visualized through a synchronization table, as shown in Fig. 7.
This table indicates the source's best estimate of the destination's sequence of NAK/non-NAK decisions.
Whenever the source marks an entry as a NAK that means that the source plans to retransmit the packet sent in that time slot and those in the (∆ + 1) time slots just before.
The table is updated at the end of every time slot.
Transmitting a NAK takes priority over a retransmission, and retransmissions take priority over transmitting new data.
By picking the number of users L such that L ∆, by the time the first opportunity to retransmit arises the source is very sure whether or not to retransmit.Error detection and synchronization operate on two distinct time scales.
The source must detect errors relatively promptly so as to be able to NAK decoding errors promptly.
On the other hand, the source need know whether to retransmit a message much less quickly.
As long as retransmissions are suitably rare, the effect on average decoding delay of long retransmission delays can be negligible.We now summarize the components of the scheme.
First we outline the operation of the source, then that of the destination.
The source transmitter is always in one of two states: data transmission mode or emergency signaling mode.
1) Transmit mode: a) At the beginning of each time slot the source decodes the feedback message transmitted by the destination.
b) The decoded fed-back hash is compared to the correct value of that hash known by the source.
c) If the hashes match, the source transmits the next data message in the time slot, chosen according to the round-robin schedule described above.
d) If the hashes do not match, the transmitter enters emergency mode and starts transmitting NAKs.
is determined to be a data message, the decoder makes its ML estimate of the message.
a) The destination calculates the hash of the product of the last˜∆last˜ last˜∆ tentative messages-a NAK is counted as message zero.
b) The result of this hash is transmitted to the source using the first γN uses of the reverse channel in the next time slot, and protected by a standard length-γN block code.
c) We set˜∆set˜ set˜∆ = ∆.
This gives the source as many chances as possible to detect the error before the decision is finalized-see Fig. 8.
At the same time, the hash window length˜∆ length˜ length˜∆ is finite so that emergency mode can end.
The source does not pay attention to the feedback messages while in emergency mode (see above), but by choosing˜∆choosing˜ choosing˜∆ appropriately (equal to ∆), when emergency mode ends the hash window no longer includes the (likely erroneous) tentative decision that first triggered a hash mismatch.
3) Final Decision: If no NAKs have been detected in the last ∆ + 1 time slots, the tentative decision made about the message sent ∆ + 2 time slots ago is finalized.
At this point the message is served up to the destination's application layer.
1) Error bound: In the noiseless feedback setting the only error mechanism is a missed NAK.
In the noisy via the hash sent back in this time slot err msg nak nak nak nak nak nak N ∆ Time to decide whether to make final decision about messageHash window corresponding to last chance to detect decoding error Last chance for source to detect error is via hash sent back in this time slotFirst chance for source to detect error is setting there are additional sources of error.
Before transmitting a NAK the source must first learn of the erroneous tentative decision.
Undetected errors can slow this process.
These errors occur when the destination's tentative decision is incorrect, but the source does not detect the error because the decoded feedback hash and the hash of the correct messages match.
We term this a hash "collision".
A second source of error is when source and destination get out of synchronization.To bound the probability of error, we describe the operation of the feedback hash in full detail.
The hash is calculated across the last˜∆last˜ last˜∆ tentative decisions ( ˆ m j− ˜ ∆+1 , . . . , ˆ m j ).
The 2 ˜ ∆N R possible message combinations are randomly partitioned into M r = 2 γN Rr bins B 1 . . . B Mr .
Next, the index k of the bin such that ( ˆ m j− ˜ ∆+1 , . . . , ˆ m j ) ∈ B k is encoded and transmitted along the reverse channel using a length-γN block code.
The source decodes this message tô k.
If h(m j− ˜ ∆+1 , . . . , m j ) / ∈ B ˆ k (equivalently we say ifˆk ifˆ ifˆk = B(m j− ˜ ∆+1 , . . . , m j )) the source enters emergency mode and begins transmitting the denial sequence in the next time slot.
Otherwise it sends its next message.The probability of error is the probability that by the end of the (∆ + 1)st time slot after a tentative decoding error occurs, the destination has not learned that it has made an error.
We write this event as ¯ E dest (∆+1)N .
To bound the probability of this event we define E src kN to be the event that the source first learns of a tentative decoding error kN channel uses after the erroneous tentative decision is made.
We further define ¯ E src kN to be the event that the source still has not learned of the error by time kN .
The error is bounded as Pr ¯ E dest(∆+1)N = Pr ∆ k=1 E src kN ¯ E src ∆N ¯ E dest (∆+1)N (27) ≤ ∆ k=1 Pr{E src kN } Pr{ ¯ E dest (∆+1)N | E src kN } + Pr{ ¯ E src ∆N } Pr{ ¯ E dest (∆+1)N | ¯ E src ∆N } ≤ ∆+1 k=1 Pr{ ¯ E src (k−1)N }2 −(∆+1−k)N D(q * pp) (28) = ∆+1 k=1 2 −(k−1)N γRr 2 −(∆+1−k)N D(q * pp) = ∆+1 k=1 2 −∆N k−1 ∆ γRr+(1− k−1 ∆ )D(q * pp) ≤ ∆+1 k=1 2 −∆N min λ λγRr+(1−λ)D(q * pp) = ∆+1 k=1 2 −∆N min γRr,D(q * pp) = (∆ + 1)2 −∆N min{γRr,D(q * pp)} .
(29)In (27) the index starts at k = 1 because it takes at least one time-slot for the source to learn of a decoding error.
During this time slot the initial hash is fed back-see Fig. 8.
In (28) the first factor is the probability that the first k − 1 hashes are all collisions.
The source is forced to make a decision on the fed back block code.
If any of the fed back messages is decoded in error the probability of a hash collision (leading to a still-undetected error) is the reciprocal of the number of codewords, i.e., 2 −N γRr .
This is the same as the probability of hash collision when the fed back message is decoded correctly.
While (27)-(29) analyzes the probability of error when the system starts out operating correctly, and then drops into emergency mode, there is a second possibility.
It is possible that part-way through an emergency NAK transmission, the destination will mistakenly think that a time slot actually corresponds to a data message rather than a NAK.
In effect the destination mis-detects the end of the denial signal.
Say that this occurs at the lth time-slot of the (length-∆) denial transmission where l ≤ ∆ − 1.
The probability that this mistake isn't itself NAK-ed is the probability that the remaining time-slots of the on-going denial signal are all mis-detected as data messages and that the message is still not NAK-ed in time even after the on-going denial signal concludes and the source starts checking hashes again.
The probability that the remaining (∆ − l) NAK are all missed is2 −(∆−l)N D(q * pp) .
(30)The probability that after the conclusion of the denial signal the error is not detected and NAK-ed by the (∆ + 1)st time slot after the mistaken hypothesis test is just (29) evaluated with ∆ = (∆ + 1) − (∆ − l) = l + 1.
Putting these together gives a probability equal to2 −(∆−l)N D(q * pp) (l + 2)2 −(l+1)N min{γRr,D(q * pp)} ≤ (l + 2)2 −(∆+1)N min{γRr,D(q * pp)} ,which is smaller than the probability in (29).
Now we bound the probability that any of the synchronization messages are in error.
When first considering whether to retransmit a particular data message, the most recent string of relevant NAK/non-NAK decisions entered the anytime encoder between (L − 1) and (L − ∆ − 1) time slots before.
These ∆ + 1 decisions can trigger a retransmission while later NAKs cannot.
The second most recent string of decisions entered the anytime encoder L time slots before that, and so forth.
We upper bound this probability with (∆ + 1) times the error probability of the least reliable bit in each string, i.e.,(∆ + 1) ∞ i=1 2 −(iL−∆−2)(1−γ)N Eany( 1 (1−γ)N ) = 2 −(L−∆−2)(1−γ)N Eany( 1 (1−γ)N ) 1 − 2 −L(1−γ)N Eany( 1 (1−γ)N ) .
(31)Letting N grow large and setting (31) equal to (29) allows us to solve for L, the number of users we need to cycle through to maintain the exponent under noisy feedback.L = ∆ min{γR r , D(q * pp)} (1 − γ)E any 1 (1−γ)N + ∆ + 2 .
(32)2) Service time bound: The probability of retransmission can be bounded in almost the same way as in the noiseless setting (23).
The two additional sources of retransmissions comes from errors on the reverse link.
An erroneous feedback transmission usually leads to a non-match in the hashes, triggering a denial and a subsequent retransmission.
As long as R r < C r then for N large enough, this probability can be made arbitrarily small.
The second source of retransmissions comes from mis-synchronization.
As just discussed in the context of the overall error probability (32), this probability can be made arbitrarily small.
Thus, the probability of retransmission can again be bounded by any positive constant δ .
Given the bound δ on the probability of retransmission, the average communication rate is bounded just as in (24).
Thus any average communication rate such that ¯ R < R 1 + δ 1−δ (∆ + 2) is achievable.We now bound the expected duration of transmission.
Before making a final decision the destination must have received the data transmission and not detected a NAK in any of the ensuing ∆ + 1 time slots.
If there are no retransmissions, the duration of communication is (∆ + 2)N , if there are k retransmissions it is (kL + ∆ + 2)N .
The expected duration of transmission E [t] can be bounded asE [t] < (∆ + 2)N + δ 1 − δ LN.
(33)Substituting the probability of error from (29) and the expected duration from (33) into the definition of the streaming error exponent (13) gives∆ min{γR r , D(q * pp)} (∆ + 2) + δ 1−δ LThe best rate/reliability tradeoff is made by examining the limits when ∆ → ∞, δ → 0, but δ · ∆ → 0, also γ → 0 (so L → ∞), but ∆·L → 0, and finally R r → C r from below, which keeps δ small.
In these limits any pair ( ¯ R, E) that satisfies¯ R < H B (q(1 − p) + (1 − q)p) − H B (p),(34)E < min{C r , D(q(1 − p) + (1 − q)pp)},(35)is achievable, where 0.5 ≤ q ≤ 1.
In Fig. 9 we plot the achievable tradeoff for our scheme over a BSC with cross-over probability 0.1, and a feedback link capacity C r = 1.5.
In the low-rate region hash collisions dominate.
In the high-rate region missed denial signals dominate, the same error event as in the noiseless case.
Respectively, these are the first and second terms of (35).
For comparison we also plot the Burnashev and sphere-packing bounds, and the tradeoff achieved by erasure decoding paired with singlebit feedback as explored by Forney in [6].
In earlier work [5] we have shown that using techniques related to those presented herein, half the Burnashev exponent is achievable (with a hard-limit from hashing errors at C r /2) while Forney's exponent may be maintained with any positive-capacity feedback channel.In our current research we are working to show that the rate/reliability trade off encapsulated in Thm.
1, equations (14) and (15), is the best achievable.
In addition to some preliminary work, the fact that the scheme we present herein is far different from Horstein's [9], and yet the rate/reliability trade off achieved is the same, makes us optimistic that this trade off is fundamental.
Effect of noise on streaming feedback exponent.
For comparison the Burnashev and sphere-packing bounds are plotted as well as Forney's exponent (variable-length single-bit feedback).
