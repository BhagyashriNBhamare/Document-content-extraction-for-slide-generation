Scientific workflows have recently emerged as a new paradigm for representing and managing complex distributed scientific computations and are used to accelerate the pace of scientific discovery.
In many disciplines, individual workflows are large due to the large quantities of data used.
As scientific workflows scale quickly, they become very hard to build and maintain.
Recent efforts from scientific workflow community aiming at large-scale capturing of provenance present a new opportunity for building scientific workflows using provenance.
Process mining focusses on extracting information about processes by examining event logs, and has been successfully applied to business workflow management.
This paper presents a method using process mining based on provenance to build and analyze scientific workflows, which provides a new direction in using captured provenance.
Scientific computing has entered a new era of large scaled sharing provided by the cyberinfrastructure.
Scientific workflows have recently emerged as a new paradigm for declarative representation of scientific applications as complex compositions of software components and the dataflow among them [1].
Current scientific workflow management systems, such as Pegasus [2], Kepler [3], Taverna [4], VisTrails [5] and VIEW [6], facilitate the definition and execution of scientific workflows.
However, it is often very hard to create and maintain scientific workflows.
In many disciplines, individual workflows are large due to the large quantities of data used.
In [7] three stages in the creation of workflows are suggested to enable the management of the complexity of workflow creation by making the process more modular, but creating scientific workflows remain a challenge to domain scientists, and updating scientific workflows is also a challenge as the workflows can keep evolving when they are used by domain scientists.Provenance, in scientific workflow community, refers to the sources of information, including entities and processes, involved in producing or delivering an artifact.
Provenance is important for scientists to assess data quality, validate results, reproduce experiments, consequently provenance capture becomes an important scientific workflow research area.
Many existing scientific workflow management systems, such as Taverna, Kepler and Pegasus, capture provenance information implicitly in an event log that records events related to the start and end of particular steps in the workflow execution and the corresponding data read and write events.
Provenance systems above are tightly coupled with their scientific workflow management systems, while the VisTrails provenance technology [5] and infrastructure are general to enable system-level monitoring and applicable to a wide range of applications that involve complex computational processes.
One of the major advantages of this general approach is that users will be able to leverage provenance using the same applications and environments that they are used to.
Provenance is also argued in [8] as first class data in the cloud.
We believe that complete provenance [8] [12] [13] aiming at large-scale capturing of provenance present a new opportunity for building scientific workflow using provenance.
Captured provenance of a single scientific experiment may come from executing existing scientific workflows, or executing provenance enabled applications.
What's more, before creating scientific workflows, the provenance can only be captured from provenance enabled applications.
This paper aims at answering a question: Can we learn from provenance to build scientific workflows?
Several researchers have investigated how to synthesize a process model from event logs [14] [15] [16].
The research area of process mining focusses on extracting information about processes by examining event logs.
Practical experience has shown that typical information recorded in event logs includes information about which activities are performed, at what time, by whom and in the context of which case (i.e., process instance) [14].
By explicitly using the case context, process discovery algorithms are capable of constructing process models that accurately describe the process [15].
Since both event logs and provenance contain process information, a given scientific workflow may be executed multiple times [17] thus creating multiple workflow execution instances.
Scientific experiments are exploratory in nature thus change are the norm.
As a result, mining processes from scientific workflows is highly valuable.
Provenance does not record control flows associated no data flows, we are interested in building scientific workflows by combining data flows from provenance and control flows mined from provenance.
Our work provides a new direction in using captured provenance.This paper presents a method using process mining based on provenance to create and analyze scientific workflows.
Figure 1 shows a high level view of the context to mine provenance.
Applying process mining in the context of scientific workflow needs to address the following issues.
In this paper we focus on control flow mining, and Figure 2.
Overview of the method discuss other two issues in Section IV.1) Control flow mining: To mine control flows from provenance, we need to extract information and to present it in the format acceptable to existing process mining tools.
we also need to select appropriate process discovery algorithms depending on the context of scientific workflows.
2) Data dependency: Data dependency contained in provenance can contribute to process mining for improving the mining results.
It is critical to enhance the existing control flow based process mining algorithms with data flow capabilities.
3) Incremental mining: Given a scientific workflow template [7], scientists need to fine-tune it for many times, which makes updating large scientific workflows a challenge for scientists.
Mining from scratch is neither efficient for large scale scientific workflows nor effective to address existing scientific workflow templates.
Incremental mining can utilize the information in existing scientific workflow templates to make mining more efficient and effective.
Figure 1 shows a high level view of the context to mine provenance, to build and update scientific workflows.
We adopt the challenge workflow from the third Provenance Challenge as a running example (http://www.myexperiment.org/workflows/750), which contains both control flow and data flow.
Because there is no open provenance repository available, this paper generates provenance by running the example scientific workflow.
As a result, results of the method in this paper can be compared with the existing scientific workflow.
Note that the method can be applied to provenance generated from both sources in Figure 1: scientific workflows based systems and system level monitoring.
Figure 2 shows a high level view of the method presented and evaluated in this paper.
1) Using the Fuzzy Miner: The fuzzy miner [16] assumes that problems in mining large scale processes are caused by mismatch between fundamental assumptions of traditional process mining, and the characteristics of real-life processes.
Fuzzy miner developed an adaptive simplification and visualization technique for process models, which is based on two metrics, significance and correlation.
The two metrics are similar to the concept of data clustering domain where a binary distance metric is inferred to find related subsets of attributes.
In the context of scientific workflows, significance, which can be determined both for tasks and precedence relations over them, measures the relative importance of behavior.
As such, it specifies the level of interest we have in tasks and their control dependency.
Correlation is only relevant for precedence relations over tasks, which measures how closely related two events following one another is.As scientific workflows are usually quickly evolving, change can be made to the example workflow several times, including the activities and data.
Using the fuzzy miner, a workflow can be mined to provide an abstract view of what does not change, which offers insight of evolving workflows.
For the running example, we run it for 10 times, then remove ReadCSVReadyFile and run it for 10 times again, after that we undo removing ReadCSVReadyFile, remove IsMatchCSVFileTables and run it for 10 times.
Using XESame provenance can be transformed to a XES file, based on which the fuzzy miner can be applied.
Figure 3 shows a resulting model in which there is every task but IsMatchCSVFileTables, when significance cutoff is increased to 0.392, as Figure 4, ReadCSVReadyFile disappeared so that the unchanged part is shown, which can be the key part of the whole workflow.
What's more, by double clicking "Cluster 14" that contains 2 elements, the tasks with low significance are shown, which in our context is the changing tasks.
As Figure 5 shows, there is a process model related with low significance tasks, which exactly matchs the original workflow model in the running example.
Therefore, in case there is provenance from either workflow based systems or nonworkflow systems that include tasks scientists perform, a scientific workflow can be built automatically at different abstract level by using the fuzzy miner.2) Using the Alpha Miner: The alpha miner [15] assumes the completeness of direct succession (DS) such that "if two transitions can follow each other directly, then this has occurred at least once in the log", yet it may not be the case in reality, the alpha miner allow users to edit log relations manually to offer more information about direct succession, as shown in Figure 6.
For large amount of events, manually adding log relations can be impossible.
In scientific workflows context, provenance contains data dependencies that imply direct succession in time order, data dependencies can somehow be considered in the alpha miner thus making it closer to completeness of direct succession.
We discuss further about data dependencies in Section IV.3) Using the Genetic Miner: The genetic miner [18] is a controlflow process mining algorithm that can discover all the common control-flow structures (i.e. sequences, choices, parallelism, loops and non-free-choices, invisible tasks and duplicate tasks) while being robust to noisy logs.
The genetic miner has more difficulties to mine models with constructs that allow for many interleaving situations.
Figure 7 shows the result of the genetic miner on the running example.
Genetic miner successfully get a non-free-choices construct such as both IsMatchTableRowCount and IsMatchTableColumnRanges depend on UpdateComputedColumns while IsMatchTableRowCount depends on others as well that means mixture of choice and synchronization.
It also successfully suggests the dependency between IsMatchTableRowCount and IsMatchTableColumnRanges that is a control link in the running example.
The results also give a clear view of frequence by annotating numbers on each event and arc, where numbers in event boxs mean how many times the events happen in 4) Using the Heuristic Miner: The heuristics Miner [19] is a practical applicable mining algorithm that can deal with noise, and can be used to express the main behavior (i.e. not all details and exceptions) registered in an event log.
It includes three steps: (1) the construction of the dependency graph, (2) for each activity, the construction of the input and output expressions and (3) the search for long distance dependency relations.
Figure 8 shows the result of heuristics miner on the running example.
Although IsMatchCSVFileTables does not directly succeed ReadCSVReadyFile in event logs, heuristics miner successfully suggests their dependency with reliability 0.833 and it happens 5 times in event logs considering long distance dependency relations.
This is particularly useful in the context of scientific workflows, just as the running example, many scientific workflows have multiple tasks even hundreds of tasks scheduled in parallel, not each parallel task succeed the dependent task directly in provenance, therefore, long distance dependency discovery is especially important in the context of scientific workflows.
The size of provenance is growing large quickly, Linear Temporal Logical (LTL) checking is a great tool to help scientists discovering Figure 9.
LTL Checking Example and double checking temporal properties of provenance.
As shown in Figure 9, we can easily check whether ReadCSVFileColumnNames eventually happens when IsExistsCSVFile happens, it is true for 27 instances while false for 4 instances, for further information, the specific workflow run can be referred to according to workflow run identifier.
The cloud computing and other technologies are changing the way we create, share and use information, which offers great benefits but also exposes us to serious new problems.
Cheney et al. [20] believe that provenance will play an essential role in this revolution, providing data integrity, trustworthiness, authenticity, and availability, while offering potential benefits to information retrieval, collaboration, and scientific computation.
Zhao et al. [12] address the queries from the provenance challenge workshop such as semantic reasoning which exposes the implicit links between provenance, e.g. the implicit links between provenance of studying any part of a human's body including chest, legs, arms and etc.
An abstraction over the provenance information is presented by two means: one is the users' specified annotations that draw an interpretative link between tasks, and the other is the typed views that hide or expose the execution details of an iteration or a nested run, or the data lineage of a collection and its elements.
Other works such as [10], [21] and [22] also address the queries from the provenance challenge workshop, however do not deal with mining processes from provenance.
Section II-A presents results of four different process discovery algorithms on the running example.
Table I discusses the results in the context of scientific workflows.
Note that the result of each miner is correct based on given provenance, but providing different views of the provenance.
It is found that the result of the fuzzy miner is closest to the original scientific workflow in the running example.
Section IV-C discusses a possible way to improve the results in Table I.
As Figure 2 shows, this paper uses provenance from scientific workflow management systems.
A question that current tools can not address is how many times should the scientific workflow be run to get enough traces.
There should be a fixed point after that no more precedence relations to be discovered even given additional provenance.
This paper manually find a point after that the mined results do not change significantly with additional provenance.
Scientific workflows include data dependency and control dependency, provenance provides data dependency besides temporal sequences.
The method provided in this paper only uses the temporal sequences of tasks in provenance to mine dependency among tasks.Data dependency can contribute to process mining for improving the mining result, but process mining and its existing tools do not accept explicit data dependency as source.
Since provenance provides data dependency, we can derive causality relation from data dependency, which compliments the causality relation extracted from the precedence of tasks [23].
Scientific problem solving is an evolving process.
Scientists start with a set of questions then observe phenomenon, gather data, develop hypotheses, perform tests, negate or modify hypotheses, reiterate the process with various data, and finally come up with a new set of questions, theories, or laws.
Often before this process can end in results, scientists will fine-tune the experiments, going through many iterations with different parameters [9].
Updating scientific workflows is hence a challenge for scientists.
We believe with pre-existing scientific workflow template, created either manually or automatically through mining, we can apply process mining to update it based on new provenance obtained from either workflow based systems or non-workflow systems.
We are working on incremental scientific workflow mining.
Incremental mining can utilize the information in existing scientific workflow templates to make mining more efficient for large scale scientific workflows and more effective for addressing existing scientific workflow templates.
Provenance is typically visualized as a graph, however, the graph of a large scale workflow ususally exceeds a visually manageable size.
There can be two approaches to address it.
First, provenance queries can be used to focus on part of provenance.
Second, the abstraction of these complex graphs can be provided to give a high level view of the provenance.
However, it is difficult to write provenance query statements, and abstraction does not give details for navigation of the whole provenance.
The method in this paper may be applied to improve navigation of collected provenance, by providing a zoomable view.
Furthermore, the unchanged part and changed part of an evolving workflow can be highlighted.
Another benefit of the method in this paper in terms of visualization, is finding relations in collaborative work scenarios to help understanding the origin of data.
For example, several workflows share the access to the same data product, the method in this paper may find the relation and visualize it.
This paper provides a method using process mining to build and analyze scientific workflows, which offers a new approach to build large scale workflows in the context of scientific workflows.
Recent efforts from scientific workflow community on capturing provenance present a new opportunity for using provenance.
This paper presents a method using process mining based on provenance to build and analyze scientific workflows, which provides a new direction in using captured provenance.
Given the fact that provenance captured in any scientific workflow based systems or system level monitoring systems contains information about tasks and their temporal order, there is always a way to translate the provenance to XES format acceptable to process mining tools, the method provided in this paper can be applied to any scientific workflow management systems.
This work was partially supported by the NSF of U.S. under award OISE-0730065, HRD-0833093, and Presidential Fellowship of Florida International University.
Under certain significance cutoff, the fuzzy miner successfully gives the changed part and unchanged part.
Comparing with original scientific workflow, the fuzzy miner gets most dependency correctly, but concludes some dependency that does not exist.Alpha Miner Provides a view of direct sucession between tasks in provenance.Assuming the completeness of direct succession, the alpha miner fails to give a view close to the original scientific workflow.Genetic Miner Provides a view of frequence for both tasks and succession between tasks, and discovers all common control-flow structures assuming the existence of noises.The genetic miner gets a good view of structures and frequences, yet gives some wrong dependency which does not exist in both the original scientific workflow and the results of the fuzzy miner.Heuristic Miner Provides a view of scientific workflows by considering long distance dependency.The heuristic miner gives long distance dependency successfully, but gives too much dependency for some tasks such as ReadCSVFileColumnNames.
