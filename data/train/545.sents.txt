As more and more structured documents, such as the SGML or XML documents, become available on the Web, there is a growing demand to develop effective structured document retrieval which exploits both content and hierarchical structure of documents and return document elements with appropriate granularity.
Previous work on partial retrieval of structured document has limited applications due to the requirement of structured queries and restriction that the document structure cannot be traversed according to queries.
In this paper , we put forward a method for flexible element retrieval which can retrieve relevant document elements with arbitrary granularity against natural language queries.
The proposed techniques constitute a novel hierarchical index propagation and pruning mechanism and an algorithm of ranking document elements based on the hierarchical index.
The experimental results show that our method significantly outperforms other existing methods.
Our method also shows ro-bustness to the long-standing problems of text length normalization and threshold setting in structured document retrieval.
Traditional information retrieval treats document as the smallest retrieval unit, but in many scenarios a user may actually require part of the document with higher precision and finer granularity.
Suppose a user who studies history of military operations would like to find out "what military aircrafts were used in Desert Storm".
He or she may retrieve articles named Military Aircrafts and Gulf War as two of the top-ranked results, both of which contain only a part of relevant content.
The user then has to scan each (usually very long) document to look for relevant information.
This is a time-consuming process which hinders the effectiveness of information retrieval.
Such an information overload is very common in typical Web searching applications.Today, with the widely use of XML, there is an increasing demand to develop better techniques for structured document retrieval.
XML provides a standard and effective way for the author to explicitly express the structure of a document.
For example, our corpus from the Encarta website (http://encarta.msn.com) can be considered as a set of content-oriented XML documents.
A typical structured document is represented as a collection of nodes such as sections, subsections, and paragraphs, as shown in Figure 1.
We call each node as an element in the rest of this paper.
The node representing the whole document, known as the root, is also considered as an element such that all nodes in the entire document tree are treated equally.
The leaf nodes are made up of paragraphs.
All upper-level nodes are ancestors of paragraphs, with their contents formed by those of paragraphs.
A document, especially a long one, usually covers multiple aspects of a central topic.
The elements in a document can be viewed as a concept tree, i.e., the upper element represents a broader concept which covers all the concepts beneath it.
Document retrieval can only be partially called information retrieval unless the elements expressing the appropriate level of concept can be precisely retrieved.
An effective retrieval system should provide this capability without imposing too much burden on users.In this paper, we propose a method of retrieving relevant document elements, exploiting both structural information and the statistics of term distributions in structured documents.
The main thrust of this solution is to allow the retrieval of relevant document elements with arbitrary granularity using keyword-based queries.
We call it a flexible element retrieval strategy.
Our solution is mainly made up of two parts -a novel hierarchical index propagation and pruning mechanism and an algorithm for selecting suitable document elements based on the hierarchical index.Comparing to existing works, we put much emphasis on the indexing phase.
Applying specific indices to retrieving data with structural information has long been studied in the areas of database and IR, such as indexing semi-structured data for XML documents retrieval [12] and bottom-up indexing schemes for structured documents retrieval [11].
Previous approaches assign index terms to only the leaf nodes [10] [12] [14] [15] or fixed-length passages [3] [8] [9].
The main drawback of such a kind of indexing mechanism is that the flat index does not match the hierarchical structure of documents.
It discards semantic relationships among the elements.
The inconsistency between the structures of documents and indices prevents users from obtaining composite elements, thus results in many discrete passages, which leads to the tough work of assembling the resulting excerpts of text to users [15].
The essential problem for indexing structured document is that, in order to get elements at arbitrary levels, the weights for various elements against a given query must be comparable.
[4] has a similar purpose in indexing and retrieving hypertext medical handbook in which related materials are represented as linked cards.
In their method, the weight of a card E is determined by the TF-IDF values of all the query terms in E plus the average TF-IDF weights of all immediate-descendant elements of E. Card weights are propagated recursively from the leaf elements to the root element.
This is one of the first works to index document elements by combining the content and structure information.
But this method may not be practical to index a large amount of structured documents mainly due to two reasons.
First, in the hypertext medical handbook model, every element has its own content and the contents of its descendant elements are only viewed as supplements to its own content.
However, in the case of general structured documents, such as the XML documents, an intermediate element usually does not have its own content and it is totally made of the contents of its descendant elements.
If the weight propagation technique in [4] is directly employed, the weight of a composite element without its own content will always be ranked lower than that of its descendents, because its weight is the average value of the summed weights of all its descendents.
Consequently, the leaf elements will always be retrieved as best matches.
Second, the propagation mechanism in [4] does not perform any pre-processing and thus the same index terms may be distributed in multiple elements of one document, which is very costly in terms of both storage space and computation time, especially when handling a large amount of documents.
Moreover, the author did not give any quantitative evaluation of the proposed method.
Thus it is hard to judge its effect in a real application scenario.We approach the goal of flexible element retrieval by a hierarchical indexing mechanism, which is not only able to index the leaf nodes but also intermediate nodes, i.e. section and document nodes.
Basically, we use a propagation and pruning mechanism to select index terms.
From bottom up, terms that can "exactly" describe the inherent concept of an element are propagated to it while terms with too broad or too narrow meanings are pruned.
Index pruning is employed to ensure that an index term appearing in an element would not appear in any of its descendent elements thus the content overlap in the text is avoided in the index.
This saves much storage space and retrieval time.
Moreover, this hierarchical indexing mechanism produces an index structure that is identical to the document structure.
Hence we can perform document element retrieval on the index space directly.
Figure 2 illustrates the process of index propagation and pruning.
Assuming that we have a document named "China" with a section "History" and this section contains subsections such as "Tang dynasty", "Ming dynasty" and "Qing dynasty", etc.
Then for the section "History", only terms like "history" and "dynasty" are good index terms, while for the whole document, only the term "China" is the best choice.Based on the hierarchical index, we also propose a flexible element retrieval algorithm to rank candidate elements against queries so that suitable document elements that precisely meet user's information needs can be returned.We conducted a series of experiments to evaluate the performance of our method in terms of precision and recall at element level.
The results show that our method significantly outperforms the compared method and is less sensitive to threshold setting than the traditional passage retrieval methods.
In recent years, many structured document retrieval techniques have been developed.
In traditional IR community, due to the absence of explicit structural information, documents are treated as a sequence of fixed-length [3] or pre-defined [15] portions of text, which are considered as passages or paragraphs.
Passage retrieval [3] [8] [9] [15] [16] is one of the early techniques aiming to retrieve and return more compact and shorter answers at passage level to the user.
A passage retrieval method usually indexes the documents at passage or paragraph level, and applies the variants of TFIDF measure to rank passages, while [13] is an exception, which suggests using Hidden Markov Model to retrieve both documents and passages.
More recently, researchers start to address the problem of mixing content and structure in retrieval models [2].
[12] suggests a model containing a number of useful operators that can achieve relatively high efficiency.Another group of methods, mainly developed by the database community, concentrate on retrieving specific fields of semi-structured or XML data by indexing structures and strictly defined query languages [1] [7].
In the case of XML query languages, these methods require the user to specify structured queries.
However, without the knowledge of the document structure, it would be very hard for the users to formulate meaningful queries.
Moreover, only the data elements whose structures exactly match the specified query structure can be retrieved.We found there was a lack of an appropriate method that balances the trade-off between the full utilization of document structure and the convenience of common users.
Some researchers attempt to address this problem.
[14] explores the use of inference network to represent elements of a document at different levels so that all elements can be treated equally.
However it still has difficulty in properly ranking various elements with the existence of content overlaps.
[6] proposes a new way to index a bibliography repository with a hierarchical structure.
Focused retrieval method of locating document components that contain relevant information is introduced in [10].
[5] describes a new query language introducing some information retrieval features, such as weighting to XML documents retrieval.
In this section, we describe the details of our hierarchical indexing strategy.
For each document, we automatically establish a hierarchical index with the same structure as that of the document.
Index terms are distributed across all nodes in the document tree.
The basic idea of assigning an index term to an element node is that the term should characterize the concept of this element and differentiate it from the others.
Thus, a rule of thumb for selecting good index terms is that the term should appear frequently and be distributed evenly in the text of an element and, its rank is high compared to its peer terms.
By taking advantage of the hierarchical structure of the documents, the distribution of a term in an element can be measured by investigating the term's appearances in the descendant elements of this element.
It is noted here that we consider only immediate-descendant elements of the element because we believe that the topic of an element is best supported by the elements that it owns directly.
If a term is distributed evenly in a composite element's immediate-descendant elements, this term would be a good candidate index term for this element.We introduce the concept of entropy here as a criterion to measure the distribution of a term in an element.
Here we distinguish between two types of elements -the intermediate elements and leaf elements which are paragraphs.
For an intermediate element, we compute the weight of a term by combining the term's intra frequency in this element and the term's distribution in its immediate-descendent elements.
That is the weight of term i t in an arbitrary composite element j E can be defined as:) , ( )) , ( 1 ln( ) , ( j i j i j i E t I E t tf E t Weight × + = (1)where tf(t i , E j ) denotes the frequency of term t i in the element E j .
I(t i , E j ) is the entropy measure, i.e. the distribution of the term t i in element E j and is defined as: ) ( 1 ln ) , ( ) , ( ) , ( ln ) , ( ) ( 1 ln ) ( ) , ( ) , ( ) , ( ln ) , ( ) , ( sub N E t× − × − = × − × − = ∑ ∑ ∑ ∈ ∈ ∈ (2)where sub k stands for the th k immediate-descendant element of E j and N(sub) the number of such descendant elements.In Equation 2, it is worthwhile to notice that term frequency varies greatly in different elements due to the great variance of text lengths.
Entropy measure may encounter the same length normalization problem as in other document or passage retrieval methods.
[3] [8] [9] [6] [14] [15] addressed the normalization of text length but were limited to the factor of term frequency.
We compute the theoretic maximum entropy) ( 1 ln ) , ( sub N E t tf j i × −and use this as normalization factor.
It hypothesizes that all appearances of this term in a specific element are exactly equal in each of its immediate-descendant elements.
The proportion of this value is used as the distribution measure of a term.
It counters the negative effect of varying text lengths to some extent.Leaf elements of paragraphs are "atomic" elements, which have no children elements, thus we simply employ the traditional TFIDF measure to compute the weight of terms in a single paragraph.
A term's weight in a paragraph is defined as:i j i j i n N P t tf P t Weight ln )) , ( ln( ) , ( × = (3)Weight(t i , P j ) represents the weight of term t i in paragraph P j .
tf(t i , P j ) is the term frequency of t i in the paragraph.
N denotes the total number of documents in the corpus and i n the number of documents containing t i .
Term weights are further normalized to be comparable in different elements.
Term weights obtained by Equations 1 and 3 are divided by the maximum weight of all terms in the same element so that all terms' weights fall into the range of between 0 and 1.
Recall that a term in an element whose weight is relatively high should be selected as the index term for this element.
Specifically, the selection of index terms is realized by the propagation and pruning process.
In the previous section, we derive the weights for each term in an arbitrary element.
A term is propagated to an upper element if its weight exceeds a certain threshold, and meanwhile this term is pruned from these descendant elements since it may stand for a more general concept.
This process is done recursively from bottom up until all the nodes in the tree are assigned proper index terms without duplications in the same branch of the index tree.
Obviously, the threshold controlling the term selection should be dynamically adjusted according to the statistics of all the terms' weights in a specific element.
More precisely, a term is chosen as an index term for an element if and only if its weight is above the average value plus the standard deviation of all terms' weights in this element.
Our indexing propagation and pruning mechanism can be described as follows:Algorithm 1 -terms selection (index terms propagation and pruning)1.
For each leaf element, i.e. paragraph, calculate all terms' weights for paragraphs according to Equation (3 This indexing solution makes full use of the internal structural information of documents.
Since all terms are compared to each other at the same level and a theoretic maximum entropy value is used as the normalization factor, the negative effect of varying lengths of text in elements at different levels is minimized.
Our experimental results are able to testify this.
In addition, an index term of an element need not necessarily appear in all sub-elements of this element due to the nature of the measurement of the term weight.
Thus more representative index terms other than just a few words in titles can be found.
In this section, we describe the flexible element retrieval algorithm which is used to select suitable document elements.
With the help of hierarchical index, the main task of the retrieval phase is online searching and ranking of candidate elements.
For each document, we use a path ranking algorithm to calculate relevance values of all candidate elements against a query.
A path for an element is defined as the branch containing all the ancestor elements of this element (including itself) in the document tree.
According to our hierarchical indexing mechanism, an element does not share any index terms with its ancestors.
Thus we say that an element is completely represented by all index terms of the elements along its path.
Conversely, a path can be expressed as the element at the lowest level in the path.
Therefore, the element ranking problem can be transformed to a path ranking problem, that is, to find those element paths with high relevance values to the query.The relevance value for a path against a given query is defined as:∑ = × = Q i i p i p n N Path t Weight Path levance 1 ln ) , ( ) ( Re (4) i n N lnis the IDF value of query term t i and is used here as the query term's weight.
Q stands for the number of query terms in a query.
Weight(t i, Path p ) is defined as the weight of the query term t i for path Path p .
We define that a term's weight for a path is its weight for the element that containing this term along the path, as is defined by Equations (1) and (3).
Given a new query, we use traditional document retrieval methods to get a list of relevant documents first in order to narrow down the search space.
Then when the user selects one of the relevant documents, the system searches for all candidate elements of this document and ranks their paths according to Equation (4).
The most relevant elements are sorted and displayed with the structural context to the user.
The overall process is described as below: 1.
Find all elements that contain at least one query term.
2.
Get paths for all candidate elements and merge the paths, that is, merge two paths into one if one is a part of the other.
3.
Assign the weights of the query terms for elements to their paths respectively.
4.
Rank these paths according to Equation (4).
5.
Return the elements corresponding to the ranked paths with the ranks satisfying the pre-defined threshold in a descending order.A long-standing problem in structured document retrieval is how to select proper elements which best satisfy the user's query needs.
Usual method to solve this problem is to set a fixed threshold and the elements with ranks above this threshold are returned as the results [15].
However due to the variation in text length, the proper threshold varies with documents and queries.
We use the average of all retrieved elements' ranks as the dynamic threshold.
The experiments show that a more accurate element retrieval can be attained based on this dynamic threshold.
Flexible information retrieval may return larger or smaller granularity results than what the user needs.
Therefore a good user interface for browsing the results in the original tree structure context is crucial for improving users' query process.
Figure 3 shows a snapshot of the interface of our flexible element retrieval system with a given query "Qing dynasty".
In Figure 3, we can see that total of sixteen elements are returned for the document named "China", among which there are sections and paragraphs.
The top element is a section with the title "The Manchu Qing Dynasty" that is dedicated for describing the Qing Dynasty in the history of China.
This section is under the 7th section of this document, whose title is "History".
From the left browsing pane, we can see clearly each section or paragraph's position in the document.
In comparison, when we click the first article "Qing Dynasty", we get the whole document since the entire document is rooted on this topic.
In summary, the flexible retrieval system returns the most appropriate document elements to users according to their queries.
In this section, we evaluate the performance of our proposed flexible element retrieval method and investigate the effects of threshold settings on element retrieval.
The experiments are conducted on the Encarta corpus, which contains 41,942 well structured XML documents.
The query set is made up of 10 queries, which can be best answered by only a part of the relevant documents.
The 10 queries used in this experiment are listed in Figure 4.
For comparison purpose, we implemented a passage retrieval system, TFIDF Para.
This system uses only pre-defined paragraphs in Encarta documents as passages while ignoring other structural information.
A term's weight in a paragraph is defined by the conventional TFIDF measure [15], which is the same as Equation (3).
The relevance measure between a given query and a specific paragraph is the cosine similarity between their term vectors.
Previous work on passage retrieval or structured document retrieval focuses their evaluations mainly on the impact of passage level evidence on retrieving the whole documents [3] [9] [15].
Some of them gave out several examples of extracted components in a selected document given a specific query [15].
But none of them conducted special experiments dedicated to the evaluation of the effectiveness of element retrieval.
[14] intends to implement such experiments but they lack appropriate test collection.
We conducted a series of experiments in order to testify if our flexible element retrieval method can find elements with proper granularity against the users' queries.Relevance judgments are made by human assessors.
For each query, the assessors first select a document that is considered as most relevant.
Then the relevant elements in that document against this query are judged and selected by the assessors without the knowledge of the targeting systems.
Besides precision and recall, we also employ F-Value to be an integrated measure for performance evaluation.precision recall Value F / 1 / 1 2 + = −(5)When deciding what fractions of the retrieved elements should be returned to the users as the answers, we use both fixed thresholds from 0.1 to 0.9 at the increment of 0.1 plus 0.95 and two dynamic thresholds.
One such dynamic threshold is the average of the rank values of all retrieved elements for a query (Avg), and the other is Avg plus the standard deviation of these values (Std_Dev).
The results obtained by these two methods with various thresholds are illustrated in Tables 1, 2 and 3 for precision, recall and F-value respectively.
For the flexible element retrieval method, we test its performance on two different sets of index.
Each composite element, say a document or a section, has a title, which is a good indicator for its content.
In order to get more convincing results, we build the first set of index without using the titles.
Experiments indicate that most of the title terms can be re-constructed by our indexing mechanism.In the second set of index, we add the title for a document or a section to every paragraph below it as index terms.
For TFIDF Para system, the index utilizes the titles as is done in the second set of index.
From the above tables, we can see clearly that with the various threshold settings our flexible element retrieval method has a significant improvement in retrieval performance, especially measured by precision and F-Value, over the method of applying TFIDF measure to paragraph level directly.
With respect to F-Value, the average improvement is 56.02% involving titles, and 40.89% without considering titles.
In both cases of adding title terms into index terms and not dealing with title terms, the precision of the flexible element retrieval system is much better than the TFIDF Para system with the average improvement of 48.83% and 41.67% respectively.
We attribute the drastic augment in precision to the high quality index terms selected by our index propagation and pruning algorithm.
In addition, the flexible element retrieval method can return elements with various granularities which may be paragraphs, sections or even the whole documents depending on the specification of queries.
In contrast, previous passage retrieval methods return only fixed-level passages.
However, there is slight decrease in recall for some threshold settings when using the index set without adding the title terms.
This is caused by our index term selection threshold, which is somehow too tight such that some proper terms are missed because their distributions in text do not meet the selection threshold.
But we deem that the decreased recall can be compensated by our interface which allows users to browse in the document structure freely.
Previous leaf nodes indexing methods make an element available against a query only if the element contains a part of the query, i.e., a relevant composite element can be retrieved with all of its descendant elements if and only if each of the descendants contains at least one query term.
This is not the case in many documents so a lot of relative paragraphs containing no query terms are missed in the TFIDF Para system's results.
On the other hand, TFIDF Para system introduces much noise into the final result by adding some paragraphs which do not cover the meaning of the user query but do contain some query terms.
In comparison, with the index propagation and pruning mechanism, the index with the tree structure in our system can make sure of a relatively better concept matching.
To a composite element, say a section, the appropriate index terms would be propagated to it even if only a part of its descendant elements contain these terms.
This index structure ensures the integrity of the resulting elements.
Threshold setting is very crucial for structured document retrieval to get a set of desirable resulting elements.
In previous works, the thresholds are usually fixed [15].
In our experiments, we find that using a single threshold cannot make the system always perform well for different queries since the documents vary greatly in structure and length.
We explore the use of dynamic thresholds instead of fixed threshold in our experiments.In order to see how various thresholds affect the retrieval performance, we plot the F-Values obtained with various thresholds in Figure 5.
The Figure shows that the curve generated by our method, especially the curve representing the results obtained without using title terms, is much flatter than that obtained by the TFIDF Para method.
The performance of the TFIDF Para method varies greatly with the changing of threshold.
The highest F-Value obtained by TFIDF Para is 0.6513(at the threshold of 0.4), which is 177.96% greater than the lowest value of 0.2343 (at no threshold).
In comparison, with the use of title terms, the maximum (at threshold Avg) and the minimum (at threshold Avg+SDev) F-Values of our method vary only 26.61%; and in the case of without considering title terms, the variation is only 15.13%.
This indicates the fact that our method is less sensitive to threshold setting.
We attribute the robustness to that our method takes full advantage of the document structure to mix the statistics of term occurrences and distributions in weighting terms.
Moreover, from Figure 5, it is interesting to note that the dynamic thresholds, such as Avg and Avg+SDev, can produce desirable results.
When using the index set with title terms, the F-Value of the flexible retrieval system achieves the best performance when using the threshold avg.
Our method using the index set without title terms can also get very good result with the threshold Avg, which is slightly less (9.47%) than the best one.
But due to the sensitivity to the threshold setting, TFIDF Para system cannot be improved when using dynamic threshold.
This testifies that dynamic threshold is a good alternative for threshold setting for our system since in most cases we cannot use one threshold to ensure the best performance for all documents and queries.
Passage retrieval based on structural information in documents has long been suggested as effective ways to retrieve elements of a document with finer granularity.
In this paper, we proposed a new hierarchical index propagation and pruning mechanism for structured documents and realize a flexible element retrieval system based on this index structure.
An index term is propagated to an upper level element in the tree structure if it represents a more general concept, which is judged by comparing its statistical information with other peer terms' weights in that element.
Index terms are distributed across the whole document tree and each element has a list of index terms which can best represent the concept of that element.
The flexible element retrieval method is dedicated to providing users with the most appropriate elements at any level.
We conducted experiments to evaluate our method in terms of precision and recall in element level.
Experimental results showed that our method significantly outperformed the method of applying TFIDF measure to only the paragraph level.
It was also found that our method was not sensitive to threshold setting compared to other passage retrieval methods.
Moreover, we observed that dynamic threshold is a better solution for the threshold setting for element retrieval.
The authors would like to express their sincere thanks to Dr. Wei-Ying Ma for his valuable comments and suggestions to improve this paper.
