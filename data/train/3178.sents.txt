With the advent of virtualization and cloud computing, virtualized systems can be found from small companies to service providers and big data centers.
All of them use this technology because of the many benefits it has to offer, such as a greener ICT, cost reduction , improved profitability, uptime, flexibility in management , maintenance, disaster recovery, provisioning and more.
The main reason for all of these benefits is server consolidation which can be even further improved through dynamic resource allocation techniques.
Out of the resources to be allocated, memory is one of the most difficult and requires proper planning, good predictions and proactivity.
Many attempts have been made to approach this problem, but most of them are using traditional statistical mathematical methods.
In this paper, the application of discrete Bayesian networks is evaluated , to offer probabilistic predictions on system utilization with focus on memory.
The tool Bayllocator is built to provide proactive dynamic memory allocation based on the Bayesian predictions, for a set of virtual machines running in a single hypervisor.
The results show that Bayesian networks are capable of providing good predictions for system load with proper tuning, and increase performance and consolidation of a single hypervisor.
The modularity of the tool gives a great freedom for experimentation and even results to deal with the reactivity of the system can be provided.
A survey of the current state-of-the-art in dynamic memory allocation for virtual machines is included in order to provide an overview.
Computers and ICT (Information and communications technology) undoubtedly is emerging more and more into our lives.
A Statistical research (2007) provided that we would have 1 billion personal computers by 2008 [18].
This was confirmed by another research in June, 2008 [5] and both of them foresee that this number will be doubled by 2014-2015.
The adoption in the Enterprise increases as well as ICT increases corporate productivity [1], but the companies obviously need to use non stop running servers.
This leads to increased hardware purchase costs, as well as peripheral costs and environmental damage coming from the power consumption of the servers and the cooling facilities [9].
If one considers that most of the time (>70%) in typical deployments the servers are idle, the cost to operate underutilized servers is significant [9].
Furthermore, if a server requires more computing power at peak load and not for more than a few hours every day, either better hardware has to be acquired, or more servers in a load balanced topology have to be added.
As an outcome, even more power consumption and idle time is added to the infrastructure.
Except that, human presence and intervention is needed to take care of the hardware changes.A solution to the described problem can be given using server consolidation and Virtualization technology.
Since the virtual machines have no physical boundaries, they maintain great flexibility to manipulation of their consumable resources and extend the options to provide high Quality of Service (QoS) using scripts or other soft technologies.
Probably the most famous technique to address performance issues and underutilization, is the live migration between different hypervisors [2,12,4], but it needs further infrastructure like the existence of a common storage device (SAN/NAS) and more than one physical hosts -hypervisors [4].
Small businesses (SMBs) might not even have this additional infrastructure or spare servers to use live migration.
An alternative solution could be to use the dynamic resource allocation ability of virtualization to dynamically change the resources allocated to the running virtual machines on a single hypervisor at the right time in order to achieve optimal performance.Dynamic CPU and live memory scaling is provided by mainstream virtualization technologies like KVM, XEN and VMware [8,15].
CPU is a time-shared resource so it can be easily shared among the virtual machines and priority can be given by the scheduler to the most important virtual machines [8].
Memory, on the other hand, is harder to share since a memory page reserved by one virtual machine, cannot be released as long as it is in use.
Common tactics used for memory sharing and scaling are achieved by memory overcommitment.
Memory overcommitment builds upon the assumption that all virtual machines residing in the same hypervisor do not need to consume 100% of their available memory at all time.
Following this assumption, more memory than the total memory available in the hypervisor is assigned to the total number of virtual machines and some memory addresses are used by more than one guest, usually not at the same time.Ballooning is a common memory overcommitment method which is used in this paper.
Ballooning needs a driver to be installed in the guest operating system.
The driver communicates directly with the hypervisor and acts on demand.
When the hypervisor needs more memory for a guest, it will choose a virtual machine which is the "victim" or the "donor" and the balloon driver will "inflate" in this virtual machine, trying to allocate memory pages from it and give them back to the hypervisor.
Then the hypervisor will "deflate" the balloon of the guest who is the "beneficiary" and needs to get the claimed memory, making available these memory addresses to it (see figure 1).
One disadvantage of ballooning, is that even if the virtual machine is trying to collaborate, the balloon driver might not be able to recover the memory requested by the host fast enough to avoid performance degradation [8,13].
To avoid or reduce this undesirable behavior, proactivity is needed.
A tool which is able to learn from repeatable events, predict virtual machine memory load beforehand and act, would help to solve the disadvantage of real time ballooning to a large extent.
The scope of this paper, is an attempt to create a prototype self learning, predictive system for dynamic memory allocation in virtual machines running in a single KVM hypervisor using Bayesian networks.
A Bayesian belief network is a probabilistic graphical directed acyclic model, indicating the conditional dependence in a set of random variables [3].
Bayesian networks are popular to probabilistic artificially intelligent decision support systems for their good ability to learn from new observations, perceive and plan ahead [7,10,6].
A Bayesian network first needs to be trained by a person who is knowledgeable in the environment it will have to work with.
Nodes of random variables (chosen by the trainer) have to be created and their directed relationship influence needs to be defined.
The Bayesian network will then provide probabilities for the event represented by a node to happen, given the probabilities of the surrounding nodes.
More nodes for more accurate results can be added to the Bayesian network if there is evidence of interference from other sources, and the current ones can adapt to behavioral changes of the system giving accurate results as more knowledge is absorbed.
This means the longer the system works, more confident results it will provide.The layout of this paper is as follows: In the related work section an overview of similar scoped papers and their difference from this approach are explained.
The methodology section comes to give an explanation of the methods used to perform the experiments, which is followed by the results, discussion, future work and a conclusion.
Research in the area of virtual machine dynamic resource allocation is highly active, as this is the key to achieve proper resource utilization, environment friendliness, cost reduction and increased profits by physical resource oversubscription.
There are many papers found addressing the same topic, but a brief survey with the most closely related work with similar scope as this paper is gathered in this section.
Adaptive Control of Virtualized Resources in Utility Computing Environments [11] This system is a quite simple approach based on control theory, for dynamically allocating virtualization resources in a single hypervisor to succeed in CPU QoS.
The experiment comprises input data from the test virtual machines.
An actuator in the control system controls the CPU scheduler of the hypervisor, to assign resources to the virtual machines so that they will not exceed 100% utilization and performance decrement.
They only focus on CPU utilization.
Dynamic Memory Balancing for Virtual Machines [19] MEmory Balancer (MEB) is a software which dynamically monitors the memory usage of virtual machines, it will then calculate its memory needs, and periodically reallocates memory to the virtual machines.MEB has an estimator and a balancer.
The estimator will build a Least Recently Used (LRU) memory pages histogram for each virtual machine and it will also monitor their swap space usage.
Then the balancer runs with an interval and adjusts virtual machine memory, based on the information given by the estimator and the available host resources.
Ballooning is used for the memory management from MEB.
Memory Buddies: Exploiting Page Sharing for Smart Colocation in Virtualized Data Centers [17] Memory Buddies, is a project which will try to maximize the efficiency of the page or memory sharing feature available in hypervisors, between multiple hypervisors.
The page sharing feature will only merge memory pages of virtual machines running in the same hypervisor, so in a data center with multiple hypervisors, memory sharing opportunities may be lost because the guest machines holding identical pages are located on different hosts.The contribution of this paper is a memory fingerprinting technique to identify guests with high memory sharing potential.
Then it will use live migration to move these hosts and shutdown or start on demand hypervisors not in use to trim down operational costs by reducing the energy consumption.
Their evaluation shows a 17% increase of the virtual machines running in a data center.
Overdriver: Handling Memory Overload in an Oversubscribed Cloud [16] Ultimately, the target of this project is to maximize competitiveness and profitability of cloud providers by oversubscribing customers.
Since most of the physical resources are leased using virtual machines, oversubscription means that the cloud provider sells more subscriptions, or more virtual machines to their customers than what its infrastructure can actually handle if all of them would run at peak load at the same time.The coherence is that the peak load for each customer is largely transient (up to 88.1% of overloads last for less than 2 minutes) and not at the same time for all of them.
Overdriver focuses on memory oversubscription as memory is not largely oversubscribed in practice like CPU, because memory overload leads to swapping and consequently to severely degraded performance.Existing methods to handle memory overload use mostly migration to another physical machine that can handle the memory requirements, but virtual machine migration is a heavyweight process needs also high network usage, best suited to handle sustained or predictable overloads.
They propose a new application of network memory to manage overload giving it the name "cooperative swap".
This will take swap pages and store them to memory servers over the network.
Then they present Overdriver, the system that it will respectively choose between VM migration and cooperative swap to manage either sustained or transient overloads.
Overload will create a probability profile for each virtual machine to decide after how much time the coming load is considered to be sustained load for the specific guest.
When the increased memory load comes, it will first use its cooperative swap feature and if the load surpass the sustained threshold set for this guest (based on the probability profile), a live migration will be executed.
Overdriver is a reactive tool to avoid excessive memory load.
Dynamic Placement of Virtual Machines for Managing SLA Violations [2] In this paper, the authors introduce a management algorithm for dynamic resource allocation in virtualized environments using live migration.
Their elemental goal is to meet the Service Level Agreement (SLA) the company has with its customers, while reducing the operational costs from the data centers of the company.
From those three categories the second and the third category of virtual machines are potential candidates for live migration.
The first one shows sustainable resource usage so it does not need to change host often.The next step is the calculation of available physical resources needed to handle the predicted load and start or shutdown non needed servers to reduce costs.
This method is a proactive probabilistic method like the one proposed in this paper but they use different statistical tools, while their experimental studies are only focused CPU utilization which is known that it is much easier to handle since it is a time shared resource.
VMCTune: A Load Balancing Scheme for Virtual Machine Cluster Based on Dynamic Resource Allocation [20] This paper proposes VMCTune, a tool that monitors the resource utilization of virtual machines and their hosts.
Then it uses dynamic resource allocation for virtual machines running on same hypervisor to achieve better local resource utilization and if the QoS cannot be met, it uses live migration for virtual machines among different hypervisors to achieve global load balancing.
The tool focuses in Paravirtualized machines and offers a reactive solution dealing with CPU, memory and network bandwidth.
Paravirtualized machines are easier to handle their resources in comparison with the Fully virtualized ones, as they are aware that they run in a virtualized environment.VMCTune has several tools to monitor, log the data, schedule the resource allocation or issue a live migration if needed and a command line tool by which the user can monitor the status of the virtual machines and control the host.Improving of scheduling algorithm of the live migration is the key work mentioned as their future research work in this paper, as the one used is a very simple best-fit algorithm.
For example, if a virtual machine needs more resources and it cannot fit to the current hypervisor, it will be transferred in a different one with the available resources.
There will be no attempt to squeeze resources from other hosts to achieve the best possible utilization.
In the next section the design of Bayllocator will be presented.
In order to improve working efficiency and extendability, the system is designed in a modular fashion.
As illustrated in the conceptual system design in figure 2, everything runs on top of a single physical machine which is the hypervisor.
The hypervisor is split into two logical partitions.
First is the space available for the virtual machines (left part on the figure) and the latter (right part on the figure) is the space available for the administration of the virtual machines.Data generation is taking place on the virtual machines.
Data collection resides on the administrative part of the system together with the prediction system.
A script collects the data through the virtualization layer (the dotted separation line) and stores it in a database.
The prediction then is made using as the data from the database as input and the dynamic memory allocation mechanism will reallocate the memory using the virtualization layer.
Controlled random data are generated and mostly used to carry out the experiments.
Data generation is a good starting point to explore something new.
Generated data has a unique feature.
It can be controlled so that one can make prior assumptions and expectations need to be confirmed by the results.For data generation, a script is created and a flow chart in figure 3 explains its working logic.
The design of this script was made with the ambition in mind to create random data with controlled randomness by modifying the variation.
The script will generate data given 3 parameters:1.
Max memory to occupy (given in MB).
This parameter will set the maximum memory the script will try to claim.
The passed memory is a rough estimate.2.
Max threads to create.
This parameter will start the given number of random consuming memory threads and all of them together will consume a maximum amount of memory given by the first parameter.3.
Max runtime of the script.
This will control the time length the script will be generating data.
Real life data from two servers in production (nexus and studssh) have also been collected in parallel with the generated data.
Nexus is a webserver, while studssh is an ssh server for students, with many logged in users.
A simulated prediction based on this data is run in the end, which gives an indication of how good the designed Bayesian network and its predictions work on real systems.
Dynamic memory allocation driven by the Bayesian predictions is the outcome of this paper and short term prediction is the main goal.
A memory allocation script is created and it tries to reallocate the memory of the virtual machines 5 minutes in advance before the expected memory demands come.
The infrastructure schematic already explained briefly in figure 2.
On top of this, a test environment is being built for the experimental part of the project.
Some virtual machines are created, and high memory load is generated and collected on each one of them.
Simple Bayesian networks are tested and in the end a prototype (Bayllocator) is created to put everything together.
With the final system built, a simulation is running against the real data collected.
The observed memory utilisation should follow the predictions closely to be considered successful, and since ballooning is implemented any slowdowns introduced by heavy memory utilisation should be trimmed off.
Bayllocator is the tool created to accomplish the task in this paper.
Some clarifications of the principles this program operates are given as bullets below and a very detailed flow chart explains visually the entire operation steps can be studied in figure 11.
Bayllocator will:• Make a prediction of how much memory each of the virtual machines will need and set this amount of memory plus some predefined percentage (default 15% more).
• Ensure that the virtual machines do not get less or more than the minimum and maximum limits set.
• Make sure that the hypervisor will not swap any memory.
In the case of high memory pressure, it is preferred that the virtual machines start swapping, instead of the hypervisor which is responsible to handle them all.
• Distribute fairly (according to a percentage of the needed memory of the total predicted for the virtual machines) any excessive hypervisor memory to the virtual machines.
If there is more memory than needed available, it can be used for disk caching purposes so it will boost guest performance.
• Claim memory fairly from virtual machines if they need more than the total amount allowed to get to avoid hypervisor swapping.
In this case some of the virtual machines might start swapping under pressure.It is important to note from the list above, that even though the predictions are made on a per-VM basis, Bayllocator acts with all VMs in mind, trying to distribute the memory as fairly as possible based on individual predictions.
The Bayesian prediction is being made with an R script which will be given as command line arguments the states of the known nodes (evidence), the name of the node which the answer is to be provided and the file with the discrete values to learn the CPTs (Conditional Probability Tables) from.
The answer is a two-column comma separated output with the first column showing the possible state and the second column the probability (a percentage) to observe this state for the given inputs.
In the example on the following code block, the Bayesian network is asked "what is the expected memory when it is Monday, 07:55-07:59 and the currently observed memory of the guest system is between 100MB and 200MB".
The answer is 14.8% to get 100MB-200MB, 24.3% to get 200MB-300MB and so on.
The result from the Bayesian network apparently contains more than one probability (the previous output of the script has more than one row), so a single number has to be chosen as the expected memory.
To make a fair decision, all of the given results are used to calculate this number.
First the mean value of the discrete states memory will be calculated and then a single number given the probabilities of all of them as illustrated in the following equations.
Many Bayesian networks with simple nodes related to the memory and date were tested, but the following one affected by current memory and date proved to be more successful (see figure 4) and its results for the generated data are presented in figure 5, while simulations on real data with the same network are taking place in fig- ures 6 The red line in figure 5 shows the predictions which comes 5 minutes earlier and the black line is the actual data observed.
There is a large variation in the observed data and this is related to the randomly generated data, but as illustrated the prediction follows quite well.Some of the predictions often reach a certain wrong value in y axis, marked with a horizontal dotted line in figure 5.
This value is exactly 2099200 KB and it is an indication that the system does not know how to answer for the given evidence.
When the Bayesian network gets an unobserved combination of evidence, then all of the probabilities of the query node are equal.
Because the discrete states defined for the memory nodes CMU and FMU are 41 (from mem 0 100, mem 100 200 to mem 4000 greater every 100MB), the probability for each state is 1/41 = 0.024390244 which gives this num- ber as expanded in equation 1.
∑ n=100,4000 n · 1 41 + 39 ∑ n=1 (n · 100 + 50) · 1 41 = 2050MB (1) 2050MB · 1024 = 2099200KB Three simulations ran with different training datasets in nexus2.
The first learning dataset for nexus2 is from April 10th, to April 16th (figure 6), the second from April 10th, to April 22nd ( figure 7), and the third one from April 10th, to April 25th ( figure 8).
All of the three simulations ran have missed predictions (2099200KB values as explained earlier), but it is obvious that when the system is trained with a larger dataset it fails much less.
A comparison of the common predictions for all of the simulations (after the vertical dotted line) shows that for the first training set, 808/2774 predictions failed (29.1%), for the second 122/2774 (4.4%) while for the third only 76/2774 which makes up the 2.7% of the total predictions.If one takes a better look to the predictions of nexus2, will notice that the predictions follow steps.
This is because the training datasets are based on discretized and not continuous variables, so as the predictions.
If the memory in the system is 501MB or 600MB, both of these observations are encoded as the memory state mem 500 600 and they represent a memory state of 550MB in the reverse operation.
A simple evaluation was made to see the effect of dynamic memory allocation.
Two operations were running in test server 1 and their execution time was measured.
As can be seen in figure 9, the execution time of a PHP script running on an apache 2 web server would take as much as 50 seconds under heavy memory load (between 08:00-18:00), while it would not take more than 3 seconds under normal circumstances.
When ballooning is initiated, the operation looked like normal at any time.
Same observations can be made for figure 10, where a secure copy operation initiated from an external machine to test server 1.
The reason for this slowdown before ballooning, is the heavy memory swapping on hard disk.
Hard disk is many orders of magnitude slower than the To avoid this kind of slowdowns and use the most out of the physical hypervisors, the dynamic memory allocation is necessary.
The competence of Bayllocator resides in the prediction method to predict system utilisation in a non traditional way, using Bayesian networks.
The focus is mainly in memory prediction and appliance of dynamic memory allocation based on this information to improve sharing efficiency.
Due to its nature, memory is not easy to share as the time shared resources like CPU or Disk I/O, becoming an obstacle to server consolidation, green and low cost ICT.
Highly active ongoing research tries to predict system utilisation and use this information for dynamic resource allocation, but most of them use traditional statistical methods to approach the problem.
The traditional statistical methods might involve rigorous mathematics and they usually are single purpose, or hard to adapt them to different needs.
Bayesian networks are strongly associated with artificial intelligence.
Moreover, after an extensive literature survey it does not seem that effort to apply the use of Bayesian networks on server utilisation prediction exists.
Bayesian networks differ significantly from the traditional statistical methods, and their big advantage is that they are modular directed acyclic graphs, composed of nodes representing variables related to the system they work with, and changing of these nodes might give totally different results and use cases.
Furthermore, even the output from traditional methods can be used as the input in a Bayesian network, and more than one of them can be combined.
The modular design gives flexibility and allows the easy combination and alteration of different parameters affecting the system.The prototype software is made in Perl, which is calling an R script for the Bayesian predictions.
This modularity gives the flexibility to change the prediction method at any time and evaluate the guest performance under different circumstances.
The lack of wide purpose collected data from real servers prevented from further experimentation with the causal nodes affecting the final memory predictions.
Each change to the Bayesian network needed time to be tested and make assumptions on how well it works, but when one gets used to work with Bayesian networks, there is a broad spectrum of applications this method can be applied, and certainly computing utilisation prediction and decision making is one of them.
The date related variables used in this paper are not the best choice because the date is not the true reason behind high memory activity.
They had to be used though, because of the lack of representative collected data.
The true reasons are probably the number of logged in users and the number of running processes or network connections which are factors an expertise in the field knows, or is able to suspect.
This is why the trainer must be knowledgeable to the subject where the Bayesian networks needs to work with.
The date might be an indirect causal node since it affects the number of connected users in a server (for example if it is a weekend less people might work on a server).
Not well directed nodes and excessive number of states decrease the learning efficiency of the Bayesian networks, and as a result the training period needs a longer time.
In this paper, an implementation of simple discrete Bayesian networks and their ability to predict memory utilisation was evaluated.
Since the nodes represent discrete states for continuous variables, there is a loss of information as illustrated by the introduced imaginary steps of the prediction in figure 8.
Hybrid Bayesian networks which include both discrete and continuous nodes to achieve higher prediction resolution would be the first task for the future work list.
Moreover, the focus of this paper was in the predictions and proactivity, which are followed blindly by Bayllocator.
Proactivity solve some problems of reactivity which it might be slow to sudden large memory changes, but reactivity is mandatory in a dynamic resource allocation system because if the prediction is wrong, then the system will perform very inadequately.
Implementation of reactivity which will be ruled by predictions is another key improvement for Bayllocator.
Design of a more sophisticated Bayesian network with more accurately chosen nodes is also under work.
This paper is work made for a master thesis in system administration at the University of Oslo and Oslo and Akershus University College.
Therefore, we would like to express our gratitude to the institutes provided the test equipment, and the people involved directly or indirectly.
The scripts and prototype software created for this project are based on Perl and R statistics language.
They can be acquired upon request by email.
Further details can be found in the accompanying MSc thesis [14] Iterate through guests -read current memory in use Is the hypervisor memory in 1 enough for the demands of the guests?Set total Hypervisor memory limit for all of the guests (1)Calculate the time to make the prediction for each guest (default 5 mins in future)Make the actual prediction for each guest
