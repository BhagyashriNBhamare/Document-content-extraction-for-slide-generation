The reliability of a storage system is crucial in large data centers.
Hard disks are widely used as primary storage devices in modern data centers, where disk failures constantly happen.
Disk failures could lead to a serious system interrupt or even permanent data loss.
Many hard disk failure detection approaches have been proposed to solve this problem.
However, existing approaches are not generic models for heterogeneous disks in large data centers, e.g, most of the approaches only consider datasets consisting of disks from the same manufacturer (and often of the same disk models).
Moreover, some approaches achieve high detection performance in most cases but can not deliver satisfactory results when the datasets of a relatively small amount of disks or have new datasets which have not been seen during training.
In this paper, we propose a novel generic disk failure detection approach for heterogeneous disks that can not only deliver a better detective performance but also have good detective adaptability to the disks which have not appeared in training, even when dealing with imbalanced or a relatively small amount of disk datasets.
We employ a Long Short-Term Memory (LSTM) based siamese network that can learn the dynamically changed long-term behavior of disk healthy statues.
Moreover, this structure can generate a unified and efficient high dimensional disk state embeddings for failure detection of heterogeneous disks.
Our evaluation results on two real-world data centers confirm that the proposed system is effective and outperforms several state-of-the-art approaches.
Furthermore, we have successfully applied the proposed system to improve the reliability of a data center and exhibit practical long-term availability.
Device failure is a common problem in large data centers, where hard disks are widely used as the primary storage devices.
A disk failure could lead to temporary data loss and thus system breakdown, or even permanent data loss if the lost data cannot be recovered by data protection schemes (eg., replication and erasure codes) due to disk failures exceeding the designed correction capability [1].
About 80% of system breakdowns are caused by hard drive failures in the data center [2].
Therefore, how to ensure the reliability of disks becomes an important issue in a storage system [3].
Although there are a series of passive fault defense mechanisms like EC (Erasure Codes) [4,5] and RAID (Redundant Arrays of Independent Disks) [6], many researchers have focused on proactive disk failure detection which aims to ensure the reliability and availability of large-scale storage systems in advance [7][8][9].
Disk failure prediction is an important issue in system researches.
Timely and accurate failure prediction can ensure the operational continuity of systems and even avoid data loss.
It is because of this common realization among the storage research community, there have recently emerged a decent amount of researches on disk failure prediction.We observed six classes of approaches of disk failure detection: threshold-based (TB) approaches [10,11], distancebased anomaly detection (DAD) approaches [12][13][14][15][16], shallow machine learning (SML)-based approaches [17][18][19][20][21][22][23][24][25][26][27][28][29], deep neural network (DNN)-based approaches [30][31][32][33][34], one-class classification (OCC) based approaches [35][36][37][38][39] and transfer learning (TL)-based approaches [1,[40][41][42][43][44].
However, these approaches have their limitations as summarized in Table 1.
(1) Limited applicability.
Different disk manufacturers have different S.M.A.R.T (Self-Monitoring, Analysis, and Reporting Technology) values or data distribution, even in different disk models of the same manufacturer [1,43].
This will result in a situation where methods (SML, DNN, OCC, TL) trained on specific parameters only work well for the same manufacturer, and often even for the same models, limiting their scope of applicability in practice.
(2) Lack of adaptability.
New disk models enter gradually to replace or augment the storage capacity, leading storage systems to consist of disks from different vendors and/or different models [1,41,42].
Facing these different types of heterogeneous disks, the existing prediction models (DAD, SML, DNN, OCC, TL) must be retrained to obtain more reliable predictions in order to adapt to the changes in the data distribution introduced by these new disk models.
Such re- Performance TPR: 3%-10% 56%-70% 75%-96% 87%-98% 70%-92% 80%-97% 92%-97% FPR: 0%-2% 0%-1% 1%-4% 0%-1% 0%-10% FPR: 0%-6% 0.2%-0.4% F-Measure: 2%-13% 49%-58% 67%-92% 86%-93% 65%-91% 77%-93% 91%-97%training is tedious and expensive in a large data center.
(3) Imbalanced datasets.
Imbalanced data refers to a situation where the number of samples is not the same for all the classes in a classification dataset.
Most machine learning (ML) models tend to bias the class with the largest proportion of observations (known as majority class), which may lead to inaccuracies.
This may be particularly problematic when we are interested in the correct classification of a "rare" class (also known as minority class).
In real world cloud storage systems, the imbalanced ratio of positive (failure) samples and negative (healthy) samples poses a significant threat to the efficiency of machine learning models [2].
The most commonly used technique of existing methods (DAD, SML, DNN, TL) to approach this problem are under-sampling [1,15,28] and over-sampling techniques [45].
In under-sampling, the data samples are adjusted based on the class with the lowest sample count to keep the number of samples per class equal.
In over-sampling the samples of the sparsely populated class are re-sampled to match the number of data samples in the other classes.
Under-sampling discards a large amount of data while oversampling can easily cause overfitting in the model.
Moreover, these approaches might increase the training cost.
(4) Minority disk failure detection.
In large-scale storage systems, new disks gradually replace failed disks, which results in a situation where the data centers continuously contain small amounts of new disk models.
Due to a lack of sufficient training data, some detective approaches (DAD, SML, DNN, OCC) fail to deliver satisfactory detective performance for these models.
Although some TL methods (transfer learning is good at transferring knowledge from the source dataset to the target dataset) have been proposed to address this issue, their performance depends on finding a suitable source domain (in the form of another disk model) for knowledge transfer, which might be difficult in a real world data center (detailed in Section 3.1.2).
(5) Detective performance.
The True Positive Rate (TPR), False Positive Rate (FPR) and F-Measure (all these evaluation metrics see Section 5.1.3 for details) are the commonly used metrics to measure the capabilities of classification models in disk failure detection [1,15,17,19].
Most methods show unstable performance in practical long-term use and often fail to obtain both high TPR and low FPR.
In this paper, we propose a novel disk failure detection system called "High-Dimensional Disk State Embedding for Generic Failure Detection" (HDDse).
It is a distancebased anomaly detection approach using deep learning and addresses the discussed shortcomings of the existing methods.In summary, we provide the following contributions: • To the best of our knowledge, we propose the first generic disk failure detection system HDDse for heterogeneous disks.
It is not sensitive to imbalanced datasets, has wider applicability, well detects the minority disks and exhibits high adaptability.
(Section 4.1) • We propose a Long Short-Term Memory (LSTM)-based siamese network to calculate the similarity of disk health states in high-dimension space, which combines distancebased anomaly detection and deep learning to classify disk state in high-dimension.
(Section 4.2) • We experimentally evaluate our method on datasets from two real world data centers.
We demonstrate that HDDse can effectively detect disk failures in long-term availability that greatly improves the reliability and availability of the storage system and outperforms the state-of-the-art approaches in five adopted metrics (Section 5.2 and 5.3).
Existing work mostly uses the S.M.A.R.T (Self-Monitoring, Analysis and Reporting Technology) data to build a disk failure detection model.
Almost all hard disk drives and flashbased SSDs now support S.M.A.R.T, which monitors the internal attributes of individual drives.Threshold-based Methods (TB).
All disk manufacturers use a thresholding algorithm which triggers a failure alarm when any single S.M.A.R.T attribute exceeds a predefined value [10,11].
However, this approach provides only an estimated TPR (True Positive Rate, see Section 5.1.3 for details) of 3%-10% with a 0.1% FPR (False Positive Rate, see Section 5.1.3 for details).
The reason is that the hard disk manufacturers set the thresholds conservatively to avoid expensive false alarm costs, i.e., they keep the FPR to a minimum at the expense of the TPR.Distance-based Anomaly Detection Methods (DAD).
DAD is the method of finding data objects with behaviors that are very different from expectation based on some similarity metrics.
Shen et al. [15] utilize the change in the Euclidean distance [46] between the healthy disk samples and the last sample of a failed drive.
Wang et al. [13] propose a model for drive anomaly prediction based on Mahalanobis distance (MD).
In their subsequent study [14], they use a generalized likelihood ratio test over the dissimilarity vector to detect disk failures.
Huang et al. [16] explore the read/write head failures and bad sector failures using the Euclidean distance to calculate the dissimilarity between each S.M.A.R.T record prior to the failure and the failure record.
Gao et al. [12] present an incremental detection model of disk failures based on the Euclidean distance to measure the local anomalies of test points within their isolation regions optimizing the judgment of test point anomalies.Shallow Machine Learning based Methods (SML).
Conventional (shallow) machine learning methods typically require manual extraction and selection of features (eg., Support Vector Machines (SVM [47]), Logistic Regression (LR [48])), a critical step that is dispensed within the deep learning approach, i.e., it is automatic in deep learning approaches.
Shortcomings of existing work.
The above mentioned approaches (SML, DNN and OCC) deliver good detective performance only when both training and testing data are drawn from the same distribution [54].
A recent study [22] on heterogeneous disk failure prediction has pointed out that the predictive results are not good enough for adoption in prac- methods using datasets of disk models from two data centers.
Although the SML, DNN and OCC achieved better performance than the DAD method in the case of datasets consisting of disks from the same disk models, the DAD approach delivers strong applicability and adaptability.tice.
Therefore, most of the experiments for these methods only consider datasets consisting of disks from the same manufacturer (and often of the same disk models) and thereby have limited applicability.
Except for the method DAD, the methods (SML, DNN and OCC) learn the S.M.A.R.T data distribution of the specific disk model but not the unified detection measure, as a result, these approaches have bad predictive performance when dealing with the disk models thathave not yet appeared in previously trained models (i.e., poor adaptability).
Furthermore, all the methods (especially for DNN and OCC) require a large number of training samples to build robust models, which is difficult to be satisfied for minority disks in data centers.
Training models on the minority disks would dramatically increase the risk of overfitting, and the resulting poor generalization will decrease the performance of predictive models [1].
Although TL approaches can handle this situation well, an important premise of this approach is that there is one or more appropriate source majority disk models for knowledge transfer, but we find this to be a tough assumption in practice (see Section 3.1.2).
Moreover, most of these approaches increase the training cost to process the imbalanced datasets and could result in discarding a large amount of data or model overfitting (mentioned in Section 1).
In this section, we investigate the performance of existing approaches in three aspects (applicability, adaptability and minority disk failure detection) and describe our motivation for enabling high-dimensional disk state embedding for heterogeneous disk failure detection.
We analyzed the overall performance of existing proposed approaches using different disk models from both the publicly available S.M.A.R.T dataset Backblaze 1 and the data center of Tencent (one of the largest social network companies in the world).
Figure 1(a), 1(b), 1(c) and 1(d) respectively show the overall detective performance of the state-of-the-art methods (DAD [12], SML [17], DNN [31] and OC [35]) using different datasets of disk models.
For convenience, we use Data1 https://www.backblaze.com/b2/hard-drive-test-data.htmlCenter-Disk Manufacturers-Disk Model to denote the dataset we use.
For example, the disk model C from Seagate in data center BackBlaze can be referred to as B-STX-C and the disk model A from WDC in data center Tencent can be referred to as F-WDC-A.
In each figure, the vertical and horizontal axes refer to the disk models of training and testing dataset respectively.
We use F-Measure (detailed in Section 5.1.3) to evaluate the performance of failure detection models.
The higher the value is (the darker in the heatmap), the better the performance is.
In the last row of each figure, we use the hybrid datasets (the first 6 disk models contain F-STX-A, B-STX-B, F-WDC-A, B-WDC-B, F-HIT-A and B-HIT-B) for training and then detect on different disk models.
Note that the last three disk models F-STX-C, F-WDC-C, B-HIT-C are not included in the hybrid disk models for training.
We summarize the findings from these four figures.
(1) Detection approaches (SML, DNN and OCC) built on a specific disk model only has good results test on the same disk model (i.e., the detective model built on F-STX-A and detect on F-STX-A, as illustrated by the darker diagonal lines).
Moreover, DNN-based approach shows the best performance in this case.
(2) The SML, DNN and OCC approaches built on hybrid disk model datasets decrease the detective performance compared to a model built on the same disk model (we call the model has poor applicability in this case).
Moreover, the performance of these approaches further deteriorates when detecting the disk models that have not appeared in the training datasets.
(3) Although the overall detective results of the DAD method is not good enough to be deployed in practice, it is not sensitive to the different disk models.
In other words, the performance of cross-model disk failure detection is very close.
Besides, the DAD approach built on hybrid disks increases the performance compared to the model built on a single disk model (good applicability) and shows high adaptability to disk models that have not appeared in training.
Note that we also evaluated many other studies on these methods and got similar results and we don't discuss all the results here due to space limitations.
In order to investigate the detection for minority disks (the number of disks less than 1,500 [1]), for TL approach, we use the majority disk model which has the smallest Kullback Leibler Divergence (KLD) values with the detecting minority The TL approach achieves the best performance but it depends on the small enough KLD value of the majority disk which is chosen for training.
disk model from the same manufacturer to train the detective models.
The detecting minority disk models are listed on the xaxis ordered by the calculated smallest KLD values.
For other approaches, they only trained the detective model based on minority disk datasets.
Note that KLD is a metric measuring the divergence degree of one probability distribution from another expected probability distribution [55].
It indicates the disparities between two S.M.A.R.T datasets distributions.
A zero KLD value means that the distributions of these two disk datasets are the same, while the KLD value increases as the differences between two data distributions widen.
In general, the larger a KLD value is, the greater differences between two disk data distributions will be and the more difficult the knowledge transfer between two distributions will be in the transfer learning approach [1].
Figure 2 shows the results.
The TL approach delivers the best detective performance on minority disk failure detection especially with the training datasets having smaller KLD values while other candidates are difficult to handle this situation.
In order to take an in-depth look at the feasibility of this method in practical large storage systems, we studied the disk quantities by the different KLD values in two data centers.
As shown in Table 2, in Tencent data center, only 35% of all minority disk models could find a majority disk model with small KLD value (range from 0 to 1) for training.
In other words, most minority disk models only find the majority disk models with a KLD value greater than 1 which might result in poor detection performance.
A similar observation has been made in the data center Backblaze.
Therefore, even in such large data centers with millions of disks, it is still difficult to find the most suitable majority disk model with small enough KLD value to use TL for minority disk failure detection.
The preliminary study results above show that The DAD approach has better applicability and adaptability than other approaches (SML, DNN, OCC), and DNN approach gives the best detective performance.
Before introducing our motivation, we first to answer the following three problems: (1) Why the DAD approaches have good applicability and high adaptability while DNN does not?
The DAD method learns the distance (similarity) between the normal and abnormal disk samples in a certain space which has a commonality and not sensitive to the disk models.
However, the DNN approach learns the distribution of S.M.A.R.T data which varies with disk models, the performance of this approach would decrease when the distribution changes.
(2) Why the overall detective performance of the DAD method is not as good as other approaches.
We think the reason is it performs distance-based transformation and computation in low-dimensional space but does not learn from the dynamically changed long-term behavior in high-dimension.
(3) Why the DNN approach achieves the best performance among other candidates?
DNN is good at mapping the raw low-dimensional S.M.A.R.T attributes to high-dimensional target spaces through complex transformations that perform good expression and fitting ability and thus achieves better performance.Considering the above advantages of the DAD and DNN approaches, we are motivated to apply the distance-based anomaly detection approach and deep learning to build a general disk failure detection system for heterogeneous disks.
In order to learn a unified measure of distance in high-dimension space using deep learning and then easily use the distancebased anomaly detection approach for comparison for two input data, we applied the siamese networks [56] (commonly used in the image recognition technology) which we will describe in detail in the next section.
In this section, we first provide an overview of our proposed system HHDse in Section 4.1.
Then, we introduce the LSTM-based siamese network for disk failure detection in Section 4.2.
Finally, we describe the sample pool and decision maker of HDDse respectively in Section 4.3 and Section 4.4.
Figure 3 provides an overview of our proposed novel system HDDse which combines a sample pool, an LSTM-based siamese network for disk failure detection, and a decision maker.
Sample pool (see Section 4.3 for details) is used to store the S.M.A.R.T instances collected daily for each disk.
These instances are combined to form training and detecting samples for our approach.
Note that the sample pool has both the disk S.M.A.R.T instances with ground truth (true labels with the disk states) for training and the unlabeled instances for detecting.
LSTM-based siamese network for disk failure detection (see Section 4.2 for details) is the core part in HDDse, the input of the network is a pair of samples from the sample pool and the output is a binary classification result that indicates the similarity of these two samples.
In online detection, since there are many results of the target detecting samples at a continuous moment compared with other labeled samples, each output detective result indicates for a particular sample at different moments rather than the whole disk health state.
Therefore, Decision Maker (see Section 4.4 for details) is a module to map these sub-results of samples to the final whole disk healthy state.
Many previously proposed machine learning models, such as random forests (RFs), decision trees, SVM and DNN rely on the phenomenon that some key attributes are distinct from others when the disk is going to fail.
Therefore, these approaches take a single snapshot of S.M.A.R.T attributes as training data for detection, without considering the sequential dependency between different statuses of a hard disk over time (only rely on features extracted from one day) because they are unable to make use of the time series data (except for converting them to sequential features manually).
However, many researches have shown that the S.M.A.R.T of the disk changes dynamically with a certain trend [2,19,21,27,57], thus the current state of the disk may depend on a long-term historical trend.
In contrast to all the aforementioned methods, we apply the LSTM to the parsing of sequential S.M.A.R.T information.
LSTMs have been successfully applied to a variety of applications, including text sentiment classification [58] and multi-language text classification [59].
Traditional approaches to solving a classification problem, such as SVM, random forests (RFs) or even DNN, generally require that all the categories be known in advance (some newly disk models entered the data center without enough history information to classify the categories) for training.
Moreover, those approaches are not suitable for applications where the number of samples per category is small (minority disk models).
Siamese networks are dual-branch networks with tied shared weights, i.e., they consist of the same network copied.
This method is proposed for training a similarity metric from data, which can be used for classification tasks (eg., face recognition) in which the categories need to be classified have not appeared during the training process, and can also handle the situation of training samples for a single category which is very small [60].
The symmetry of siamese networks is important and reasonable for learning a unified measure of distance, for example, the distance from disk state S 1 to state S 2 should be equal to the distance from S 2 to S 1 .
Therefore, we propose an LSTM-based siamese network for disk failure detection.
Figure 4 shows the structure of the network.
The training sample pairs we feed to the network are randomly selected from the sample pool which contains two S.M.A.R.T samples (see Section 4.3 for details) from the same disk manufacturer denoted as < S, S >.
We design two LSTM networks to receive these two S.M.A.R.T samples respectively which need to be compared for their similarity.
Note that these two LSTM networks (BiLSTM [61] refers to bi-direction LSTM layers) shared their weights in order to map the inputs to the same target high-dimension space for comparison.
Each LSTM consists of an input layer U, four hidden layers H, one dense (fully connected) layer D with 128-dimensional units and an embedding layer E.
In contrast to traditional neural networks, the LSTM operates over sequences of input vectors.
This structure is able to capture the historical context of disk healthy statuses and makes LSTMs suitable for tasks related to sequential detection.
Note that the dense layer is followed by an embedding layer (a fully connected layer) with 256-dimensional units, and then one more layer computing the distance metric (Euclidean distances 2 ) between each siamese twin network.
We employ a Sigmoid function in the final layer to output a normalized value on the learned high-dimensional feature space and scores the result between the feature vectors of the input sample pair.
Note that our proposal is the first to propose an LSTM-based Siamese network based on the peculiar features of disk failures and has shown promising prediction outcomes.
Learning process.
Let E ω (S) and E ω (S ) be the projections of the input pair S and S in the embedding space computed by the embedding layer (high-dimension space) network function E ω .
The output layer is a single unit computed by the induced distance metric between each siamese twin.
The detective vector is given by:ED ω (S, S ) = f sig ( N−1 ∑ i=0 β i |E i ω (S) − E i ω (S )|))where f sig is a Sigmoid activation function.
β i are additional parameters that are learned by the model during training, weighting the importance of the component-wise distance.
Supposing that N represents the total number of S.M.A.R.T sample pairs over a dataset D = < S i , S i ,Y i >, where i indexes the ith training pair and Y (S i , S i ) is the corresponding label.
We assume Y (S i , S i ) = 1 whenever S i and S i are the same disk state label and Y (S i , S i ) = 0 otherwise.
The total loss function is given by:L ω (D) = λ||ω|| 2 + 1 2N N−1 ∑ i=0 i ω (S i , S i ,Y i )We use a squared L2-norm regularization (also called ridge regression) in this loss function to improve the ability of model generalization.
The ω are the weights of the neural network and λ is the weight decay (this prevents the weights from growing too large and can be seen as gradient descent on a quadratic regularization term to prevent from the model overfitting) set as 0.001 to train our model.
The instance loss function i ω comprises of terms including the similar (Y = 1) case (L s ), and the dissimilar (Y = 0) case (L d ):i ω = Y i s (S i , S i ) + (1 −Y i ) d (S i , S i )The loss functions for the similar and dissimilar cases are given by:s (S, S ) = (ED ω ) 2 d (S, S ) = (m − ED ω ) 2 , m < ED ω , 0, otherwise.m is a margin which defines how far away the dissimilarities should be.
These settings were chosen during cross validation, grid searching over possible margin settings.
Suitable margin helps us distinguish the two input S.M.A.R.T samples better.
Therefore, the instance loss function can also be given by:i ω = Y i (ED ω ) 2 + (1 −Y i ){max(m − ED ω , 0)} 2It is interesting to investigate the proposed loss function.
When the two samples are similar/dissimilar (Y = 1/ Y=0), if the ED ω is wrongly calculated large/small by our model, the value of this loss function will become larger.
Our goal is to minimize it.The parameters of our model are optimized using the Adam optimizer [62] with a decreased decaying learning rate.
The training process was run for 150,000 epochs with learning rate (lr) starting at 0.1 and decrease it by a factor of 2 every 50 training epochs.
We use the dropout technique [63] (a dropout of 0.5) used on the recurrent units and between layers to prevent overfitting.
For the hyper parameter (margin m, weight decay λ, learning rate, the unit number of fully-connected layers) optimization, we use the grid searching to perform hyper parameter selection.
Our sample pool consists of the collected S.M.A.R.T instances with their corresponding confirmed labels and some instances that need to be detected.
We collect all the instances of each disk in the data center every day.
All the time data have been discretely sampled at an interval of one day.
If the data collection starts at day T 0 and a disk can fail in any day T f after that, a disk can have data for all such time indices t where t varies from T 0 to T f .
We can formulate this instance as a multivariate sequential vector I t = {I t 0 , I t 1 , I t 2 , ..., I t a } that contain length-a attributes of S.M.A.R.T data at time t for each disk.
More specific information about the attributes we use in our evaluation is given in Table 3.
Besides, each input of the LSTM consists of a fixed length (we set 14 days in our system to learn the long-term disk state behavior) continuous instances (referred to one sample) with its corresponding label.
The first day recorded in a disk failed sample is not the day when the disk fails, but the latest day when the collected attribute stops changing [2,21,23].
We use change-point detection to decide how many days samples of failed disks preserve for training.
Change-point detection can find an abrupt change during a period.
We observe that most attributes have a significant change around 7 days before failures.
Therefore, for a failed disk, continuous samples in a period of 7 days (our method has the ability to predict the failure 1-7 days in advance) before actual failure (T f ) are labeled as failed (y = 1).
For healthy disks, we label the total continuous samples as healthy (y = 0).
Note that Y = 1 (Y = 0) means the label of the generated input pairs which is a combination of two same (different) labeled samples.
The relationship between S.M.A.R.T instances, samples and the input training pairs is shown in the Figure 5.
RAID arrays will not affect the operations in the sample pool and the decision maker in Section 4.4.
As mentioned in Section 4.2, the inputs of our proposed network are two S.M.A.R.T samples < S, S > in pairs.
There-fore, we can freely combine and label a pair of samples from the same disk manufacturer.
There are two benefits for generating this form of training datasets compared to existing approaches which treat each S.M.A.R.T sample as a snapshot in the training process.
Better with imbalanced datasets.
It reduces the degree of data imbalance by the simplest free combination.
We use the imbalance degree (IDe) [64] to indicate the dataset imbalance which is defined as the ratio between the majority and minority samples (the larger value the IDe is when IDe is larger than 1, the more imbalanced the dataset is).
For an imbalanced dataset containing a minority class sample with size A and the IDe is α, the majority class sample size is αA.
The number of pairs with labels Y = 1 (Y = 0) n 1 (n 0 ) after combining the input samples can be expressed as:n 1 = C 2 A +C 2 αA , n 0 = C 1 A ×C 1 αA .
where the C 2 A (C 2 αA ) is the number of "similar" sample pairs generated by the minority class samples (majority class samples).
The new imbalance degree IDe of the input pairs is given by: IDe = n 1 n 0 = α 2 − 1+α−A 2Aα since A, α > 1, the value of IDe will be around α 2 , which effectively alleviates the original data imbalance by a factor of two.
Note that we directly arrange all labeled samples to form the input training pairs without losing large amounts of information (instances) in the sample pool compared to the Under-sampling method which is commonly used in recent researches.
Although our method can alleviate imbalanced datasets, it is difficult to eliminate.
Fortunately, extensive experimental results in Section 5 demonstrate that the siamese network is insensitive to imbalanced datasets, which is the same as many existing research results [65,66].
Better with minority disk models.
It forms large training samples even with the minority disk models.
The number of training pairs with the minority disk models in existing methods is P = A(1 + α).
However, in our method the number of training pairs is: P!
2!
(P−2)!
= P(P−1) 2 which is extremely large compared to existing methods.
Therefore, our model can increases the number of samples greatly and make better use of deep learning algorithms to detect the failure and avoid model overfitting (the experimental results are discussed in Section 5.2.2).
In this section, we aim to seek answers to the following two problems: (1) Which training samples need to be arranged to form the input pairs with the detecting sample and how to make a decision (same state or not) for these pairs in the online detection process.
(2) How to make a disk healthy state decision for a target disk based on the results of these detecting samples at continuous moments?When a sample of a target detecting disk needs to be detected, we let all the labeled training samples from the same disk manufacturer to be arranged to form the input pairs.
For accelerating the process of making a decision for each sample, we follow four detecting steps: Step 1.
We arrange all the samples labeled as failed (y = 1) from the same disk model (all majority and minority disks) to form the input pairs with the target detecting sample respectively.
If any of these pairs are detected as similar (Y = 1), we will mark this detecting sample as failed (y = 1), otherwise, proceed to the next step.Step 2.
Considering the sparsity of the state of healthy disk samples, we first randomly select 10% healthy disks of the same disk model and arrange the samples (y = 0) collected randomly in one-month intervals to form the input pairs with the detecting sample.
If all these pairs are detected as similar (Y = 1), we will mark this sample as healthy (y = 0).
Otherwise, follow the third step.Step 3.
We compare with the samples labeled as failed (y = 1) from the different disk models but the same manufacturer with the detecting sample.
If more than half of the results are detected as similar (Y = 1), we will mark this sample as failed (y = 1).
Step 4.
Similar to step 2, the only difference is we arrange the different disk models from the same manufacturer.
Note that when the disk model of the detecting sample did not exist in the sample pool, we will start from step 3.
Each target detecting disk consists of several results of detecting samples at continuous moments, each output result indicates the detection for a particular sample at one moment rather than the whole disk health state in a period.
Therefore, to improve the robustness of the detection method against noise, we propose a voting-based sliding window (V SW ) method to make a disk healthy state decision for the final disk state.
Figure 6 shows the architecture of V SW .
According to the results of the detecting samples stored in the Decision Maker, we define the V SW method for failure detection in the following manner: Define a length-W time sliding window and move it forward everyday.
A failure alarm will be reported, if the window consists of V (R) consecutive results from step 1 (step 3), otherwise, there is no failure alarm.
These parameters (W,V, R) will be optimized as hyper parameters of the model to determine its optimal value and were chosen during cross validation, grid searching over possible settings.
The configuration of our real-world large scale storage system is W = 7,V = 1, R = 2.
Note that some other decision solutions can be explored to improve the robustness of our method further (eg., a weighted k-nearest neighbors approach).
In this section, we evaluate the detective performance of HDDse.
We first describe the methodology, followed by the experimental results of effectiveness and efficiency and compare HDDse against the state-of-the-art approaches with respect to the evaluation metrics.
We describe the characteristics of two real world S.M.A.R.T datasets and the attributes selection in our experiments.
Then we introduce the experiment setup and some evaluation metrics used in our experiments.
Datasets.
We use S.M.A.R.T datasets from two real world data centers for evaluation.
One is the publicly available data set from "Backblaze" 3 , which spans a period of 58 months consisting of 146,203 healthy disks and 8,256 failed disks.
The second proprietary dataset has been collected by Tencent and spans 29 months consisting of 70,192 healthy disks and 2,971 failed disks.
All disks in these datasets were labeled to be either failed or healthy.
Note that the data from these two data centers are extremely imbalanced.
We tried to impute the missing S.M.A.R.T values or disks by replacing them with the median value.
Attribute Selections.
Each S.M.A.R.T instance contains many meaningful attributes.
We first select all the common attributes of the disk manufacturers.
However, we find some attributes are irrelevant to disk failure events because they are immutable or have not experienced noticeable abnormal changes.
Therefore, we use correlation coefficients and select nine attributes that correlate most with disk failure.
The selected attributes are listed in Table 3.
Each SMART attribute entry consists of many elements.
In our paper, we focus on the three elements (ID, Normalized value, Raw value) in our collected datasets.
Since different attributes have different output ranges, (which might lead to different impacts on the detection model), we normalize the range of all S.M.A.R.T attributes using min-max normalization, a common preprocessing technology in machine learning: x norm = x−x min x max −x min where x is the original value of a S.M.A.R.T attribute, x max and x min are the maximum and minimum value of the attribute in the training data set, respectively.
Note that we tried other normalization methods (e.g., z-score), but achieved the best results using min-max normalization.
The hyper parameters and attribute selections were done over the entire datasets.
To simulate the detecting process of disk failure in the real world, we use the following method to build the experimental datasets.
All disks are randomly divided into a training set and a testing set at a ratio of 7 to 3, as in most researches [1,35,67,68] which guarantees that the failed disks in the training set and the testing set are completely independent.
Note that the deterioration of a failed disk is a gradual process from healthy to failure, and not all samples of failed disks need to be used in the training set; otherwise, those healthy samples of failed disks which are far from the actual failure would disturb the training of the detection model.
Therefore, only the last seven continuous samples (we detailed it in Section 4.3) before the moment of failure of the training disks can be regarded as failed samples and need to be added to the training dataset.
Furthermore, we obtain all results via cross-validation [69] to decrease the variability of the detections (analogous to many methods [1,41,70]).
For the configurations and parameters of our system HDDse, the maximum number of training epochs is set to 1000; the learning rate is initially set to 0.1, and we decrease it by a factor of 2 every 50 training epochs; the coefficient of weight decay λ is set to 10 −8 .
We train and evaluate our method on a Linux server with 12-core 4.0GHz CPU, 64GB RAM and 200GB HDD.
We use the following five metrics to report the detective performance in our experiments which are commonly used for evaluating the capability of disk failure detection approaches.
TPR.
True Positive Rate (also called recall) is the proportion of failed disks that are correctly predicted.
The higher the TPR is, the better the model is.
FPR.
False Positive Rate (also called false alarm rate) is the proportion of healthy disks that are falsely predicted as failed.The lower the FPR is, the better the model is.
AUC.
We use the AUC (Area under the receiver operating characteristic curve) value under the ROC curve (receiver operating characteristic) to evaluate the binary classification performance of our detection model in imbalanced datasets.
ROC is a curve plotting the TPR against the FPR where TPR is on the y-axis and FPR is on the x-axis.
Therefore, the larger the AUC value, the higher the TPR and the lower the FPR.
AUC is the area under this curve.
A higher AUC means the model is better at distinguishing failed and healthy disks.
T data before and after embedding using our approach.
After the disk state embedding, the healthy and failed disks are nearly clustered together and easily separated.F-Measure.
F-Measure is a balance between the two metrics TPR and Prediction Precision (PP).
PP is the proportion of detected failed disks that are correctly detected.
The higher the F-Measure is, the better the model is.
C-MTTDL.
We use Cost-based MTTDL (Mean Time To Data Loss) to evaluate the reliability and availability of the storage system.
MTTDL [71] was proposed to approximate the mean time to data loss with failure detection model which is given by:MT T DL ≈ MT T F 1− kµ µ+γwhere MT T F is the Mean Time To Failure of a disk.
k is the TPR and γ is the inverse of how far in advance the model can detect the impending failures.
µ is the inverse value of Mean Time To Repair (MTTR, replace a new disk or transfer the data of the failing disk to a new one).
However, this metric only demonstrates the relationship between the MTTDL and the TPR (correctly detected) but neglects the cost of misclassification by the approach.
Too many misclassifications will result in unavailability of the storage system.
Therefore, we propose an end-toend economic analysis metric called the Cost-based MTTDL (C − MMT DL) which considers not only the reliability but also the misclassifications cost (considering the false positive rate and cost of replacing disks).
We will give the detailed definition of C − MT T DL in Section 5.2.5.
Although we propose the C − MT T DL, it is interesting to explore other end-to-end evaluation metrics (benefit in customer-perceived latency or throughput from accurate prediction).
In this section, we first analyze the disk state embeddings learned by our LSTM-based Siamese Network.
Then we show the results of HDDse compared to several state-of-the-art approaches in aspects of the ability of the minority disk detection, model applicability and adaptability respectively.
To visualize the high-dimension embedded disk statues of the embedding layers in our approach (See Figure 4), we use the t-Distributed Stochastic Neighbor Embedding (t-SNE) [72] technique which can project high-dimensional embedding spaces into 2D spaces for visualization while striving to keep data clustered together in the high dimensional space clustered together in the low-dimensional space as well.
For comparison, Figure 7 shows the t-SNE of the S.M.A.R.T data attributes in low and high dimensionality respectively (before and after embedding using HDDse) based on the collected data from three disk manufacturers.
In our case, the low dimensionality is the original S.M.A.R.T attributes most of the recently proposed methods (DAD, SML, DNN, OCC and TL) leveraged (the specific attributes are listed in Table 3).
Note that the x and y axes of a particular point have no meaning on their own and the t-SNE only attempts to preserve clusters in higher dimensional space.
The data points have been colored and shaped based on disk statues and their manufacturers.
It is observed the data points of these three disk manufacturers cluster relatively closely and the relationship between the healthy and failed disks is hard to distinguish with a unified method shown in Figure 7(a).
This highlights the challenges in failure detection of disks based on S.M.A.R.T attributes in heterogeneous populations.
This result is consistent with the findings of the research [70] and results in most of the related works only considered population consisting of the same disk models in their experiments.
As can be seen from Figure 7(b), the healthy and failed disks are easily separated (the healthy state is above the failed state for all the disks from different manufacturers) after the embedding using our proposed approach.
This experiment demonstrates that our HDDse can generate a unified and efficient high-dimensional disk state embeddings for generic disk failure detection of heterogeneous disks.
As mentioned in Section 4.3, the input training pairs generated by our method is extremely large compared to the original samples of existing approaches.
It is interesting to investigate the detective performance of HHDse when only trained on minority disk datasets.
We compare our approach with the other five state-of-the-art approaches: DAD [12], SML [17], OCC [35], DNN [31] and TL [1].
For a fair comparison, the TL approach uses the majority disk model which has the smallest KLD value with the detecting minority disk model from the same manufacturer to train the detective models.
Minority disk models from different data centers and manufacturers are listed in the x-axis ordered by these calculated the smallest KLD values.
For other approaches, they only trained the detective model based on minority disk datasets.
As can be seen from Figure 8(a), none of the four approaches (DAD, SML, OCC and DNN) can deliver a high AUC value.
The poor detective performance is due to overfitting caused by using small homogeneous datasets [1].
In particular, DNN achieved the worst results because the neural network required a huge number of samples to fit a large number of weights.
Besides, the results of the TL method imply it largely depends on whether you can find the smallest KLD value majority disk training dataset for modeling as discussed in Section 3.1.2.
It is worthy to note that our HDDse achieves the best performance in all cases.
The reason is two-fold.
On the one hand, the training pairs generated by our method are extremely large which makes our model not easy to get overfitting.
On the other hand, the disk state embeddings in high-dimension learned by our designed LSTM-based Siamese Network is effective for model classification.
In order to investigate the model applicability of our HDDse, we use the imbalanced datasets of ten disk models from three disk manufacturers in two data centers to conduct this experiment.
We compare our approach with the other four approaches: DAD, SML, OCC and DNN.
Considering the generality, those ten detecting disk models consist of three from the data center Tencent (F-STX-E, F-WDC-F and F-Hi-F), three from data center BackBlaze (B-STX-F, B-WDC-F, B-HIT-F) and four minority disk models from two data centers (F-STX-F, F-WDC-G, B-HIT-G, B-STX-G).
We use all these hybrid disk datasets to train and detect these models respectively, and the detective results are shown in Figure 8(b).
When dealing with the disks from different manufacturers, data centers and even minority disk models, HDDse achieves higher F-Measure values compared to other candidates.
The main reason is that our model maps low-dimensional attributes (disk status) to a general high-dimensional space that is not sensitive to the differences in disk models, which leads to the detection to be performed well using a unified distance calculation.
This experiment demonstrates that HDDse has good applicability for disk failure detection in a heterogeneous environment.
We evaluate the adaptability of our HHDse, e.g., how an approach can adapt to a disk model that has not appeared in the training dataset.
We use another ten disk models (note that they are different from the ten disk models showed in Figure 8(b)) from three disk manufacturers in two data centers to conduct this experiment.
As can be seen from Our method using different hybrid datasets all achieved better detective performance than other candidates.
It is worthy to note that the datasets of the detecting disk models have not appeared for training delivers comparable performance as those disk models contained (framed by red lines) in training data sets in the first five rows of Figure 8(c).
It indicates that our HDDse does not need to establish or maintain a new model and owns strong adaptability that can completely adapt to a new disk model regardless of disk manufacturers, disk models, data centers, and minority disks.
Note that we also verified the HDDse's performance on NVMe SSD and obtained promising results, which are not included due to the space limit.
As the above comprehensive analysis of detective results described, we achieved better AUC and F-Measure compared to other approaches.
In this section, we will first give the definition of the economic analysis metric C − MT T DL and then quantitatively evaluate the reliability and availability of the system based on different approaches.
C − MT T DL can be expressed as:C − MT T DL = MT T DL Cost ≈ MT T F (1− kµ µ+γ )(C a FP+C b FN)where MTTDL was defined in Section 5.1.3 and FP (FN) is the number of true healthy (failed) disks that are falsely predicted as failed (healthy).
C a and C b are the corresponding cost of these misclassifications.
These two factors can be set differently and obtain different results according to the model maintenance requirement (cost sensitivity) in the real world.
C a and C b are set to 200 and 100 (dollars) respectively in our evaluation which were estimated in Tencent data center.
C − MT T DL denotes the MTTDL per dollar cost and the larger the better.
The larger the C − MMT DL is, the better is the reliability and availability the storage.
We investigate the C − MT T DL in based on the datasets from data center Tencent.
We assume all models can detect the impending failures seven days in advance (γ = 1/(7 * 24hours), the inverse value of MT T R µ = 1/10hours and MT T F = 1,390,000 hours.
All these parameters come from data center Tencent and our experiments.
We list the results in Table 4, which shows our approach improves the C − MT T DL by about 2 orders of magnitudes than the other four candidates.
In other words, in addition to ensuring the detective performance of our approach HDDse, we have greatly improved the reliability of the storage system at a lower cost.
In this section, we evaluate the effect on training/detecting time and the practical long-term availability of our approach HDDse compared to the state-of-the-art approaches.
We train and evaluate all the approaches on a Linux server with 12-core 4.0GHz CPU, 64GB RAM and 200GB HDD.
All the approaches record the total training (from start until convergence is achieved, i.e. little changes in the performance) and online detecting time (it is for the entire testing set).
DAD has the lowest training time and the highest detecting due to its easy training method and large computation of calculating distances.
Our approach HDDse takes the secondhighest training time followed by the SML method (Random Forests) and the second-highest detecting time followed by the DAD method.
This is attributed to our method generating large training pairs compared to the original datasets that need more time to converge.
Moreover, it needs more time compared to other training samples to determine the disk statue in the detecting process (we use some sampling methods to accelerate the process of detecting mentioned in Section 4.4).
Considering the training task in a data center and sometimes, the detective models are updated weekly or monthly (we perform once a week), so the time cost of HDDse is acceptable.
Note that the time cost can be further shortened if GPU and many model compression and acceleration technologies [73] are used.
We leave in our future work to explore other solutions for optimizing the efficiency of our approach.
We last simulate practical long-term availability in data centers Tencent.
As we mentioned in section 4.2, S.M.A.R.T data of the disk changes dynamically with a certain trend, thus the distribution of S.M.A.R.T attributes changes over time, resulting in unstable detective performance for many approaches.
However, it is important to design a stable detection approach for large data centers without additional manual model tuning.
To fairly evaluate the detective performance of different approaches in the long term, we employ the same accumulation strategy to update the model periodically e.g., once a week, using all the training data collected from the beginning.
Figure 9(b) shows the TPRs and FPRs of the different detective approaches in the following 15 months.
As can be seen, HDDse shows higher TPR and lower FPR compared to other state-of-the-art methods.
It is worthy to note that HDDse exhibits stable detective performance than other candidates.
We attribute this to the LSTM-based network which is well learned from the dynamically changed long-term behavior of disk statues.
Similar to most of related works, we are focused on the predictive accuracy, because designing an accurate approach is the first critical step toward building a robust, highly reliable, and readily available operational storage system.
With a high-accuracy failure prediction approach in place, we will have a high level of confidence in integrating it into the system, which is more of a mechanism rather than a policy.
For instance, a direct application is to use the prediction results to perform data backups and replace disks that are about to fail to prevent data loss.
Moreover, we can use the predictive results to analyze the mechanism of disk sector error and build a sector error predictive model to accelerate the scrubbing rate of disks to find the sector errors in advance and improve the reliability of the storage system.
Disk failures have become one prevailing reason for unexpected system unavailability.
In this paper, we propose HDDse, an LSTM-based siamese network that can learn the dynamically changed long-term behavior of disk healthy statues and generate a unified and efficient high dimensional disk state embeddings from low dimensional S.M.A.R.T attributes for disk failure detection.
We evaluate our approach using two real-world datasets to demonstrate that HDDse is effective and outperforms several state-of-the-art approaches.
Specifically, HDDse has good detective adaptability to the disks which have not appeared in training and deliver good performance for the imbalance or minority disk datasets, thus improving storage system availability.
Furthermore, the proposed approach improves the reliability of a data center and exhibits long-term availability.
We thank the anonymous reviewers and our shepherd Eno Thereska for their help in improving our paper.
This work is supported by the Innovation Group Project of the National Natural Science Foundation of China No.61821003.
