This paper presents Prio, a privacy-preserving system for the collection of aggregate statistics.
Each Prio client holds a private data value (e.g., its current location), and a small set of servers compute statistical functions over the values of all clients (e.g., the most popular location).
As long as at least one server is honest, the Prio servers learn nearly nothing about the clients' private data, except what they can infer from the aggregate statistics that the system computes.
To protect functionality in the face of faulty or malicious clients, Prio uses secret-shared non-interactive proofs (SNIPs), a new cryptographic technique that yields a hundred-fold performance improvement over conventional zero-knowledge approaches.
Prio extends classic private aggregation techniques to enable the collection of a large class of useful statistics.
For example, Prio can perform a least-squares regression on high-dimensional client-provided data without ever seeing the data in the clear.
Our smartphones, cars, and wearable electronics are constantly sending telemetry data and other sensor readings back to cloud services.
With these data in hand, a cloud service can compute useful aggregate statistics over the entire population of devices.
For example, navigation app providers collect real-time location data from their users to identify areas of traffic congestion in a city and route drivers along the least-crowded roads [80].
Fitness tracking services collect information on their users' physical activity so that each user can see how her fitness regimen compares to the average [75].
Web browser vendors collect lists of unusually popular homepages to detect homepage-hijacking adware [57].
Even when a cloud service is only interested in learning aggregate statistics about its user population as a whole, such services often end up collecting private data from each client and storing it for aggregation later on.
These centralized caches of private user data pose severe security and privacy risks: motivated attackers may steal and disclose clients' sensitive information [84,117], cloud services may misuse the clients' information for profit [112], and intelligence agencies may appropriate the data for targeting or mass surveillance purposes [65].
To ameliorate these threats, major technology companies, including Apple [72] and Google [57,58], have deployed privacy-preserving systems for the collection of user data.
These systems use a "randomized response" mechanism to achieve differential privacy [54,118].
For example, a mobile phone vendor may want to learn how many of its phones have a particular uncommon but sensitive app installed (e.g., the AIDSinfo app [113]).
In the simplest variant of this approach, each phone sends the vendor a bit indicating whether it has the app installed, except that the phone flips its bit with a fixed probability p < 0.5.
By summing a large number of these noisy bits, the vendor can get a good estimate of the true number of phones that are running the sensitive app.This technique scales very well and is robust even if some of the phones are malicious-each phone can influence the final sum by ±1 at most.
However, randomizedresponse-based systems provide relatively weak privacy guarantees: every bit that each phone transmits leaks some private user information to the vendor.
In particular, when p = 0.1 the vendor has a good chance of seeing the correct (unflipped) user response.
Increasing the noise level p decreases this leakage, but adding more noise also decreases the accuracy of the vendor's final estimate.
As an example, assume that the vendor collects randomized responses from one million phones using p = 0.49, and that 1% of phones have the sensitive app installed.
Even with such a large number of responses, the vendor will incorrectly conclude that no phones have the app installed roughly one third of the time.An alternative approach to the data-collection problem is to have the phones send encryptions of their bits to a set of servers.
The servers can sum up the encrypted bits and decrypt only the final sum [48,56,81,92,99,100].
As long as all servers do not collude, these encryptionbased systems provide much stronger privacy guarantees: the system leaks nothing about a user's private bit to the vendor, except what the vendor can infer from the final sum.
By carefully adding structured noise to the final sum, these systems can provide differential privacy as well [56,92,107].
However, in gaining this type of privacy, many secretsharing-based systems sacrifice robustness: a malicious client can send the servers an encryption of a large integer value v instead of a zero/one bit.
Since the client's value v is encrypted, the servers cannot tell from inspecting the ciphertext that v > 1.
Using this approach, a single malicious client can increase the final sum by v, instead of by 1.
Clients often have an incentive to cheat in this way: an app developer could use this attack to boost the perceived popularity of her app, with the goal of getting it to appear on the app store's home page.
It is possible to protect against these attacks using zero-knowledge proofs [107], but these protections destroy scalability: checking the proofs requires heavy public-key cryptographic operations at the servers and can increase the servers' workload by orders of magnitude.In this paper, we introduce Prio, a system for private aggregation that resolves the tension between privacy, robustness, and scalability.
Prio uses a small number of servers; as long as one of the Prio servers is honest, the system leaks nearly nothing about clients' private data (in a sense we precisely define), except what the aggregate statistic itself reveals.
In this sense, Prio provides a strong form of cryptographic privacy.
This property holds even against an adversary who can observe the entire network, control all but one of the servers, and control a large number of clients.Prio also maintains robustness in the presence of an unbounded number of malicious clients, since the Prio servers can detect and reject syntactically incorrect client submissions in a privacy-preserving way.
For instance, a car cannot report a speed of 100,000 km/h if the system parameters only allow speeds between 0 and 200 km/h.
Of course, Prio cannot prevent a malicious client from submitting an untruthful data value: for example, a faulty car can always misreport its actual speed.To provide robustness, Prio uses a new technique that we call secret-shared non-interactive proofs (SNIPs).
When a client sends an encoding of its private data to the Prio servers, the client also sends to each server a "share" of a proof of correctness.
Even if the client is malicious and the proof shares are malformed, the servers can use these shares to collaboratively check-without ever seeing the client's private data in the clear-that the client's encoded submission is syntactically valid.
These proofs rely only upon fast, information-theoretic cryptography, and require the servers to exchange only a few hundred bytes of information to check each client's submission.Prio provides privacy and robustness without sacrificing scalability.
When deployed on a collection of five servers spread around the world and configured to compute private sums over vectors of private client data, Prio imposes a 5.7× slowdown over a naïve data-collection system that provides no privacy guarantees whatsoever.
In contrast, a state-of-the-art comparison system that uses client-generated non-interactive zero-knowledge proofs of correctness (NIZKs) [22,103] imposes a 267× slowdown at the servers.
Prio improves client performance as well: it is 50-100× faster than NIZKs and we estimate that it is three orders of magnitude faster than methods based on succinct non-interactive arguments of knowledge (SNARKs) [16,62,97].
The system is fast in absolute terms as well: when configured up to privately collect the distribution of responses to a survey with 434 true/false questions, the client performs only 26 ms of computation, and our distributed cluster of Prio servers can process each client submission in under 2 ms on average.Contributions.
In this paper, we:• introduce secret-shared non-interactive proofs (SNIPs), a new type of information-theoretic zero-knowledge proof, optimized for the client/server setting, • present affine-aggregatable encodings, a framework that unifies many data-encoding techniques used in prior work on private aggregation, and • demonstrate how to combine these encodings with SNIPs to provide robustness and privacy in a largescale data-collection system.With Prio, we demonstrate that data-collection systems can simultaneously achieve strong privacy, robustness to faulty clients, and performance at scale.
A Prio deployment consists of a small number of infrastructure servers and a very large number of clients.
In each time epoch, every client i in the system holds a private value x i .
The goal of the system is to allow the servers to compute f (x 1 , . . . , x n ), for some aggregation function f , in a way that leaks as little as possible about each client's private x i values to the servers.Threat model.
The parties to a Prio deployment must establish pairwise authenticated and encrypted channels.
Towards this end, we assume the existence of a publickey infrastructure and the basic cryptographic primitives (CCA-secure public-key encryption [43,108,109], digital signatures [71], etc.) that make secure channels possible.
We make no synchrony assumptions about the network: the adversary may drop or reorder packets on the network at will, and the adversary may monitor all links in the network.
Low-latency anonymity systems, such as Tor [51], provide no anonymity in this setting, and Prio does not rely on such systems to protect client privacy.Security properties.
Prio protects client privacy as long as at least one server is honest.
Prio provides robustness (correctness) only if all servers are honest.
We summarize our security definitions here, but please refer to Appendix A for details.Robustness.
A private aggregation system is robust if a coalition of malicious clients can affect the output of the system only by misreporting their private data values; a coalition of malicious clients cannot otherwise corrupt the system's output.
For example, if the function f (x 1 , . . . , x n ) counts the number of times a certain string appears in the set {x 1 , . . . , x n }, then a single malicious client should be able to affect the count by at most one.Prio is robust only against adversarial clients-not against adversarial servers.
Although providing robustness against malicious servers seems desirable at first glance, doing so would come at privacy and performance costs, which we discuss in Appendix B.
Since there could be millions of clients in a Prio deployment, and only a handful of servers (in fixed locations with known administrators), it may also be possible to eject faulty servers using out-of-band means.
Let us introduce Prio by first presenting a simplified version of it.
In this simple version, each client holds a one-bit integer x i and the servers want to compute the sum of the clients' private values i x i .
Even this very basic functionality has many real-world applications.
For example, the developer of a health data mobile app could use this scheme to collect the number of app users who have a certain medical condition.
In this application, the bit x i would indicate whether the user has the condition, and the sum over the x i s gives the count of affected users.The public parameters for the Prio deployment include a prime p. Throughout this paper, when we write "c = a+b ∈ F p ," we mean "c = a+b (mod p)."
The simplified Prio scheme for computing sums proceeds in three steps:1.
Upload.
Each client i splits its private value x i into s shares, one per server, using a secret-sharing scheme.
In particular, the client picks random integers [x i ] 1 , . . . , [x i ] s ∈ F p , subject to the constraint:x i = [x i ] 1 + · · · + [x i ] s ∈ F p .
The client then sends, over an encrypted and authenticated channel, one share of its submission to each server.2.
Aggregate.
Each server j holds an accumulator value A j ∈ F p , initialized to zero.
Upon receiving a share from the ith client, the server adds the uploaded share into its accumulator:A j ← A j + [x i ] j ∈ F p .3.
Publish.
Once the servers have received a share from each client, they publish their accumulator values.
Computing the sum of the accumulator values j A j ∈ F p yields the desired sum i x i of the clients' private values, as long as the modulus p is larger than the number of clients (i.e., the sum i x i does not "overflow" the modulus).
There are two observations we can make about this scheme.
First, even this simple scheme provides privacy: the servers learn the sum i x i but they learn nothing else about the clients' private inputs.
Second, the scheme does not provide robustness.
A single malicious client can completely corrupt the protocol output by submitting (for example), a random integer r ∈ F p to each server.The core contributions of Prio are to improve this basic scheme in terms of security and functionality.
In terms of security, Prio extends the simple scheme to provide robustness in the face of malicious clients.
In terms of functionality, Prio extends the simple scheme to allow privacy-preserving computation of a wide array of aggregation functions (not just sum).
Upon receiving shares of a client's data value, the Prio servers need a way to check if the client-submitted value is well formed.
For example, in the simplified protocol of Section 3, every client is supposed to send the servers the share of a value x such that 0 ≤ x ≤ 1.
However, since the client sends only a single share of its value x to each server-to preserve privacy-each server essentially receives an encrypted version of x and cannot unilaterally determine if x is well formed.
In the more general setting, each Prio client submits to each server a share [x] i of a vector x ∈ F L , for some finite field F.
The servers hold a validation predicate Valid(·), and should only accept the client's data submission if Valid(x) = 1 (Figure 1).
To execute this check in Prio, we introduce a new cryptographic tool called secret-shared non-interactive proofs ("SNIPs").
With these proofs, the client can quickly prove (a) The client sends a share of its encoded submission and SNIP proof to each server.
to the servers that Valid(x) = 1, for an arbitrary function Valid, without leaking anything else about x to the servers.Building blocks.
All arithmetic in this section takes place in a finite field F, or modulo a prime p, if you prefer.
We use a simple additive secret-sharing scheme over F: to split a value x ∈ F into s shares, choose random values([x] 1 , . . . , [x] s ) ∈ F s subject to the constraint that x = i [x] i ∈ F.In our notation, [x] i denotes the ith share of x.
An adversary who gets hold of any subset of up to s − 1 shares of x learns nothing, in an information-theoretic sense, about x from the shares.This secret-sharing scheme is linear, which means that the servers can perform affine operations on shares without communicating.
That is, by adding shares [x] i and [y] i , the servers can locally construct shares [x+y] i .
Given a share [x] i , the servers can also construct shares [αx + β] i , for any constants α, β ∈ F. (This is a classic observation from the multi-party computation literature [15].)
Our construction uses arithmetic circuits.
An arithmetic circuit is like a boolean circuit except that it uses finite-field multiplication, addition, and multiplicationby-constant gates, instead of boolean and, or, and not gates.
See Appendix C.1 for a formal definition.
A secret-shared non-interactive proof (SNIP) protocol consists of an interaction between a client (the prover) and multiple servers (the verifiers).
At the start of the protocol:-each server i holds a vector [x] i ∈ F L , -the client holds the vector x = i [x] i ∈ F L ,and -all parties hold an arithmetic circuit representing a predicate Valid :F L → F.The client's goal is to convince the servers that Valid(x) = 1, without leaking anything else about x to the servers.
To do so, the client sends a proof string to each server.
After receiving these proof strings, the servers gossip amongst themselves and then conclude either that Valid(x) = 1 (the servers "accept x") or not (the servers "reject x").
For a SNIP to be useful in Prio, it must satisfy the following properties:Correctness.
If all parties are honest, the servers will accept x.Soundness.
If all servers are honest, and if Valid(x) 1, then for all malicious clients, even ones running in super-polynomial time, the servers will reject x with overwhelming probability.
In other words, no matter how the client cheats, the servers will almost always reject x.Zero knowledge.
If the client and at least one server are honest, then the servers learn nothing about x, except that Valid(x) = 1.
More precisely, when Valid(x) = 1, every proper subset of servers can simulate its view of the protocol execution.These three security properties are nearly identical to the properties required of a zero-knowledge interactive proof system [70].
However, in the conventional zeroknowledge setting, there is a single prover and single verifier, whereas here we have a single prover (the client) and many verifiers (the servers).
Our contribution.
We devise a SNIP that requires minimal server-to-server communication, is compatible with any public Valid circuit, and relies solely on fast, informationtheoretic primitives.
(We discuss how to hide the Valid circuit from the client in Section 4.4.)
To build the SNIP, we first generalize a "batch verification" technique of Ben-Sasson et al. [19] and then show how a set of servers can use it to verify an entire circuit computation by exchanging a only few field elements.
We implement this last step with a new adaptation of Beaver's multi-party computation (MPC) protocol to the client/server setting [9].
Related techniques.
Prior work has studied interactive proofs in both the many-prover [14,60] and many-verifier settings [1,10].
Prior many-verifier protocols require relatively expensive public-key primitives [1] or require an amount of server-to-server traffic that grows linearly in the size of the circuit for the Valid function [10].
In concurrent independent work, Boyle et al. [25] construct what we can view as a very efficient SNIP for a specific Valid function [25].
They also use a Beaver-style MPC multiplication; their techniques otherwise differ from ours.
To run the SNIP protocol, the client and servers execute the following steps:Set-up.
Let M be the number of multiplication gates in the arithmetic circuit for Valid.
We work over a field F that is large enough to ensure that 2M |F|.
Step 1: Client evaluation.
The client evaluates the Valid circuit on its input x.
The client thus knows the value that every wire in the circuit takes on during the computation of Valid(x).
The client uses these wire values to construct three polynomials f , g, and h, which encode the values on the input and output wires of each of the M multiplication gates in the Valid(x) computation.Specifically, if the input wire values to the t-th multiplication gate, in topological order from inputs to outputs, are u t and v t , then for all 1 ≤ t ≤ M, we define f and g to be the lowest-degree polynomials such that f (t) = u t and g(t) = v t .
Then, we define the polynomial h as h = f · g.The polynomials f and g will have degree at most M−1, and the polynomial h will have degree at most 2M − 2.
Since h(t) = f (t) · g(t) = u t · v t for all t ∈ {1, . . . , M}, h(t) is equal to the value of the output wire (u t · v t ) of the t-th multiplication gate in the Valid(x) circuit.In Step 1 of the checking protocol, the client executes the computation of Valid(x), uses polynomial interpolation to construct the polynomials f and g, and multiplies these polynomials to produce h = f · g.
The client then splits the coefficients of h using additive secret sharing and sends the ith share of the coefficients [h] i to server i.Step 2: Consistency checking at the servers.
Each server i holds a share [x] i of the client's private value x. Each server also holds a share [h] To see how, first observe that if a server has a share of every wire value in the circuit, it can construct [ f ] i and [g] i using polynomial interpolation.
Next, realize that each server can reconstruct a share of every wire value in the circuit since each server:• has a share of each of the input wire values ( [x] i ),• has a share of each wire value coming out of a multiplication gate (the value [h] i (t) is a share of the t-th such wire), and • can derive all other wire value shares via affine operations on the wire value shares it already has.
Using these wire value shares, the servers use polynomial interpolation to construct [ f ] i and [g] i .
If the client and servers have acted honestly up to this point, then the servers will now hold shares of polynomials f , g, and h such that f · g = h.In contrast, a malicious client could have sent the servers shares of a polynomiaî h such that, for some t ∈ {1, . . . , M}, ˆ h(t) is not the value on the output wire in the t-th multiplication gate of the Valid(x) computation.
In this case, the servers will reconstruct shares of polynomialsˆfnomialsˆ nomialsˆf andˆgandˆ andˆg that might not be equal to f and g.
We will then have with certainty thatˆhˆfthatˆ thatˆhthatˆhˆ thatˆhˆf · ˆ g. To see why, consider the least t 0 for whichˆhwhichˆ whichˆh [19] use polynomial identities to check the consistency of secret-shared values in a very different MPC protocol.
Their construction inspired our approach.)
(t 0 ) h(t 0 ).
For all t ≤ t 0 , ˆ f (t) = f (t) andˆgandˆ andˆg(t) = g(t), by construction.
Since ˆ h(t 0 ) h(t 0 ) = f (t 0 ) · g(t 0 ) = ˆ f (t 0 ) · ˆ g(t 0 ), it must be thatˆhthatˆ thatˆh(t 0 ) ˆ f (t 0 ) · ˆ g(t 0 ), sô h ˆ f · ˆ g. (Ben- Sasson et al.Step 3a: Polynomial identity test.
At the start of this step, each server i holdsshares [ ˆ f ] i , [ˆ g] i , and [ ˆ h] i of poly- nomialsˆfnomialsˆ nomialsˆf , ˆg, andˆhandˆ andˆh.
Furthermore, it holds thatˆfthatˆ thatˆf · ˆ g = ˆ h if and only if the servers collectively hold a set of wire value shares that, when summed up, equal the internal wire values of the Valid(x) circuit computation.The servers now execute the Schwartz-Zippel randomized polynomial identity test [104,126] to check whether this relation holds.
The principle of the test is that ifˆfifˆ ifˆf · ˆ g ˆ h, then the polynomiaî f · ˆ g − ˆ his a non-zero polynomial of degree at most 2M − 2.
Such a polynomial can have at most 2M − 2 zeros in F, so if we choose a random r ∈ F and evaluatê f (r) · ˆ g(r) − ˆ h(r), the servers will detect thatˆfthatˆ thatˆf · ˆ g ˆ h with probability at least 1 − 2M−2 |F| .
To execute the test, one of the servers samples a random value r ∈ F. Each server i then evaluates her share of each of the three polynomials on the point r to get [ ˆ f (r)] i , [ˆ g(r)] i , and [ ˆ h(r)] i .
The servers can perform this step locally, since polynomial evaluation requires only affine operations on shares.Assume for a moment that each server i can multiply her shares [ ˆ f (r)] i and [ˆ g(r)] i to produce a share [ ˆ f (r) · ˆ g(r)] i .
In this case, the servers can use a linear operation to get sharesσ i = [ ˆ f (r) · ˆ g(r) − ˆ h(r)] i .
The servers then publish these σ i s and ensure thati σ i = 0 ∈ F, which implies that ifˆfifˆ ifˆf (r) · ˆ g(r) = ˆ h(r).
The servers reject the client's submission if i σ i 0.
Step 3b: Multiplication of shares.
Finally, the servers must somehow multiply their shares [ ˆ f (r)] i and [ˆ g(r)] i to get a share [ ˆ f (r) · ˆ g(r)] i without leaking anything to each other about the valuesˆfvaluesˆ valuesˆf (r) andˆgandˆ andˆg(r).
To do so, we adapt a multi-party computation (MPC) technique of Beaver [9].
The details of Beaver's MPC protocol are not critical here, but we include them for reference in Appendix C.2.
Beaver's result implies that if servers receive, from a trusted dealer, one-time-use shares ([a] i , [b] i , [c] i ) ∈ F 3 of random values such that a · b = c ∈ F ("multiplication triples"), then the servers can very efficiently execute a multi-party multiplication of a pair secret-shared values.
Furthermore, the multiplication protocol is fast: it requires each server to broadcast a single message.In the traditional MPC setting, the parties to the computation have to run an expensive cryptographic protocol to generate the multiplication triples themselves [46].
In our setting however, the client generates the multiplication triple on behalf of the servers: the client chooses (a, b, c) ∈ F 3 such that a · b = c ∈ F, and sends shares of these values to each server.
If the client produces shares of these values correctly, then the servers can perform a multi-party multiplication of shares to complete the correctness check of the prior section.Crucially, even if the client sends shares of an invalid multiplication triple to the servers, the servers will still catch the cheating client with high probability.
To see why: say that a cheating client sends the servers shares([a] i , [b] i , [c] i ) ∈ F 3 such that a · b c ∈ F.
Then we can write a · b = (c + α) ∈ F, for some constant α > 0.
In this case, when the servers run Beaver's MPC multiplication protocol to execute the polynomial identity test, they will instead test whetherˆfwhetherˆ whetherˆf(r) · ˆ g(r) − ˆ h(r) + α = 0 ∈ F.(To confirm this, consult our summary of Beaver's protocol in Appendix C.2.)
Since we only require soundness to hold if all servers are honest, we may assume that the client did not know the servers' random value r when the client generated its multiplication triple.
This implies that r is distributed independently of α, and since we only require soundness to hold if the servers are honest, we may assume that r is sampled uniformly from F as well.So, even if the client cheats, the servers will still be executing the polynomial identity test on a non-zero polynomial of degree at most (2M − 2).
The servers will thus catch a cheating client with probability at least 1 − 2M−2 |F| .
Step 4: Output verification.
If all servers are honest, at the start of the final step of the protocol, each server i will hold a set of shares of the values that the Valid circuit takes on during computation of Valid(x):([w 1 ] i , [w 2 ] i , . . . ).
The servers already hold shares of the input wires of this circuit ( [x] i ), so to confirm that Valid(x) = 1, the servers need only publish their shares of the output wire.
When they do, the servers can sum up these shares to confirm that the value on the output wire is equal to one, in which case it must be that Valid(x) = 1, except with some small failure probability due to the polynomial identity test.
The correctness of the scheme follows by construction.
To trick the servers into accepting a malformed submission, a cheating client must subvert the polynomial identity test.
This bad event has probability at most (2M −2)/|F|, where M is the number of multiplication gates in Valid(·).
By taking |F| ≈ 2 128 , or repeating Step 3 a few times, we can make this failure probability extremely small.
We require neither completeness nor soundness to hold in the presence of malicious servers, though we do require soundness against malicious clients.
A malicious server can thus trick the honest servers into rejecting a wellformed client submission that they should have accepted.
This is tantamount to the malicious server mounting a selective denial-of-service attack against the honest client.
We discuss this attack in Section 7.
NIZK SNARK Prio (SNIP) Client Exps.
M M 0 Muls.
0 M log M M log M Proof len.
M 1 M Servers Exps.
/Pairs.
M 1 0 Muls.
0 M M log M Data transfer M 1 1As long as there is at least one honest server, the properties of the secret sharing scheme guarantee that the dishonest servers gain no information-in an unconditional, information-theoretic sense-about the client's data values nor about the values on the internal wires in the Valid(x) circuit.
Beaver's analysis [9] guarantees that the multiplication step leaks no information to the servers.Efficiency.
The remarkable property of this SNIP construction is that the server-to-server communication cost grows neither with the complexity of the verification circuit nor with the size of the value x (Table 2).
The computation cost at the servers is essentially the same as the cost for each server to evaluate the Valid circuit locally.That said, the client-to-server communication cost does grow linearly with the size of the Valid circuit.
An interesting challenge would be to try to reduce the client's bandwidth usage without resorting to relatively expensive public-key cryptographic techniques [17,18,26,41,97].
Constructing the SNIP proof requires the client to compute Valid(x) on its own.
If the verification circuit takes secret server-provided values as input, or is itself a secret belonging to the servers, then the client does not have enough information to compute Valid(x).
For example, the servers could run a proprietary verification algorithm to detect spammy client submissions-the servers would want to run this algorithm without revealing it to the (possibly spam-producing) clients.
To handle this use case, the servers can execute the verification check themselves at a slightly higher cost.
See Appendix D for details.
So far, we have developed the means to compute private sums over client-provided data (Section 3) and to check an arbitrary validation predicate against secret-shared data (Section 4).
Combining these two ideas with careful data encodings, which we introduce now, allows Prio to compute more sophisticated statistics over private client data.At a high level, each client first encodes its private data value in a prescribed way, and the servers then privately compute the sum of the encodings.
Finally, the servers can decode the summed encodings to recover the statistic of interest.
The participants perform this encoding and decoding via a mechanism we call affine-aggregatable encodings ("AFEs").
In our setting, each client i holds a value x i ∈ D, where D is some set of data values.
The servers hold an aggregation function f : D n → A, whose range is a set of aggregates A. For example, the function f might compute the standard deviation of its n inputs.
The servers' goal is to evaluate f (x 1 , . . . , x n ) without learning the x i s.An AFE gives an efficient way to encode the data values x i such that it is possible to compute the value f (x 1 , . . . , x n ) given only the sum of the encodings of x 1 , . . . , x n .
An AFE consists of three efficient algorithms (Encode, Valid, Decode), defined with respect to a field F and two integers k and k , where k ≤ k:• Encode(x): maps an input x ∈ D to its encoding in F k , • Valid(y): returns true if and only if y ∈ F k is a valid encoding of some data item in D,• Decode(σ): takes σ = n i=1 Trunc k Encode(x i )∈ F k as input, and outputs f (x 1 , . . . , x n ).
The Trunc k (·) function outputs the first k ≤ k components of its input.
The AFE uses all k components of the encoding in validation, but only uses k components to decode σ.
In many of our applications we have k = k.An AFE is private with respect to a functionˆffunctionˆ functionˆf , or simplyˆfplyˆ plyˆf -private, if σ reveals nothing about x 1 , . . . , x n beyond whatˆfwhatˆ whatˆf (x 1 , . . . , x n ) itself reveals.
More precisely, it is possible to efficiently simulate σ given onlyˆfonlyˆ onlyˆf (x 1 , . . . , x n ).
UsuallyˆfUsuallyˆ Usuallyˆf reveals nothing more than the aggregation function f (i.e., the minimum leakage possible), but in some casesˆfcasesˆ casesˆf reveals a little more than f .
For some functions f we can build more efficient fprivate AFEs by allowing the encoding algorithm to be randomized.
In these cases, we allow the decoding algorithm to return an answer that is only an approximation of f , and we also allow it to fail with some small probability.Prior systems have made use of specific AFEs for sums [56,86], standard deviations [100], counts [28,92], and least-squares regression [82].
Our contribution is to unify these notions and to adopt existing AFEs to enable better composition with Prio's SNIPs.
In particular, by using more complex encodings, we can reduce the size of the circuit for Valid, which results in shorter SNIP proofs.AFEs in Prio: Putting it all together.
The full Prio system computes f (x 1 , . . . , x n ) privately as follows (see Figure 1): Each client encodes its data value x using the AFE Encode routine for the aggregation function f .
Then, as in the simple scheme of Section 3, every client splits its encoding into s shares and sends one share to each of the s servers.
The client uses a SNIP proof (Section 4) to convince the servers that its encoding satisfies the AFE Valid predicate.Upon receiving a client's submission, the servers verify the SNIP to ensure that the encoding is well-formed.
If the servers conclude that the encoding is valid, every server adds the first k components of the encoding share to its local running accumulator.
(Recall that k is a parameter of the AFE scheme.)
Finally, after collecting valid submissions from many clients, every server publishes its local accumulator, enabling anyone to run the AFE Decode routine to compute the final statistic in the clear.
The formal description of the system is presented in Appendix G, where we also analyze its security.Limitations.
There exist aggregation functions for which all AFE constructions must have large encodings.
For instance, say that each of n clients holds an integer x i , where 1 ≤ x i ≤ n.
We might like an AFE that computes the median of these integers {x 1 , . . . , x n }, working over a field F with |F| ≈ n d , for some constant d ≥ 1.
We show that there is no such AFE whose encodings consist of k ∈ o(n/ log n) field elements.
Suppose, towards a contradiction, that such an AFE did exist.
Then we could describe any sum of encodings using at most O(k log |F|) = o(n) bits of information.
From this AFE, we could build a single-pass, space-o(n) streaming algorithm for computing the exact median of an n-item stream.
But every single-pass streaming algorithm for computing the exact median over an n-item stream requires Ω(n) bits of space [74], which is a contradiction.
Similar arguments may rule out space-efficient AFE constructions for other natural functions.
This section presents the basic affine-aggregatable encoding schemes that serve as building blocks for the more sophisticated schemes.
In the following constructions, the clients hold data values x 1 , . . . , x n ∈ D, and our goal is to compute an aggregate f (x 1 , . . . , x n ).
In constructing these encodings, we have two goals.
The first is to ensure that the AFE leaks as little as possible about the x i s, apart from the value f (x 1 , . . . , x n ) itself.
The second is to minimize the number of multiplication gates in the arithmetic circuit for Valid, since the cost of the SNIPs grows with this quantity.In what follows, we let λ be a security parameter, such as λ = 80 or λ = 128.
Integer sum and mean.
We first construct an AFE for computing the sum of b-bit integers.
Let F be a finite field of size at least n2 b .
On input 0 ≤ x ≤ 2 b − 1, the Encode(x) algorithm first computes the bit representation of x, denoted (β 0 , β 1 , . . . , β b−1 ) ∈ {0, 1} b .
It then treats the binary digits as elements of F, and outputsEncode(x) = (x, β 0 , . . . , β b−1 ) ∈ F b+1 .
To check that x represents a b-bit integer, the Valid algorithm ensures that each β i is a bit, and that the bits represent x. Specifically, the algorithm checks that the following equalities hold over F:Valid(Encode(x)) = x = b−1 i=0 2 i β i ∧ n i=1 (β i − 1) · β i = 0 .
The Decode algorithm takes the sum of encodings σ as input, truncated to only the first coordinate.
That is,σ = n i=1 Trunc 1 Encode(x 1 ) = x 1 + · · · + x n .
This σ is the required aggregate output.
Moreover, this AFE is clearly sum-private.
To compute the arithmetic mean, we divide the sum of integers by n over the rationals.
Computing the product and geometric mean works in exactly the same matter, except that we encode x using b-bit logarithms.Variance and stddev.
Using known techniques [30,100], the summation AFE above lets us compute the variance of a set of b-bit integers using the identity: 2 .
Each client encodes its integer x as (x, x 2 ) and then applies the summation AFE to each of the two components.
(The Valid algorithm also ensures that second integer is the square of the first.)
The resulting two values let us compute the variance.Var(X) = E[X 2 ] − (E[X])This AFE also reveals the expectation E [X].
It is private with respect to the functionˆffunctionˆ functionˆf that outputs both the expectation and variance of the given set of integers.Boolean or and and.
When D = {0, 1} and f (x 1 , . . . , x n ) = or(x 1 , . . . , x n ) the encoding operation outputs an element of F λ 2 (i.e., a λ-bit bitstring) as:Encode(x) =        λ zeros if x = 0 a random element in F λ 2 if x = 1.
The Valid algorithm outputs "1" always, since all λ-bit encodings are valid.
The sum of encodings is simply the xor of the n λ-bit encodings.
The Decode algorithm takes as input a λ-bit string and outputs "0" if and only if its input is a λ-bit string of zeros.
With probability 1 − 2 −λ , over the randomness of the encoding algorithm, the decoding operation returns the boolean or of the encoded values.
This AFE is or-private.
A similar construction yields an AFE for boolean and.
Let F be a field of size at least n.
The Encode algorithm encodes a value x ∈ D as a length-B vector (β 0 , . . . , β B−1 ) ∈ F B where β i = 1 if x = i and β i = 0 otherwise.
The Valid algorithm checks that each β value is in the set {0, 1} and that the sum of the βs is exactly one.
The Decode algorithm does nothing: the final output is a length-B vector, whose ith component gives the number of clients who took on value i. Again, this AFE is private with respect to the function being computed.The output of this AFE yields enough information to compute other useful functions (e.g., quantiles) of the distribution of the clients' x values.
When the domain D is large, this AFE is very inefficient.
In Appendix F, we give AFEs for approximate counts over large domains.Sets.
We can compute the intersection or union of sets over a small universe of elements using the boolean AFE operations: represent a set of B items as its characteristic vector of booleans, and compute an and for intersection and an or for union.
When the universe is large, the Table 3: Time in seconds for a client to generate a Prio submission of L four-bit integers to be summed at the servers.
Averaged over eight runs.
We can use Prio for training machine learning models on private client data.
To do so, we exploit the observation of Karr et al.[82] that a system for computing private sums can also privately train linear models.
(In Appendix F, we also show how to use Prio to privately evaluate the R 2 -coefficient of an existing model.)
In Prio, we extend their work by showing how to perform these tasks while maintaining robustness against malicious clients.
Suppose that every client holds a data point (x, y) where x and y are b-bit integers.
We would like to train a model that takes x as input and outputs a real-valued predictionˆy predictionˆ predictionˆy i = M(x) ∈ R of y.
We might predict a person's blood pressure (y) from the number of steps they walk daily (x).
We wish to compute the least-squares linear fit h(x) = c 0 + c 1 x over all of the client points.
With n clients, the model coefficients c 0 and c 1 satisfy the linear relation:       n n i=1 x i n i=1 x i n i=1 x 2 i        ·        c 0 c 1        =        n i=1 y i n i=1 x i y i       (1)To compute this linear system in an AFE, every client encodes her private point (x, y) as a vector(x, x 2 , y, xy, β 0 , . . . , β b−1 , γ 0 , . . . , γ b−1 ) ∈ F 2b+4 ,where (β 0 , . . . , β b−1 ) is the binary representation of x and (γ 0 , . . . , γ b−1 ) is the binary representation of y.
The validation algorithm checks that all the β and γ are in {0, 1}, and that all the arithmetic relations hold, analogously to the validation check for the integer summation AFE.
Finally, the decoding algorithm takes as input the sum of the encoded vectors truncated to the first four components:σ = n i=1 x, n i=1 x 2 , n i=1 y, n i=1 xy ,from which the decoding algorithm computes the required real regression coefficients c 0 and c 1 using (1).
This AFE is private with respect to the function that outputs the least-squares fit h(x) = c 0 + c 1 x, along with the mean and variance of the set {x 1 , . . . , x n }.
When x and y are real numbers, we can embed the reals into a finite field F using a fixed-point representation, as long as we size the field large enough to avoid overflow.The two-dimensional approach above generalizes directly to perform linear regression on d-dimensional feature vectors ¯ x = (x (1) , . . . , x (d) ).
The AFE yields a leastsquares approximation of the form h( ¯ x) = c 0 +c 1 x (1) +· · ·+ c d x (d) .
The resulting AFE is private with respect to a function that reveals the least-square coefficients (c 0 , . . . , c d ), along with the d × d covariance matrix i ¯ x i · ( ¯ x i ) T .
In this section, we demonstrate that Prio's theoretical contributions translate into practical performance gains.
We have implemented a Prio prototype in 5,700 lines of Go and 620 lines of C (for FFT-based polynomial operations, built on the FLINT library [59]).
Unless noted otherwise, our evaluations use an FFT-friendly 87-bit field.
Our servers communicate with each other using Go's TLS implementation.
Clients encrypt and sign their messages to servers using NaCl's "box" primitive, which obviates the need for client-to-server TLS connections.
Our code is available online at https://crypto.stanford.edu/prio/.
We evaluate the SNIP-based variant of Prio (Section 4.1) and also the variant in which the servers keep the Valid predicate private ("Prio-MPC," Section 4.4).
Our implementation includes three optimizations described in Appendix H.
The first uses a pseudo-random generator (e.g., AES in counter mode) to reduce the client-to-server data transfer by a factor of roughly s in an s-server deployment.
The second optimization allows the servers to verify SNIPs without needing to perform expensive polynomial interpolations.
The third optimization gives an efficient way for the servers to compute the logical-and of multiple arithmetic circuits to check that multiple Valid predicates hold simultaneously.We compare Prio against a private aggregation scheme that uses non-interactive zero-knowledge proofs (NIZKs) to provide robustness.
This protocol is similar to the "cryptographically verifiable" interactive protocol of Kursawe et al. [86] and has roughly the same cost, in terms of exponentiations per client request, as the "distributed decryption" variant of PrivEx [56].
We implement the NIZK scheme using a Go wrapper of OpenSSL's NIST P256 code [50].
We do not compare Prio against systems, such as ANONIZE [76] and PrivStats [100], that rely on an external anonymizing proxy to protect against a network adversary.
(We discuss this related work in Section 8.)
Figure 4: Prio provides the robustness guarantees of zero-knowledge proofs but at 20-50× less cost.
the client time is roughly 0.03 seconds on a workstation, and just over 0.1 seconds on a mobile phone.
To investigate the load that Prio places on the servers, we configured five Amazon EC2 servers (eight-core c3.2xlarge machines, Intel Xeon E5-2680 CPUs) in five Amazon data centers (N. Va., N. Ca., Oregon, Ireland, and Frankfurt) and had them run the Prio protocols.
An additional three c3.2xlarge machines in the N. Va. data center simulated a large number of Prio clients.
To maximize the load on the servers, we had each client send a stream of pre-generated Prio data packets to the servers over a single TCP connection.
There is no need to use TLS on the client-to-server Prio connection because Prio packets are encrypted and authenticated at the application layer and can be replay-protected at the servers.
Figure 4 gives the throughput of this cluster in which each client submits a vector of zero/one integers and the servers sum these vectors.
The "No privacy" line on the chart gives the throughput for a dummy scheme in which a single server accepts encrypted client data submissions directly from the clients with no privacy protection whatsoever.
The "No robustness" line on the chart gives the throughput for a cluster of five servers that use a secret-sharing-based private aggregation scheme (à la Section 3) with no robustness protection.
The five-server "No robustness" scheme is slower than the single-server "No privacy" scheme because of the cost of coordinating the processing of submissions amongst the five servers.
The throughput of Prio is within a factor of 5× of the no-privacy scheme for many submission sizes, and Prio outperforms the NIZK-based scheme by more than an order of magnitude.Finally, Figure 5 shows how the throughput of a Prio cluster changes as the number of servers increases, when the system is collecting the sum of 1,024 one-bit clientsubmitted integers, as in an anonymous survey application.
For this experiment, we locate all of the servers in the same data center, so that the latency and bandwidth between each pair of servers is roughly constant.
With more servers, an adversary has to compromise a larger number of machines to violate Prio's privacy guarantees.Adding more servers barely affects the system's throughput.
The reason is that we are able to load-balance the bulk of the work of checking client submissions across all of the servers.
(This optimization is only possible because we require robustness to hold only if all servers are honest.)
We assign a single Prio server to be the "leader" that coordinates the checking of each client data submission.
In processing a single submission in an s-server cluster, the leader transmits s times more bits than a nonleader, but as the number of servers increases, each server is a leader for a smaller share of incoming submissions.
The NIZK-based scheme also scales well: as the number of servers increases, the heavy computational load of checking the NIZKs is distributed over more machines.
Figure 6 shows the number of bytes each non-leader Prio server needs to transmit to check the validity of a single client submission for the two Prio variants, and for the NIZK scheme.
The benefit of Prio is evident: the Prio servers transmit a constant number of bits per submission-independent of the size of the submission or complexity of the Valid routine.
As the submitted vectors grow, Prio yields a 4,000-fold bandwidth saving over NIZKs, in terms of server data transfer.
To demonstrate that Prio's data types are expressive enough to collect real-world aggregates, we have configured Prio for a few potential application domains.Cell signal strength.
A collection of Prio servers can collect the average mobile signal strength in each grid cell in a city without leaking the user's location history to the aggregator.
We divide the geographic area into a km 2 grid-the number of grid cells depends on the city's sizeand we encode the signal strength at the user's present location as a four-bit integer.
(If each client only submits signal-strength data for a few grid cells in each protocol run, extra optimizations can reduce the client-to-server data transfer.
See "Share compression" in Appendix F.) Figure 7: Client encoding time for different application domains when using Prio, a non-interactive zero-knowledge system (NIZK), or a SNARK-like system (estimated).
Averaged over eight runs.
The number of × gates in the Valid circuit is listed in parentheses.Browser statistics.
The Chromium browser uses the RAPPOR system to gather private information about its users [35,57].
We implement a Prio instance for gathering a subset of these statistics: average CPU and memory usage, along with the frequency counts of 16 URL roots.
For collecting the approximate counts, we use the count-min sketch structure, described in Appendix F.
We experiment with both low-and high-resolution parameters (δ = 2 −10 , = 1/10; δ = 2 −20 , = 1/100).
Health data modeling.
We implement the AFE for training a regression model on private client data.
We use the features from a preexisting heart disease data set (13 features of varying types: age, sex, cholesterol level, etc.) [78] and a breast cancer diagnosis data set (30 realvalued features using 14-bit fixed-point numbers) [120].
Anonymous surveys.
We configure Prio to compute aggregates responses to sensitive surveys: we use the Beck Depression Inventory (21 questions on a 1-4 scale) [6], the Parent-Child Relationship Inventory (78 questions on a 1-4 scale) [63], and the California Psychological Inventory (434 boolean questions) [42].
Comparison to alternatives.
In Figure 7, we compare the computational cost Prio places on the client to the costs of other schemes for protecting robustness against misbehaving clients, when we configure the system for the aforementioned applications.
The fact that a Prio client need only perform a single public-key encryption means that it dramatically outperforms schemes based on public-key cryptography.
If the Valid circuit has M multiplication gates, producing a discrete-log-based NIZK requires the client to perform 2M exponentiations (or elliptic-curve point multiplications).
In contrast, Prio requires O(M log M) multiplications in a relatively small field, which is much cheaper for practical values of M.In Figure 7, we give conservative estimates of the time required to generate a zkSNARK proof, based on timings of libsnark's [18] implementation of the Pinocchio system [97] at the 128-bit security level.
These proofs have the benefit of being very short: 288 bytes, irrespective of the complexity of the circuit.
To realize the benefit of these succinct proofs, the statement being proved must also be concise since the verifier's running time grows with the statement size.
To achieve this conciseness in the Prio setting would require computing sL hashes "inside the SNARK," with s servers and submissions of length L.We optimistically estimate that each hash computation requires only 300 multiplication gates, using a subset-sum hash function [2,17,67,77], and we ignore the cost of computing the Valid circuit in the SNARK.
We then use the timings from the libsnark paper to arrive at the cost estimates.
Each SNARK multiplication gate requires the client to compute a number of exponentiations, so the cost to the client is large, though the proof is admirably short.
Finally, we perform an end-to-end evaluation of Prio when the system is configured to train a d-dimensional leastsquares regression model on private client-submitted data, in which each training example consists of a vector of 14-bit integers.
These integers are large enough to represent vital health information, for example.In Figure 8, we show the client encoding cost for Prio, along with the no-privacy and no-robustness schemes described in Section 6.1.
The cost of Prio's privacy and robustness guarantees amounts to roughly a 50× slowdown at the client over the no-privacy scheme due to the overhead of the SNIP proof generation.
Even so, the absolute cost of Prio to the client is small-on the order of one tenth of a second.
Table 9 gives the rate at which the globally distributed five-server cluster described in Section 6.1 can process client submissions with and without privacy and robustness.
The server-side cost of Prio is modest: only a 1-2× slowdown over the no-robustness scheme, and only a 5-15× slowdown over a scheme with no privacy at all.
In contrast, the cost of robustness for the state-of-the-art NIZK schemes, per Figure 4, is closer to 100-200×.
Table 9: The throughput, in client requests per second, of a global fiveserver cluster running a private d-dim.
regression.
We compare a scheme with no privacy, with privacy but no robustness, and Prio (with both).
Deployment scenarios.
Prio ensures client privacy as long as at least one server behaves honestly.
We now discuss a number of deployment scenarios in which this assumption aligns with real-world incentives.Tolerance to compromise.
Prio lets an organization compute aggregate data about its clients without ever storing client data in a single vulnerable location.
The organization could run all s Prio servers itself, which would ensures data privacy against an attacker who compromises up to s − 1 servers.App store.
A mobile application platform (e.g., Apple's App Store or Google's Play) can run one Prio server, and the developer of a mobile app can run the second Prio server.
This allows the app developer to collect aggregate user data without having to bear the risks of holding these data in the clear.
Private compute services.
A large enterprise can contract with an external auditor or a non-profit (e.g., the Electronic Frontier Foundation) to jointly compute aggregate statistics over sensitive customer data using Prio.Jurisdictional diversity.
A multinational organization can spread its Prio servers across different countries.
If law enforcement agents seize the Prio servers in one country, they cannot deanonymize the organization's Prio users.Common attacks.
Two general attacks apply to all systems, like Prio, that produce exact (un-noised) outputs while protecting privacy against a network adversary.
The first attack is a selective denial-of-service attack.In this attack, the network adversary prevents all honest clients except one from being able to contact the Prio servers [105].
In this case, the protocol output is f (x honest , x evil 1 , . . . , x evil n ).
Since the adversary knows the x evil values, the adversary could infer part or all of the one honest client's private value x honest .
In Prio, we deploy the standard defense against this attack, which is to have the servers wait to publish the aggregate statistic f (x 1 , . . . , x n ) until they are confident that the aggregate includes values from many honest clients.
The best means to accomplish this will depend on the deployment setting.One way is to have the servers keep a list of public keys of registered clients (e.g., the students enrolled at a university).
Prio clients sign their submissions with the signing key corresponding to their registered public key and the servers wait to publish their accumulator values until a threshold number of registered clients have submitted valid messages.
Standard defenses [3,114,124,125] against Sybil attacks [52] would apply here.The second attack is an intersection attack [20,49,83,122].
In this attack, the adversary observes the output f (x 1 , . . . , x n ) of a run of the Prio protocol with n honest clients.
The adversary then forces the nth honest client offline and observes a subsequent protocol run, in which the servers compute f (x 1 , . . . , x n−1 ).
If the clients' values are constant over time (x i = x i ), then the adversary learns the difference f (x 1 , . . . , x n )− f (x 1 , . . . , x n−1 ), which could reveal client n's private value x n (e.g., if f computes sum).
One way for the servers to defend against the attack is to add differential privacy noise to the results before publishing them [54].
Using existing techniques, the servers can add this noise in a distributed fashion to ensure that as long as at least one server is honest, no server sees the un-noised aggregate [55].
The definition of differential privacy ensures that computed statistics are distributed approximately the same whether or not the aggregate includes a particular client's data.
This same approach is also used in a system by Melis, Danezis, and De Cristofaro [92], which we discuss in Section 8.
Robustness against malicious servers.
Prio only provides robustness when all servers are honest.
Providing robustness in the face of faulty servers is obviously desirable, but we are not convinced that it is worth the security and performance costs.
Briefly, providing robustness necessarily weakens the privacy guarantees that the system provides: if the system protects robustness in the presence of k faulty servers, then the system can protect privacy (a) RAPPOR [57] provides differential privacy [54] (not information-theoretic privacy) by adding random noise to client submissions.
(b) ANONIZE [76] and PrivStats [100] rely on an anonymizing proxy, such as Tor [51], to protect privacy against network eavesdroppers.
(c) Prio and other schemes using secret sharing [30,48,56,79,86,92] offer ideal anonymity provided that the servers do not collude.
only against a coalition of at most s − k − 1 malicious servers.
We discuss this issue further in Appendix B. Private data-collection systems [30,48,53,56,79,86,92] that use secret-sharing based methods to compute sums over private user data typically (a) provide no robustness guarantees in the face of malicious clients, (b) use expensive NIZKs to prevent client misbehavior, or (c) fail to defend privacy against actively malicious servers [33].
Other data-collection systems have clients send their private data to an aggregator through a general-purpose anonymizing network, such as a mix-net [27,32,47,87] or a DC-net [31,[38][39][40]110].
These anonymity systems provide strong privacy properties, but require expensive "verifiable mixing" techniques [8,95], or require work at the servers that is quadratic in the number of client messages sent through the system [38,121].
PrivStats [100] and ANONIZE [76] outsource to Tor [51] (or another low-latency anonymity system [61,88,101]) the work of protecting privacy against a network adversary ( Figure 10).
Prio protects against an adversary that can see and control the entire network, while Torbased schemes succumb to traffic-analysis attacks [94].
In data-collection systems based on differential privacy [54], the client adds structured noise to its private value before sending it to an aggregating server.
The added noise gives the client "plausible deniability:" if the client sends a value x to the servers, x could be the client's true private value, or it could be an unrelated value generated from the noise.
Dwork et al. [55], Shi et al. [107], and Bassily and Smith [7] study this technique in a distributed setting, and the RAPPOR system [57,58], deployed in Chromium, has put this idea into practice.
A variant of the same principle is to have a trusted proxy (as in SuLQ [21] and PDDP [34]) or a set of minimally trusted servers [92] add noise to already-collected data.The downside of these systems is that (a) if the client adds little noise, then the system does not provide much privacy, or (b) if the client adds a lot of noise, then lowfrequency events may be lost in the noise [57].
Using server-added noise [92] ameliorates these problems.In theory, secure multi-party computation (MPC) protocols [11,15,68,90,123] allow a set of servers, with some non-collusion assumptions, to privately compute any function over client-provided values.
The generality of MPC comes with serious bandwidth and computational costs: evaluating the relatively simple AES circuit in an MPC requires the parties to perform many minutes or even hours of precomputation [44].
Computing a function f on millions of client inputs, as our five-server Prio deployment can do in tens of minutes, could potentially take an astronomical amount of time in a full MPC.
That said, there have been great advances in practical general-purpose MPC protocols of late [12,13,23,45,46,73,89,91,93,98].
General-purpose MPC may yet become practical for computing certain aggregation functions that Prio cannot (e.g., exact max), and some special-case MPC protocols [4,29,96] are practical today for certain applications.
Prio allows a set of servers to compute aggregate statistics over client-provided data while maintaining client privacy, defending against client misbehavior, and performing nearly as well as data-collection platforms that exhibit neither of these security properties.
The core idea behind Prio is reminiscent of techniques used in verifiable computation [16,37,62,69,97,115,116,119], but in reverse-the client proves to a set of servers that it computed a function correctly.
One question for future work is whether it is possible to efficiently extend Prio to support combining client encodings using a more general function than summation, and what more powerful aggregation functions this would enable.
Another task is to investigate the possiblity of shorter SNIP proofs: ours grow linearly in the size of the Valid circuit, but sublinear-size information-theoretic SNIPs may be feasible.
We use the standard definitions of negligible functions and computational indistinguishability.
Goldreich [66] gives a formal treatment of these concepts.
For clarity, we often prefer to leave the security parameter implicit.It is possible to make our notion of privacy formal with a simulation-based definition.
The following informal definition captures the essence of the full formalism:Definition 1 ( f -Privacy).
Say that there are s servers and n clients in a Prio deployment.
We say that the scheme provides f -privacy for a function f , if for:• every subset of at most s − 1 servers, and • every subset of at most n clients, there exists an efficient simulator that, for every choice of client inputs (x 1 , . . . , x n ), takes as input:• the public parameters to the protocol run (all participants' public keys, the description of the aggregation function f , the cryptographic parameters, etc.), • the indices of the adversarial clients and servers, • oracle access to the adversarial participants, and • the value f (x 1 , . . . , x n ), and outputs a simulation of the adversarial participants' view of the protocol run whose distribution is computationally indistinguishable from the distribution of the adversary's view of the real protocol run.Let SORT be the function that takes n inputs and outputs them in lexicographically increasing order.Definition 2 (Anonymity).
We say that a data-collection scheme provides anonymity if it provides f -privacy, in the sense of Definition 1, for f = SORT.A scheme that provides this form of anonymity leaks to the adversary the entire list of client inputs (x 1 , . . . , x n ), but the adversary learns nothing about which client submitted which value x i .
For example, if each client submits their location via a data-collection scheme that provides anonymity, the servers learn the list of submitted locations { 1 , . . . , n }, but the servers learn nothing about whether client x or y is in a particular location * .
Definition 3.
A function f (x 1 , . . . , x n ) is symmetric if, for all permutations π on n elements, the equality f (x 1 , . . . , x n ) = f (x π(1) , . . . , x π(n) ) holds.Claim 4.
Let D be a data-collection scheme that provides f -privacy, in the sense of Definition 1, for a symmetric function f .
Then D provides anonymity.Proof sketch.
The fact that D provides f -privacy implies the existence of a simulator S D that takes as input f (x 1 , . . . , x n ), along with other public values, and induces a distribution of protocol transcripts indistinguishable from the real one.
If f is symmetric, f (x 1 , . . . ,x n ) = f (x 1 , . . . , x n ), where (x 1 , . . . , x n ) = SORT(x 1 , . . . , x n ).
Using this fact, we construct the simulator required for the anonymity definition: on input (x 1 , . . . , x n ) = SORT(x 1 , . . . , x n ), compute f (x 1 , . . . , x n ), and feed the output of f to the simulator S D .
The validity of the simulation is immediate.The following claim demonstrates that it really only makes sense to use an f -private data collection scheme when the function f is symmetric, as all of the functions we consider in Prio are.Claim 5.
Let f be a non-symmetric function.
Then there is no anonymous data collection scheme that correctly computes f .
Proof sketch.
Because f is not symmetric, there exists an input (x 1 , . . . , x n ) in the domain of f , and a permutation π on n elements, such that f (x 1 , . . . , x n ) f (x π(1) , . . . , x π(n) ).
Let D be a data-collection scheme that implements the aggregation function f (x 1 , . . . , x n ).
This D outputs f (x 1 , . . . , x n ) for all x 1 , . . . , x n in the domain, and hence f (x 1 , . . . , x n ) is part of the protocol transcript.For D to be anonymous, there must be a simulator that takes SORT(x 1 , . . . , x n ) as input, and simulates the protocol transcript.
In particular, it must output f (x 1 , . . . , x n ).
But given SORT(x 1 , . . . , x n ), it will necessarily fail to output the correct protocol transcript on either (x 1 , . . . , x n ) or (x π(1) , . . . , x π(n) ).
x i , where the value x i is an element of some set of data items D. For example, D might be the set of 4-bit integers.
The definition of robustness states that when all servers are honest, a set of malicious clients cannot influence the final aggregate, beyond their ability to choose arbitrary valid inputs.
For example, malicious clients can choose arbitrary 4-bit integers as their input values, but cannot influence the output in any other way.Definition 6 (Robustness).
Fix a security parameter λ > 0.
We say that an n-client Prio deployment provides robustness if, when all Prio servers execute the protocol faithfully, for every number m of malicious clients (with 0 ≤ m ≤ n), and for every choice of honest client's inputs (x 1 , . . . , x n−m ) ∈ D n−m , the servers, with all but negligible probability in λ, output a value in the set:f (x 1 , . . . , x n ) | (x n−m+1 , . . . , x n ) ∈ D m .
If at least one of the servers is honest, Prio ensures that the adversary learns nothing about clients' data, except the aggregate statistic.
However, Prio provides robustness only if all servers are honest.
Providing robustness in the face of faulty servers is obviously desirable, but we are not convinced that it is worth the security and performance costs.
First, providing robustness necessarily weakens the privacy guarantees that the system provides: if the system protects robustness in the presence of k faulty servers, then the system can protect privacy only against a coalition of at most s − k − 1 malicious servers.
The reason is that, if robustness holds against k faulty servers, then s − k honest servers must be able to produce a correct output even if these k faulty servers are offline.
Put another way: s − k dishonest servers can recover the output of the system even without the participation of the k honest servers.
Instead of computing an aggregate over many clients ( f (x 1 , . . . , x n )), the dishonest servers can compute the "aggregate" over a single client's submission ( f (x 1 )) and essentially learn that client's private data value.So strengthening robustness in this setting weakens privacy.
Second, protecting robustness comes at a performance cost: some our optimizations use a "leader" server to coordinate the processing of each client submission (see Appendix H).
A faulty leader cannot compromise privacy, but can compromise robustness.
Strengthening the robustness property would force us to abandon these optimizations.That said, it would be possible to extend Prio to provide robustness in the presence of corrupt servers using standard techniques [10] (replace s-out-of-s secret sharing with Shamir's threshold secret-sharing scheme [106], etc.).
This appendix reviews the definition of arithmetic circuits and Donald Beaver's multi-party computation protocol [9].
An arithmetic circuit C over a finite field F takes as input a vector x = x (1) , . . . , x (L) ∈ F L and produces a single field element as output.
We represent the circuit as a directed acyclic graph, in which each vertex in the graph is either an input, a gate, or an output vertex.Input vertices have in-degree zero and are labeled with a variable in {x (1) , . . . , x (L) } or a constant in F. Gate vertices have in-degree two and are labeled with the operation + or ×.
The circuit has a single output vertex, which has out-degree zero.To compute the circuit C(x) = C(x (1) , . . . , x (L) ), we walk through the circuit from inputs to outputs, assigning a value in F to each wire until we have a value on the output wire, which is the value of C(x).
In this way, the circuit implements a mapping C : F L → F.
This discussion draws on the clear exposition by Smart [111].
Each server starts the protocol holding a share [x] i of an input vector x.
The servers want to compute C(x), for some arithmetic circuit C.The multi-party computation protocol walks through the circuit C wire by wire, from inputs to outputs.
The protocol maintains the invariant that, at the t-th time step, each server holds a share of the value on the t-th wire in the circuit.
At the first step, the servers hold shares of the input wires (by construction) and in the last step of the protocol, the servers hold shares of the output wire.
The servers can then publish their shares of the output wires, which allows them all to reconstruct the value of C(x).
To preserve privacy, no subset of the servers must ever have enough information to recover the value on any internal wire in the circuit.There are only two types of gates in an arithmetic circuit (addition gates and multiplication gates), so we just have to show how the servers can compute the shares of the outputs of these gates from shares of the inputs.
All arithmetic in this section is in a finite field F.Addition gates.
In the computation of an addition gate "y + z", the ith server holds shares [y] i and [z] i of the input wires and the server needs to compute a share of y + z. To do so, the server can just add its shares locally [y + z] i = [y] i + [z] i .
Multiplication gates.
In the computation of a multiplication gate, the ith server holds shares [y] i and [z] i and wants to compute a share of yz.When one of the inputs to a multiplication gate is a constant, each server can locally compute a share of the output of the gate.
For example, to multiply a share [y] i by a constant A ∈ F, each server i computes their share of the product as [Ay] i = A[y i ].
Beaver showed that the servers can use pre-computed multiplication triples to evaluate multiplication gates [9].
A multiplication triple is a one-time-use triple of values (a, b, c) ∈ F 3 , chosen at random subject to the constraint that a · b = c ∈ F.
When used in the context of multi-party computation, each server i holds a share ([a] Recall that s is the number of servers-a public constantand the division symbol here indicates division (i.e., inversion then multiplication) in the field F.
A few lines of arithmetic confirm that σ i is a sharing of the product yz.
To prove this we compute: The last step used that c = ab (by construction of the multiplication triple), so: i σ i = yz, which implies thati , [b] i , [c] i ) ∈Fσ i = [yz] i .
Since the servers can perform addition and multiplication of shared values, they can compute any function of the client's data value in this way, as long as they have a way of securely generating multiplication triples.
The expensive part of traditional MPC protocols is the process by which mutually distrusting servers generate these triples in a distributed way.
If the Valid predicate takes secret inputs from the servers, the servers can compute Valid(x) on a client-provided input x without learning anything about x, except the value of Valid(x).
In addition, the client learns nothing about the Valid circuit, except the number of multiplication gates in the circuit.Let M be the number of multiplication gates in the Valid circuit.
To execute the Valid computation on the server side, the client sends M multiplication triple shares (defined in Appendix C.2) to each server, along with a share of its private value x. Let the t-th multiplication triple be of the form (a t , b t , c t ) ∈ F 3 .
Then define a circuit M that returns "1" if and only if c t = a t · b t , for all 1 ≤ t ≤ M.The client can use a SNIP proof (Section 4.1) to convince the servers that all of the M triples it sent the servers are well-formed.
Then, the servers can execute Beaver's multiparty computation protocol (Section C.2) to evaluate the circuit using the M client-provided multiplication triples.Running the computation requires the servers to exchange Θ(M) field elements, and the number of rounds of communication is proportional to the multiplicative depth of the Valid circuit (i.e., the maximum number of multiplication gates on an input-output path).
An AFE is defined relative to a field F, two integers k and k (where k ≤ k), a set D of data elements, a set A of possible values of the aggregate statistic, and an aggregation function f : D n → A.
An AFE scheme consists of three efficient algorithms.
The algorithms are:• Encode : D → F k .
Covert a data item into its AFEencoded counterpart.
• Valid : F k → {0, 1}.
Return "1" if and only if the input is in the image of Encode.
• Decode : F k → A. Given a vector representing a collection of encoded data items, return the value of the aggregation function f evaluated at these items.
To be useful, an AFE encoding should satisfy the following properties:Definition 7 (AFE correctness).
We say that an AFE is correct for an aggregation function f if, for every choice of (x 1 , . . . , x n ) ∈ D n , we have that:Decode i Trunc k Encode(x i ) = f (x 1 , . . . , x n ).
Recall that Trunc k (v) denotes truncating the vector v ∈ F k p to its first k components.The correctness property of an AFE essentially states that if we are given valid encodings of data items (x 1 , . . . , x n ) ∈ D n , the decoding of their sum should be f (x 1 , . . . , x n ).
Definition 8 (AFE soundness).
We say that an AFE is sound if, for all encodings e ∈ F k : the predicate Valid(e) = 1 if and only if there exists a data item x ∈ D such that e = Encode(x).
An AFE is private with respect to a functionˆffunctionˆ functionˆf , if the sum of encodings σ = i Trunc k (Encode(x i )), given as input to algorithm Decode, reveals nothing about the underlying data beyond whatˆfwhatˆ whatˆf (x 1 , . . . , x n ) reveals.Definition 9 (AFE privacy).
We say that an AFE is private with respect to a functionˆffunctionˆ functionˆf : D n → A if there exists an efficient simulator S such that for all input data (x 1 , . . . , x n ) ∈ D n , the distribution S ( ˆ f (x 1 , . . . , x n )) is indistinguishable from the distribution σ = i Trunc k (Encode(x i )).
Relaxed correctness.
In many cases, randomized data structures are more efficient than their deterministic counterparts.
We can define a relaxed notion of correctness to capture a correctness notion for randomized AFEs.
In the randomized case, the scheme is parameterized by constants 0 < δ, and the Decode algorithm may use randomness.
We demand that with probability at least sApproximate counts.
The frequency count AFE, presented in Section 5.2, works well when the client value x lies in a small set of possible data values D.
This AFE requires communication linear in the size of D.
When the set D is large, a more efficient solution is to use a randomized counting data structure, such as a count-min sketch [36].
Melis et al. [92] demonstrated how to combine a countmin sketch with a secret-sharing scheme to efficiently compute counts over private data.
We can make their approach robust to malicious clients by implementing a count-min sketch AFE in Prio.
To do so, we use ln(1/δ) instances of the basic frequency count AFE, each for a set of size e//, for some constants and δ, and where e ≈ 2.718.
With n client inputs, the count-min sketch yields counts that are at most an additive n overestimate of the true values, except with probability e −δ .
Crucially, the Valid algorithm for this composed construction requires a relatively small number of multiplication gates-a few hundreds, for realistic choices of and δ-so the servers can check the correctness of the encodings efficiently.This AFE leaks the contents of a count-min sketch data structure into which all of the clients' values (x 1 , . . . , x n ) have been inserted.Share compression.
The output of the count-min sketch AFE encoding routine is essentially a very sparse matrix of dimension ln(1/δ) × (e//).
The matrix is all zeros, except for a single "1" in each row.
If the Prio client uses a conventional secret-sharing scheme to split this encoded matrix into s shares-one per server-the size of each share would be as large as the matrix itself, even though the plaintext matrix contents are highly compressible.A more efficient way to split the matrix into shares would be to use a function secret-sharing scheme [24,25,64].
Applying a function secret sharing scheme to each row of the encoded matrix would allow the size of each share to grow as the square-root of the matrix width (instead of linearly).
When using Prio with only two servers, there are very efficient function secret-sharing constructions that would allow the shares to have length logarithmic in the width of the matrix [25].
We leave further exploration of this technique to future work.Most popular.
Another common task is to return the most popular string in a data set, such as the most popular homepage amongst a set of Web clients.
When the universe of strings is small, it is possible to find the most popular string using the frequency-counting AFE.
When the universe is large (e.g., the set of all URLs), this method is not useful, since recovering the most popular string would require querying the structure for the count of every possible string.
Instead, we use a simplified version of a data structure of Bassily and Smith [7].
When there is a very popular string-one that more than n/2 clients hold, we can construct a very efficient AFE for collecting it.
Let F be a field of size at least n.
The Encode(x) algorithm represents its input x as a bbit string x = (x 0 , x 1 , x 2 , . . . , x b−1 ) ∈ {0, 1} b , and outputs a vector of b field elements (β 0 , . . . , β b−1 ) ∈ F b , where β i = x i for all i.
The Valid algorithm uses b multiplication gates to check that each value β i is really a 0/1 value in F, as in the summation AFE.The Decode algorithm gets as input the sum of n suchThe Decode algorithm rounds each value e i either down to zero or up to n (whichever is closer) and then normalizes the rounded number by n to get a b-bit binary string σ ∈ {0, 1} b , which it outputs.
As long as there is a string σ * with popularity greater than 50%, this AFE returns it.
To see why, consider the first bit of σ.
If σ * [0] = 0, then the sum e 0 < n/2 and Decode outputs "0."
If σ * [0] = 1, then the sum e 0 > n/2 and Decode outputs "1."
Correctness for longer strings followsThis AFE leaks quite a bit of information about the given data.
Given σ, one learns the number of data values that have their ith bit set to 1, for every 0 ≤ i < b.
In fact, the AFE is private relative to a function that outputs these b values, which shows that nothing else is leaked by σ.With a significantly more complicated construction, we can adapt a similar idea to collect strings that a constant fraction c of clients hold, for c ≤ 1/2.
The idea is to have the servers drop client-submitted strings at random into different "buckets," such that at least one bucket has a very popular string with high probability [7].
Evaluating an arbitrary ML model.
We wish to measure how well a public regression model predicts a target y from a client-submitted feature vector x.
In particular, if our model outputs a predictionˆypredictionˆ predictionˆy = M(x), we would like to measure how good of an approximationˆyapproximationˆ approximationˆy is of y.
The R 2 coefficient is one statistic for capturing this information.Karr et al. [82] observe that it is possible to reduce the problem of computing the R 2 coefficient of a public regression model to the problem of computing private sums.
We can adopt a variant of this idea to use Prio to compute the R 2 coefficient in a way that leaks little beyond the coefficient itself.The R 2 -coefficient of the model for client inputswhere y i is the true value associated with x i , ˆ y i = M(x i ) is the predicted value of y i , and Var(·) denotes variance.An AFE for computing the R 2 coefficient works as follows.
On input (x, y), the Encode algorithm first computes the predictionˆypredictionˆ predictionˆy = M(x) using the public model M.
The Encode algorithm then outputs the tuple (y, y 2 , (y − ˆ y) 2 , x), embedded in a finite field large enough to avoid overflow.Given the tuple (y, Y, Y * , x) as input, the Valid algorithm ensures that Y = y 2 and Y * = (y−M(x)) 2 .
When the model M is a linear regression model, algorithm Valid can be represented as an arithmetic circuit that requires only two multiplications.
If needed, we can augment this with a check that the x values are integers in the appropriate range using a range check, as in prior AFEs.
Finally, given the sum of encodings restricted to the first three components, the Decode algorithm has the information it needs to compute the R 2 coefficient.This AFE is private with respect to a function that outputs the R 2 coefficient, along with the expectation and variance of {y 1 , . . . , y n }.
G Prio protocol and proof sketchWe briefly review the full Prio protocol and then discuss its security.The final protocol.
We first review the Prio protocol from Section 5.
We assume that every client i, for i ∈ {1, . . . , n}, holds a private value x i that lies in some set of data items D.
We want to compute an aggregation function f : D n → A on these private values using an AFE.
The AFE encoding algorithm Encode maps D to F k , for some field F and an arity k.
When decoding, the encoded vectors in F k are first truncated to their first k components.The Prio protocol proceeds in four steps: The client then sends, over an encrypted and authenticated channel, one share of its submission to each server, along with a share of a SNIP proof (Section 4) that Valid(y i ) = 1.2.
Validate.
Upon receiving the ith client submission, the servers verify the client-provided SNIP to jointly confirm that Valid(y i ) = 1 (i.e., that client's submission is well-formed).
If this check fails, the servers reject the submission.3.
Aggregate.
Each server j holds an accumulator value A j ∈ F k , initialized to zero, where 0 < k ≤ k. Upon receiving a share of a client encoding [y i ] j ∈ F k , the server truncates [y i ] j to its first k components, and adds this share to its accumulator:Recall that Trunc k (v) denotes truncating the vector v ∈ F k p to its first k components.
Security.
We briefly sketch the security argument for the complete protocol.
The security definitions appear in Appendix A.First, the robustness property (Definition 6) follows from the soundness of the SNIP construction: as long as the servers are honest, they will correctly identify and reject any client submissions that do not represent proper AFE encodings.Next, we argue f -privacy (Definition 1).
Define the functionWe claim that, as long as:• at least one server executes the protocol correctly,• the AFE construction is private with respect to f , in the sense of Definition 9, and • the SNIP construction satisfies the zero-knowledge property (Section 4.1), the only information that leaks to the adversary is the value of the function f on the clients' private values.To show this, it suffices to construct a simulator S that takes as input σ = g(x 1 , . . . , x n ) and outputs a transcript of the protocol execution that is indistinguishable from a real transcript.
Recall that the AFE simulator takes f (x 1 , . . . , x n ) as input and simulates σ.
Composing the simulator S with the AFE simulator yields a simulator for the entire protocol, as required by Definition 1.
On input σ, the simulator S executes these steps: • To simulate the submitted share [x] i of an honest client, the simulator samples a vector of random field elements of the appropriate length.
• To simulate the SNIP of an honest client, the simulator invokes the SNIP simulator as a subroutine.
• To simulate the adversarially produced values, the simulator can query the adversary (presented as an oracle) on the honest parties' values generated so far.
• To simulate the values produced by the honest servers in Step 4 of the protocol, the simulator picks random values A j subject to the constraints σ = j A j , and such that the A j s for the adversarial servers are consistent with their views of the protocol.
As long as there exists a single honest server that the adversary does not control, the adversary sees at most s − 1 shares of secret-shared values split into s shares throughout the entire protocol execution.
These values are trivial to simulate, since they are indistinguishable from random to the adversary.Finally, anonymity (Definition 2) follows by Claim 4 whenever the function f is symmetric.
Otherwise, anonymity is impossible, by Claim 5.
H Additional optimizationsOptimization: PRG secret sharing.
The Prio protocol uses additive secret sharing to split the clients' private data into shares.
The naïve way to split a value x ∈ F L into s shares is to choose [x] A standard bandwidthsaving optimization is to generate the first s − 1 shares using a pseudo-random generator (PRG) G : K → F L , such as AES in counter mode [85,102].
To do so, pick s − 1 random PRG keys k 1 , . . . , k s−1 ∈ K, and define the first s − 1 shares as G(k 1 ), G(k 2 ), . . . , G(k s−1 ).
Rather than representing the first s − 1 shares as vectors in F L , we can now represent each of the first s − 1 shares using a single AES key.
(The last share will still be L field elements in length.)
This optimization reduces the total size of the shares from sL field elements down to L + O(1).
For s = 5 servers, this 5× bandwidth savings is significant.
The degree of these polynomials is close to M, where M is the number of multiplication gates in the Valid circuit.
If the servers used straightforward polynomial interpolation and evaluation to verify the SNIPs, the servers would need to perform Θ(M log M) multiplications to process a single client submission, even using optimized FFT methods.
When the Valid circuit is complex (i.e., M ≈ 2 16 or more), this Θ(M log M) cost will be substantial.Let us imagine for a minute that we could fix in advance the random point r that the servers use to execute the polynomial identity test.
In this case, each server can perform interpolation and evaluation of any polynomial P in one step using only M field multiplications per server, instead of Θ(M log M).
To do so, each server precomputes constants (c 0 , . . . , c M−1 ) ∈ F M .
These constants depend on the x-coordinates of the points being interpolated (which are always fixed in our application) and on the point r (which for now we assume is fixed).
Then, given points {(t, y t )} M−1 t=0 on a polynomial P, the servers can evaluate P at r using a fast inner-product computation: P(x) = t c t y t ∈ F. Standard Lagrangian interpolation produces these c i s as intermediate values [5].
Our observation is that the servers can fix the "random" point r at which they evaluate the polynomials [ f ] i and [g] i as long as: (1) the clients never learn r, and (2) the servers sample a new random point r periodically.
The randomness of the value r only affects soundness.
Since we require soundness to hold only if all Prio servers are honest, we may assume that the servers will never reveal the value r to the clients.A malicious client may try to learn something over time about the servers' secret value r by sending a batch of well-formed and malformed submissions and seeing which submissions the servers do or do not accept.
A simple argument shows that after making q such queries, the client's probability of cheating the servers is at most 2Mq/|F|.
By sampling a new point after every Q ≈ 2 10 client uploads, the servers can amortize the cost of doing the interpolation precomputation over Q client uploads, while keeping the failure probability bounded above by 2MQ/|F|, which they might take to be 2 −60 or less.In Prio, we apply this optimization to combine the interpolation of [ f ] i and [g] i with the evaluation of these polynomials at the point r.In Step 2 of the SNIP verification process, each server must also evaluate the client-provided polynomial [h] i at each point t ∈ {1, . . . , M}.
To eliminate this cost, we have the client send the polynomial [h] i to each server i in point-value form.
That is, instead of sending each server shares of the coefficients of h, the client sends each server shares of evaluations of h.
In particular, the client evaluates [h] Circuit optimization In many cases, the servers hold multiple verification circuits Valid 1 , . . . , Valid N and want to check whether the client's submission passes all N checks.
To do so, we have the Valid circuits return zero (instead of one) on success.
If W j is the value on the last output wire of the circuit Valid j , we have the servers choose random values (r 1 , . . . , r N ) ∈ F N and publish the sum j r j W j in the last step of the protocol.
If any W j 0, then this sum will be non-zero with high probability and the servers will reject the client's submission.
Approximate counts.
The frequency count AFE, presented in Section 5.2, works well when the client value x lies in a small set of possible data values D.
This AFE requires communication linear in the size of D.
When the set D is large, a more efficient solution is to use a randomized counting data structure, such as a count-min sketch [36].
Melis et al. [92] demonstrated how to combine a countmin sketch with a secret-sharing scheme to efficiently compute counts over private data.
We can make their approach robust to malicious clients by implementing a count-min sketch AFE in Prio.
To do so, we use ln(1/δ) instances of the basic frequency count AFE, each for a set of size e//, for some constants and δ, and where e ≈ 2.718.
With n client inputs, the count-min sketch yields counts that are at most an additive n overestimate of the true values, except with probability e −δ .
Crucially, the Valid algorithm for this composed construction requires a relatively small number of multiplication gates-a few hundreds, for realistic choices of and δ-so the servers can check the correctness of the encodings efficiently.This AFE leaks the contents of a count-min sketch data structure into which all of the clients' values (x 1 , . . . , x n ) have been inserted.Share compression.
The output of the count-min sketch AFE encoding routine is essentially a very sparse matrix of dimension ln(1/δ) × (e//).
The matrix is all zeros, except for a single "1" in each row.
If the Prio client uses a conventional secret-sharing scheme to split this encoded matrix into s shares-one per server-the size of each share would be as large as the matrix itself, even though the plaintext matrix contents are highly compressible.A more efficient way to split the matrix into shares would be to use a function secret-sharing scheme [24,25,64].
Applying a function secret sharing scheme to each row of the encoded matrix would allow the size of each share to grow as the square-root of the matrix width (instead of linearly).
When using Prio with only two servers, there are very efficient function secret-sharing constructions that would allow the shares to have length logarithmic in the width of the matrix [25].
We leave further exploration of this technique to future work.Most popular.
Another common task is to return the most popular string in a data set, such as the most popular homepage amongst a set of Web clients.
When the universe of strings is small, it is possible to find the most popular string using the frequency-counting AFE.
When the universe is large (e.g., the set of all URLs), this method is not useful, since recovering the most popular string would require querying the structure for the count of every possible string.
Instead, we use a simplified version of a data structure of Bassily and Smith [7].
When there is a very popular string-one that more than n/2 clients hold, we can construct a very efficient AFE for collecting it.
Let F be a field of size at least n.
The Encode(x) algorithm represents its input x as a bbit string x = (x 0 , x 1 , x 2 , . . . , x b−1 ) ∈ {0, 1} b , and outputs a vector of b field elements (β 0 , . . . , β b−1 ) ∈ F b , where β i = x i for all i.
The Valid algorithm uses b multiplication gates to check that each value β i is really a 0/1 value in F, as in the summation AFE.The Decode algorithm gets as input the sum of n suchThe Decode algorithm rounds each value e i either down to zero or up to n (whichever is closer) and then normalizes the rounded number by n to get a b-bit binary string σ ∈ {0, 1} b , which it outputs.
As long as there is a string σ * with popularity greater than 50%, this AFE returns it.
To see why, consider the first bit of σ.
If σ * [0] = 0, then the sum e 0 < n/2 and Decode outputs "0."
If σ * [0] = 1, then the sum e 0 > n/2 and Decode outputs "1."
Correctness for longer strings followsThis AFE leaks quite a bit of information about the given data.
Given σ, one learns the number of data values that have their ith bit set to 1, for every 0 ≤ i < b.
In fact, the AFE is private relative to a function that outputs these b values, which shows that nothing else is leaked by σ.With a significantly more complicated construction, we can adapt a similar idea to collect strings that a constant fraction c of clients hold, for c ≤ 1/2.
The idea is to have the servers drop client-submitted strings at random into different "buckets," such that at least one bucket has a very popular string with high probability [7].
Evaluating an arbitrary ML model.
We wish to measure how well a public regression model predicts a target y from a client-submitted feature vector x.
In particular, if our model outputs a predictionˆypredictionˆ predictionˆy = M(x), we would like to measure how good of an approximationˆyapproximationˆ approximationˆy is of y.
The R 2 coefficient is one statistic for capturing this information.Karr et al. [82] observe that it is possible to reduce the problem of computing the R 2 coefficient of a public regression model to the problem of computing private sums.
We can adopt a variant of this idea to use Prio to compute the R 2 coefficient in a way that leaks little beyond the coefficient itself.The R 2 -coefficient of the model for client inputswhere y i is the true value associated with x i , ˆ y i = M(x i ) is the predicted value of y i , and Var(·) denotes variance.An AFE for computing the R 2 coefficient works as follows.
On input (x, y), the Encode algorithm first computes the predictionˆypredictionˆ predictionˆy = M(x) using the public model M.
The Encode algorithm then outputs the tuple (y, y 2 , (y − ˆ y) 2 , x), embedded in a finite field large enough to avoid overflow.Given the tuple (y, Y, Y * , x) as input, the Valid algorithm ensures that Y = y 2 and Y * = (y−M(x)) 2 .
When the model M is a linear regression model, algorithm Valid can be represented as an arithmetic circuit that requires only two multiplications.
If needed, we can augment this with a check that the x values are integers in the appropriate range using a range check, as in prior AFEs.
Finally, given the sum of encodings restricted to the first three components, the Decode algorithm has the information it needs to compute the R 2 coefficient.This AFE is private with respect to a function that outputs the R 2 coefficient, along with the expectation and variance of {y 1 , . . . , y n }.
We briefly review the full Prio protocol and then discuss its security.The final protocol.
We first review the Prio protocol from Section 5.
We assume that every client i, for i ∈ {1, . . . , n}, holds a private value x i that lies in some set of data items D.
We want to compute an aggregation function f : D n → A on these private values using an AFE.
The AFE encoding algorithm Encode maps D to F k , for some field F and an arity k.
When decoding, the encoded vectors in F k are first truncated to their first k components.The Prio protocol proceeds in four steps: The client then sends, over an encrypted and authenticated channel, one share of its submission to each server, along with a share of a SNIP proof (Section 4) that Valid(y i ) = 1.2.
Validate.
Upon receiving the ith client submission, the servers verify the client-provided SNIP to jointly confirm that Valid(y i ) = 1 (i.e., that client's submission is well-formed).
If this check fails, the servers reject the submission.3.
Aggregate.
Each server j holds an accumulator value A j ∈ F k , initialized to zero, where 0 < k ≤ k. Upon receiving a share of a client encoding [y i ] j ∈ F k , the server truncates [y i ] j to its first k components, and adds this share to its accumulator:Recall that Trunc k (v) denotes truncating the vector v ∈ F k p to its first k components.
Security.
We briefly sketch the security argument for the complete protocol.
The security definitions appear in Appendix A.First, the robustness property (Definition 6) follows from the soundness of the SNIP construction: as long as the servers are honest, they will correctly identify and reject any client submissions that do not represent proper AFE encodings.Next, we argue f -privacy (Definition 1).
Define the functionWe claim that, as long as:• at least one server executes the protocol correctly,• the AFE construction is private with respect to f , in the sense of Definition 9, and • the SNIP construction satisfies the zero-knowledge property (Section 4.1), the only information that leaks to the adversary is the value of the function f on the clients' private values.To show this, it suffices to construct a simulator S that takes as input σ = g(x 1 , . . . , x n ) and outputs a transcript of the protocol execution that is indistinguishable from a real transcript.
Recall that the AFE simulator takes f (x 1 , . . . , x n ) as input and simulates σ.
Composing the simulator S with the AFE simulator yields a simulator for the entire protocol, as required by Definition 1.
On input σ, the simulator S executes these steps: • To simulate the submitted share [x] i of an honest client, the simulator samples a vector of random field elements of the appropriate length.
• To simulate the SNIP of an honest client, the simulator invokes the SNIP simulator as a subroutine.
• To simulate the adversarially produced values, the simulator can query the adversary (presented as an oracle) on the honest parties' values generated so far.
• To simulate the values produced by the honest servers in Step 4 of the protocol, the simulator picks random values A j subject to the constraints σ = j A j , and such that the A j s for the adversarial servers are consistent with their views of the protocol.
As long as there exists a single honest server that the adversary does not control, the adversary sees at most s − 1 shares of secret-shared values split into s shares throughout the entire protocol execution.
These values are trivial to simulate, since they are indistinguishable from random to the adversary.Finally, anonymity (Definition 2) follows by Claim 4 whenever the function f is symmetric.
Otherwise, anonymity is impossible, by Claim 5.
Optimization: PRG secret sharing.
The Prio protocol uses additive secret sharing to split the clients' private data into shares.
The naïve way to split a value x ∈ F L into s shares is to choose [x] A standard bandwidthsaving optimization is to generate the first s − 1 shares using a pseudo-random generator (PRG) G : K → F L , such as AES in counter mode [85,102].
To do so, pick s − 1 random PRG keys k 1 , . . . , k s−1 ∈ K, and define the first s − 1 shares as G(k 1 ), G(k 2 ), . . . , G(k s−1 ).
Rather than representing the first s − 1 shares as vectors in F L , we can now represent each of the first s − 1 shares using a single AES key.
(The last share will still be L field elements in length.)
This optimization reduces the total size of the shares from sL field elements down to L + O(1).
For s = 5 servers, this 5× bandwidth savings is significant.
The degree of these polynomials is close to M, where M is the number of multiplication gates in the Valid circuit.
If the servers used straightforward polynomial interpolation and evaluation to verify the SNIPs, the servers would need to perform Θ(M log M) multiplications to process a single client submission, even using optimized FFT methods.
When the Valid circuit is complex (i.e., M ≈ 2 16 or more), this Θ(M log M) cost will be substantial.Let us imagine for a minute that we could fix in advance the random point r that the servers use to execute the polynomial identity test.
In this case, each server can perform interpolation and evaluation of any polynomial P in one step using only M field multiplications per server, instead of Θ(M log M).
To do so, each server precomputes constants (c 0 , . . . , c M−1 ) ∈ F M .
These constants depend on the x-coordinates of the points being interpolated (which are always fixed in our application) and on the point r (which for now we assume is fixed).
Then, given points {(t, y t )} M−1 t=0 on a polynomial P, the servers can evaluate P at r using a fast inner-product computation: P(x) = t c t y t ∈ F. Standard Lagrangian interpolation produces these c i s as intermediate values [5].
Our observation is that the servers can fix the "random" point r at which they evaluate the polynomials [ f ] i and [g] i as long as: (1) the clients never learn r, and (2) the servers sample a new random point r periodically.
The randomness of the value r only affects soundness.
Since we require soundness to hold only if all Prio servers are honest, we may assume that the servers will never reveal the value r to the clients.A malicious client may try to learn something over time about the servers' secret value r by sending a batch of well-formed and malformed submissions and seeing which submissions the servers do or do not accept.
A simple argument shows that after making q such queries, the client's probability of cheating the servers is at most 2Mq/|F|.
By sampling a new point after every Q ≈ 2 10 client uploads, the servers can amortize the cost of doing the interpolation precomputation over Q client uploads, while keeping the failure probability bounded above by 2MQ/|F|, which they might take to be 2 −60 or less.In Prio, we apply this optimization to combine the interpolation of [ f ] i and [g] i with the evaluation of these polynomials at the point r.In Step 2 of the SNIP verification process, each server must also evaluate the client-provided polynomial [h] i at each point t ∈ {1, . . . , M}.
To eliminate this cost, we have the client send the polynomial [h] i to each server i in point-value form.
That is, instead of sending each server shares of the coefficients of h, the client sends each server shares of evaluations of h.
In particular, the client evaluates [h] Circuit optimization In many cases, the servers hold multiple verification circuits Valid 1 , . . . , Valid N and want to check whether the client's submission passes all N checks.
To do so, we have the Valid circuits return zero (instead of one) on success.
If W j is the value on the last output wire of the circuit Valid j , we have the servers choose random values (r 1 , . . . , r N ) ∈ F N and publish the sum j r j W j in the last step of the protocol.
If any W j 0, then this sum will be non-zero with high probability and the servers will reject the client's submission.
