Voting trees describe an iterative procedure for selecting a single vertex from a tournament.
They provide a very general abstract model of decision-making among a group of individuals, and it has therefore been studied which voting rules have a tree that implements them, i.e., chooses according to the rule for every tournament.
While partial results concerning implementable rules and necessary conditions for implementability have been obtained over the past forty years, a complete characterization of voting rules implementable by trees has proven surprisingly hard to find.
A prominent rule that cannot be implemented by trees is the Copeland rule, which singles out vertices with maximum degree.
In this paper, we suggest a new angle of attack and reexamine the implementability of the Copeland solution using paradigms and techniques that are at the core of theoretical computer science.
We study the extent to which voting trees can approximate the maximum degree in a tournament, and give upper and lower bounds on the worst-case ratio between the degree of the vertex chosen by a tree and the maximum degree, both for the deterministic model concerned with a single fixed tree, and for randomizations over arbitrary sets of trees.
Our main positive result is a randomization over surjective trees of polynomial size that provides an approximation ratio of at least 1/2.
The proof is based on a connection between a randomization over caterpillar trees and a rapidly mixing Markov chain.
Voting is a general method for aggregating the preferences of a set of individuals.
In the case of two alternatives, the voting rule that selects the alternative preferred by a majority of the voters, commonly known as the majority rule, is uniquely characterized by anonymity, neutrality, and monotonicity (May, 1952).
It is thus the only "reasonable" rule for two alternatives that is symmetric with respect to both voters and alternatives.
A natural way to generalize the majority rule to more than two alternatives is to base the choice on an asymmetric dominance relation over the set of alternatives, in which one alternative dominates the other if it is preferred by a majority of the voters.
Assuming an odd number of voters with linear preferences this relation is a tournament, i.e., both asymmetric and complete.
In graph theoretic terms, a tournament is an orientation of the complete graph on a set of alternatives, with a directed edge from a dominating alternative to a dominated one.Unfortunately, the situation becomes much less favorable when moving to this more general setting.
The dominance relation may contain cycles ( de Condorcet, 1785), and in fact any tournament can be obtained from a set of voters of size polynomial in the number of alternatives (McGarvey, 1953).
As a consequence, an important area in social choice is concerned with so-called tournament solutions that map each tournament to a nonempty set of "good" alternatives in the absence of maximal, i.e., undominated, ones (see, e.g., Laslier, 1997).
Voting trees provide an abstract model for decision-making among a group of individuals.
They were first studied by Farquharson (1969), and have consequently been applied to the analysis of a wide range of decision procedures (see, e.g., Shepsle and Weingast, 1984;Banks, 1985, and the references therein).
A voting tree over a set A of alternatives is a binary tree with leaves labeled by elements of A. Given a tournament T , a labeling for the internal nodes is defined recursively by labeling a node by the label of its child that beats the other child according to T (or by the unique label of its children if both have the same label).
The label at the root is then deemed the winner of the voting tree given tournament T .
This definition expressly allows an alternative to appear multiple times at the leaves of a tree.A voting tree over A is said to implement a particular solution concept if for every tournament on A it selects an optimal alternative according to said solution concept.
While there have been some partial results concerning particular implementable rules and necessary conditions for implementability, an axiomatic characterization of voting rules implementable by trees remains one of the most intriguing open problems in social choice theory (see, e.g., Moulin, 1986;Srivastava and Trick, 1996).
It should be noted that the interest in implementation by voting trees does not stem from their attractiveness as an algorithmic procedure, but rather from their importance as an abstract model of decision-making.
To this end, voting trees were first studied in the context of so-called "binary procedures" (Farquharson, 1969).
Assume that the set of alternatives is split into two, possibly overlapping, subsets.
Then, one alternative is chosen from each of the subsets by applying the idea recursively, and finally the voters decide which of these two alternatives is to be chosen.
It is easy to see that each instance of this procedure induces a voting tree, with subsets of alternatives corresponding to subtrees.
While the division into two subsets rather than, say, three, seems a bit arbitrary, it nevertheless makes perfect sense given that we know how to choose from two alternatives, namely by majority vote.
The class of binary procedures furthermore includes many procedures that are relevant in practice, like "those of Parliament [...] and the usual committee method of voting on amendments to a motion.
It also includes some electoral procedures, such as that whereby each candidate is considered in turn for acceptance, and the Scots' practice of election by paired comparisons" (Farquharson, 1969, p. 9).
Binary procedures possess the following remarkable property: if voters have strict preferences over the set of alternatives, and are assumed to vote strategically at each division into subsets in order to achieve the best possible outcome according to their own preference order, then there always exists a unique outcome that survives the iterated elimination of dominated strategies.
It turns out that the alternative elected in this outcome is precisely the one chosen by the corresponding voting tree.
Implementability by voting trees further implies implementability by backward induction, which is considered one of the most appealing solution concepts in terms of the plausibility of the underlying strategic behavior (Herrero and Srivastava, 1992;Dutta and Sen, 1993).
A particular solution that cannot be implemented by voting trees is the Copeland solution, which selects a vertex with maximum (out-)degree (Moulin, 1986).
This is rather surprising, because degree is conceivably one of the most basic properties to single out vertices in a tournament, and it is also very easy to find a vertex with maximum degree.
In other words, although the Copeland rule is computationally tractable, it cannot be rationalized in terms of the iterative comparison-based model of choice provided by voting trees.In this paper, we suggest a new angle to attack the problem of characterizing implementable rules, and re-examine implementability of the Copeland solution using paradigms and techniques that are at the core of theoretical computer science.
Indeed, we study the extent to which voting trees can approximate the maximum degree in a tournament, by asking for the largest value of α, such that for any set A of alternatives, there exists a tree Γ, which for every tournament on A selects an alternative with at least α times the maximum degree in the tournament.
We address this question both in the deterministic model, where Γ is a fixed voting tree, and in the randomized model, where voting trees are chosen randomly according to some distribution.
Conceptually, randomizations over voting trees provide an abstract model for decision-making processes that include an element of chance, just like voting trees do for deterministic rules, and we find it quite surprising that seemingly they have not been considered before.
1 This is not the first time that theoretical computer science provides a new perspective on problems in social choice theory.
In the end, any model of decision-making is also a computational model, and by studying the power and limitations of the latter in computing certain functions, one directly obtains insights about the former.
A prominent example where this observation has been applied successfully is the agenda of using computational complexity as a barrier against manipulation in elections (see, e.g., Bartholdi et al., 1989;Conitzer et al., 2007;Zuckerman et al., 2009;Friedgut et al., 2008), thereby circumventing the Gibbard-Satterthwaite impossibility result (Gibbard, 1973;Satterthwaite, 1975).
Results Our main negative results are upper bounds of 3/4 and 5/6, respectively, on the approximation ratio achievable by deterministic trees and randomizations over trees.
It should be noted that this directly implies a strong negative result for exact implementability: no rule guaranteed to select an alternative preferred by a majority over at least 3/4 of the other alternatives can be implemented by voting trees.
We also find it quite surprising that randomizations over trees cannot achieve a ratio arbitrarily close to 1.
For most of the paper we concentrate on the randomized model.
We study a class of trees we call voting caterpillars, which are characterized by the fact that they have exactly two nodes on each level below the root.
We devise a randomization over "small" trees of this type, which crucially satisfies an important property we call admissibility: its support only contains trees where every alternative appears in some leaf.
Our main positive result is the following.Theorem 4.1.
Let A be a set of alternatives.
Then there exists an admissible randomization over voting trees on A of size polynomial in |A| with an approximation ratio of 1/2 − O(1/|A|).
We prove this theorem by establishing a connection to a nonreversible, rapidly mixing random walk on the tournament, and analyzing its stationary distribution.
The proof of rapid mixing involves reversibilizing the transition matrix, and then bounding its spectral gap via its conductance.
To the best of our knowledge, this constitutes the first use of rapid mixing, and in particular of notions like conductance, as a proof technique in Computational Economics.
We further show that our analysis is tight, and that voting caterpillars also provide a lower bound of 1/2 for the second order degree of an alternative, defined as the sum of degrees of those alternatives it dominates.The paper concludes with negative results about more complex tree structures, which turn out to be rather surprising.
In particular, we show that the approximation ratio provided by randomized balanced trees can become arbitrarily bad with growing height.
We finally show that "higher-order" caterpillars, with labels chosen by lower-order caterpillars instead of uniformly at random, can also cause the approximation ratio to deteriorate.Related Work In economics, the problem of implementation by voting trees was introduced by Farquharson (1969), and further explored, for example, by McKelvey and Niemi (1978), Miller (1980), Moulin (1986), Herrero and Srivastava (1992), Dutta and Sen (1993), Srivastava and Trick (1996), and Coughlan and Breton (1999).
In particular, Moulin (1986) shows that the Copeland solution is not implementable by voting trees if there are at least 8 alternatives, while Srivastava and Trick (1996) demonstrate that it can be implemented for tournaments with up to 7 alternatives.
Laffond et al. (1994) compute the Copeland measure of several prominent choice correspondencesfunctions mapping each tournament to a set of desirable alternatives.
In contrast to the (Copeland) approximation ratio considered in this paper, the Copeland measure is computed with respect to the best alternative selected by the correspondence, so strictly speaking it is not a worst-case measure.
More importantly, however, Laffond et al. study properties of given correspondences, whereas we investigate the possibility of constructing voting trees with certain desirable properties.
In this sense, our work is algorithmic in nature, while theirs is descriptive.Implementability in the randomized model is related to work that studies the influence of the strength of a player on his winning probability in knockout tournaments (see, e.g., Chen and Hwang, 1988, and the references therein).
In theoretical computer science, the problem studied in this paper is somewhat reminiscent of the problem of determining the query complexity of graph properties (see, e.g., Kahn et al., 1984).
In the general model, one is given an unknown graph over a known set of vertices, and must determine whether the graph satisfies a certain property by querying the edges.
The complexity of a property is then defined as the height of the smallest decision tree that checks the property.
Voting trees can be interpreted as querying the edges of the tournament in parallel, and in a way that severely limits the ways in which, and the extent up to which, information can be transferred between different queries.In the area of computational social choice at the boundary of computer science and economics, several authors have looked at the computational properties of voting trees and of various solution concepts.
Organization We begin by introducing the necessary concepts and notation.
In Section 3 we present upper bounds for the deterministic and the randomized setting.
In Section 4, we establish our main positive result using a randomization over voting caterpillars.
Section 5 is devoted to balanced trees, and Section 6 concludes with some open problems.
An analysis of "higher order" caterpillars can be found in the appendix.
Let A = {1, . . . , m} be a set of alternatives.
A tournament T on A is an orientation of the complete graph with vertex set A.
We denote by T (A) the set of all tournaments on A. For a tournament T ∈ T (A), we write iT j if the edge between a pair i, j ∈ A of alternatives is directed from i to j, or i dominates j. For an alternative i ∈ A we denote by s i = s i (T ) = |{j ∈ A : iT j}| the degree or (Copeland) score of i, i.e., the number of outgoing edges from this alternative, omitting T when it is clear from the context.We then consider computations performed by a specific type of tree on a tournament.
In the context of this paper, a (deterministic) voting tree on A is a structure Γ = (V, E, ) where (V, E) is a binary tree with root r ∈ V , and : V → A is a mapping that assigns an element of A to each leaf of (V, E).
Given a tournament T , a unique function T : V → A exists such thatT (v) = (v) if v is a leaf, (u 1 ) if v has children u 1 and u 2 , and (u 1 )T (u 2 ) or (u 1 ) = (u 2 ).
We will be interested in the label of the root r under this labeling, which we call the winner of the tree and denote by Γ(T ) = T (r).
We call a tree Γ surjective if is surjective.
Obviously, surjectivity corresponds to a very basic fairness requirement on the solution implemented by a tree.Other authors therefore view surjectivity as an inherent property of voting trees and define them accordingly (see, e.g., Moulin, 1986).
The sole reason we do not require surjectivity by definition is that our analysis will use trees that are not necessarily surjective.
Finally, a voting tree Γ on A will be said to provide an approximation ratio of α (with respect to the maximum degree) ifmin T ∈T (A) s Γ(T ) max i∈A s i (T ) ≥ α.The above model can be generalized by looking at randomizations over voting trees according to some probability distribution.
We will call a randomization admissible if its support contains only surjective trees.
A distribution ∆ over voting trees will then be said to provide a (randomized) approximation ratio of α ifmin T ∈T (A) E Γ∼∆ [s Γ(T ) ] max i∈A s i (T ) ≥ α.While we are of course interested in the approximation ratio achievable by admissible randomizations, it will prove useful to consider a specific class of randomizations that are not admissible, namely those that choose uniformly from the set of all voting trees with a given structure.
Equivalently, such a randomization is obtained by fixing a binary tree and assigning alternatives to the leaves independently and uniformly at random, and will thus be called a randomized voting tree.
In this section we present upper bounds on the approximation ratio achievable by voting trees, both in the deterministic model and in the randomized model.
We build on concepts and techniques introduced by Moulin (1986), and begin by quickly familiarizing the reader with these.
Given a tournament T on a set A of alternatives, we say that C ⊆ A is a component 2 of T if for all i 1 , i 2 ∈ C and j ∈ A \ C, i 1 T j if and only if i 2 T j. For a component C, denote by T C the subset of tournaments that have C as a component.
If T ∈ T C , we can unambiguously define a tournament T C on (A \ C) ∪ {C} by replacing the component C by a single alternative.
The following lemma states that for two tournaments that differ only inside a particular component, any tree chooses an alternative from that component for one of the tournaments if and only if it does for the other.
Furthermore, if an alternative outside the component is chosen for one tournament, then the same alternative has to be chosen for the other.
Laslier (1997) calls a solution concept satisfying these properties weakly composition-consistent.
Lemma 3.1 (Moulin 1986).
Let A be a set of alternatives, Γ a voting tree on A. Then, for all proper subsets C A, and for all T, T ∈ T C ,1.
[T C = T C ] implies [Γ(T ) ∈ C if and only if Γ(T ) ∈ C], and2.
[T C = T C and Γ(T ) ∈ A \ C] implies [Γ(T ) = Γ(T )].
Our first result asserts that no deterministic tree can always choose an alternative that has a degree significantly larger than 3/4 of the maximum degree, thereby strengthening the negative result concerning implementability of the Copeland solution (Moulin, 1986).
Theorem 3.2.
Let A be a set of alternatives, |A| = m, and let Γ be a deterministic voting tree on A with approximation ratio α.
Then, α ≤ 3/4 + O(1/m).
Proof.
For ease of exposition, we assume |A| = m = 3k for some odd k, but the same result (up to lower order terms) holds for all values of m. Define a tournament T comprised of three components C 1 , C 2 , and C 3 , such that for r = 1, 2, 3, (i) |C r | = k and the subgraph of T induced by C r is regular, i.e., each i ∈ C r dominates exactly (k − 1)/2 of the alternatives in C r , and (ii) for all i ∈ C r and j ∈ C (r mod 3)+1 , iT j.
An illustration for k = 3 is given on the left of Figure 1.
Now consider any deterministic voting tree Γ on A, and assume without loss of generality that Γ(T ) ∈ C 1 .
Define T to be a tournament on A such that the subgraphs of T and T induced by B ⊆ A are identical if |B ∩ C 2 | ≤ 1, and the subgraph of T induced by C 2 is transitive; in particular, there is i ∈ C 2 such that for any i = j ∈ C 2 , iT j.
An illustration for k = 3 is given on the right of Figure 1.
By Lemma 3.1, Γ(T ) = Γ(T ).
Furthermore, T satisfiess Γ(T ) = k + (k − 1) 2 = 3k 2 − 1 2 and max i∈A s i = 2k − 1,and thuss Γ(T ) max i∈A s i (T ) = 3k − 1 4k − 2 ≤ 3(k − 1) + 2 4(k − 1) = 3 4 + 1 2(k − 1).
In particular, this ratio tends to 3/4 as k tends to infinity.2 Moulin (1986) uses the term "adjacent set".
C 1 C 2 C 3 C 1 C 2 C 3 tournament T (C 2 regular) tournament T (C 2 transitive)Figure 1: Tournaments used in the proof of Theorem 3.2, illustrated for k = 3.
A voting tree is assumed to select an alternative from C 1 .
We now look at the randomized model.
It turns out that one cannot obtain an approximation ratio arbitrarily close to 1 by randomizing over large trees.
We derive an upper bound for the approximation ratio by using similar arguments as in the deterministic case above, and combining them with the minimax principle of Yao (1977).
Theorem 3.3.
Let A be a set of alternatives, |A| = m, and let ∆ be a probability distribution over voting trees on A with an approximation ratio of α.
Then, α ≤ 5/6 + O(1/m).
Proof.
Reformulating the minimax principle for voting trees, an upper bound on the worst-case performance of the best randomized tree on a set A of alternatives is given by the performance of the best deterministic tree with respect to some probability distribution over tournaments on A.As in the proof of Theorem 3.2, we assume for ease of exposition that |A| = m = 3k for some odd k, and define a tournament T as a cycle of three regular components C 1 , C 2 , and C 3 , each of size k. Further define three new tournaments T 1 , T 2 , and T 3 such that for r = 1, 2, 3, the subgraphs of T and T r induced by B ⊆ A are identical if |B ∩ C r | ≤ 1, and the subgraph of T r induced by C r is transitive.
Let Γ be any deterministic tree on A. Combining both statements of Lemma 3.1, there exists i ∈ {1, 2, 3} such that for r = 1, 2, 3, Γ(T r ) ∈ C i .
In particular, Γ selects an alternative with score at most 3k/2 − 1/2 for two of the three tournaments T r .
Now consider a tournament T drawn uniformly from {T 1 , T 2 , T 3 }.
By the above,E Γ∼∆ [s Γ(T ) ] ≤ (2(3k/2 − 1/2) + (2k − 1))/3 = 5k/3 − 2/3 and max i∈A s i = 2k − 1,and thusE Γ∼∆ [s Γ(T ) ] max i∈A s i ≤ 5k − 2 6k − 3 ≤ 5(k − 1) + 3 6(k − 1) = 5 6 + 1 2(k − 1).
In particular, this ratio tends to 5/6 as k tends to infinity.We point out that the theorem holds in particular for inadmissible randomizations.
A weak deterministic lower bound of Θ((log m)/m) can be obtained straightforwardly from a balanced tree where every label appears exactly once.
While balanced trees will be discussed in more detail in Section 5, they become increasingly unwieldy with growing height, and an improvement of this lower bound or of the deterministic upper bound given in the previous section currently seems out of reach.
In the remainder of the paper, we therefore concentrate on the randomized model.
In this section we put forward our main result, a lower bound of 1/2, up to lower order terms, for admissible randomizations over voting trees.
Let us state the result formally.Theorem 4.1.
Let A be a set of alternatives.
Then there exists an admissible randomization over voting trees on A of size polynomial in |A| with an approximation ratio of 1/2 − O(1/m).
In addition to satisfying the basic admissibility requirement, the randomization also has the desirable property of relying only on trees of polynomial size.
The latter is relevant even when assuming a purely descriptive point of view, since a huge voting tree would not provide a very realistic model of real-world decision-making.
To prove Theorem 4.1, we make use of a specific binary tree structure known as caterpillar trees.
We begin by inductively defining a family of binary trees that we refer to as k-caterpillars.
The 1-caterpillar consists of a single leaf.
A k-caterpillar is a binary tree, where one subtree of the root is a (k − 1)-caterpillar, and the other subtree is a leaf.
Then, a voting k-caterpillar on A is a k-caterpillar whose leaves are labeled by elements of A.It is straightforward to see that an upper and lower bound of 1/2 holds for the randomized 1-caterpillar, i.e., the uniform distribution over the m possible voting 1-caterpillars.
Indeed, such a tree is equivalent to selecting an alternative uniformly at random.
Since we have i∈A s i = m 2 , the expected score of a random alternative is (m − 1)/2, whereas the maximum possible score is m − 1.
This randomization, however, like other randomizations over small trees that conceivably provide a good approximation ratio, is not admissible and actually puts probability one on trees that are not surjective.
This leads to absurdities from a social choice point of view; for instance, in a tournament where there are both a Condorcet winner, an alternative that beats every other, and a Condorcet loser, which loses to every other alternative, the probabilities (under the above inadmissible randomization) of electing the former and the latter are equal, namely 1/m.
By contrast, any admissible randomization would elect a Condorcet winner with probability 1 whenever one exists, and a Condorcet loser with probability 0.
To prove Theorem 4.1, we instead use the uniform randomization over surjective k-caterpillars, henceforth denoted k-RSC, which is clearly admissible.
Theorem 4.1 can then be restated as a more explicit-and slightly stronger-result about the k-RSC.
The lemma directly implies Theorem 4.1 by letting = 1 and recalling that the maximum score is m − 1.
The remainder of this section is devoted to the proof of this lemma.
For the sake of analysis, we will use the randomized k-caterpillar, or k-RC, as a proxy to the k-RSC.
We recall that the k-RC is equivalent to a k-caterpillar with labels for the leaves chosen independently and uniformly at random.
In other words, it corresponds to the uniform distribution over all possible voting k-caterpillars, rather than just the surjective ones.Clearly the k-RC corresponds to a randomization that is not admissible.
In contrast to very small trees, however, like the one consisting only of a single leaf, it is straightforward to show that the distribution over alternatives selected by the RC is very close to that of the RSC.
the probability that alternative i ∈ A is selected by the k-RC and by the k-RSC, respectively, for some tournament T ∈ T (A).
Then, for all i ∈ A, |¯ p(k) i − p (k) i | ≤ m e k/m .
Proof.
For all i ∈ A, |¯ p (k) i − p (k)i | is at most the probability that the k-RC does not choose a surjective tree.
By the union bound, we can bound this probability byi∈A Pr[i does not appear in the k-RC] ≤ m · 1 − 1 m k ≤ m e k/m .
With Lemma 4.3 at hand, we can temporarily restrict our attention to the k-RC.
A direct analysis of the k-RC, and in particular of the competition between the winner of the (k − 1)-RC and a random alternative, shows that for every k, the k-RC provides an approximation ratio of at least 1/3.
It seems, however, that this analysis cannot be extended to obtain an approximation ratio of 1/2.
In order to reach a ratio of 1/2, we shall therefore proceed by employing a second abstraction.
Given a tournament T , we define a Markov chain M = M(T ) as follows: 3 The state space Ω of M is A, and its initial distribution π (0) is the uniform distribution over Ω.
The transition matrix P = P (T ) is given byP (i, j) =      s i +1 m if i = j 1 m if jT i 0 if iT j.We claim that the distribution π (k) of M after k steps is exactly the probability distribution ¯ p (k+1) over alternatives selected by the (k + 1)-RC.
In order to see this, note that the 1-RC chooses an alternative uniformly at random.
Then, the winner of the k-RC is the winner of the (k − 1)-RC if the latter dominates, or is identical to, the alternative assigned to the other child of the root.
This happens with probability (s i +1)/m when i is the winner of the k-RC.
Otherwise the winner is some other alternative that dominates the winner of the k-RC, and each such alternative is assigned to the other child of the root with probability 1/m.
We shall be interested in the performance guarantees given by the stationary distribution π of M.
We first show that M is guaranteed to converge to a unique such distribution, despite the fact that it is not necessarily irreducible.
Proof.
Let A be a set of alternatives.
We first observe that any tournament T ∈ T (A) has a unique strongly connected component tc(T ) ⊆ A, the top cycle of T , such that there is a directed path in T from every i ∈ tc(T ) to every j ∈ A. Clearly, a is a recurrent state of M = M(T ) if and only if a ∈ tc(T ).
It follows that for every > 0 there exists k ∈ N such that i∈tc(T ) π (k) i ≥ 1 − .
Since the subgraph of T induced by tc(T ) is strongly connected, and since there is a positive probability of going from any state of M to the same state in one step, the restriction of M to state space tc(T ) is ergodic and thus has a unique stationary distribution.
Moreover, M is guaranteed to converge to this distribution as soon as it has reached a state in tc(T ), which in turn happens with probability tending to one as the number of steps tends to infinity.
Finally, it is easily verified that the distribution which assigns probability zero to every i / ∈ tc(T ) and equals the stationary distribution of the restriction of M to tc(T ) for every i ∈ tc(T ) is a stationary distribution of M.We are now ready to show that an alternative drawn from the stationary distribution will have an expected degree of at least half the maximum possible degree.
To analyze π, we first require the following lemma.
Proof.
Letq i = 2π i ·   j:iT j π j   + π 2 i .
Then m i=1 q i = i =j π i π j + m i=1 π 2 i = m i=1 π i 2 = 1.
On the other hand, since π is a stationary distribution,π i = s i + 1 m π i + 1 m j:iT j π j ,and thusj:iT j π j = (m − s i − 1) · π i .
Hence, q i = (2m − 2s i − 1)π 2 i , which completes the proof.We are now ready to prove Lemma 4.5.
Proof of Lemma 4.5.
For any i ∈ A, define w i = m − s i − 1.
It then holds thati π i s i + i π i w i = (m − 1) i π i = m − 1.
(1)By the Cauchy-Schwarz inequality,i (2w i + 1)π i ≤ i (2w i + 1) · i (2w i + 1)π 2 i .
Using Lemma 4.6,i (2w i + 1)π 2 i = 1.
Furthermore, i (2w i + 1) = 2m 2 − 2 m 2 − m = m 2 ,and thusi (2w i + 1)π i ≤ √ m 2 · √ 1 = m and i w i π i ≤ m 2 − i π i 2 = m − 1 2 .
(2)By combining (1) and (2) we obtaini π i s i ≥ m − 1 2 .
The last ingredient in the proof of Lemma 4.2 and Theorem 4.1 is to show that for some k polynomial in m, the distribution over alternatives selected by the k-RC, which we recall to be equal to the distribution of M after k − 1 steps, is close to the stationary distribution of M.
In other words, we want to show that for every tournament T , M(T ) is rapidly mixing.
4 The proof works by reversibilizing the transition matrix of M and then bounding the spectral gap of the reversibilized matrix via its conductance.Lemma 4.7.
Let T be a tournament.
Then, for every > 0 there exists k = k(m, ) polynomial in m and 1//, such that for all k > k and all i ∈ A, |π (k ) i − π i | ≤ , where π (k) is the distribution of M(T ) after k steps and π is the stationary distribution of M(T ).
Proof.
We make use of the fact that for every tournament T ∈ T (A) and every alternative i ∈ A with maximum degree, there exists a path of length at most two from i to any other alternative.
To see this, assume for contradiction that i ∈ A has maximum degree, and that j ∈ A is not reachable from i in two steps.
Then jT i, and for all j ∈ A, iT j implies jT j .
Thus, s j > s i , a contradiction.
Since M = M(T ) traverses the edges of T backwards, this observation implies that at any given time M either is in a state corresponding to an alternative with maximum degree, or it will reach such a state within two steps with probability at least 1/m 2 .
It further implies that any alternative with maximum degree is in tc(A), defined as in the proof of Lemma 4.4.
We recall that once M reaches the top cycle, it stays there indefinitely.
Hence, for every > 0 there exists k polynomial in m and 1//, such that for all k > k and all i / ∈ tc(T ), |π(k ) i − π i | = |π (k )i | ≤ , where the equality follows from the fact that the support of π is contained in tc(T ) (see the proof of Lemma 4.4).
We further observe that π is positive on tc(T ), i.e., for all i ∈ tc(T ), π i > 0.
Too see this, consider the largest subset of tc(T ) that is assigned probability zero by π, and assume that this set is nonempty.
Then, for π to be a stationary distribution, no alternative in this subset can dominate an alternative in tc(T ) but outside the subset, contradicting the fact that tc(T ) is strongly connected.
By the above arguments, we can thus focus on the restriction of M to tc(T ).
For notational convenience, we henceforth assume without loss of generality that M, rather than its restriction, is irreducible and has a stationary distribution that is positive everywhere.Conveniently, the state space Ω of M has size m, and all entries of its transition matrix P are either 0 or polynomial in m. However, there exist tournaments T such that the stationary distribution of M(T ) has entries that are positive but exponentially small.
Furthermore, things are complicated by the fact that M is usually not reversible.
We follow Fill (1991) in defining the time reversal of P as˜P as˜ as˜P(i, j) = π j P (j, i) π i ,and the multiplicative reversibilization of P as M = M (P ) = P ˜ P .
Then, both P and˜Pand˜ and˜P are ergodic with stationary distribution π, and M is a reversible transition matrix that has stationary distribution π as well.
Denote by β 1 (M ) the second largest eigenvalue of M .
Then, by Theorem 2.7 of Fill (1991),4π (k) − π 2 ≤ (β 1 (M )) k |Ω|,(3)where σ −π = 1 2 i |σ i −π i | is the variation distance between a given probability mass function σ and π.
Since |Ω| = m, it is sufficient to show that β 1 (M ) is polynomially bounded away from 1.
To this end, we will look at the conductance 5 of M , which measures the ability of M to leave any subset of the state space that has small weight under π.
For a nonempty subset S ⊆ A, denote ¯ S = A \ S and π S = i∈S π i , and define Q(i, j) = π i M (i, j) and Q(S, ¯ S) = i∈S,j∈ ¯ S Q(i, j).
The conductance of M is then given by Φ = minS⊂A: π(S)≤1/2 Q(S, ¯ S) π S .
It is known from the work of Sinclair and Jerrum (1989) that for a Markov chain reversible with respect to a stationary distribution that is positive everywhere,1 − 2Φ ≤ β 1 (A) ≤ 1 − Φ 2 2 .
It thus suffices to bound Φ polynomially away from 0.
For any S with π S ≤ 1/2 it holds thatQ(S, ¯ S) π S ≥ Q(S, ¯ S) 2π S π ¯ S = i∈S,j∈ ¯ S Q(i, j) 2 i∈S,j∈ ¯ S π i π j ≥ min i∈S,j∈ ¯ S Q(i, j) 2π i π j .
In our case,Q(i, j) = π i r∈A P (i, r) ˜ P (r, j) ≥ π i [P (i, i) ˜ P (i, j) + P (i, j) ˜ P (j, j)] ≥ 1 m [π i P (i, j) + π j P (j, i)].
(4)A crucial observation is that for every i = j, either P (i, j) = 1/m or P (j, i) = 1/m, since either iT j or jT i. Now, let i 0 ∈ S and j 0 ∈ ¯ S be the two alternatives for which the minimum above is attained.
If P (i 0 , j 0 ) = 1/m, then by (4),Q(i 0 , j 0 ) 2π i 0 π j 0 ≥ π i 0 m 2 2π i 0 π j 0 = 1 2m 2 π j 0 , whereas if P (j 0 , i 0 ) = 1/m, then Q(i 0 , j 0 ) 2π i 0 π j 0 ≥ 1 2m 2 π i 0 .
In both cases, Φ ≥ 1/(2m 2 ), which completes the proof.We now have all the necessary ingredients in place.Proof of Lemma 4.2 and Theorem 4.1.
Let > 0.
By Lemma 4.3 and Lemma 4.7, there exists k polynomial in m and 1// such that for all i ∈ A, |p(k) i − ¯ p (k) i | ≤ /(2 m 2 ) and |¯ p (k) i − π i | ≤ /(2 m 2 ).
By the triangle inequality, |p(k) i − π i | ≤ / m 2 .
Now, i π i s i − i p (k) i s i ≤ i |π i − p (k) i |s i ≤ m 2 i s i = .
Lemma 4.2 and thus Theorem 4.1 follow directly by Lemma 4.5.
It turns out that the analysis in the proof of Theorem 4.1 is tight.
Indeed, since we have seen that the stationary distribution π of M is very close to the distribution of alternatives chosen by the k-RSC, it is sufficient to see that π cannot guarantee an approximation ratio better than 1/2 in expectation.
Consider a set A of alternatives, and a partition of A into three sets A , A , and {a} such that |A | = (1 − )(m − 1) and |A | = (m − 1) for some > 0.
Consider further a tournament T ∈ T (A) where a dominates every alternative in A and is itself dominated by every alternative in A , and such that the subgraph induced by A ∪ A is regular, i.e., has each alternative dominate exactly (|A | + |A | − 1)/2 other alternatives.
The structure of T is illustrated in Figure 2.
It is easily verified that the stationary distribution π of M(T ) satisfiesπ a = j:aT j π j m − s a − 1 ≤ 1 m − s a − 1 ≤ 1 (m − 1), and therefore, Furthermore, a has degree (1 − )(m − 1).
If we choose appropriately, say = 1/ √ m, the approximation ratio tends to 1/2 as m tends to infinity.i π i s i ≤ 1 (m − 1) (m − 1) + (m − 1) − 1 (m − 1) · m − 1 2 + 1 ≤ m − 1 2 + 1 + 1.
We proceed to demonstrate that the above tournament is a generic bad example.
Indeed, the following stability property will be shown to hold in addition to Lemma 4.5: in every tournament where π achieves an approximation ratio only slightly better than 1/2, almost all alternatives have degree close to m/2, as it is the case for the example above.
In particular, this implies that M either provides an expected approximation ratio better than 1/2, or selects an alternative with score around m/2 with very high probability.Theorem 4.8.
Let > 0, m ≥ 1/(2 √ ).
Let T be a tournament over a set of m alternatives, π the stationary distribution of M(T ).
If i π i s i = (m − 1)/2 + m, then i ∈ A : s i − m 2 > 3 4 √ 4 2 m ≤ 4 √ 4 · m.We shall require two lemmata.
The first one is a "geometric" version of the Cauchy-Schwarz inequality.
The second one is a well-known result about the sequence of degrees of a tournament, which we state without proof.Lemma 4.9.
Let a = (a 1 , . . . , a m ) ∈ R m , b = (b 1 , . . . , b m ) ∈ R m .
Then, m i=1 a i a − b i b 2 = if and only if m i=1 a i b i = (1 − 2 )a · b.Proof.
We have the following chain of equivalences: By Lemma 4.9,m i=1 a i a − b i b 2 = ⇐⇒ m i=1 (a i ) 2 a 2 + m i=1 (b i ) 2 b 2 − 2 m i=1 a i a b i b = ⇐⇒ m i=1 a i a b i b = 1 − 2 ⇐⇒ m i=1 a i b i = (1 − 2 )a · b.i a i a − b i b 2 = 4.
Denoting = 4, i √ 2w i + 1 m − √ 2w i + 1 · π i 2 = .
By simplifying and rearranging, we geti (2w i + 1) π i − 1 m 2 = .
(5)Now let = 4 √ andB = i ∈ A : π i − 1 m > m .
We claim that |B| ≤ m. Assume for contradiction that |B| > m. Then, by Lemma 4.10,i∈B s i = m 2 − i / ∈B s i ≤ m 2 − m − |B| 2 and i∈B w i ≥ |B|(m − 1) − m 2 + m − |B| 2 = |B| 2 .
We thus have On the other hand,i∈B (2w i + 1) π i − 1 m 2 > √ m 2 i∈B (2w i + 1) ≥ √ m 2 2 |B|(|B| − 1) 2 + |B| > √ m 2 · √ m 2 = ,j / ∈B π j ≥ (1 − )m · 1 − m = (1 − ) 2 ,and therefore(m − s i − 1) ≤ s i 1+ m + 1 − (1 − ) 2 1− m .
The last implication is true because i dominates at most s i alternatives outside B, and the overall probability assigned to alternatives in B is at most 1 − (1 − ) 2 .
Now,(m − s i − 1)(1 − ) ≤ s i (1 + ) + m(2 − ( ) 2 ).
Thus, for m ≥ 1 ( ) 2 , s i ≥ m 2 − 3 2 m.
So far we have been concerned with the Copeland solution, which selects an alternative with maximum degree.
A related solution concept, sometimes referred to as second order Copeland, has also received attention in the social choice literature (see, e.g., Bartholdi et al., 1989).
Given a tournament T , this solution breaks ties with respect to the maximum degree toward alternatives i with maximum second order degree j:iT j s j .
Second order Copeland was the first voting ruleand still is one of only two natural voting rules-known to be easy to compute but difficult to manipulate ( Bartholdi et al., 1989).
Interestingly, the same randomization studied in Section 4.1 also achieves a 1/2-approximation for the second order degree.Theorem 4.11.
Let A be a set of alternatives, T ∈ T (A).
For k ∈ N, let p (k) i denote the probability that alternative i ∈ A is selected by the k-RSC for T .
Then, there exists k = k(m) polynomial in m such that p(k) i j:iT j s j max i∈A j:iT j s j ≥ 1 2 + Ω(1/m).
Clearly, the sum of degrees of alternatives dominated by an alternative i is at most m−1 2 .
The lower bound is then obtained from an explicit result about the second order degree of alternatives chosen by the k-RSC.
Along similar lines as in the proof of Theorem 4.1, it suffices to prove that the stationary distribution of M(T ) provides an approximation.
The following lemma is the second order analog of Lemma 4.5.
It turns out, however, that the technique used in the proof of Lemma 4.5, namely directly manipulating the stationary distribution equations and applying Cauchy-Schwarz, does not work for the second order degree.
We instead formulate a suitable LP and bound the primal by a feasible solution to the dual.Lemma 4.12.
Let T be a tournament, π the stationary distribution of M(T ).
Then,i∈A π i j:iT j s j ≥ m 2 4 − m 2 .
Proof.
Fix some tournament T ∈ T (A), and consider the degrees s i in T .
The minimum expected second order degree of an alternative drawn according to the stationary distribution of M(T ) is given by the following linear program with variables π i :min i∈A π i   j:iT j s j   s.t. ∀i, (m − s i − 1)π i − j:iT j π j = 0, i∈A π i = 1, ∀i, π i ≥ 0.
The dual is the following program with variables x i and y:max y s.t. ∀i, (m − s i − 1)x i − j:jT i x j + j:iT j s j ≥ y.By weak duality, any feasible solution to the dual provides a lower bound on the optimal assignment to the primal.
Consider the assignment x i = −s i to the dual.
The maximum feasible value of y given this assignment is the minimum over the left hand side of the constraints.
We claim that for any i, the value of the left hand side is at least m 2 /4 − m/2.
Indeed, for all i,(m − s i − 1)(−s i ) − j:jT i (−s j ) + j:iT j s j = (m − s i − 1)(−s i ) + j =i s j = (m − s i − 1)(−s i ) + m 2 − s i = m 2 /2 − m/2 − s i (m − s i ) ≥ m 2 /4 − m/2.
We point out that the analysis is tight.
Indeed, the second order degree of any alternative in a regular tournament, i.e., one where each alternative dominates exactly (m−1)/2 other alternatives, is (m − 1)/2 · (m − 1)/2 = m 2 /4 − m/2 + 1/4.
Theorem 4.11 itself is also tight, by the example given in Section 4.2.
In the previous section we presented our positive results, all of which were obtained using randomizations over caterpillars.
Since caterpillars are maximally unbalanced, one would hope to do much better by looking at balanced trees, i.e., trees where the depth of any two leaves differs by at most one.
We briefly explore this intuition.
Consider a balanced binary tree where each alternative in a set A appears exactly once at a leaf.
We will call such a tree a permutation tree on A.
As we have already mentioned in the previous section, permutations trees provide a very weak deterministic lower bound.
Indeed, the winning alternative must dominate the Θ(log m) alternatives it meets on the path to the root, all of which are distinct.
Since there always exists an alternative with score at least (m − 1)/2, we obtain an approximation ratio of Θ((log m)/m).
On the other hand, no voting tree in which every two leaves have distinct labels can guarantee to choose an alternative with degree larger than the height of the tree, so the above bound is tight.
More interestingly, it can be shown that no composition of permutation trees, i.e., no tree obtained by replacing every leaf of an arbitrary binary tree by a permutation tree, can provide a lower bound better than 1/2.
Unfortunately, larger balanced trees not built from permutation trees have so far remained elusive.Can we obtain a better bound by randomizing?
Intuitively, a randomization over large balanced trees should work well, because one would expect that the winning alternative dominate a large number of randomly chosen alternatives on the way to the root.
Surprisingly, the complete opposite is the case.
In the following, we call randomized perfect voting tree of height k, or k-RPT, a voting tree where every leaf is at depth k and labels are assigned uniformly at random.
This tree obviously corresponds to a randomization that is not admissible, but a similar result for admissible randomizations can easily be obtained by using the same arguments as before.Theorem 5.1.
Let A be a set of alternatives, |A| ≥ 5.
For every K ∈ N there exists K ≥ K such that the K -RPT provides an approximation ratio of at most O(1/m).
To prove the theorem, we will show that given a tournament consisting of a 3-cycle of components, the distribution over alternatives chosen by the k-RPT oscillates between the different components as k grows.
This is made precise in the following lemma.Lemma 5.2.
Let A be a set of alternatives, T ∈ T (A) containing three components C i , i = 1, 2, 3, such that for all alternatives a ∈ C i and b ∈ C (i mod 3)+1 , aT b. For i = 1, 2, 3 and k ∈ N, denote by p (k) i the probability that the k-RPT selects an alternative from C i .
If for some K ∈ N and > 0, p(K) 1 ≤ ≤ 2 −12 , then there exists K > K such that p (K ) 3 ≤ /2 and p (K ) 2 ≥ 1 − √ .
Proof.
The event that some alternative from C i is chosen by a perfect tree of height k + 1 can be decomposed into the following two disjoint events: either an element from C i appears at the left child of the root, and an element from C i or C (i mod 3)+1 at the right child, or an element from C i appears at the right child and one from C (i mod 3)+1 at the left.
Thus, for all k > 0,p (k+1) i = p (k) i p (k) i + p (k) (i mod 3)+1 + p (k) i · p (k) (i mod 3)+1 = p (k) i p (k) i + 2p (k) (i mod 3)+1 .
(6)It should be noted that (6) is independent of the structure of T inside the different components, but only depends on the relationship between them.
Now, consider the largest, possibly empty, set S = {K, K + 1, K + 2, . . . , } such that for all k ∈ S, p(k) 1 + p (k) 2 ≤ 1/2.
It then holds for all k ∈ S that 2p (k) 1 + 2p (k) 2≤ 1, and, by (6), thatp (k+1) 1 ≤ p (k) 1 ≤ p (K) 1 ; that is, p (k) 1is weakly decreasing for indices in S, and since we assumed p(K) 1 ≤ ≤ 2 −12 , we have that p (k+1) 1 ≤ ≤ 2 −12 for all k ∈ S.
Since p (k) 2 < 0.5 and p (k) 3 ≥ 0.5, we have that for all k ∈ S, p (k) 2 + 2p (k) 3 > 1.3.
Hence, we conclude by (6) that for all k ∈ S, p (k+1) 2≥ 1.3 · p (k) 2 .
Choosing K 1 to be the smallest integer such that K 1 ≥ K and K 1 / ∈ S, we have that p(K 1 ) 1 ≤ and p (K 1 ) 3≤ 1/2.
Also, by (6), for all i = 1, 2, 3 and all k ∈ N, p(k+1) i ≤ 2p (k) i .
Choosing L ≥ 12 such that 2 −(L+1) ≤ ≤ 2 −L , we have for all k = K 1 , . . . , K 1 + L/2 − 1, p (k) 1 ≤ · 2 L/2−1 ≤ 2 −−L/2 2 ≤ √ /2.
(7)By the assumption that ≤ 2 −12 , this also implies for all such k that p (k)1 ≤ 2 −7 .
We now claim that K = K 1 + L/2 − 1 is as required in the statement of the lemma.
Indeed, by applying (6), we havep (K 1 +1) 3 = p (K 1 ) 3 (p (K 1 ) 3 + 2p (K 1 ) 1 ) ≤ 1 2 ( 1 2 + 2 −6 ) ≤ 0.258,and thus p(K 1 +2) 3 = p (K 1 +1) 3 (p (K 1 +1) 3 + 2p (K 1 +1) 1) ≤ 0.258(0.258 + 2 −6 ) < 0.08.
Finally, p(K 1 +3) 3 = p (K 1 +2) 3 (p (K 1 +2) 3 + 2p (K 1 +2) 1) ≤ 0.08(0.08 + 2 −6 ) < 0.0077.
Now, for k = K 1 + 3, . . . , K 1 + L/2 − 2, p We will now prove a stronger version of Theorem 5.1.
Lemma 5.3.
For k ∈ N, denote by ∆ k the distribution corresponding to the k-RPT.
Then, for every set A of alternatives, |A| ≥ 5, there exists a tournament T ∈ T (A) such that for every K ∈ N and > 0, there exists K ≥ K such thatE Γ∼∆ K [s Γ(T ) ] max i∈A s i ≤ 1 + m − 2 .
Proof.
Let m ≥ 5, and define a tournament as in the statement of Lemma 5.2 with components C 1 = {1}, C 2 = {2}, and C 3 = {3, . . . , m}, such that C 3 is transitive.We first show that there exists K 0 such that, using the notation of Lemma 5.2, p (K 0 ) 1 ≤ 2 −12 .
If m ≥ 2 12 , this holds trivially for K 0 = 0, since the uniform distribution selects each alternative with probability 1/m ≤ 2 −12 .
For m < 2 12 , the claim is easily verified using a computer simulation.
Now, by Lemma Iteratively applying the lemma in this fashion, we get that there exists K ≥ K such that p Many interesting questions arise from our work.
Perhaps the most interesting open problem in the context of this paper concerns tighter bounds for deterministic trees.
Some results for restricted classes of trees have been discussed in Section 5, but in general there remains a large gap between the upper bound of 3/4 derived in Section 3 and the straightforward lower bound of Θ((log m)/m).
In the randomized model our situation is somewhat better.
Nevertheless, an intriguing gap remains between our upper bound of 5/6, which holds even for inadmissible randomizations over arbitrarily large trees, and the lower bound of 1/2 obtained from an admissible randomization over trees of polynomial size.
It might be the case that the height of a k-RPT could be chosen carefully to obtain some kind of approximation guarantee.
For example, one could investigate the uniform distribution over permutation trees.
The analysis of this type of randomization is closely related to the theory of dynamical systems, and we expect it to be rather involved.
More generally, the problem of characterizing voting rules implementable by trees remains open.
While we have seen that techniques from theoretical computer science can contribute to the solution of this problem, they are perhaps even more promising for attacking questions concerning the implementability of probabilistic rules by randomized trees or upper and lower bounds on the size of trees implementing certain rules.
caterpillars with order reduced by one.
To analyze the behavior of these higher order caterpillars on a particular tournament T , we again employ a Markov chain abstraction.
Given a tournament T , we inductively define Markov chains M k = M k (T ) for k ∈ N as follows: for all k, the state space of M k is A.
The initial distribution and transition matrix of M 1 are given by those of M as defined in Section 4.1.
For k > 1, the initial distribution of M k is given by the stationary distribution π (k−1) of M k−1 , which can be shown to exist and be unique using similar arguments as in Section 4.1.
Its transition matrix P k = P k (T ) is defined as We thank Julia Böttcher, Felix Brandt, Shahar Dobzinski, Dvir Falik, Paul Harrenstein, Jeff Rosenschein, and Michael Zuckerman for many helpful discussions.
sIn Section 5 we studied the ability of randomizations over balanced trees to improve the lower bound of Section 4, with somewhat unexpected results.
A different approach to improve the randomized lower bound is to take a tree structure that provides a good lower bound, and construct a more complex tree by composing several trees of this type to form a new structure.
Since a particular randomized tree chooses alternatives according to some probability distribution, this technique is conceptually closely related to probability amplification as commonly used in the area of randomized algorithms.In our case, the obvious candidate to be used as the basis for the composition is the RSC, both because it provides the strongest lower bound so far, and because it can conveniently be analyzed using the stationary distribution of a Markov chain.
We will thus focus on higher order caterpillar trees obtained by replacing each leaf of a caterpillar of sufficiently large height by higher orderThe class of tournaments used in Section 4.2 to show tightness of our analysis of ordinary caterpillars can also be used to show that the approximation ratio cannot be improved significantly by means of higher order caterpillars of small order.
Perhaps more surprisingly, a different class of tournaments can be shown to cause the stationary distribution of M k to oscillate as k increases, leading to a deterioration of the approximation ratio.
This phenomenon is similar to the one witnessed by the proof of Theorem 5.1.
Theorem A.1.
Let A be a set of alternatives, |A| ≥ 6, and let K ∈ N.
Then there exists a tournament T ∈ T (A) and k ∈ N such that K ≤ k ≤ K + 5 and the stationary distributionProof.
Consider a tournament T with three components C i , 1 ≤ i ≤ 3 such that C i T C j if j = (i mod 3) + 1 (as in the proof of Theorem 5.1).
For i = 1, 2, 3 and k ∈ N, denote by p Then, for all k ∈ N and i = 1, 2, 3, and taking the subsequent index modulo three,and thusTaking two steps, replacing pi+1 , and simplifying, we getand thus pAnalogously,Summing (8) and (9) and adding one,and thus p Observing that the sole vertex in C 2 has degree m − 2 completes the proof.
In Section 5 we studied the ability of randomizations over balanced trees to improve the lower bound of Section 4, with somewhat unexpected results.
A different approach to improve the randomized lower bound is to take a tree structure that provides a good lower bound, and construct a more complex tree by composing several trees of this type to form a new structure.
Since a particular randomized tree chooses alternatives according to some probability distribution, this technique is conceptually closely related to probability amplification as commonly used in the area of randomized algorithms.In our case, the obvious candidate to be used as the basis for the composition is the RSC, both because it provides the strongest lower bound so far, and because it can conveniently be analyzed using the stationary distribution of a Markov chain.
We will thus focus on higher order caterpillar trees obtained by replacing each leaf of a caterpillar of sufficiently large height by higher orderThe class of tournaments used in Section 4.2 to show tightness of our analysis of ordinary caterpillars can also be used to show that the approximation ratio cannot be improved significantly by means of higher order caterpillars of small order.
Perhaps more surprisingly, a different class of tournaments can be shown to cause the stationary distribution of M k to oscillate as k increases, leading to a deterioration of the approximation ratio.
This phenomenon is similar to the one witnessed by the proof of Theorem 5.1.
Theorem A.1.
Let A be a set of alternatives, |A| ≥ 6, and let K ∈ N.
Then there exists a tournament T ∈ T (A) and k ∈ N such that K ≤ k ≤ K + 5 and the stationary distributionProof.
Consider a tournament T with three components C i , 1 ≤ i ≤ 3 such that C i T C j if j = (i mod 3) + 1 (as in the proof of Theorem 5.1).
For i = 1, 2, 3 and k ∈ N, denote by p Then, for all k ∈ N and i = 1, 2, 3, and taking the subsequent index modulo three,and thusTaking two steps, replacing pi+1 , and simplifying, we getand thus pAnalogously,Summing (8) and (9) and adding one,and thus p Observing that the sole vertex in C 2 has degree m − 2 completes the proof.
