In this paper, we assert that usability and security for poll workers are intimately linked in enabling free, fair, and secure elections.
By focusing on these important but often neglected users of voting systems in designing voting systems, unintended security problems can be avoided.
The overall goal of our research was to create a framework for voting system manufacturers to meet the requirements of the Voluntary Voting System Guidelines (VVSG) for the usability of voting system documentation.
As part of our research, we tested voting system documentation with poll workers, which revealed troubling usability issues that could create security problems.
The voting system documentation style guidelines we developed are based on research-based best practices for creating usable documentation.
Each guideline includes direction for voting system manufacturers on how to implement the guideline and how to evaluate if it has been met.
While much research on elections has concentrated on voters and the voting process -usually emphasizing security concerns -usability for poll workers is equally important.
Yet, little research has addressed the connections between usability and security.
This paper focuses on how improving the usability of documentation can help to eliminate unintended security problems.
(Note that usable documentation can improve other aspects of voting system operation as well, but security is a key area that needs examining.)
To support security in elections, usability for poll workers is critical.
Poll workers are temporary election officials whose task is to ensure secure and private voting in voting places in the United States.
Poll workers set up voting stations, make sure the equipment is operating properly, assist voters, shut down voting stations when the polls close, and secure voting datawhile working extremely long hours on Election Day, after minimal training and for very little pay.
Election Day effectively means "live" usability testing in most jurisdictions, and when a poll worker makes a mistake on Election Day, there is often no simple, quick way to recover.
Along the way, poll workers often encounter problems with voting systems that delay or even prevent voters from voting or cause votes to go uncounted.
For example, poll workers who are not well trained might prevent voters from voting when they cannot open the polls, issue incorrect ballots, or prevent use of voting machines for people who have disabilities [1,2].
Poll workers may also break the chain of custody or otherwise compromise security if usability of voting systems is lacking.
For example, exceptional situations that are difficult to train for and are probably not well covered in system documentation may lead to security exposures, such as battery back-up units not being properly installed.
If battery back-ups are not properly installed and the power goes out, the security of the systems cannot be completely assured.Most security problems that stem from usability issues are parts of standard procedures, such as replacing the rolls of paper on which the audit trail is printed on direct record electronic (DRE) voting machines.
National Public Radio reported that in Cuyahoga County, Ohio, in at least one case in the 2006 mid-term election, a thermal paper roll had been installed backward, so nothing printed out onto it.
In other locations, there were reports of paper jamming so that votes printed over one another [3].
The Washington Post reported in 2008 that data cartridges that store votes were unreadable at one precinct in Washington, DC.
The voting system manufacturer suggested two possible causes: static discharge or election workers mishandling the cartridges.
Better documentation and attention to poll worker tasks would have helped to avoid such errors.
These situations can lead to unintended security breaches and can also easily be exploited to compromise security [4].
In http://vote.nist.gov/vvsg-report.htm.
It is undergoing a public review process; its current status can be found at http://www.eac.gov.
Most of the two million people who were temporary election workers for the November 2008 general election got training to be poll workers in their local jurisdictions [5].
The training materials developed in the local election departments are usually based on the manufacturers' technical documentation.
The overall goal of our research was to create a framework for voting system manufacturers to meet the requirements of the VVSG for voting system documentation.
There were two objectives: through style guidelines, to provide a tool for voting system manufacturers to develop usable manuals that support poll worker tasks; and to create a method for test laboratories to ensure that the VVSG usability of documentation requirement is being met by a voting system undergoing certification.
This article focuses on the first objective.The guidelines developed in this project [6] are based on research primarily from the areas of technical communication, information design, and usability.
Leading up to developing our set of guidelines, we reviewed and analyzed six sets of research-based style guidelines (listed in the Appendix), many of which were created and are used in US federal government agencies, such as the Securities and Exchange Commission (SEC).
The style guide, while mainly developed for improving poll worker documentation, is applicable to all voting system manuals.Each guideline in the style guide includes direction for voting system manufacturers on how to implement the guideline and how to evaluate if it has been met.
The discussion includes examples of poor usability in voting system documentation and suggestions of ways to revise.The specific guidelines were chosen because:• They can help communicators solve many highlevel problems that in turn eliminate typical, smaller problems.
• They are widely and consistently agreed upon and supported, based on the research we reviewed for this project.
• They provide reasonable guidance that can fit into standard writing and review cycles, making it as easy as possible for voting system manufacturers to provide usable documentation that could assist in preventing unintentional security breaches.In addition, testing methods are available to evaluate objectively whether these guidelines have been implemented effectively.
We used these methods in a separate activity to test voting system documentation with poll workers, which did reveal troubling usability issues that could create security problems.
We discuss some of those findings later in this paper.
We organized each guideline so communicators and editors (the manual developers) could take direct action, quickly assessing whether their documentation meets that guideline.
Each guideline also prescribes what to do if it is not met.
For most of the guidelines, the discussion covers:• What the basis of the guideline is.
For example, what a communicator would need to know to understand the users (the first guideline).
• How communicators can find out what they need to know to implement the guideline.
For example, for Understand your users, we recommend that technical communicators visit polling places on Election Day to either get experience as election workers or observe a voting place.
By doing so, communicators get crucial context and specific understanding of tasks and dependencies in a real setting.
This section also often discusses how to implement the guideline.
For example, for Organize the documentation logically and clearly, we direct communicators to organize documentation to reflect the order in which users complete tasks.
• Good examples demonstrate the guideline by showing a sample or an illustration that works well and meets the guideline.
• Revising (a not-so-good example) explains why a sample does not meet the guideline and suggests changes that should make the documentation clearer and easier to use.
• Why gives at least one reason for implementing the guideline.
Every Why is based on research findings.
• Evaluation checklists at the end of each guideline provide a list of yes-or-no questions that communicators and editors can use to review the documentation.
For example, the checklist for Organize the documentation logically and clearly, has these questions:o Is the documentation organized logically based on the user's tasks?o If the users must complete the tasks in a particular order, is the document organized chronologically based on that order?
o When chronological order is not important, is the document organized by the importance or frequency of the tasks?o Is the poll worker's guide in particular organized chronologically based on the poll workers' tasks?
• Tips give actions that communicators can take to implement the checklist, or they are pointers on how to recognize whether the content is meeting the guideline.
Figure 1 shows the structure of a guideline, designed to be easy to use by both the manual developers and test labs evaluating the usability of the documentation.
After reviewing the six sets of guidelines for technical communication and information design, and reading hundreds of pages of voting system documentation, we settled on eight categories of guidelines.
Although some of the sets of guidelines we reviewed included many more items to pay attention to in writing and presenting procedures and instructions, we decided to focus on a few key guidelines that, if followed earnestly, could make the biggest difference in helping poll workers to be effective and efficient in their Election Day tasks.
To see the full discussion for each guideline, you can download the report, NISTIR 7519, from http://vote.nist.gov.Here are our eight categorical guidelines, along with their underlying heuristics:1.
Writing the documentation for specific users [6,8,9,10,11,12] • Understand your users [14,19,20,21,22,24,25,26,27,28] • Use familiar, common words [13,17,25,30,31,32,33,34] • Make each instruction a separate step [14,15,18,35,36] • Use graphics to illustrate tasks [8,28,32,37,38,39,40,41] • Use informative headers and footers As we reviewed hundreds of pages of voting system documentation supplied to NIST by system manufacturers, we extracted examples for each of the guidelines to demonstrate how they should be implemented.For example, in the heuristic Understand your users' tasks, we assert that when a communicator understands the users' tasks, he or she can develop the documentation to cover the specific information poll workers need to do their jobs.
To illustrate, in one poll worker's guide, the first step of the day tells the poll workers to contact the manufacturer.
Not an auspicious beginning to an Election Day.
The task of inspecting and replacing the cord is not a poll worker's job.
Other staff must solve this problem.
Opening the Polls 1.
Inspect the power cord for damage.If the cord is damaged, discard it and contact the manufacturer for a new cord.
Opening the Polls 1.
Inspect the power cord for damage.
If the cord is damaged, contact Election Central.The guideline Keeping instructions short and simple emphasizes making each instruction a separate step.
Most users of technology take the first reasonable action they come to.
When each action is a new step, users can:• Find their place in the instructions when they switch their attention (for example, from the instructions, to the voting system or voter, and then back to the instructions).
• See that there are multiple actions that they need to take.
• See all the instructions and avoid missing any.Here is an example in which one step with three actions becomes three steps.
The phrase "When finished" isn't necessary when the actions are numbered steps.
1.
On the back of the voting unit, find the power receptacle (AC In).
Plug the power cord into power receptacle (AC In).
When finished, store the top cover in a safe location.
1.
On the back of the voting unit, find the power receptacle (AC In).
2.
Plug the power cord into the power receptacle (AC In).
3.
Store the top cover in a safe location.Two heuristics under Keeping instructions short and simple would have helped poll workers be more effective in finding the troubleshooting information in the testing we conducted.
If the authors of the documentation had Put steps in the order in which they must be completed and Put warnings before-not after-consequences (two other heuristics under the guideline Keeping instructions short and simple), the test participants may not have encountered the operational problems they did.
Information that is presented in a logical order is easier to understand.
This is especially true for series of steps in a procedure.
When the steps are in order, users can:• Avoid missing important steps.
• Concentrate on the current step and forget the previous one.
• Save the time and effort of figuring out what to do next.In this example from a poll worker's guide, the preparation for transmitting is in step 1; the transmitting is in step 2.
The poll workers need to prepare in step 1, but they don't need to know that the transmission starts until the end of the procedure.
headquarters by modem, the scanner will begin to transmit after it has finished printing the reports.
Unlock and open the Counter Access Panel, and connect the telephone cord to the modem jack below the scanner door.
2.
Press Close Polls.
The scanner will print the reports.
After printing, if you transmit results, the scanner will begin to transmit automatically.
To transmit results to election headquarters by modem:1.
Unlock and open the Counter Access Panel.2.
Connect the telephone cord to the modem jack below the scanner door.
3.
Press Close Polls.The scanner prints the reports and then transmits the results.The final guideline is Testing the documentation.
In a separate activity, we developed a usability test protocol for voting system documentation.
In an exploratory study, we applied it to actual voting systems, testing with participants who were typical poll workers.
The testing demonstrated that the protocol uncovers areas in which the documentation has errors, is confusing, or describes a task too difficult to perform.
In general, testing shows where documentation could be revised to better support poll workers in their tasks.
Testing can also reveal critical issues related to usability of voting systems, some of which affect security.
This is because adherence to the style guide does not necessarily insure that the interaction of the poll worker with the documentation and system to perform a task is usable.
This test protocol and the guidelines themselves are proposed for use in testing voting systems for conformance to the VVSG requirement for the usability of poll worker documentation.
In the exploratory study, we asked four pairs of poll workers-each pair working on a different day-to work together as they followed the instructions in the documentation to perform typical poll worker tasks: set up systems to open the polls and accept votes, conduct voting, and shut down systems and close the polls so that voting machines cannot accept any more votes.Among other things, we observed that the documentation had the basic problem that its authors seemed not to thoroughly understand their audiences and the tasks that those people were trying to accomplish.
This fundamental issue affected everything else that happened as poll worker participants tried to perform typical Election Day tasks using the instructions.
Some of the issues we saw that stemmed from the lack of attention to the users and their tasks included these:Poll workers had difficulty matching the machine to the documentation content.
This tells us that the documentation probably was not based on a thorough understanding of poll workers and their Election Day tasks (the first guideline).
Also, it is likely that the instructions were not short or simple enough (the fifth guideline) and the graphics and other illustrations were not clear or located effectively in the documentation (the sixth guideline).
The documentation didn't answer all of the taskrelated questions that the poll workers had.
For example, it was not obvious that the voting system had reached the end state that poll workers were looking for to know that they had reached their task goal.
This suggests that the documentation wasn't designed for easy scanning and reading (the seventh guideline) and probably wasn't task oriented (the second guideline).
It wasn't easy for the poll workers to respond to system messages by following the instructions in the voting system documentation.
Having looked at the documentation, the problem appears to be that it was too system-oriented (first and second guidelines), and probably not technically accurate.
The wording of the messages was not the same between the voting machine and the documentation -a classic problem in hardware and software development because the print documentation often lags behind the completion of the rest of the system.
Troubleshooting happened in the context of a task but the supporting information was not located with the task procedures.
For example, the poll worker participants had to generate some reports to open or close the polls.
The reports print out on paper tape that is on a roll.
Inevitably, the paper rolls had to be replaced at some point during the usability test session.
But the instructions for doing so were buried in the troubleshooting section at the end of the 100-page system manual.
So, the documentation was not organized logically and it did not take into account the users' tasks (the first and second guidelines).
Documentation covered too many systems.
From the manufacturer's point of view, it can make sense to cover all the systems in a product line in one manual.
But it is unlikely that a poll worker will have to deal with more than one voting system at a time.
Putting procedures and other information for multiple systems into one manual makes it more difficult to find specific answers to specific questions.
The entry point -a table of contents or an index -can be helpful, but in this case was not.
The table of contents was too long.
The system that the poll workers were using was one of two covered in the manual; in fact, it was the second.
The test participants stopped at the first reasonable heading, which happened to be for the system they were not going to be working with.
This performance suggests that the documentation fell short of several guidelines (most likely the first, second, fourth, and seventh).
It seemed clear that if the voting system manufacturers had conducted usability tests on the documentation themselves that many of the problems we observed would not have occurred.
You may have noticed that some of the issues that came out of our test were not specific to the documentation, such as problems with interpreting messages or on-screen instructions.
These types of usability issues with the voting system could lead to unintended security issues, as well.
We discuss this concern in the next section.
User-centered design must cover the whole systemBy focusing on poll worker activities as well as voter interactions during the voting system design process, designers and developers can ensure that those users can perform their tasks efficiently and effectively, including tasks related to the security of the voting process.
This will prevent many types of unintentional security breaches.A voting system is more than the voting machine.
The system includes voting equipment -both hardware and software, as well as data collection, security measures, and documentation.
Documentation is integral.Documentation can't stand alone.
It is not uncommon for developers and engineers to rely on the documentation to explain elements of systems that are complex, rather than designing a simpler system or interface.
It is the refrain of many a development team that something in the user interface that is not intuitively obvious to use is a "training issue."
However, poll worker training is minimal, training materials don't always make it to the voting place, and voting system documentation is often not easy to find and use in the midst of a high-pressure crisis at a precinct when accumulating vote data at the end of a 15-to 20-hour Election Day.To support security in elections, usability for poll workers -in the entire voting system, at every stepbecomes critical.Guidelines are good, but systems must be tested with users.
Our research-based style guidelines for voting system documentation provide a set of tools for manufacturers to use to create usable, user-centered, task-oriented documentation.
Keeping the user in mind in the design and development process is excellent, but not enough.
Verifying with end-users is critical to ensuring that the voting system documentation is usable.Our focus has been on usability for poll workers.
When, while working extremely long hours on Election Day, after minimal training and for very little pay, poll workers can perform important tasks in free, fair, and safe elections, the connection between usability and security seems clear.
Usable voting systems -system documentation and local training included -are the best insurance that there will be no unintentional security breaches by election workers.
Dana Chisnell and Susan Becker were funded under NIST contract SB1341-05-Z-0023-67310.
The entire team wishes to thank our many reviewers for their valuable feedback on this paper and on the deliverables generated for the research project.
d• GMAP (Government Management Accountability & Performance).
General guidelines.
Plain Talk, http://www.accountability.wa.gov/plaintalk/ptguidelines/default.
asp (accessed December 15, 2007).
This is the state of Washington's Plain Talk Guidelines (GMAP).
It is written for employees of state agencies writing for customers.
• Guidelines for Document Designers (Felker and others 1981),developed as part of the Document Design Project, which was funded by the Department of Education.
It was written for professionals who work in business, government, law, medicine, or related fields.
• HHS (Health and Human Services Department).
2006.
Research-Based Web Design & Usability Guidelines.Usability.gov, http://usability.gov/pdfs/guidelines.html (accessed September 25, 2007).
This was written for government agencies and the private sector.
• Office of the Federal Register.
1998.
"Making regulations readable" in Document drafting handbook, MMR-1-MMR-6.
http://www.archives.gov/federal-register/write/plainlanguage/readable-regulations.pdf (accessed October 17, 2007).
This is intended to help agencies prepare documents for publication in the Federal Register.
• • GMAP (Government Management Accountability & Performance).
General guidelines.
Plain Talk, http://www.accountability.wa.gov/plaintalk/ptguidelines/default.
asp (accessed December 15, 2007).
This is the state of Washington's Plain Talk Guidelines (GMAP).
It is written for employees of state agencies writing for customers.
• Guidelines for Document Designers (Felker and others 1981),developed as part of the Document Design Project, which was funded by the Department of Education.
It was written for professionals who work in business, government, law, medicine, or related fields.
• HHS (Health and Human Services Department).
2006.
Usability.gov, http://usability.gov/pdfs/guidelines.html (accessed September 25, 2007).
This was written for government agencies and the private sector.
• Office of the Federal Register.
1998.
"Making regulations readable" in Document drafting handbook, MMR-1-MMR-6.
http://www.archives.gov/federal-register/write/plainlanguage/readable-regulations.pdf (accessed October 17, 2007).
This is intended to help agencies prepare documents for publication in the Federal Register.
•
