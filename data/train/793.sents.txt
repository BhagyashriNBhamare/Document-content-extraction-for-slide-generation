Recent research has created a significant interest [18], [19] in the design and development of a new global-scale communication network that can overcome the limitations of the current Internet.
Among the many directions for improving networking technology, recent pursuit to design better flow control has led to the emergence of explicit congestion control methods that solicit active feedback from intermediate routers [5], [11], [22], [25], [26].
As a step towards understanding these methods, we analyze stability and transient performance of Rate Control Protocol (RCP) [5], which is a recent method that aims to emulate processor sharing and achieve quick flow completion.
However, we find that RCP can become unstable in certain topologies and may exhibit very high buffering requirements at routers.
To address these limitations, we propose a new controller called Proportional Integral Queue Independent RCP (PIQI-RCP), prove its stability under heterogeneous delay, and use ns2 simulations, as well as Linux experiments, to show that the new method has significantly better transient dynamics (i.e., much smaller link-capacity overshoot) and better stability properties in single-and multi-bottleneck scenarios.
The enormous growth and success of the Internet has recently raised questions about the ability of existing network algorithms to maintain the same level of performance as the Internet continues to change.
One specific area of concern is congestion control in high-speed networks, where theoretical, simulation, and experimental results [9], [12] suggest that the current version of TCP may experience serious scalability problems as the bandwidth-delay product of network links continues to increase.
One approach to solving this issue is to develop more aggressive end-to-end algorithms [3], [9], [10], [12], [13], [20], [24], while another direction [18], [19] is to re-design the Internet to utilize explicit network feedback from Internet routers [5], [11], [22], [23], [25], [26] to achieve faster convergence, smaller packet loss, and better fairness between end-users.
Analysis and improvement of protocols in the latter category is the focus of this paper.Explicit congestion control algorithms require network devices in each path to send feedback to end-hosts indicating the actual degree of congestion rather than just a binary signal (e.g., packet loss or ECN bits) stating whether congestion is present or not.
To generate feedback p l (t), each router l performs certain processing of incoming data and executes a controller whose input is the aggregate rate of all flows observed within a certain time-interval.
This feedback is then * Supported by NSF grants CCR-0306246, ANI-0312461, CNS-0434940, and CNS-0519442.
inserted into headers of all passing packets and later communicated to sources in acknowledgments.
Explicit feedback provides more accurate congestion information to end-hosts and allows them to adjust their congestion window size or sending rate with much better results, often leading to high link utilization, max-min fairness, and zero packet loss.Among several recent proposals, Rate Control Protocol (RCP) [5] is a simple method that achieves max-min fairness in the steady-state and maintains close-to-optimal average flow completion time (AFCT).
RCP requires lower per-packet computation overhead compared to some of the traditional methods (such as XCP [11]) and has a smaller control header size compared to most other schemes (including JetMax [26], MKC [25], and XCP [11]).
However, the existing literature lacks thorough analysis of RCP regarding its stability in general networks and transient dynamics.
In this work, we aim to fill the void in understanding RCP and study its vulnerabilities in practice.
Our results show that RCP can behave in an unstable manner in certain topologies under highly heterogeneous delays.
We also find that in the pursuit of achieving lower AFCT, end-hosts in RCP use an overly aggressive controller that in certain cases drastically overshoots link capacity and requires huge buffers inside routers.
To overcome the former drawback, we first investigate a method called Queue Independent RCP (QI-RCP) that addresses stability issues in RCP by removing the queue term from the router controller and properly normalizing its gain parameter.
We derive stability conditions for QI-RCP under heterogeneous RTTs and show ns2 [17] simulations that confirm the tightness of the obtained bounds.Even though QI-RCP is stable in topologies where the original RCP was unstable, the new method still requires the same huge buffers inside routers.
To address this issue, we next propose Proportional Integral Queue Independent RCP (PIQI-RCP) 1 , which consists of a PI controller inside routers and an EWMA-type controller at end-users.
We establish stability conditions for PIQI-RCP under heterogeneous RTTs and mild assumptions on the router control interval.
Simulations show that PIQI-RCP's stability bounds derived from a theoretical model are tight in real networks and that the protocol remains stable in single-and multi-bottleneck topologies.
We also show using Linux experiments that PIQI-RCP significantly outperforms RCP in terms of transient capacity overshoot, peak queue size, and buffer space requirements.
Since PIQI-RCP has stability conditions that can be easily satisfied inside routers, incurs small overhead inside routers, and exhibits smaller AFCT than TCP or XCP, it poses an appealing alternative to existing methods.
The rest of the paper is organized as follows.
In Section II, we briefly review RCP and introduce common terminology.
In Section III, we discuss RCP's strengths and weaknesses.
Section IV focuses on the design and analysis of QI-RCP and PIQI-RCP.
In Section V, we compare RCP and PIQI-RCP using ns2 simulations and in Section VI using Linux experiments.
We conclude the paper and suggest directions for future work in Section VII.
Assume N flows in the network whose sending rates at time t are x 1 (t), . . . , x N (t).
For max-min fairness, each flow responds only to feedback p l (t) of the most-congested router l of its path, which we call the bottleneck link of the flow.
The forward/backward delays of flow i to/from its bottleneck link are denoted by D → i and D ← i , respectively.
Then the RTT of each flow can be written asD i = D → i + D ← iand the aggregate traffic arrival rate at router l can be expressed asy l (t) = i∈l x i (t − D → i ), where notation i ∈ l denotes the set of flows passing through link l [15].
Rate Control Protocol (RCP) [5] is an explicit congestion control method based on max-min fairness.
Each router l computes the desired sending rate R l (t) for flows bottlenecked at l using the following non-linear controllerR l (t) = R l (t − T ) 1 + T d l C l α(C l − y l (t)) − β q l (t) d l ,(1) where α and β are constants, d l is a moving average of flow RTTs sampled by router l, C l is its link capacity, q l (t) is its instantaneous queue size at time t, and T is its control interval.The goal of controller (1) is to converge the input traffic rate y l (t) to link capacity C l and set the queue length q l (t) to zero.
To accomplish this, rate R l (t) is fed back to end-flows that adjust their sending rates x i (t) by setting them to the smallest suggested rate of their paths where l ∈ i is the set of routers along the path of flow i [15].
Since all flows bottlenecked at l set their sending rate to the same received feedback R l (t), (2) ensures fairness among flows.
Assuming infinite queues, (2) also guarantees that completion time of each flow is close to the minimum possible.x i (t) = min l∈i R l (t − D ← i ),(2) In this section, we first demonstrate several drawbacks associated with RCP and then summarize its known strengths.
In [6], RCP has been analyzed for stability assuming all flows have homogeneous RTTs (i.e., D i = D for all i).
For users with heterogeneous RTTs, stability results of RCP are available only using simulations for several choices of delays.
The presence of the queue term q l (t) in the router control equation (1) makes rigorous stability analysis difficult, because the stationary queue size q * = 0 lies in the region where q l (t) cannot be linearized.
It is therefore unknown how to select parameters for arbitrary choices of flow delay and whether the RCP equation is stable in general networks.
We next show one example where RCP behaves in an unstable manner and then explain what causes it.Consider a multi-link topology T 1 in Fig. 1, where flow x 1 with RTT 710 ms is bottlenecked at link l 1 and flows x 2 − x 10 with RTT 20 ms are bottlenecked at link l 3 .
Flow x 1 starts at time t = 0 and converges to 155 mb/s after a short delay.
Then at time t = 30, the other nine flows join the system and instantly become unstable as demonstrated in Fig.
2(a) using ns2 simulations.
Similar unstable behavior of RCP has been observed in [1]; however, it was attributed to the oscillation of the bottleneck of flows x 2 − x 10 between links l 1 and l 3 .
As we discuss below, oscillating bottlenecks are the effect of a destabilized RCP equation rather than its cause.
This is confirmed in Fig. 2(b) after fixing the bottleneck of flow x 1 to l 1 and that of the remaining flows to l 3 .
As seen in the figure, the system remains unstable even though the assignment of bottlenecks is correct and time-invariant.
We next elaborate on how this unstable scenario arises and what causes it.
Recall that in the Internet, routers may carry a mix of flows some of which are bottlenecked locally (i.e., at the current router) and some remotely (i.e., at other routers).
In such cases, the average RTT d l computed by router l may not reflect the correct delay of flows that are being controlled by the router.
To simplify discussion, define flows to be responsive with respect to router l if they adapt their rates based on feedback R l (t) (i.e., link l is their bottleneck).
Further define flows to be unresponsive with respect to l if they are being controlled by some other router r = l.
It then follows from common sense that metric d l must include the RTTs of only responsive flows at l rather than all flows passing through it.
In topology T 1 , link l 1 is controlling only flow x 1 since the other nine flows are bottlenecked at l 3 ; however, all 10 flows contribute to the computation of d l .
This leads to a large discrepancy between the flow response time at link l 1 and the average delay computed by the router (i.e., d l = 89 ms instead of 710 ms) and causes instability.As the rate of x 1 starts to oscillate, the queue in l 1 responds by fluctuating with each overshoot and undershoot of link capacity.
This causes the RTT of flows x 2 − x 10 to fluctuate as well, which in turn destabilizes the controller in l 3 since it is closely coupled with flow delays, all of which leads to the result in Fig. 2.
Note that a similar problem surfaces in other explicit-feedback controllers that rely on average delay, one notable example being XCP [11].
We omit simulations showing this result for brevity, but note that analysis of congestion control under heterogeneous delay is of fundamental importance in diverse networks such as the Internet.
Besides unknown stability conditions in certain cases, RCP is very aggressive during flow join and can significantly overshoot link capacity in the transient phase.
Recall that RCP's source controller (2) sets the sending rate x i (t) of each joining flow i to the feedback received from the router.
As a result, new flows entering the system directly use the current router control rate as their sending rate.
For a router that is already in its steady state (i.e., C l = y l (t)), this causes the input traffic rate to overflow the link and create a sudden surge in queue size.
The problem becomes severe when a large number of flows join the system simultaneously.
This is illustrated by the ns2 simulations we show next.Consider a dumb-bell topology with a 100 mb/s bottleneck link and delay 50 ms. At t = 0, flow x 1 enters the system and quickly saturates the bottleneck link as shown in Fig. 3(a).
At t = 15, flows x 2 − x 51 enter the system and obtain the current control rate R l (t) = 100 mb/s from the router.
For at least one RTT following the join, all 51 flows use the latest rate provided to them (i.e., x i (t) = C l ) and produce a combined input load on the router equal to 5.1 gb/s.
Assuming unlimited buffer space, this aggressive behavior increases the queue length to 80, 868 packets (i.e., 81 MB) as shown in Fig. 3(b), which takes the router 7.5 seconds to drain.
Considering that the commonly deployed [2] rule is to allocate buffers equal to the bandwidth-delay product of the link (i.e., 1.25 MB in this case), RCP's overshoot requires 64 times more buffer space than used today in most commercial routers [4], [21].
Hence, unless unrealistically large buffers are provisioned inside routers, RCP will sustain significant packet loss, which may result in drastic rate reductions 2 , retransmissions, slow convergence, and even instability.
As we show later in this paper, RCP's buffering requirement increases proportionally to the number of flows entering the system and the delay to drain the queue increases dramatically with flow RTT.
In highly dynamic scenarios where flows constantly join and depart the system, RCP may require more buffer space or even offer lower performance than the traditional TCP, which is highly undesirable in practice.
Apart from the drawbacks identified above, RCP has certain strengths as well.
First, RCP requires lower per-packet computation to compute the feedback signal inside routers than some of its counterparts (e.g., 2 additions and 2 multiplications compared to 6 additions and 3 multiplications in XCP [11]).
Second, RCP has a smaller control header size (i.e., 16 bytes) compared to XCP's 20 bytes [8], JetMax's 32 bytes [26], and MKC's 20 bytes [25].
Third, unlike XCP [14], RCP's steady-state rates achieve max-min fairness in general network topologies.
Finally, RCP [5] has a much smaller average flow completion time than XCP or TCP, which allows short flows to quickly utilize available bandwidth and finish their transfers.
Considering these strengths, we next strive to improve upon the drawbacks of RCP.
In this section, we propose several modifications to RCP's router and user control equations (1)-(2) to address its stability and link-overshoot issues.
We next introduce a simple modification to RCP, which we call Queue Independent RCP (QI-RCP), that decouples queue dynamics from the feedback computed by the router.
This allows us to prove heterogeneous stability of the new controller and therefore achieve good performance in topology T 1 .
We then improve QI-RCP by reducing its overshoot of link capacity and lowering buffering requirements at routers.Define the error function of link l at time t to bee l (t) = 1 − y l (t) γ l C l ,(3)where y l (t) is the combined input rate of all flows at router l, C l is its capacity, and 0 < γ l < 1 is the desired link utilization in the steady-state.
Then, the router controller of QI-RCP is given byR l (t) = R l (t − T )[1 + κe l (t)],(4)where R l (t) is the control rate, T is the control interval, and κ is a constant whose range we determine below.
Control equation (4) is similar to RCP's version (1), but does not include the queue term inside the error function.
In order to drain any possible queue build-up, the QI-RCP controller operates with a virtual link capacity γ l C l instead of the physical capacity C l .
End-flow rates are still adjusted using (2), which coupled with (4) represents an integral controller that tries to converge the input traffic rate y l (t) to the virtual link capacity γ l C l (see [16] for more discussion of integral controllers).
Hence, in the steady state y l (t) = γ l C l and any packets buffered due to transient affects in the system are drained using spare bandwidth(1 − γ l )C l .
We next analyze QI-RCP's stability.
Although multiple packets may carry the same feedback value computed by the router during the last control interval, each end-user in QI-RCP responds to each feedback no more than once and may be viewed as operating on the time-scale of T units even if its RTT is smaller than T .
Keeping this in mind and converting the delayed feedback loop of (4) toR l (t) = R l (t − T ) 1 + κ 1 − 1 γ l C l N i=1 R i (t − D i ), (5) we arrive at the following result.Theorem 1: Assume N flows with heterogeneous RTTs and defineD = max{D 1 , . . . , D N }, D = D/T .
Then, the discrete version (5) of QI-RCP is locally asymptotically stable if 0 < κ < κ * , whereκ * = 2 sin π 2(2D − 1) .
(6)Furthermore, if flow RTTs are homogeneous (i.e., D i = D for all i), the above condition is also necessary.Proof: The z-transform of the linearized system (5) is given byR l (z) = R l (z) z −T − κ N N i=1 z −D i + K,(7)where K is a constant.
The system transfer function is thenR l (z) = K/(1 − z −T ) 1 + G(z) ,(8)whereG(z) = κ N N i=1 z −D i 1 − z −T .
(9)The transfer function G(z) in the frequency domain can be written asG(e jω ) = κ N N i=1 e −jω(D i −T ) e jωT − 1 .
(10)After expanding the exponentials, (10) can also be written asG(e jω ) = − κ 2N sin(ωT /2) N i=1 sin ω(2D i − T ) 2 +j cos ω(2D i − T ) 2 .
(11)Most discrete controllers inside a router must operate every T time steps, keeping the rate constant between the control intervals.
This can be converted to the case of T = 1 by normalizing each delay using D i = D i /T ,G(e jω ) = − κ 2 sin(ω/2) sin ω(2D − 1) 2 +j cos ω(2D − 1) 2 .
(12)It can be seen that G(e jω ) crosses the real axis (i.e., Im[G(e jω )] = 0) for ω i = (2i + 1)π/(2D − 1), where i is an integer.
For i = 0, we have ω 0 = π/(2D − 1) and the real part ofG(e jω 0 ) is Re[G(e jω0 )] = −κ 2 sin(ω 0 /2) = −κ 2 sin π 2(2D −1) .
(13)Applying Nyquist stability criterion, it can be seen that stability is ensured if and only if0 < κ < 2 sin π 2(2D − 1) .
(14)However, when delays are heterogeneous G(e jω ) crosses the real axis (i.e.,Im[G(e jω )] = 0) when N i=1 cos ω(2D i − 1) 2 = 0.
(15)It can be seen that none of the roots ω i of the above equation have absolute value smaller than ω 0 = π/(2D − 1).
We prove this by contradiction.
Assume that 0 ≤ ω 0 < ω 0 is the smallest root of (15).
Then, 0 ≤ ω 0 D i < π/2, which means that all cosine terms in the summation are strictly positive, which contradicts the assumption that ω 0 is a root of (15).
Since cosine is a symmetric function, we immediately obtain the same contradiction for −ω 0 ≤ ω 0 < 0.
Therefore, it follows that |ω 0 | ≥ ω 0 .
Also, due to the periodic nature (with period 2π) of the frequency domain of a discrete-time system, we can limit our attention toω i ∈ [−π, π].
Again, π is a solution to (15) since (2D i −1) is odd for any integer D i .
Based on these arguments, the smallest root ω 0 of (15) should satisfy 0 < ω 0 ≤ π and ω 0 > ω 0 .
Again, because of the monotonicity of the sine function between 0 and π/2, the condition sin(ω 0 /2) > sin(ω 0 /2) holds.
For ω 0 , the real part of G(e jω 0 ) is Re[G(e jω 0 )] = − κ 2N sin(ω 0 /2) N i=1 sin ω 0 (2D i − 1) 2 ≥ − κ 2 sin(ω 0 /2) ≥ − κ 2 sin(ω 0 /2) = − κ 2 sin π 2(2D −1) .
(16)The above inequality is obtained by bounding the sines with 1, using sin(ω 0 /2) > sin(ω 0 /2), and remains valid even if ω 0 < 0.
Therefore, the magnitude of the point at which the real axis is crossed can only be reduced (i.e., moved closer to zero) in the heterogeneous case compared to that in the homogeneous case.
Finally, noticing that the remaining ω i are larger than ω 0 , it follows that they can only shift (16) further toward zero and thus lead to looser bounds on κ.
Hence, using Nyquist stability criterion, a sufficient condition to ensure stability is0 < κ < 2 sin π 2(2D − 1) ,(17)which leads to the desired result.
Note that in the synchronized case (i.e., D i = T for all i), κ * is simply 2.
Furthermore, for small T /D ≈ 0, stability margin κ * ≈ πT /(2D), which can be directly obtained using continuous-time analysis of (5); however, in cases when flow RTTs are close to T , the two expressions are different.
3 Furthermore, as a rule of thumb, upper bound (6) can be considered necessary when delays are close to each other (i.e., V ar[D i ] ≈ 0); however, for highly varying delays, the system may be stable even when κ exceeds κ * as we show below.
We next examine QI-RCP's stability in ns2 and investigate how good the derived bounds on κ are.
Fig. 4 shows the sending rate of QI-RCP in a single-link network with two flows, both having steady-state RTT equal to 120 ms. The router adjusts its κ by keeping it equal to ηκ * , where η is a scale parameter and κ * is the upper bound in (6).
Observe in the figure that η = 0.99 keeps the system stable and η = 1.01 makes it unstable, confirming the sufficiency and necessity of condition κ < κ * .
In Fig. 5, we show an example of a system with heterogeneous RTTs.
Observe that the system is stable for η = 0.99 and only becomes unstable when η reaches 1.8.
This confirms that when delays are highly variable, κ < κ * is sufficient, but not necessary.We finish our ns2 simulations with QI-RCP by showing in Fig. 6 its performance in topology T 1 where RCP was unstable.
As seen in the figure, at t = 0 flow x 1 enters the system and quickly saturates its bottleneck link l 1 .
At t = 30, nine additional flows x 2 − x 10 join the system, which causes small oscillations from which the network quickly recovers and converges to a stable steady state.
Note that QI-RCP remains stable for η as high as 0.99 (see Fig. 6(b)), where larger η actually speeds up convergence since routers make more aggressive changes to their R l (t).
QI-RCP has mathematically tractable stability conditions that can be easily satisfied since routers have access to the RTT of each flow using QI-RCP packet headers, which are similar to those in RCP.
Knowing the maximum flow RTT D in every control interval, QI-RCP dynamically tunes the control parameter κ so as to comply with the stability condition κ < κ * .
This keeps the system stable even when D is timevarying due to the changes in the queuing delay as seen in simulations above.
However, the main drawback of QI-RCP is that it uses the same aggressive source controller (2), which leads to similar queue build-up as in RCP.
We next focus on modifying the user controller to eliminate this drawback.
In this section, we propose a new congestion control framework called Proportional Integral Queue Independent RCP (PIQI-RCP) that significantly improves the transient behavior of the methods studied earlier in this paper.
We start with the router controller of the formR l (t) = R l (t − T )[1 + κ 1 e l (t) + κ 2 e l (t − T )],(18)where error e l (t) is given by (3) and κ 1 , κ 2 are some constants.
It can be seen from the equation that (18) is a simple PI controller [16], where the proportional component helps improve system response time and limit the queue to lower levels (see simulations below).
We next discuss the rationale for the new source controller.
The user equation in RCP and QI-RCP causes the input traffic rate to significantly overshoot link capacity and skyrocket the queue size when a flash crowd of flows joins the system.
Instead, we desire a controller that does not immediately jump to the current fair bandwidth share in the network and uses caution during rate increase.
To achieve this, new flows joining the system should gradually increase their sending rate towards the feedback provided by their bottleneck router.For the discussion that follows, define e i (t) = R l (t−D ← i )− x i (t − T ) to be the error between the previous rate of user i and the last rate suggested by the network, assuming the current bottleneck of user i is router l. Also denote byδ i (t) = R l (t − D ← i ) − R l (t − T − D ← i )the difference between the two most-recent rates provided by the network to flow i. Then, the PIQI-RCP source controller is given byx i (t) = x i (t − T ) + τ 1 e i (t) + τ 2 δ i (t),(19)where τ 1 and τ 2 are constants that we determine below.
The first two terms in (19) constitute an Exponentially Weighted Moving Average (EWMA) controller.
Rather than directly setting the sending rate x i (t) to the received feedback (2), this controller changes the current Fig. 7.
Feedback control system model of explicit congestion control sending rate in steps that take x i (t) toward R l (t).
The δ i (t) term performs a comparison of two successive feedback values to understand what the bottleneck router wants flows to do: if δ i (t) > 0, then the router is under-utilized and wants to encourage the flows to increase their sending rate; if δ i (t) < 0, then the router is over-utilized and wants the flows to decrease their sending rate.
Including this information in the source controller makes it more responsive and reduces queue overshoot in the transient state.R(t − D ← i ) as inC(z) G(z) y(n) R(n) e(n) = C -y(n) C - Controller Plant +It should be noted that comparison of successive feedback values is achieved by simply saving the last received feedback from the bottleneck and does not incur any network overhead.
Also note that τ 2 affects the behavior of the system when the bottleneck link is in a transient state, i.e., when the successive feedback values are different.
After the bottleneck controller has reached its steady state, δ i (t) = 0 and the performance of the source is governed only by τ 1 .
Using the Nyquist stability criterion, we next show that PIQI-RCP can be easily stabilized assuming the maximum RTT D is known at the router.
We also replace the general router controller with a simpler version that we use in practice by setting κ 1 = κ 2 = κ.Theorem 2: Assume N flows with heterogeneous RTTs and define D = max{D 1 , . . . , D N }, D = D/T .
Then, the discrete PIQI-RCP system (18)-(19) with sufficiently small T is locally asymptotically stable if 0 < τ 1 < 1, 0 < τ 1 + 2τ 2 < 2, and 0 < κ < κ * , whereκ * = sin π 2(2D − 1) .
(20)Furthermore, if flow RTTs are homogeneous (i.e., D i = D for all i), condition 0 < κ < κ * is also necessary.
Proof: We first develop a linear control-theoretic model of PIQI-RCP and then analyze the model for stability using Nyquist stability criterion.
Consider the feedback control system model of explicit congestion control as shown in Fig. 7.
Let G(z) be the plant consisting of N flows each with sending rate x i (t) and round-trip time (RTT) D i = D → i + D ← i .
Let C(z) be the router controller whose goal is to operate the closed loop system in a stable manner.
The output of the plant is the total sending rate y(n) arriving at the router controller and the input being the per-flow sending rate R(n) generated by the router.
The individual blocks, i.e., the controller and the plant, are analyzed below.The linearized controller (18) in the discrete-time domain can be written asR(n) = R(n − T ) + κe l (n) N + κe l (n − T ) N .
(21)Taking the z-transform of both sides of the equation, we getR(z)[1 − z −T ] = κ N 1 + z −T e(z).
(22)After re-arranging the terms in the above equation, the transfer functionC(z) = R(z)/e(z) is C(z) = κ(1 + z −T ) N (1 − z −T ) ,(23)The plant consists of N flows, each of which adjusts its sending rate using (19).
In the discrete-time domain and after expanding the error terms, (19) can be written asx i (n) = x i (n − T ) − τ 1 [x i (n − T ) − R l (n − D ← i )] + τ 2 [R l (n − D ← i ) − R l (n − T − D ← i )] = (1 − τ 1 )x i (n − T ) + (τ 1 + τ 2 )R l (n − D ← i ) − τ 2 R l (n − T − D ← i ).
(24)The total input traffic rate y l (n) observed at the router is given byy l (n) = N i=1 x i (n − D → i ) = N i=1 [x i (n − T − D → i )(1 − τ 1 ) + (τ 1 + τ 2 )R l (n − D i ) − τ 2 R l (n − T − D i )] = (1 − τ 1 )y(n − T ) + (τ 1 + τ 2 ) N i=1 R l (n − D i ) − τ 2 N i=1 R l (n − T − D i ).
(25)Taking the z-transform of both sides of the above equation, the transfer function G(z) = Y (z)/R(z) of the plant can be written asG(z) = (τ 1 + τ 2 ) − τ 2 z −T 1 − (1 − τ 1 )z −T N i=1 z −D i .
(26)The overall open loop transfer function T f (z) = C(z)G(z) combining the controller and the plant can be obtained from (23) and (26) asT f (z) = τ 1 + τ 2 + τ 1 z −T − τ 2 z −2T 1 − (1 − τ 1 )z −T N i=1 κ N z −Di 1 − z −T = T (z)T D (z),(27)whereT (z) = τ 1 + τ 2 + τ 1 z −T − τ 2 z −2T 1 − (1 − τ 1 )z −T ,(28)T D (z) = N i=1 κ N z −D i 1 − z −T .
(29)In the frequency domain, we have Function T (e jω ) crosses the real axis when ω = ω 1 = 0 or ω = ω 2 given byT f (e jω ) = T D (e jω )T (e jω ),(30)T (e jω ) = τ 1 + τ 2 + τ 1 e −jωT − τ 2 e −jω2T 1 − (1 − τ 1 )e −jωT ,(31)T D (e jω ) = N i=1 κ N e −jωD i 1 − e −jωT .
(32)ω 2 = τ 2 1 − 2τ 1 + 2τ 1 τ 2 T 2 τ 2 (1 − τ 1 ) 1 2 .
(33)In the former case, Re[T (e jω 1 )] = 2κτ 1 /τ 1 = 2κ.
In the latter case, for 0 < τ 1 < 1 and τ 1 +2τ 2 < 2, the value of ω 2 is imaginary, which ensures that for this set of constants T (e jω 2 ) does not cross the real axis.
Hence, selecting sufficiently small values of τ 1 and τ 2 that satisfy both inequalities above, one can enforce that T (e jω ) crosses the real axis only when ω equalsω 1 .
Further assuming small ωT (i.e., T /D ≈ 0), T f (e jω ) can be reduced to T f (e jω ) = N i=1 2κτ 1 N τ 1 e −jωDi 1 − e −jωT = N i=1 2κ N e −jωDi 1 − e −jωT , (34)which using the analysis in the proof of Theorem 1 gives the upper bound on the stability region in (20).
Note that (20) is very similar to the condition on QI-RCP.
The reduction by a factor of two is easy to explain since (18) has two error terms rather than one.
The result in Theorem 2 shows that with τ 1 , τ 2 sufficiently small, stability of PIQI-RCP can be reduced to that of the bottleneck controller (18).
We next use ns2 simulations to study how well the discrete model (18)-(19) of PIQI-RCP resembles the actual system.
As before, each router keeps track of the maximum RTT in every control interval and sets κ = ηκ * , where κ * is given by (20).
As we discuss in the next section, the sine function in κ * can be approximated with a much simpler equation and in our implementation none of the routers have to compute (20).
However, to verify that the derived stability condition is accurate, this section uses the exact value of κ * .
We start with the homogeneous case.
Consider a dumbbell topology with a 100-mb/s bottleneck, delay 50 ms, and 1-gb/s access links.
A new flow enters the system every 10 seconds and remains in the system for the entire duration of the simulation.
The steady-state RTT of each flow is 120 ms. Fig. 8 shows that PIQI-RCP is stable for η = 0.99 and unstable for η = 1.01, just as predicted by Theorem 2.
For the heterogeneous case, access links have different delays such that D 1 = 120 ms and the other nine flows have RTT 300 ms. The corresponding plots are shown in Fig. 9 where the condition κ < κ * is both sufficient and necessary.
This confirms our earlier observation that if RTTs are clustered close to D, the derived stability conditions become necessary.We finally examine whether PIQI-RCP is stable in topology T 1 .
Fig. 10 shows the sending rates of PIQI-RCP flows in T 1 for both η = 0.5 and η = 0.99, where the former case is slower in convergence, but much smoother in terms of sending-rate dynamics.
In this section, we compare the performance of RCP and PIQI-RCP in various simulation setups using ns-2.
In most cases, RCP's parameters are set as in the default implementation (i.e., α = 0.4, β = 1), all router intervals T are 10 ms, and PIQI-RCP's κ 1 = κ 2 .
In order to avoid computing the sine function inside routers, we replace the upper bound κ * with a much simpler upper boundκ * = T 2(T + D) ≤ κ * ,(35)where D is the maximum RTT of end flows.
Consider a dumb-bell topology with heterogeneous flows discussed in the previous section.
The performance of RCP and PIQI-RCP with κ = 0.95κ * is shown in Fig. 11.
In the steady state, all flows share the bottleneck link fairly regardless of their RTTs.
For RCP, new flows join the system with a sending rate equal to the current control rate at the router, which leads to an overshoot of link capacity for every new flow entering the system.
This in turn results in often drastic reductions in rate as seen in Fig. 11(a).
The peak queue size for RCP is nearly 3, 500 packets, while that for PIQI-RCP is only 550 packets as shown in Fig. 12.
Also observe that PIQI-RCP keeps the queue close to zero after the second flow has joined the system.
Similar behavior is observed for bottleneck capacity of 1 and 10 gb/s (not shown for brevity).
In this section, we compare the peak queue size of RCP with that of PIQI-RCP in the same simulation setup, except a single join event at t = 15 has N flows entering the system simultaneously.
Fig. 13(a) shows that RCP performs significantly worse than PIQI-RCP, reaching over 501, 000 queued packets for N = 250 and scaling its buffer requirement super-linearly (note the log-scale of the y-axis).
On the other hand, PIQI-RCP scales much better and stabilizes the queue at 10, 000 packets after N = 25.
This implies that as N increases beyond 250, the difference between RCP and PIQI-RCP will be more noticeable.
We next compare RCP, PIQI-RCP, TCP, and XCP using average flow completion time (AFCT) as the main performance metric.
AFCT is often compared to the smallest achievable average flow completion time known as Processor Sharing (PS) [6].
Intuitively, RCP will fare better in this scenario since new flows entering the system directly use the current control rate at the router, while new flows in PIQI-RCP, TCP, and XCP gradually increase their sending rate and hence require more time to complete.
We confirm this in a simulation scenario from [5] consisting of a single-bottleneck link of capacity 2.4 gb/s and delay of 50 ms. New flows enter the system as Poisson arrivals with Pareto-distributed flow sizes with mean 30 packets (1000 bytes/pkt) and shape 1.4.
The offered load is 90% of link capacity.The corresponding AFCT for all studied methods are shown in Fig. 13(b), where the results are obtained from ns2 simulations with infinite buffers.
4 Observe in the figure that PIQI-RCP is indeed slower than RCP, but nevertheless is faster than TCP and XCP.
The difference between RCP and PIQI-RCP can be bridged by selecting a higher value of τ 1 , which can be viewed as a tuning knob that controls the tradeoff between AFCT and the buffering requirement.
We finish simulations with a parking-lot topology in Fig.
14, where flow x 1 traverses two links of capacity 970 and 800 mb/s, respectively, and delay 50 ms each.
Flow x 2 only traverses the first link and flow x 3 only the second.
The three flows enter the system at t = 0, 15, 30 seconds, respectively.
The sending rate of all flows for RCP and PIQI-RCP is shown in Fig. 15.
Until t = 15, flow x 1 is bottlenecked at link l 2 .
At t = 15 when x 2 enters the system, the bottleneck of flow x 1 switches to link l 1 and both x 1 and x 2 have identical sending rates equal to 485 mb/s.
At t = 30 when x 3 enters the system, x 1 switches its bottleneck to l 2 again, after which x 1 and 4 RCP with finite buffers loses a lot of packets and performs much worse in terms of AFCT, which we do not show for brevity.
x 3 equally share link l 2 (i.e., rate 400 mb/s each).
Flow x 2 captures the remaining bandwidth at link l 1 , which is the maxmin allocation of rates for this topology.
As seen from the figures, the magnitude of transient oscillations is much smaller in PIQI-RCP compared to RCP, while the convergence time is almost the same.
We also compare RCP and PIQI-RCP using our own Linux implementation in a gigabit Emulab [7] network.
We use Linux kernel 2.6.12 to develop the end-host and router functionality of both RCP and PIQI-RCP, where each protocol is implemented as a module that can be dynamically plugged in/out of the running kernel without rebooting the system.
We modify the TCP/IP stack to convert its original windowbased data transfer to rate-based operation required by these protocols.
We tune the default kernel parameters in order to support gigabit throughput for a wide-range of RTTs and fairly evaluate the limitations of each protocol.
Specifically, we increase the maximum size of socket read/write buffers, per-connection memory space, backlog queue in the receive path, transmit queue in the forward path, and transmit/receive ring buffers of the network interface card.
We set control parameters α = 0.1, β = 1 for RCP and κ = κ * , τ 1 = 0.01, τ 2 = 0.1, γ = 0.95 for PIQI-RCP.
All routers use T = 10 ms for their control equations.
Consider a scenario where three flows pass through a singlebottleneck link of capacity 1 gb/s and round-trip propagation delay of 50 ms. Each flow is connected to the bottleneck link through a different access link of capacity 1 gb/s and negligible delay.
These flows start with a 30-second delay and each lasts for 90 seconds.
The sending rates 5 of the flows are illustrated in Fig. 16, where both methods are able to maintain high throughput and keep CPU utilization below 30% at the router.
During the experiment, we also monitor the IP layer queue size inside the bottleneck router.
As shown in Fig. 17(a), RCP experiences significant queue buildup (up to 9, 415 packets) whenever a new flow joins the system.
In contrast, PIQI-RCP maintains queue size of at most 1 packet (not shown in the figure), which can be explained by the gradual increase of user rates in the source controller.
This allows the router enough time to converge to a new steady state without significantly overshooting link capacity.
In this experiment, we examine the performance of RCP and PIQI-RCP with an abrupt increase or decrease in traffic demand.
We use a dumb-bell topology with gigabit access links and a bottleneck link with capacity 100 mb/s and delay 25 ms. At t = 0, one long flow is started for a duration of 120 seconds.
At t = 30, another 10 flows abruptly join the network and continue to remain in the system until t = 113, at which time they all suddenly exit.In RCP, at time t = 30 the average input traffic increases to 300 mb/s and the queue size jumps to around 11, 000 packets as shown in Fig. 17(b), which is very similar to the behavior of RCP in ns2.
Next, with the rise in both the input traffic rate and queue size, the router's control equation overcompensates and drives the combined sending rate to 10 mb/s as shown in 18(a).
This explains the drop in link utilization at t = 30.
The system remains in this transient state for about 7 seconds before eventually recovering.
As can be seen from Fig. 18(b), PIQI-RCP has a very small overshoot of C l and all excess traffic gets absorbed in network device queues without increasing the router queue (i.e., the peak IPlayer queue is again 1 packet).
In this section, we study RCP and PIQI-RCP when the input traffic is a combination of both short-lived (i.e., mice) and long-lived flows.
We start the long flow at t = 0 from one of the two sender machines and generate mice traffic starting at t = 30 from the other machine.
All flows pass through a common bottleneck link of capacity 1 gb/s and delay of 25 ms. The pattern of mice traffic follows Poisson arrivals with the mean inter-arrival time of 0.2 seconds and Paretodistributed duration (i.e., number of transferred packets) with shape parameter 1.4 and mean 100 packets.The results of this experiment are shown in Fig. 19.
In RCP, link utilization remains generally very high, but experiences occasional overshoots by 40% and undershoots by 25%.
PIQI-RCP, on the other hand, demonstrates much less rate fluctuation, a virtually non-existent queue, and the same high link utilization as in RCP.
This shows that PIQI-RCP is not only a stable protocol with good transient properties in theory, but also a practical approach suitable for GENI-style [19] networks of the future.
In this work, we found that RCP could become unstable in certain cases and required unrealistically large buffers to absorb transient overshoots of link capacity.
As an alternative to RCP, we proposed a new controller called PIQI-RCP and showed that its heterogeneous stability could be easily established using common control-theory tools.
We further demonstrated in simulations and experiments that PIQI-RCP required much smaller buffers at routers and had a lower average flow completion time compared to TCP and XCP.Future work involves analysis of multi-link stability of maxmin congestion control and deployment of explicit-feedback methods in large-scale testbeds with millions of flows.
