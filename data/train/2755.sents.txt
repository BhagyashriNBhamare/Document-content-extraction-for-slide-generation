RDMA is increasingly popular for low-latency communication in datacenters, marking a major change in how we build distributed systems.
Unfortunately, as we pursue significant system redesigns inspired by new technology, we have not given equal thought to the consequences for system security.
This paper investigates security issues introduced to datacen-ter systems by switching to RDMA and challenges in building secure RDMA systems.
These challenges include changes in RPC reliability guarantees and unauditable data-accesses.
We show how RDMA's design makes it challenging to build secure storage systems by analyzing recent research systems; then we outline several directions for solutions and future research, with the goal of securing RDMA datacenter systems while they are still in the research and prototype stages.
Remote Direct Memory Access (RDMA) is a networking technology that improves performance by making use of the direct connection between a server's network card (NIC) and memory to bypass its CPU.
RDMA originates from the HighPerformance Computing (HPC) community, where applications are homogenous, highly parallel, and require both high bandwidth and low latency communication between nodes.
Recently, researchers in the systems and networking community have proposed the use of RDMA in distributed storage systems in datacenters, citing the falling costs of RDMA NICs and rising network bandwidths relative to CPU speeds.Since RDMA originated in the HPC community, its design has a security model that differs from that of the datacenter.
For example, HPC clusters often assumed a high degree of trust between users; when that was not possible (e.g., for classified jobs) clusters used physical isolation [42].
In contrast, the datacenter is a shared environment, with untrusted users.
As a result, many of RDMA's original security assumptions no longer hold, making it important to re-evaluate the danger of any security concerns.
Researchers have been documenting concerns about the RDMA protocol (e.g., its lack of encryption) for more than two decades, and continue to discover more.
Once those protocol concerns are addressed, however, we find CPU-bypassing RDMA still poses challenges for distributed system designers, and we analyze these challenges here.
RDMA networking is widely deployed in datacenters [2,19], and multiple research datacenter storage systems using RDMA have recently appeared, offering systems designers an ideal opportunity to rethink RDMA security.In this paper, we explore the security challenges RDMA introduces by analyzing eight recently proposed distributed storage systems; we then discuss directions for solutions and further research.
We believe achieving more secure RDMA communication without sacrificing performance is possible and the time to investigate this is now, while RDMA-using datacenter systems are still in research and prototype stages.
This section describes deployment of RDMA in datacenters and reviews security concerns in RDMA's design and implementation.
Section 3 analyzes current proposals that use RDMA to build distributed systems in the datacenter.RDMA Operations.
RDMA offers two types of API calls: SEND, RECV.
These "two-sided" calls implement a traditional RPC abstraction of sending and receiving messages.
The recipient enqueues a RECV request to the card from userspace to give the NIC a buffer in which to write the received data.
After this happens, the sender enqueues a SEND request to pass a message descriptor and data buffer to the NIC.
These APIs achieve kernel-bypass but both the sender and recipient CPUs are involved.
READ, WRITE, ATOMICS.
These "one-sided" RDMA calls bypass the recipient CPU entirely and operate directly on its memory.
The receiver must first register memory regions that may be accessed remotely via the NIC, and communicate access information with the sender.
Once that is complete, the sender enqueues a request to its NIC containing a message descriptor with one-sided opcode and a data buffer.
One-sided RDMA offers a shared memory abstraction.RDMA Setup.
Before running RDMA operations, two setup steps are required, neither of which are contained in the RDMA protocol itself [22,23].
First, a connection must be established between each sender/receiver pair.
A library called RDMACM (CM for Connection Manager) offers APIs for this set-up, using unencrypted TCP for communication [30].
Second, host memory regions must be registered with the NIC.
The registration process generates a static 32-bit token Figure 1: Structure of a RoCEv2 (RDMA over Converged Ethernet) packet, from the spec [22].
These packets operate over IP and UDP, so RDMA must provide reliability and ordering semantics.
Nothing is encrypted or authenticated.
(called an R_Key) that senders must include in one-sided requests to demonstrate authorization to access that memory region.
Since there is no mechanism to exchange these tokens in the RDMA protocols, the RDMACM library is often used for this exchange, again using unencrypted TCP [30].
RDMA replaces the standard datacenter networking protocols with an RDMA protocol such as iWarp or RoCEv2 (RDMA over Converged Ethernet) [22].
Figure 1 shows a RoCEv2 packet.
The RoCE metadata and contents sit inside Ethernet, IP, and UDP frames.Security Gaps in RDMA.
Researchers have identified security gaps in the RDMA protocol design since its original use in the HPC community and continue to uncover new vulnerabilities.
We summarize their findings before exploring the consequences of these flaws on modern RDMA systems.
• Lack of Confidentiality.
RDMA NICs do not encrypt RDMA packets by default.
Both metadata (such as memory addresses and R_Keys) and contents (application data) are visible on the wire [29], and can be seen by machines on the network, such as switches or middleboxes, as well as an adversary who has, via some compromise, obtained root access on the client's virtual machine 1 .
This lack of confidentiality is not in line with modern best practices where packet transport is usually encrypted [18], either using a standard protocol such as TLS or a custom protocol such as Google's ALTS [16].
Neither of these protocols, which are based on a TCP transport layer, would be easy to use with RoCEv2 [40].
• No Integrity Checks or Authentication.
By relying on the unencrypted and unauthenticated packet data, RDMA NICs make it impossible to enforce meaningful access controls [11].
For example, the R_Key in the READ and WRITE APIs is supposed to be a capability, passed from the server to the client during memory region registration, and used to prove authorization on the datapath.
In practice, several weaknesses may allow adversaries to read and spoof RDMA packets, including the lack of transport encryption, the small (32-bit) size of the R_Key, and unrobust implementations (e.g. NICs often assign R_Keys sequentially [45]).
• Availability Challenges.
Guo et al. point out several availability dangers in their 2016 paper, including deadlock, livelock, and the colorfully named "PFC Pause Frame Storms" [19].
RoCE (both v1 and v2) require "lossless" link layers; to achieve this, RDMA NICs and switches employ Priority Flow Control (PFC), a mechanism that issues "Pause" commands to senders when a recipient's buffer becomes full [22].
In a tree-like network structure with hosts at the leaves, if a switch gets a "Pause" from a host and then receives more traffic bound for that host, the switch's buffer will fill, causing it to propagate the "Pause" commands up the tree.
This can lead to Denial of Service for unrelated hosts.
Guo et al. saw these storms "multiple times" in production [19].
Recent RoCE and iWarp NICs do not require PFC to be enabled, but they are not necessarily interoperable with the existing installed base of RoCE NICs PFC [34].
• Side Channels.
Tsai and Zhang in 2019 explored sidechannels in RDMA NICs, inspired by recent security problems found with CPU speculative execution [43].
As the more glaring vulnerabilities in RDMA are fixed, we expect future research to uncover more attacks.We have optimism that hardware vendors are considering these problems (e.g. [33]), but, as we discuss in the next section, there is additional complexity to building secure systems atop RDMA.
Just as satisfying basic compliance concerns does not prevent vulnerabilities and compromises [41], addressing RDMA security fundamentals will not eliminate the security challenges of designing an RDMA-based distributed storage system.
Particularly, our analysis found that the use of RDMA exacerbates the harm done by a compromised storage client, which threatens the attempt to preserve security parity with current datacenter systems.
In this section we present an analysis of recent research systems that use RDMA and identify further security challenges.System and Threat Model.
We expect RDMA-based distributed systems to be entirely deployed in the datacenter setting.
We assume datacenter servers are connected through a standard datacenter Ethernet network running RoCEv2 [22], as in [19].
Each server runs one or more RDMA processes that serve as either clients or servers in the distributed RDMA system.
Figure 2 illustrates this system model.
Although the nodes can be virtualized (e.g., virtualizing the RDMA NIC through SR-IOV), the RDMA systems we analyzed do not mention using virtualization.We assume the datacenter is safe from physical breaches and that the datacenter provider is trusted; however, the customer deploying the RDMA system might not be the provider and may have different goals (unlike in RDMA's original HPC setting where provider and user goals aligned).
Figure 2: RDMA-based distributed systems operate entirely inside the datacenter and are connected via Ethernet.
Many recent RDMA systems have been storage systems; thus the client is likely also an application server for some internetbased application and is especially vulnerable to compromise.
System designers must consider the security consequences of such a compromise when designing RDMA systems.We assume that any datacenter storage system, including one using RDMA, has security goals including: (1) preventing unauthorized exfiltration of data from the system, (2) maintaining the integrity of data and (3) preserving availability in the face of an attempted denial of service attack.
Systems that provide transactional storage and consistency guarantees will be especially concerned about the integrity of metadata (e.g. locks), as well as the storage contents.We are primarily concerned with violations of the security goals if a server or client is compromised.
While distributed systems typically do not worry about a compromised node, we argue that RDMA systems must consider them more closely.
Traditional distributed systems have well-defined interfaces between client and server, limiting the damage of a compromised node.
For example, while a malicious key-value store client could perform arbitrary reads and writes, these operations would be logged server-side, and in production systems, the server would perform permissions checking [37].
RDMA servers, however, expose a broader API to other nodes, often giving clients the ability to read or write large regions of memory.
A malicious client could release locks, abort transactions, or re-write portions of the log.
In many RDMA systems today, a single malicious client could leak the entire database with no trace.VLANs are Insufficient.
Datacenters employ network virtualization techniques (e.g., VLANs) to isolate each customer's traffic.
However, an adversary who has compromised a client machine (or the customer's VM on the client machine) needs only to see that customer's RDMA traffic to glean the necessary details for accessing the storage server, such as memory addresses and R_Keys.
No other machine or VM traffic is necessary.
The adversary can then use the same compromised client to modify, or undetectably exfiltrate data.
Recently, a number of research systems have used RDMA as a high-performance communication mechanism.
Table 1 lists 8 recent systems and the RDMA features that they use.
In general, systems leverage one-sided RDMA operations when possible, as these operations are faster and reduce remote CPU usage.
This section analyzes the security challenges introduced by RDMA for each system design (the right side of Table 1).
Unauditable reads.
After a compromise, investigators attempt to determine what data has been accessed by the adversary; adversaries may seek to hide what data they have breached in attempts to avoid detection or attribution, or to increase the time they have to exploit their stolen data.
System designers have a well-established tool to help audit data accesses: server-side logging.
The server logs read requests received, even those from compromised clients.
Unfortunately, since RDMA READ commands from client to server do not involve the server's CPU, suddenly these data accesses cannot be logged.
We call these unauditable reads and believe they are untenable for systems that contain user data.Concurrency and protocol problems.
Unauditable writes are less sneaky than reads since the written data leaves a trace.
However, they can still cause chaos.
For example, if transactions execute without the server CPU, it becomes the responsibility of the client to correctly acquire and release locks (for example, in DrTM [47]).
An adversary may disrupt consistency by releasing a lock, or by simply ignoring locks and/or "abort" messages during a distributed transaction.
Additionally, traditionally immutable objects such as transaction history could be overwritten after they are "committed".
Breaking the RPC abstraction.
RDMA's wider interface breaks some of the layered abstractions distributed systems traditionally assume.
For instance, a non-RDMA application might use a library such as gRPC [17] for communication.
gRPC uses HTTP/2 as a transport layer with TLS encryption, carried by TCP, IP, and Ethernet.
Transport reliability would be provided by TCP, authentication might be provided by TLS, and actual modification of user data would be provided by RPC handlers running on the remote end.
Each of these layers has a narrow interface that behaves according to a simple contract.
RDMA disrupts these abstractions, particularly with the one-sided READ and WRITE operations that bypass the remote CPU entirely.Some RDMA systems, such as FaRM [12], attempt to replicate the RPC task-queuing abstraction by using RDMA WRITE operations to a shared buffer and keeping shared state about the head and tail of the buffer.
Unfortunately, this requires all clients to correctly and non-maliciously write to the appropriate point in the buffer; otherwise a client could overwrite an RPC or even modify another client's RPC before it is read by the server.Whole-Network denial of service.
Denial of service by spoofed packets was a concern in the Lee et al. 2005 paper on InfiniBand security [29] and denial of service situations were observed in practice in an early RoCEv2 deployment [19].
Table 1: The security consequences of using RDMA for distributed systems depend on how the system is designed to use the RDMA APIs.The left half of the table summarizes recent systems and their use of RDMA operations (to show directionality of SEND and RECV, we indicate APIs used by the client).
The right half summarizes the security implications of each system's design, which we discuss in Section 3.
An empty cell means a certain danger is not applicable to that system.
The security issues we explore make the compromise of a node in an RDMA system more damaging than typical distributed system compromises due to use of RDMA rather than a narrower API.
[12] x x x x HERD (2014) [24] x x x x DrTM (2016) [47] x x x x FaSST (2016) [25] x x x Octopus (2017) [31] x x x x x x Hyperloop (2018) [28] x x x x x x DrTM+H (2018) [46] x x x x x x xThe combination of these two factors is, however, unstudied and potentially quite dangerous: since RoCEv2 (unlike InfiniBand) requires a lossless network and Priority Flow Control [22], spoofed packets could contribute to problems such as the "PFC Pause Frame Storms" [19], potentially slowing down the entire network.
For example, if an adversary spoofs traffic that causes servers to produce a SEND to a specific client that is not expecting to RECV anything (as for data reads in HERD and FaSST [24,25]), the adversary may be able to overwhelm buffers at the targeted client or one of the switches en-route.
Depending on the application design, an unexpected SEND might instead push the connection into a corrupted state where no future RDMA commands will succeed, a situation difficult to recover from without recreating the connection and another form of Denial of Service.Execution Parameter Manipulation.
Hyperloop [28] is a unique system which registers portions of the server NIC's work queue (the buffers containing the commands and arguments for the NIC to execute in the future) as remotely writable memory so that arbitrary data can be replicated from the client to a third party without any involvement of the intermediate server CPU.
This strategy leads to vulnerabilities not seen in other systems, specifically parameter manipulation in the remote execution.
A malicious client could perform an unauditable write to the work queue, causing the server NIC to write data to a third-party that the client itself may not have access to!
This is another example of how the use of the RDMA APIs rather than more narrowly scoped APIs from traditional distributed systems can lead to more downstream harms from a single compromised client.We define this vulnerability as parameter manipulation because the authors of Hyperloop noted (in response to a query about APIs they use) that the APIs allowed them to separate the arguments that needed to be remotely writable from the specification of which RDMA operation to use [21].
Without this separation, the vulnerability would be even more serious since the client would be able to specify code to remotely execute on the server NIC.
Given the existing security problems with RDMA and increased difficulty in reasoning about system security, we consider remote execution to be exceptionally dangerous in an RDMA environment.Lessons from System Analysis.
There is more complexity to building secure RDMA systems than just fixing transport encryption and the other missing components from Section 2.
We consider unauditable reads to be particularly dangerous for cloud systems due to recent regulations (such as GDPR [14] and CCPA [5]) that expect details of which data was adversarially accessed in a data breach.
Now is the time to secure RDMA in the datacenter: we must address both fundamentals and the system design challenges while these systems are still in research and prototype stages.
Two hopeful trends for addressing RDMA's security problems are the prevalence of centralized configuration services in datacenter environments and the continued increase in processing capabilities of RDMA network hardware.
Below, we outline how these trends might combine to address the challenges of unencrypted packets and unauditable reads while minimally impacting RDMA performance.Encrypting and signing RDMA packets.
With the dangers of unencrypted RDMA traffic, particularly RDMA header information such as memory addresses and R_Keys, repeated for more than two decades [11,29,40,43], it is important to consider what components of the solution are difficult.
One common challenge in setting up encryption over the network is key distribution: each pair of communicating servers must derive shared secrets that can be used to encrypt and integrity-check (MAC or sign) packets.
The position of RDMA systems inside a datacenter offers an opportunity: in datacenters, centralized configuration services such as Chubby [4] or Zookeeper [20] abound.
Using one of these services to distribute shared keys between clients and servers seems tractable, since these services are already used to distribute per-machine information such as IP addresses.
In their 2005 work identifying problems with InfiniBand security, Lee et al. suggested that hosts could use provided keys to "sign" their messages, preventing undetectable modifications and preserving message integrity [29].
One aspect of this challenge that needs further investigation is how to transfer keys from a host CPU to its NIC.With modern, widely-used, cryptographic protocols, we can preserve both confidentiality and integrity of packets.
One possibility for RoCEv2 would be the DTLS (Datagram TLS) scheme that creates the functionality of TLS for UDP packets [39].
NICs are starting to offer accelerated encryption (though not for RDMA): there are NICs that offer DTLS (for standard UDP traffic) via an onboard ASIC [8,9,33] and programmable "SmartNICs" advertise high-performance encryption with their own hardware acceleration [6,32].
A 2016 press release from a NIC vendor announced "Low Latency 100Gbps line-rate" for DTLS [7].
Moving beyond NICs, on-the-wire solutions such as Catapult could also provide encryption at line rate [15,38].
A standardized secure version of RoCE (using DTLS) or iWarp (using TLS) would ensure that implementers on all platforms achieve the same guarantees.
The ingredients for high-performance packet encryption and integrity-checking are in place: researchers, cloud providers and hardware vendors need to standardize the needed features and ensure that they are available.Regaining auditability.
Preventing unauditable RDMA READ operations during a data breach requires logging that the adversary cannot circumvent.
Although SmartNICs might offer the programmability necessary to log one-sided operations at the receiver side, there would be a significant performance cost.
Instead, could a programmable switch, designed for much higher throughput than a NIC, sample RDMA packets that transverse it and duplicate them out to a logging server?
Does adversarial RDMA use have distinct statistical patterns from typical system behavior, detectable even via encrypted packets?
Could some control-plane RDMA traffic be redirected to a centralized system that will log it (in plaintext), while subsequent dataplane traffic proceeds on the existing, high-performance route?
This may require a move away from the "register memory once, use forever" design choice made by the systems we analyzed, instead having the logged packets give more specific information about which memory regions are currently being accessed.
We strongly encourage researchers to investigate these approaches.Additional directions.
Future security research is also necessary in other aspects of these increasingly advanced NICs.
For example, do the NIC design and its driver successfully protect process isolation on the local machine?
Between VMs that share the hardware?
Are there any additional security considerations when using RDMA over a wide-area network (such as between datacenters)?
Can adding additional computation or memory to advanced NICs help mitigate any of the security problems?
We encourage other researchers to consider these and related questions.
While a number of systems have incorporated RDMA for performance benefits [10,12,13,24,25,31,35,46,47] and others have attempted to improve the interface [1,44], relatively few have attempted to improve the security of such systems.
We briefly review those here.In a 2005 RFC about RDMA over IP, Romanow et al. identify security as a crucial component to the success of their proposal [40].
Unfortunately, their proposed solution, IPSec [3,26,27], never received wide adoption.Also in 2005, Lee et al. wrote about security flaws in the InfiniBand Architecture, including pointing out the critical weakness that is plaintext R_Keys for remote memory region access [29].
It appears that some of their mitigations for denial of service were incorporated into the InfiniBand spec [23].
Noronha et al. discuss some security considerations when layering NFS on top of RDMA: instead of opening the server memory up for READ and WRITE operations by the client, they have the client register its memory for remote access, contact the server via two-sided operations, and then let the server deposit or retrieve data from the client's registered memory [36].
This reduces the security risk of a compromised client, at the cost of much more effort by the server's CPU.
This goes against the trend of recent RDMA research systems, which seek to reduce the server's computational workload.Tsai and Zhang propose a number of improvements to RDMA in LITE [44], including doing a secure key exchange between servers involved in remote memory operations.
Their system design relies on the kernel to provide this functionality and does not consider an on-the-wire attacker.
Additionally, their implementation registers a single RDMA region for each machine due to limitations in NIC memory; this exacerbates the danger of a compromised machine.In more recent work, Tsai and Zhang demonstrate a number of security threats, implementation issues, and side channel vulnerabilities in RDMA NICs [43,45].
RDMA is increasingly being used to build critical distributed datacenter systems.
Unfortunately, we find that the security weaknesses of RDMA mean that a compromised node can do more damage when employing a RDMA-based implementation of these systems, such as exfiltrating data without leaving a trace or breaking concurrency contracts.
We believe it is crucial to close this security gap now, while these systems are still at the prototype stage in the datacenter.
3.
Unauditable RDMA READ operations -performed by an adversary who has compromised a storage client in the datacenter and is exfiltrating data -are a particularly concerning attack in the cloud scenario.
In "Regaining auditability", we presented a few ideas for ways to log data such that reads are still auditable.
We are eager to hear feedback on feasibility of these and any other ideas!
4.
If you have experience with other forms of modern kernel-bypass or CPU-bypass networking, are there security lessons we can learn from those systems?
Do any of the security concerns we identified for RDMA apply to other systems you are familiar with?
Are the risks and threat models similar?
5.
As other aspects of cloud processing are offloaded from the CPU on to specialized hardware, are there any confidentiality, integrity, or availability properties that are being lost in the transition?
If an adversary is another tenant on the cloud system, what might they be able to exfiltrate or manipulate?
How can their harm be limited?
The authors would like to thank our shepherd Michael Wei, as well as Ivan Evtimov, Shrirang Mare, and members of the University of Washington Systems lab for feedback on the paper.
This work was supported in part by an NSF Graduate Research Fellowship under Grant No.
DGE-1256082 and by DARPA grant FA8750-16-2-0032.
