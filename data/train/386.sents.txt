It would be useful to have a joint probabilistic model for a general relational database.
Objects in a database can be related to each other by indices and they are described by a number of discrete and continuous attributes.
Many models have been developed for relational discrete data, and for data with nonlin-ear dependencies between continuous values.
This paper combines two of these methods, relational Markov networks and hierarchical nonlinear factor analysis, resulting in joining nonlinear models in a structure determined by the relations in the data.
The experiments on collective regression in the board game go suggest that regression accuracy can be improved by taking into account both relations and nonlinearities.
Growing amount of data is collected every day in all fields of life.
For the purpose of automatic analysis, prediction, denoising, classification etc. of data, a huge number of models have been created.
It is natural that a specific model for a specific purpose works often the best, but still, a general method to handle any kind of data would be very useful.
For instance, if an artificial brain has a large number of completely separate modules for different tasks, the interaction between the modules becomes difficult.
Probabilistic modelling provides a well-grounded framework for data analysis.
This paper describes a probabilistic model that can handle data with relations as well as discrete and continuous values with nonlinear dependencies.Terminology: Using Prolog notation, we write knows(alex, bob) for stating a fact that the knows relation holds between the objects alex and bob, that is, Alex knows Bob.
The arity of the relation tells how many objects are involved.
The knows relation is binary, that is, between two objects, but in general relations can be of any arity.
The atom knows(alex, B) matches all the instances where the variable B represents an object known by Alex. In this paper, the terms are restricted to constants and variables, that is, compound terms such as thinks(A, knows(B, A)) are not considered.
For every relation that is logically true, there are associated attributes x, say a class label or a vector of real numbers.
The attributes x(knows(A, B)) describe how well A knows B and whether A likes or dislikes B.
The attribute vector x(con(A)) describes what kind of a consumer the person A is.
Given a relational database describing relationships between people and their consuming habits, we might study the dependencies that might be found.
For instance, some people cloth like their idols, and nonsmokers tend to be friends with nonsmokers.
The modelling can be done for instance by finding all occurrences of the template (con(A), knows(A, B), con(B)) in the data and studying the distribution of the corresponding attributes.
The situation is depicted in Figure 1.
Bayesian networks [6] are popular statistical models based on a directed graph.
The graph has to be acyclic, which is in line with the idea that the arrows represent causality: an occurrence cannot be its own cause.
In relational generalisations of Bayesian networks [7], the graphical structure is determined by the data.
Often it can be assumed that the data does not contain cycles, for instance in the case when the direction of the arrows is always from the past to the future.
Sometimes the data has cycles, like in Figure 1.
Markov networks [6], on the other hand, are based on undirected graphical models.
A Markov network does not care whether A caused B or vice versa, it is interested only whether there is a dependency or not.
This section describes the models that are combined into nonlinear relational Markov networks.
In (linear) factor analysis, continuous valued observation vectors x(t) are generated from unknown factors (or sources) s(t), a bias vector b, and noise n(t) by x(t) = As(t) + b + n(t).
The factors and noise are assumed to be Gaussian and independent.
The index t may represent time or the object of the observation.
The mapping A, the factors, and parameters such as the noise variances are found using Bayesian learning.
Factor analysis is close to principal component analysis (PCA).
The unknown factors may represent some real phenomena, or they may just be auxillary variables for inducing a dependency between the observations.
Hierarchical nonlinear factor analysis (HNFA) [11] generalises factor analysis by adding more layers of factors that form a multi-layer perceptron type of a network.
In this paper, there are two layers of factors h and s, and the mappings are:h(t) = Bs(t) + b + n h (t)(1)x(t) = Af [h(t)] + Cs(t) + a + n x (t) ,(2)where the nonlinearity f (ξ) = exp(−ξ 2 ) operates on each element separately.
HNFA can easily be implemented using the Bayes Blocks software library [10,12].
The update rules are automatically derived in a manner shortly described below.The unknown variables θ (factors, mappings, and the parameters) are learned from data with variational Bayesian learning [4].
A parametric distribution q(θ) over the unknown variables θ is fitted to the true posterior distribution p(θ | X) where the matrix X contains all the observations x(t).
The misfit is measured by Kullback-Leibler divergence D(· 񮽙 ·).
An additional term − log p(X) is included to avoid calculation of the model evidence termp(X) = 񮽙 p(X, θ)dθ.
The cost function is C = D(q(θ) 񮽙 p(θ|X)) − log p(X) = 񮽙 log q(θ) p(X, θ) 񮽙 ,(3)where 񮽙·· denotes the expectation over distribution q(θ).
Note that since D(q 񮽙 p) ≥ 0, it follows that the cost function provides a lower bound for the model evidence p(X) ≥ exp(−C).
The posterior approximation q(θ) is chosen to be Gaussian with a diagonal covariance matrix.
It is possible, though slightly impractical, to model also discrete values in HNFA by using the discrete variable with a soft-max prior [12].
In the binary case, the ith component of x(t) is left as a latent auxiliary variable, and an observed binary variable y(t) is conditioned by p(y(t) = 1 | x i (t)) = exp xi(t)1+exp xi(t) .
The general discrete case follows analogously requiring more than one auxiliary component of x(t).
The experiments in Section 3 use a thousand copies of a binary variable having the same conditional probability.
They can be united into one variable by multiplying its cost by one thousand.
Observing 800 ones and 200 zeros corresponds to fixing the variable to a distribution of 0.8 times one and 0.2 times zero.
A relational Markov network (RMN) [9] is a model for data with relations and discrete attributes.
It is specified by a set of clique templates C and corresponding potentials Φ.
Using the example in the introduction, a model can be formed by defining a single clique template C = (con(A), knows(A, B), con(B)) and the corresponding potential φ C over x(C) which is (a subset of) the concatenation of attribute vectors x(con(A)), x(knows(A, B)), and x(con(B)).
Given a relational database, the RMN produces an unrolled Markov network over all the attributes X.
The cliques c ∈ C(I) instantiated by a template C share the same clique potential φ C .
The combined probabilistic model isp(X) = 1 Z 񮽙 C∈C 񮽙 c∈C(I) φ C (x(c)),where Z is a normalisation constant and C(I) contains all the instantiations of the template C.
In general, a template can be any boolean formula over the relations.The general inference task is to compute the posterior distribution over all the variables X.
The network induced by data can be very large and densely connected, so exact inference is often intractable [9].
The belief propagation (BP) algorithm [6] is guaranteed to converge to the correct marginal probabilities only for singly connected Markov networks, but it is used as a good approximation also in the loopy case.
The learning task, or the estimation of the potentials Φ is done using the maximum a posteriori criterion.
It requires an iterative algorithm alternating between updating the parameters of the potentials and running the inference algorithm on the unrolled Markov network.
In nonlinear relational Markov networks (NRMN), the clique potentials are replaced by a probability density function for continuous values, in this case HNFA 1 The combination of these two methods is not completely straightforward.
For instance, marginalisation required by the BP algorithm is often difficult with nonlinear models.
Also, algorithmic complexity needs to be considered, since the model will be quite demanding.
One of the key points is to use probability densities p in place of potentials Φ.
Then, overlapping templates give multiple probability functions for some variable and they are combined using the product-of-experts combination rule described below.Combination Rules: One of the non-trivialities in making relational extensions of probabilistic models is the so called combination rule [7].
When the structure of the graphical model is determined by the data, one cannot know in advance how many links there are for each node.
One solution is to use combination rules such as the noisy-or.
Combination rule transforms a number of probability functions into one.
Noisy-or does not generalise well to continuous values, but two alternatives are introduced below.Using a Markov network and the BP algorithm corresponds to using probability densities as potentials and the maximum entropy combination rule.
The probability densities p C (x(C)) are combined to form the joint probability distribution by maximising the entropy of p(X) given that all instantiations of p C (x(C)) coalesce with the corresponding marginals of p(X).
For singly connected networks, this means that the joint distribution isp(X) = 񮽙 c p c (x(c))/ 񮽙 k p k (x(k)),where k runs over pairs of instantiations of templates and x(k) contains the shared attributes in those pairs.
Marginalisation of nonlinear models cannot usually be done exactly and therefore one should be very careful with the denominator.
Also, one should take care in handling loops.In the product-of-experts (PoE) combination rule, the logarithm of the probability density of each variable is the average of the logarithms of the probability functions that the variable is included in: p(x) ∝ n 񮽙 񮽙 C∈C 񮽙 c∈C(I) p C (x) for all x ∈ X, where only those n instantiated templates c that contain x, are considered.
PoE is easy to implement in the variational Bayesian framework because the term in the cost function (3) can be split into familiar looking terms.
Consider the combination of two probability functions p 1 (x) and p 2 (x) (that are assumed to be independent):񮽙 log q(x) 񮽙 p 1 (x)p 2 (x) 񮽙 = 񮽙 log q(x) p1(x) 񮽙 + 񮽙 log q(x) p2(x) 񮽙 2 .
(4)A characteristic of PoE is that implicit weighting happens in some sense automatically.
When one of the experts gives a distribution with a large variance and another one with a small variance, the combination is close to the one with small variance.
Inference in Loopy Networks: Inferring unobserved attributes in a database is in this case an iterative process which should end up in a cohesive whole.
Information can traverse through multiple relations.
2 The basic element in the inference algorithm of Bayes Blocks is the update of the posterior approximation q(·) of a single unknown variable, assuming the rest of the distribution fixed.
The update is done such that the cost function (3) is minimised.
One should note that when the distribution over the Markov blanket of a variable is fixed, the local update rules apply, regardless of any loops in the network.
Therefore the use of local update rules is well founded, that is, local inference in a loopy network does not bring any additional heuristicity to the system.
Also, since the inference is based on minimising a cost function, the convergence is guaranteed, unlike in the BP algorithm.Learning: The learning or parameter estimation problem is to find the probability functions associated with the given clique templates C.
Now that we use probability functions instead of potentials, it is possible in some cases to separate the learning problem into parts.
For each template C ∈ C, find the appropriate instantiations c ∈ C(I) and collect the associated attributes x(c) into a table.
Learn a HNFA model for this table ignoring the underlying relations.
This divide-and-conquer strategy makes learning comparatively fast, because all the interaction is avoided.
There are some cases that forbid this.
If the data contains missing values, they need to be inferred using the method in the previous paragraph.
Also, it is possible to train experts cooperatively rather than separately [3].
Clique Templates: In data mining, so called frequent sets are often mined from binary data.
Frequent sets are groups of binary variables that get the value 1 together often enough to be called frequent.
The generalisation of this concept to continuous values could be called the interesting sets.
An interesting set contains variables that have such strong mutual dependencies that the whole is considered interesting.
The methodology of inductive logic programming could be applied to finding interesting clique templates.
The definition of a measure for interestingness is left as future work.
Note that the divide-and-conquer strategy described in the previous paragraph becomes even more important if one needs to consider different sets of templates.
One can either learn a model for each template separately and then try combinations with the learned models, or try a combination of templates and learn cooperatively the models for them.
Naturally the number of templates is much smaller than the number of combinations and thus the first option is computationally much cheaper.So what are meaningful candidates for clique templates?
For instance, the template (con(A), con(B)) does not make much sense.
Variables A and B are not related to each other, so when all pairs are considered, con(A) and con(B) are always independent and thus uninteresting by definition.
In general, a template is uninteresting, if it can be split into two parts that do not share any variables.
When considering large templates, the number of involved attributes grows large as well, which makes learning more involved.
An interesting possibility is to make a hierarchical model.
When a large template contains others as subtemplates, one can use the factors s in Eq.
(1, 2) of the subtemplate as the attributes for the large template.
The factors already capture the internal structure of the subtemplates and thus the probabilistic model of the large template needs only to concentrate on the structure between its subtemplates.
As expected, nonlinear models were better than linear ones and collective regression was better than separate regression.
A traditional Markov network was applied for statically determining the status of the go board in [2].
Games played by people were used as data.
Humans play the game better, but still, this approach has an important downside.
The data contains only one possible future for each board position whereas a computer player can produce many possible futures.
At the learning stage, all those futures can be used together for the computational price of one.
Also, stones that are provably determined to be captured under optimal play (dead), might still be useful: By threathening to revive them, the player can gain elsewhere.
When data is gathered with unoptimal play, the stones are marked as not quite dead, which might be desirable.NRMN includes a probabilistic model only for the attributes and not for the logical relations.
Link uncertainty means that one models the possibility of a certain relation to exist or not.
Actually one can model link uncertainty using just the proposed methodology.
All the uncertain relations are assumed to be logically true and an additional binary attribute is included to mark whether the link exists or not.
One only needs to take into account that when this binary attribute gets the value zero, the dependencies between the other attributes are not modelled.
Also, time series data can be represented using relations obs(T ) for the observations at time T and ensues(T 1, T 2) to denote that the time indices T 1 and T 2 are adjacent.
These two examples give light to the generality of the proposed method.
In [12], HNFA is augmented with a variance model.
Modelling variances would be important also in the NRMN setting, because then each expert would produce an estimate of its accuracy and thus implicitly a weight compared to other experts.
In [9], relational Markov networks were constructed to be discriminative so that the model is specialised to classification.
The same could be applied here.Conclusion: A model was proposed for data containing both relations and nonlinear dependencies.
The model was built by combining two state-of-the art probabilistic models, hierarchical nonlinear factor analysis and relational Markov networks by using the product-of-experts combination rule.
Many simplifying assumptions were made, such as diagonality of the posterior covariance matrix, and separate learning of experts.
Also, learning the model structure (the set of clique templates) was left as future work.
Experiments with the game of go give promise for the proposed methodology.
