This work proposes a novel metric, Maximally Amortized Cost (MAC), for cost evaluations of error correction of predictive Chinese input methods (IMs).
With a series of real-time simulation , user correction behaviors are analyzed by estimating generalized backward compatibility of adaptive Chinese IMs.
Comparisons between three IMs by using MAC with different context lengths report empirical factors of context length for improving predictive IMs.
The error-tolerance level-Futile Effort, Beneficial Effort and Utility-of adaptive IMs is also proposed and analyzed.
Most ideograph-based Asian languages consist of thousands of characters, making it impractical to create keyboards along the same style as alphabetic languages.
In response, most modern systems come with built-in tools called input methods (IMs) for transforming multiple keystrokes into single ideographs.
IMs are often categorized into "radical-based" or "phoneticbased" methods.
With radical-based IMs, users construct characters by typing the composing radicals or strokes.
Alternatively, phonetic-based IMs rely on phonetic transcriptions of ideographs, where users create characters by typing in the approximate spellings of their syllables.
In the case of homographs or homophones, users are given a choice, and the proper character is selected and entered.Besides desktop environments in Asian languages, IMs are also essential in any language for ambiguous keyboards that have more than one character or letter assigned to each key, resulting in some uncertainty about the intended symbol when a key is pressed.
Ambiguous keyboards gain attentions because of mobile computing, which has limited space.
Also, such keyboards expand the communication possibilities for users with physical disabilities who have insufficient motor facility to operate a full-size keyboard.
Two methods enable ambiguous keyboards to access a large set of characters, and these differ depending on who performs the disambiguation.
First, there is the multi-tap method or non-predictive method, in which the user disambiguates using multiple keystrokes to uniquely indicate a character.
In the case of a full-size keyboard, additional keystrokes such as those applied through the CapsLock key are a kind of multi-tap entry.
The second approach uses a predictive method, in which the system disambiguates and presents a list of ordered candidates from which the user chooses.
For example, predictive IMs on the 12-key ITU-T keypad of mobile phones such as T9 and LetterWise have been studied with human-computer interaction (HCI) metrics that measure text entry performance in terms of speed and accuracy, in order to quantitatively analyze user experiences of different IMs Silfverberg et al., 2000).
All of these studies, however, focus on alphabetic languages, and mostly English; thus far, HCI research on IM in other languages has been underdeveloped.While various types of IM can be used with a keyboard, this work specifically examines the context of predictive phonetic-based methods for Chinese.
Predictive phonetic-based IM not only facilitates word prediction and word or phrase completion, but also disambiguates homophones of syllables into characters.
To date, most natural language processing (NLP) research on Chinese IMs has focused on these predictive phoneticbased approaches.
Many researchers have applied n-gram language modeling (LM) and hidden Markov models to IMs, such as Chen et al. (2000), Gao et al. (2002), Wang et al. (2004), and Wu et al. (2003); Maximum entropy (Li et al., 2007) and conditional random fields (Xiao et al., 2009) have also been employed.
While the studies above have made important contributions, they also assume fixed rules or stationary probabilities.
Developers of IMs, however, are expected to pay more attention to the increasing needs on personalization 1 and new word supplements via search engine logs 2 or social networks 3 .
Only a handful of research papers to our knowledge explore adaptive language modeling of IM for Asian languages.
Tanaka-Ishii et al. (2003) have examined corpus for vocabulary acquisition for Japanese in terms of reused words and unused words; Suzuki and Gao (2005) have proposed an error ratio corresponding to the number of newly introduced errors per each improvement after new training text was supplied.
These two studies reflect a common expectation of IM users-backward compatibility-which means a word prediction that was previously correct should remain correct with new words recognized simultaneously.This work intends to expand the approach towards backward compatibility using novel evaluation methods for Chinese predictive phoneticbased IM, by comparing text entry performance before and after user corrections of predictive IM-generated errors.
Once an error is left uncorrected, it becomes noise to an IM with the ability to adapt.
In addition, user corrections could be more complicated in predictive Chinese IMs than Japanese ones.
When the user modifies some character, its surrounding characters often change automatically, because unlike Japanese, Chinese syntax does not have clear cues and orders of subject-verb-object typology.
Thus, predictive Chinese IMs must rearrange the whole entered text to construct more likely context according to certain user modifications.
After this kind of continuous automatic adjustment, user feedback is often too vague to interpret into exact word boundaries for adaptation, in terms of vocabulary acquisitions.
It is considerably closer to daily usage of IM and more difficult than most previous works of adaptive IMs that acquire new information from correct and manually segmented transcriptions.
This work suggests that a robust predictive Chinese IM should tolerate noisy user feedback during adaptation, in addition to the backward compatibility mentioned earlier.To improve understanding of these situations, this work reviews existing performance evaluation metrics related to IMs, and then proposes extensions of these metrics for predictive and adaptive Chinese IMs, especially in cases of generalized backward compatibility and errortolerance level for cost and influence.
This work also develops a platform that is fully capable of simulating user-IM interaction, so as to collect data for quantitative comparison of various uses or different IMs.
The proposed evaluation metrics and simulation results provide helps for further NLP investigation of predictive phoneticbased IM on error-tolerant adaptation and conduct pilot tests to report empirical factors before engaging in labor-intensive corpus annotations and human-participated HCI research.
with Adaptation Ability Recent Chinese predictive IM products provide several ways for users to leave feedback on vocabulary acquisition.
These methods practice in two different perspectives: online vs. offline and explicit vs. implicit.
Online feedback indicates that an IM collects unknown words or re-ranks known words based on the user's current actions, while offline feedback means an IM extracts similar information via user-provided content or logs.
When the user indicates their preferences directly, an IM receives explicit feedback; otherwise it must interpret user-IM interactions for implicit feedback.
While offline and explicit feedback can be modeled as reinforcement learning or through the research of Tanaka-Ishii et al. (2003) or Suzuki and Gao (2005), our goal is to explore the relatively unfamiliar territory of implicitly online user feedback.
First, extending the definition from Tanaka-Ishii et al., (2003) any predictive IM with adaption abilities lets the user enter text continuously in five stages:1.
The user enters an ambiguous source keystroke string.2.
The IM retrieves candidate chunks corresponding to the source string from its built-in database and the user's profile.3.
The IM sorts these candidate chunks and composes most likely chunks to a target string, according to a particular evaluation function.4.
The user modifies the target string by choosing candidate chunks in case the IM's prediction is not entirely correct.5.
The IM adapts the user's modifications with context as implicit online feedback for user profiling.One may argue that user's modifications can be accumulated as logs for lazy evaluation as offline feedback.
According to some Chinese IM product's customer service reports (personal communication), however, users expect their modifications to be adapted as soon as possible to avoid repeat modifications for the same error cases.
This expectation motivates this work to investigate real-time solutions of online feedback.
One intuitive and ideal solution of online feedback involves applying early evaluations of Move-to-Front ( Bentley et al., 1986) and Prediction by Partial Match ( Bell et al., 1990) techniques on modified chunks with context.
In our experience, however, users may also adapt to an IM's performance and develop habits to correct just one chunk and then submit the target string immediately, which leaves fewer contexts for an IM to analyze.
To overcome this situation, some IMs analyze unmodified target strings for more information, which can be misleading if the user has left some incorrect chunks.
Eventually users will face a dilemma: typing more chunks to feed an IM for better adaptive predictions but encountering more errors.
Hence this work studies properties of IM regarding the trade-off between cost and benefit of error correction.
In order to understand the role of Amortized Cost that will be defined later in this section, it is first useful to examine previous research on error correction by describing well-known evaluation metrics for text entry and considering their shortcomings.
To avoid confusion, all metrics use the notations formerly introduced by as follows: Presented text (P) is text that participants were required to enter by the experiment, and |P| is the length of P; Transcribed text (T) is the final text entered by the participant, and |T| is the length of T; Input stream (IS) is the text that contains all keystrokes performed while entering P and |IS| is the length of IS; Correct (C): the number of correct characters in T; Incorrect Not Fixed (INF): the number of unnoticed errors in T; Incorrect Fixed (IF): keystrokes are those in IS that are not editing keys (F), and which do not appear in T; Fixes (F): are keystrokes in IS, which are edit functions, modifier keys, or navigation keys.
Evaluating the accuracy of text entry involves more than simply comparing strings.
Consider the following example:P: the quick brown fox T: the quixck brwn foxThe notion of minimum string distance (MSD), which is the minimum number of primitivesinsertions, deletions, or substitutions-needed to transfer one string to another, is introduced to deal with such a situation ( Soukoreff et al., 2001).
In this case, P and T's MSD is 2.
The idea of MSD error rate is to find the smallest number of operations to transform T to match P, and then to calculate the ratio of that number to the larger of |P| and |T|.
The MSD error rate is defined as%, 100 ) , ( × = A S T P MSD te MSDErrorRawhere A S is the mean length of the alignment strings.
MSD can only provide information about the remaining T, because errors corrected by the editing process can no longer be observed.
In contrast to MSD, it is possible to observe corrected errors by logging all keystrokes as IS.From IS, a new metric, key-strokes per character (KSPC), is defined by MacKenzie (2001) simply as |IS| / |T|.
KSPC sketches the effort required to correct errors without considering uncorrected errors.
A large number of errors that only require low correction effort and a few errors requiring high correction effort may result in the same KSPC value.
Although the keystrokes that send errors and keystrokes that correct errors are different, they are not differentiated by KSPC.
After observing the shortcomings of the MSD error rate and the KSPC value, proposed a unified error metric that logs IS in the same way as KSPC and then classifies the keystrokes to analyze T.
The MSD is only concerned with INF, while KSPC only reports the sum of IF and F.
The Total Error Rate is a unified method, which recognizes all keystrokes of INF and IF and measures the ratio of the total number of incorrect and corrected characters as% 100 × + + + = IF INF C IF INF Rate TotalError .
The MSD error rate and KSPC statistic can be defined in terms of the keystroke taxonomy as%; 100 × + = INF C INF te MSDErrorRa .
INF C F IF INF C KSPC + + + + ≈For example, once a user corrected the error "brwn" of T to form "the quixck brown fox" as T', TotalErrorRate(T'), MSDErrorRate(T'), and KSPC(T') will be (2/18)%, (1/17)%, and 19/17, respectively.
Predictive Chinese IMs consist of a display buffer for composition as a target string waiting for editing, and lists of candidate chunks for every potential editing position.
These characteristics, which come from the complexity of languages that do not have delimiters (e.g. spaces) in their writing systems, such as Chinese and Japanese, are not captured by the metrics discussed above, because those metrics were originally designed for short text entry with alphabetic languages on handheld devices.
It is therefore necessary to consider an alternative approach to overcome the shortcomings of existing metrics.
In doing so, this work first examines long buffer variables and multiple candidate lists by reviewing Fitts' law and Hick's law before using them to create an improved evaluation metric.
Fitts' law is a function of the distance to the final target and its size, and is used to predict the time required to move rapidly from a starting position to a final target area.
Mathematically, Fitts' law can be formulated in several ways.
One refined form, proposed by ) is ), 1 / ( log 2 + + = w d b a twhere the average time t is taken to complete the movement, and a and b are empirical constants that can be determined by fitting a straight line to measured data.
The distance d is from the starting point to the center of the target.
The width w is of the target measured along the axis of motion.
The term log 2 (d/w + 1) represents the index of difficulty (ID) of the given task.
Since a text entry task usually shifts the cursor by keystrokes rather than mouse movements, ID may link to the number of keystrokes directly.
When correcting typing errors, both the time taken by moving cursor and the time for candidate selection should be considered.
Here, Hick's law, ) 1 ( log 2 + + = n b a t , describes the time, t, it takes users to make a decision as a function of the equal possible n choices they have, where a and b are empirical constants.
The law hints some baseline points, but the realistic candidate selection time still needs to be measured via subject experiments.
As far as we know, Hick's law has not been widely adapted to candidate selection for typing error correction of text entry tasks.
In previous work of Arif et al. (2009), text entry experiments are conducted with one of three error correction conditions, including None, Recommended and Forced.
The participants are not allowed to correct any error in the None condition.
On the other extreme, participants are forced to correct every error to keep T error free in the Forced condition.
Lastly, participants are recommended to correct errors as they identify them in the Recommended condition.
During the None condition, typists sometimes instinctively tried to correct their errors before they remembered that they could not.
Such a failed error correction attempt takes a bit of time, as participants need to mentally recover and resume the original task.
Again, during the Recommended condition participants tended to correct their errors almost the moment they made them (i.e. character level error correction), making this condition similar to the Forced condition.In the end, Arif et al. did not find any relationship between the typists' entry speed and their instinctive attempt to correct errors.
Therefore, the None and Forced conditions are not considered hereafter.
Furthermore, this work argues that a more realistic condition of error correction lies in the spectrum of motivations behind Recommended conditions.
For the purpose of efficiency, a user may not correct most errors that occur during mobile phone texting or Internet chatting, but the same user is likely to try to make every word as effective as possible in situations of formal writing.
When a predictive IM is involved, the user tends to find a compromise between efficiency and effectiveness according to the certain IM's performance, as mentioned in subsection 2.1.2 of users' habit, for example.
In fact, technical news articles in China have even devised a conventional performance evaluation metric called "accuracy rate of the first suggested chunk 4 (首選詞正確率)".
This has not been adopted in academic papers, since it lacks clear definitions for chunk and reference corpus.
If the predictive IM adapts user behavior while the user adapts IM behavior simultaneously, feedback inbetween could be very complicated.
To model this phenomenon, situations are categorized, as shown in Table 1, and an information theoretic point of view is applied to define the Amortized Cost (AC) of text entry as follows: where the basic measurement of the four categories is character.
Some might argue that the metric F should be counted on keystrokes.
However, each function/control keystroke F can successfully map to a virtual character unit as an information term.
As long as the numerators and denominators are measured in the same unit, the definition is satisfied.
Although Table 1 shows three situations, only situation S 0 is easy for automated simulation because it is unconcerned about methods of corrections.In alphabetic text entry, if assuming the same amount of errors occurred and the user applied the same correction skill in different situations, one could design a keystroke logger to record all editing processes and find the boundary of AC: 4 Unfortunately, unlike alphabetic text entry, it is insufficient to map the metric F to as the same measurement of the keystroke or character one by one for Chinese IMs, as with other metrics.
For example, a backspace keystroke can be used to either erase a Chinese character or a phonetic character, and thus runs into trouble when evaluating its cost.
For this reason, this work defines the metrics average correction penalty (p), average correction reward (r) and then another AC of modification (AC m ) instead of the original termF all / C as , ) max( , , ) max( 0 0 0 0 C ID t INF t r p AC INF C C r INF C ID t INF t p F H m F H × + × = = ⇒ + = + × + × =where ID is calculated by the distance moving to the furthest wrong word needing correction; t H describes the time for selecting candidates measured by Hick's law; t F represents the time for moving a cursor through ID based on Fitt's law.
From these variables, a Maximally Amortized Cost (MAC) is proposed as follows:. )
max( 0 0 0 C ID t INF t C INF AC C INF MAC H H m × + × + = + =Here, MAC can be viewed as a metric to estimate user experiences of Chinese predictive IMs using automated simulation, which will be demonstrated in the next section.
Tanaka- Ishii et al. (2003) argue that the major drawback to predictive IM is related to dictionary use; a user cannot enter vocabulary not registered in the dictionary.
They presume that missing vocabulary should exist within the user's text, depending on the user's context.
In order to analyze how vocabulary is reused when a user edits text, they investigate how the reused word rate changed according to the offset of a text, by marking the text at the offset of 0.5 KB and counting the reused word rate in the 1 KB window.
Their results suggest that context is provided by 70% to 80% of the vocabulary and the story evolves through the rest.
From this observation, they suspect that typical users reuse 70% to 80% of their vocabulary only after an offset window of several KB.
Based on this previous work, simulations where text is typed repeatedly should Gao (2005) present comparative experiment results on four techniques of adaptive LM for IMs.
Their evaluation of four techniques is unique in that they go beyond simply comparing those techniques in terms of character error rate (CER); they measure the distance between background and adaptation domains by using a metric of distributional similarity, and attempt to correlate it with the CER of each adaptation method.
They also propose a novel metric for measuring the side effects of adapted models using the notion of backward compatibility.
The error ratio (ER) is introduced for estimating side effects, which is defined as |E A | / |E B |, where |E A | is the number of errors found only in the newly adapted model, and |E B | the number of errors corrected by the new model.
Intuitively, ER captures the cost of improvement of certain adaptation method, corresponding to the number of newly introduced errors per each improvement.Arif et al. have observed that error correction involves both human-specific elements and system-specific elements; for example, the time to verify a correction, and the key sequence required for replacing a wrong character, respectively.
On one hand, users usually immediately verify what they have typed and correct errors right away, i.e. character-level correction.
On the other hand, users also chunk their input and verify the result only after typing a few characters or even the whole word as word-level correction.
This observation is quite similar to common usages of predictive Chinese IMs.
As determined by analysis of human error correction behavior, however, the predominant strategy for alphabet text entry is to use the backspace key for both character-level and word-level corrections.
This situation is different from predictive Chinese IMs, in that users tend to move to particular positions and then correct Chinese chunks (i.e. de facto words from the user's perception) by substitution.This work expands the concept of backward compatibility to indicate a considerably more general and continuous scenario: previous corrections must not only remain correct after adaptation, but also new manual corrections made during adaptation should come into effect as soon as possible and remain correct as long as possible.
For generalized backward compatibility (GBC) of adaptive Chinese IMs, a diagram from Arif et al. (2010) is modified to introduce new factors that represent intentional user skip error correction as Figure 1.
Unlike Arif et al., who focused on how errors from non-predictive text entry systems (ρ s error ) affect user experiences, this work is interested in how human correction behaviors (ρ h correction ) influence accuracy of adaptively predictive IMs.The γ values stand for components of ρ at certain decision point.
For instance, γ i,h error represents the chance of human error occurred during the process of input.
In order to test and demonstrate the ability of proposed evaluation methodology, this work conducts a simulation of three IM products.
Three products of adaptively predictive IMs, named IM-A, IM-B, and IM-C, are used in the simulation.
The presented text P consists of 4,000 sentences, containing 39,469 words retrieved from the Academia Sinica Balanced Corpus (ASBC) (Chen et al., 1996).
Two independent variables are simulated: context length in terms of character and ρ h correction .
The context length k is for different strategies of word-level correction.
Since there is not yet a consensus on the Chinese word-hood debate, the number of words is calculated by characters as context length k in this work.
It is interesting to observe how IMs are influenced by these different strategies.
The simulation is designed so that if |T| is shorter than k, errors occurring in T will not change.
Otherwise, the simulation will chop the first k characters of T to form a substring, denoted as T', and then process T' in the same way.
For example, in a simulation with context length 3, "ab" remains intact, while "abcdefgh" is processed separately in three substrings "abc", "def", and finally "gh.
"The factor ρ h correction simulates human correction behavior.
Here, errors are classified into two types: IM prediction error (ρ s error ) and human typing error (ρ h error ).
The simulation simplifies Figure 1.
Activity diagram of user correction the sum of ρ s error and ρ h error as the ratio of corrected errors.To simulate the actual typing process, the presented text P is converted into related keystrokes.
Common transcription methods of Chinese characters are Bopomofo (also known as Zhuyin) and Pinyin.
This simulation uses Bopomofo.
There are many keyboard layouts for Bopomofo, such as Daqian (大千), Eten (倚天) or Hsu's (許氏).
This work applies Daqian.
Each Chinese character of P is transcribed into Bopomofo syllables and then transformed into Daqian keystrokes.For MAC, estimating the time spent on candidate selection (t H ) and cursor movement (t F ) to the error needing correction is complicated.
Many situations can occur during candidate selection, such as resorting to numeric keys to make a choice or seeking the correct word appearing on the next page of the candidate list, etc.
Time also varies from person to person depending on how familiar they are with the IM.
Clearly, it is impossible to quantify these two factors without having real-time user inquiries.
This simulation assumes that the average time taken to choose a proper candidate is the same for every correction.
Notably, the method of estimating t F on a QWERTY keyboard is different from that of estimating t F on a mobile keypad, because only thumbs are usually used in the latter case.
In spite of this difference, it is observed that Chinese IM users rarely approach cursor movement with direct pointing devices such as a mouse.
Thus, the value of t F is simplified to the distance in terms of the character to which the cursor has to be moved.The steps of the simulation consists of using different ρ h correction to type all data of P, and then typing the same data again without correcting any error, so as to record and compare the character accuracy rate (CAR) after adaptation.
For calculating CAR, T generated via particular IM is recorded and checked with P. For calculating MAC, the number of C and INF are counted while typing.
During the simulation, the adaptive features of the IMs are enabled.
Before the simulation, the adapted user profile of each IM is cleaned to ensure that the IM's CAR is unbiased.
Figure 2 shows ρ h correction effects at context length 6 that is in the middle of relatively stable curves with low MAC for IM-A, IM-B, and IM-C, according to previous results.
Instead of using ER, it is found sufficient to compare CARs before and after adaptations in order to analyze the GBC of IM-A, IM-B, and IM-C.
While the more corrections the user made the better adaptation IM-A performs, IM-B and IM-C show lower GBC when the user corrects more than 50% of errors.
According to Figure 2, the balanced choice of context length for IM-B and IM-C, in terms of MAC managing the trade-off between correction costs and context-provided benefits, is around 6 characters.
This result suggests that it is possible to improve IM-B or IM-C by maintaining the size of a chunk for prediction and adaptation to 6 characters to save users' precious time in cursor movement and candidate selection, without significantly decreasing accuracy.
In the situation of IM-A, however, the ideal window size can expand to 8-13 characters, since the tail of its curve is smoother than IM-B and IM-C.
Such difference is conjecturally related to their respective prediction and adaptation algorithms.
The simulation result of Figure 3 show that at a context length of six characters, IM-A represents genuine GBC when the user corrects more than 50% of errors, but IM-B and IM-C encounter confusions when the user actively provides feedback.
Since GBC involves user expectations of how fast a manually corrected chunk is adapted and how long it is sustained, this work provides a deeper analysis by defining three aspects of the error-tolerance level (ETL) as follows:Futile Effort (E f ): how many times a missing vocabulary in terms of chunk is typed by the user but still cannot be adapted by the IM;Beneficial Effort (E b ): how many times a missing vocabulary in terms of chunk is corrected by the user before it is adapted by the IM; Utility (U): how many times an adapted chunk is used before it is "forgotten" (because of the IM's limitation of memory space and/or adaptation algorithm, in general cases).
Table 2 and Table 3 show the corresponding maximums/averages of these three aspects for IM-A and IM-B, respectively, where chunks are sampled by character bi-grams and tri-grams automatically, so as to bypass the issue of Chinese word segmentation standards.
The ETLs of IM-C are omitted in the interest of brevity and clarity, since IM-C's curves of MAC and GBC are similar to IM-B's.
For counts of manually corrected chunks that are never adapted as E f , both IM-A and IM-B show that when the user puts more effort into correction, systems encounter more trouble with disambiguation.
Statistics on reused counts of chunks U provide a different angle to CAR comparison of adaptation on GBC.
IM-A holds adapted chunks better when the user has partially corrects input errors.
Although IM-B seems to be relatively stable, it is unable to sustain its accuracy as long as IM-A.
For quick responses and short-term memory of recently adapted chunks that are interpreted from E b , IM-A and IM-B both get confused when the user corrects more frequently, and IM-A struggles harder than IM-B on the top-1 chunk.
More specifically, for example, IM-A encounters frequent problems with Chinese homophones, where "his," "her" and "it" are all pronounced in the same disyllable, while IM-B seems to avoid any problems with this situation.
Notably, IM-A's CAR series of GBC has correlation coefficients 0.49, 0.92, and 0.66 to E f avg , E b avg , and U avg , respectively, while IM-B's has -0.78, -0.62, and -0.51.
This work proposes a novel metric for text entry evaluation of adaptively predictive Chinese IMs.
The modification process of predictive Chinese IMs is quite different from that of alphabetic text entry (e.g. in English).
Therefore, combining the time taken by cursor movements and candidate selections, and the Amortized Cost of information theory, the proposed metric, called the Maximally Amortized Cost (MAC), estimates the error correction cost of predictive Chinese IMs.
A series of real-time simulation is then conducted, which approximates user correction behaviors for evaluation of generalized backward compatibility of adaptive Chinese IMs.
Comparisons between three IMs using MAC with different context lengths report the appropriate context length as empirical factors for simulation and a possible direction to improve predictive Chinese IMs.
This work has also suggested three aspects of error-tolerance level-Futile Effort, Beneficial Effort, and Utility-that could be useful for further investigation such as building reference corpus for shared tasks of IMs.
This research was supported in part by the National Science Council under grant NSC 100-2631-S-001-001, and the research center for Humanities and Social Sciences under grant IIS-50-23.
Jaimie Lin, James Zhan, Jerry Lin, and Even Zheng contributed a lot of programming assistances.
Dane Meyer is appreciated for his editorial assistance.
The authors would like to thank anonymous reviewers for their constructive criticisms.
