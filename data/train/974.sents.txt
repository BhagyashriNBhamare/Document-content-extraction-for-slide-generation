This paper introduces a new scoring criterion, factorized normalized maximum likelihood, for learning Bayesian network structures.
The proposed scoring criterion requires no parameter tuning, and it is decomposable and asymptotically consistent.
We compare the new scoring criterion to other scoring criteria and describe its practical implementation.
Empirical tests confirm its good performance.
The popular Bayesian criterion, BDeu (Buntine, 1991), for learning Bayesian network structures has recently been reported to be very sensitive to the choice of prior hyperparameters (Silander et al., 2007).
On the other hand, general model selection criteria, such as AIC (Akaike, 1973) and BIC (Schwarz, 1978), are derived through asymptotics and their behavior is suboptimal for small sample sizes.
The study of different scoring criteria is further complicated by the fact that learning the network structure is NPhard for all popular scoring criteria (Chickering, 1996), even if these criteria have a convenient characteristic of decomposability, which allows incremental scoring in heuristic local search (Heckerman et al., 1995).
Due to recent advances in exact structure learning ( Koivisto and Sood, 2004;Silander and Myllymäki, 2006) it is feasible to find the optimal network for decomposable scores when the number of variables is less than about 30.
This makes it possible to study the behavior of different scoring criteria without the uncertainty stemming from the heuristic search.In this paper we introduce a new decomposable scoring criterion for learning Bayesian network structures, the factorized normalized maximum likelihood (fNML).
This score features no tunable parameters, thus avoiding the sensitivity problems of Bayesian scores.
We show that the new criterion is asymptotically consistent.Unlike AIC and BIC, it is derived based on optimality criterion for finite sample sizes, and it has a probabilistic interpretation.The rest of the paper is structured as follows.
In Section 2, we will first introduce Bayesian networks and the notation needed later.
In Section 3, we review the most popular decomposable scores, after which in Section 4, we are ready to introduce the fNML criterion.
We then briefly discuss the implementation of this new score in Section 5.
Section 6 presents the empirical experiments, and the conclusions are summarized in Section 7.
We assume that reader is familiar with Bayesian networks (for tutorial, see (Heckerman, 1996)), and only introduce the notation needed later in this paper.A Bayesian network defines a joint probability distribution for an m-dimensional multivariate data vector X = (X 1 , . . . , X m ).
We assume that all variables are discrete, so that variable X i may have r i different values {1, . . . , r i }.
A Bayesian network consists of a directed acyclic graph G and a set of conditional probability distributions.
We specify the DAG with a vector G = (G 1 , . . . , G m ) of parent sets so that G i ⊂ {X 1 , . . . , X m } denotes the parents of variable X i , i.e., the variables from which there is an arc to X i .
Each parent set G i has q i (q i = Xp∈G i r p ) possible values that are the possible value combinations of the variables belonging to G i .
We assume a non-ambiguous enumeration of these values and denote the fact that G i holds the j th value combination simply by G i = j.The local Markov property for Bayesian networks states that each variable is independent of its non-descendants given its parents.
Functionally this is equivalent to the following factorization of the joint distributionP (x | G) = m i=1 P (x i | G i ).
(1)The conditional probability distributions P (X i | G i ) are determined by a set of parameters, Θ, via the equationP (X i = k | G i = j, Θ) = θ ijk ,where k is a value of X i , and j is a value configuration of the parent set G i .
We denote the set of parameters associated with variable X i by Θ i .
For Since the rows of D are assumed to be i.i.d, the probability of a data matrix can be calculated just by taking the product of the row probabilities.
Combining equal terms yieldsP (D | G, Θ) = m i=1 q i j=1 r i k=1 θ N ijk ijk ,(2)where N ijk denotes number of rows inD X i =k,G i =j .
For a given structure G, we use notationˆP notationˆ notationˆP (D | G) = sup θ P (D | G, θ).
The maximizing parameters are simply the relative frequencies found in data:ˆ θ ijk = N ijk N ij, where N ij denotes the number of rows in D G i =j , or 1.0 if N ij = 0.
We often drop the dependency on G when it is clear from the context.
In general, a scoring function Score(G, D) for learning a Bayesian network structure is called decomposable, if it can be expressed as a sum of local scoresScore(G, D) = m i=1 S(D i , D G i ).
(3)Many popular scoring functions avoid overfitting by balancing the fit to the data with the complexity of the model.
A common form of this idea can be expressed asScore(G, D) = logˆPlogˆ logˆP (D | G) − ∆(D, G), (4)where ∆(D, G) is a complexity penalty.The maximized likelihoodˆPlikelihoodˆ likelihoodˆP (D | G) decomposes by the network structure, and for the decomposable scores handled in this paper, the complexity penalty decomposes too.
Hence, we can write the penalized scores in the decomposed form (3), with the local scores given byS(D i , D G i ) = logˆPlogˆ logˆP (D i | D G i ) + ∆ i (D i , D G i ).
(5) Different scores differ in how the local penalty ∆ i (D i , D G i ) is determined.
Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) are two popular decomposable scores for learning Bayesian network structures.
These scores do not have any additional parameters so in this sense they are similar to the proposed fNML score.
The penalty terms for these scores are∆ BIC i = q i (r i −1) 2ln N , and ∆ AIC i = q i (r i − 1).
Both of these complexities are independent of the data, and only depend on the arities r i of random variables and the structure of the Bayesian network.
Bayesian Dirichlet (BD) scores assume that the parameter vectors Θ ij are independent of each other and distributed by Dirichlet distributions with hyper-parameter vector α ij .
Given a vector of hyper-parameters α, the local score can be written asS BD (D i , D G i , α) = log P (D i | D G i , α) = q i j=1 log P (D G i =j i | D G i =j G i , α ij ) = q i j=1 log B( α ij + N ij ) B( α ij ) ,where B is a multinomial Beta functionB(α 1 , . . . , α K ) = K k=1 Γ(α k ) Γ( K i=1 α k ).
With all α ijk = 1 we get a K2-score (Cooper and Herskovits, 1992), and with α ijk = α q i r i we get a family of BDeu scores popular for giving equal scores to different Bayesian network structures that encode the same independence assumptions.
BDeu scores depend only on a single parameter, the equivalent sample size α.
Recent studies on the role of this parameter show that network learning under BDeu is very sensitive to this parameter ( Silander et al., 2007).
For comparison, we can write the BD-score as a penalized maximized likelihood with penalty∆ BD i (D i , D G i ) = (6) q i i=i logˆP logˆ logˆP (D G i =j i | D G i =j G i ) P (D G i =j i | D G i =j G i , α ij ) .
We immediately notice that this penalty is always positive.
The complexity is datadependent and it is controlled by the hyperparameters α ijk .
The asymptotic behavior of this Bayesian regret is well studied (Grünwald, 2007).
However, when learning Bayesian networks, the data parts D G i =j i are often very small, which makes asymptotic result less informative.
The factorized normalized maximum likelihood (fNML) score is based on the normalized maximum likelihood (NML) distribution (Shtarkov, 1987;Rissanen, 1996).
The NML distribution for the model class M (which may or may not be a Bayesian network) is the unique distribution solving the minimax problemmin Q max D ′ ˆ P (D ′ | M) Q(D ′ | M) ,(7)where Q ranges over all distributions.
As originally shown by Shtarkov (1987) the solution of the above minimax problem is given byP NML (D | M) = ˆ P (D | M) D ′ ˆ P (D ′ | M) ,(8)where the normalization is over all data sets D ′ of a fixed size N .
The log of the normalizing factor is called parametric complexity or regret.
Evaluation of the normalizing sum is often hard due to exponential number of terms in the sum.
Currently, there are tractable formulas for only a handful of models; for examples, see (Grünwald, 2007).
In the case of a single r-ary multinomial variable and the sample size n the normalizing sum is given byC r n = k 1 +k 2 +...+kr=n n!
k 1 !
k 2 !
· · · k r !
r j=1 k j n k j ,(9)where the sum goes over all non-negative integer vectors (k j ) r j=1 that sum to n.
A linear-time algorithm for the computation of C r n was introduced recently by .
Given a data set D, the NML model selection criterion proposes to choose the model M for which the P NML (D | M) is largest.
After taking the logarithm the score is in a form of penalized log likelihood with complexity penalty describing how well the model can fit any equal size dataset D ′ .
Because of the score equivalence of the maximum likelihood score, the NML score is score equivalent as well.
However, it is not decomposable, and the parent assignment problem is known to be NP-hard (Koivisto, 2006).
Sacrificing the score equivalence we propose a decomposable version of this score, which penalizes the complexity locally similarly to the other decomposable scores.
Specifically, we propose the local scoreS fNML (D i , D G i ) = log P NML (D i | D G i ) (10) = logˆP logˆ logˆP (D i | D G i ) D ′ i ˆ P (D ′ i | D G i ) ,where the normalizing sum goes over all the possible D i -column vectors of length N , i.e.,D ′ i ∈ {1, . . . , r i } N .
Since equation (10) defines a (log) conditional distribution for the data column D i , adding these local scores together yields a total score that defines a distribution for the whole data.
In this sense fNML can be seen as an alternative way to define the marginal likelihood for the datalog P fNML (D | G) = m i=1 log P NML (D i | D G i ).
At the same time, combining the local scores yields an enumerator that equals the decomposition of the maximum likelihood, thus the whole score can be seen as a penalized maximum log-likelihood with local (data-dependent) penalties∆ fNML i (D G i ) = log D ′ i ˆ P (D ′ i | D G i ).
(11)The following observation follows from the factorization of the maximum likelihood by the parent configurations, and it is crucial for efficient calculation of the local penalty term.
Theorem 1.
The local penalty of fNML can be expressed in terms of multinomial normalizing constants∆ fNML i (D G i ) = q i j=1 log C r i N ij ,whereC r i N ijis the normalizing constant of NML for an r i -ary multinomial model with sample size N ij .
The theorem follows by noting that the maximized likelihoodˆPlikelihoodˆ likelihoodˆP (D i | D G i ) factorizes into independent parts according to the values of D G i .
To conclude this section we show that asymptotically, and under mild regularity conditions, the fNML score belongs to the (large) class of BIC-like scores that are consistent.
Other scores in this class include most Bayesian and MDL criteria.
The regularity conditions required for BIC-like behavior typically exempt a measure zero set of generating parameters, such as the boundaries of the parameter simplex.
The following theorem gives sufficient conditions on the penalty term that guarantee consistency for exponential family models.Theorem 2 (Remark 1.2 in (Haughton, 1988)).
For (curved) exponential families, if data is generated by an i.i.d. distribution p, and the penalty term is given by 1 2 k a N , where k is the number of parameters and a N is a sequence of positive real numbers, satisfying a N /N → 0, and a N → ∞, as N → ∞, then, symptotically, the model containing p that has the least number of parameters will be chosen.Since Bayesian networks are curved exponential families (Geiger et al., 2001;Chickering, 2002), it now remains to prove that the penalty term of fNML satisfies this property.Theorem 3 (Asymptotically fNML behaves like BIC).
Assuming that the maximum likelihood parameters are asymptotically bounded away from the boundaries of the parameter simplex, the local penalty of fNML behaves as∆ fNML i (D G i ) = q i (r i − 1) 2 log N + O(1),almost surely, where the O(1) term is bounded by a constant wrt.
N .
Proof.
By Thm.
1, the local penalty is a sum of logarithms of multinomial normalizing constants.
The latter is known to grow as log C r i N ij = r i −1 2 log N ij +O(1), (Rissanen, 1996).
Under the assumption that the maximum likelihood parameters are bounded away from the boundaries, the counts N ij grow linearly in the total sample size N almost surely, which implies that we have log N ij = log([η + o(1)]N ) = log N + O(1) with some 0 < η < 1.
Adding together the q i terms yields the result.Since q i (r i − 1) is the number of parameters (associated with the ith variable), the property of Thm.
2 holds for the fNML penalty.
We now provide information for practical implementation of the fNML score for Bayesian networks.
Due to the decomposability of the score the only new implementational issue for the fNML is to calculate the terms C r n of the Thm.
1.
For reasonable N and R (R = max r i ) these values can be stored in an N × R table, which can be done before structure learning.
Moreover, this table does not depend on data or any parameters, so it can be done just once.The calculation of the C-table with N rows and R columns proceeds as follows.
First of all, C r 0 = 1 for all r, and C 1 n = 1 for all n. For r = 2 we can use the formula (9), which yieldsC 2 n = n h=0 n h h n h n − h N n−h ,(12)and for r > 2 we can use the recursion (Kontka- nen and Myllymäki, 2007)C r n = C r−1 n + n r − 2 C r−2 n .
(13)Calculating the column C 2 * using the formula (12) takes time O(N 2 ), and the calculation of the rest of the table using the formula (13) takes just O(N K).
For very large N , the complexity of calculating the column C 2 * may be prohibitive.
In this case a very accurate Szpankowski approximation ( Kontkanen et al., 2003)C 2 n = nπ 2 e q 8 9nπ + 3π−16 36nπ (14)can be used.If the space for storing the table is critical, one may just store 1000 first entries of column C 2 * , use Szpankowski approximation for the rest of the column, and use formula (13) for calculating the values for r > 2.
It is not obvious how to compare different criteria for learning Bayesian network structures.
If the data is generated from a Bayesian network, one might call for selecting the data generating network, but if the generating network is complex, and the sample size is small, it may be rational to pick a simpler model.
This simplicity requirement is often backed up by arguments about the generalization capability of the model.
However, it is not always clear how the network structure should be used for prediction.A softer version of discovering the generating model is to compute a structural distance measure between the selected and the generating network structures.
A common choice is to calculate an editing distance with operations such as arc additions, deletions and reversals.
Even if we take the generating structure as a golden standard, this approach is problematic, since these editing operations are not independent.
For example, fixing a certain arc can lead to several other changes to the network structure if the selection by a score is made only among the structures having the fixed arc present.Despite of these problems in the empirical testing, we conducted a golden standard experiment.
We first generated data from different networks with five nodes, and then studied how the generating network structures were ranked among all the possible networks by different scoring criteria.For BDeu and fNML scores that both calculate the probability P (D | G), we also compared the scores for the real data sets.
This experiment can be seen as the result of a sequential prediction competition, since by the chain rule we can writeP (D | G) = N i=1 P (d i | G, d i−1 ),(15)where d i is the ith data vector, and d i−1 = {d 1 , . . . , d i−1 } denotes the first i−1 vectors.
The idea follows the principle of prequential model selection (Dawid, 1984).
We will now explain the experiments in more detail.
We first compared the ability of different scoring criteria to discover the data generating structure.
For this purpose we generated 100 different 5-node Bayesian network structures with 4 edges and another 100 structures with 7 edges.
The variables were randomly assigned to have 2 -4 values (r i ∈ {2, 3, 4}).
For each network, we generated parameters by two different schemes.
The first scheme exactly matched the assumptions of the BDeu score with α = 1, i.e., the parameters were distributed by θ ij ∼ Dir( 1r i q j , . . . , 1 r i q j).
The other scheme was to generate the parameters independently from a Dirichlet distribution θ ij ∼ Dir(1/2, . . . , 1/2).
This distribution was selected instead of the uniform distribution in order to make the generating structure more identifiable.For each network (structure + parameters), we generated 100 data sets of 1000 data vectors, and studied how different scoring criteria ranked the structure of the generating network among all the 5-node networks as a function of (sub)sample size.Not surprisingly, the results indicate that when parameter generation mechanism matches the assumptions of the BDeu-score, the BDeu usually also ranks the generating structure higher than the other scores (Figure 1(a)).
However, fNML usually behaves very similarly to BDeu.
The density of the network (4 vs. 7 edges) is not a very significant factor.
If anything, the similar behavior of fNML and BDeu is more pronounced in networks with 7 edges.
For the parameter-free scores, AIC and BIC, the underfitting tendency of BIC can be clearly detected whereas AIC tends to rank the generating network higher.
Qualitatively these two scores seem to behave similarly to each other.Switching the parameter generation scheme to independent Dirichlets with α ijk = 0.5 usually also switches the ranking ability of fNML and BDeu, while the behavior of AIC and BIC stays mostly unaffected.
For example, Fig- ure 1(b) was generated using the same network structure as for Figure 1(a).
Only the parameter generation scheme was changed from BDeu to Dir.
For dense networks fNML often appears as a clear winner.
Learning the structure with AIC or BIC does not readily suggest any particular way to use the learned structure for prediction, but the prequential interpretation of the BDeu score and the fNML allows comparison.
However, the BDeu score is known to be very sensitive to the For predictive comparison we selected 20 UCI data sets 1 for which the score maximizing hyperparameter α has been reported (Silander et al., 2007), and we compared the maximum fNML scores to the maximum scores obtained with BDeu1 (BDeu with α = 1.0) and BDeu* (BDeu with score maximizing α).
In reality, we do not know the score maximizing α's, and searching structures with many α is usually computationally too hard.
Optimal structures were obtained by the exact structure learning algorithm described in (Silander and Myl- lymäki, 2006).
Table 1 lists for each data set the number of data vectors N , the number of variables m, the average number of values per variable #vals, the BDeu maximizing equivalent sample size parameter α * (with integer precision), and the ac-1 http://www.ics.uci.edu/ ∼ mlearn/MLRepository.html tual scores obtained with three different scoring criteria.
The score obtained with fNML is the best of the three 14 times out of 20, and only once BDeu1 yields higher score than fNML.
We have introduced a new probabilistic scoring criterion, the factorized normalized maximum likelihood, for learning Bayesian network structures from complete discrete data.
The score aims at being an efficient and parameter-free criterion for finite sample sizes.
The score is also decomposable, which makes it possible to use it with existing search heuristics and exact structure learning algorithms.Initial empirical tests are promising.
We are particularly pleased with fNML's ability to learn network structures with good predictive capabilities.
While lot more empirical work has to be done, the current experiments already show a great promise for a good and care free scoring criterion for learning Bayesian network structures.
The authors thank the anonymous referees for valuable comments.
This work was supported in part by the Academy of Finland (Project Civi), by the Finnish Funding Agency for Technology and Innovation (Kukot, PMMA), and the IST Programme of the European Community, under the PASCAL Network of Excellence.
