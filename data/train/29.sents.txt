The traditional model of two-sided matching assumes that all agents fully know their own preferences.
As markets grow large, however, it becomes impractical for agents to precisely assess their rankings over all agents on the other side of the market.
We propose a novel model of two-sided matching in which agents are endowed with known partially ordered preferences and unknown true preferences drawn from known distributions consistent with the partial order.
The true preferences are learned through interviews, which reveal the pairwise rankings among all interviewed agents.
Our goal is to identify a centralized interview policy, i.e., an algorithm which adaptively schedules interviews.
We would like the policy to produce a matching that is guaranteed to be both stable and optimal for a given side of the market, with respect to the underlying true preferences of the agents.
As interviews are costly, we seek a policy that minimizes the number of interviews.
We introduce three potential minimization objectives: (very weak) dominance, which minimizes the number of interviews for any underlying true preference profile; Pareto optimality, which guarantees not being dominated by any other policy; and optimal-in-expectation with respect to the distribution.
We formulate our problem as an exponentially large Markov decision process.
Thus, given access to the distributions of true preferences, the optimal-in-expectation interviewing policy can be computed in exponential time.
We show that it is possible to polynomially identify pairs that match in all or no underlying preference profiles, but that such interviews nevertheless cannot be avoided by policies with our desired properties.
We then derive structural properties, called optimality certificates, of dominant policies.
We show that computing a minimum optimality certificate is NP-hard.
This shows that constructing a dominant policy, if it exists, is NP-hard and suggests that even optimal-in-expectation policies might be NP-hard to compute.
Thus we restrict attention to a setting in which agents on one side of the market have common partially ordered preferences (but potentially distinct underlying true preferences).
In this restricted setting, we show how to leverage the idea of minimum optimality certificates to design a computationally efficient interview-minimizing policy.
Our policy works without knowledge of the distributions and is dominant (and therefore also Pareto optimal and optimal-in-expectation).
* * We thank Scott Kominers for helpful conversations during the research that led to this paper.
Two-sided matching markets arise in many practical settings, such as corporate hiring, marriage, and university admission.
In such markets, participants are partitioned into two disjoint sets-men and women in a marriage market, for example.
Each participant on one side of the market wishes to be matched to a candidate from the other side of the market.
Participants have preferences over potential matches.
A matching is called stable if no pair of participants would prefer to leave their assigned partners to pair with each other.
It is optimal for one side of the market if each participant on that side prefers that matching to any other stable matching.
Gale and Shapley [6] proposed a tractable algorithm for identifying such optimal stable matchings.
A rich literature has developed since.
See e.g., Roth and Sotomayor [25] for an excellent survey; there is also a wealth of work that takes a more computational perspective [17,13,8,4,2,9,15,16,7,10,11,18,3,4].
Overall, the study of matching has made contributions in both descriptive and prescriptive senses.
Descriptively, computational models have enriched our understanding of existing social systems; for example, Gale and Shapley's work helps us to understand marriage markets, even though no such markets employ that algorithm.
Prescriptively, algorithmic tools proposed in the literature are practical enough to be used directly in applications, and indeed have transformed several matching markets.
Perhaps most famously, the National Residency Matching Program (NRMP)-see, e.g., [23]-matches American medical students to internships at hospitals, using a method quite similar to the Gale-Shapley algorithm.A key assumption that underlies much of the matching literature is that all market participants know their full (and often strict) preference orderings.
This assumption is often reasonable, as attested by the practical impact just described.
However, as markets grow large it quickly becomes impractical for participants to assess their precise preference rankings.
Returning to the NRMP, in practice students typically interview at only 10-15 hospitals out of the tens of thousands that participate.
Under the current system, students are considered to rank as unacceptable all hospitals at which they did not interview, allowing the algorithm to proceed as though a full preference ordering had been declared.
Prescribing the use of this system is clearly suboptimal: students who make the wrong decisions about where to interview can remain unmatched or be matched badly.
There are likewise drawbacks from a descriptive perspective: such models shed little light on how matching works when participants are endowed with partial information about their preferences.We are aware of two threads of related work that address this issue.
First is a literature on augmenting the preference model to allow indifference between candidates.
For example, consider a school choice domain in which high school students are matched to public schools.
Schools have some preferences over students based on geography and legacy considerations, but many students are equivalent according to these measures and hence it is reasonable to say that the school is indifferent between them.
However, this literature (e.g., [19,1]) is not intended to fully address the problem of incomplete preferences, and indeed it does not.
Furthermore, even this simple extension to the standard model is quite tricky; for example, depending on how stability is defined, stable matchings are not always guaranteed to exist.
Second, some work set up the matching problem as a Bayesian game, assuming that participants have strict preferences drawn according to a commonly known probability distribution over preference orderings, and that all participants know their own preferences once the draw has taken place.
Work in this vein typically seeks to design Bayes-Nash incentive compatible mechanisms or to describe the Bayes-Nash equilibria of standard mechanisms (see e.g. [25]).
One recent paper augments such Bayesian models with interviews, which are costly and chosen in a decentralized fashion [14].
The authors investigate equilibrium interviewing behavior and observe that "clustered interviews" yield high social welfare.
However, they do not insist that the final matching be stable with respect to agents' true preferences.In this paper, we propose a novel model of two-sided matching in which participants are endowed with partially ordered preferences over candidates, but can refine these preferences through interviews.
Specifically, we assume that each participant partitions candidates into ranked equivalence classes, with the property that candidates in higher-ranked equivalence classes are preferred to those in lower-ranked classes.
Each participant additionally has a strict preference ordering over candidates consistent with the known partial order.
These strict preference orderings are initially unknown to participants, but are drawn according to a known distribution.
Participants learn the strict preference orders through a process of interviews: for a given participant, the first interview in an equivalence class is uninformative; each subsequent interview in the class reveals the pairwise rankings among all previously interviewed candidates.
Our goal as the social planner is to design an adaptive centralized interviewing policy which, given any partial information state, either selects the next interview or terminates with an optimal stable matching.
As interviews are costly, we would like our policy to minimize the number of interviews performed.
We suggest three minimization criteria: (very weak) dominance, which is optimal for all underlying true preference profiles consistent with the partial information; Pareto optimality, which guarantees not being dominated by any other policy; and optimal-in-expectation, which minimizes the expected number of interviews with respect to the known distribution of strict preference orders.
Note that the first two of these notions are prior-free, i.e., a policy that satisfies them must run without knowledge of the preference distributions, and so is applicable in more general settings (e.g., if there is no common prior).
Furthermore, as dominant policies are Pareto optimal and optimal-in-expectation, it would be ideal if we could compute a dominant policy.
However, as we show, dominant policies may not exist.
Nevertheless, we leverage a Markov Decision Process (MDP) encoding of our problem to show that interview policies that minimize the expected number of interviews can be found in time polynomial in the number of possible preference orderings, which is exponentially faster than a naive algorithm, but still exponential in the size of the input.
The key question we investigate is whether we can do better.
One natural building block is to ask whether a given pair is "necessary" in the sense that they match in the stable, optimal matching for every possible set of preference orderings, or "impossible" in the sense that they never match.
We show that unfortunately neither necessary nor impossible interviews can be avoided: both can be required for certifying the optimality of a matching.
Another building block we introduce is the notion of an optimality certificate, which is a potential matching and a set of interviews whose outcomes can be used to prove that the potential matching is optimal and stable.
We show that in general, finding minimum optimality certificates is NP-hard, proving that identifying a dominant policy, if such policies exist, is hard, and suggesting that finding an optimal-in-expectation policy may also be NP-hard.
Finally, we also consider a restricted setting in which participants on one side of the market start out with the same partial information structures.
We show that in this setting, minimum optimality certificates-and hence an optimal interviewing policy-can be computed efficiently.
Our policy is in fact optimal in the strongest sense: it is dominant, meaning that it is also prior-free, Pareto optimal, and optimal-in-expectation with respect to any prior consistent with the partial information.
Let A = {a 1 , . . . , a n } be a set of applicants and let E = {e 1 , . . . , e m } be a set of employers.
We use the term agents when making statements that apply both to applicants and employers, and the term candidates to refer to the agents on the opposite side of the market as an agent currently being considered.
Each agent has an equivalence relation over (a subset of) the candidates and a strict ordering over the equivalence classes.
1 We denote the equivalence classes of employer e i and applicant a j that are ranked th in this strict ranking by c e i ,, and c a j ,, , respectively.
We let c E,A denote the equivalence class profile for all employers and applicants.The agents additionally have strict total orders: each applicant a has a strict preference ordering a over E ∪ {∅}, and each employer e has a strict preference ordering e over A ∪ {∅}.
If an agent i prefers ∅ to candidate j, we say j is unacceptable to i; all other candidates are acceptable to i. 2 We let E,A = ( e 1 , e 2 , . . . , em , a 1 , a 2 , . . . , an ).
The preference orderings E,A are drawn according to a distribution whose support is consistent with the equivalence relation.
That is to say, for each agent i, total order in the support of the distribution, and every two candidates j and k, (i) if i has j in a higher ranked equivalence class than k then i strictly prefers j to k under , and (ii) i has j in some equivalence class if and only if j is acceptable to i under .
Throughout the paper, we assume that the equivalence class profile c E,A is known and that the strict total order profile E,A is unknown.
Furthermore, most of our definitions and results do not assume knowledge of the distributions, and are thus prior free; i.e., the definitions and results apply regardless of the preference distribution.
Table 1: A setting with 2 employers and 2 applicants.
Applicants have full knowledge of their preferences; employers don't.
e 1 e 2 a 1 a 1 a 2 a 2 a 1 a 2 e 1 e 2 e 2 e 1e 1 e 2 a 1 a 1 a 2 a 2 (a) e 1 e 2 a 1 a 2 a 2 a 1 (b) e 1 e 2 a 2 a 1 a 1 a 2 (c) e 1 e 2 a 2 a 2 a 1 a 1 (d) The goal of our work is to construct a matching for agents that is stable with respect to the underlying preferences, and optimal for one side of the market.
We now define these notions mathematically.Definition 1 (Matching).
A matching µ : A ∪ E → A ∪ E ∪ {∅} is an assignment of applicants to employers such that each applicant is assigned to at most one employer and vice versa.
More formally, µ(a j ) = e i if and only if µ(e i ) = a j .
Furthermore, ∀a j ∈ A either ∃e i ∈ E, µ(a j ) = e i or µ(a j ) = ∅ (the applicant is unmatched), and likewise ∀e i ∈ E either ∃a j ∈ A, µ(e i ) = a j or µ(e i ) = ∅.
Definition 2 (Blocking pair).
A pair (a j , e i ) is a blocking pair in matching µ if a j and e i are not matched together in µ, e i a j µ(a j ), and a j e i µ(e i ).
Definition 3 (Stable matching).
A matching µ is stable if it has no blocking pair and if no agent is matched to an unacceptable partner.Example 4.
Consider the setting with 2 employers and 2 applicants depicted in Table 1.
The column corresponding to each agent i gives that agent's strict partial preference ordering, with the most preferred equivalence class at the top.
Applicants have full knowledge of their preferences (equivalence classes of size 1), while employers have no knowledge of their preferences (equivalence classes of size 2).
Table 2 gives all four possible strict preference orderings for the employers.
In every case, matching µ 1 , µ 1 (e 1 ) = a 1 and µ 1 (e 2 ) = a 2 , is stable.
Matching µ 2 , µ 2 (e 1 ) = a 2 and µ 2 (e 2 ) = a 1 , is also stable under (c).
µ 2 is not stable in the other cases: (e 1 , a 1 ) blocks µ 2 under (a) and (b), while (e 2 , a 2 ) blocks µ 2 under (d).
Employer-optimal and applicant-optimal matchings are particularly interesting: these are the matchings most preferred by all employers (resp., applicants), as compared to all other stable matchings.
When agents have strict preferences, as in our model, such matchings always exist and are unique [6].
These matchings can be used to build mechanisms in which truthtelling is a dominant strategy for the side of the market favored by the matching [5,22].
For example, if the employer-optimal matching is always picked, it is a dominant strategy for employers to reveal their preference orderings truthfully.
In what follows we restrict our attention to the problem of finding employer-optimal matchings rather than arbitrary stable matchings.
3Definition 5 (Employer-optimal matching).
A matching is employer-optimal if it is stable and weakly preferred by all employers to every other stable matching.Example 6.
Continuing Example 4, µ 1 is the employer-optimal matching under cases (a), (b), and (d), and µ 2 is the employer-optimal matching under case (c).
We have defined stability of a matching in terms of agents' true preferences (as distinct from [14]); thus, it will generally not be possible to find a stable matching based on agents' initial knowledge.
To find and certify a stable matching, employers and applicants must gather additional information about each other through interviews.
Each interview pairs a single applicant a with a single employer e; we denote it e:a.
After interview e:a, both e and a are able to strictly order the acceptable candidates interviewed so far.Informally, a policy describes how to conduct interviews: it starts with input I = (E, A, c E,A ), performs a sequence of interviews, and then outputs a matching.
Interviews can be selected based on the results of previous interviews, and the whole procedure is centralized.
More formally, a policy maps information states to subsequent interviews or to a matching that is stable and optimal for the underlying preference profile.
To reduce notation, from this point on we assume that the input I = (E, A, c E,A ) is given and fixed.Definition 7 (Information State).
The information state I i of agent i after interviews with ≥ 0 candidates is a list of these candidates, ordered according to the underlying true preference profile.
When = 0, we let I i = ∅.
The global information state after a sequence of interviews is I = i∈E∪A I i .
We say that the information state I refines the equivalence class profile c E,A , which we write as I c E,A , if I is consistent with c E,A : for all agents i and all candidates j and k, i preferring j to k under c E,A implies i also preferring j to k under I. Given a fixed c E,A and information states I and I that refine c E,A , we say that I refines I when it contains strictly more information: when for all agents i, all candidates who were interviewed in I i were also interviewed in I i , and for all candidates j and k who were interviewed in both I i and I i , i preferring j to k under I i implies i preferring j to k under I i .
We say that a preference profile refines an information state I, and write I, if is consistent with both c E,A and I.
We write c E,A to denote that is consistent with c E,A .
Definition 8 (Policy).
A policy is a mapping from a global information state I c E,A either to an interview to perform or to a matching.
A policy is sound if it is guaranteed to return an employer-optimal matching, regardless of the true preference order c E,A .
Example 9.
Continuing Example 6, a sound policy follows: given an information state I, if e 1 has not interviewed a 1 , schedule that interview; else if e 1 has not interviewed a 2 , schedule that interview.
Otherwise, if e 1 prefers a 2 to a 1 : if e 2 has not interviewed a 1 schedule that interview; else if e 2 has not interviewed a 2 , schedule that interview.
These interviews are sufficient to distinguish the state of the world; hence, for the remaining information states, the policy can simply output a matching.
If e 1 prefers a 1 to a 2 , the state of the world is (a) or (b), and so return µ 1 .
If e 1 prefers a 2 to a 1 and e 2 prefers a 2 to a 1 , the state of the world is (d), and so again return µ 1 .
Otherwise, the state of the world is (c), and so return µ 2 .
It is not hard to identify a sound policy: e.g., simply instruct all employers to interview all applicants and then run the Gale-Shapley algorithm to find the employer-optimal matching.
However, this policy is likely to perform unnecessary interviews.
We are motivated by the intuition that in reality, interviews are very costly; thus, we seek sound policies that minimize their number.
However, there is a problem.
Because policies select interview schedules dynamically, the number of necessary interviews may not only depend on the policy's input, but can also depend on the true underlying preference orderings.
What does it mean, then, to say that a sound policy performs the minimal number of interviews given an input I?One straightforward answer is to say that we should minimize the expected number of interviews with respect to the prior distribution over preference orderings.
Let θ(f, , c E,A ) denote the number of interviews that policy f performs when the true underlying preference profile is c E,A .
Definition 10 (Optimal in expectation).
A policy f is optimal in expectation if it is sound and it minimizes the expected number of interviews performed, given the prior Pr.
That is, for all sound policies g,c E,A Pr() · θ(f, , c E,A ) ≤ c E,A Pr() · θ(g, , c E,A ).
This objective has a major drawback: optimal-in-expectation policies are not robust with respect to changes in the setting, i.e., they are not prior-free.
We would prefer a sound policy that performs no more interviews than any other sound policy, regardless of the underlying preference profile.Definition 11 (Very weak domination).
A policy f very weakly dominates another sound policy g if and only if f performs no more interviews than g for any underlying preference profile.
That is,θ(f, , c E,A ) ≤ θ(g, , c E,A ) for all c E,A .
This dominance notion is called "very weak" because two algorithms can very weakly dominate each other by always performing the same number of interviews for every .
Definition 12 (Very weakly dominant policy).
A policy f is very weakly dominant if it very weakly dominates any other policy g.We would like to find a sound, very weakly dominant policy.
Unfortunately, no such policy always exists.Theorem 13.
There exist inputs for which no very weakly dominant, sound policy exists.Proof.
Consider the setting given in Table 1.
To certify that µ 1 is employer-optimal for (a) or (b), we only need e 1 to interview both candidates a 1 and a 2 , to distinguish (a) or (b) from (c).
To certify that µ 1 is employer-optimal for (b) or (d), we only need e 2 to interview both candidates, to distinguish (b) or (d) from (c).
Thus any policy that instructs e 1 to interview first-e.g. the policy described in Example 9-is dominated in case (d) and any policy that instructs e 2 to interview first is dominated in case (a).
Motivated by this impossibility result, we turn to the weaker, but still prior-free, notion of Pareto optimality.Definition 14 (Pareto domination).
A policy f Pareto dominates another policy g if and only if both policies are sound, f very weakly dominates g and, furthermore, ∃∃ c E,A such that θ(f, , c E,A ) < θ(g, , c E,A ).
Now we briefly survey relationships between our solution concepts.
Very weak dominance is the strongest guarantee we can hope for: if we can find such a policy, it will also be Pareto optimal and optimal in expectation.
Furthermore, every optimal-in-expectation policy is guaranteed to be Pareto optimal when the prior distribution has full support.Proposition 17.
If a policy f is optimal in expectation and Pr has full support, then f is Pareto optimal.Proof.
Assume for contradiction that f is not Pareto optimal.
Thus there exists a policy g that Pareto dominates f .
Therefore, θ(g, , c E,A ) ≤ θ(f, , c E,A ) for all c E,A and θ(g, , c E,A ) < θ(f, , c E,A ) for at least one c E,A .
Since Pr has full support, Pr() > 0 for all c E,A .
Therefore,c E,A Pr() · θ(f, , c E,A ) > c E,A Pr() · θ(g, , c E,A ), which implies that f does not minimize the expected number of interviews performed, a contradiction.
To compute an optimal-in-expectation (or Pareto optimal) policy, we can perform a brute-force search, considering every policy in turn.
If S denotes the number of global information states, then the number of distinct policies is Ω((n 2 ) S )-w.l.o.g. we assume n ≥ m. Thus, brute-force search requires time exponential in the number of information states, or doubly-exponential in the input.
In this section we show how to do better.Theorem 18.
An optimal-in-expectation policy can be computed in time polynomial in S.Proof.
We leverage the planning paradigm of MDPs [20].
An MDP is a tuple (S, A, C, T, s 0 , F ), where S is a finite set of states; A is a finite set of actions; C is a cost function where C(s, i, s ) represents the cost of taking action i in state s and transitioning to state s ; T is a transition function where T (s, i, s ) denotes the probability that action i in state s leads to state s ; s 0 denotes the system's initial state; and F denotes a set of terminal states.
Intuitively, our MDP encoding will work as follows.
We start at an empty global information state and take actions corresponding to interviews, paying a cost of 1 for every interview performed.
The effect of an action is to transition to a new information state that refines the previous state in the appropriate way, with new rankings being revealed according to conditional probabilities derived from the prior.
We reach a terminal state when we have gathered enough information to stop conducting interviews.
Formally, let S denote the set of global information states, A denote the set of all possible interviews, and C(I, e:a, I ) = 1 for all e:a, I and I .
Let T (I, e:a, I ) = Pr(I ) Pr(I) if I refines I and has exactly one more interview than I, that interview being e:a, and T (I, e:a, I ) = 0 otherwise, where Pr(I) = I Pr().
Let s 0 be the empty global information state: I where I i = ∅ for all i. Finally, we will define F as the set of information states such that I ∈ F if all preference profiles that refine I have the same employer-optimal matching, and there is no I , I I for which the same property holds.We compute F as follows.
We will iteratively refine a mapping h from information states to matchings, which will store all information states that we know to be safe stopping points for a sound policy.
(In fact, h stores optimality certificates-see Definition 23 below-that are minimal in size; i.e. no interview can be dropped and yet obtain an optimality certificate.)
Initially, let h map every information state to the null matching, in which no agent is matched.
A sound policy can clearly stop when all interviews have been performed.
Thus, for all information states I in which all interviews have been performed-including even interviews with unacceptable candidates-let h(I) = µ I , where µ I is the employer-optimal matching for the preference profile induced by I. Initialize Q to be the list of all such information states ordered arbitrarily, and initialize F to be the empty set.
We repeat the following until Q is empty.
Select the first information state I from Q. Now, make a linear pass over Q, asking whether there exists a second information state I such that h(I) = h(I ) and there exists a pair (e, a) where removing e from I a and I a and removing a from I e and I e yields the same global information state I * .
If so, remove both I and I from Q, add I * to the end of Q and let h(I * ) = h(I).
If no such I exists, remove I from Q and add it to F .
The computation of F takes polynomial time in the number of states since initializing Q can be done in polynomial time, each pass over Q takes time O(n · m · S), and at least one information state is removed from Q in each pass.Our MDP is finite horizon because we always reach a terminal state within n · m actions (i.e., performing all interviews).
Therefore, a standard result from the literature on MDPs applies: a policy that minimizes expected cost can be computed in time linear in the number of states via the backward induction algorithm (see, e.g., [21]).
This policy is sound by the construction of F , and hence is optimal in expectation.
So far, we have shown how to construct interview-minimizing policies in time polynomial in the number of possible preference ordering profiles, or exponential in the input size.
We are interested in whether it is possible to do better.
An algorithm that runs in time polynomial in the input size would have to leverage structural properties of our problem.
One natural candidate for such structure is interviews that can be avoided entirely, either because the employer-applicant pair match in the employer-optimal matching for every underlying preference profile or because they likewise never match.
It seems reasonable to hope that there would be algorithmic benefit to removing such employer-applicant pairs from consideration and hence reducing the size of our problem.
As we will see, we can detect such pairs efficiently; however it is surprisingly not true that the corresponding interviews can be avoided.
We begin by formally describing the pairings we would like to detect.Definition 19 (Necessary and impossible matches).
A pair (e, a) is a necessary (resp., impossible) match if for all c E,A , e and a are (not) matched in the employer-optimal matching of .
Definition 20 (Strongly necessary and impossible matches).
A pair (e, a) is a strongly necessary (resp., impossible) match if for all c E,A , e and a are (not) matched in any stable matching of .
Theorem 21.
All strongly necessary and impossible matches can be found in time polynomial in the size of I.Proof.
profile that refines a partial information structure.
We can leverage this LP to check whether each (e i , a j ) pair is a strongly necessary or impossible match by imposing this as a constraint in the LP: to test if (e i , a j ) is a strongly necessary (respectively impossible) match, we add a constraint to the LP forcing the variable x e i ,a j = 1 (respectively x e i ,a j = 0) and test if the resulting polytope is feasible.Because the set of strongly necessary (resp., impossible) matches is a subset of the set of necessary (impossible) matches, our LP is also a sound, but not complete, test for necessary (impossible) matches.
That is, all strongly necessary (impossible) matches found by the test are guaranteed to be necessary (impossible), but there may exist further necessary (impossible) matches that are not found by the test.We motivated this section with the hope that an algorithm could avoid interviews for necessary and impossible matches.
Unfortunately, and surprisingly, even when we restrict ourselves to the strongly necessary and impossible matches found by our LP, this turns out not to be true in general.
Proof.
Consider the setting in Table 3.
Under every preference profile that refines this setting, e 1 and a 3 are matched in every stable matching (and thus in the employer-optimal matching).
Thus (e 1 , a 3 ) is a strongly necessary match, and (e 1 , a 1 ) and (e 1 , a 2 ) are strongly impossible matches.
If e 1 's top choice is a 3 then all employers get their top choice in the employer-optimal matching (case 1).
Otherwise, e 2 matches with a 1 and e 3 matches with a 2 (case 2), as the employers' favorite matching is blocked by (e 1 , a 1 ) and/or (e 1 , a 2 ).
In order to distinguish between cases (1) and (2), a sound policy needs to know whether e 1 has a 3 at the top of his ranking.
Thus, e 1 has to interview both strongly necessary and strongly impossible matches.
A sound policy does not have to conduct every possible interview; instead, it can terminate when it has gathered enough information to be sure of the employer-optimal matching.
We call an information state at which a sound policy can terminate an optimality certificate.Definition 23 (Optimality certificate).
A pair (I, µ) is an optimality certificate if µ is employer-optimal w.r.t. all I.In this section we consider the computational problem of finding an optimality certificate that certifies the employer-optimal matching for a given preference profile in as few interviews as possible.
Computation of such an optimality certificate would have to be performed by any very weakly dominant policy, and would likely be useful for optimal-in-expectation policies as well.
Formally, define the size of an optimality certificate (I, µ) as the number of interviews performed in I. Then, Definition 24 (Minimum optimality certificate for ).
(I, µ) is a minimum optimality certificate for a preference profile if µ is employer-optimal w.r.t. , I, and if there does not exist a smaller optimality certificate (I , µ) such that I .
Theorem 25.
A policy f is very weakly dominant if and only if it computes a minimum optimality certificate for every preference profile.Proof.
To prove the first direction, assume for contradiction that f is not very weakly dominant.
Then there must exist a policy g and a preference profile such that θ(g, , c E,A ) < θ(f, , c E,A ).
Let µ be 's employer-optimal matching and I be the information state after performing interviews that g performs under .
For g to be sound, (I, µ) must be an optimality certificate.
Thus f does not compute a minimum optimality certificate for , a contradiction.
To prove the second direction, assume for contradiction that a minimum optimality certificate is not computed for some preference profile .
Thus a policy that given I, where (I, µ) is a minimum optimality certificate for , returns µ dominates the f on , a contradiction.Unfortunately, the problem of computing a minimum optimality certificate is NP-hard.
Definition 26 (Optimality Certificate (OC) decision problem).
Given (E, A, c E,A ), a preference profile that refines c E,A and a bound K, decide whether there exists an optimality certificate (I, µ) of size at most K where µ is employer-optimal w.r.t. .
Proof sketch.
The proof is by reduction from the feedback arc set (FAS) problem [12].
Let G = (V, D) be a directed graph with no self-loops or multiple arcs.
The feedback arc set problem is to decide whether there exists a set of arcs C of size ≤ K such that C contains at least one arc from every directed cycle in G; i.e. removing all arcs in C breaks all directed cycles of G.
We construct an instance of the optimality certificate (OC) problem from (G, K) as follows.
We do not know how to prove a similar result about optimal-in-expectation or Pareto optimal policies; these policies need not compute optimality certificates for every input.
Nevertheless, we consider this result to be discouraging evidence about the tractability of the problem of identifying such policies.
In many two-sided matching markets, there is some degree of positive correlation between agents' preferences.
Taken to the extreme, this means that agents on at least one side of the market may have common a priori information, though perhaps different underlying preferences.
Formally, we assume that c a i ,k = c a j ,k for all pairs of applicants a i and a j and all k; we allow applicants to have different distributions and different underlying preference orderings, i.e., a i = a j .
We do not restrict employers' preferences in any way.
We additionally assume that agents cannot be matched unless they have interviewed together.
We need this requirement for technical reasons, but note that it is consistent with the way hiring usually happens in practice.Even in this restricted setting, a tabular representation of an optimal-in-expectation policy requires exponential space, since there are an exponential number of information states.
However, we can do better by giving an algorithmic description of a policy.
We present a polynomial-time algorithm that executes a very weakly dominant policy, and hence both an optimal-in-expectation and a Pareto optimal policy.Our algorithm for identifying a very weakly dominant policy works like an asynchronous version of Gale-Shapley.
(It is described formally as Algorithm 1 in the appendix; an informal description follows.)
It alternates between two main components, an interview scheduling component and a tentative matching component.
It thereby dynamically constructs the interview schedule, adapting to information revealed in the tentative matching component.
To schedule interviews, the algorithm repeatedly chooses a tentatively unmatched employer from the applicants' top (remaining) equivalence class who has not been rejected by all applicants he finds acceptable, and instructs him to interview all plausible applicants, i.e., those in the chosen employer's (current) top equivalence class who are achievable in the sense that they have not yet received better offers.
We refer to this step in the algorithm as the interviewing step.
After these interviews have been performed, the algorithm transitions to the tentative matching component, in which the employer initiates a sequence of proposals, in order, to his newly interviewed candidates.
Applicants receive proposals, tentatively accept their best proposed matches, and reject employers who are inferior.
This rejection can occur even when employers have not yet interviewed the applicant.
We refer to these steps by proposal, tentative acceptance, and denial state respectively.
Like in the Gale-Shapley algorithm, no employer proposes when he is tentatively matched, and an unmatched employer proposes to his most preferred achievable (and interviewed) applicant.
When there is no unmatched employer who has an achievable applicant in his list that he has interviewed, the tentative matching component halts and the algorithm transitions to the interview scheduling component.
The algorithm halts and returns the current tentative matching when no employer is instructed to perform an interview in the interviewing step.Our main claim in this section is that Algorithm 1 executes a very weakly dominant policy.
The basic idea of the proof is to show that, regardless of the underlying preference profile, Algorithm 1 always identifies a minimum optimality certificate.Theorem 29.
Algorithm 1 executes a very weakly dominant policy in time polynomial in the input size.Proof sketch.
The proof proceeds in six steps.Step 1: Algorithm 1 executes a sound policy.
Recall that the employer-proposal variant of the Gale-Shapley algorithm yields the employer-optimal stable matching.
The algorithm is robust w.r.t. varying the order in which the employers propose, as long as no tentatively matched employer proposes, and employers always propose to their top choice among achievable candidates.
In Algorithm 1, no employer interviews an applicant unless all the applicants he ranks in higher equivalence classes are unachievable, no employer proposes when he is tentatively matched, and unmatched employers always propose to the most-preferred achievable, interviewed applicant.
The algorithm only halts when each employer is matched or has no more achievable applicants to propose to or interview.
Thus Algorithm 1 returns the same matching that Gale-Shapley would have returned for any preference profile that refines the global information state that holds at the moment Algorithm 1 terminates.
Because Gale-Shapley is sound, Algorithm 1 is sound.Step 2: Algorithm 1 terminates in time polynomial in the input size.
Algorithm 1 halts once no interview is performed in the interviewing step, and thus is guaranteed to perform at least one interview in each previous iteration.
Therefore, in each invocation of the tentative matching component at least one employer proposes to an applicant and is then either rejected by that applicant or is tentatively matched.
There are n.m possible interviews and hence n.m possible proposals.
Thus the algorithm halts in polynomial time.Step 3: Algorithm 1 only ever instructs an employer in applicants' equivalence class + 1 (that is, the + 1st class from the top) to interview applicants, or to make offers, when all employers in applicants' higher-ranked equivalence classes are matched to their employer-optimal matches or have been rejected by all applicants they find acceptable.
The interview scheduling component only selects an employer to perform interviews if he is unmatched and in the top (remaining) equivalence class of the applicants.
Thus, if an employer in applicants' equivalence class + 1 is chosen, all employers in higher-ranked equivalence classes must either be tentatively matched or have been rejected by all applicants they find acceptable.
If none of the matched employers makes a new offer, their tentative matches become final and so must be, by Step 1, their employer-optimal matches.
If any of the matched employers makes a new offer, it can only be because he has been rejected by his current tentative match.
Let e * be the first employer in applicants' equivalence class or higher that gets rejected by his current match in a round in which employers in applicants' equivalence class ranked + 1 or lower are interviewing.
Then e * 's tentative match must have received an offer from a more-preferred employer, e * , in applicants' equivalence class or higher.
This is only possible if e * was rejected by his match in an earlier round, contradicting our definition of e * .
Step 4: (I, µ) is a minimum optimality certificate w.r.t. if and only if µ is the employer-optimal matching w.r.t. and, for any applicants' equivalence class and any employer e i in class , I includes interviews between e i and all applicants who belong to equivalence classes of e i above or equal to the equivalence class containing µ(e i ), unless those applicants are matched to employers belonging to applicants' equivalence classes above .
Take any employer e i in class .
By our requirement that matched agents must have interviewed, any employer-optimal policy must require e i to interview µ(e i ).
We show that for each a j , a j = µ(e i ), who is ranked by e i in the same equivalence class as µ(e i ) or higher, and who is not matched to an employer she ranks in a higher equivalence class than , there exists a preference ordering that is the same as except that e i and a j promote each other to the highest possible position in their respective rankings.
Under , (e i , a j ) blocks µ; thus µ is not employer-optimal under .
However, unless e i interviews a j , preference profile refines I and thus (I, µ) is not an optimality certificate.Step 5: Each time Algorithm 1 instructs an employer e in applicants' equivalence class to perform interviews, the set of applicants who are achievable to e is the set of applicants who are not tentatively matched to employers ranked in an applicants' equivalence class higher than .
The only step in the algorithm at which an applicant a rejects an employer without first being interviewed by him is the denial state, in which those employers who are inferior to a's best proposed match are rejected.
Thus the proof follows from Step 3.
Step 6: For every c E,A , the interviews that Algorithm 1 requires under preference ordering are precisely those that define the information state in a minimum optimality certificate for .
Let µ be the employer-optimal matching under .
Let the applicants' equivalence class containing e i be .
Take any applicant a j who is achievable to e i when Algorithm 1 instructs e i to interview.
By Step 3, all applicants who rank their partners under µ in a better equivalence class than are already matched to their partners under µ.
Therefore, following Step 4, a j must be achievable to e i whenever e i is picked, and will be interviewed by e i if e i is instructed to.
Furthermore, e i is not instructed to interview applicants in an equivalence class unless e i has been rejected by all applicants in higher ranked equivalence classes.
Since e i never gets rejected by µ(e i ), we can conclude that e i does not interview any applicant in lower equivalence classes.
The proof thus follows by Step 4.
Finally, the desired result follows by Theorem 25.
We introduced a model of two-sided matching markets in which agents begin with partially ordered preference information, and can refine these preferences through interviews.
We defined three optimization criteria to capture the idea of minimizing the number of interviews required to find a stable matching that is optimal for a given side of the market.
We showed that among these criteria, very weak dominance may not exist, and it is NP-hard to find such a policy if it does exist.
In contrast, we showed how to find an optimal-in-expectation (and so Pareto optimal) policy in exponential time via an MDP formulation.
We then explored the possibility of polynomially computable policies.
We showed how to identify interviews corresponding to strongly necessary and/or impossible matches, but proved that a sound policy is not always be able to avoid performing these interviews.
We also proved that finding minimum optimality certificates is a hard problem in general, which suggests (though it does not prove) that identifying optimal-in-expectation and/or Pareto optimal policies is hard.
Finally, we used the notion of minimum optimality certificates to design a polynomial time algorithm that identifies a very weakly dominant policy for the setting in which one side of the market has symmetric partial information.Our paper raises many questions.
An important open problem is the hardness of finding optimal-inexpectation policies (or Pareto optimal policies) in general settings; one could also consider approximating these objectives.
It would be interesting to identify settings under which we can bound the number of interviews our proposed algorithm performs (e.g., w.r.t. the number of equivalence classes and the number of agents in each equivalence class).
Of particular importance is understanding when we only need a linear number of interviews, as this mimics the setting in the NRMP where applicants can only list a constant number of hospitals.
Finally, one could consider the computational impact of committing to decentralized policies.
Given a total ordering , the set of matchings that are stable w.r.t. can be characterized by the integral solutions to a linear feasibility program (see e.g. [24]).
We extend the linear feasibility program formulation used in [24] to characterize the set of matchings that are stable w.r.t. some total ordering that refines a given equivalence class profile.Theorem 30.
Given a equivalence class profile c E,A , a matching is stable w.r.t. some total ordering that refines c E,A if and only if it is an integral solution to the following polytope:j∈A x e,j ≤ 1 ∀e ∈ E (1) i∈E x i,a ≤ 1 ∀a ∈ A (2) jea,j =a x e,j + iae,i =e x i,a + x e,a ≥ 1 ∀ acceptable (e, a) pairs (3) x e,a ≥ 0 ∀e ∈ E, ∀a ∈ A (4) x e,a = 0 ∀ unacceptable (e, a) pairs (5)where j e a denotes that e ranks j in a weakly higher equivalence class than that of a.Note that constraint (3) implies that for all acceptable pairs (e, a), either at least one of e and a is matched to someone weakly more preferred, or that e and a are matched to each other.
This constraint captures the notion that there are no blocking pairs.Proof.
(If direction: x is an integer solution to the linear feasibility program ⇒ it corresponds to a matching that is stable w.r.t. some strict ordering that refines the partial information.)
By (1), (2), (4), and (5) all x i,j 's are either equal to zero or to one.
For each employer e and applicant a, let µ(e) = a and µ(a) = e iff x e,a = 1; otherwise let µ(e) = µ(a) = ∅.
Let µ be any strict ordering that refines the partial information in which each employer e ranks µ(e) at the top of her corresponding equivalence class and each applicant a ranks µ(a) at the top of her corresponding equivalence class.
We claim that µ is stable w.r.t. µ .
Assume, for contradiction, that µ is not stable w.r.t. µ .
By (5) no one is matched to an unacceptable match.
Thus the instability could only arise by the existence of a blocking pair.
Let (e, a) be a pair that blocks µ under µ , thus (i) e and a are not matched and therefore x e,a = 0, (ii) e is not matched to an applicant he ranks above a under µ , thus he is not matched to an applicant in a higher equivalence class.
Furthermore, by the construction of µ , he is not matched to an applicant he ranks in the same equivalence class as a (as otherwise e would prefer µ(e) to a and thus the pair would not be blocking).
By similar arguments, (iii) a is not matched to an employer she ranks above e under µ .
By (i), (ii), and (iii) it follows that x e,a = 0; x e,j = 0; ∀i e a, x i,a = 0; ∀j a e, x e,j = 0.
Thus (3) does not hold for the pair (e, a) and therefore x is not an integer solution to the linear feasibility program, a contradiction.
(Only if direction: µ is stable w.r.t. some preference ordering that refines the partial information ⇒ it corresponds to an integer solution to the linear feasibility program.)
Let x e,a be equal to one if µ(e) = a and equal to zero otherwise.
Since µ is a matching, (1), (2) and (4) hold.
As it is stable, no one is matched to an unacceptable pair and thus (5) holds.
To prove that (3) holds, we use the fact that µ has no blocking pair.
Assume, for contradiction, that (3) does not hold.
Thus, there exists an acceptable pair (e, a) such that (i) x e,a = 0, i.e. µ(e) = a , (ii) x e,j = 0, ∀j e a, i.e. e is not matched to an applicant he ranks in the same or a higher equivalence class as a, and (iii) x i,a = 0, ∀i a e, i.e. a is not matched to an employer she ranks in the same or a higher equivalence class as e. Thus e and a are not matched (by i), e is not matched to an applicant he ranks above a (by ii) and a is not matched to an employer she ranks above e (by iii).
Thus (e, a) is a blocking pair, a contradiction.
In Section 6 we proposed a polynomial time algorithm that identifies a very weakly dominant policy for a restricted setting.
We now formally state that algorithm as Algorithm 1.
Function Next Class(e i ) returns e i 's top equivalence class with an achievable applicant, if any, and returns 0 otherwise.
Function Pick(E u,, ) chooses an employer from the set of unmatched employers E u,, ⊆ E who belong to the th equivalence class of the applicants.
PS, IS, JS, TS, and DS denote the proposal, interview, job offer, tentative acceptance and denial stages of Algorithm 1.
We say that an employer e i has been denied by an applicant a j under Algorithm 1 if either a j has rejected a job offer from e i , or a j was removed from e i 's list.
An applicant a j is said to be still achievable to an employer e i if a j has not yet denied e i .
TS Each applicant who has received one or more job offers tentatively accepts the offer from the employer she most prefers and rejects the rest; matching µ is updated accordingly; Each tentatively matched applicant aj is removed from the lists of those employers that are in the equivalence classes ranked lower than the one µ(aj) belongs to; ce i and Pe i are updated accordingly for all ei ∈ E; until there is no unmatched employer ei who has interviewed all achievable applicants in his current class-i.e. Pe i = ∅-and has not yet been denied by all of them; until each employer is either tentatively matched or is denied by all applicants; return µ ; // The current tentative matching is returned as the outcome Finally, we consider Theorem 27 from Section 5.
Below, we give a proof that depends on an additional assumption: that matched agents are required to first have interviewed together, which is a restriction we also imposed in Section 6.
Theorem 27 holds without this assumption, and indeed the sketch we provided in Section 5 describes the full proof that does not make the additional assumption.
However, the full proof is more complicated and harder to follow (albeit using similar techniques), and depends upon additional concepts that require formal definitions.
Thus, for the sake of clarity, we present only the simpler proof in this conference version of our work.Theorem 31.
The optimality certificate decision problem is NP-hard.
Proof.
The proof is by reduction from the feedback arc set (FAS) problem, or its alternative formulation maximum acyclic subgraph problem, which are both NP-complete problems [12].
Let G = (V, D) be a directed graph (with no self-loops or multiple arcs).
The feedback arc set problem is to decide whether there exists a set of arcs A of size ≤ K such that A contains at least one arc from every directed cycle in G; i.e. removing arcs in A breaks all directed cycles of G.Let G = (V, D) be any given directed graph where V = {v 1 , . . . , v n }.
We first construct an instance of the optimality certificate problem from (G, K).
• Let E = {e 1 , . . . , e n } and A = {a 1 , . . . , a n } be the set of employers and applicants respectively, where n = |V |, the number of vertices in G.
That is, there is a one-to-one correspondence between the vertices and the sets of employers and applicants.
• Let the equivalence classes be such that -each employer e i has exactly one equivalence class containing a i and any applicant a j where(v i , v j ) ∈ D.-each applicant has exactly two equivalence classes.
The top equivalence class of a j contains only e j .
The bottom equivalence class of a j contains any employer e i where (v i , v j ) ∈ D.• Let be any strict ordering refining the equivalence classes under which each employer e i ranks a i at top.
Thus µ, µ(e i ) = a i , is the employer-optimal matching of .
We claim that G has a FAS of size K if and only if there exists an optimality certificate (I, µ) of size K + |µ| where µ is the employer-optimal matching of .
The proof has two parts:
