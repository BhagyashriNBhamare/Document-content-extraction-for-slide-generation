The proliferation of connected sensing devices (or Internet of Things) can in theory enable a range of applications that make rich inferences about users and their environment.
But in practice developing such applications today is arduous because they must implement all data sensing and inference logic, even as devices move or are temporarily disconnected.
We develop Beam, a framework that simplifies IoT applications by letting them specify "what should be sensed or inferred," without worrying about "how it is sensed or inferred."
Beam introduces the key abstraction of an inference graph to decouple applications from the mechanics of sensing and drawing inferences.
The inference graph allows Beam to address three important challenges: (1) device selection in heterogeneous environments, (2) efficient resource usage , and (3) handling device disconnections.
Using Beam we develop two diverse applications that use several different types of devices and show that their implementations required up to 12× fewer source lines of code while resulting in up to 3× higher inference accuracy.
Connected sensing devices, such as cameras, thermostats, in-home motion, door-window, energy, water sensors [2], collectively dubbed as the Internet of Things (IoT), are rapidly permeating our living environments [3], with an estimated 50 billion such devices in use by 2020 [34].
In theory, they enable a wide variety of applications spanning security, efficiency, healthcare, and others.
But in practice, developing IoT applications is arduous because the tight coupling of applications to specific hardware requires each application to implement the data collection logic from these devices and the logic to draw inferences about the environment or the user.Unfortunately, this monolithic approach where applications are tightly coupled to the hardware, is limiting in two important ways.
First, for application developers, this complicates the development process, and hinders * Work done during an internship at Microsoft Research broad distribution of their applications because the cost of deploying their specific hardware limits user adoption.
Second, for end users, each sensing device they install is limited to a small set of applications, even though the hardware capabilities may be useful for a broader set of applications.
How do we break free from this monolithic and restrictive setting?
Can we enable applications to be programmed to work seamlessly in heterogeneous environments with different types of connected sensors and devices, while leveraging devices that may only be available opportunistically, such as smartphones and tablets?To address this problem, we start from an insight that many inferences required by applications can be drawn using multiple types of connected devices.
For instance, home occupancy can be inferred by either detecting motion or recognizing people in images, with data sampled from motion sensors (such as those in security systems or Nest [12]), cameras (e.g. Dropcam [4], Simplicam [18]), microphone, smartphone GPS, or using a combination of these sensors, since each may have different sources of errors.
We posit that inference logic, traditionally left up to applications, ought to be abstracted out as a system service, thus decoupling "what is sensed and inferred" from "how it is sensed and inferred".
Such decoupling enables applications to work in heterogeneous environments with different sensing devices while at the same time benefiting from shared and well trained inferences.
Consequently, there are three key challenges in designing such a service: Device selection: The service must be able to select the appropriate devices in a deployment that can satisfy an application's inference request (including inference accuracy).
Device selection helps applications to run in heterogeneous deployments.
It also helps applications to operate in settings with user mobility where the set of usable devices may change over time.
Moreover, applications can leverage multiple available devices to improve inference accuracy, as shown in Figure 1.
Efficiency: For inferences that are computationally ex- Figure 1: Improvement in occupancy and activity inference accuracy by combining multiple devices in a lab deployment.
For occupancy, sensor set 1 = {camera, microphone} in one room and set 2 ={PC interactivity detection} in a second room.
For physical activity, set 1 = {phone accelerometer} and set 2 = {wrist worn FitBit [5]}.
pensive to run locally on user devices, or to support deployments that span geographical boundaries, the service should be able to offload computation to remote servers.
In doing so, the service should partition computation while efficiently using network bandwidth.
Disconnection tolerance: The service should be able to handle dynamics that can arise due to device disconnections and user mobility.To address these challenges concretely, we propose Beam, an application framework and associated runtime which provides applications with inference-based programming abstractions.
It introduces the key abstraction of an inference graph to not only decouple applications from the mechanics of sensing and drawing inferences, but also directly aid in addressing the challenges identified above.
Applications simply specify their inference requirements, while the Beam runtime bears the onus of identifying the required sensors in the given deployment and constructing an appropriate inference graph.Inference graphs are made up of modules which are processing units that encapsulate inference algorithms; modules can use the output of other modules for their processing logic.
Beam introduces three simple building blocks that are key to constructing and maintaining the inference graph: typed inference data units (IDUs) which guide module composability, channels that abstract all inter-module communications, and coverage tags that aid in device selection.
The Beam runtime instantiates the inference graph by selecting suitable devices and assigning computational hosts for each module.
Beam also mutates this assignment by partitioning the graph at runtime for efficient resource usage.
Beam's abstractions and runtime together provide disconnection tolerance.Our implementation of the Beam runtime works across Windows PCs, tablets, and phones.
Using the framework, we develop two realistic applications, eight different types of inference modules, and add native support for many different types of sensors.
Further, Beam supports all device abstractions provided by HomeOS [33], thus enabling the development of a variety of inference modules.
We find that for these applications: 1) using Beam's abstractions results in up to 4.5× fewer development tasks and 12× fewer source lines of code with negligible runtime overhead; 2) inference accuracy is 3× higher due to Beam's ability to select devices in the presence of user mobility; and 3) network resource usage due to Beam's dynamic graph partitioning matches hand-optimized versions for the applications.
In this section, we first describe two representative classes of applications and distill the challenges an inference framework should address.
Next, we describe the key abstractions central to Beam's design in addressing the identified challenges.
Our motivation for designing Beam are data-driveninference based applications, aimed at homes [12,19], individual users [11,14,59,69,72] and enterprises [8,16,24,46,60].
We identify the challenges of building an inference framework by analyzing two popular application classes in detail, one that infers environmental attributes and another that senses an individual user.Rules: A large class of popular applications is based on the 'If This Then That (IFTTT)' pattern [9,67].
IFTTT enables users to create their own rules connecting sensed attributes to desired actions.
We consider a particular rules application which alerts a user if a high risk appliance, e.g., electric oven, is left on when the home is unoccupied [64].
This application uses the appliance-state and home occupancy inferences.Quantified Self (QS) [11,14,23,35,53] disaggregates a user's daily routine by tracking her physical activity (walking, running, etc), social interactions (loneliness), mood (bored, focused), computer use, and more.Using these two popular classes of applications we address three important challenges they pose: device selection, efficiency, and disconnection tolerance, as detailed in Section 1.
Next, we explain the key abstractions in Beam aimed at tackling these challenges.
In Beam, application developers only specify their desired inferences.
To satisfy the request, Beam bears the onus of identifying the required sensors and inference algorithms in the given deployment and constructing an inference graph.
Inference Graphs are directed acyclic graphs that connect devices to applications.
The nodes in this graph correspond to inference modules and edges correspond to channels that facilitate the transmission of inference data units (IDUs) between modules.
While these abstractions are described in more detail below, Figure 2 shows an example inference graph for the QS application that we later build and evaluate.
The graph uses eight different devices spread across the user's home and workplace, and includes mobile and wearable devices.
The application requests a top-level inference as an IDU and Beam dynamically selects the modules that can satisfy this inference based on the devices available.
For example, in Figure 2, to satisfy the application's request for inferences pertaining to fitness activities Beam uses a module that combines inferences drawn separately from a user's smartphone GPS, accelerometer, and Fitbit device, thus forming part of the inference graph for QS.
Figure 3 shows the inference graph for the Rules application.Composing an inference as a directed graph enables sharing of data processing modules across applications and other modules that require the same input.
In Beam, each computing device associated with a user, such as a tablet, phone, PC, or home hub, has a part of the runtime, called the Engine.
Engines are computational hosts for inference graphs.
Figure 4 shows two engines, one on the user's home hub and another on her phone; the inference graph for QS (shown in Figure 2) is split across these engines, while the QS application runs on a cloud server.
For simplicity, we do not show another engine that may run on the user's work PC.
IDU: An Inference data unit (IDU) is a typed inference, and in its general form is a tuple <t,e,s>, which denotes any inference with state information s, generated by an inference algorithm at time t and error e.
The types of the inference state s, and error e, are specific to the inference at hand.
For instance, s may be of a numerical type such as a double (e.g., inferred energy consumption), or an enumerated type such as high, medium, or low.
Similarly, error e may specify a confidence measure (e.g., standard deviation), probability distribution, or error margin (e.g., radius).
IDUs abstract away "what is inferred" from "how it is inferred".
The latter is handled by inference modules, which we describe next.Inference Modules: Beam encapsulates inference algorithms into modules.
Inference modules consume IDUs from one or more modules, perform certain computation using IDU data and pertinent in-memory state, and output IDUs.
Special modules called adapters interface with underlying sensors and output sensor data as IDUs.
Adapters are device drivers that decouple "what is sensed" from "how it is sensed".
Inference developers specify (i) a module's input dependencies (either as IDU types or as modules), (ii) the IDU type it generates, and (iii) its configuration parameters.
Modules have complete autonomy over how and when to output an IDU, and can maintain arbitrary internal states.
Listing 1 shows a specification for the Home Occupancy inference module in the Rules inference graph (Figure 3).
It lists (i) input dependencies of PC Activity OR Mic Occupancy OR Camera Occupancy, (ii) HomeOccupancyIDU to be the type of output it generates, and (iii) a control parameter, sampleSize, that specifies the temporal size of input samples (in seconds) to consider in the inference logic.
Application developers request the local engine for desired infer-1 <Spec> 2 <ControlParameters> <!--Module parameters --> 3 <Param name="sampleSize" type="int" value="5"/> 4 </ControlParameters> Beam's runtime also consists of a Coordinator which interfaces with all engines in a deployment and runs on a replicated server that is reachable from all engines.
The coordinator maintains remote channel buffers to support reader or writer disconnections (typical for mobile de- vices).
It also provides a place to reliably store state of inference graphs at runtime while being resistant to engine crashes and disconnections.
The coordinator is also used to maintain reference time across all engines.
Engines interface with the coordinator using a persistent web-socket connection, and instantiate and manage the parts of inference graphs local to them.
In this section, we describe how the Beam runtime uses the inference graph to aid in device selection, efficient graph partitioning, and handling device disconnections.
Beam simplifies application development by automatically selecting devices that match its inference request in heterogeneous deployments and in the presence of user mobility.
Beam leverages the device discovery mechanism in HomesOS [33] to discover and instantiate adapter modules for available sensors in the deployment.Applications request their local Beam engines for all inferences they require, including the coverage associated with each inference.
All application requests are forwarded to the coordinator.
Using inference module specifications and devices with matching coverage tags available in the deployment 1 , the coordinator recursively resolves all required inputs of each module.
A module's coverage tag set includes tags from the downstream modules it processes data from.
Handling environmental dynamics: Movement of users and devices can change the set of sensors and devices that satisfy an application's requirement.
For instance, consider an application that requires camera input from the device currently facing the user at any time, such as the camera on her home PC, work PC, or smartphone.
In such scenarios, the inference graph needs to be updated dynamically.
Beam updates the coverage tags to handle such dynamics.
Tags of location type (e.g., "home") are assumed to be static and are only edited by the user.
For tags of type user, the sensed subject is mobile and hence the sensors that cover it may change.
The coordinator's tracking service manages the coverage tags associated with adapters on various engines.The user tracking service updates the coverage tags as the user moves.
When a user leaves home for work, the tracking service removes the user tag from device adapters on the home PC and adds them to adapters on her smartphone.
When she arrives at work, the tracking service removes the user tag from her smartphone and add them to adapters on her work PC.
The user tracking service relies on device interactions.
When a user interacts with a device, it updates the tags of all sensors on the device to include the user's tag.Finally, changes in coverage tags (e.g., due to user movements) or device availability (e.g., device disconnections and re-connections) will result in the coordinator reselecting devices for requested inferences and recreating the graph accordingly.
Beam uses the inference graph for partitioning computation across devices and optimizing for efficiency.
Graph creation and partitioning: The Beam coordinator maintains a set of inference graphs in memory as an incarnation.
When handling an inference request, the coordinator first incorporates the requested inference graph into the incarnation, re-using already running modules, and merges inference graphs if needed.
Once the coordinator finishes resolving all required inputs for each module in the inference graph, it determines where each module should run using the optimization schemes described next.
The coordinator then initializes remote channels and partitions the graph into engine-specific subgraphs which are sent to the engines.
Whenever the tracking service updates coverage tags, e.g. due to user movements, the coordinator re-computes the inference graphs and sends updated subgraphs to the affected engines.
Next, the engines receive their respective subgraphs, compare each subgraph to existing ones, and update them by terminating deleted channels and modules before initializing new ones.
Engines ensure that exactly one inference module of each type with a given coverage tag is created.
Optimizing resource usage: In Beam, optimizations are either performed reactively, i.e., when an application issues/cancels an inference request, or proactively at periodic intervals.Beam's default reactive optimization determines where each module should run by partitioning the inference graph to minimize the number of remote channels.
Let G(V, E) be an inference graph, where V represents the nodes (inference modules), and E represents its adjacency matrix.
In E, e i j is the cost of the edge (channel) connecting module i to module j; e i j = 0 if two modules are not connected directly.
Beam's optimizer determines potential partitions of the inference graph and picks the partition with the minimum cost.
To determine a partition P |V |×|D| , Beam assigns each module i ∈ V to run on a device d ∈ D.
That is, p id = 1 if module i runs on device d and p id = 0 otherwise.
We define the cost matrix of a partition P of the inference graph as C |D|×|D| = P T EP, where c d 1 d 2 denotes the sum of the cost of all channels from device d 1 to device d 2 .
Since the reactive optimizer aims at minimizing the number of remote channels, here e i j = 1 for all connected modules i and j in the graph.
An adapter module runs on a device co-located with the sensor, and an application runs on the device requested by the user.
Beam solves the following linear program to find P with the minimum cost:Minimize ∑ ∀d 1 ,d 2 ∈D,d 1 񮽙 =d 2 c d 1 d 2 subject to ∑ d∈D p id = 1 ∀i ∈ V p id ∈ {0, 1} ∀i ∈ V, ∀d ∈ DBeam's default proactive optimization minimizes the amount of data transferred over remote channels by solving the same linear program but using the data rate profile of each edge as e i j .
Engines profile their subgraphs, and report profiling data (e.g., per-channel data rate or estimated per-module CPU utilization) to the coordinator periodically.
Other potential optimizations can minimize CPU/memory usage at engines, or IDU delivery latency.
Beam allows for modular replacement of optimizers.
The coordinator applies optimizations by re-configuring inference graphs and remapping the engine on which each inference module runs.Scatter node optimization: The coordinator further optimizes the inference graph by finding remote channels which have the same writer module, and whose readers reside on a common engine (R e ).
For each such set of edges (E), it adds a single remote channel edge from the writer to a new scatter node at R e .
The scatter node is then set as the writer for all edges in E, in effect, replacing multiple remote channels with one and reducing the amount of wide-area network transfers by a factor of |E|.
Beam's remote channels always go through the coordinator and support reader/writer disconnections by using buffers at the coordinator.
Thus, a channel is split into three logical components: writer-side, reader-side, and coordinator-side (present only in remote channels not receive duplicate IDUs, and ii) readers receive IDUs in FIFO timestamp order.
Beam specifies a default size for remote channel buffers but also allows application developers to customize buffer sizes based on deployment scenarios, e.g., network delays and robustness.
Internally, channels assign sequence numbers to IDUs.
They are used for reader-writer flow control, and in remote channels for applying back-pressure on the writerside component when the coordinator-side buffer is full, e.g., when a reader is disconnected.
Currently, the writerside and coordinator-side buffers use the drop-tail policy to minimize data transfer from writer to coordinator in the event of a disconnected/lazy reader (as opposed to drop head).
This design implies that after a long disconnection a reader will first receive old inference values followed by recent ones.Channels and modules do not persist data.
If necessary, applications and modules may use a temporal data store, such as Bolt [37], to make inferences durable.
Our Beam prototype is implemented in C# as a crossplatform portable service that can be used by .
NET v4.5, Windows Store 8.1, and Windows Phone 8.1 applications.
The Beam inference library has sample implementations for 8 inference modules and 9 adapters (listed in Table 1).
It also includes a HomeOS-adapter that allows Beam to leverage various other device abstractions provided by HomeOS [33], such as the camera and energy meter device drivers used by some of our sample inferences.
Each Beam module has a single data event queue and a thread to deliver received IDUs (akin to the actor model [22,26,29]).
All communication between the coordinator and engine instances uses the SignalR [17] library, and Json.NET [10] is used for data serialization.
The engine library, coordinator, sample adapters, and tracking service are implemented in 6614, 952, 1824, and 219 (total=9609) source lines of code respectively.
We implement the motivating applications described in Section 2.1 in Beam.
Inference graphs of Rules and Quantified Self (QS) are shown in Figure 3 and Figure 2, respectively.
Device adapters such as Microphone, Camera, and PC Event adapters are shared by both inference graphs.
For common inference modules such as the PC Activity inference, Beam instantiates only one of them across these graphs.
Changes in coverage tags and device availability caused by user mobility prompt Beam to re-select appropriate devices for inference graphs.
For instance, PC Activity for QS might either be drawn from the home PC or the work PC depending on the user's current location.
The Rules application requires the Appliance Usage and Home Occupancy inferences implemented as follows.The Appliance Usage inference module reads aggregated power consumption of a home from a whole-home power meter, or a utility smart-meter, and disaggregates it to determine the set of appliances that are on at any given instant, using the CO algorithm from [39], configured with 10 commonly owned home appliances [25].
The whole-house power readings are generated using our power-sensor adapter, which interfaces with an Aeon ZWave whole-house meter [1].
The Mic Occupancy inference module reads audio samples using the PC Microphone adapter at a sampling rate of 8 kHz (in 4 second frames), and filters out background noise (such as wind, fans, etc.) [38].
If after filtering, the audio sample still indicates sound is present, the inference output is 'occupied'.
The PC Activity module infers the current activity a user is performing on a PC (described in Section 4.1.2).
The Camera Occupancy module receives streaming video input from an adapter provided by the HomeOS web-cam driver.
The input video is of 640 × 480 resolution and streams at a frame rate of 1 fps.
The module compares consecutive frames in the video.
If any significant difference indicating possible human movement is detected [28], the inference output is 'occupied'.
The Home Occupancy module combines Mic Occupancy, Camera Occupancy, and PC Activity modules, to produce a Home Occupancy inference, outputting 'occupied' if one of the following is true: Mic Occupancy, Camera Occupancy, or PC Activity 񮽙 = No activity.
QS tracks a user's fitness activities, social behaviors, and computing activities on a PC.
It is implemented as a Windows Azure web application.
Users view plots of their data at leisure on the QS webpage.
The inference modules used by this application are described as follows.The Social Interaction (Is Alone) module detects the presence of human voice, outputting 'user not alone' when human voice is present (likely due to conversations with others, though false positives may arise due to TV sounds and background noises [32,52] over a 200 ms window of the microphone adapter data at 44.1 kHz and uses a decision tree [58] to classify if human voice is present.
The module also incorporates movement detection by analyzing video streams from the camera.The PC Activity inference module reads the name of the currently active desktop window from the PC-event adapter using a Win32 system call.
It then classifies the name into one of the known PC activity categories (coding, web browsing, social networking, emailing, reading etc.) using a pre-configured mapping.
It also infers the psychological state of the user (bored vs. focused) using the features proposed in [51], including window switches, web page switches, time spent browsing Facebook.com, and time spent using e-mail.
The Fitness Activity module implements the algorithm from [61] to infer human transportation modes (still, walking, driving) using the phone accelerometer.
It also uses the Fitbit [5] API to fetch users' FitBit activity logs, and combines it with accelerometer-based inferences.
Listings 1 and 2 show how application and inference developers leverage the Beam APIs using the Home Occupancy inference as an example.
Inference developers provide an XML specification for each inference module (Listing 1) configuring its One driver per sensor type.
For each inference an application requires, at least one inference component is needed, e.g., incorporating feature extraction techniques, inference algorithm, learning model, etc.
An application must also incorporate logic to match its inference logic with the underlying sensors (for a range of sensors), e.g. configuring sensor-specific parameters such as sampling rate, frame rate for cameras, sensitivity level for motion sensors, etc.
Depending on the development approach, an application may require several cloud services, e.g., a storage service for data archival, an execution environment for hosting inference logic, authentication services, etc.
Since devices such as smartphones, tablets, may have intermittent connectivity, developers need to appropriately handle disconnections.
Typical applications require certain UI components, e.g., to allow configuration of sensors for data collection, or for users to view results.
We evaluate how Beam's inference graph abstraction simplifies application development, benchmark its performance, and evaluate its efficacy in addressing the three key challenges identified in Section 1.
Our evaluation uses micro-benchmarks as well as the two motivating applications from Section 4.1.
First, in Section 5.2 we quantify how Beam's abstractions simplify application development and evaluate the overhead of graph creation.
Then, in Section 5.3, we evaluate how Beam's device selection in a real-world deployment with user mobility improves inference accuracy.
Next, in Section 5.4, we show the impact of Beam's inference graph partitioning to optimize for efficient resource usage.
Finally, in Section 5.5 we showcase Beam's ability to handle device disconnections.
For our experiments, the Beam coordinator runs on a Windows Azure VM (with AMD Opteron Processor, 7 GB RAM, 2 virtual hard disks, running Windows Server 2008 R2); the engines run on desktop machines (with AMD FX-6100 processor, 16 GB RAM, running Windows 8.1) and a Windows Phone (Nokia Lumia).
Both sample applications, Rules and Quantified Self (QS), run on the same VM as the coordinator; local engines run in the cloud, a home PC, phone, and a work PC.
To quantify the reduction in development effort achieved by Beam, we explore different approaches that a developer may adopt to design such applications.
Monolithic-All Cloud (M-AC).
In this approach, the application is developed as a monolithic silo without the use of any framework.
All application logic is tightly coupled to the sensing devices, and all collected data is relayed to cloud services, as is the case with Xively [20] and SmartThings [19].
The cloud service runs the application's data processing and inference logic.
Monolithic-Cloud and Device (M-CD).
In this approach, an application developer hard-codes the division of inference logic across the cloud VM and end devices [13,69].
Thus, sensor values are processed to some degree on the end device before being uploaded to the cloud VM which hosts the remainder of the application logic.
Depending on the deployment and resource constraints, the developer may need to hand-optimize the resource usage (e.g., CPU, memory, or network usage).
Monolithic-using inference libraries (M-Lib).
This approach is similar to the previous one (M-CD), except that application developers may use libraries of inference algorithms tuned by domain experts, thus leading to some reduction in development effort [31,44,57].
Monolithic-using sensor hub systems (M-Hub).
Platforms such as HomeOS [33], Homeseer [7], and others [15], facilitate the development of applications by providing homogeneous device-based programming abstractions.
Typically, these platforms implement sensor Beam.
In this approach, an application on any of the user's devices simply presents its inference requests to the local Beam instance.
Using the inference graph abstraction, Beam bears the onus of device selection, optimizing for efficiency, and handling disconnections.
Note that using Beam does not preclude the M-Hub approach where all sensing and inference logic run locally on a single hub device (e.g., a home hub).
We refer to such scenarios built using Beam's inference abstractions as Beam-Hub, with the engine and coordinator running locally without needing an external network connection.
In this section we highlight the saving in application development effort using Beam's inference graph abstraction and quantify the overhead of graph creation.
We implement our representative applications using the different development approaches described above and present a quantitative comparison of the development effort using two metrics: (i) number of development tasks and (ii) number of source lines of code (SLoC).
Number of development tasks is defined as the number of architectural components that need to be designed, implemented, and maintained for a complete functioning application.
To analyze development effort in greater depth, these components can further be categorized based on the function they perform (Table 2).
This metric captures the diverse range of tasks developers of applications for connected devices are required to handle.
Although comparing the number of tasks provides insight into the development effort required for each approach, different components often require varying levels of implementation efforts.
Thus, to distinguish individual components, we also measure the number of source lines of code (SLoC) required for the components in each approach.
Figures 5 and 6 show the number of development tasks and number of SLoC, respectively, for the Rules and QS 1.05 ± 0.14 0.16 ± 0.01 0.90 ± 0.04 0.20 ± 0.07 0.12 ± 0.01 Coordinator (split inference graphs) 0.06 ± 0.01 0.12 ± 0.01 0.06 ± 0.01 0.15 ± 0.07 0.11 ± 0.01 Engine (instantiate subgraphs)1.05 ± 0.13 0.16 ± 0.03 0.30 ± 0.08 0.12 ± 0.04 0.40 ± 0.10 Table 3: Inference graph setup times (in ms) in two sample scenarios, with one standard deviation.applications using the different development approaches.
Compared with M-AC and M-CD, the M-Lib approach reduces developer effort.
It leverages existing libraries which provide implementations of inference algorithms and also handle their training and tuning.
Similarly, in the M-Hub approach, developer effort is reduced due to existing sensor driver implementations provided by the platform.
Finally, when using Beam, application developers do not need to design or implement sensor drivers, inference logic, tuning timing parameters, or handling disconnections.
Application developers only need to decide their required inferences, and develop application-specific components, e.g., user interface, third-party authentication, etc.
Number of SLoC: As shown in Figure 6, we observe that for all approaches, the SLoC count is generally proportional to the development task count.
For most approaches SLoC is dominated by tasks of developing sensor drivers and inference logic.
For instance, the Social Interaction inference in QS contributes more than 9796 SLoC.
Both Beam and M-Lib help alleviate this complexity.
Beam improves upon M-Lib by handling the complexity of implementing sensor drivers, disconnection tolerance, and optimizing resource usage, etc.
We study the time taken by Beam to satisfy requests for a single Mic Occupancy inference, which in turn uses the PC Mic adapter.
We consider two sample scenarios, 1) applications request for a local inference, and 2) applications request for a remote inference.
In both cases, application 1 initiates a request first, followed by application 2, with the same coverage tag.In both scenarios, the overhead of instantiating and maintaining the inference graph at end-points is minimal and dwarfed by the latency of transferring the request to the coordinator and receiving back the subgraphs.
Table 3 shows the overhead of graph creation for each of the scenarios.
In both cases, the second request uses less time for graph creation at the coordinator, since much of the graph already exists when the second request arrives (e.g., module specifications are not re-read).
Likewise, in both scenarios, time spent at the engine(s) in applying the subgraph is lower for the second request as compared to the first request.
Further, it is lower in scenario 2 because the inference graph is split across two engines.
Lastly, the coordinator performs a periodic reevaluation based on the channel data rates and applies the proactive optimization discussed in Section 3.2.
The time taken to perform the re-evaluation is minimal.
Unlike other approaches described in Section 5.1, the inference graph in Beam can select devices for applications even in heterogeneous environments with user mobility, resulting in increased inference accuracy.
We demonstrate this using the PC Activity inference in the context of the QS application (inference graph in Figure 2).
We perform an experimental lab deployment with two locations -a lab which acts as 'home' and an office.
Movements from home to office are used to simulate user commuting.
We compute Beam's inference accuracy against manually-collected ground truth data from the deployment, and compare it to three other development approaches that may be used in the absence of a Beam-like tracking service.
The first approach performs the PC Activity inference using only inputs from the home PC, while the second approach uses only inputs from the work PC.
We assume that the home PC goes into sleep after a certain period of user inactivity, while the work PC remains on even after the user leaves.
In the third approach, the inference is drawn using simultaneous inputs from both the home and work PCs.
However, when the two inputs conflict, the output is set to 'Other'.
Figure 7 shows a comparison of inference accuracy for these different schemes over a ten minute interval of using the QS application.
Inferring PC-based activities using only the home PC works accurately until the user leaves home, but deviates significantly from ground truth once the user has left.
Similarly, using only the work PC can only accurately compute the PC-based activities of the user after the user arrives at work.
On the other hand, using both the work and home PC without a tracking service often produces conflicting results, for instance, when home PC and work PC both generate PC Activity inferences during user commuting.
Beam's tracking service correctly identifies the location of the user and triggers the inference graph to re-select appropriate devices, achieving inference accuracy 3× higher than the best performing scheme above.
Using the tracking service, Beam's smartphone engine can also correctly indicate that the user is 'Mobile' while commuting.
Table 4 summaries these accuracy improvements.Although the above experiments are performed in a lab setting with a simulated commuting scenario, having a longer commuting time will only reduce the accuracy of non-Beam approaches, since only Beam with the tracking service can infer user commuting and all other approaches will yield incorrect results.
Finally, we expect to observe a similar accuracy improvement for other Table 4: Accuracy of PC Activity Inference compared to ground truth (a summary of Figure 7).
inferences that require handling of sensor coverage, e.g. the Social Interaction inference in the QS application.
Next, we illustrate that Beam can match the resource usage of hand-optimized applications by partitioning the inference graph across devices.
We also evaluate different optimization schemes used in Beam.
Although we consider network usage to benchmark Beam in this paper, we expect similar optimizations can be performed on other resources such as CPU usage, latency, and energy.Graph partitioning: For the Rules and QS applications, we compare Beam's data transfer overhead (i.e., number of bytes transferred over the wide area) with that of different approaches (M-AC, M-CD, M-Lib, M-Hub).
Fig- ure 8 shows the total number of bytes transferred over the wide area in one hour, for the sample applications using different approaches.
Medians and standard deviations across three runs are reported.
M-AC incurs the largest overhead, because it transfers all sensor data from the device to a cloud VM for processing.
On the other hand, the M-CD, M-Lib, and M-Hub approaches are optimized to perform most of their processing at the edges before transferring data to the cloud VM.
Beam automatically partitions the inference graph using both reactive and proactive optimizations and comes close to matching the network transfer overhead incurred by M-CD; it incurs a slightly higher overhead for transferring control messages such as forwarding the application's request to the coordinator, receiving the part of the inference graph to instantiate, sending channel data rates to coordinator (for proactive optimization), acknowledgments, etc.
Note that, when the M-Hub approach is used for the Rules application, there is no wide area IDU transfers because all In this section we quantify the ability of the Beam inference graph to handle device disconnections.
Remote channels in Beam buffer data at both the coordinator and at the writer endpoints to tolerate reader and writer disconnections.
The size of these buffers and the writer's sending rate determine the time window for which disconnections are lossless, and can be sized as per the deployment scenario.
Figure 11 shows a time series plot of the number of IDUs and data messages received by a reader over a 100 seconds interval.
The writer produces ten IDUs every second.
Each IDU produced is pushed out in a separate data message until a reader disconnection at t=15s results in data buffering, first at the coordinator, and then at the writer.
We constrain the channel buffers at the writer and coordinator ends to 100 IDUs each, thus supporting buffering of only 20 seconds worth of IDUs in this configuration, forcing the remaining IDUs to be dropped.
When the reader reconnects at t=80 s, the 200 buffered IDUs are batched in a small number of data messages and delivered to the reader, showing Beam's support for tolerating device disconnections.
Beam's inference graph draws inspiration from dataflow graphs used in a wide range of scenarios such as routers [45], operating systems [54,62], data-parallel computation frameworks [6,40], and Internet services [70].
Beam is the first framework that provides inference abstractions to decouple applications, inference algorithms, and devices, using the inference graph for device selection, efficiency, and disconnection tolerance.
We classify prior work into four categories.
Device abstraction frameworks: HomeOS [33] and other platforms [7,15,21,68] provide homogeneous programming abstractions to communicate with devices.
For instance, HomeOS applications can use a generic motion sensor role, regardless of the sensor's vendor and protocol.
These approaches only decouple devicespecific logic from applications, but are unable to decouple inference algorithms from applications.
Moreover, they cannot provide device selection or inference partitioning capabilities.Cross-device frameworks: Rover [41], an early distributed object programming framework for mobile applications, allows programmers to partition client-server applications; it provides abstractions such as relocatable objects and queued remote procedure calls to ease application development.
Sapphire [73], a more recent framework, requires programmers to specify per-object deployment managers which aid in runtime object placement decisions, while abstracting away complexities of inter-object communication.
MagnetOS [48] dynamically partitions a set of communicating Java objects in a sensor network with a focus on energy efficiency.
Like these frameworks, channels in Beam abstract away local and remote inter-module communication.
Beam fundamentally differs from them by using the inference graph to decouple applications from sensing and inferences, aid in device selection to operate in heterogeneous environments, and support global resource optimizations.
Macro-programming frameworks [27,36,49] provide abstractions to allow applications to dynamically compose dataflows [50,56].
Semantic Streams [71] and Task Cruncher [66] address sharing sensor data and processing across devices.
However these approaches focus on data streaming and simple processing methods, e.g., aggregations, rather than generic inferences, and do not target general purpose devices e.g., phones, PCs.
In addition, they do not address device selection or inference partitioning at runtime.
Mobile sensing frameworks: Existing work has focused only on applications requiring continuous sensing on a single mobile device.
Kobe [31], Auditeur [57], and Senergy [44] propose libraries of inference algorithms to promote code re-use and explore single device energylatency-accuracy trade-offs.
Other work [42,43,44,47] has focused on improving resource utilization by sharing sensing and processing across multiple applications on a mobile device.
None of these approaches address problems such as modular inference composition, device selection with user mobility, inference partitioning across multiple devices, or handling disconnections.An early version of our work appears in a workshop paper that outlined the problem and presented a basic design [65].
The current paper extends the design, implements real applications, and evaluates performance.
We discuss potential improvements to Beam.Error and error propagation: Beam currently supports typed errors such as probability distributions (e.g. mean and standard deviation), and error margin (e.g. center and radius).
Although error propagation has been studied in the field of artificial intelligence (e.g. neural network [63]), there is no prior work on error propagation in mobile context sensing.
We are investigating techniques to enable inference module developers to implement customized error propagation functions for specific inferences, so that Beam can propagate the error from a module's inputs to its output.
Actuation and timeliness: Many in-home devices possess actuation capabilities, such as locks, switches, cameras, and thermostats.
Applications and inference modules in Beam may want to use such devices.
If the inference graph for these applications is geo-distributed, timely propagation and delivery of such actuation commands to the devices becomes important and raises interesting questions of what is the safe thing to do if an actuation arrives "late".
Data archival and correlation mining: Prior work has shown that exploiting the correlation among inferences can effectively reduce sensing cost [55].
While Beam modules do not currently store data either at the engines or the coordinator, applications and modules may use a temporal datastore, such as Bolt [37], to make inferences durable.
Storing and querying archived inference data will allow inference developers to perform correlation mining to improve inferences.
Data privacy: While we do not address privacy concerns in our work, we believe the use of inferences can enable better data privacy controls [30].
For example, users may allow an application to access the occupancy inference (using a camera) instead of the raw image data used for drawing the inference.
This prevents the leakage of private information by preventing other inferences that can be drawn using the raw data.
Moreover, Beam's coverage tags allow the user to define fine-grained controls, for instance, allowing an application to access activity inference only for a certain user tag.
Applications using connected sensing devices are difficult to develop today because they must incorporate all the data sensing and inference logic, even as devices move or are temporarily disconnected.
We design and implement Beam, a framework and runtime for distributed applications using connected devices.
Beam introduces the inference graph abstraction which is central to decoupling applications, inference algorithms, and devices.
Beam uses the inference graph to address the challenges of device selection, efficient resource usage, and device disconnections.
Using Beam, we develop two representative applications (Rules and QS), where we show up to 4.5× lower number of tasks and 12× lower source line of code in application development effort, with negligible runtime overhead.
Moreover, Beam results in up to 3× higher inference accuracy due to its ability to select devices in heterogeneous environments, and Beam's dynamic optimizations match hand-optimized applications for network resource usage.
