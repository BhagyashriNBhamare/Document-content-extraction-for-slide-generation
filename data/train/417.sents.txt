This paper studies the fundamental trade-off between communication cost and delay cost arising in various contexts such as control message aggregation or organization theory.
An optimization problem is considered where nodes are organized in a tree topol-ogy.
The nodes seek to minimize the time until the root is informed about their states and to use as few transmissions as possible at the same time.
We derive an upper bound on the competitive ratio of O(min(h, c)) where h is the tree's height, and c is the transmission cost per edge.
Moreover, we prove that this upper bound is tight in the sense that any oblivious algorithm has a ratio of at least Ω(min(h, c)).
For chain networks, we prove a tight competitive ratio of Θ(min(√ h, c)).
Furthermore, the paper introduces a new model for online event aggregation where the importance of an event depends on its difference to previous events.
The analysis of distributed algorithms often revolves around time and message complexity.
On the one hand, we want our distributed algorithms to be fast, on the other hand, communication should be minimized.
Problems often ask to optimize one of the two-and treat the other only as a secondary target.
However, there are situations where time and message complexity are equally important.In this paper, we study such a case known as distributed aggregation.
Nodes of a large distributed network may sense potentially interesting data which they are to report to a central authority.
Not Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
PODC'08, August 18-21, 2008, Toronto, Ontario, Canada.
Copyright 2008 ACM 978-1-59593-989-0/08/08 ...$5.00.
only should the data make its way fast through the network such that information is not unnecessarily delayed; but also, since message transmission is costly, one may reduce the number of transmissions by aggregating messages along the way.
In other words, nodes may wait for further packets before forwarding them in order to decrease the number of transmission at the expense of a later arrival of the information at the sink.
This problem has many applications.
In the past it was mostly studied in contexts such as control message aggregation, or organization theory.
In the heyday of wireless networking the first application that comes to mind is perhaps sensor networking.
Due to energy constraints, it is necessary to minimize the number of transmissions.
At the same time, it is desirable to aim at minimizing the time until the nodes are informed about changes of measured values.This paper assumes that the communication network of the nodes forms a pre-computed directed spanning tree on which information about events is passed to the root node (the sink).
We assume that data arrives at the nodes in an online (worst-case) fashion.
A main challenge is to decide at what points in time data should be forwarded to a parent in the tree.Our contributions are the following.
We prove that a simple algorithm achieves a competitive ratio of O(min(h, c)) where h is the tree's height, and c is the transmission cost per edge, which improves on an existing upper bound of O(h log (cn)), where n is the network size.
This algorithm is oblivious, i.e., decisions at each node are based solely upon the static local information available at the node.
Being oblivious is a desirable property of distributed algorithms, since non-oblivious algorithms need dynamic updating mechanisms-a costly operation.
We also demonstrate that this upper bound is tight in the sense that there exist problem instances where any oblivious algorithm has a ratio of at least Ω(min(h, c)).
Earlier work proved a lower bound of Ω( √ h) on a chain network.Therefore, we examine this topology more closely and show that chain networks are inherently simpler than general trees by giving a competitive ratio of Θ(min( √ h, c)) for oblivious algorithms.
In the last part of this paper, we initiate the study of a new event aggregation model which takes into account that nodes often have non-binary data to aggregate and greater differences between values need to be reported to the root faster than small differences.
We present a model comprising this additional constraint as well as an oblivious algorithm achieving a competitive ratio of Θ(c//) on a one-link network, where is the minimum difference between two values.
Moreover, we devise a polynomial algorithm that can compute an optimal aggregation strategy offline for chain networks.This paper is organized as follows.
We review related work in Section 2 and we introduce our model in Section 3.
Section 4 contains our main technical contributions and Section 5 addresses value-sensitive aggregation.
We conclude the paper in Section 6.
The trade-off between delay and communication cost appears in various contexts, and plays a role in the design of algorithms for wireless sensor networks, for Internet transfer protocols, and also appears in organization theory.
This section gives a brief overview of related work on this topic.Papadimitriou et al. [11,12] investigate the following optimization problem: An organization is modeled as a tree where employees (leaves) receive messages to be sent to the boss (the root).
The authors observe that before it is possible to accept some communication, humans typically must do a "context switch" in order to process the message properly, and that the cost of these context switches becomes large if communications are not scheduled carefully.
Concretely, the cost function consists of two components, one capturing the total number of messages sent along the tree, and the other one capturing the total delay incurred by the messages before they reach the root.
For the formal analysis of this dilemma of interruptions, a Poisson process queuing model is assumed.A basic problem in the design of Internet transfer protocols such as the TCP protocol concerns the acknowledgements (ACKs) which have to be sent by a receiver in order to inform the sender about the successful reception of packets: In many protocols, a delay algorithm is employed to acknowledge multiple ACK packets with a single message or to piggy-back the ACK on outgoing data segments [14].
The main objective of these algorithms is to save bandwidth (and other overhead at the sender and receiver) while still guaranteeing small delays.
The problem of aggregating ACKs in this manner is also known as the TCP acknowledgment problem [5].
Karlin et al. [7] pointed out interesting relationships of the singlelink acknowledgment problem to other problems such as ski-rental, and gave an optimal, e/(e − 1)-competitive randomized online algorithm.
Brito et al. [4] calculated general upper and lower bounds for an asynchronous ACK delaying problem.There are many variations of the theme, e.g., Albers et al.[1] seek to minimize the number of acknowledgments sent plus the maximum delay incurred for any of these packets.
They propose a π/6-competitive deterministic algorithm for the single link, which is also a lower bound for any deterministic online algorithm.
Frederiksen et al. [6] consider deterministic and randomized algorithms for bundling packets on a single-link network; their objective function measures the total time elapsed while packets are waiting at the leaf node, but have not been delivered yet.Finally, there is much literature on aggregation in sensor networks [10,13,15,16,17].
E.g., Becchetti et al. [2] studied online and offline algorithms for scenarios where fixed deadlines must be met.
They show that the offline version of the problem is strongly NP-hard and provide a 2-approximation algorithm.The paper closest to ours is by Khanna et al. [8].
Our model is derived from the one by [8] which investigates the task of centralized and decentralized online control message aggregation on weighted tree topologies.
In particular, [8] presents a O(h log α)-competitive distributed algorithm, where h is the tree's height, and α is the sum of the weights of the tree's edges.
Moreover, the authors show that any oblivious distributed online algorithm has a competitive ratio of at least Ω( √ h).
In this paper, we study the same algorithm and we give a new analysis for scenarios where the communication cost is c on all links, resulting in a better upper bound of O(min (h, c)).
We also derive a new generalized lower bound for edge cost which are different from h, and show that for any oblivious aggregation algorithm, the competitive ratio is at least Ω(min(h, c)).
Moreover, by taking into account many interesting properties of our algorithm, we show that for chain graphs an upper bound of O(min( √ h, c)) holds.
This is asymptotically tight.
Korteweg et al. [9] address the same problem, but they follow a bicriterion approach which considers time and communication as two independent optimization problems: a (B, A)-bicriterion problem minimizes objective A under a budget on objective B. Inter alia, the authors prove that if r is the ratio between the maximum and the minimum delay allowed, then the competitive ratio of their algorithm is (2h λ , 2h 1−λ log r) for any λ in (0, 1].
Let there be a rooted tree T = (V, E) of height h with root r ∈ V and n = |V | nodes.
Every node u except for the root r (the sink) has a parent node v, i.e., an edge (u, v) ∈ E.
The cost of transmitting a message over an edge is c.We assume that events occur at the leaf nodes L ⊂ V (e.g., a control message arriving at a node, or a sensor node detecting an environmental change).
We will refer to the information about the occurrence of a single event as an event packet.
Leaf l creates an event packet p for every event that happens at l.Eventually, all event packets have to be forwarded to the root.
Instead of sending each packet p ∈ P individually to a node's parent after the event took place, nodes can retain packets and send a message m consisting of one or more packets together later, thus saving on communication cost as we have to pay for a link only once per message (rather than per event).
Messages can be merged iteratively with other messages on their way to the root.We consider a synchronous model where time is divided into time slots.
In each slot, an arbitrary number of events can arrive at each node.
For an event packet p, t l (p) denotes the time slot its corresponding event occurred at a node and tr (p) the time when it reaches the root.
For each time slot an event waits at a node, we add one unit to the delay cost, i.e., the delay cost dc (p) the event accumulates until reaching the root is dc (p) = tr (p) − t l (p).
Each message can only be forwarded one hop per round, i.e., a message always has to wait one round.
Thus, the delay accumulated by an event is at least h l , where h l denotes the length of the path from the respective leaf l to the root.
The total delay cost of all events accumulated up to time slot T is hencedcT = X p∈P,tr (p)≤T dc (p) + X p∈P,tr (p)>T (T − t l (p)).
Nodes can aggregate as many event packets as needed.
At each time step t, a node may aggregate awaiting event packets and forward the resulting message to its parent.
The cost of sending a message is c per edge no matter how many event packets are combined.
Consequently, the total communication cost is the sum of the edge cost of all message transmissions.
More formally, let St be the set of nodes sending out a message in time slot t, then the total communication cost ccT up to time slot T is ccT = P T t=1 |St|.
The total cost up to time T is the sum of both the delay and the communication cost,costT = dcT + ccT .
Observe that the edge cost c allows us to weight delay and communication costs: a larger c implies that communication cost become relatively more important compared to the delay cost.
Note that we neglect the energy consumption in idle listening mode and consider the nodes' transmission cost only.
We believe that this is justified for networks where listening nodes have their radios turned off most of the time and only check for data transfers at the very beginning of each time slot.Nodes do not know the future arrival time of events, and hence have to make the decisions on when to send messages online.
We are in the realm of competitive analysis [3] and define the (strict) competitive ratio ρ achieved by an online algorithm AGG as the delay and communication cost of AGG divided by the total cost of an optimal offline algorithm OPT .
DEFINITION 3.1 (ρ-COMPETITIVENESS).
An online algorithm AGG is (strictly) ρ-competitive compared to an optimal offline algorithm OPT if for all input sequences I, i.e., all possible event arrival sequences,cost ALG (I) ≤ ρ · cost OPT (I).
The goal of an online algorithm designer is hence to devise algorithms minimizing ρ, as a small ρ describes the guaranteed worstcase quality of an algorithm.In this paper, we focus on oblivious online algorithms.DEFINITION 3.2 (OBLIVIOUS ALGORITHMS).
A distributed online algorithm ALG is called oblivious if the decisions by each node v ∈ V whether to transmit a message solely depends on the time slots when the packets currently stored at v arrived (at v).
In particular, Definition 3.2 implies that the decisions of a node v do not depend on packets forwarded by v earlier or on v's location in the aggregation network.
This section describes and analyzes the deterministic online algorithm AGG presented in [5,8].
The algorithm is oblivious in the sense that given the same packet arrival times, each node will react in the same way, i.e., independently of its distance to the root (cf. Definition 3.2).
Essentially, the event aggregation algorithm AGG seeks to balance the total delay cost and the total communication cost.
In order to do so, it aggregates information about multiple events into one message until the forwarding condition is satisfied.
Whenever a new event occurs or a message arrives, it is merged with the message waiting for transmission at the node.For each message m, we define delay(m, t), denoting the delay associated with message m at time t. Informally, it is the sum of the accumulated delay cost of all the event packets the message m contains, minus the sum of the edge cost of every edge a message was sent over.
Thus, not only the delay but also the communication cost paid already is taken into account.
More formally, let a message m be a set of merged messages {m1, . . . , m k }, where message mi consists of |mi| packets and arrived at the current node in time slot ti.
The delay of message m at time t is defined bydelay(m, t) := k X i=1 [delay(mi, ti) − c + |mi|(t − ti)] .
When executing algorithm AGG, a node v forwards a message m to its parent as soon as the current accumulated delay exceeds the transmission cost.delay (m, t) ≥ c.We demonstrate the execution of AGG on a simple example.
Consider the tree and the event arrival sequence in Figure 1.
There are two events occurring at leaf node v1, one in time slot t = 1, one at time t = 2.
Node v2 receives two packets at t = 2.
The transmission cost is set to c = 3.
For this input sequence, node v1 sends its two packets after time t = 2 and node v2 after time t = 3, i.e., as soon as the accumulated delay reaches or exceeds c = 3.
Node v3 incurs a delay of two after the message from v1 arrives.
1 1 1 1 1 1 1 1 root v 1 v 2 v 3The goal of an online algorithm designer is hence to devise algorithms minimizing ρ, as a small ρ describes the guaranteed (worstcase) quality of an algorithm.In the following, we will mainly focus on oblivious online algorithms.
Being oblivious is a desirable property of distributed algorithms, since non-oblivious algorithms require a dynamic updating mechanism at each node that informs it about changes in the hierarchical structure-a costly operation [8].
DEFINITION 3.2 (OBLIVIOUS ALGORITHMS).
A distributed online algorithm ALG is called oblivious if the decisions by each node v ∈ V whether to transmit a message or not solely depends on the time slots when the packets currently stored at v arrived (at v).
In particular, Definition 3.2 implies that the decisions of a node v do not depend on packets forwarded by v earlier or on v's location in the aggregation network.TODO: Define delay (m) For each message m, we define delay(m), denoting the delay associated with message m. Informally, it is the sum of the accumulated delay cost of all the event packets it contains, minus the sum of the edge cost of every edge a message was sent over.
Thus not only the delay but also the communication cost paid already is taken into account.
END TODO This section describes and analyzes the deterministic online algorithm AGG presented in [5,8].
The algorithm is oblivious in the sense that given the same packet arrival times, each node will react in the same way, i.e., independently of its distance to the root (cf. Definition 3.2).
Essentially, the event aggregation algorithm AGG seeks to balance the total delay cost and the total communication cost.
In order to do so, it aggregates information about multiple events into one message until the forwarding condition is satisfied.
Whenever a new event occurs or a message arrives, it is merged with the message waiting for transmission at the node.
Concretely, a node u forwards a message m to its parent v as soon asdelay (m) ≥ c.We demonstrate the execution of AGG on a simple example.
Consider the tree and the event arrival sequence in Figure 1.
There are two events occurring at leaf node v1, one in time slot t = 1, one at time t = 2.
Node v2 receives two packets at t = 2.
The transmission cost is set to c = 3.
For this input sequence, node v1 sends its two packets after time t = 2 and node v2 after time t = 3, i.e., as soon as the accumulated delay reaches or exceeds three.
Node v3 incurs a delay of two after the message from v1 arrives.
In the next time slot, v3's delay cost increases to 7, as the message from v2 carries an "overflow delay" of 4 − c = 1 and there are four messages at v3.
Adding this up to the delay cost of the previous slot results in 2+1+4=7.
We establish a new upper bound of O(min(h, c)) on the competitive ratio of AGG by an astoundingly simple analysis.
Instead of calculating the delay and the communication cost the event packets accumulate, we focus on the messages AGG and OPT send.
We proceed as follows.
First, we investigate the competitiveness of AGG for a single link network, then tackle the chain network, and finally generalize our analysis to tree topologies.
THEOREM 4.1.
On arbitrary trees, the competitive ratio of AGG is at mostρ = cost AGG cost OPT ∈ O(min (h, c)).
PROOF.
The proof unfolds in several lemmas.
= c + xi for some xi ≥ 0, because mi will be sent as soon as its events' delay exceeds c, and because there can be (xi + 1) ≥ 0 simultaneous event arrivals in the time slot immediately preceding ti.
Any optimal offline algorithm OPT will have at least delay costs xi as well.
In addition, OPT incurs a cost of at least c for the event packets contained in mi, either because of a transmission or due to the accumulated delay,cost AGG i /cost OPT i ≤ (2c + xi)/(c + xi).
This expression is maximized for xi = 0, implying a competitive ratio of 2.2In a next step we analyse the chain network.
First, we assume that each message of the optimal offline algorithm which is sent from a given leaf node comprises packets of multiple messages sent by AGG at this leaf, and show that the claim indeed holds in this case.
Second, we prove that the claim holds true also if AGG sends more messages than OPT .
Finally, our results are generalized for arbitrary sending sequences and for trees.
In the next time slot, v3's delay cost increases to 7, as the message from v2 carries an "overflow delay" of 4 − c = 1 and there are four messages at v3.
Adding this up to the delay cost of the previous slot results in 2 + 1 + 4 = 7.
We establish a new upper bound of O(min(h, c)) on the competitive ratio of AGG by an astoundingly simple analysis.
Instead of calculating the delay and the communication cost the event packets accumulate, we focus on the messages AGG and OPT send.
We proceed as follows.
First, we investigate the competitiveness of AGG for a single link network, then tackle the chain network, and finally generalize our analysis to tree topologies.
THEOREM 4.1.
On arbitrary trees, the competitive ratio of AGG is at mostρ = cost AGG cost OPT ∈ O(min (h, c)).
PROOF.
The proof unfolds in several lemmas.LEMMA 4.2.
[5] The competitive ratio of AGG on a single link is at most 2.
In a next step we analyze the chain network.
First, we assume that each message of the optimal offline algorithm which is sent from a given leaf node comprises packets of multiple messages sent by AGG at this leaf, and show that the claim indeed holds in this case.
Second, we prove that the claim holds true also if AGG sends more messages than OPT .
Finally, our results are generalized for arbitrary sending sequences and for trees.
AGG at l be denoted by M A l .
Due to our assumption, a message m O j of OPT contains the event packets of one or several messages of AGG, i.e., m O j = ∪ i k=i m A k for some i ≥ i.The cumulated cost for AGG is less than (i − i + 1)(3h l c), since any message incurs a delay cost of less than 2c and a transmission cost of c per hop towards the root.Let the total number of messages sent by the optimal algorithm at node l be M O l .
The cost a message m O j accumulates is at least (i − i + 1)(c + h l − 1); the term (i − i)c is the delay cost the events accrue while waiting at the leaf and (i −i+1)(h l −1) is the lower bound for the delay incurred on the way to the root, matched if AGG's messages contain one event each.
The additional cost c stands for the communication cost the optimal algorithm has to pay for the first link.
Note that this cost cannot decrease due to a possible aggregation closer to the root.
Hence we can writeρ = cost AGG /cost OPT ≤ P M A l i=1 3h l c P M O l j=1 (i − i + 1) (c + h l − 1) = 3h l c c + h l − 1 ∈ O(min(h l , c)),which completes our proof.
2 LEMMA 4.4.
If the optimal algorithm sends more messages than AGG from a given leaf node l, the competitive ratio is at most ρ ∈ O (min (h l , c)).
PROOF.
Let the total number of messages that node l at depth h l sends be M A l and let the total number of messages by the optimal algorithm be M O l .
The delay cost these messages accumulate for OPT is at least M O l h l , regardless of aggregation operations closer to the root, and the communication cost is at least M O l c since every message has to be sent over the first link separately.
The cumulated cost for AGG is at most M A l (3h l c).
Thusρ ≤ P M A l i=1 3h l c P M O l j=1 h l + c ≤ 3h l c h l + c ∈ O (min (h l , c)) .
Continuing the proof of Theorem 4.1, it remains to consider an arbitrary sequence of event arrivals where the optimal algorithm's messages are not unions of the packets of several messages of the online algorithm AGG or where the optimal algorithm transmits more often at the leaf, but messages of AGG are split and recombined across several messages the optimal algorithm sends.
We divide the sequence of event arrivals into sections where AGG sends more messages than OPT and into section where AGG sends fewer messages than OPT .
We proceed in the following way: Set t := 0.
For every time slot ti where AGG sends a message we check whether the number of messages so far exceeds the number of messages the optimal algorithm sends.
As soon as this condition is not satisfied anymore (time slot t k ) we backtrack to the previous message at time slot t k−1 .
We exempt OPT from paying for the messages it did not send towards the root up to this time slot.
For the section [0, t k−1 ], Lemma 4.3 can be applied.
We continue by resetting t := 0.
For every time slot ti where AGG sends a message we check whether the number of messages so far is below the number of messages the optimal sends.
As soon as this condition is not satisfied anymore (time slot t k ) we backtrack to the previous message at time slot t k−1 .
We exempt OPT from paying for the messages it did not send towards the root up to this time slot.
For the section [0, t k−1 ] we can now apply Lemma 4.4.
We repeat this examination for all remaining slots.
Consequently it holds for each leaf that there is no section where AGG's ratio is higher than O (min(h, c)).
Since no assumptions on the behavior of the optimal algorithm have been made in the arguments above and since we only count the communication cost incurring on the edges between the leaves and their neighbors, the statements hold for general trees as well.
2We conclude our investigations of the tree network with a lower bound stating that AGG is asymptotically optimal for any oblivious algorithm.
Recall from Definition 3.2 that for oblivious algorithms, it holds that the wait time w only depends on the packet arrival time of the packets currently stored by a given node.
THEOREM 4.5.
Any oblivious deterministic online algorithm has a competitive ratio of at leastρ = cost ALG cost OPT ∈ Ω(min(h, c)) on the tree.PROOF.
Consider the tree topology depicted in Figure 2 which consists of a chain network of n/2 + 1 nodes, where all nodes except for the two last ones have an additional neighbor.
The leaf nodes are referred to by v1, ..., v n/2 .
Assume an input sequence where all leaves simultaneously get one packet and consider any oblivious online algorithm ALG.
Since ALG is oblivious, according to Definition 3.2, each leave node vi will send the packet after waiting for w time slots to its parent, where the packet arrives at time w + 1 (the value of w > 0 depends on the chosen algorithm).
From there, the packet leaves at time 2w + 1.
And so on.
Generally, the packet of leaf node vi will arrive at a node at distance j from vi at time jw + j, and will stay there for w rounds.
Observe that the packets of two nodes vi−1 and vi are never merged into one message, as the time intervals [(j − 1) w + (j − 1) , jw + (j − 1)] and [jw + j, (j + 1) w + j] are disjoint.
Thus, ALG has communication cost in the order of Θ ` h 2 c ´ and delay cost in the order of Θ ` h 2 w ´ .
Now consider an algorithm which aggregates all these packets on the way to the root: the communication cost are in Θ (ch), and the delay cost are Θ ` h 2 ´ .
As the optimal algorithm OPT can only have lower cost, we have the following (asymptotic) competitive ratio:ρ = cost ALG cost OPT ≥ h 2 w + h 2 c 2hc + h 2 ,and the claim follows.
2Discussion.
The analysis of Theorem 4.1 can be compared to the results obtained in [8].
There, an upper bound of O (h log α) is derived for the competitive ratio of AGG, where α is the total edge weight of the tree.
If all edges have a weight c, this translates into O (h log (nc)), which is O ` h 2 log c ´ in balanced binary trees.
In this case, our much simpler analysis is better by a factor of Θ (h log c) if h < c.
In other networks, for instance, on chain topologies, the gap between the two bounds narrows, although it always remains positive.
In order to obtain our upper bound for trees, the previous section has already briefly studied the competitiveness of AGG on chain networks.
In the following, it is shown by a more detailed analysis taking into account many intrinsic properties of AGG, that the bound can be improved.
Concretely, we prove that on the chain topology, AGG is O( √ h)-competitive, and that no oblivious algorithm is can be less than Ω(min(c, √ h))-competitive.THEOREM 4.6.
In chain graphs, the competitive ratio of AGG isρ = cost AGG cost OPT ∈ O " min " √ h, c "" .
PROOF.
We start analyzing input sequences where AGG does not merge any messages at inner nodes.
We then show that merge operations cannot improve or deteriorate the competitive ratio.LEMMA 4.7.
On chain graphs and for sequences where AGG does not have any merge operations, the competitive ratio of AGG is O( √ h).
OPT , and assume that OPT 's message m O consists of packets which are distributed over x √ h messages m A i of the online algorithm AGG.
Observe that x ∈ ω(1) since otherwise the claim trivially holds due to the communication cost.Let ni denote the number of packets in message m A i , and let ti denote the time when this message departs from the leaf node.
Without loss of generality we assume that ni ≤ c.
In order to send the x √ h messages individually to the root, AGG incurs a transmission cost of cc AGG = chx √ h and the delay cost is bounded bydc AGG < 2chx √ h.For the optimal algorithm this transmission entails a communication cost of cc OPT = ch.
We now bound the delay cost accumulated by each message m A i which is merged into message m O by the optimal algorithm.
Without loss of generality, assume that for 1 ≤ i ≤ x √ h, all ni packets arrive simultaneously: if packets arrived dispersed over time, OPT would incur higher delay cost.
Let λi denote the time interval from the arrival of the ni packets until the corresponding message departs from the leaf.
Moreover, let δi be the time interval after the message has departed from the leaf until the next set of ni+1 packets arrives.
The delay cost the OPT accumulates at the leaf is given byx √ h−1 X l=i x √ h−1 X j=l n l (δj + λj) .
We have λ l = c/n l by the definition of AGG.
Under the assumption that λ l is c/n l , the delay of the optimal algorithm decreases while AGG's cost remain the same.
In order to guarantee that consecutive messages cannot merge, it must hold for δ l thatδ l ≥ max " h 2 ‰ 2c n l ı − h 2 ‰ 2c n l+1 ı − λ l+1 , 0 « .
We show now that the delay cost for the optimal algorithm decreases if we balance the number of packets per message.
Consider two consecutive messages m A i and m A i+1 , where m A i+1 is not the last message of m O j for some j. Assume ni ≥ ni+1 + 1.
We want to compute the difference between the delay cost in this case (case a: dc1) and the delay cost when we remove one packet from m A i and add it to m A i+1 (case b: dc2).
To this end it suffices to examine the delay cost accrued in the time slots between the departure of m A i−1 and the arrival of m A i+2 .
The relevant delay cost isP i−1 l=1 n l · (δi−1 + λi + δi + λi+1 + δi+1) + ni (λi + δi + λi+1 + δi+1) + ni+1 (λi+1 + δi+1) .
Note that m A i+1 cannot catch up with m A i because of its size in dc1, thus δi = 0.
For dc2, δi can only exceed 0 if ni − 1 > ni+1 + 1.
The difference ∆ dc between the two costs is hence∆ dc = i−1 X l=1 n l · (δ a) i−1 + λ a) i + λ a) i+1 + δ a) i+1 − δ b) i−1 − δ b) i −λ b) i+1 − δ b) i+1 ) + ni(λ a) i + λ a) i+1 + δ a) i+1 − λ b) i − δ b) i − λ b) i+1 −δ b) i+1 ) + ni+1(λ a) i+1 + δ a) i+1 − λ b) i+1 − δ b) i+1 ) − λ b) i − δ b) i = i−1 X l=1 n l · " h 2 "‰ 2c ni+1 ı − ‰ 2c ni ı« + c ni+1 « +ni " h 2 "‰ 2c ni+1 ı − ‰ 2c ni − 1 ı« + c ni − c ni − 1 + c ni+1 « +ni+1 " h 2 "‰ 2c ni+1 ı − ‰ 2c ni+1 + 1 ı« + c ni+1 − c ni+1 + 1 « − c ni − 1 − h 2 "‰ 2c ni − 1 ı − ‰ 2c ni+1 + 1 ı« + c ni+1 + 1 .
Clearly, the sum of the terms multiplied by h/2 is at least zero.
Observe that the following inequality holds for all ni ≥ 2, ni −1 > ni+1, and arbitrary ni−1:ni " 1 ni − 1 ni − 1 + 1 ni+1 « − 1 ni − 1 +ni+1 " 1 ni+1 − 1 ni+1 + 1 « + 1 ni+1 + 1 > 0.
Hence, the difference of the cost is always positive, and a lower bound for the delay cost is reached if for all pairs of consecutive messages the second one contains at least as many packets as the first one.We now compute the delay cost of this balanced arrival sequence.
Let the last message with a size four times its predecessor's, i.e., n k ≥ 4n k−1 , be m A k .
(If no such message exists, take k = 1.)
The total sum of the delay cost in this case isx √ h−1 X i=1 x √ h−1 X j=i ni (tj − tj+1) > k−1 X i=1 k−1 X j=i niδj+ x √ h−1 X i=k x √ h−1 X j=i niλj.The second summand is at least (x √ h − 1 − k) 2 c/4 since the delay cost m A i accrues in between the arrival of m A j and m A j+1 is at least niλj = nic/nj ≥ c/4 since nj ≤ 4ni for all i, j > k.
In order to bound the first summand, we use the fact that because∀ i : ni < ni+1 it holds that 2c/ni − 2c/ni+1 ≥ 0.
Thus k−1 X i=1 k−1 X j=i niδj = k−1 X i=1 ni k−1 X j=i h 2 "‰ 2c nj ı − ‰ 2c nj+1 ı« = k−1 X i=1 ni h 2 "‰ 2c ni ı − ‰ 2c n k ı« > k−1 X i=1 ni h 2 " 2c ni − 2c n k − 1 « > (k − 1) hc 4 .
Note that if k < x √ h/2 the delay cost amounts to more thanΩ((x √ h − 1 − k) 2 c/4) = Ω(x 2 hc)and otherwise the delay cost exceeds Ω(xh √ hc).
Thus, we can conclude our proof byρ ∈ O((x √ hhc)(hc + hx √ h + xhc)) ∈ O( √ h).2 LEMMA 4.8.
Consider a transmission of OPT and assume that AGG merges µi messages into one message at hop distance i from the leaf.
Compared to a sequence where no messages are merged, AGG can reduce its cost by at least Ω(µi · c · (h − i)).
PROOF.
If the µi messages are sent to the root separately, the online algorithm pays µi(h − i)c communication cost for the transmissions between the node at distance i to the root node.
By merging theses messages the cost for the transmission amounts to (h − i)c, consequently the reduction is in Ω(µi · c · (h − i)).2 LEMMA 4.9.
Consider a transmission of OPT and assume that AGG merges µi messages into one message at hop distance i from the leaf.
Compared to a sequence where no messages are merged, OPT can reduce its cost by at most O(µi · c · (h − i)).
PROOF.
We prove this lemma in two steps.
First, we assume that in the execution of the online algorithm AGG the µi messages departed from the leaf node separately and did not merge with any messages before reaching the node at distance i. Thereafter we show how to generalize our results for arbitrary merges.Consider the µi messages that AGG merges at node i.
We denote the size of the messages under scrutiny by n1, ..., nµ i .
Without loss of generality, assume that for 1 ≤ j ≤ µi, all nj packets arrive at the same time: if packets arrived dispersed over time, only the delay cost of AGG would decrease.
In the following, let Xs denote that variable X is considered in the scenario where AGG does not have any merges, and Xm denote a variable in the other scenario.
Let δ l denote the time interval between two consecutive arrival time slots of the set of n l and the set of n l+1 packets.
For sequences where AGG does not merge any packets, OPT 's delay cost is given bydc OPT s = µ i −1 X l=1 µ i −1 X j=l n l δ s j .
In order to guarantee that consecutive messages cannot merge by the definition of AGG we have δ l s = max (κs, 1), where κs = h/2 (2c/n l − 2c/n l+1 ) + c/n l − c/n l+1 .
If we assume the first merge operation of µi messages to happen at depth h − i, it must hold that n l < n l+1 and we can compute a lower bound for the reduce time interval between two messages.
Observe that in order to ensure that messages do not merge too early, it must hold that δ l m > max (κm, 1), where κm= (i − 1) /2 (2c/n l − 2c/n l+1 ) + c/n l − c/n l+1 .
Thus, OPT can reduce its delay cost by at most:∆dc OPT = dc OPT s − dc OPT m ≤ µ i −1 X l=1 n l µ i −1 X j=î j=î δ s j − δ m j ˜ ≤ µ i −1 X l=1 µ i −1 X j=l n l h − i + 1 2 »‰ 2c n l ı − ‰ 2c n l+1 ı- = h − i + 1 2 µ i −1 X l=1 n l »‰ 2c nj ı − ‰ 2c nµ i ı- ≤ h − i + 1 2 (µi − 1)3c.
Hence, the claim holds for non-recursive merges.
To see why the claim also holds for repeated merges, consider again AGG's messages which are aggregated by OPT , and consider the locations in the chain topology where they merge the first time.
If this is the only time a merge occurs, we are done.
Otherwise, regard the node where the merge occurs as a new leaf node and consider the remaining chain until the root.
For this network, the same arguments apply, and hence, the claim also holds in this case.2 LEMMA 4.10.
Fix a sequence of packet arrivals such that on a chain graph AGG sends ν messages individually to the root and merges µ messages at distance i from the leaf the competitive ratio is O(min( √ h, c)).
AGG sends ν messages individually to the root and merges µ messages at distance i from the leaf.
If the packets that form the µ messages the online algorithm merges arrive before the ν messages sent to the root separately the claim follows directly from Lemmas 4.8 and 4.9.
Otherwise we have to take the delay cost the ν messages can save since the to be merged messages can arrive closer to each other into account.
Applying the Lemmas 4.8 and 4.9 leads to a total cost for AGG of less than 3νhc + 3hc + 3µic and the total cost for OPT amounts to at least Ω ` hc + min(ν 2 c, νhc) + µic´.
µic´ µic´.
As in the proofs above we can assume without loss of generality that (ν + µ) ∈ ω( √ h).
If νh < ν 2 the competitive ratio is in O(1), otherwise the ratio is at most O( νh+µ h+ν 2 +µ).
Assume ν to be lager than µ.
This implies that ν > √ h and hence the ratio isO(νh/ν 2 ) = O( √ h).
If µ is larger than ν, we have a ratio of O(hnu/(h + nu 2 )), which is O( √ h).
2The online algorithm performing several merge operations cannot increase the competitive ratio, and together with Theorem 4.1, it follows that the competitive ratio is at most O(min( √ h, c)) on chain graphs.
2We now show that AGG is asymptotically optimal for all oblivious online algorithms, i.e., we derive a lower bound for chain networks of Ω(min( √ h, c)).
For this lower bound, we consider a chain network with h + 1 nodes.
Let ALG denote any oblivious online algorithm, and assume that packets arrive one-by-one: at time 0, a packet p arrives at the leaf node l.
The next packet arrives at the leaf exactly when ALG sends the packet at l. Let w denote the time a packet waits at l, and observe that the same waiting time holds for all nodes on the way from the leaf to the root.
Thus, the total waiting time per packet is hw, and the communication cost is hc: cost ALG = hw + hc.
We now derive an upper bound on the optimal algorithm's cost for this sequence.
We partition the packets into blocks of size √ h, i.e., one message contains √ h packets.
Thus, the communication cost per packet of this algorithm is hc/ √ h = √ hc.
The delay cost per message at the leaf isP √ h−1 i=1iw ∈ Θ(hw).
In addition, each packet experiences one unit of delay per hop on the way up to the root.
Thus, the optimal cost per packet is cost OPT ≤ Θ(√ hc + w √ h + h).
Therefore,for this sequence, it asymptotically holds thatρ ≥ hc + hw ( √ hc + w √ h + h = h(c + w) √ h(c + w) + h .
The lower bound follows from distinguishing three cases.
If h and c + w are asymptotically equivalent, the above expression becomes Ω( √ h).
If h is asymptotically larger than c + w, the best oblivious algorithm which chooses w as small as possible yields a lower bound of Ω (c).
Finally, if h < c + w, we have Ω( √ h).
THEOREM 4.11.
The competitive ratio of any oblivious algorithm is at leastρ = cost ALG cost OPT ∈ Ω " min( √ h, c) " .
Discussion.
Our findings can be compared to the analysis presented in [8].
Their Ω( √ h) lower bound holds for arbitrary oblivious algorithms on trees.
In this paper, we have shown that this upper bound is too pessimistic, as general trees are inherently more difficult than chain topologies, and that the lower bound can be increased to Ω(min(h, c)).
For chain networks, we have generalized their result to arbitrary edge cost, yielding a lower bound of Ω(min( √ h, c)), which is proved tight by AGG.
Before we conclude this paper, we introduce a novel model for online event aggregation.
In contrast to the aggregation model studied so far, this model is more appropriate in scenarios where the to be delivered information is not binary (e.g., event messages) but where arbitrary value aggregations need to be performed at the root.
Take wireless sensor networks as a motivating example: A set of nodes measures the temperature at a certain outdoor location, and the root is interested to have up-to-date information on these measurements.
Thereby, larger value changes are more important and should be propagated faster to the root, e.g., such that an alarm can be raised soon in case of drastic environmental changes.In the following, we consider a most simple topology: a network consisting of a leaf and a sink.
Let the value measured by the leaf l at time t be lt. We assume that the leaf node can only send the value it currently measures.
The root node's latest value of node l at time t is denoted by rt.
We seek to minimize the following optimization function: cost = M · c + P t |lt − rt| where M is the total number of message transmissions and c the cost per transmission, i.e., M · c is the total communication cost.Typically, the values measured by a sensor node do not change arbitrarily, but there is a bound on the maximal change per time unit.
In the following, we assume that the value measured by a node changes by at most ∆ per round.
Moreover, we assume that the sensor nodes can only measure discrete quantities, and that the difference between two measured values is at least .
First observe that there exists a simple optimal (offline) algorithm which employs dynamic programming.
OPT exploits the following optimal substructure: For all time slots i, we compute the minimal cost given that the node sends its value at time i; in order to find this minimum cost, we consider each optimal last transmission j < i and add the inaccuracy cost which accrued at the root node between the two transmissions j and i. Observe that it is not necessary to iterate over all time slots i, because an optimal algorithm only sends a value immediately after it has changed, i.e., we only have to consider the time slots with value changes.
Hence we can construct an array OP T [·] of size λ, where λ is the total number of value changes at the leaf node.
We set OP T [0] = 0, as we assume that initially, the root stores the correct value.
The remaining matrix entries are then computed as follows:OP T [i] = min j<i OP T [j] + c + i X t=j+1 |lt − lj| !
.
We have the following theorem.THEOREM 5.1.
In a link network, the optimal aggregation strategy can be computed in time O(λ 3 ), where λ is the number of value changes at the leaf.We propose the following online algorithm AGG, which can be seen as a generalization of the algorithm presented in the previous section: The leaf l sends the value it currently measures if and only if P T t=τ |lt − lτ | ≥ c, where τ is the last time l has transmitted its value and T is the current time.For the analysis of AGG, we consider the time intervals between two transmissions of AGG.
For each such interval, we can bound the competitive ratio yielding an overall competitive ratio.
We first need the following helper lemma.LEMMA 5.2.
Let ρ be the competitive ratio of AGG when AGG's delay cost is c in each time interval I, then 3ρ/2 is an upper bound on the total competitive ratio.PROOF.
First observe that AGG can have a larger delay cost than c in an interval, e.g., if in a round where the accumulated delay cost is c − for an arbitrarily small > 0 there is a large value change of size ∆ at the leaf.
Hence, the online algorithm's delay in any interval is at most 2(c − ) + ∆.
Consider an interval I where the online algorithm's delay cost is 2(c − ) + k for some k ≤ ∆.
Compared to the case studied so far, AGG's delay cost will increase by at most k + c − 2.
However, due to the large value change, we know that the optimal algorithm's delay cost must increase by at least k as well.
The new competitive ratio ρ is hence PROOF.
We first prove that ρ ∈ O(c//), and subsequently show that ρ ∈ Ω(c//).
ρ = CC AGG + DC AGG CC OPT + DC OPT ≤ cc AGG + dc AGG + k + c − 2 cc OPT + dc OPT + k = cc AGG + dc AGG cc OPT + dc OPT + k + k + c − 2 cc OPT + dc OPT + k < ρ + c − 2 cc OPT + dc OPT < ρ + c − 2 (cc AGG + dc AGG )/ρ < ρ + c − 2 2c/ρ < 3ρ 2 .
Proof for ρ ∈ O(c//): First, the ratio is computed under the assumption that the delay cost of AGG is exactly c; we then apply Lemma 5.2.
We classify the possible types of intervals I between two sending events of the online algorithm and consider them separately.
Observe that for any interval where the optimal algorithm OPT transmits, the competitive ratio is at most 2, as OPT has cost at least c and the online algorithm AGG has communication cost c and delay cost c.
It remains to examine the situations where OPT does not send.Assume that at the beginning of this interval, AGG sends the value A0, and at the end, it sends the value A1.
Furthermore we denote the optimal algorithm's value at the root at the beginning and at the end of this interval by O0 and O1, respectively.
We define δ0 := |A0 − O0| and δ1 := |A1 − O1| and examine all possible cases under the assumption that the delay cost of AGG is c for every interval.Case δ0 = δ1 = 0: If OPT has no transmission, it must have the same delay cost in this interval as AGG, because the initial and final values are the same, and hence ρI ≤ 2.
Case δ0 = 0, δ1 = 0: If OPT has no transmission, it must have at least the same delay cost as AGG in I , thus ρI ≤ 2.
Case δ0 = 0, δ1 = 0: If OPT has no transmission, it incurs at least delay cost δ0 in the first time slot, as AGG sends the correct value at the beginning of the interval.
Hence, ρI ≤ 2c/δ0.
Case δ0 = 0, δ1 = 0: In this case, OPT has delay cost δ0 as well yielding ρI ≤ 2c/δ0.
Thus, for each of these intervals, ρI ≤ 2c/δ0.
It must hold that δ0 > , and the claim follows by applying Lemma 5.2.
Proof for ρ ∈ Ω(c//): Consider the following sequence of values at the leaf node: where α β denotes that the value α remains for β rounds.
Observe that for each subsequence (0 c//−1 , −, 0 c//−1 , ), 2 is an upper bound on OPT 's delay cost: It is the total delay cost if there are no transmissions at all in the entire sequence.
In contrast, AGG has 2c delay cost plus two transmissions.
That is, neglecting the cost of the first time slot, we have ρ ≥ 4c/2 = 2c//.
2 This paper investigated an online aggregation problem which can be regarded as a generalization of the classic ski-rental problem to trees.
This generalization is motivated by the increasing popularity of wireless sensor networks where a trade-off between event notification time and transmission cost exists.
We have studied a simple distributed algorithm which achieves a competitive ratio of Θ(min(h, c)) in case of general trees and Θ(min( √ h, c)) in case of chains.
Apart from the efficiency criterion, this algorithm is attractive as it poses minimal hardware requirements on the sensor nodes (low memory and computational requirements).
In addition to binary event aggregation, this paper has initiated the analysis of a new model where the root is interested in the nodes' values (e.g., the measured temperature or humidity).
We believe that both problems still pose interesting questions for future research.
E.g., the exploration of asynchronous models, the study of non-oblivious algorithms, or algorithms which have a limited amount of information about the states of their neighbors, can yield deeper insights into the event aggregation problem and may also be useful in other applications.
Moreover, it would be interesting to examine whether the techniques used in [7] can also be applied to our value aggregation problem in order to reduce the competitive ratio further by randomization.
We thank Thibaut Britz and Pascal von Rickenbach from ETH Zurich for interesting discussions.
