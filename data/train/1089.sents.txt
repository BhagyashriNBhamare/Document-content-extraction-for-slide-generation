In this paper, we introduce a parametric semantics for timed controllers called the Almost ASAP semantics.
This semantics is a relaxation of the usual ASAP semantics (also called the maximal progress semantics) which is a mathematical idealization that can not be implemented by any physical device no matter how fast it is.
On the contrary, any correct Almost ASAP controller can be implemented by a program on a hardware if this hardware is fast enough.
We study the properties of this semantics, show how it can be analyzed using the tool HyTech, and illustrate its practical use on examples.
Timed and hybrid systems are dynamical systems with both discrete and continuous components.
A paradigmatic example of a hybrid system is a digital embedded control program for an analog plant environment, like a furnace or an airplane: the controller state moves discretely between control modes, and in each control mode, the plant state evolves continuously according to physical laws.
A natural model for hybrid systems is the hybrid automaton, which represents discrete components using finite-state machines and continuous components using real-numbered variables which evolution is governed by differential equations or differential inclusions.
Several verification and control problems have been studied for hybrid automata or interesting subclasses (see for example [HKPV98]).
Tools like HyTech [HHWT95] have proven useful to analyze high-level descriptions of embedded controllers in continuous environments.When a high level description of a controller has been proven correct it would be valuable to ensure that an implementation of that design can be obtained in a systematic way in order to ensure the conservation of correctness.
This is often called program refinement: given a high-level description P 1 of a program, refine that description into another description P 2 such that the "important" properties of P 1 are maintained.
Usually, P 2 is obtained from P 1 by reducing nondeterminism.
To reason about the correctness of P 2 w.r.t. P 1 , we often use a notion of simulation [Mil80] which is powerful enough to ensure conservation of LTL properties for example.In this paper, we show how to adapt this elegant schema in the context of real-time embedded controllers.
To reach this goal, there are several difficulties to overcome.
First, the notion of time used by hybrid automata is based on a dense set of values (usually the real numbers).
This is unarguably an interesting notion of time at the modeling level but when implemented, a digital controller manipulates timers that are digital clocks.
Digital clocks have finite precision and take their values in a discrete domain.
As a consequence, any control strategy that requires clocks with infinite precision can not be implemented.
Second, hybrid automata can be called "instantaneous devices" in that they are capable of instantaneously react to time-outs or incoming events by taking discrete transitions without any delay.
Again, while this is a convenient way to see reactivity and synchronization at the modeling level, any control strategy that relies for its correctness on that instantaneity can not be implemented by any physical device no matter how fast it is.
Those problems are known and have already attracted some attention from our research community.
For example, it is well-known that timed automata may describe controllers that control their environment by playing a so called zeno strategy, that is, by taking an infinite number of actions in a finite amount of time.
This is widely considered as unacceptable even by authors making the synchrony hypothesis [AFP + 03].
But even if we prove our controller model non-zeno, that does not mean that it can be implemented.
In fact, we recently showed in [CHR02] that there are (very simple) timed automata that respect a syntactic criterion that ensures nonzenoness but require faster and faster reactions, say at times 0, 1 2 , 1, 1 1 4 , 2, 2 1 8 , 3, 3 1 16 , . . ..
So, timed automata may model control strategies that can not be implemented because the control strategy does not maintain a minimal bound between two control actions.
A direct consequence is that we can not hope to define for the entire class of timed automata a notion of refinement such that if a model of a real-time controller has been proven correct then it can be systematically implemented in a way that preserves its correctness.The infinite precision and instantaneity characteristics of the traditional semantics given to timed automata is very closely related to the synchrony hypothesis that is commonly adopted in the community of synchronous languages [Ber00].
Roughly speaking, the synchrony hypothesis can be stated as follows: "the program reacts to inputs of the environment by emitting outputs instantaneously".
The rationale behind the synchrony hypothesis is that the speed at which a digital controller reacts is usually so high w.r.t. the speed of the environment that the reaction time of the controller can be neglected and considered as nil.
This hypothesis greatly simplify the work of the designer of an embedded controller: he/she does not have to take into account the performances of the platform on which the system will be implemented.
We agree with this view at the modeling level.
But as any hypothesis, the synchrony hypothesis should be validated not only by informal arguments but formally if we want to transfer correctness properties from models to implementations.
We show in this paper how this can be done formally and elegantly using a semantics called the Almost ASAP semantics (AASAP-semantics).
The AASAP-semantics is a parametric semantics that leaves as a parameter the reaction time of the controller.
This semantics relaxes the synchrony hypothesis in that it does not impose the controller to react instantaneously but imposes on the controller to react within ∆ time units when a synchronization or a control action has to take place (is urgent).
The designer acts as if the synchrony hypothesis was true, i.e. he/she models the environment and the controller strategy without referring to the reaction delay.
This reaction delay is taken into account during the verification phase: we compute the largest ∆ for which the controller is still receptive w.r.t. to the environment in which it will be embedded and for which the controller is still correct w.r.t. to the properties that it has to enforce (to avoid the environment to enter bad states for example).
We show that the AASAP semantics has several important and interesting properties.
First, the semantics is such that "faster is better".
That is, if the controller is correct for a reaction delay bounded by ∆ then it is correct for any smaller ∆ .
Second, any controller which is correct for a reaction delay bounded by ∆ > 0 can be implemented by a program on a hardware provided that the hardware is fast enough and provides sufficiently precise digital clocks.
Third, the semantics can be analyzed using existing tools like HyTech.Structure of the paper.
The paper is organized as follows.
In section 2, we recall the notions of timed transition systems, receptiveness and safety control.
We also define a notion of simulation that will ensure the conservation of receptiveness and safety properties imposed by the controller.
In section 3, we review the syntax and classical semantics of timed automata.
In section 4, we define formally the AASAP semantics and study some of its properties.
In section 5, we introduce a very simple and naive notion of real-time program to make clear that any correct real-time controller for the AASAP semantics can be implemented.
In section 6, we explain how the AASAP semantics can be analyzed and used in practice.
Proofs and other examples can be found in a longer version of this paper at the following web page: http://www.ulb.ac.be/di/ssd/jfr.
In this section, we recall the definition of timed transition systems and extend them with structured sets of labels.
We define a notion of freedom of receptiveness problem and a compatible notion of simulation.
This notion of simulation will be the formal basis for our notion of refinement.
Finally, we introduce the problem of safety control and show how our notion of simulation can be used in that context.
Definition 1 [TTS] A timed transition system T is a tuple S, ι, Σ, → where S is a (possibly infinite) set of states, ι ∈ S is the initial state, Σ is a finite set of labels, and →⊆ S × Σ ∪ R ≥0 × S is the transition relation where R ≥0 is the set of positive real numbers.In the sequel, we use one STTS to model a timed controller and one to model the environment in which the controller has to be embedded.
We model the communication between the two STTS using the mechanism of synchronization on common labels.
This is a blocking communication mechanism.
But we want to verify that the controller does not control the environment by refusing to synchronize on its output, and on the other hand, we do not want our controller to issue outputs that can not be accepted by the environment.
To verify the absence of those synchronization problems, we make their potential presence explicit by introducing the notion of refusal function.Definition 3 [Refusal function of a STTS] Given a STTS T = S, ι, Σ in , Σ out , Σ τ , →, we define its refusal function Ref T : S → 2 Σin as follows :Ref T (s) = {σ ∈ Σ in | ¬∃s ∈ S : (s, σ, s ) ∈→}We now define when and how two STTS can be composed to define a timed transition system.Definition 4 [Composition of STTS] Two STTS T 1 = S 1 , ι 1 , Σ 1 in , Σ 1 out , Σ 1 τ , → 1 and T 2 = S 2 , ι 2 , Σ 2 in , Σ 2 out , Σ 2 τ , → 2 are composable if Σ 1 in = Σ 2 out and Σ 2 in = Σ 1 out .
Their composition, noted T 1 T 2 is the TTS T = S, ι, Σ, → such that S = {(s 1 , s 2 ) | s 1 ∈ S 1 and s 2 ∈ S 2 }, ι = (ι 1 , ι 2 ), Σ = Σ 1 out ∪ Σ 2 out ∪ Σ 1 τ ∪ Σ 2τ , and → is such that for any σ ∈ Σ ∪ R ≥0 , we have that ((s 1 1 , s 2 1 ), σ, (s 1 2 , s 2 2 )) ∈→ iff one of the following three assertions holds:-σ ∈ Σ 1 out ∪ Σ 2 out ∪ R ≥0 and (s 1 1 , σ, s 1 2 ) ∈→ 1 and (s 2 1 , σ, s 2 2 ) ∈→ 2 -σ ∈ Σ 1 τ and (s 1 1 , σ, s 1 2 ) ∈→ 1 and s 2 1 = s 2 2 -σ ∈ Σ 2 τ and (s 2 1 , σ, s 2 2 ) ∈→ 2 and s 1 1 = s 1 2When composing two STTS, we say that the result is free of receptiveness problem if there is no reachable state in the product where one STTS wants to issue an output that is not accepted by the other one.Definition 5 [Freedom of receptiveness problems] The composition of two com-posable STTS T 1 = S 1 , ι 1 , Σ 1 in , Σ 1 out , Σ 1 τ , → 1 and T 2 = S 2 , ι 2 , Σ 2 in , Σ 2 out , Σ 2 τ , → 2 is free of receptiveness problems if their composition T 1 T 2 = S, ι, Σ, → is such that there does not exist (s 1 1 , s 2 1 ) ∈ Reach(T 1 T 2 ), such that either: -there exist σ ∈ Σ 1 out , s 1 2 ∈ S 1 such that (s 1 1 , σ, s 1 2 ) ∈→ 1 and σ ∈ Ref T 2 (s 2 1 ) -there exist σ ∈ Σ 2 out , s 2 2 ∈ S 2 such that (s 2 1 , σ, s 2 2) ∈→ 2 and σ ∈ Ref T 1 (s 1 1 ) Implementations of controllers are also formalized using STTS.
To reason about the correctness of implementations w.r.t. higher level models, we use a notion of simulation.
That notion of simulation makes explicit the notion of refusal in order to preserve the potential freedom of receptiveness problem property of the model.Definition 6 [Simulation relation for STTS] Given two STTS T 1 = S 1 , ι 1 , Σ 1 in , Σ 1 out , Σ 1 τ , → 1 and T 2 = S 2 , ι 2 , Σ 2 in , Σ 2 out , Σ 2 τ , → 2 , let Σ = Σ 1 out ∪ Σ 1 in ∪ Σ 1τ , we say that T 1 is simulable by T 2 and as receptive as T 2 , noted T 1 r T 2 , if there exists a relation R ⊆ S 1 × S 2 (called a simulation relation) such that:-(ι 1 , ι 2 ) ∈ R -for any (s 1 1 , s 2 1 ) ∈ R, we have that: • for any σ ∈ Σ ∪ R ≥0 , for any s 1 2 such that (s 1 1 , σ, s 1 2 ) ∈→ 1 , there exists s 2 2 ∈ S 2 such that (s 2 1 , σ, s 2 2 ) ∈→ 2 and (s 1 2 , s 2 2 ) ∈ R; • Ref T 1 (s 1 1 ) = Ref T 2 (s 2 1 ).
The notion of simulation we have defined can be used to define a notion of refinement.
We say that the STTS T 2 refines the STTS T 1 , if T 1 r T 2 .
The following theorem shows that our notion of refinement ensures that if a STTS T 1 is free of receptiveness problems when composed with a STTS T 2 , then we can conclude the same for any STTS T 3 that refines T 1 .
Theorem 1 Let T 1 and T 2 be two composable STTS, let T 3 be an STTS such that T 3 r T 1 , if T 1 T 2 is free of receptiveness problems then T 3 T 2 is free of receptiveness problems.We are now equipped to define the notion of safety control.
This notion together with the notion of refinement we have introduced above allow us to formalize in section 4 and 5, the notion of correct implementation of an embedded timed controller.Definition 7 [Safety Control] Let T 1 = S 1 , ι 1 , Σ 1 in , Σ 1 out , Σ 1 τ , → 1 and T 2 = S 2 , ι 2 , Σ 2 in , Σ 2 out , Σ 2 τ , → 2 be two composable STTS.
Let B ⊆ S 2, we say that T 1 controls T 2 to avoid B if the following two conditions hold:-T 1 T 2 is free of receptiveness problems; -Reach(T 1 T 2 ) ∩ {(s 1 , s 2 ) | s 1 ∈ S 1 ∧ s 2 ∈ B} is empty.We can now state a theorem linking our notion of refinement with the notion of safety control.Theorem 2 Let T 1 = S 1 , ι 1 , Σ 1 in , Σ 1 out , Σ 1 τ , → 1 and T 2 = S 2 , ι 2 , Σ 2 in , Σ 2 out , Σ 2 τ , → 2be two composable STTS, let T 3 be a STTS such that T 3 r T 1 , and let B ⊆ S 2 , if T 1 controls T 2 to avoid B then T 3 controls T 2 to avoid B.
The STTS of previous section are specified using the formalism of timed automata.
We recall their definition in this section.Let X be a finite set of real-valued variables.
A valuation for X is a function v : X → R ≥0 .
We write [Y → E] for the set of all valuations of set of variables Y to domain E. For a set V ⊆ [X → R ≥0 ] of valuations, and x ∈ X, define V (x) = {v(x) | v ∈ V }.
A rectangular constraint over X is a formula of the form "x ∈ I" where x belongs to X, and I is one of the intervals (a,b), [a, b), (a, b] or [a, b]where a, b ∈ Q ≥0 ∪ {+∞}, and a ≤ b. Q ≥0 denotes the positive rational numbers and, in the sequel, we also use Q >0 to denote the strictly positive rational numbers.
A rectangular predicate is a finite set of rectangular constraints.
For a rectangular predicate p and a valuation v, we write v |= p if v(x) ∈ I for all "x ∈ I" appearing in p. For a rectangular predicate p, [[p]] denotes the set {v | v |= p}.
We say that a rectangular predicate is in normal form if it contains at most one rectangular constraint for any variable "x ∈ X"; any rectangular predicate can be put in that normal form.
Let g be a rectangular predicate in normal form, then g(x) denotes the rectangular constraint x ∈ I if "x ∈ I" is the constraint over x in g and true if there is no constraint over x in g.
We note Rect(X) the set of rectangular predicates built using variables in X. Rect c (X) is the subset of rectangular predicates containing only closed rectangular constraints.
Let g(x) denote the closed rectangular constraints "x ∈ [a, b]", lb(g(x)) denotes the value a and rb(g(x)) denotes the value b. Let v :E 1 → E 2 be a valuation, let E 3 ⊆ E 1 , and c ∈ E 2 , then v[E 3 := c] denotes the valuation v such that v (e) = c if e ∈ E 3 v(e) if e ∈ E 3In the sequel, we sometimes write v[e := c] instead of v[{e} := c].
Let v : X → R ≥0 be a valuation, for any t ∈ R ≥0 , v − t is a valuation in [X → R] such that for any x ∈ X, (v − t)(x) = v(x) − t.
We define v + t in a similar way.
We extend this definition to valuation v in [X → R ≥0 ∪ {⊥}] as follows: (v + t)(x) = v(x) + t, if v(x) ∈ R ≥0 , and (v + t)(x) = ⊥ otherwise.
We are now equipped to define timed automata and their classical semantics.
For simplicity, we restrict ourselves in this paper to environments modeled as timed automata.
Nevertheless, all the results presented below hold if hte environment is modeled using any class of hybrid automata.Running example.
Consider Fig. 1.
The timed automaton of Fig. 1(b) models a simple environment (a plant): when a request A is received, the response B is emitted before y = 1, and then the event C is accepted but it should occur at least one half time unit after A was received.
Moreover, the event A must occur at least every α time units.
If it was not the case, the environment would enter the location Bad modeling a fatal error.
We will try to control the environment for α = 1 and α = 2.
The role of the controller is to produce an event A at least every α time units, to accept the subsequent event B and to output C respecting the timing constraint.
An example of such a controller is given in Fig. 1(a).
The designer has chosen here to react to the event B only after three quarter time unit.
Given this controller for the system, we must verify that it gives orders in such a way that any resulting behavior of the environment avoids to enter the bad state.
We must additionally verify that the controller is receptive to the event B from the environment (otherwise it could simply control the environment to avoid Bad by refusing to synchronize with B).
We must also verify that the environment is ready to receive the orders (A and C) when emitted by the controller.
The reader can check that, with the classical semantics of timed automata, the controller controls the environment such that the location Bad is not reachable for α = 1 and α = 2.
Later, we will see that if α = 1 then the controller is not implementable, on the other hand, if α = 2 then the controller can be implemented and control the environment to avoid Bad.As we already pointed out in the introduction, the classical semantics given in definition 9 is problematic for the controller part if our goal is to transfer the properties verified on the model to an implementation.
Below, we illustrate the properties of the classical semantics that makes it impossible to both implement the controller and ensure formally that the properties of the model are preserved.First, note that invariants (grayed constraints in Fig. 1(a)) are used to force the controller to take actions.
Invariants can be removed if we assume a ASAP semantics for the controller: any action is taken as soon as possible, this is also called the maximal progress assumption.
So the transition labeled with A!
proceeds exactly when z = 0, i.e. instantaneously.
Clearly, no hardware can guarantee that the transition will always proceed without any delay.
Second, synchronizations between the environment and the controller (e.g. transitions labeled B) cannot be implemented as instantaneous: some time is needed by the hardware to detect the incoming event B and for the software that implements the control strategy to take this event into account.
Third, the use of real-valued clocks is only possible in the model: implementations use digital clocks with finite precision.
It is then necessary to show that a digital clock can replace the real-valued clocks while preserving the verified safety properties.These three problems illustrates that even if we have formally verified our control strategy, we can not conclude that an implementation will conserve any of the properties that we have proven on the model.
This is unfortunate.
If we simplify, there are two options to get out of this situation: (i) we ask the designer to give up the synchrony hypothesis and ask the designer to model the platform on which the control strategy will be implemented, as in [IKL + 00], or (ii) we let the designer go on with the synchrony hypothesis at the modeling level but relax the ASAP semantics during the verification phase in order to formally validate the synchrony hypothesis.We think that the second option is much more appealing and we propose in the next section a framework that makes the second option possible theoretically but also feasible practically.
The framework we propose is centered on a relaxation of the ASAP semantics that we call the AASAP semantics.
The main characteristics of this semantics are summarized below:-any transition that can be taken by the controller becomes urgent only after a small delay ∆ (which may be left as a parameter); -a distinction is made between the occurrence of an event in the environment (sent) and in the controller (received), however the time difference between the two events is bounded by ∆; -guards are enlarged by some small amount depending on ∆.
We define formally this semantics in the next section and show in section 5 that it is robust in the sense that it defines a tube of strategies (instead of a unique strategy as in the ASAP semantics) which can be refined in a formal way into an implementation while preserving the safety properties imposed by this tube of strategies.
As explained in the previous section, invariants are useful when modeling controllers with the classical semantics in order to force the controller to take actions but they are useless with an ASAP semantics.
This is also true with the semantics we define in this section.
So, we restrict our attention to the subclass of timed automata without invariants.
In the rest of the paper, we call the controller specified by this subclass Elastic 1 controllers.
Elastic controller A is a tuple Loc, l 0 , Var, Lab, Edg where Loc is a finite set of locations, l 0 ∈ Loc is the initial location, Var = {x 1 , . . . , x n } is a finite set of clocks, Lab is a finite structured alphabet of labels, partitioned into input labels Lab in , output labels Lab out , and internal labels Lab τ , Edg is a set of edges of the form (l, l , σ, g, R) where l, l ∈ Loc are locations, σ ∈ Lab is a label, g ∈ Rect c (Var) is a guard and R ⊆ Var is a set of clocks to be reset.Before defining the AASAP semantics we need some more notations: TS(v, g) = t if v |= g ∧ v − t |= g ∧ ∀t > t : v − t |= g −∞ otherwise .
Definition 12 [Guard Enlargement] Let g(x) be the rectangular constraint "x ∈ [a, b]", the rectangular constraint ∆ g(x) ∆ with ∆ ∈ Q ≥0 is the formula "x ∈ [a − ∆, b + ∆]" if a − ∆ ≥ 0 and "x ∈ [0, b + ∆]" otherwise.If g is a closed rectangular predicate then ∆ g ∆ is the set of closed rectangular constraints{ ∆ g(x) ∆ | g(x) ∈ g}.
We are now ready to define the AASAP semantics.
Intuitions are given right after the definition.
∈ Loc, v ∈ [Var → R ≥0 ], I ∈ [Σ in → R ≥0 ∪ {⊥}] and d ∈ R ≥0 ; (A2) ι = (l 0 , v, I, 0)where v is such that for any x ∈ Var : v(x) = 0, and I is such that for any σ ∈ Σ in , I(σ) = ⊥; (A3) Σ in = Lab in , Σ out = Lab out , and Σ τ = Lab τ ∪ Lab in ∪ {}; (A4) The transition relation is defined as follows:• for the discrete transitions, we distinguish five cases: ∈→.
(A4.1) let σ ∈ Lab out .
We have ((l, v, I, d), σ, (l , v , I, 0)) ∈→ iff there exists (l, l , g, σ, R) ∈ Edg such that v |= ∆ g ∆ and v = v[R := 0] ; (A4.2) let σ ∈ Lab in .
We have ((l, v, I, d), σ, (l, v, I , d)) ∈→ iff I(σ) = ⊥ and I = I[σ := 0] ; (A4.3) let ¯ σ ∈ Lab in .
We have ((l, v, I, d), ¯ σ, (l , v , I , 0)) ∈→ iff there exists (l, l , g, σ, R) ∈ Edg, v |= ∆ g ∆ , I(σ) 񮽙 = ⊥, v =• for the continuous transitions: (A4.6) for any t ∈ R ≥0 , we have ((l, v, I, d), t, (l, v + t, I + t, d + t)) ∈→ iff the two following conditions are satisfied: · for any edge (l, l , g, σ, R) ∈ Edg with σ ∈ Lab out ∪ Lab τ , we have that: ∀t : 0 ≤ t ≤ t : (d + t ≤ ∆ ∨ TS(v + t , g) ≤ ∆) · for any edge (l, l , g, σ, R) ∈ Edg with σ ∈ Lab in , we have that:∀t : 0 ≤ t ≤ t : (d + t ≤ ∆ ∨ TS(v + t , g) ≤ ∆ ∨ (I + t )(σ) ≤ ∆)Comments on the AASAP semantics.
Rule (A1) defines the states that are tuples of the form l, v, I, d.
The first two components, location l and valuation v, are the same as in the classical semantics; I and d are new.
The function I records, for each input event σ, the time elapsed since its last occurrence if this occurrence has not been "treated" yet, otherwise the function returns the special value ⊥.
The time elapsed since the last location change in the controller is recorded by d. Rule (A2) and (A3) are straightforward.
Rules (A4.1 − 6) require more explanations.
Rule (A4.1) defines when it is allowed for the controller to emit an output event.
The only difference with the classical semantics is that we enlarge the guard by the parameter ∆.
Rules (A4.2 − 3) defines how inputs from the environment are received (A4.2) and treated (A4.3) by the controller.
First, the controller maintains, through the function I, a list of events that have occurred and are not yet treated.
An input event σ can be received by the controller if no occurrence of σ is already present.
An input event σ can be treated if I(σ) is different of ⊥.
Once treated, the value of I for that event goes back to ⊥.
Rule (A4.4) is similar to (A4.1).
Rule (A4.5) expresses that the event can always be emitted.
Rule (A4.6) specifies how much time can elapse.
Intuitively, time can pass as long as no transition starting from the current location is urgent.
A transition labeled with an output or an internal event is urgent in a location l when the control has been in l for more than ∆ time units (d + t > ∆) and the guard of the transition has been true for more than ∆ time units (TS(v + t , g) > ∆).
A transition labeled with an input event σ is urgent in a location l when the control has been in l for more than ∆ time units (d+t > ∆), the guard of the transition has been true for more that ∆ time units (TS(v + t , g) > ∆), the last occurrence of σ event has not been treated yet and has been emitted by the environment at least ∆ time units ago (I + t (σ) > ∆).
This notion of urgency parameterized by ∆ is the main difference between the AASAP semantics and the usual ASAP semantics.
We now state a first property of the AASAP semantics.
The following theorem and corollary state formally the informal statement "faster is better", that is if an environment is controllable with an Elastic controller reacting within the bound ∆ 1 then this environment is controllable by the same controller for any reaction time ∆ 2 ≤ ∆ 1 .
This is clearly a desirable property.Theorem 3 Let A be an Elastic controller, for any ∆ 1 , ∆ 2 ∈ Q ≥0 such that∆ 1 ≥ ∆ 2 we have that [[A]] AAsap ∆2 r [[A]] AAsap .
Theorem 2 and theorem 3 allow us to state the following corollary:Corollary 1 Let E be a timed automaton, [[E]] be an STTS with set of states S E , B ⊆ S E be a set of bad states, and A be an Elastic controller.
For any∆ 1 , ∆ 2 ∈ Q ≥0 , such that ∆ 1 ≥ ∆ 2 , if [[A]] AAsap ∆1 controls [[E]] to avoid B then [[A]] AAsap ∆2 controls [[E]] to avoid B.We say that an Elastic controller is able to control an environment modeled as a timed automaton E for a safety property modeled by a set of bad states B if there exists∆ > 0 such that [[A]] AAsap ∆ controls [[E]] to avoid B.
In this section, we show that any Elastic controller which controls an environment E for a safety property modeled by a set of bad states B can be implemented provided there exists a hardware sufficiently fast and providing sufficiently precise digital clocks.To establish this result, we proceed as follows.
First, we define what we call the program semantics of an Elastic controller.
The so-called program semantics can be seen as a formal semantics for the following procedure interpreting Elastic controllers.
This procedure repeatedly executes what we call execution rounds.
An execution round is defined as follows:-first, the current time is read in the clock register of the CPU and stored in a variable, say T; -the list of input events to treat is updated: the input sensors are checked for new events issued by the environment; -guards of the edges of the current locations are evaluated with the value stored in T.
If at least one guard evaluates to true then take nondeterministically one of the enabled transitions; -the next round is started.All we require from the hardware is to respect the following two requirements: (i) the clock register of the CPU is incremented every ∆ P time units and (ii) the time spent in one loop is bounded by a certain fixed value ∆ L .
We choose this semantics for its simplicity and also because it is obviously implementable.
There are more efficient ways to interpret Elastic controllers but as the AASAP semantics is such that "faster is better", this semantics is good enough for our purpose.
In section 6, we show how to use this semantics in the context of the Lego Mindstorms TM platform.We proceed now with the definition of the program semantics.
This semantics manipulates digital clocks, so we need the following definition:Definition 14 [Clock Rounding] Let T ∈ R, ∆ ∈ Q >0 , T ∆ = T ∆ ∆.
We are now ready to define the program semantics.
Intuitions are given right after the definition.Definition 15 [Program Semantics] Let A be an Elastic controller and ∆ L , ∆ P ∈ Q >0 .
We define ∆ S = ∆ L + 2∆ P .
The (∆ L , ∆ P ) program semantics of A, noted [[A]]Prg ∆L,∆P is the structured timed transition system T = S, ι, Σ in , Σ out , Σ τ , → where: (P 1) S is the set of tuples (l, r, T, I, u, d, f ) such that l ∈ Loc, r is a function from Var into R ≥0 , T ∈ R ≥0 , I is a function from Lab in into R ≥0 ∪ {⊥}, u ∈ R ≥0 , d ∈ R ≥0 , and f ∈ {, ⊥}; (P 2) ι = (l 0 , r, 0, I, 0, 0, ⊥) where r is such that for any x ∈ Var, r(x) = 0, I is such that for any σ ∈ Lab in , I(σ) = ⊥;(P 3) Σ in = Lab in , Σ out = Lab out , Σ τ = Lab τ ∪ Lab in ∪ {};(P 4) the transition relation → is defined as follows:• for the discrete transitions: ( · for any ¯ σ such that σ ∈ Lab in , for any (l, l , g, σ, R) ∈ Edg, we have that either T ∆P − r |= ∆S g ∆S or I(σ) ≤ u · for any σ ∈ Lab out ∪ Lab τ , for any (l, l , g, σ, R) ∈ Edg, we have that T ∆P − r |= ∆S g ∆S • for the continuous transitions:(P 4.6) ((l, r, T, I, u, d, f ), t, (l, r, T, I + t, u + t, d + t, f )) ∈→ iff u + t ≤ ∆ L .
Comments on the program semantics.
Rule (P 1) defines the states which are tuples (l, r, T, I, u, d, f ), where l is the current location, r maps each clock to the digital time when it has last been reset, T records the (exact) time at which the last round has started; I, as in the AASAP semantics, records the time elapsed since the last arrival of each input event not yet treated, u records the time elapsed since the last round was started (so that T + u is the exact current time), d records the time elapsed since the last location change, and f is a flag which is set to if a location change has occurred in the current round.
Rules (P 2) and (P 3) should be clear.
We comment rules (P 4.1 − 6).
First, we make some general comments on digital clocks and guards of discrete transitions of the controller.
Note that in those rules, we evaluate the guards with the valuation T ∆P −r for the clocks, that is, for variable x, the difference between the digital value of the variable T at the beginning of the current round and the digital value of x at the beginning of the round when x was last reset.
This value approximates the real time difference between the exact time at which the guard is evaluated and the exact time at which the clock x has been reset.
Let t be this exact time difference, then we know that:T ∆P − r(x) − ∆ L − ∆ P ≤ t ≤ T ∆P − r(x) + ∆ L + ∆ P .
Also note that the guard g has been enlarged by the value ∆ S = ∆ L + 2∆ P , this ensures that any event enabled at some point will be enabled sufficiently long so that the change can be detected by the procedure.
Rule (P 4.1) expresses when transitions labeled with output events can be taken.
Note that variables are reset to the digital time of the current round.
Rule (P 4.2) simply records the exact time at which input event from the environment occurred.
This rule simply ensures that the function I is updated when a new event is issued by the environment.
Rule (P 4.3) says when an input of the environment can be treated by the controller: it has to be present at the beginning of the current round and the enlargement of the guard labelling the transition has to be true for digital values of the clocks at the beginning of the round, and no other discrete transitions should have been taken in the current round.
Rule (P 4.4) is similar to rule (P 4.1) but applies to internal events.
Rule (P 4.5) expresses that the event is issued when the current round is finished and the system starts a new round.
Note that this is only possible if the program has taken a discrete transition or there were no discrete transition to take.
This ensures that the program always takes discrete transitions when possible.
Rule (P 4.6) expresses that the program can always let time elapse unless it violates the maximal time spent in one round.The following simulation theorem expresses formally that if the hardware on which the program is implemented is fast enough (parameter ∆ L ) and precise enough (parameter ∆ P ) then the program semantics can be simulated by the AASAP semantics.
And so, given a sufficiently fast hardware with a sufficiently precise digital clock, we can implement any controller that have been proved correct.
This is expressed by the following corollary:Corollary 2 (Implementability) Let E be a timed automaton , let [[E]] be a STTS with set of states S E , B ⊆ S E be a set of bad states.
In this section, we show that the AASAP semantics can be analyzed automatically using the tool HyTech [HHWT95].
This is a direct corollary of the next theorem: for any ∆ ∈ Q ≥0 , for any Elastic controller A, the AASAP semantics of A can be encoded using the classical semantics of a timed automaton A ∆ constructed from A and ∆.
Corollary 3 For any Elastic controller A, for any ∆ ∈ Q >0 , for any timed automaton E with state space S E , for any set of states B ⊆ S E , we have that[[A]] AAsap ∆ controls [[E]] to avoid B iff [[F (A, ∆)]] controls [[E]] to avoid B.In practice, we use theorem 6 to reduce the controllability problem to a reachability problem:-we construct F (A, ∆) (where we can leave ∆ as a parameter);-we construct a HyTech file with a description of F (A, ∆) and E; -we ask for which parameter value reach( [[F (A, ∆)]] [[E]]) ∩ Bad = ∅ (whereBad is a set of bad states) and the system is free of receptiveness problems.If we apply the construction of theorem 6 to our running example (Fig. 1), we can ask HyTech to establish for which value of ∆, the tube of control strategies defined by the timed automaton obtained by the construction of theorem 6 is valid.In the case α = 1, the result is ∆ = 0.
We can interpret this as follows: we have a correct model w.r.t to the classical ASAP semantics but it is nevertheless not guaranteed to be correct when implemented on a real hardware.
In fact, the condition ∆ = 0 means that some transitions in the controller are required to be taken instantaneously, which is impossible in the real world.
It must be admitted that the synchrony hypothesis was not realistic in that case.
The second case (α = 2) is more useful: the model is correct for any ∆ ≤ 1 4 .
If we assume that the unit of time is the second, theorem 4 then tells us that, to preserve the desired property with a systematic implementation of the Elastic controller, we should have a platform with loop time ∆ L and clock precision ∆ P such that 3∆ L + 4∆ P < 250ms.
For instance, we can implement the controller on the Lego Mindstorms TM platform, since it allows ∆ L to be as low as 6ms and offers a digital clock with ∆ P = 1ms which is thus ample enough.
