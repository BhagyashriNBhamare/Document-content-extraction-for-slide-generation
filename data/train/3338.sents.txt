We have recently witnessed the emergence of RF-based indoor localization systems that can track user motion without requiring the user to hold or wear any device.
These systems can localize a user and track his gestures by relying solely on the reflections of wireless signals off his body, and work even if the user is behind a wall or obstruction.
However, in order for these systems to become practical, they need to address two main challenges: 1) They need to be able to operate in the presence of more than one user in the environment, and 2) they must be able to localize a user without requiring him to move or change his position.
This paper presents WiTrack2.0, a multi-person local-ization system that operates in multipath-rich indoor environments and pinpoints users' locations based purely on the reflections of wireless signals off their bodies.
WiTrack2.0 can even localize static users, and does so by sensing the minute movements due to their breathing.
We built a prototype of WiTrack2.0 and evaluated it in a standard office building.
Our results show that it can localize up to five people simultaneously with a median accuracy of 11.7 cm in each of the x/y dimensions.
Furthermore, WiTrack2.0 provides coarse tracking of body parts, identifying the direction of a pointing hand with a median error of 12.5 • , for multiple users in the environment.
Over the past decade, the networking community has made major advances in RF-based indoor localization [5,34,21,26,38,17,21,11,22], which led to systems that can localize a wireless device with centimeter-scale accuracy.
Recently however the research community has realized that it is possible to localize a user, without requiring him to wear or carry a wireless device [25,3].
Such a leap from device-based to device-free indoor localization can enable ubiquitous tracking of people and their gestures.
For example, it can enable a smart home to continuously localize its occupants and adjust the heating in each room according to the number of people in it.
It would also enable a smart home to track our hand gestures so that we may control appliances by pointing at them, or turn the TV with a wave of our arm.
Device-free tracking can also be leveraged in many applications where it is either inconvenient or infeasible for the user to hold/wear a device such as in gaming and virtual reality, elderly monitoring, intrusion detection, and search and rescue missions [3].
Past work has taken initial steps towards this vision [3,18,7].
However, these proposals have fundamental limitations that render them impractical for natural home environments.
Specifically, they either require covering the entire space with a dense, surveyed grid of sensors [18,7] or they fail in the presence of multiple users in the environment [3].
Additionally, these past proposals are also limited in their ability to detect the presence of users.
In particular, they either require the user to continuously move to detect his presence [3], or they need to perform extensive prior calibration or training [18,7].
In this paper, we introduce WiTrack2.0, a device free localization system that transcends these limitations.
Specifically, WiTrack2.0 accurately localizes multiple users in the environment.
It does so by disentangling the reflections of wireless signals that bounce off their bodies.
Furthermore, it neither requires prior calibration nor that the users move in order to localize them.To achieve its goal, WiTrack2.0 has to deal with multiple challenges.
As with traditional device-based localization, the most difficult challenge in indoor environments is the multipath effect [34,17].
Specifically, wireless signals reflect off all objects in the environment making it hard to associate the incoming signal with a particular location.
To overcome this challenge, past work [3] focuses on motion to capture signal reflections that change with time.
It then assumes that only one person is present in the environment, and hence all motion can be attributed to him.
However, if multiple people move in the environment or if the person is static, then this assumption no longer works.To address this challenge, we observe that the indoor multipath varies significantly when it is measured from different vantage points.
Hence, one can address this problem by positioning multiple transmit and receive antennas in the environment, and measuring the time of flight from each of these transmit-receive antenna pairs.
However, the signals emitted from the different transmitters will reflect off the bodies of the all the users in the environment, and these reflections interfere with each other leading to wireless collisions.
In §5, we show how WiTrack2.0 disentangles these interfering reflected signals to localize multiple users in the presence of heavy indoor multipath.A second challenge that WiTrack2.0 has to address is related to the near-far problem.
Specifically, reflections off the nearest person can have much more power than distant reflections, obfuscating the signal from distant people, and preventing their detection or tracking.To address this issue, we introduce Successive Silhou-ette Cancellation (SSC) an approach to address the nearfar problem, which is inspired by successive interference cancellation.
This technique starts by localizing the closest person, then eliminates his impact on the received signal, before proceeding to localize further users (who have weaker reflections).
It repeats this process iteratively until it has localized all the users in a scene.
Note, however, that each user is not a point reflector; hence, his wireless reflection has a complex structure that must be taken into account, as we describe in §6.
A third challenge that our system addresses is related to localizing static users.
Specifically, past work that tracks human motion needs to eliminate reflections off static objects by subtracting consecutive measurements.
However, this subtraction also results in eliminating the reflections off static users.
To enable us to localize static users, we exploit the fact these users still move slightly due to their breathing.
However, the breathing motion is fairly slow in comparison to body motion.
Specifically, the chest moves by a sub-centimeter distance over a period of few seconds; in contrast, a human would pace indoors at 1 m/s.
Hence, WiTrack2.0 processes the reflected signals at multiple time scales that enable it to accurately localize both types of movements as we describe in §7,We have built a prototype of WiTrack2.0, using USRP software radios and an analog FMCW radio.
We run experiments both in line-of-sight (LOS) scenarios and nonline-of-sight (NLOS) scenarios, where the device is in a different room and is tracking people's motion through the wall.
Empirical results from over 300 experiments with 11 human subjects show the following:• Motion Tracking: WiTrack2.0 accurately tracks the motion of up to four users simultaneously, without requiring the users to hold or wear any wireless device.
In an area that spans 5 m × 7 m, its median error across all users is 12.1cm in the x/y dimensions.
• Localizing Static People: By leveraging their breathing motion, WiTrack2.0 accurately localizes up to five static people in the environment.
Its median error is 11.2 cm in the x/y dimensions across all the users in the scene.
• Tracking Hand Movements: WiTrack2.0's localization capability extends beyond tracking a user's body to tracking body parts.
We leverage this capability to recognize concurrent gestures performed in 3D space by multiple users.
In particular, we consider a gesture in which three users point in different directions at the same time.
Our WiTrack2.0 prototype detects the pointing directions of all three users with a median accuracy of 10.3 • .
Contributions: This paper demonstrates the first devicefree RF-localization system that can accurately localize multiple people to centimeter-scale in indoor multipathrich environments.
This is enabled by a novel transmission protocol and signal processing algorithms which allow isolating and localizing different users in the environment.
The paper also presents an evaluation of the system, showing that it can localize moving and static users in line-of-sight and through-wall settings with a median accuracy of 7-18 cm across all of these scenarios.
Indoor Localization.
WiTrack2.0 builds on a rich networking literature on indoor localization [5,34,21,26,38,17,21,11,22] which has focused on localizing wireless devices.
In comparison to all of these works, however, WiTrack2.0 focuses on localizing users by relying purely on the reflections of RF signals off their bodies.
WiTrack2.0 is also related to proposals for device-free localization, which deploy a sensor network and measure the signal strength between different nodes to localize users [36,40].
However, in comparison to these past proposals, WiTrack2.0 neither requires deploying a network of dozens to hundreds of sensors [36,18] nor does it require extensive calibration [25,24,40].
Furthermore, because it relies on time-of-flight measurements, it can achieve a localization accuracy that is 10× higher than state-of-the-art RSSI-based systems [25,24,18,7,19].
WiTrack2.0's design builds on our prior work, WiTrack [3], which also used time of flight (TOF) measurements to achieve high localization accuracy, and which did not require prior environmental calibration.
In comparison to WiTrack, which could localize only a single person and only if that person is moving, WiTrack2.0 can localize up to five users simultaneously, even if they are perfectly static (by relying on their breathing motion).
WiTrack2.0 is also related to non-localization systems that employ RF reflections off the human body [4,20,33,35].
These systems can detect the presence of people or identify a handful of gestures or activities.
However, unlike WiTrack2.0, they have no mechanism for obtaining the location of a person.
Radar Systems.
WiTrack2.0 builds on past radar literature.
In particular, it uses the FMCW (Frequency Modulated Carrier Waves) technique to obtain accurate timeof-flight measurements [15,23,31,9].
However, its usage of FMCW has a key property that differentiates it from all prior designs: it transmits from multiple antennas concurrently while still allowing its receivers to isolate the reflections from each of the Tx antennas.More importantly, none of the past work on radar addresses the issue of indoor multipath.
Specifically, past work on see-through-wall radar has been tailored for usage in strictly military settings.
Hence, it mostly operates in an open field with an erected wall [23,10], or it focuses on detecting metallic objects which have significantly higher reflection coefficients than furniture, walls, or the human body [13,28,27].
Work tested on human subjects in indoor environments has focused on detecting the presence of humans rather than on accurately localizing them [16,39] shows how a TOF measurement maps to a round-trip distance, which may correspond to any location on an ellipse whose foci are Tx and Rx.
that multipath leads to the well-known "ghosting effect", but ignore these effects since they do not prevent detecting the presence of a human.
In comparison to the above work, WiTrack2.0 focuses on accurate localization of humans in daily indoor settings, and hence introduces two new techniques that enable it to address the heavy multipath in standard indoor environments: multi-shift FMCW, and successive silhouette cancellation.
Iterative Cancellation Frameworks.
The framework of iteratively identifying and canceling out the strongest components of a signal is widely used in many domains.
Naturally, however, the details of how the highest power component is identified and is eliminated varies from one application to another.
In the communications community, we refer to such techniques as successive interference cancellation, and they have been used in a large number of applications such as ZigZag [12], VBLAST [37], and full duplex [6].
In the radio astronomy community, these techniques are referred to as CLEAN algorithms and, similarly, have a large number of instantiations [14,29,30].
Our work on successive silhouette cancellation also falls under this framework and is inspired by these algorithms.
However, in comparison to all the past work, it focuses on identifying the reflections of the humans in the environment and canceling them by taking into account the different vantage points from which the time-of-flight is measured as well as the fact that the human body is not a point reflector.
This section provides necessary background regarding single-person motion tracking via RF body reflections.The process of localizing a user based on radio reflections off her body has three steps: 1) obtaining time-offlight (TOF) measurements to various reflectors in the environment; 2) eliminating TOF measurements due to reflections of static objects like walls and furniture; and 3) mapping the user's TOFs to a location.Step 1: Obtaining TOF measurements to various reflectors in the environment.
A typical way for measuring the time-of-flight (TOF) is to use a FrequencyModulated Carrier Waves (FMCW) radio.
An FMCW transmitter sends a narrowband signal (e.g., a few KHz) but makes the carrier frequency sweep linearly in time, as illustrated by the solid green line in Fig. 1(a).
The reflected signal is a delayed version of the transmitted signal, which arrives after bouncing off a reflector, as shown by the dotted green line in Fig. 1(a).
Because time and frequency are linearly related in FMCW, the delay between the two signals maps to a frequency shift Δf between them.
Hence, the time-of-flight can be measured as the difference in frequency Δf divided by the slope of the sweep in Fig. 1(a):TOF = Δf /slope(1)This description generalizes to an environment with multiple reflectors.
Because wireless reflections add up linearly over the medium, the received signal is a linear combination of multiple reflections, each of them shifted by some Δf that corresponds to its TOF.
Hence, one can extract all these TOFs by taking an FFT of the received signal.
The output of the FFT gives us the TOF profile which we define as the reflected power we obtain at each possible TOF between the transmit antenna and receive antenna, as shown in Fig. 1(b).
1 Step 2: Eliminating TOFs of static reflectors.
To localize a human, we need to identify his/her reflections from those of other objects in the environment (e.g., walls and furniture).
This may be done by leveraging the fact that the reflections of static objects remain constant over time.
Hence, one can eliminate the power from static reflectors by performing background subtraction -i.e., by subtracting the output of the TOF profile in a given sweep from the TOF profile of the signal in the previous sweep.
Fig. 1(b) and 1(c) show how background subtraction eliminates the power in static TOFs from the TOF profile, and allows one to notice the weak power resulting from a moving person.Step 3: Mapping TOFs to distances.
Recall that the TOF corresponds to the time it takes the signal to travel from the transmitter to a reflector and back to the receiver.
Hence, we can compute the corresponding round-trip distance by multiplying this TOF by the speed of light C: Knowing the round trip distance localizes the person to an ellipse whose foci are the transmit and receive antennas.round trip distance = C × TOF = C × Δf slope (2) (a) Antenna (b) Antenna Setup WiTrack2.0 is a wireless system that can achieve highly accurate localization of multiple users in multipath-rich indoor environments, by relying purely on the reflections of wireless signals off the users' bodies.
For static users, it localizes them based on their breathing, and can also localize the hand motions of multiple people, enabling a multi-user gesture-based interface.WiTrack2.0 is a multi-antenna system consisting of five transmit antennas and five receive antennas, as shown in Fig. 2.
The antennas are directional, stacked in a single plane, and mounted on a foldable platform as shown in Fig. 2(b).
This arrangement is chosen because it enables see-through-wall applications, whereby all the antennas need to be lined up in a plane facing the wall of interest.WiTrack2.0 operates by transmitting RF signals and capturing their reflections after they bounce off different users in the environment.
Algorithmically, WiTrack2.0 has two main components: 1) Multi-shift FMCW, a technique that enables it to deal with multipath effects, and (2) Successive Silhouette Cancellation (SSC), an algorithm that allows WiTrack2.0 to overcome the near-far problem.
The following sections describe these components.
Multipath is the first challenge in accurate indoor localization.
Specifically, not all reflections that survive background subtraction correspond to a moving person.
This is because the signal reflected off the human body may also reflect off other objects in the environment before arriving at the receive antenna.
As this person moves, this multipath reflection also moves with him and survives the background subtraction step.
In single-user localization, one may eliminate this type of multipath by leveraging that these secondary reflections travel along a longer path before they arrive at the receive antenna.
Specifically, by electing the smallest TOF after background subtraction, one may identify the round-trip distance to the user.However, the above invariant does not hold in multiperson localization since different users are at different distances with respect to the antennas, and the multipath of a nearby user may arrive earlier than that of a more distant user, or even interfere with it.
In this section, we explore this challenge in more details, and show how we can overcome it by obtaining time-of-flight measurements from different vantage points in the environment.
To explore the above challenge in practice, we run an experiment with two users in a 5 × 7 m furnished room (with tables, chairs, etc.) in a standard office building.
We study what happens as we successively overlay ellipses from different transmit-receive pairs.
Recall from §3 that each transmit-receive antenna pair provides us with a TOF profile -i.e., it tells us how much reflected power we obtain at each possible TOF between the transmit antenna and receive antenna (see Fig. 1(c)) -and that each such TOF corresponds to an ellipse in 2D (as in Fig. 1(d)).
Now let us map all TOFs in a TOF profile to the corresponding round trip distances using Eq.
2, and hence the resulting ellipses.
This process produces a heatmap like the one in Fig. 3(a), where the x and y axes correspond to the plane of motion.
For each ellipse in the heatmap, the color in the image reflects the amount of received power at the corresponding TOF.
Hence, the ellipse in red corresponds to a strong reflector in the environment.
The orange, yellow, and green ellipses correspond to weaker reflections respectively; these reflections could either be due to another person, multi-path reflections of the first person, or noise.
The blue regions in the background correspond to the absence of reflections from those areas.Note that the heatmap shows a pattern of half-ellipses; the foci of these ellipses are the transmit and receive antennas, both of which are placed along the y = 0 axis.
The reason we only show the upper half of the ellipses is that we are using directional antennas and we focus them towards the positive y direction.
Hence, we know that we do not receive reflections from behind the antennas.
Fig. 3(a) shows the ellipses corresponding to the TOF profiles from one Tx-Rx pair.
Now, let us see what happens when we superimpose the heatmaps obtained from two Tx-Rx pairs.
Fig. 3(b) shows the heatmap we obtain when we overlay the ellipses of the first transmit-receive pair with those from a second pair.
We can now see two patterns of ellipses in the figure, the first pattern resulting from the TOFs of the first pair, and the second pattern due to the TOFs of the second pair.
These ellipses intersect in multiple locations, resulting in red or orange regions, which suggest a higher probability for a reflector to be in those regions.
Recall that there are two people in this experiment.
However, Fig. 3(b) is not enough to identify the locations of these two people.
antennas averages out to result in a dark blue background.
This is because different Tx-Rx pairs have different perspectives of the indoor environment; hence, they do not observe the same noise or multi-path reflections.
As a result, the more we overlay heatmaps from different Tx-Rx pairs, the dimmer the multipath effect, and the clearer the candidate locations for the two people in the environment.Next, we overlay the ellipses from five transmit-receive pairs and show the resulting heatmap in Fig. 3(e).
We can now clearly see two bright spots in the heatmap: one is red and the other is orange, whereas the rest of the heatmap is mostly a navy blue background indicating the absence of reflectors.
Hence, in this experiment, we are able to localize the two users using TOF measurements from five Tx-Rx pairs.
Combining these measurements together allowed us to eliminate the multipath effects and localize the two people passively using their reflections.
Summary: As the number of users increases, we need TOF measurements from a larger number of Tx-Rx pairs to localize them, and extract their reflections from multipath.
For the case of two users, we have seen a scenario whereby the TOFs of five Tx-Rx pairs were sufficient to accurately localize both of them.
In general, the exact number would depend on multipath and noise in the environment as well as on the number of users we wish to localize.
These observations motivate a mechanism that can provide us with a large number of Tx-Rx pairs while scaling with the number of users in the environment.
In the previous section, we showed that we can localize two people by overlaying many heatmaps obtained from mapping the TOF profiles of multiple Tx-Rx pairs to the corresponding ellipses.
But how do we obtain TOFs from many Tx-Rx pairs?
One option is to use one FMCW transmitter and a large number of receivers.
In this case, to obtain N Tx-Rx pairs, we would need one transmitter and N receivers.
The problem with this approach is that it needs a large number of receivers, and hence does not scale well as we add more users to the environment.A more appealing option is to use multiple FMCW transmit and receive antennas.
Since the signal transmitted from each transmit antenna is received by all receive antennas, this allows us to obtain N Tx-Rx pairs using only √ N transmit antennas and √ N receive antennas.
Figure 4-Multi-shift FMCW.
WiTrack2.0 transmits FMCW signals from different transmit antennas after inserting virtual delays between them.
Each delay must be larger than the highest time-of-flight (TOF limit ) due to objects in the environment.However, the problem with this approach is that the signals from the different FMCW transmitters will interfere with each other over the wireless medium, and this interference will lead to localization errors.
To see why this is true, consider a simple example where we want to localize a user, and we have two transmit antennas, Tx1 and Tx2, and one receive antenna Rx.
The receive antenna will receive two reflections -one due to the signal transmitted from Tx1, and another due to Tx2's signal.
Hence, its TOF profile will contain two spikes referring to two time-of-flight measurements TOF 1 and TOF 2 .
With two TOFs, we should be able to localize a single user based on the intersection of the resulting ellipses.
However, the receiver has no idea which TOF corresponds to the reflection of the FMWC signal generated from Tx1 and which corresponds to the reflection of the FMCW signal generated by Tx2.
Not knowing the correct Tx means that we do not know the foci of the two ellipses and hence cannot localize.
For example, if we incorrectly associate TOF 1 with Tx2 and TOF 2 with Tx1, we will generate a wrong set of ellipses, and localize the person to an incorrect location.
Further, this problem becomes more complicated as we add more transmit antennas to the system.
Therefore, to localize the user, WiTrack2.0 needs a mechanism to associate these TOF measurements with their corresponding transmit antennas.We address this challenge by leveraging the structure of the FMCW signal.
Recall that FMCW consists of a continuous linear frequency sweep as shown by the green line in Fig. 4.
When the FMCW signal hits a body, it reflects back with a delay that corresponds to the body's TOF.
Now, let us say TOF limit is the maximum TOF that we expect in the typical indoor environment where WiTrack2.0 operates.
We can delay the FMCW signal from the second transmitter by τ > TOF limit so that all TOFs from the second transmitter are shifted by τ with respect to those from the first transmitter, as shown by the red line in Fig. 4.
Thus, we can prevent the various FMCW signals from interfering by ensuring that each transmitted FMCW signal is time shifted with respect to the others, and those shifts are significantly larger than the time-of-flight to objects in the environment.
We refer to this design as Multi-shift FMCW.As a result, the receiver would still compute two TOF measurements: the first measurement (from Tx1) would be TOF 1 , and the second measurement (from Tx2) would be TOF 񮽙 2 = TOF 2 + τ .
Knowing that the TOF measurements from Tx2 will always be larger than τ , WiTrack2.0 determines that TOF 1 is due to the signal transmitted by Tx1, and TOF 񮽙 2 is due to the signal transmitted by Tx2.
This idea can be extended to more than two Tx antennas, as shown in Fig. 5.
Specifically, we can transmit the FMCW signal directly over the air from Tx1, then shift it by τ and transmit it from Tx2, then shift it by 2τ and transmit it from Tx3, and so on.
At the receive side, all TOFs between 0 and τ are mapped to Tx1, whereas distances between τ and 2τ are mapped to Tx2, and so on.
Summary: Multi-shift FMCW has two components: the first component allows us to obtain TOF measurements from a large number of Tx-Rx pairs; the second component operates on the TOFs obtained from these different Tx-Rx pairs by superimposing them into a 2D heatmap, which allows us to localize multiple users in the scene.
With multi-shift FMCW, we obtain TOF profiles from a large number of Tx-Rx pairs, map them to 2D heatmaps, overlay the heatmaps, and start identifying users' locations.
However, in practice this is not sufficient because different users will exhibit the near-far problem.
Specifically, reflections of a nearby user are much stronger than reflections of a faraway user or one behind an obstruction.
.
Iteration: re-computes the heatmaps using the TOF profiles after cancellation, overlays them, and proceeds to find the next strongest reflector.
We now describe each of these steps in detail by walking through the example with four persons shown in Fig. 6.
SSC Detection.
In the first step, SSC finds the location of the highest power reflector in the 2D heatmap of Fig. 6(a).
In this example, the highest power is at (0.5, 2), indicating that there is a person in that location.
SSC Re-mapping.
Given the (x, y) coordinates of the person, we map his location back to the corresponding TOF at each transmit-receive pair.
Keep in mind that each person is not a point reflector; hence, we need to estimate the spread of reflections off his entire body on the TOF profile of each transmit-receive pair.To see how we can do this, let us look at the illustration in Fig. 7 to understand the effect of a person's body on one transmit-receive pair.
The signal transmitted from the transmit antenna will reflect off different points on the person's body before arriving at the receive antenna.
Thus, the person's reflections will appear between some TOF min and TOF max in the TOF profile at the Rx antenna.Note that TOF min and TOF max are bounded by the closest and furthest points respectively on a person's body from the transmit-receive antenna pair.
Let us first focus on how we can obtain TOF min .
By definition, the closest point on the person's body is the one that corresponds to the shortest round-trip distance to the Tx-Rx pair, where the round-trip distance is the summation of the forward path from Tx to that point and the path from that point back to Rx.
Formally, for a Tx antenna at (x t , 0, z t ), an Rx antenna at (x r , 0, z r ), 2 we can compute d min as:min z 񮽙 (xt − x) 2 + y 2 + (zt − z) 2 + 񮽙 (xr − x) 2 + y 2 + (zr − z) 2(3)where (x, y, z) is any reflection point on the user's body.
One can show that this expression is minimized when:z − zt z − zr = − 񮽙 (xt − x) 2 + y 2 (xr − x) 2 + y 2(4)Hence, using the detected (x, y) position, we can solve for z then substitute in Eq.
3 to obtain d min .
Similarly, TOF max is bounded by the round-trip distance to point on the person's body that is furthest from the Tx-Rx pair.
Again, the x and y coordinates of the furthest point are determined by the person's location from the SSC Detection step.
However, we still need to figure out the z coordinate of this point.
Since the transmitter and receiver are both raised above the ground (at around 1.2 meters above the ground), the furthest point from the Tx-Rx pair is typically at the person's feet.
Therefore, we know that the coordinates of this point are (x, y, 0), and hence we can compute d max as:dmax = 񮽙 (xt − x) 2 + (y) 2 + z 2 t + 񮽙 (xr − x) 2 + (y) 2 + z 2 r .
Finally, we can map d min and d max to TOF min and TOF max by dividing them by the speed of light C. SSC Cancellation.
The next step is to use TOF min and TOF max to cancel the person's reflections from the TOF profiles of each transmit-receive pair.
To do that, we take a conservative approach and remove the power in all TOFs between TOF min and TOF max within that profile.
Of course, this means that we might also be partially canceling out the reflections of another person who happens to have a similar time of flight to this Tx-Rx pair.
However, we rely on the fact that multi-shift FMCW provides a large number of TOF profiles from many Tx-Rx pairs.
Hence, even if we cancel out the power in the TOF of a person with respect to a particular Tx-Rx pair, each person will continue to have a sufficient number of TOF measurements from the rest of the antennas.We repeat the process of computing TOF min and TOF max with respect of each Tx-Rx pair and cancelling the power in that range, until we have eliminated any power from the recently localized person.
Iteration.
We proceed to localize the next person.
This is done by regenerating the heatmaps from the updated TOF profiles and overlaying them.
Fig. 6(b) shows the obtained image after performing this procedure for the first person.
Now, a person at (−0.5, 1.3) becomes the strongest reflector in the scene.We repeat the same procedure for this user, canceling out his interference, then reconstructing a 2D heatmap in Fig. 6(c) using the remaining TOF measurements.
Now, the person with the strongest reflection is at (0.8, 2.7).
Note that this heatmap is noisier than Figs. 6(a) and 6(b) because now we are dealing with a more distant person.WiTrack2.0 repeats the same cancellation procedure for the third person and constructs the 2D heatmap in Fig. 6(d).
The figure shows a strong reflection at (1, 4).
which means that this is indeed the furthest person in the scene.
Also note that the heatmap is now even noisier.
This is expected because the furthest person's reflections are much weaker.
WiTrack2.0 repeats interference cancellation for the fourth person, and determines that the SNR of the maximum reflector in the resulting heatmap does not pass a threshold test.
Hence, it determines that there are only four people in the scene.We note that each of these heatmaps are scaled so that the highest power is always in red and the lowest power is in navy blue; this change in scale emphasizes the location of the strongest reflectors and allows us to better visualize their locations.
To gain more insight into the power values and to better understand how SSC improves our detection of further away users, Fig. 8 plots the Signal to Interference and Noise Ratio (SINR) of the fourth person during each iteration of SSC.
The fourth user's SINR initially starts at -21dB and is not visible in Fig. 6(a).
Once the first and second users are removed by SSC, the SINR increases to -7dB and we can start detecting the user's presence in the back of Fig. 6(c).
Performing another iteration raises the fourth person's SINR above the noise floor to 7dB.
It also brings it above our threshold of 6dB -i.e., twice the noise floor -making him detectable.We perform four additional steps to improve SSC: • Refocusing Step: After obtaining the initial estimates of the locations of all four persons, WiTrack2.0 performs a focusing step for each user to refine his location estimate.
This is done by reconstructing an interference-free 2D heatmap only using the range in the TOF profiles that corresponds to TOFs between TOF min and TOF max for that Tx-Rx pair.
Figs. 6(e)-6(h) show the images obtained from this focusing step.
In these images, the location of each person is much clearer, 3 which enables higher-accuracy localization.
• Leveraging Motion Continuity: After obtaining the estimates from SSC, WiTrack2.0 applies a Kalman filter and performs outlier rejection to reject impractical jumps in location estimates that would otherwise correspond to abnormal human motion over a very short period of time.
• Disentangling Crossing Paths: To disentangle multiple people who cross paths, we look at their direction of motion before they crossed paths and project how they would proceed with the same speed and direction as they are crossing paths.
This helps us with associating each person with his own trajectory after crossing.
Fig. 9 shows an example with two people crossing paths and how we were able to track their trajectories despite that.
Of course, this approach does not generalize to every single case, which may lead to some association errors after the crossings but not to localization errors.
• Extending SSC to 3D Gesture Recognition: Similar to past work [3], WiTrack2.0 can differentiate a hand motion from a whole-body motion (like walking) by leveraging the fact that a person's hand has a much smaller reflective surface than his entire body.
Unlike past work, however, WiTrack2.0 can track gestures even when they are simultaneously performed by multiple users.
Specifically, by exploiting SSC focusing, it zooms onto each user individually to track his gestures.
In our evaluation, we focus on testing a pointing gesture, where different users point in different directions at the same time.By tracking the trajectory of each moving hand, we can determine its pointing direction.
Note that we perform these pointing gestures in 3D and track hand motion by using the TOFs from the different Tx-Rx pairs to construct a 3D point cloud rather than a 2D heatmap.
4 The results in §10.3 show that we can accurately track hand gestures performed by multiple users in 3D space.
We extend WiTrack2.0's SSC algorithm to localize static people based on their breathing.
Recall from §3 that in order to track a user based on her radio reflections, we need to eliminate reflections off all static objects in the environment (like walls and furniture).
This is typically achieved by performing a background subtraction step, i.e., by taking TOF profiles from adjacent time windows and subtracting them out from each other.
5 Whereas this approach enables us to track moving people, it prevents us from detecting a static person -e.g., someone who is standing or sitting still.
Specifically, because a static person remains in the same location, his TOF does not change, and hence his reflections would appear as static and will be eliminated in the process of background subtraction.
To see this in practice, we run two experiments where we perform background subtraction by subtracting two TOF profiles that are 12.5 milliseconds apart from each other.
The first experiment is performed with a walking person and the resulting heatmap is shown in Fig. 10(a), whereas the second experiment is performed in the presence of a person who is sitting at (0, 5) and the resulting heatmap is shown in Fig. 10(b).
These experiments show how the heatmap of a moving person after background subtraction would allow us to localize him accurately, whereas the heatmap of the static person after background subtraction is very noisy and does not allow us to localize the person.To localize static people, one needs to realize that even a static person moves slightly due to breathing.
Specifically, during the process of breathing, the human chest moves by a sub-centimeter distance over a period of few seconds.
The key challenge is that this change does not translate into a discernible change in the TOF of the person.
However, over an interval of time of a few seconds (i.e., as the person inhales and exhales), it would result in discernible changes in the reflected signal.
Therefore, by subtracting frames in time that are few seconds apart, we should be able to localize the breathing motion.In fact, Fig. 10(d) shows that we can accurately localize a person who is sitting still by using a subtraction window of 2.5 seconds.
Note, however, that this long subtraction window will introduce errors in localizing a pacing person.
In particular, since typical indoor walking speed is around 1 m/s [8], subtracting two frames that are 2.5 seconds apart would result in smearing the person's location and may also result in mistaking him for two people as shown in Fig. 10(c).
Thus, to accurately localize both static and moving people, WiTrack2.0 performs background subtraction with different subtraction windows.
To localize moving users, it uses a subtraction window of 12.5 ms. On the other hand, normal adults inhale and exhale over a period of 3-6 seconds [32] causing their TOF profiles to change over such intervals of time.
Hence, we consider the first TOF profile during each 10-second interval, and subtract it from all subsequent TOF profiles during that interval.
As a result, breathing users' reflections pop up at different instances, allowing us to detect and localize them.
We built WiTrack2.0 using a single FMCW radio whose signal is fed into multiple antennas.
The FMCW radio generates a low-power (sub-milliWatt) signal that sweeps 5.46-7.25 GHz every 2.5 milliseconds.
The range and power are chosen in compliance with FCC regulations for consumer electronics [2].
The schematic in Fig. 5 shows how we use this radio to implement Multi-shift FMCW.
Specifically, the generated sweep is delayed before being fed to directional antennas for transmission.
6 At the receive side, the signal from each receive antenna is mixed with the FMCW signal and the resulting signal is fed to the USRP.
The USRP samples the signals at 2 MHz and transfers the digitized samples to the UHD driver.
These samples are processed in software to localize users and recognize their gestures.
7 The analog FMCW radio and all the USRPs are driven by the same external clock.
This ensures that there is no frequency offset between their oscillators, and hence enables subtracting frames that are relatively far apart in time to enable localizing people based on breathing.
Human Subjects.
We evaluate the performance of WiTrack2.0 by conducting experiments in our lab with 6 The most straightforward option to delay the signal is to insert a wire.
However, wires attenuate the signal and introduce distortion over the wide bandwidth of operation of our system, reducing its SNR.
Instead, we exploit the fact that, in FMCW, time and frequency are linearly related; hence, a shift τ in time can be achieved through a shift Δf = slope × τ in the frequency domain.
Hence, we achieve this delay by mixing FMCW with signals whose carrier frequency is Δf .
This approach also provides us with the flexibility of tuning multi-shift FMCW for different TOF limit 's by simply changing these carrier frequencies.7 Complexity-wise, WiTrack2.0's algorithms are linear in the number of users, the number of Tx antennas, and the number of Rx antennas.
eleven human subjects: four females and seven males.
The subjects differ in height from 165-185 cm as well as in weight and build and span 20 to 50 years of age.
In each experiment, each subject is allowed to move as they wish throughout the room.
These experiments were approved by MIT IRB protocol #1403006251.
Ground Truth.
We use the VICON motion capture system to provide us with ground truth positioning information [1].
It consists of an array of infrared cameras that are fitted to the ceiling of a 5 m × 7 m room, and requires instrumenting any tracked object with infrared-reflective markers.
When an instrumented object moves, the system tracks the infrared markers on that object and fits them into a 3D model to identify the object's location.We evaluate WiTrack2.0's accuracy by comparing it to the locations provided by the VICON system.
To track a user using the VICON, we ask him/her to wear a hard hat that is instrumented with five infrared markers.
In addition, for the gestures experiments, we ask each user to wear a glove that is instrumented with six markers.
Experimental Setup.
We evaluate WiTrack2.0 in a standard office environment that has standard furniture: tables, chairs, boards, computers, etc.
We experiment with two setups: line-of-sight and through-the-wall.
In the through-wall experiments, WiTrack2.0 is placed outside the VICON room with all transmit and receive antennas facing one of the walls of the room.
Recall that WiTrack2.0's antennas are directional and hence this setting means that the radio beam is directed toward the room.
The VICON room has no windows; it has 6-inch hollow walls supported by steel frames, which is a standard setup for office buildings.
In the line-of-sight experiments, we move WiTrack2.0 inside the room.
In all of these experiments, the subjects' locations are tracked by both the VICON system and WiTrack2.0.
Detection.
Recall that WiTrack2.0 adopts iterative cancellation to detect different users in the scene.
This limits the number of users it can detect because of residual interference from previous iterations.
Therefore, we run experiments to identify the maximum number of people that WiTrack2.0 can reliably detect under various conditions.
Detection accuracy is measured as the percentage of time that WiTrack2.0 correctly outputs the number of users present in the environment.
The number of users in each experiment is known and acts as the ground truth.
We run ten experiments for each of our testing scenarios, and plot the accuracies for each them in Fig. 11.
We make two observations from this figure.
First, the accuracy of detection is higher in line-of-sight than in through-wall settings.
This is expected because the wall causes significant attenuation and hence reduces the SNR of the reflected signals.
Second, the detection accuracy for breathing-based localization is higher than that of the tracking experiments.
While this might seem surprising, it is actually due to the fact that the breathing experiments operate over longer subtraction windows.
Specifically, the system outputs the number of people detected and their locations by analyzing the trace over windows of 10 seconds.
In contrast, the tracking experiments require outputting a location of each person once every 12.5 ms, 8 and hence they might not be able to detect each person within such a small time window.For our evaluation of localization accuracy, we run experiments with the maximum number of people that are reliably detectable, where "reliably detectable" is defined as detected an accuracy of 95% or higher.
For reference, we summarize these numbers in the We first evaluate WiTrack2.0's accuracy in multiperson motion tracking.
We run 100 experiments in total, half of them in line-of-sight and the second half in through-wall settings.
In each experiment, we ask one, two, three, or four human subjects to wear the hard hats that are instrumented with VICON markers and move inside the VICON-instrumented room.
Each subject's location is tracked by both the VICON system and WiTrack2.0, and each experiment lasts for one minute.
Since each FMCW sweep lasts for 2.5ms and we average 5 sweeps to obtain each TOF measurement, we collect around 5,000 location readings per user per experiment.Figs.
12 and 13 plot the CDFs of the location error along the x and y coordinates for each of the localized persons in both line-of-sight and through-wall scenarios.
The subjects are ordered from the first to the last as detected by SSC.
The figures reveal the following findings: • WiTrack2.0 can accurately track the motion of four users when it is in the same room as the subjects.
Its median location error for these experiments is 8.5 cm in x and 6.4 cm in y for the first user detected, and decreases to 15.9 cm in x and 7.2 cm in y for the last detected user.
• In through-wall scenarios, WiTrack2.0 can accurately localize up to three users.
Its median location error for these experiments is 8.4 cm and 7.1 cm in x/y for the first detected user, and decreases to 16.1 cm and 10.5 cm in x/y for the last detected user.
As expected, the accuracy when the device is placed in the same room as the users is better than when it is placed behind the wall due to the extra attenuation (reduced SNR) caused by the wall.
• The accuracy in the y dimension is better than the accuracy in the x dimension.
This discrepancy is due to the asymmetric nature of WiTrack2.0's setup, where all of its antennas are arranged along the y = 0 axis.
• The localization accuracy decreases according to the order the SSC algorithm localizes the users.
This is due to multiple reasons: First, a user detected in later iterations is typically further from the device, and hence has lower SNR, which leads to lower accuracy.
Second, SSC may not perfectly remove the reflections of other users in the scene, which leads to residual interference and hence lower accuracy.
We evaluate WiTrack2.0's accuracy in localizing static people based on their breathing.
We run 100 experiments in total with up to five people in the room.
Half of these experiments are done in line-of-sight and the other half are through-wall.
Experiments last for 3-4 minutes.
Subjects wear hard hats and sit on chairs in the VICON room.Figs.
14 and 15 plot WiTrack2.0's localization error in line-of-sight and through-wall settings as a function of the order with which the subject is detected by the SSC algorithm.
The figures show the median and 90 th percentile of the estimation error for the x and y coordinates of each of the subjects.
The figures show the following results:• WiTrack2.0's breathing-based localization accuracy goes from a median of 7.24 and 6.3 cm in x/y for the nearest user to 18.31 and 10.85 cm in x/y for the furthest user, in both line-of-sight and through-wall settings.
• Localization based on breathing is more accurate than during motion.
This is because when people are static, they remain in the same position, providing us with a larger number of measurements for the same location.
We evaluate WiTrack2.0's accuracy in tracking 3D pointing gestures.
We run 100 experiments in total with one to three subjects.
In each of these experiments, we ask each subject to wear a glove that is instrumented with infrared-reflective markers, stand in a different location in the VICON room, and point his/her hand in a random 3D direction of their choice -as if they were playing a shooting game or pointing at some household appliance to control it.
In most of these experiments, all subjects were performing the pointing gestures simultaneously.Throughout these experiments, we track the 3D location of the hand using the VICON system and WiTrack2.0.
We then regress on the 3D trajectory to determine the direction in which each user pointed (similar to [3]).
Fig. 16(a) and 16(b) plot the CDFs of the orientation error between the angles as measured by WiTrack2.0 and the VICON for the 1st, 2nd and 3rd participant (in the order of detection by SSC).
Note that we decompose the 3D pointing gesture along two directions: azimuthal (in the x − y plane), which we denote as φ, and elevation (in the r−z plane), which we denote as θ.
The accuracy along both of these angles is important since appliances which the user may want to control in a home environment (e.g., lamps, screens, shades) span the 3D space.The figure shows that the median orientation error in φ goes from 8.2 degrees to 12.4 degrees from the first to the third person, and from 12 degrees to 16 degrees in θ.
Note that WiTrack2.0's accuracy in φ is slightly higher than its accuracy in θ.
This is due to WiTrack2.0's setup, where the antennas are more spread out along the x than along the z, naturally leading to lower robustness to errors along the z axis, and hence lower accuracy in θ.
These experiments demonstrate that WiTrack2.0 can achieve high accuracy in 3D tracking of a pointing gesture.
WiTrack2.0 marks an important step toward enabling accurate indoor localization that does not require users to hold or wear any wireless device.
WiTrack2.0, however, has some limitations that are left for future work.
1.
Number of Users: WiTrack2.0 can accurately track up to 4 moving users and 5 static users.
These numbers may be sufficient for in-home tracking.
However, it is always desirable to scale the system to track more users.2.
Coverage Area: WiTrack2.0's range is limited to 10m due to its low power.
To cover larger areas and track more users, one may deploy multiple devices and hand off the trajectory tracking from one to the next, as the person moves around.
Managing such a network of devices, coordinating their hand-off, and arbitrating their medium access are interesting problems to explore.
The system can track multiple users simultaneously, but it cannot identify them.
Additionally, it can track limb motion (e.g., a hand) but cannot differentiate between different body parts (a hand vs. a leg).
We believe that future work can investigate this issue by identifying fingerprints of various reflectors.4.
Limited Gesture Interface: WiTrack2.0 focuses on tracking pointing gestures; however, the user cannot move other body parts while performing the pointing gesture.
Extending the system to enable rich gesturebased interfaces is an interesting avenue for future work.
Overall, we believe WiTrack2.0 pushes the limits of indoor localization and enriches the role it can play in our daily lives.
By enabling smart environments to accurately follow our trajectories, it paves way for these environments to learn our habits, react to our needs, and enable us to control the Internet of Things that revolves around our networked homes and connected environments.
