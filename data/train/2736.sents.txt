In-network processing, where data is processed by special-purpose devices as it passes over the network, is showing great promise at improving application performance, in particular for data analytics tasks.
However, analytics and in-network processing are not yet integrated and widely deployed.
This paper presents a vision for providing in-network processing as a service to data analytics frameworks, and outlines benefits , remaining challenges, and our current research directions towards realizing this vision.
In-network compute capability is growing.
Figure 1 illustrates the network-attached compute resources that are (or are becoming) available in modern data centers.
New programmable hardware includes packet processors that can efficiently process packets using specialized hardware designs, such as SmartNICs [20,75], programmable switches [12], and NPUs [13,58,80].
In parallel, software data paths are becoming increasingly programmable via tools like the Data Plane Development Kit (DPDK) [69] or the eXpress Data Path (XDP) [27], while network function virtualization platforms are being optimized for flexible high-performance packet processing [62,65,83].
Programmable network processors can improve application performance.
Prior work has shown the benefits of taking advantage of compute that is conveniently located along the data-path [23, 32, 33, 45-47, 49, 50, 72].
However, existing systems that have used in-network processing have been application specific [45][46][47]50] or have only been feasible in the research lab.
Often, they require invasive changes to infrastructure or the use of unreliable network protocols [23,45,50].
How can we deploy in-network processing in real settings?
Our vision: We propose In-Network Processing as a Service (NPaaS) 1 .
End-users continue to write high level programs (e.g., SQL) and use existing data processing frameworks such as Apache Spark [7], but the framework would use NPaaS to offload operations to processing elements along (or near) the data path.
A common scenario might be NPaaS initiating the read from storage, pre-processing the data, and directing the processed data to compute nodes of the framework.
NPaaS could be operated by cloud providers or as a user-run service that requests lower level resources from the provider.
Realizing this vision will require designing solutions to challenges presented by this new type of computing, including changes to the existing system stack ( §2).
To drive research into NPaaS, we are developing a prototype called Jumpgate ( §3).
Why should data analytics adopt in-network processing?
Data analytics need to leverage new high performance hardware.
Data analytics is an expensive but common task.
Substantial effort has been spent to accelerate query workflows with high performance devices.
We view network processors as another heterogeneous processing device to be adopted in order to improve performance.
Just as data analytics systems have integrated GPUs [70], TPUs [2], DPUs [3], and FPGAs [37], they should also coordinate with in-network processors.
Since many analytics tasks can be CPU-bound [60], offloading operations to network devices helps to alleviate valuable CPU resources [20] while decreasing workload execution time for the end user.
Prior work and our estimates show that in-network processing can accelerate data analytics tasks by orders of magnitude, detailed in §1.2.
We believe that network processing devices, specialpurpose and resource constrained as they may be, can act as specialized compute stages as part of data analytics pipelines.
For example, Reconfigurable Match Table (RMT) switches [12], programmed in P4 [11], present a very challenging and restrictive programming environment.
In spite of this, prior work has used programmable switches to perform join-and-group-by operations [45], aggregations [72], build replicated key-value stores [32,33], optimize consensus and transaction protocols [46,47], offload network telemetry queries [25,57], and implement several network management algorithms [73,74].
Work like Domino [74] and FlowBlaze [68] provides even higher-level languages for these devices.
We can't move all compute to storage.
Existing data processing systems try to place compute near storage nodes to reduce data movement costs [82].
But, modern cloud architectures are decoupling compute and storage to achieve better resource utilization and fault tolerance.
Instead of general purpose machines with attached storage, we now have specialpurpose data serving machines [26,38,56] with very little compute capability.
In these deployments, the classic 'move compute to data' optimization is no longer possible.For instance, Facebook's Bryce Canyon storage server combines 72 high capacity hard drives with two Xeon D-1500 SoCs [16,17], each with at most 16 cores -less than half a core per drive.
Since we can no longer place a lot of compute on storage nodes, we should find ways to place computation near data, and our next option is the network path.
Data analytics need flexible deployments.
Data processing systems behave inefficiently if their nodes are statically allocated in advance and they assume no other compute resources are available.
For instance, to filter a large volume of data quickly, we require many nodes.
After applying a highly selective filter, the data will be 10-1000x smaller but distributed across the same nodes used to filter it.
However, it is often faster to process small datasets on a single machine because it avoids distribution overheads [53].
NPaaS could be used to push the filter operation into the network and ensure all relevant records arrive at a single host.Ephemeral (serverless) compute service (e.g., AWS Lambda [1]) can address this need for flexibility [35], but are currently hamstrung by the lack of direct access to the network [26] and instead rely on inefficient cloud file systems for state exchange [39].
If they had direct network access, we could treat ephemeral compute services as in-network processors.Why provide network processing as a service?
As we've seen, in-network processing has a growing number of hardware implementations, but as far as we know, there are no proposals to manage and expose this plethora of new hardware to end-users.
However, the burden of managing all this hardware should not fall to each data analytics framework, as Lerner et al. propose [45].
Instead, analytics systems and in-network processing should be decoupled with an interface that allows the framework to specify desired operations, while NPaaS manages instantiating requested operations on appropriate hardware.
NPaaS allows hardware to be managed independently from the data analytics systems while saving analytics developers from implementing device-specific code.
We describe potential general interfaces in §2, and our NPaaS prototype in §3.
We want to inspire more network-aware hardware designs.
We believe network processors are good hardware accelerators for data analytics.
Recent work on near-storage [15,24,31,34,41] or in-memory processors [3,10,22,81] tightly couples storage with specialized processors, but as we've discussed, storage and compute are better utilized if they are decoupled.
We think more data processing devices could be designed assuming data arrives over the network as coordinated by NPaaS, and hope that our work inspires new network-aware data analytics accelerators.
In-network processing can reduce the overall work required of end-hosts by performing computation in network, reducing data volume and speeding up applications.
To demonstrate, we run an experiment and draw on prior work to show that in-network processing will benefit data analytics.
Experiments.
We estimate the effect of offloading common analytics operations to the network by measuring reduction in time and bytes transmitted on a query 2 run using Apache Spark.
We offload operations in the query that require no storage (filter, projection, shuffle) or can be bounded (partial aggregation).
To measure traffic reduction, we pack each record in a UDP packet and drop or modify packets as dictated by the operation, measuring data sent over the wire before and after.
To measure query time, we simulate offloading operators using Spark SQL to query pre-processed files that contain data that would come from the offloaded operators.
This assumes operators work as fast as our cluster 3 so our measurements give an upper-bound on the benefits.
Table 1 summarizes our results, averaged over 5 runs.
Filter and Project reduce traffic commensurate with the amount of rows or columns they remove.
For our query test, shuffle and partial aggregation also apply filter and project.
Shuffle eliminates the need for nodes to exchange records by sending the network by selecting and configuring available devices.
This is challenging because the devices that can be used depend on the data format and transport protocols used to send data, which in turn depend on where data is stored.
For example, Figure 1 shows on-path and off-path devices.
Onpath devices operate at line-rate, but can only read a small number of bytes of each packet, and have small amounts of state [11,14,45,72].
Off-path devices are more flexible, but slower, and introduce latency.
Achieving even basic network processing requires co-designing storage systems, network transport, and data formats with the capabilities of the available network processors.
Network Transports.
Table 2 covers network transports NPaaS could use to send data.
Our main constraint is many network devices (see §1.1) only operate on packets, and can't buffer data across packets in a network flow.
To operate perpacket, a complete record must be in a single packet.
In other words, each record must be packetized.Stream protocols like TCP require fewer modifications to existing systems.
But, operating on a flow requires buffering data, observing all packets, and modifying TCP state; tasks that are outside the capabilities of packet processors.
Even if records are chunked into individual TCP packets, they cannot be reordered or dropped without tracking the behavior of the TCP state machine per flow.
In practice, modifying TCP streams requires a proxy, stream processor or middlebox.Prior work has thus sent records over UDP-based protocols (e.g., Netaccel [45]).
In practice, we need a reliable protocol to ensure data has been processed.
Fortunately, reliable datagram protocols, such as SCTP [76] and DCCP 4 [40], are available in the Linux kernel today.
However, the downside to datagram protocols is that the sender must packetize records.
Data Formats.
Table 3 covers data formats NPaaS might support.
Our main concern is the ability to process popular data formats while guaranteeing the packet content is parseable by the network devices we wish to support.
For instance, RMT switches can only process 200-500 bytes of fixed-length data from each packet [12,72,73].
Unstructured formats, like JSON, are prevalent but are difficult to parse quickly [42,48,61] hardware accelerators [18]; binary formats can be parsed more quickly.
We argue NPaaS should support both unstructured data (JSON) for general applicability and binary formats for best performance and compatibility with hardware.
Not all in-network processors need to support all formats, but NPaaS should allow for processing of different formats.Data formats vary in how complex it is to find record boundaries to packetize data.
JSON or CSV records are easily found by searching for newlines [8,28] and flat binary formats just need offset calculations, but binary formats for nested schemata require complex algorithms [36].
Storage System Requirements.
As said earlier, to send data via record transport, a storage system needs to packetize records.
We must also be careful with distributed file systems that split data files into chunks, like HDFS [9] or Ceph [79].
Since chunking is done without awareness of records, records can span multiple chunks, and it is possible to see incomplete records at the flow level.
If we want to use a record transport, one solution is to have a middlebox read all chunks that make up a file, transcoding data into a record transport on the fly.
Open Research Questions.
There are many more research questions along the road to co-designing NPaaS.
Here is a short selection.
Q1: How should we allocate and schedule processing with respect to the network topology?
How long will processing pipelines need to last?
Q2: Can middleboxes perform fast enough to make a difference to applications?
Even though hardware packet processors are faster, it is worthwhile to implement operators in software, even to just provide a performance baseline.
Q3: Are existing transport protocol sufficient for NPaaS or do we need custom protocols?
Customized protocols allow for domain-specific optimizations but require significant development effort.
Multiple data analytics systems need to communicate their operations to NPaaS.
Is there a common format?
What operations can be supported?
Conveniently, most data processing systems model programs as dataflow between nodes in an abstract graph [2,4,30,82] and have equivalent operators: many support SQL dialects and functional style operations (e.g., filter, project, map, reduce, group-by, shuffle) that can be directly mapped between frameworks [21].
When an analytics framework requests computation, the task for NPaaS is to map the desired operations to implementations on network processors.
A simple way is to use pre-written or templated implementations for each device.
To support framework-specific operators, or avoid hand-coding a multitude of operators, NPaaS could draw on cross-framework intermediate representations that enable compilation to different backend devices (e.g., Weld [63,64], Dandelion [71]).
How can we run user code on hardware that lacks isolation?
If NPaaS only uses client-allocated resources, such as VMs and containers, isolation and multi-tenancy is, arguably 5 addressed by existing isolation mechanisms.
But, if NPaaS runs user-provided code on provider-managed devices that lack hardware isolation, such as programmable switches, a major challenge is to ensure user programs don't abuse access to the switch.
A promising option is software isolation (SI), as proposed by Singularity [43], where user supplied programs are type and memory safe and restricted to use specific interfaces.
Proposals to support this notion of isolation already exist for switches [51] and Netbricks [65] uses SI to eliminate hardware-isolation costs to improve performance.
Similarly, Azure SmartNICs let users write policies for the Virtual Filtering Platform (VFP) [19], which implicitly restricts them to the user's network.
NPaaS can provide operations which are guaranteed to only act on traffic belonging to the requester.
How should NPaaS recover from failure?
NPaaS systems will be composed of heterogeneous devices with their own failure modes.
Detecting failures will be an ongoing issue that NPaaS systems must address.
Prior work handles failures by restarting jobs on new nodes [23,45] or by routing around the failure [50].
The best option depends on the expected lifetime of the pipeline, likelihood of a failure, and any existing failure recovery mechanisms.
For short-lived jobs, failure is unlikely and restarting is fast, so a lightweight mechanism like restarting is ideal [45].
For longer-lived jobs, partial recovery becomes ideal [50].
In either case, the calling framework may provide better failure recovery than NPaaS can provide (e.g., Spark's lineage graph [82]).
How can we debug in-network programs?
Data processing errors are often data dependent and difficult to trace because errors are caused by a few malformed data records [29].
As with existing distributed computation systems, NPaaS should Figure 2: Overview of the how Jumpgate will interact with a data processing system to compile and orchestrate in-network processing.return a summary of any problems encountered during execution to the framework, including enough context to help find the problematic record(s).
Is it better if the cloud provider or the user operates NPaaS?The cloud provider has a privileged view of the network topology, lower level control over the hardware and network configuration, and often more money to pay experts to develop fast operators.
On the other hand, users have a better understanding of their specific workload and could implement workload-specific operators.
Users may also prefer to keep any needed encryption keys on infrastructure they own.
One way to capture the best of both is for the user to operate the NPaaS system, while allocating proprietary in-network operators from the cloud provider.
We are developing Jumpgate, a compiler and orchestration system that can provide NPaaS.
Jumpgate provides a clientfacing API and maps client requests to relevant devices using an extensible architecture that simplifies adding new operators and devices without modifying the client.
Figure 2 shows an overview of a client's interaction with Jumpgate.Step 1: the compiler receives a logical plan of operations from data analytics frameworks (e.g., filter, project, shuffle, partial or full aggregation) and maps logical operations to stages of physical operators that can be deployed on available devices.
Step 2: the orchestration layer coordinates runtime execution of the physical plan on devices.
Devices are allocated and initialized to perform the physical operations 6 .
After initialization, network addresses are known and can be propagated as needed (e.g., end-host addresses, or next-hop addresses in a processing pipeline).
Client API.
Jumpgate's API allows a client to specify input data sources (files or network tuples), a DAG of logical operations to apply to the input data, and the destination network tuples for receiving processed data.
We plan to expand the API as our evaluations determine a need for it (e.g., to communicate skew and cardinality of input data).
Mapping.
The compiler maps logical operations to stages of pipelines of physical operators.
For example, joins require a build stage to load data into the device and then a probe stage to output matched records.
Since in-network operations execute concurrently in pipelines, we must make sure that other operators execute at the correct time to feed and receive data from the join.
Jumpgate computes all needed stages and which stage(s) each operator executes in using a dependency-driven simulation.
Logical operators are then mapped to physical operators, as determined by each physical operator's matching functions (below).
Extensibility.
Jumpgate supports adding new logical and physical operators.
For instance, a logical operator that translates unstructured to structured data, or a physical operator that runs filters on supporting storage systems.
Logical operations are represented as typed nodes in the DAG with specified input/output connectivity and stage logic.
Physical operators are comprised of: (1) matching functions and (2) a controller used to drive device allocation and execution.
Matching functions determine which logical operators can be replaced based on type and properties, such as available resources and operator-specific parameters.
We plan to evaluate heuristic and optimal approaches (e.g., SMT solvers) for exploring the space of potential logical to physical matches.
Limitations and Future Work A compiler and orchestration layer are bare necessities for providing NPaaS, but are not sufficient for a full NPaaS system.
At the very least, NPaaS also needs failure handling and topology-aware scheduling.
For now, we are focused on enabling analytics applications to execute in-network computations on software and programmable in-network devices, supporting common operations (e.g., TPC-DS [67], BigDataBench [78]), and measuring performance.
Our eventual goal is to share Jumpgate with other researchers in order to answer broader challenges posed by this paper and lay fertile groundwork for research into making in-network processing available to more users.
In-network compute capability is growing, and the benefits to data analytics are clear.
To allow all analytics systems to benefit, this paper advocated for providing in-network processing as a service (NPaaS) that abstracts the desired operations on data from their low-level implementation on network processors.
We are developing Jumpgate to provide NPaaS and help drive research and adoption of in-network processing.
Feedback desired and open issues: We are not cloud providers and have little knowledge about the day-to-day deployment and management challenges such a company might face if they offered NPaaS.
While we have covered many open issues in §2, we are hoping to hear about additional challenges we have not addressed.
Examples include the integration of NPaaS into cloud systems and potential security, fairness, reliability, and usability concerns.
In particular, we are interested in discussing difficulties deploying applications to FPGAs and network accelerators currently used in data centers, so that we can work on addressing them in Jumpgate.
Discussion: More generally, we are hoping to spark a discussion of how best to expose in-network processing hardware to end users and allow them to accelerate their applications, ideally without writing low-level code.
For example, are analytics operators the right abstractions to expose in-network processors to users?
Are there other abstractions that could be more useful or more easily deployed?
Controversial points: Placing more functionality than just packet processing on networking devices is highly controversial.
For instance, McCauley et al. [52] argue strongly against pushing complex operators to the network, on the basis that it is unnecessary for performance and too restrictive to applications semantics.
Detractors might suggest we instead develop more efficient data analytics software.
However, we believe that network processors present a unique hardware architecture that is distinct from classical out-of-order CPU designs, that can benefit data analytics so much ( §1.2) that it is worthwhile exploring ways to make them available to end-users.
Circumstances in which the whole idea might fall apart: This project hinges on the assumption that network processors will become ubiquitous in datacenters.
This requires that these devices are cost-effective and flexible enough to be widely used.
Currently, this is at a stand-still: users can't benefit from in-network processing until cloud providers make programmable network processors available, but providers won't bother if there are no popular use-cases.
By proposing NPaaS we hope to break this deadlock.
