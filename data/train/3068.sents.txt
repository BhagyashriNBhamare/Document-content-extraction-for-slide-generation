Infrastructure-as-a-Service (IaaS) clouds offer diverse instance purchasing options.
A user can either run instances on demand and pay only for what it uses, or it can prepay to reserve instances for a long period, during which a usage discount is entitled.
An important problem facing a user is how these two instance options can be dynamically combined to serve time-varying demands at minimum cost.
Existing strategies in the literature, however, require either exact knowledge or the distribution of demands in the long-term future, which significantly limits their use in practice.
Unlike existing works, we propose two practical online algorithms, one deterministic and another randomized, that dynamically combine the two instance options online without any knowledge of the future.
We show that the proposed deterministic (resp., randomized) algorithm incurs no more than 2 − ↵ (resp., e/(e − 1 + ↵)) times the minimum cost obtained by an optimal offline algorithm that knows the exact future a priori, where ↵ is the entitled discount after reservation.
Our online algorithms achieve the best possible competitive ratios in both the deterministic and randomized cases, and can be easily extended to cases when short-term predictions are reliable.
Simulations driven by a large volume of real-world traces show that significant cost savings can be achieved with prevalent IaaS prices.
Enterprise spending on Infrastructure-as-a-Service (IaaS) cloud is on a rapid growth path.
According to [1], the public cloud services market is expected to expand from $109 billion in 2012 to $207 billion by 2016, during which IaaS is the fastest-growing segment with a 41.7% annual growing rate [2].
IaaS cost management therefore receives significant attention and has become a primary concern for IT enterprises.Maintaining optimal cost management is especially challenging, given the complex pricing options offered in today's IaaS services market.
IaaS cloud vendors, such as Amazon EC2, ElasticHosts, GoGrid, etc., apply diverse instance (i.e., virtual machine) pricing models at different commitment levels.
At the lowest level, cloud users launch on-demand instances and pay only for the incurred instance-hours, without making any long-term usage commitments, e.g., [3], [4], [5].
At a higher level, there are reserved instances wherein users prepay a one-time upfront fee and then reserve an instance for months or years, during which the usage is either free, e.g., [4], [5], or is priced under a significant discount, e.g., [3].
Table I gives a pricing example of on-demand and reserved instances in Amazon EC2.Acquiring instances at the cost-optimal commitment level plays a central role for cost management.
Simply operating the entire load with on-demand instances can be highly inefficient.
For example, in Amazon EC2, three years of continuous ondemand service cost 3 times more than reserving instances for the same period [3].
On the other hand, naively switching to a long-term commitment incurs a huge amount of upfront payment (more than 1,000 times the on-demand rate in EC2 [3]), making reserved instances extremely expensive for sporadic workload.
In particular, with time-varying loads, a user needs to answer two important questions: (1) when should I reserve instances (timing), and (2) how many instances should I reserve (quantity)?
Recently proposed instance reservation strategies, e.g., [6], [7], [8], heavily rely on long-term predictions of future demands, with historic workloads as references.
These approaches, however, suffer from several significant limitations in practice.
First, historic workloads might not be available, especially for startup companies who have just switched to IaaS services.
In addition, not all workloads are amenable to prediction.
In fact, it is observed in real production applications that workload is highly variable and statistically nonstationary [9], [10], and as a result, history may reveal very little information about the future.
Moreover, due to the long span of a reservation period (e.g., 1 to 3 years in Amazon EC2), workload predictions are usually required over a very long period of time, say, years.
It would be very challenging, if not impossible, to make sufficiently accurate predictions over such a long term.
For all these reasons, instance reservations are usually made conservatively in practice, based on empirical experiences [11] or professional recommendations, e.g., [12], [13], [14].
In this paper, we are motivated by a practical yet fundamental question: Is it possible to reserve instances in an online manner, with limited or even no a priori knowledge of the future workload, while still incurring near-optimal instance acquisition costs?
To our knowledge, this paper represents the first attempt to answer this question, as we make the following contributions.With dynamic programming, we first characterize the optimal offline reservation strategy as a benchmark algorithm (Sec.
III), in which the exact future demand is assumed to be known a priori.
We show that the optimal strategy suffers "the curse of dimensionality" [15] and is hence computationally intractable.
This indicates that optimal instance reservation is in fact very difficult to obtain, even given the entire future demands.Despite the complexity of the reservation problem in the offline setting, we present two online reservation algorithms, one deterministic and another randomized, that offer the best provable cost guarantees without any knowledge of future demands beforehand.
We first show that our deterministic algorithm incurs no more than 2 − ↵ times the minimum cost obtained by the benchmark optimal offline algorithm (Sec.
IV), and is therefore (2 − ↵)-competitive, where ↵ 2 [0, 1] is the entitled usage discount offered by reserved instances.
This translates to a worst-case cost that is 1.51 times the optimal one under the prevalent pricing of Amazon EC2.
We then establish the more encouraging result that, our randomized algorithm improves the competitive ratio to e/(e − 1 + ↵) in expectation, and is 1.23-competitive under Amazon EC2 pricing (Sec.
V).
Both algorithms achieve the best possible competitive ratios in the deterministic and randomized cases, respectively, and are simple enough for practical implementations.
Our online algorithms can also be extended to cases when short-term predictions into the near future are reliable (Sec.
VI).
In addition to our theoretical analysis, we have also evaluated both proposed online algorithms via large-scale simulations (Sec.
VII), driven by Google cluster-usage traces [16] with 40 GB workload demand information of 933 users in one month.
Our simulation results show that, under the pricing of Amazon EC2 [3], our algorithms closely track the demand dynamics, realizing substantial cost savings compared with several alternatives.Though we focus on cost management of acquiring compute instances, our algorithms may find wide applications in the prevalent IaaS services market.
For example, Amazon ElastiCache [17] also offers two pricing options for its web caching services, i.e., the On-Demand Cache Nodes and Reserved Cache Nodes, in which our proposed algorithms can be directly applied to lower the service costs.
We start off by briefly reviewing the pricing details of the on-demand and reservation options in IaaS clouds, based on which we formulate the online instance reservation problem for optimal cost management.
On-Demand Instances: On-demand instances let users pay for compute capacity based on usage time without long-term commitments, and are uniformly supported in leading IaaS clouds.
For example, in Amazon EC2, the hourly rate of a Standard Small Instance (Linux, US East) is $0.08 (see Table I).
In this case, running it on demand for 100 hours costs a user $8.On-demand instances resemble the conventional pay-asyou-go model.
Formally, for a certain type of instance, let the hourly rate be p.
Then running it on demand for h hours incurs a cost of ph. Note that in most IaaS clouds, the hourly rate p is set as fixed in a very long time period (e.g., years), and can therefore be viewed as a constant.Reserved Instances: Another type of pricing option that is widely supported in IaaS clouds is the reserved instance.
It allows a user to reserve an instance for a long period (months or years) by prepaying an upfront reservation fee, after which, the usage is either free, e.g., ElasticHosts [4], GoGrid [5], or is priced with a heavy discount, e.g., Amazon EC2 [3].
For example, in Amazon EC2, to reserve a Standard Small Instance (Linux, US East, Light Utilization) for 1 year, a user pays an upfront $69 and receives a discount rate of $0.039 per hour within 1 year of the reservation time, as oppose to the regular rate of $0.08 (see Table I).
Suppose this instance has run 100 hours before the reservation expires.
Then the total cost incurred is $69 + 0.039⇥100 = $72.9.
Reserved instances resemble the wholesale market.
Formally, for a certain type of reserved instance, let the reservation period be ⌧ (counted by the number of hours).
An instance that is reserved at hour i would expire before hour i + ⌧ .
Without loss of generality, we assume the reservation fee to be 1 and normalize the on-demand rate p to the reservation fee.
Let ↵ 2 [0, 1] be the received discount due to reservation.
A reserved instance running for h hours during the reservation period incurs a discounted running cost ↵ph plus a reservation fee, leading to a total cost of 1+↵ph. In the previous example, the normalized on-demand rate p = 0.08/69; the received discount due to reservation is ↵ = 0.039/0.08 = 0.49; the running hour h = 100; and the normalized overall cost is 1 + ↵ph = 72.9/69 .
In practice, cloud providers may offer multiple types of reserved instances with different reservation periods and utilization levels.
For example, Amazon EC2 offers 1-year and 3-year reservations with light, medium, and high utilizations [3].
For simplicity, we limit the discussion to one type of such reserved instances chosen by a user based on its rough estimations.
We also assume that the on-demand rate is far smaller than the reservation fee, i.e., p ⌧ 1, which is always the case in IaaS clouds, e.g., [3], [4], [5].
In general, launching instances on demand is more cost efficient for sporadic workload, while reserved instances are more suitable to serve stable demand lasting for a long period of time, for which the low hourly rate would compensate for the high upfront fee.
The cost management problem is to optimally combine the two instance options to serve the timevarying demand, such that the incurred cost is minimized.
In this section, we consider making instance purchase decisions online, without any a priori knowledge about the future demands.
Such an online model is especially important for startup companies who have limited or no history demand data and those cloud users whose workloads are highly variable and non-stationary -in both cases reliable predictions are unavailable.
We postpone the discussions for cases when shortterm demand predictions are reliable in Sec.
VI.Since IaaS instances are billed in an hourly manner, we slot the time to a sequence of hours indexed by t = 0, 1, 2, . . . At each time t, demand d t arrives, meaning that a user requests d t instances, d t = 0, 1, 2, . . . To accommodate this demand, the user decides to use o t on-demand instances and d t −o t reserved instances.
If the previously reserved instances that remain available at time t are fewer than d t − o t , then new instances need to be reserved.
Let r t be the number of instances that are newly reserved at time t, r t = 0, 1, 2, . . . The overall cost incurred at time t is the on-demand cost o t p plus the reservation cost r t + ↵p(d t − o t ), where r t is the upfront payments due to new reservations, and ↵p(d t − o t ) is the cost of running d t − o t reserved instances.The cost management problem is to make instance purchase decisions online, i.e., r t and o t at each time t, before seeing future demands d t+1 , d t+2 , . . . The objective is to minimize the overall instance acquisition costs.
Suppose demands last for an arbitrary time T (counted by the number of hours).
We have the following online instance reservation problem:min {rt,ot} C = T X t=1 (o t p + r t + ↵p(d t − o t )) , s.t. o t + t X i=t−⌧ +1 r i ≥ d t , o t , r t 2 {0, 1, 2, . . . }, t = 1, . . . , T .
(1)Here, the first constraint ensures that all d t instances demanded at time t are accommodated, with o t on-demand instances and P t i=t−⌧ +1 r i reserved instances that remain active at time t. Note that instances that are reserved before time t − ⌧ + 1 have all expired at time t, where ⌧ is the reservation period.
For convenience, we set r t = 0 for all t  0.
The main challenge of problem (1) lies in its online setting.
Without knowledge of future demands, the online strategy may make purchase decisions that turn out later not to be optimal.
Below we clarify the performance metrics to measure how far away an online strategy may deviate from the optimal solution.
To measure the cost performance of an online strategy, we adopt the standard competitive analysis [18].
The idea is to bound the gap between the cost of an interested online algorithm and that of the optimal offline strategy.
The latter is obtained by solving problem (1) with the exact future demands d 1 , . . . , d T given a priori.
Formally, we have Definition 1 (Competitive analysis): A deterministic online reservation algorithm A is c-competitive (c is a constant) if for all possible demand sequencesd = {d 1 , . . . , d T }, we have C A (d)  c · C OPT (d) ,(2)where C A (d) is the instance acquisition cost incurred by algorithm A given input d, and C OPT (d) is the optimal instance acquisition cost given input d. Here, C OPT (d) is obtained by solving the instance reservation problem (1) offline, where the exact demand sequence d is assumed to know a priori.
A similar definition of the competitive analysis also extends to the randomized online algorithm A, where the decision making is drawn from a random distribution.
In this case, the LHS of (2) is simply replaced by E[C A (d)], the expected cost of randomized algorithm A given input d. (See [18] for a detailed discussion.)
Competitive analysis takes an optimal offline algorithm as a benchmark to measure the cost performance of an online strategy.
Intuitively, the smaller the competitive ratio c is, the more closely the online algorithm A approaches the optimal solution.
Our objective is to design optimal online algorithms with the smallest competitive ratio.We note that the instance reservation problem (1) captures the Bahncard problem [19] as a special case when a user demands no more than one instance at a time, i.e., d t  1 for all t.
The Bahncard problem models online ticket purchasing on the German Federal Railway, where one can opt to buy a Bahncard (reserve an instance) and to receive a discount on all trips within one year of the purchase date.
It has been shown in [19], [20] that the lower bound of the competitive ratio is 2 − ↵ and e/(e − 1 + ↵) for the deterministic and randomized Bahncard algorithms, respectively.
Because the Bahncard problem is a special case of our problem (1), we haveLemma 1: The competitive ratio of problem (1) is at least 2−↵ for deterministic online algorithms, and is at least e/(e− 1 + ↵) for randomized online algorithms.However, we show in the following that the instance reserving problem (1) is by no means a trivial extension to the Bahncard problem, mainly due to the time-multiplexing nature of reserved instances.
A natural way to extend the Bahncard solutions in [19] is to decompose problem (1) into separate Bahncard problems.
To do this, we introduce a set of virtual users indexed by 1, 2, . . . Whenever demand d t arises at time t, we view the original user as d t virtual users 1, 2, . . . , d t , each requiring one instance at that time.
Each virtual user then reserves instances (i.e., buy a Bahncard) separately to minimize its cost, which is exactly a Bahncard problem.However, such an extension is highly inefficient.
An instance reserved by one virtual user, even idle, can never be multiplexed with another, who still needs to pay for its own demand.
For a real user, this implies that it has to acquire additional instances, either on-demand or reserved, even if the user has already reserved sufficient amount of instances to serve its demand, which inevitably incurs a large amount of unnecessary cost.We learn from the above failure that instances must be reserved jointly and time multiplexed appropriately.
These factors significantly complicate our problem (1).
Indeed, as we see in the next section, even with full knowledge of the future demand, obtaining an optimal offline solution to (1) is computationally prohibitive.
In this section we consider the benchmark offline cost management strategy for problem (1), in which the exact future demands are given a priori.
The offline setting is an integer programming problem and is generally difficult to solve.
We derive the optimal solution via dynamic programming.
However, such an optimal offline strategy suffers from "the curse of dimensionality" [15] and is computationally intractable.We start by defining states.
A state at time t is defined as a (⌧ − 1)-tuple s t = (s t,1 , . . . , s t,⌧ −1 ), where s t,i denotes the number of instances that are reserved no later than t and remain active at time t + i, i = 1, . . . , ⌧ − 1.
We use a (⌧ − 1)-tuple to define a state because an instance that is reserved no later than t will no longer be active at time t+⌧ and thereafter.
Clearly, s t,1 ≥ · · · ≥ s t,⌧ −1 as reservations gradually expire.We make an important observation, that state s t only depends on states s t−1 at the previous time, and is independent of earlier states s t−2 , . . . , s 1 .
Specifically, suppose state s t−1 is reached at time t−1.
At the beginning of the next time t, r t new instances are reserved.
These newly reserved r t instances will add to the active reservations starting from time t, leading state s t−1 to transit to s t following the transition equations below: ⇢s t,i = s t−1,i+1 + r t , i = 1, . . . , ⌧ − 2 ; s t,⌧ −1 = r t .
(3)Let V (s t ) be the minimum cost of serving demands d 1 , . . . , d t up to time t, conditioned upon the fact that state s t is reached at time t.
We have the following recursive Bellman equations:V (s t ) = min st−1 � V (s t−1 ) + c(s t−1 , s t ) , t > 0,(4)where c(s t−1 , s t ) is the transition cost, and the minimization is over all states s t−1 that can transit to s t following the transition equations (3).
The Bellman equations (4) indicate that the minimum cost of reaching s t is given by the minimum cost of reaching a previous state s t−1 plus the transition cost c(s t−1 , s t ), minimized over all possible previous states s t−1 .
LetX + = max{0, X} .
(5)The transition cost is defined asc(s t−1 , s t ) = o t p + r t + ↵p(d t − o t ) ,(6)where r t = s t,⌧ −1 ,o t = (d t − r t − s t−1,1 ) + ,(7)and the transition from s t−1 to s t follows (3).
The rationale of (6) is straightforward.
By the transition equations (3), state s t−1 transits to s t by reserving r t = s t,⌧ −1 instances at time t. Adding the s t−1,1 instances that have been reserved before t, we have r t + s t−1,1 reserved instances to use at time t.
We therefore need o t = (d t − r t − s t−1,1 ) + on-demand instances at that time.The boundary conditions of Bellman equations (4) areV (s 0 ) = s 0,1 , for all s 0 = (s 0,1 , . . . , s 0,⌧ −1 ),(9)because an initial state s 0 indicates that a user has already reserved s 0,1 instances at the beginning and paid s 0,1 .
With the analyses above, we see that the dynamic programming defined by (3), (4), (6), and (9) optimally solves the offline instance reserving problem (1).
Therefore, it givesC OPT (d) in theory.Unfortunately, the dynamic programming presented above is computationally intractable.
This is because to solve the Bellman equations (4), one has to compute V (s t ) for all states s t .
However, since a state s t is defined in a highdimensional space -recall that s t is defined as a (⌧ − 1)-tuple -there exist exponentially many such states.
Therefore, looping over all of them results in exponential time complexity.
This is known as the curse of dimensionality suffered by highdimensional dynamic programming [15].
The intractability of the offline instance reservation problem (1) suggests that optimal cost management in IaaS clouds is in fact a very complicate problem, even if future demands can be accurately predicted.
However, we show in the following sections that it is possible to have online strategies that are highly efficient with near-optimal cost performance, even without any knowledge of the future demands.
In this section, we present a deterministic online reservation strategy that incurs no more than 2 − ↵ times the minimum cost.
As indicated by Lemma 1, this is also the best that one can expect from a deterministic algorithm.
We start off by defining a break-even point at which a user is indifferent between using a reserved instance and an on-demand instance.
Suppose an on-demand instance is used to accommodate workload in a time interval that spans a reservation period, incurring a cost c.
If we use a reserved instance instead to serve the same demand, the cost will be 1 + ↵c.
When c = 1/(1 − ↵), both instances cost the same, and are therefore indifferent to the user.
We hence define the break-even point asβ = 1/(1 − ↵) .
(10)Clearly, the use of an on-demand instance is well justified if and only if the incurred cost does not exceed the break-even point, i.e., c  β.
Our deterministic online algorithm is summarized as follows.
By default, all workloads are assumed to be operated with on-demand instances.
At time t, upon the arrival of demand d t , we check the use of on-demand instances in a recent reservation period, starting from time t − ⌧ + 1 to t, and reserve a new instance whenever we see an ondemand instance incurring more costs than the break-even point.
Algorithm 1 presents the detail.
1.
Let x i be the number of reserved instances at time i, Initially, x i 0 for all i = 0, 1, . . . 2.
Let I(X) be an indicator function where I(X) = 1 if X is true and I(X) = 0 otherwise.
Also let X + = max{X, 0}.
3.
Upon the arrival of demand d t , loop as follows: 4.
while pP t i=t−⌧ +1 I(d i > x i ) > β do 5.
Reserve a new instance: r t r t + 1.
Update the number of reservations that can be used in the future: x i x i + 1 for i = t, . . . , t + ⌧ − 1.
Add a "phantom" reservation to the recent period, indicating that the history has already been "processed":x i x i + 1 for i = t − ⌧ + 1, . . . , t − 1.
8.
end while 9.
Launch on-demand instances: o t (d t − x t ) + .
10.
tt + 1, repeat from 3.
Fig. 1 helps to illustrate Algorithm 1.
Whenever demand d t arises, we check the recent reservation period from time t − ⌧ + 1 to t.
We see that an on-demand instance has been used at time i if demand d i exceeds the number of reservations x i (both actual and phantom), i = t−⌧ +1, . . . , t.
The shaded area in Fig. 1 represents the use of an ondemand instance in the recent period, which incurs a cost ofp P t i=t−⌧ +1 I(d i > x i ).
If this cost exceeds the break-even point β (line 4 of Algorithm 1), then such use of an on-demand instance is not well justified: We should have reserved an instance before at time t−⌧ +1 and used it to serve the demand (shaded area) instead, which would have lowered the cost.
As a compensation for this "mistake," we reserve an instance at the current time t (line 5), and will have one more reservation to use in the future (line 6).
Since we have already compensated for a misuse of an on-demand instance (the shaded area), we add a "phantom" reservation to the history so that such a mistake will not be counted multiple times in the following rounds (line 7).
This leads to an update of the reservation number {x i } (see the bottom figure in Fig. 1).
Unlike the simple extension of the Bahncard algorithm described in Sec.
II-D, Algorithm 1 jointly reserves instances by taking both the currently active reservations (i.e., x t ) and the historic records (i.e., x i , i < t) into consideration (line 4), without any knowledge of the future.
We will see later in Sec.
VII that such a joint reservation significantly outperforms the Bahncard extension where instances are reserved separately.
The "trick" of Algorithm 1 is to make reservations "lazily": no instance is reserved unless the misuse of an on-demand instance is seen.
Such a "lazy behaviour" turns out to guarantee that the algorithm incurs no more than 2 − ↵ times the minimum cost.
Let A β denote Algorithm 1 and let OPT denote the optimal offline algorithm.
We now make an important observation, that OPT reserves at least the same amount of instances as A β does, for any demand sequence.Lemma 2: Given an arbitrary demand sequence, let n β be the number of instances reserved by A β , and let n OPT be the number of instances reserved by OPT.
Then n β  n OPT .
Lemma 2 can be viewed as a result of the "lazy behaviour" of A β , in which instances are reserved just to compensate for the previous "purchase mistakes."
Intuitively, such a conservative reservation strategy leads to fewer reserved instances.
The proof of Lemma 2, however, is tedious and is deferred to our technical report [21].
We are now ready to analyze the cost performance of A β , using the optimal offline algorithm OPT as a benchmark.Proposition 1: Algorithm 1 is (2 − ↵)-competitive.
Formally, for any demand sequence,C A β  (2 − ↵)C OPT ,(11)where C A β is the cost of Algorithm 1 (A β ), and C OPT is the cost of the optimal offline algorithm OPT.
Proof: Suppose A β (resp., OPT) launches o t (resp., o ⇤ t ) ondemand instances at time t. Let Od(A β ) be the costs incurred by these on-demand instances under A β , i.e., Od(A β ) = P T t=1 o t p.
We refer to Od(A β ) as the on-demand costs of A β .
Similarly, we define the on-demand costs incurred by OPT asOd(OPT) = P T t=1 o ⇤ t p. Also, let Od(A β \OPT) = P T t=1 (o t − o ⇤ t )+ p be the on-demand costs incurred in A β that are not incurred in OPT.
We seeOd(A β \OPT)  βn OPT(12)by noting the following two facts: First, demands P T t=1 (o t − o ⇤ t ) + are served by at most n OPT reserved instances in OPT.
Second, demands that are served by the same reserved instance in OPT incur on-demand costs of at most β in A β (by the definition of A β ).
We therefore bound Od(A β ) as follows:Od(A β )  Od(OPT) + Od(A β \OPT)  Od(OPT) + βn OPT .
(13)Let S = P T t=1 d t p be the cost of serving all demands with on-demand instances.
We bound the cost of OPT as follows:C OPT = Od(OPT) + n OPT + ↵(S − Od(OPT)) (14) ≥ Od(OPT) + n OPT + ↵βn OPT (15) ≥ n OPT /(1 − ↵) .
(16)Here, (15) holds because in OPT, demands that are served by the same reserved instance incur at least a break-even cost β when priced at an on-demand rate p.With (13) and (16), we bound the cost of A β as follows:C A β = Od(A β ) + n β + ↵(S − Od(A β ))  (1 − ↵)Od(A β ) + n OPT + ↵S(17) (1 − ↵)(Od(OPT) + βn OPT ) + ↵S + n OPT (18) = C OPT + n OPT (19)  (2 − ↵)C OPT .
(20)Here, (17) holds because n β  n OPT (Lemma 2).
Inequality (18) follows from (13), while (20) is derived from (16).
By Lemma 1, we see that 2 − ↵ is already the best possible competitive ratio for deterministic online algorithms, which implies that Algorithm 1 is optimal in a view of competitive analysis.Proposition 2: Among all online deterministic algorithms of problem (1), Algorithm 1 is optimal with the smallest competitive ratio of 2 − ↵.
As a direct application, in Amazon EC2 with reservation discount ↵ = 0.49 (see Table I), algorithm A β will lead to no more than 1.51 times the optimal instance purchase cost.Despite the already satisfactory cost performance offered by the proposed deterministic algorithm, we show in the next section that the competitive ratio may be further improved if randomness is introduced.
In this section, we construct a randomized online strategy that is a random distribution over a family of deterministic online algorithms similar to A β .
We show that such randomization improves the competitive ratio to e/(e − 1 + ↵) and hence leads to a better cost performance.
As indicated by Lemma 1, this is the best that one can expect without knowledge of future demands.We start by defining a family of algorithms similar to the deterministic algorithm A β .
Let A z be a similar deterministic algorithm to A β with β in line 4 of Algorithm 1 replaced by z 2 [0, β].
That is, A z reserves an instance whenever it sees an on-demand instance incurring more costs than z in the recent reservation period.
Intuitively, the value of z reflects the aggressiveness of a reservation strategy.
The smaller the z, the more aggressive the strategy.
As an extreme, a user will always reserve when z = 0.
Another extreme goes to z = β (Algorithm 1), in which the user is very conservative in reserving new instances.Our randomized online algorithm picks a z 2 [0, β] according to a density function f (z) and runs the resulting algorithm A z .
Specifically, the density function f (z) is defined asf (z) = ⇢ (1 − ↵)e (1−↵)z /(e − 1 + ↵), z 2 [0, β), δ(z − β) · ↵/(e − 1 + ↵), o.w.,(21)where δ(·) is the Dirac delta function.
That is, we pick z = β with probability ↵/(e − 1 + ↵).
It is interesting to point out that in other online rent-or-buy problems, e.g., [22], [20], [23], the density function of a randomized algorithm is usually continuous 1 .
However, we note that a continuous density function does not lead to the minimum competitive ratio in our problem.
Algorithm 2 formalizes the descriptions above.Algorithm 2 Randomized Online Algorithm1.
Randomly pick z 2 [0, β] according to a density function f (z) defined by (21) 2.
Run A zThe rationale behind Algorithm 2 is to strike a suitable balance between reserving "aggressively" and "conservatively."
Intuitively, being aggressive is cost efficient when future demands are long-lasting and stable, while being conservative is efficient for sporadic demands.
Given the unknown future, the algorithm randomly chooses a strategy A z , with an expectation that the incurred cost will closely approach the ex post minimum cost.
The following theorem shows that the choice of f (z) in (21) leads to the optimal competitive ratio e/(e − 1 + ↵).
The proof is given in [21].
Proposition 3: Algorithm 2 is e/(e − 1 + ↵)-competitive.
Formally, for any demand sequence,E[C Az ]  e e − 1 + ↵ C OPT ,(22)where the expectation is over z between 0 and β according to density function f (z) defined in (21).
By Lemma 1, we see that no online randomized algorithm is better than Algorithm 2 in terms of the competitive ratio.Proposition 4: Among all online randomized algorithms of problem (1), Algorithm 2 is optimal with the smallest competitive ratio e/(e − 1 + ↵).
As a direct application, in Amazon EC2 with reservation discount ↵ = 0.49 (see Table I), the randomized algorithm will lead to a competitive ratio of 1.23, compared with the 1.51-competitiveness of the deterministic alternative.
In the previous sections, our discussions focus on the extreme cases, with either full future demand information (i.e., the offline case in Sec.
III) or no a priori knowledge of the future (i.e., the online case in Sec.
IV and V).
In this section, we consider the middle ground in which short-term demand predictions are reliable.
For example, websites typically see diurnal patterns exhibited on their workloads, based on which it is possible to have a demand prediction window that is weeks into the future.
Both our online algorithms can be easily extended to utilize these knowledge of future demands when making reservation decisions.We begin by formulating the instance reservation problem with limited information of future demands.
Let w be the prediction window.
That is, at any time t, a user can predict its future demands d t+1 , . . . , d t+w in the next w hours.
Since only short-term predictions are reliable, one can safely assume that the prediction window is less than a reservation period, i.e., w < ⌧ .
The instance reservation problem resembles the online reservation problem (1), except that the instance purchase decisions made at each time t, i.e., the number of reserved instances (r t ) and on-demand instances (o t ), are based on both history and future demands predicted, i.e., d 1 , . . . , d t+w .
The competitive analysis (Definition 1) remains valid in this case.The Deterministic Algorithm: We extend our deterministic online algorithm as follows.
As before, all workloads are by default served by on-demand instances.
At time t, we can predict the demands up to time t + w. Unlike the online deterministic algorithm, we check the use of on-demand instances in a reservation period across both history and future, starting from time t + w − ⌧ +1 to t + w.
A new instance is reserved at time t whenever we see an on-demand instance incurring more costs than the break-even point β and the currently effective reservations are less than the current demand d t .
Algorithm 3, also denoted by A w β , shows the details.
Reserve a new instance: r t r t + 1.
Update the number of reservations that can be used in the future: x i x i + 1 for i = t, . . . , t + ⌧ − 1.
Add a "phantom" reservation to the history, indicating that the history has already been "processed":x i x i + 1 for i = t + w − ⌧ + 1, . . . , t − 1.
7.
end while 8.
Launch on-demand instances: o t (d t − x t ) + .
9.
t t + 1, repeat from 2.
The Randomized Algorithm: The randomized algorithm can also be constructed as a random distribution over a family of deterministic algorithms similar to A w β .
In particular, let A w z be similarly defined as algorithm A w β with β replaced by z 2 [0, β] in line 3 of Algorithm 3.
The value of z reflects the aggressiveness of instance reservation.
The smaller the z, the more aggressive the reservation strategy.
Similar to the online randomized, we introduce randomness to strike a good balance between reserving aggressively and conservatively.
Our algorithm randomly picks z 2 [0, β] according to the same density function f (z) defined by (21), and runs the resulting algorithm A w z .
Algorithm 4 formalizes the description above.
It is easy to see that both the deterministic and the randomized algorithms presented above improve the cost performance of their online counterparts, due to the knowledge of future demands.
Therefore, we have Proposition 5 below.
We will quantify their performance gains via trace-driven simulations in the next section.Proposition 5: Algorithm 3 is (2 − ↵)-competitive, and Algorithm 4 is e/(e − 1 + ↵)-competitive.
So far, we have analyzed the cost performance of the proposed algorithms in a view of competitive analysis.
In this section, we evaluate their performance for practical cloud users via simulations driven by a large volume of real-world traces.
Long-term user demand data in public IaaS clouds are often confidential: no cloud provider has released such information so far.
For this reason, we turn to Google cluster-usage traces that were recently released in [16].
Although Google is not a public IaaS cloud, its cluster-usage traces record the computing demands of its cloud services and Google engineers, which can represent the computing demands of IaaS users to some degree.
The dataset contains 40 GB of workload resource requirements (e.g., CPU, memory, disk, etc.) of 933 users over 29 days in May 2011, on a cluster of more than 11K Google machines.Demand Curve: Given the workload traces of each user, we ask the question: How many computing instances would this user require if it were to run the same workload in a public IaaS cloud?
For simplicity, we set an instance to have the same computing capacity as a cluster machine, which enables us to accurately estimate the run time of computational tasks by learning from the original traces.
We then schedule these tasks onto instances with sufficient resources to accommodate their requirements.
Computational tasks that cannot run on the same server in the traces (e.g., tasks of MapReduce) are scheduled to different instances.
In the end, we obtain a demand curve for each user, indicating how many instances this user requires in each hour.
Fig. 2 illustrates such a demand curve for a user.User Classification: To investigate how our online algorithms perform under different demand patterns, we classify all 933 users into three groups by the demand fluctuation level measured as the ratio between the standard deviation σ and the mean µ.
Specifically, Group 1 consists of users whose demands are highly fluctuating, with σ/µ ≥ 5.
As shown in Fig. 3 (circle 'o'), these demands usually have small means, which implies that they are highly sporadic and are best served with ondemand instances.
Group 2 includes users whose demands are less fluctuating, with 1  σ/µ < 5.
As shown in Fig. 3 (cross 'x'), these demands cannot be simply served by on-demand or reserved instances alone.
Group 3 includes all remaining users with relatively stable demands (0  σ/µ < 1).
As shown in Fig. 3 (plus '+'), these demands have large means and are best served with reserved instances.
Our evaluations are carried out for each user group.Pricing: Throughout the simulation, we adopt the pricing of Amazon EC2 standard small instances with the ondemand rate $0.08, the reservation fee $69, and the discount rate $0.039 (Linux, US East, 1-year light utilization).
Since the Google traces only span one month, we proportionally shorten the on-demand billing cycle from one hour to one minute, and the reservation period from 1 year to 6 days (i.e., 24 ⇥ 365 = 8760 minutes = 6 days) as well.
We start by evaluating the performance of online algorithms without any a priori knowledge of user demands.Benchmark Online Algorithms: We compare our online deterministic and randomized algorithms with three benchmark online strategies.
The first is All-on-demand, in which a user never reserves and operates all workloads with ondemand instances.
This algorithm, though simple, is the most common strategy in practice, especially for those users with time-varying workloads [11].
The second algorithm is Allreserved, in which all computational demands are served via reservations.
The third online algorithm is the simple extension to the Bahncard algorithm proposed in [19] (see Sec.
II-D), and is referred to as Separate because instances are reserved separately.
All three benchmark algorithms, as well as the two proposed online algorithms, are carried out for each user in the Google traces.
All the incurred costs are normalized to All-on-demand.
Cost Performance: We present the simulation results in Fig. 4, where the CDF of the normalized costs are given, grouped by users with different demand fluctuation levels.
We see in Fig. 4a that when applied to all 933 users, both the deterministic and randomized online algorithms realize significant cost savings compared with all three benchmarks.In particular, when switching from All-on-demand to the proposed online algorithms, more than 60% users cut their costs.
About 50% users save more than 40%.
Only 2% incur slightly more costs than before.
For users who switch from All-reserved to our randomized online algorithms, the improvement is even more substantial.
As shown in Fig. 4a, cost savings are almost guaranteed, with 30% users saving more than 50%.
We also note that Separate, though generally outperforms All-on-demand and All-reserved, incurs more costs than our online algorithms, mainly due to its ignorance of reservation correlations.
We next compare the cost performance of all five algorithms at different demand fluctuation levels.
As expected, when it comes to the extreme cases, All-on-demand is the best fit for Group 1 users whose demands are known to be highly busty and sporadic (Fig. 4b), while All-reserved incurs the least cost for Group 3 users with stable workloads (Fig. 4d).
These two groups of users, should they know their demand patterns, would have the least incentive to adopt advanced instance reserving strategies, as naively switching to one option is already optimal.
However, even in these extreme cases, our online algorithms, especially the randomized one, remain highly competitive, incurring only slightly higher cost.However, the acquisition of instances is not always a blackand-white choice between All-on-demand and All-reserved.
As we observe from Fig. 4c, for Group 2 users, a more intelligent reservation strategy is essential, since naive algorithms, either All-on-demand or All-reserved, are always highly risky and can easily result in skyrocketing cost.
Our online algorithms, on the other hand, become the best choices in this case, outperforming all three benchmark algorithms by a significant margin.Table II summarizes the average cost performance for each user group.
We see that, in all cases, our online algorithms remain highly competitive, incurring near-optimal costs for a user.
While our online algorithms perform sufficiently well without knowledge of future demands, we show in this section that more cost savings are realized by their extensions when shortterm demand predictions are reliable.
In particular, we consider three prediction windows that are 1, 2, and 3 months into the future, respectively.
For each prediction window, we run both the deterministic and randomized extensions (i.e., Algorithm 3 and 4) for each Google user in the traces, and compare their costs with those incurred by the online counterparts without Cost performance of the deterministic algorithm with various prediction windows.
All costs are normalized to the online deterministic algorithm (Algorithm 1) without any future information.future knowledge (i.e., Algorithm 1 and 2).
Figs. 5 and 6 illustrate the simulation results, where all costs are normalized to Algorithm 1 and 2, respectively.As expected, the more information we know about the future demands (i.e., longer prediction window), the better the cost performance.
Yet, the marginal benefits of having long-term predictions are diminishing.
As shown in Figs. 5a and 6a, long prediction windows will not see proportional performance gains.
This is especially the case for the randomized algorithm, in which knowing the 2-month future demand a priori is no different from knowing 3 months beforehand.Also, we can see in Fig. 5b that for the deterministic algorithm, having future information only benefits those users whose demands are stable or with medium fluctuation.
This is because the deterministic online algorithm is almost optimal for users with highly fluctuating demands (see Fig. 4b), leaving no space for further improvements.
On the other hand, we see in Fig. 6b that the benefits of knowing future demands are consistent for all users with the randomized algorithm.
On-demand and reserved instances are the two most prominent pricing options that are widely supported in leading IaaS clouds [3], [4], [5].
Many case studies [11] show that effectively combining the use of the two instances leads to a significant cost reduction.There exist some works in the literature, including both algorithm design [6], [7], [24] and prototype implementation [8], focusing on combining the two instance options in a cost efficient manner.
All these works assume, either explicitly or implicitly, that workloads are statistically stationary in the long-term future and can be accurately predicted a priori.
However, it has been observed that in real production applications, ranging from enterprise applications to large ecommerce sites, workload is highly variable and statistically non-stationary [9], [10].
Furthermore, most workload prediction schemes, e.g., [25], [26], [27], are only suitable for predictions over a very short term (from half an hour to several hours).
Such limitation is also shared by general predicting techniques, such as ARMA [28] and GARCH models [29].
Some long-term workload prediction schemes [30], [31], on the other hand, are reliable only when demand patterns are easy to recognize with some clear trends.
Even in this case, the prediction window is at most days or weeks into the future [30], which is far shorter than the typical span of a reservation period (at least one year in Amazon EC2 [3]).
All these factors significantly limit the practical use of existing works.Our online strategies are tied to the online algorithm literature [18].
Specifically, our instance reservation problem captures a class of rent-or-buy problems, including the ski rental problem [22], the Bahncard problem [19], and the TCP acknowledgment problem [20], as special cases when a user demands no more than one instance at a time.
In these problems, a customer obtains a single item either by paying a repeating cost (renting) per usage or by paying a one-time cost (buying) to eliminate the repeating cost.
A customer makes one-dimensional decisions only on the timing of buying.
Our problem is more complicated as a user demands multiple instances at a time and makes two-dimensional decisions on both the timing and quantity of its reservation.
A similar "multi-item rent-or-buy" problem has also been investigated in [23], where a dynamic server provisioning problem is considered and an online algorithm is designed to dynamically turn on/off servers to serve time-varying workloads with a minimum energy cost.
It is shown in [23] that, by dispatching jobs to servers that are idle or off the most recently, the problem reduces to a set of independent ski rental problems.
Our problem does not have such a separability structure and cannot be equivalently decomposed into independent singleinstance reservation (Bahncard) problems, mainly due to the possibility of time multiplexing multiple jobs on the same reserved instance.
It is for this reason that the problem is challenging to solve even in the offline setting.Besides instance reservation, online algorithms have also been applied to reduce the cost of running a file system in the cloud.
The recent work [32] introduces a constrained skirental problem with extra information of query arrivals (the first or second moment of the distribution), proposing new online algorithms to achieve improved competitive ratios.
[32] is orthogonal to our work as it takes advantage of additional demand information to make rent-or-buy decisions for a single item.
Acquiring instances at the cost-optimal commitment level for time-varying workloads is critical for cost management to lower IaaS service costs.
In particular, when should a user reserve instances, and how many instances should it reserve?
Unlike existing reservation strategies that require knowledge of the long-term future demands, we propose two online algorithms, one deterministic and another randomized, that dynamically reserve instances without knowledge of the future demands.
We show that our online algorithms incur nearoptimal costs with the best possible competitive ratios, i.e., 2 − ↵ for the deterministic algorithm and e/(e − 1 + ↵) for the randomized algorithm.
Both online algorithms can also be easily extended to cases when short-term predictions are reliable.
Large-scale simulations driven by 40 GB Google cluster-usage traces further indicate that significant cost savings are derived from our online algorithms and their extensions, under the prevalent Amazon EC2 pricing.One of the issues that we have not discussed in this paper is the combination of different types of reserved instances with different reservation periods and utilization levels.
For example, Amazon EC2 offers 1-year and 3-year reserved instances with light, medium, and high utilizations.
Effectively combining these reserved instances with on-demand instances could further reduce instance acquisition costs.
We note that when a user demands no more than one instance at a time and the reservation period is infinite, the problem reduces to Multislope Ski Rental [33].
However, it remains unclear if and how the results obtained for Multislope Ski Rental could be extended to instance acquisition with multiple reservation options.
