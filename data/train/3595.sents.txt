Traditionally, training machine learning models requires all data to be in the same place accessible to a trusted third party.
However, privacy concerns and legislations such as General Data Protection Regulation (GDPR) [16] and Health Insurance Portability and Accountability Act (HIPAA) [14] inhibit transmitting data to a central place resulting in the impossibility of training machine learning models using this traditional technique.
Despite these limitations, in some cases data owners would benefit from collaboratively training a model.
To address this requirement, very recently Federated Learning (FL) has emerged as an alternative way to do collaborative model train models without sharing the training data [12] [17] [18].
In FL, each data owner, party, maintains its own data locally and engage in a collaborative learning procedure where only model updates are shared with an aggregator.
Note that the aggregator does not have access to the data of any of the parties.
Through FL, parties with relatively small datasets can learn more accurate models than they would if they had only used their own data.
Examples of such scenario include a large number of individual parties providing personal data to smart phone apps and a relatively small number of competing companies within the same domain training a single model.
A concrete scenario where FL has been used to collaboratively train models include Google's key board predictive model [6].
In these scenarios, parties may be very diverse.
This diversity largely differentiates FL from traditional distributed learning systems such as [8,11] where a datacenter is available for careful management.
Most of the times, the data parties involved in FL training have diversified training sets that may vary in size, computing power, and network bandwidth.
These differences impact the FL process as we empirically demonstrate in our experimental section.In the following, we first overview existing FL approaches.
We show that stragglers are not considered by existing techniques.
Then, through a preliminary study, we demonstrate the potential impact of stragglers on FL process and finally conclude with a discussion of the research problems.
Existing FL approaches do not account for the resource and dataset heterogeneities [7,10,12], nor are they straggler-aware.
In particular, there are two main approaches in training a FL model: synchronous and asynchronous FL.In synchronous FL, a fixed number of data parties are queried in each learning epoch to ensure performance and data privacy.
Recent synchronous FL algorithms focus on reducing the total training time without considering the straggler parties.
For example, [12] proposes to reduce network communication costs by performing multiple SGD (stochastic gradient descent) updates locally and batching data parties.
[7] reduces communication bandwidth consumption by structured and sketched updates.
Moreover, [9] exploits randomized technique to reduce communication rounds.
FedCS [13] proposes to solve data party selection issue via a deadline-based approach that filters out slowly-responding parties.
However, FedCS does not consider how this approach effects the contributing factors of straggler parties in model training.
Similarly, [19] proposes a FL algorithm for the use case of running FL on resource constrained devices.
However, they do not aim to handle straggler parties and treat all parties as resource constrained.
In contrast, we focus on scenarios where resource constrained devices are paired with high resource devices to perform FL.Most asynchronous FL algorithms work only for convex loss and do not allow parties to drop-out.
For instance, [15] provides performance guarantee only for convex loss functions with bounded delay assumption.
Similarly, [3,10] allow uniform sampling of the data parties and provide performance guarantee for convex loss functions.
Furthermore, the comparison of synchronous and asynchronous methods of distributed gradient descent [4] suggest that FL should use the synchronous approach, because it is more efficient than the asynchronous approaches [12,13].
We conduct an experimental study on AWS EC2 to quantify the impact of resource and dataset heterogeneity on training time of FL.
We use a multi-party TensorFlow [2] setup to emulate a FL environment following the configuration settings used in [5], with δ as 0.001, ε as 8, and σ in the Gaussian mechanism as 1.0.
We deploy 20 data parties to emulate a randomly picked 100-party FL environment, where each party is running inside of a Docker container.
The training process terminates until the accumulated privacy cost exceeds the privacy bound (δ).
All the containerized parties are running on a single EC2 virtual machine (VM) instance of m4.10xlarge with 40 vCPUs and 160 GiB memory.
We train a CNN (Convolutional Neural Network) model on the MNIST dataset [1], which contains 60, 000 28 grayscale images of ten handwritten digits.
To emulate a realistic imbalanced party data distribution, we use Non-IID in data selection, where each party randomly selects 5 digit categories and then performs the image sampling from these 5 categories.
The CNN model consists of two CNN layers and one MaxPooling layer.
We use a filter size of 3 for the CNN layers and 2 for the MaxPooling layer.
We also add two drop-out layers with a dropping out rate of 0.25 and 0.5, respectively.
We use Adadelta for the optimizer, and accuracy as the training evaluation metric.
We train the model with 8 learning epoches and measure the training time for each epoch.Resource Heterogeneity First, we explore the impact of CPU resource heterogeneity on training time.
Table 1 summarizes the parties and CPU resource distributions of 5 test groups.
We reduce the total amount of CPU resources from Test 1 to 5, and within each test, each party gets an equal share of the available CPU resource.
For example, in Test 1, 4 parties get allocated 16 CPU cores with 4 cores per party.
Within each test group, we conduct 4 tests each with varied dataset size (sizing from 500 -5000 data points).
Data Heterogeneity We next quantify the impact of data heterogeneity on training time.
We deploy 14 data parties, each owning a different dataset size (varying from 100-5000 data points) but with the same amount of CPU resources (i.e., 1 CPU core), to concurrently training the model.
As shown in Figure 2, the training time gets linearly increased as the dataset size gets bigger.
This demonstrates that data heterogeneity can significantly impact the FL system's training time.
Our preliminary results imply that the straggler issues can be severe under a complicated and heterogeneous FL environment.
We believe that our paper will lead to discussions on the following aspects, which are the focus of our ongoing research: P1: How to classify parties based on their response time and then use this information for our advantage without affecting the FL process?
A naive solution can lead to misrepresentation of data, because resource constraints may be correlated with quantity/quality of data.
P2: How to incorporate data of each party in the FL process without worrying about stragglers?
This problem is challenging because we need to make sure we do not over include or exclude certain data parties in FL process.
We should be able to provide performance guarantee for general machine learning models and algorithms.
P3: How to identify drop-out parties and mitigate the effect of drop-out data parties without affecting the ML process?
Existing approaches cannot identify drop-out parties dynamically during the FL process, and no effective method has been proposed to mitigate the information loss when drop-out happens.
