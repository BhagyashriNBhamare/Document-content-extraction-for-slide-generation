We have created a iSCSI SAN architecture which permits maintenance of network components without any downtime, thus improving our ability to maintain the SAN beyond iSCSI's mediocre reputation.
We currently use this system to provide web-­-based services for all of Answers.com.
During development of this architecture we learned three important lessons: Packet loss/congestion is absolutely fatal.
Network design must be smart about Spanning Tree events, and a separate network, not separate VLANs, is required.
Forethought in design creates a system that is highly maintainable, permitting an "isolate and swap" methodology for upgrades and maintenance.
Answers.com rolled out a cost effective iSCSI SAN solution from LeftHand Networks (now a part of HP's StorageWorks division) in 2008 as part of our first data-­-center deployment.
It was designed for modular growth, scalability, and all the usual checkbox features one would expect.
However, iSCSI does not have a reputation for being easy to administer or highly available.
We sought to overcome those issues.
Immediately we noticed, while we were still in the build-­-out stage of the data-­-center, that iSCSI was extremely sensitive to even the slightest hiccup in its ability to get packets from Point-­-A to Point-­-B.
Now, this may sound silly, but we had no idea going into this exactly how sensitive it would be to network issues.
If we connected a new set of blade switches, for instance as we built out a new cabinet of blades, the resulting Spanning Tree Protocol (STP) reconvergence -which might last only a small fraction of a second -would often cause iSCSI to give up and put all of the LUNs into read-­-only mode, effectively crashing their OSes.
Every time we added a new blade chassis (which, during build-­-out was happening quite itself almost entirely to the blade infrastructure, so having the SAN VLAN present on the cabinet access switches (and subject to their STP events) was largely counterproductive.
We decided to do what we should have done in the first place, and create a separate, electrically isolated, network for the SAN.
We would install a new pair of "SANCore" switches, bringing all the Bay 3 and Bay 4 blade-­-switches into those SANCore switches.
For the few non-­-blade SAN clients, we would backhaul their connections directly into the SANCores.
The practical upshot of this would be that there would only be one "A/B" connection in the entire SAN network, the one between the SANCores.
This meant that STP could be completely disabled, as there would never be a potential loop in the environment again (short of someone accidentally creating one, but in our environment of mostly-­-blade-­-switches, that was unlikely).
Our network infrastructure's robust design lent itself to a "isolate and swap" process that has worked well for us a number of times now, but got its first real test during the move to the new SANCore switches.
The process evolved organically through repeated scribblings on an office whiteboard, and while it seems simple and intuitively obvious in hindsight, every time we discuss it with our peers, the level of redundancy it provides always seems to come as a surprise to them.First, we disconnected the SAN modules from the B-­-side core switch, forcing them to use the A-­-side core.
Then we disabled the B-­-side network completely on all blade and cabinet switches, causing downstream devices to only use their A-­-side NICs.
This isolated the B-­-side Core, allowing us to move all the physical connections to the SAN from the "Core-­-B" switch to the "SANCore-­-B" switch (which was preconfigured to also have all its ports in the disabled state, so no devices would try to talk through it until we were ready for them to do so).
The "SANCore-­-B" switch was then temporarily connected to the "Core-­-A" switch.
Once the connections were all complete, we turned the B-­-side ports back up, and everything was normal, with no interruptions.
After taking a break (this is an excellent place for what we referred to as the "pre-­-programmed 30 minute hold"), we repeated the process for the other side, to install the SANCore-­-A switch, and then finally simply removed the temporary cabling that connected SANCore-­-B and Core-­-A (since there was no longer anything SAN related connected to either of the Core-­-A/B switches).
We used this same "isolate and swap" process a couple other times as we have grown to replace and upgrade our SANCore switching infrastructure, while we settled on what hardware we would be using.
I knew we were onto something when we would tell people we had hot-­-swapped out our core-­-switching infrastructure for our iSCSI SAN without causing a single hiccup in the iSCSI LUNs.We've even used similar processes to replace our LAN-­-side core switches, although that environment did trigger occasional STP reconvergences, but this was not an issue as standard TCP/IP traffic was more forgiving of half-­-second or so of packet-­-loss.
Cabinet Equipment Core Equipment Blade Enclosure Equipment SANCoreDoes it always work?
It can, if you've prepared your change procedure exhaustively beforehand and follow it religiously.
A clear set of step-­-by-­-step procedures, which you've designed while standing in front of a whiteboard with one or more of your peers, is essential to success.
At every step in the process, you should determine both "Are there any sort of events that trigger when I make this change" (uplink failure detection triggers, STP events, etc.) as well as, "Trace the path that every device will use to try and talk to the network", and ensure that after each step you haven't accidentally disconnected a consumer from its provider.
Most importantly, follow those procedures!
Don't race through your maintenance window assuming that you remember the process, or that you remember the repercussions of various actions.
Inevitably, you'll misremember and the results are disastrous.You invested the time in the room with the whiteboard for a reason.In conclusion, we were able to construct a fully fault-­-tolerant iSCSI SAN.
The key to this redundancy is to have a flat, separate network with redundant hardware.
The solution has scaled, for us, to several dozen connected devices, and should scale to significantly larger, but that has not been tested.
The design works very well for us, and should be useable by other sites of similar size, as well as larger sites potentially.
The big win for us, obviously, is the ability to remove key network hardware for maintenance, upgrades, or even forklift-­-upgrade, without causing any sort of outage.
This "isolate and swap" process was a significant win for ease of maintenance.
