We combine compositional reasoning and reachability analysis to formally verify the safety of a recent cache coherence protocol.
The protocol is a detailed implementation of token coherence, an approach that decouples correctness and performance.
First, we present a formal and abstract specification that captures the safety substrate of token coherence , and highlights the symmetry in states of the cache controllers and contents of the messages they exchange.
Then, we prove that this abstract specification is coherent, and check whether the implementation proposed by the protocol designers is a refinement of the abstract specification.
Our refinement proof is parametric in the number of cache controllers, and is compositional as it reduces the refinement checks to individual controllers using a specialized form of assume-guarantee reasoning.
The individual refinement obligations are discharged using refinement maps and reachability analysis.
While the formal proof justifies the intuitive claim by the designers about the ease of verifiability of token coherence, we report on several bugs in the implementation, and accompanying modifications, that were missed by extensive prior simulations.
Shared memory multiprocessors have become the most important architecture used for commercial and scientific workloads.
Such systems use hardware cache coherence protocols to create the illusion of a single, shared memory without caches.
These protocols are important factors of the overall system performance, and numerous optimizations contribute to their complexity.
Since hard-to-cover race conditions elude simulations of the protocols, formal methods are often employed to verify their correctness.Token Coherence is a new approach to cache coherence protocols that decouples correctness requirements from performance choices, claiming to improve both performance and verifiability [22].
Separate correctness mechanisms ensure safety and liveness.
Safety is achieved by token counting: per memory location, 1.
We present a formal specification of the safety substrate of token coherence.This abstract protocol is based on rewrite rules and multisets, and expresses the symmetry between components and messages.
It applies to arbitrary network topologies, cache numbers, and even cache hierarchies.
2.
We prove manually that the abstract protocol is safe (i.e. coherent).
The verification problem is thus reduced to checking that the implementation correctly refines the abstract protocol.
3.
We prove that the refinement can be verified for each component individually, by replacing its context with an abstraction.
We prove that this decomposition into local refinement obligations is sound, using a variant of assume-guarantee reasoning based on contextual refinement, and performing an induction on the number of caches.
4.
We discharge the local refinement obligations with the conventional model checker Murϕ [12,11].
To obtain the models, we manually translate, abstract and annotate the implementation code.
This procedure reduces the refinement checking to a reachability problem, which Murϕ solves by enumerative state space search.Even though the protocol implementation had been extensively simulated prior to this work, we discovered a few bugs, and were able to fix them quickly with the help of counterexamples produced by the model checker.
The compositional refinement method proved to be effective in avoiding the state space explosion problem [16] which is commonly encountered in system-level models [28].
Because of the page limit, we had to omit most proofs.
A more complete version of this article can be found online [7].
Prior work on formal verification of cache coherence varies in (1) the protocol complexity and level of detail (2) the coverage achieved (safety, liveness, parametric systems) (3) the underlying tools (enumerative or symbolic model checkers, decision procedures, theorem provers), (4) reduction techniques (symmetry, abstraction, compositional verification), and (5) degree of automation.We refer to Pong and Dubois [28] for a general survey, and to various illustrative efforts [23,27,14,3].
Our proof methodology modifies and combines a variety of ideas in the formal verification literature.
These include assume-guarantee reasoning for compositional verification (c.f. [1,8,2,25]), structural induction for proving properties for arbitrary number of processes (c.f. [19,9,15,13,10,4]), data abstraction (c.f. [32,17]), use of term rewrite systems for hardware verification [5], and proving refinement using reachability analysis (c.f. [18]).
In this section, we define the process model and introduce our assume-guarantee proof rules.
We chose to define the process model from scratch, so to keep it concise and self-contained, and to obtain the desired combination of features.
Except for the specialized definition of contextual refinement, all concepts (traces, composition, refinement) are standard and appear in many variations and combinations in the process algebra literature [29].
A process is defined as the set of its traces, which are finite words over an alphabet Σ of events.
Σ is considered fixed and common to all processes.
We further partition Σ = Σ e ∪Σ c into disjoint subclasses: Σ e contains events that are visible to external observers of the system only, while Σ c describes synchronous communication events.
Matching events in Σ c (e.g. sending and receiving of a message) are denoted σ and σ.
Definition 2.1.
A process P over Σ is a non-empty prefix-closed language; i.e. P ⊂ Σ * , P 񮽙 = ∅ and for all u, v ∈ Σ * : uv ∈ P ⇒ u ∈ P .
A process P refines a process Q, written P 񮽙 Q, iff P ⊂ Q.
A process P is closed if P ⊂ Σ * e .
The refinement relation 񮽙 is a complete partial order on the processes.
The bottom (silent) process {񮽙} has but one trace: the empty string.
The top (universal) process Σ * includes all possible traces.When composing processes, we merge their traces by interleaving their events and hiding mutual communication.Definition 2.2.
Let u, v, w ∈ Σ * be traces.
We define the relation u | v 񮽙 w (speak: u, v can combine to form w) by the following inference rules:񮽙 | 񮽙 񮽙 񮽙 (epsilon) u | v 񮽙 w σ ∈ Σ c uσ | vσ 񮽙 w (communication) u | v 񮽙 w σ ∈ Σ uσ | v 񮽙 wσ (l-event) u | v 񮽙 w σ ∈ Σ u | vσ 񮽙 wσ (r-event)Example 2.3.
Let Σ e = {a, b, c, d} and Σ c = {e, e}.
Then we haveab | cd 񮽙 acbd ab | cd 񮽙 abcd ae | eb 񮽙 ab ae | eb 񮽙 aeeb but not ae | eb 񮽙 ba.
Definition 2.4.
Let P , Q be processes.
Then P | Q .
= {w ∈ Σ * | ∃u ∈ P : ∃v ∈ Q : u | v 񮽙 w}.
Composition is commutative and associative.
Composition does not restrict its components: for processes P, Q we always have P 񮽙 P | Q.
This same style of communication is used by CCS [26].
Refinement is preserved by composition: if P 񮽙 񮽙 P , then P 񮽙 | Q 񮽙 P | Q.
We can use this fact to prove that a system implementation refines its specificationP 񮽙 | Q 񮽙 񮽙 P | Q(1)from the simpler, local refinement conditionsP 񮽙 񮽙 P and Q 񮽙 񮽙 Q .
(2)However, this method is not very powerful, because the refinements (2) do often not hold because of implicit assumptions on the context.
Assume-guarantee reasoning remedies this shortcoming.
We provide the context as an explicit subscript to the refinement relation, enabling us to conclude (1) fromP 񮽙 񮽙 Q P and Q 񮽙 񮽙 P Q .
(3)Most process models used for compositional refinement of hardware [2,24] can express the contextual refinement P 񮽙 񮽙 Q P directly as P 񮽙 񮽙 Q 񮽙 P (using synchronous parallel composition).
The same does not work in our context (as exemplified by the observation 5 below), so we use a direct definition instead.Definition 2.5 (Contextual refinement).
Let P, P 񮽙 , C be processes.
Then P 񮽙 is said to refine P in context C, written P 񮽙 񮽙 C P , iff for all traces u ∈ P 񮽙 the following condition holds: if there is a trace v ∈ C such that u ↑ Σ c = v ↑ Σ c (i.e. the communication events in u, v match up), then u ∈ P .
Intuitively, we require that all behaviors of P 񮽙 that are actually possible within an environment that adheres to C are allowed by P .
The following observations provide insight about contextual refinement.1.
For any process C, 񮽙 C is a pre-order on processes.2.
If P 񮽙 񮽙 C P , and C 񮽙 񮽙 C, then P 񮽙 񮽙 C 񮽙 P .
3.
Refinement in a universal context corresponds to regular refinement:P 񮽙 񮽙 Σ * P ⇔ P 񮽙 񮽙 P .
4.
Refinement in a silent context corresponds to refinement of closed processes:P 񮽙 񮽙 {񮽙} P ⇔ (P 񮽙 ∩ Σ * e ) 񮽙 (P ∩ Σ * e ) 5.
The refinement P 񮽙 | C 񮽙 {񮽙} P | C does not imply P 񮽙 񮽙 C P , because the traces of P 񮽙 | C do not indicate what mutual communication takes place.However, the converse always holds.To avoid circularity in the assume-guarantee reasoning, we conservatively require that the specification processes can always engage in a subset of communication events Σ r ⊂ Σ c that is sufficiently large, i.e. Σ r ∪ Σ r = Σ c ; in our case, we will take care of this requirement by having specification processes accept any message at any time 1 .
We use the following definition to formalize this property of processes.
Definition 2.6.
Let P be a process over Σ, and Σ r ⊂ Σ be an event subset.
P is called Σ r -enabled iff ∀u ∈ P : ∀σ ∈ Σ r : uσ ∈ P .
We now give the two proof rules for compositional refinement.
The first rule is simpler, but restricted to two components.
The second rule is a generalization suited for induction.
Σ = Σ e ∪ Σ c .
Let Σ r ⊂ Σ c such that Σ r ∪ Σ r = Σ c .
Then the following proof rules are sound:P 񮽙 񮽙 Q P P,Qare Σ r -enabled Q 񮽙 񮽙 P Q P 񮽙 | Q 񮽙 񮽙 {񮽙} P | Q P 񮽙 񮽙 Q|C P P,Qare Σ r -enabled Q 񮽙 񮽙 P |C Q P 񮽙 | Q 񮽙 񮽙 C P | QFor example, consider again the local refinement obligations (3).
Suppose that the specification processes P, Q can receive messages at any time.
We can then apply the first proof rule to conclude that P 񮽙 | Q 񮽙 refines P | Q, if there is no external communication, i.e., there are no other components in the system.
In this section, we introduce a formal specification of the safety substrate of token coherence.
This abstract protocol is a generalization of the MOESI token counting rules in Martin's dissertation [20].
We then justify it's use as a specification, by proving that it is coherent, and with it any implementation that refines it.
Cache coherence describes the contract between the memory system and the processor in a shared-memory multiprocessor.
It is typically established at the granularity of a cache block.
A memory system is cache coherent if for each block, writes are serialized, and reads get the value of the last write.Definition 3.1.
Let V be the set of values of a fixed cache block, and v 0 ∈ V the initial value.
Let Σ rw = {rd(v), wr(v) | v ∈ V } be the alphabet of events, describing accesses to the block by some processor.
Then the coherent traces of the system are given by the following regular language over Σ rw :Coh = rd(v 0 ) * 񮽙 񮽙 v∈V wr(v) rd(v) * 񮽙 *Token coherence, like many contemporary coherence protocols such as the popular MOESI protocol family [31], provides this strong form of coherence by enforcing a "single writer, multiple reader" policy 2 .
In our abstract protocol, system components and messages are of the same type and treated completely symmetrically: both are represented by token bags.
Token bags are finite multisets (or bags) over some set T of tokens, and may be required to satisfy some additional constraints (well-formedness).
The tokens in the bag constitute the state of the component, or the contents of the message.The state of the entire system is represented as yet another bag that encloses the token bags of the individual components and messages.
The sending of a message is modeled as a division, where a bag separates into two bags, dividing its tokens.
The receipt of a message, symmetrically, is modeled as a fusion of token bags.
Change is expressed by local reactions: tokens within a bag can be consumed, produced or modified according to rewrite rules.We give two preliminary definitions before proceeding to the definition of the abstract protocol.
For example, for any t 1 , t 2 ∈ T , all of the following denote the same T -bag:[ t 2 1 t 2 ] = [ t 1 t 1 t 2 ] = {t 1 t 1 t 2 , t 1 t 2 t 1 , t 2 t 1 t 1 }.
The exponent is a convenient notation for repeated symbols, and often used with regular languages.
(T, B, I, Σ e , W )where T is a set of tokens, B ⊂ M(T ) defines the set of well-formed Tbags, I ∈ M(B) is the initial configuration, Σ e is a set of local events, andW ⊂ Σ e × M(T ) × 2 T × M(T ) is a set of rewrite rules.A rewrite rule (a, x, H, y) ∈ W is denoted a: x =⇒ H y.
It describes a reaction labeled a that can occur whenever all the tokens in x are together in a bag, and 2 We are considering only the interface between the memory system and the processor here.
Independently, the contract between the processor and the programmer may use weaker forms of coherence that involve temporal reordering of events, as specified by the memory model.
the bag does not contain any of the inhibiting tokens listed in H.
When the reaction fires, the tokens x are replaced by the tokens y.
If H is empty, we omit it from the notation.A TTS defines a process over the alphabetΣ = Σ e ∪ Σ c , with Σ c = {snd(b), rcv(b) | b ∈ B}, with the traces {u ∈ Σ * | ∃C ∈ M(B) : I u − → C},where we define the transition relation C u − → C 񮽙 with the inference rules 3 below.C 񮽙 − → C (stutter) C u − → C 񮽙 C 񮽙 v − → C 񮽙񮽙 C uv −→ C 񮽙񮽙 (trans) x 񮽙 y ∈ B [ C x y ] 񮽙 − → [ C x񮽙 y ] (fusion) [ C x񮽙 y ] 񮽙 − → [ C x y ] (division) a: x =⇒ H y |z| ∩ H = ∅ y 񮽙 z ∈ B [ C x񮽙 z ] a − → [ C y 񮽙 z ] (reaction) [ C x ] snd(x) − −−− → [ C ] (send) [ C ] rcv(x) − −−− → [ C x ](receive)Token transition systems have a feel of concurrency much like a biological system where reactive substances are contained in cells that can undergo fusion and division.
Chemical abstract machines [6] capture the same idea (with molecules, membranes, and solutions instead of tokens, bags, and configurations), but are also different in many ways (for example, they do not have fusion or division).
R is a regular token as used by token coherence.
O(s) is a owner token in one of two states s ∈ {C, D} (clean or dirty).
D(v) is an instance of the data, with value v ∈ V .
M (v) is a memory cell containing the value v ∈ V .
-B is defined by imposing two conditions on a token bag x ∈ M(T ):• if x contains data D(v), then it must contain at least one regular token R or an owner token O(s).
• if x contains a dirty owner token O(D), then it must contain data D(v).
-I .
= [ [ R m−1 O(C) M (v 0 ) ] ].
-Σ e .
= {rd(v), wr(v), memread, memwrite, copy, drop | v ∈ V }.
-W consists of the rewrite rules shown in Fig. 1.
Fig. 2 shows an example trajectory of the abstract protocol.
Next, we explain the reaction rules and their interaction in some more detail.
[D(v) ] =⇒ [ D(v) ]wr(w): [ R m−1 O(s) D(v) ] =⇒ {D(v)} [ R m−1 O(D) D(w) ] memread: [ M (v) O(C) ] =⇒ [ M (v) O(C) D(v) ] memwrite: [ M (v) O(D) D(w) ] =⇒ [ M (w) O(C) D(w) ] copy: [ D(v) ] =⇒ [ D(v) D(v) ] drop: [ D(v) ] =⇒ [ ]memread − −−−− → [ [ M (v0) D(v0) O(C) R m−1 ]D [ ]C 1 [ ]C 2 ] -send data w/ tokens 񮽙 − → [ [ M (v0) ]D [ D(v0) O(C) R m−1 ] [ ]C 1 [ ]C 2 ] C1 receives response 񮽙 − → [ [ M (v0) ]D [ D(v0) O(C) R m−1 ]C 1 [ ]C 2 ]C1 writes value v1wr(v 1 ) − −−− → [ [ M (v0) ]D [ D(v1) O(D) R m−1 ]C 1 [ ]C 2 ]C2 requests S (requests are abstracted away)C1 responds -copy data copy −−→ [ [ M (v0) ]D [ D(v1) D(v1) O(D) R m−1 ]C 1 [ ]C 2 ] -send data w/ token 񮽙 − → [ [ M (v0) ]D [ D(v1) O(D) R m−2 ]C 1 [ D(v1) R ] [ ]C 2 ]rd(v) reads a value from a data instance (it can be applied at any time, and does not modify the state).
wr(w) modifies a data token, and can only be applied if all m tokens (one owner token and m − 1 regular tokens) are present, and no other data copies are in the same bag (which guarantees that the data token being modified is the only one in the system).
To guarantee proper writebacks of modified data, a special owner token is used.
The owner token records the clean/dirty state, i.e. whether the memory value is stale.
When modifying data, the owner token is set to dirty.
When the memory writes back the data (memwrite), the owner token is cleaned.
memread loads data from the memory only if there is a clean owner token, and thereby avoids reading stale data.The rules copy and drop imply that data instances D(v) can be freely copied or destroyed, subject only to the restriction enforced by B that all bags are wellformed -for example, whoever has the dirty owner token must keep at least one data instance.We can now prove that the abstract protocol is coherent.Theorem 3.5.
The closed system T m ∩ Σ * e is coherent:(T m ∩ Σ * e ) ↑ Σ rw ⊂ CohTo prove this, verify that (1) all of the following invariants hold in the initial state I and (2) prove (by induction on derivations) that if the invariants hold for a state C, they hold for any stateC 񮽙 such that C u − → C 񮽙 for some u ∈ Σ * e .1.
Together, these invariants guarantee that all data instances D(v) are always up-to-date; therefore, reads get the correct value which implies coherence.
All state is modeled by tokens, and there is no distinction between components and messages.
This symmetry points out interesting design directions.
For example, we consider the memory cell M (v) to be stationary.
However, the formal token rules do not impose this restriction and and could be used as an implementation guideline for a system with home migration.
In this section, we describe how we verified the safety of a detailed implementation of token coherence for an arbitrary number of caches.
We describe how we used compositional verification to deal with the parametric character, and how we employed abstraction to handle the fine level of detail.
We conclude with a list of discovered bugs.
The protocol implementation was developed by Martin et al. for architecture research on token coherence [20], and was extensively simulated prior to this work.
It consists of finite state machines (FSM) for the cache and memory controllers, augmented with message passing capabilities.
The FSMs are specified using the domain-specific language SLICC (Specification Language for Implementing Cache Coherence) developed by Martin et al.
The FSMs include all necessary transient states that arise due to the asynchronous nature of the protocol.
The memory and cache controller amount to 600 and 1800 lines of SLICC code, respectively, a scale on which purely manual analysis methods are impractical, in particular because these low-level specifications are usually changed over time.The SLICC compiler generates (1) executables for the simulation environment and (2) summary tables containing the control states, events and transitions in a human-readable table format 4 .
Fig. 1 shows the summary table for the memory controller, with its 3 states and 11 events.
Note that some parts of the state, such as the number of tokens, or the actual data values, are stored in variables that are not visible in the summary table.Due to lack of space, we can not reproduce the summary table for the cache controller (17 states and 20 events), and we can not explain further the meaning of the states and events.
The complete SLICC code and interactive HTMLtables are online [21], along with implementations of three other cache coherence protocols.
Consider the system S 񮽙 n consisting of n caches C 񮽙 , a directory controller D 񮽙 (which is attached to the memory, and sometimes called memory controller), and a interconnection network N 񮽙 .
We consistently use primes for implementation processes to distinguish them from specification processes:S 񮽙 n .
= C 񮽙 | C 񮽙 | · · · | C 񮽙 񮽙 񮽙񮽙 񮽙 n | N 񮽙 | D 񮽙(4)In the beginning, the memory holds all tokens.
We define local specification processes as token transition systems:D .
= T m = (T, B, I, Σ e , W ) C .
= (T, B, [ [ ] ], Σ e , W ) N .
= (T, B, [ [ ] ], Σ e , W )Since a token transition system already models all possible distributions of the state, no new behavior arises when it is composed:C | D = D C | C = CWe now state the central result which (together with Theorem 3.5) allows us to verify the implementation components D 񮽙 , C 񮽙 and N 񮽙 individually, each within an abstracted context rather than a fully instantiated system.
D 񮽙 񮽙 C D C 񮽙 񮽙 D C N 񮽙 񮽙 D Cthen for all n ∈ N, we have S 񮽙 n 񮽙 {񮽙} T m , i.e., the system refines the formal token coherence protocol.The proof uses induction and the proof rules (Theorem 2.7).
To discharge the remaining obligations, we used manual translation, abstraction, and annotation, and the explicit model checker Murϕ [12,11].
The following steps give an overview of the method.
This step involves translating the SLICC code to Murϕ, instrumenting it with the read/write events relevant for coherence, and abstracting both the state space and the message format.
Fig. 2 shows snippets of translated code.
The SLICC instructions that fell prey to the abstraction are in slanted face.
For example, only a single cache block is modeled, therefore the code dealing with addresses is abstracted away.
Also, message source and destination fields are irrelevant due to the deep symmetry of formal token coherence.
Furthermore, two data values are sufficient 5 .2.
Obtain good encodings for the specification/environment processes D, C.
We can take advantage (1) of the global system invariants established earlier and (2) of the fact that fusion and division are not observable.
For example, the flattening map[ b 1 b 2 . . . b k ] 񮽙 → b 1 񮽙 b 2 .
.
. 񮽙
b k provides a canonical representative state.
This means that a single T -bag, rather than a multiset of T -bags, is sufficient to model the context.
The models we obtain this way are compact and contribute much to the state-space economy of our approach.
3.
Annotate the transitions of the implementation with matching specification transitions, and provide refinement maps.
For each transition of the implementation process, the annotations specify a sequence of transitions of the specification process.
Fig. 2 − → q 1 v2 − → . . . v k −→ q k such that q 0 = q, q k = q 񮽙 and v 1 v 2 . . . v k = v (where v 1 v 2 . . . v k = 񮽙 for k = 0).
L i .
= (Q i , q0 i , Σ ∪ {񮽙}, δ i ) with i ∈ {I, S, C}.
Let φ : Q I → Q S be a function (the refinement map).
If R ⊂ Q I × Q C is a relation with the properties (R1)-(R4) listed below, then I 񮽙 C S. (R1) (q0 I , q0 C ) ∈ R, and φ(q0 I ) = q0 S (R2) If (q I , q C ) ∈ R and q C u − → q 񮽙 C for some u ∈ Σ e ∪ {񮽙}, then (q I , q 񮽙 C ) ∈ R. (R3) If (q I , q C ) ∈ R and q I u − → q 񮽙 I for some u ∈ Σ e ∪ {񮽙}, then (q 񮽙 I , q C ) ∈ R and φ(q I ) u =⇒ φ(q 񮽙 I ).
(R4) If (q I , q C ) ∈ R and q I σ − → q 񮽙 I and q C σ − → q 񮽙 C for some σ ∈ Σ c , then (q 񮽙 I , q 񮽙 C ) ∈ R and φ(q I ) σ =⇒ φ(q 񮽙 I ).
The full Murϕ code is available online [7].6 Theorem 4.1 lists three obligations, but we skip N 񮽙 񮽙D C because it reduces to checking the reliablity of the network, which is trivial at the given abstraction level.
The translation required about two days of work.
This estimate assumes familiarity with token coherence, and some knowledge of the implementation.
We found several bugs of varying severity, all of which were missed by prior random simulation tests similar to those described by Wood et.
al. [33].
Seven changes were needed to eliminate all failures (not counting mistakes in the verification model):1.
The implementation included assertions that do not hold in the general system.
Although they were mostly accompanied by a disclaimer like "remove this for general implementation", the latter was missing in one case.
2.
The implementation was incorrect for the case where a node has only one token remaining and answers a Request-Shared.
This situation was not encountered by simulation, probably because the number of tokens always exceeded the number of simulated nodes.
We fixed the implementation, which involved adding another state to the finite state control.
3.
Persistent-Request-Shared messages (which are issued if the regular RequestShared is not answered within a timeout period) suffered from the same problem, and we applied the same fix.
4.
The implementation copied the dirty bit from incoming messages even if they did not contain the owner token.
Although this does not compromise coherence, it can lead to suboptimal performance due to superfluous writebacks.
This performance bug would have gone undetected had we only checked for coherence, rather than for refinement of the abstract protocol.
5.
After fixing bug 4, a previously masked bug surfaced: the dirty bit was no longer being updated if a node with data received a dirty owner token.
6.
Two shaded boxes (i.e. transitions that are specified to be unreachable) were actually reachable.
This turned out to be yet another instance of the same kind of problem as in bug 2.
7.
Finally, another (last) instance of bug 2 was found and fixed.As expected, the compositional approach heavily reduced the number of searched states.
This kept computational requirements low, in particular considering that the results are valid for an arbitrary number of caches.
The measurements in Fig. 3 were carried out on a 300MHz Pentium III ThinkPad.
We make three main contributions.
First, we formally verified the safety of a system-level implementation of token coherence, for an arbitrary number of caches.
Second, we developed a general and formal specification of the safety substrate of token coherence, and prove its correctness.
Third, we demonstrated that token coherence's "design for verification" approach indeed facilitates the verification as claimed.Future work may address the following open issues.
First, the methodology does not currently address liveness.
Second, other protocols or concurrent computations may benefit from the high-level abstraction expressed by token transition systems, and offer opportunities for compositional refinement along the same lines.
Third, much room for automation remains: for example, we could attempt to integrate theorem provers with the SLICC compiler.
