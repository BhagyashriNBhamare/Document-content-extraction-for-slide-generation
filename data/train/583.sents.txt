We present a new class of parallel and distributed audio con-cealment (PDAC) algorithms which recover lost audio packets at the receiver to fight against channel impairment.
The main contribution of this work is the proposal of using nonlocal sparse representations to characterize the prior constraint of undamaged audio.
When combined with observation constraint, we obtain an alternating projection based audio concealment algorithm which recovers missing data in a parallel and distributed fashion.
We also present two extensions of PDAC for more challenging situations: expectation-maximization PDAC (EM-PDAC) to handle consecutive packet loss and filter-bank PDAC (FB-PDAC) to repair complex music signals.
Excellent preliminary experimental results are reported for a wide range of audio materials and loss conditions.
Audio concealment refers to the problem of repairing the lost packets due to channel impairments.
Channel impairments could arise from fading in a cellular network or network congestion in a packet switch network.
The impact of lost packets on subjective quality of audio signals is dramatic [1], [2].
Error concealment has found to be a useful technique in multimedia communication applications.
In particular, as voice over internet protocol (VoIP) and audio streaming becomes more popular, packet loss recovery for audio signals is expected to receive more attention in the future.
There are two classes of concealment techniques: sendera) b) based and receiver-based [1].
Our focus here is receiver-based approaches which attempt to recover the data in the lost packet by exploiting the inherent redundancy of audio source itself (refer to Fig. 1).
Existing approaches toward packet loss recovery mainly include time-scale modification [3], adaptive packetization [4] and model-based schemes [5], [2].
Interested readers are referred to two survey articles [1], [6] for more information.
However, we note that most current schemes sequentially recover the lost packet -i.e., concealment starts from the two ends of a missing frame and recover lost data on a sample-by-sample basis (refer to Fig. 1a).
The drawback of such sequential approach is error propagation.
That is, recovery at the boundary of missing frame is likely to be more accurate than that at the center.
The problem of error propagation is rooted in the locality or Markovian assumption made about the audio source for the purpose of overcoming the curse of dimensionality [7].
However, such assumption is often questionable especially for speech (e.g., pitch-related) and audio signals which often demonstrate strong non-local dependency.
The above observations motivate us to come up with a new class of algorithms that recover the missing data in a parallel and distributed fashion.
As shown in Fig. 1b, a lost frame x of length q is conceived to be a subframe of several longer frames {x 1, ..., x k } of length p > q. Therefore, the problem of estimating x can be transformed into k parallel and distributed concealment problems which can be solved independently.
Apparently, the overlapping among x i's introduces redundancy or diversity to the solution, which distinguishes ours from previous attacks.The objective of this work is to demonstrate the benefit of diversity to error concealment problem and suggest its connection to the influential paradigm in cognitive science called parallel distributed processing (PDP) [?]
.
Since human observers will ultimately judge the quality of recovered audio, there is a compelling need to develop biologically-inspired PDP algorithms which better match the mechanism of human auditory system.
The rest of the paper is organized as follows.
In Section 2, we introduce nonlocal sparse representation in the frame space which is the foundation for developing parallel and distributed concealment.
Basic algorithm and its two extensions are presented next in Section 3.
Preliminary experimental results are reported in Section 4 to justify the effectiveness of the proposed approach.
Let S = {s 1, s2, ..., sN } denote a sequence of audio samples.
To overcome the curse of dimensionality, we consider a frame-based representation of audio as shown in Fig. 2.
In speech coding, one often apply linear prediction analysis to each frame of samples and represent them by parametric autoregressive (AR) models [9].
Here we are interested in a nonparametric approach of modeling audio signals in the frame space R p -specifically, we want to develop a new representation based on the observation that all frames of length p (point clouds in R p ) form a nonlinear manifold whose dimensionality is much smaller than p.In the seminal work of nonlinear dimensionality reduction by locally linear embedding (LLE) [10], the local geometry of a manifold is characterized by linear coefficients that reconstruct each data point from its neighbors in the frame space, i.e.,x 0 = q 񮽙 i=1 wixi,(1)where x0 is the data point (frame of interest) and N (x0) = {xi} q i=1 denotes its local neighborhood.
Note that the locality in the frame space is NOT equivalent to that in the time domain where audio is sampled.
Two audio frames would have small distance in the frame space (i.e., neighboring points in R p ) but are far away from each other (e.g., separated by a pitch period).
Therefore, the subtle difference between linear prediction model in Eq.
(1) and classical AR model lies on the choice of neighborhood x i's (nonlocal vs. local in the time domain).
The key motivation behind nonlocal sparse representation lies in the question of how to exploit the manifold constraint shown in Fig. 2.
Counter-intuitively, the solution is to increase the dimensionality.
For example, any single point x0 in R p does not realize the local subspace constraint; instead multiple points in the local neighborhood of x 0 reflect the manifold constraint -the point cloud could have a lower dimensionality than p.
In other words, if we pack all points in the neighborhood of x 0 (including x0) into a 2D array X sized p × Q (Q = q + 1), the manifold constraint of the signal can be exploited by standard 2D linear transforms (e.g., FFT and DCT).
What do we buy from such increased dimensionality (2D instead of 1D)?
We argue it is the improved sparsity of signal representation.
Better sparsity is a direct consequence of nonlinearity because the nonlocal information of x i (i.e., how it is related to x0) is implicitly coded into the new dimension (intuitively we can think of it as the phase axis).
Therefore, even if a linear and nonadaptive 2D transform is used, the derived audio representation is nonlinear and adaptive due to the embedded nonlocal (phase) information.
Such joint time-phase (local-nonlocal) processing is an important departure from the current practice of pursuing adaptive yet still local representation for audio signals.One critical issue remaining to be addressed is the size of local neighborhood in the frame space -the sparsity is not guaranteed unless sufficient number of points can be found surrounding x0.
Fortunately, such condition is approximately satisfied for signals acquired from the real world such as audio.
In our framebased representation, two frames x and y are declared adjacent if y = T [x] + w where w denotes an additive noise term and T is the translation operator.
Although the above definition of local neighborhood can be further extended by incorporating timereversal and time-scale modification into T (it is essentially the transformation operator of an ergodic process [11]), we only use translation in our current implementation for its simplicity.
Sparsity constraint in the frame space offers a powerful prior constraint for undamaged audio.
Similar to image recovery [12], we can define two constraint sets for the targetˆStargetˆ targetˆS: observation constraint specified by correctly-received audio packets and prior constraint specified by the sparsity prior in the frame space (i.e., ˆ S belongs to a low-dimensional manifold).
Note that packed audio frames X ∈ R p×q are indeed 2D array, which imply that tools developed for image recovery are also applicable here.
However, we note that such borrowing is motivated by the need of exploiting nonlocal dependency in audio, which differs from the locality motivation in image recovery.
The convexity of observation and prior constraint sets are easy to justify (refer to [12]); and the recovery of missing data can be solved by alternating projections (see Fig. 3a).
The basic PDAC algorithm is summarized as follows: • Initialization: ˆ S 0 = S; • Data recovery: recover the missing data inˆSinˆ inˆS k by alternating projections -prior (sparsity) constraint: apply transform-domain thresholding to each 2D array X formed around x0 and take the average of overlapped samples as the projection resultsˆSresultsˆ resultsˆS k+1 ;-observation constraint: for those packets which are not lost, replace their corresponding data inˆSinˆ inˆS k+1 by those inˆSinˆ inˆS 0 ;We making two additional comments about the enforcement of sparsity constraint in the above algorithm.
First, transformdomain thresholding refers to the standard concatenation of forward transform, hard thresholding and inverse transform.
The choice of transform is flexible -we have found FFT and DCT achieve comparable performance.
However, we note that the 2D Fig. 4.
Flow-chart of FB-PDAC algorithm.basis used in our algorithm is not adaptive at all -temporal adaptation is due to the clustering in the frame space.
Second, averaging overlapped frames is an ad-hoc strategy for transforming the overcomplete expansion of audio back to a complete version.
It is possible to develop more sophisticated fusion strategy using Bayesian theory (but outside the scope of this work).
In our baseline algorithm, the impact of missing frame on data clustering in the frame space is ignored.
However, such issue is important because the sparsity (dimensionality of manifold) is directly determined by the clustering results.
Fortunately, such missing data problem can be solved by the classical expectation maximization (EM) algorithm -i.e., we can alternate the process of recovering missing data and determining local neighborhood N (x 0) in R p .
Intuitively, improved estimation of missing data will lead to a better definition of N (x0) and vice versa (refer to Fig. 3b).
Therefore, we can extend PDAC algorithm by adding an outer loop responsible for clustering refinement.
• Initialization: ˆ S 0 = S; • Outer loop (EM-like iteration) -neighborhood refinement: find N (x0) for every frame x0 centered at a missing sample inˆSinˆ inˆS k ;-data recovery (inner loop): recover the missing data inˆS inˆ inˆS k by Algorithm 1.
Another challenging issue arises as audio sampling rate gets higher.
For example, empirical studies have shown that music signals sampled at 44.1KHz are less aperiodic and therefore more difficult to conceal than speech signals sampled at 8KHz.
Higher sampling rate also implies more demanding computational power in real-time applications.
Those observations motivate us to extend the basic PDAC algorithm by incorporating a multi-rate filter-bank (FB) architecture [13] as shown in Fig. 4.
Despite the simplicity of FB-PDAC, we have found that it improves the concealment performance (due to improved waveform similarity at lower resolutions) and speeds up the computation (due to reduced frame length and search window size).
In this section, we use experimental results to justify the effectiveness of the proposed algorithms.
Two pieces of audio files are used as the test data: one is normal human speech sampled at 8KHz and the other is a pop music sampled at 44.1KHz.
The benchmark used in our comparison include a simplified implementation of LP-based packet loss concealment (LP-PLC) [2] (without excitation generator but with a higher-order LP and take the average of LP results from both forward and backward directions) and our own implementation of waveform similarity overlap-add (WS-OLA) [3].
LP-LPC and WS-OLA can be viewed as the representatives of parametric and nonparametric modeling of audio signals.
The objective measurement of concealment performance is the signal-to-noise (SNR) of the lost packet (we assume packet loss is isolated due to interleaving).
Although no subjective testing is performed yet, it is reasonable to assume improved SNR performance will correlate to higher perceptual quality.
In our first experiment, we test our PDAC algorithm on human speech signal.
The size of lost packet is 10ms (L = 80 samples) and we set the length of frame to be p = 4L+1 samples.
Fig. 5 includes the comparison of the error signals produced by three different concealment techniques: LP-PLC, WS-OLA and PDAC.
Our algorithm achieves the highest SNR performance among three.
To better illustrate the behavior of PDAC, we show the evolution of MSE as the iteration proceeds in Fig. 6.
It can be observed that 1) PDAC converges rapidly (little improvement after the first five iterations); 2) DCT and FFT achieve comparable performance (FFT gives SN R = 15.03dB at the convergence, DCT achieves SN R = 13.58dB).
In our second experiment, we want to demonstrate the gain of EM-PDAC over PDAC due to refined data clustering.
The same testing condition and parameter setting are used.
Fig. 7 includes the comparison between MSE profiles for PDAC and EM-PDAC algorithms (both use FFT as the sparsifying transform).
It can be observed that 1) SNR first converges and then improves again when the outer loop variable increases (neighborhood N (x 0) is updated); 2) EM-PDAC achieves over 1dB gain over PDAC.
Such findings support the benefits of refining data clustering though at the price of higher computational complexity.Finally, we report the performance of PDCA on concealing music signals.
Such type of signal is less regular than human speech and demonstrates weaker periodicity.
At the same test- ing condition (L = 80), both LP-PLC and WS-OLA give poor SNR results (< 1dB).
Fig. 8 shows the SNR performance of FB-PDAC at different decimation ratios (k = 1, 2, 4, 8).
The gain of FB-PDAC with k = 8 over PB-PDAC is about 2.5dB.
Preliminary subjective testing also justifies that such moderate SNR increase does correlate to the improvement of perceptual quality.
We will report more comprehensive results on subjective testing at the conference.
Currently it takes about one minute to run our nonoptimized MATLAB implementation of FB-PDAC on a Pentium-IV machine (2.4G processer, 512M memory).
However, we note that data clustering -computational bottleneck in our algorithmcan be efficiently implemented by associative memory [14].
Moreover, the class of PDAC algorithms might admit fast hardware implementation on VLSI chips due to their parallel nature.
[1] C. Perkins, O. Hodson, and V. Hardman, "A survey of packet loss recovery techniques for streaming audio," IEEE Net-
