We present a new class of games, local-effect games (LEGs), which exploit structure in a different way from other compact game representations studied in AI.
We show both theoretically and empirically that these games often (but not always) have pure-strategy Nash equilibria.
Finding a potential function is a good technique for finding such equilibria.
We give a complete characterization of which LEGs have potential functions and provide the functions in each case; we also show a general case where pure-strategy equilibria exist in the absence of potential functions.
In experiments, we show that myopic best-response dynamics converge quickly to pure strategy equilibria in games not covered by our positive theoretical results.
Games have long been studied in AI as a model of competitive multiagent interactions.
In particular, many researchers in AI have been interested in finding Nash equilibria (c.f. [5; 2]; for an introduction to games and equilibrium concepts, see e.g. [3]).
Recently, there has been a lot of work on compact representations of games with large numbers of players, and games for which the computation of equilibria is tractable [8; 15; 6; 7; 14; 9].
Much work in this vein has been based on the exploitation of one of two kinds of locality.
First, some approaches exploit unconditional independencies between players' abilities to affect each other's payoffs [8; 15; 6; 1].
Second, some approaches exploit symmetry in utility functions along with context-specific independencies between players' effects on each other; more precisely, games in which players' abilities to affect each other depend on the actions they choose.
Here we study games in this second class, because we believe that this sort of context-specific independence is more common in real-world games.Although compact representation has not been a primary motivation for economists, some work from economics does fall into the framework defined above.
Most influentially, Rosenthal defined congestion games [13].
In these games each agent i selects a subset S i from an available set of resources R; where n r is the number of agents who choose resource r ∈ R, and F r are arbitrary functions for each r, agent i pays:p i (S i , n) = 񮽙 r∈S F r (n r )(1)Observe that agent payoffs exhibit no unconditional independencies: all agents are given the same action choices, and so all agents can affect each other's payoffs.
On the other hand, context-specific independence does exist when two agents choose non-intersecting resource subsets.
Rosenthal's main result in [13] was that congestion games always have pure-strategy Nash equilibria (PSNE) .
This is important because, although all games have mixed-strategy Nash equilibria [11], there are few known classes of interesting games with pure strategy equilibria.
At the same time, pure strategy equilibria are attractive: they can be more likely to arise in play as they are more intuitive than mixed-strategy equilibria for many players; they can be easier for agents to coordinate to; as there are a finite number of pure strategy profiles in a given game, they can be easier to compute than mixed strategy equilibria.Rosenthal's work was extended by Monderer and Shapley [10], who showed that the class of congestion games is equivalent to the class of games with potential functions.
Potential functions map agents' joint actions to a real number, with the property that if X and Y are strategy profiles differing only in the action choice of one agent i, P (X) − P (Y ) is equal to the difference in i's payoff from selecting the two actions.
This result is useful because it means that the construction of a potential function is sufficient for showing the existence of a pure-strategy equilibrium.
Potential functions can also be used to compute equilibria: the set of pure-strategy Nash equilibria is equivalent to the set of strategy profiles that maximize P .
Recent work in computer science and AI has explored classes of games inspired by and extending congestion games.
For example, Kearns et al. examined games with bounded effects [7], and Roughgarden studied a nonatomic variant [14].
In this paper we propose a new class, which we call local-effect games.
In congestion games, whenever two agents affect each other's payoff, they each do so by the same amount.
Local-effect games (LEGs) model situations where agents' effects on each other are potentially asymmetric.
Generally, action A locally affects action B if the utility of agents taking action B depends on some function F A,B of the number of agents taking action A, but the utility of agents taking action A depends on a different function F B,A of the number of agents taking action B.There are many natural settings which are modeled by such locally-effecting actions.
One problem domain that has been studied in Economics for a three quarters of a century is the location problem [4].
These problems model situations where agents must choose a location to operate their business in the presence of other competing agents, and each agent's profit depends on how far she is from her competitors.
The canonical example concerns ice cream vendors who must choose a spot on the beach to set up a kiosk, with agents' utility depending on how many other ice cream sellers have located themselves in the same or adjacent areas.
Work from Economics on this problem has usually dealt with one-dimensional continuous spaces and has not modeled local effects explicitly; also, game theoretic analyses have typically considered only a small (e.g. 2 or 3) number of agents (c.f. [12]).
It is easy to think of many variants on the location problem: ice cream sellers arranging themselves around a lake (ring structure); vendors opening coffee houses in a city (grid structure); pairs at a cocktail party trying to pick a quiet room, with noise proportional to the number of people in the room, and noise also emanating from nearby rooms (arbitrary structure).
Another natural domain modeled by LEGs is a role formation game, where agents can take on one of a set of partiallysubstitutable roles.
Agents are rewarded according to the amount of work they do, so their payoff is reduced as other agents adopt the same or similar roles.Formally, let G = 񮽙A, F, n񮽙 be a local-effect game for n agents.
A is the set of actions available to each player in the game.
Let D denote the distribution of players across actions, and D(a) denote the number of players who chose action a ∈ A. For every pair of actions a, a 񮽙 ∈ A, F a,a 񮽙 : Z + → R + is the cost function expressing the cost due to the local effect from action a to action a 񮽙 , and depending on the number of agents having chosen action a. From this we can build the cost function of an agent a who chose action i ∈ A:cost(a) = F i,i (D(i)) + 񮽙 j∈A,j񮽙 =i F j,i (D(j)).
(2)We assume that in all local-effect games F is strictly monotonic: that ∀a, a 񮽙 񮽙 = a ∈ A F a,a 񮽙 (x) either increases strictly monotonically with x or is always 0.
Furthermore we assume ∀a, a 񮽙 񮽙 = a ∈ A F a,a 񮽙 (0) = 0.
It is useful to think of a directed graph representing the actions and their local effects.
We create a node for every action, and draw an edge from node i to node j if ∀x F i,j (x) = 0 is false.
We will sometimes denote functions of the form F i,i (x) as node functions, and functions of the form F i,j (x), i 񮽙 = j as edge functions.
Let neigh(i) denote the set of nodes to which there are directed edges originating at node i.We make one assumption about this graph's connectivity:∀A, B ∈ A, B ∈ neigh(A) → A ∈ neigh(B).
(3)That is, each pair of nodes in the graph are either both or neither neighbors of each other, though they might influence each other according to different local-effect functions. 񮽙 񮽙
= a ∈ A F a,a 񮽙 (x) = F a 񮽙 ,a (x).
For B-LEGs local-effect functions between pairs of actions are always the same in both directions; note however that for a given distribution of agents the magnitude of the local effects between a pair of actions may be different.
The graphical representation of actions and local effects in B-LEGs is undirected.
∀A, B, C ∈ A (B ∈ neigh(A) ∧ C ∈ neigh(A)) → ∀x F A,B (x) = F A,C (x).
That is, if action A has any effect on nodes B and C then the same function governs its effect on both.
We define notation for the uniform effect from node A:F u A (x) = F A,· (x).
Rosenthal was able to show that congestion games always have a PSNE.
For local-effect games, we can find counterexamples where exhaustive enumeration of strategies shows the absence of any PSNE, demonstrating that such a sweeping general result is impossible.
One example (found experimentally, and confirmed by exhaustive search) is the B-LEG G = 񮽙{A, B, C}, F, 11񮽙, with F A,A (x) = 2.79x, F B,B (x) = 4.72x, F C,C (x) = 1.5x, F A,B (x) = 0.64 log x, F A,C (x) = 0.32 log x, F B,C (x) = 2.77 log x.
In this section we show that two interesting classes of localeffect games have potential functions, meaning that they always have pure-strategy Nash equilibria.
Although these results show regions of overlap between the class of congestion games and the class of local-effect games, the potential functions themselves are interesting as their construction is nontrivial.
Also, these results are useful because they make it possible for the games to be described in the more intuitive local-effect game framework.
= i F i,j (x) = m i,j x.
Here we prove the result by giving a potential function:P = n 񮽙 i=1 D(i) 񮽙 j=1 F i,i (j) + 1 2 n 񮽙 i=1 񮽙 j∈neigh(i) D(i)m j,i D(j) (4)The first term is the standard congestion game potential function.
A game with only functions of the form F i,i (x) is a congestion game, and so must have the congestion game potential function.
The relationship between each F i,j (x) function and the agent's cost function is additive, and potential functions are only used for taking differences.
Thus if we can find a potential function P 񮽙 for a game with only local effects and all F i,i (x) = 0, the potential function for a general B-LEG will be the sum of the congestion game potential function and P 񮽙 .
Thus it remains to argue that our second term is this P 񮽙 : that it captures changes in utility arising from local effects.Consider the sum of the contribution of local effects to each agent's utility:s = 񮽙 n i=1 񮽙 j∈neigh(i) D(i)m j,i D(j).
When a single agent a deviates, s increases by twice the amount of the change to a's utility, because all F i,j (x) are linear and bidirectional.
That is, there is a change both in the amount of local effect acting on agent a, and new local effect caused by agent a, and bidirectionality and linearity imply that these two amounts are the same.
Thus the desired result is obtained by adding 1 2 s to the congestion game potential function. 񮽙
Observe that Theorem 1 holds for B-LEGs with non-linear functions F i,i (x)-what is required is linearity of the localeffect functions.
Nash equilibria if the local-effect graph is a clique.Sketch of Proof.
Again we provide a potential function:P = n 񮽙 i=1 D(i) 񮽙 j=1 F i,i (j) − n 񮽙 i=1 D(i)−1 񮽙 j=1 F u i (j)(5)As argued in Theorem 1, to construct a potential function it is sufficient to add the standard congestion game potential function with a function that accounts for changes in utility due to local effects.
This explains the first term.Let distributions X and Y be identical except thatD X (A) = α and D X (B) = β, while D Y (A) = α − 1 and D Y (B) = β + 1.
Assuming F A,A (·) = F B,B (·) = 0, P (X) − P (Y ) = F u B (β) − F u A (α − 1).
This is precisely the change in utility for an agent deviating from A in X to B in Y : the agent will be spared the local effect F u B (β) since he moves to B and is no longer subject to its local effect; however, since he moves away from A and the graph is a clique, he is now subject to the local effect F u A (α − 1).
Because the graph is a clique, and because the game is a U-LEG, the argument holds no matter which pair of nodes is chosen as A and B. 񮽙 Finding potential functions is an effective way of proving the existence of pure-strategy equilibria; however, there are many LEGs for which potential functions can be shown not to exist.
In this section we give a complete characterization of the class of LEGs which have potential functions.
∀a, a 񮽙 ∈ A F a,a 񮽙 (·) = 0.
Sketch of Proof.
Trivially, a LEG without any local effects is a congestion game. 񮽙
The class of potential games does not contain the class of local-effect games for which ∃A, B, C ∈ A where B ∈ neigh(C) and not A ∈ neigh(B) and not A ∈ neigh(C) and (F B,C 񮽙 = F C,B or F B,C is nonlinear).
Sketch of Proof.
Assume for contradiction that every LEG in the class has a potential function P .
We will consider three distributions of agents in order to derive properties of P .
Without loss of generality, we take A, B and C to be the first three actions in the game, and we take the total number of actions to be n. For more compact notation in what follows, let α = D(A), β = D(B) and γ = D(C).
Define the following three distributions:X = (α, β, γ, D(4), . . . , D(n)), Y = (α − 1, β + 1, γ, D(4), . . . , D(n)) and Z = (α, β + 1, γ − 1, D(4), .
.
.
, D(n)).
Without making any assumptions about the local effects between actions A, B and C and any of the other n − 3 actions, and for x ∈ {A, B, C}, let:U x (D(x), D(4), . . . , D(n)) = F x,x (D(x)) + 񮽙 a 񮽙 ∈{4,...,n} F a 񮽙 ,a (D(a 񮽙 )) (6) That is, U x (D(x), D(4), .
.
.
, D(n)) denotes the (negative) utility contributed to each agent taking action x ∈ {A, B, C} by those agents also taking action x, and by those agents taking the 4 th through n th actions.
For compactness we will ab-breviate U x (D(x), D(4), . . . , D(n)) as u x (D(x)) below.If distribution X were the case and an agent playing action A switched to action B, then distribution Y would be the result.
Thus:P (X) − P (Y ) = [u A (α)] − [F C,B (γ) + u B (β + 1)] (7)If X were the case and an agent playing action C switched to action B, then Z would be the result.
Thus:P (X)−P (Z) = [F B,C (β)+u C (γ)]−[F C,B (γ−1)+u B (β+1)](8)If Y were the case and an agent playing action C switched to action A, then Z would be the result.
Thus:P (Y ) − P (Z) = [F B,C (β + 1) + u C (γ)] − [u A (α)] (9)From equations (7) and (8), we can infer:P (Y ) − P (Z) = P (Y ) − P (Z) + [P (X) − P (X)] = [P (X) − P (Z)] − [P (X) − P (Y )] = 񮽙 [F B,C (β) + u C (γ)] − [F C,B (γ − 1) + u B (β + 1)] 񮽙 − 񮽙 [u A (α)] − [F C,B (γ) + u B (β + 1)] 񮽙(10)Intersect equation (10) with equation (9) and rearrange.
Observe that u A (α), u B (β + 1) and u C (γ) all cancel out, demonstrating that this proof does not depend on what edges exist between A, B, C and the rest of the graph, or on node effects.
Define I a,a 񮽙 (x) = F a,a 񮽙 (x) − F a,a 񮽙 (x − 1): the incremental cost on the local effect between a and a 񮽙 of adding the x th agent to a.
We then get: I C,B (γ) − I B,C (β + 1) = 0 (11) Clearly, equation (11) will not be satisfied for all β, γ unless F B,C = F C,B and F B,C is linear.
This contradicts our assumption that a potential function exists for every LEG in the class. 񮽙
Lemma 3 The class of potential games does not contain the class of local-effect games for which ∃A, B, C ∈ A where B ∈ neigh(C) and A ∈ neigh(B) and not A ∈ neigh(C) and (F B,C 񮽙 = F C,B or F B,C is nonlinear or F A,B 񮽙 = F B,A or F A,B is nonlinear).
Sketch of Proof.
This proof follows the proof of Lemma 2 and uses the same setting and definitions, except that (as stated in the theorem) A ∈ neigh(B).
Using the same arguments about distributions X, Y and Z we can derive:񮽙 I C,B (γ)−I B,C (β +1) 񮽙 + 񮽙 I B,A (β +1)−I A,B (α) 񮽙 = 0(12)Clearly, equation (12) will not be satisfied for all α, β, γ unless F A,B = F B,A , F B,C = F C,B , and both F A,B and F B,C are linear.
This contradicts our assumption that a potential function exists for every LEG in the class. 񮽙
The class of potential games does not contain the class of local-effect games for which ∃A, B, C ∈ A where B ∈ neigh(C) and A ∈ neigh(B) and A ∈ neigh(C) and(F B,C 񮽙 = F C,B or F B,C is nonlinear or F A,B 񮽙 = F B,A or F A,B is nonlinear or F A,C 񮽙 = F C,A or F A,C is nonlinear) and (F A,B 񮽙 = F A,C or F B,A 񮽙 = F B,C or F C,A 񮽙 = F C,B ).
Sketch of Proof.
This proof follows the proof of Lemmas 2 and 3 and uses the same setting and definitions, except that (as stated in the theorem) A ∈ neigh(B) and A ∈ neigh(C).
Using the same arguments about distributions X, Y and Z we can derive:񮽙 I A,C (α) − I A,B (α) 񮽙 + 񮽙 I B,A (β + 1) − I B,C (β + 1) 񮽙 + 񮽙 I C,B (γ) − I C,A (γ) 񮽙 = 0 (13)Equation (13) may be rewritten as:񮽙 I A,C (α) − I C,A (γ) 񮽙 + 񮽙 I B,A (β + 1) − I A,B (α) 񮽙 + 񮽙 I C,B (γ) − I B,C (β + 1) 񮽙 = 0 (14)From equation (13) we can see that the contradiction does not obtain for all α, β, γ when F A,B = F A,C , F B,A = F B,C , and F C,A = F C,B .
From equation (14) we can see that the contradiction does not obtain for all α, beta, γ when F A,B = F B,A , F B,C = F C,B , F A,C = F C, First, it is clear that a game with only a single action has a potential function.
A LEG with only two actions is trivially a U-LEG and has a local-effect graph which is a clique, so by Theorem 2 it has a potential function.
This proves statement 1 in the theorem, and leaves us to consider LEGs which have 3 or more actions.
We will do a case analysis considering all possible local-effect graph structures for these LEGs.
Clearly, all graphs with 3 or more nodes are included if we consider all graphs with no edges, all cliques, and all graphs containing subgraphs having three nodes and either exactly one or exactly two edges.Lemma 1 proves that if the local-effect graph has no edges then the LEG is a congestion game, proving statement 2.
If the local-effect graph contains a subgraph with three nodes and exactly one edge, and is not a B-LEG with linear functions, Lemma 2 shows that it does not have a potential function.
If it is a B-LEG with linear functions, Theorem 1 shows that it has a potential function, proving statement 3.
If the local-effect graph contains a subgraph with three nodes and exactly two edges, and is not a B-LEG with linear functions (again, statement 3), Lemma 3 shows that it does not have a potential function.If the local-effect graph is a clique, it contains a a clique of size three as a subgraph.
If the graph is not a U-LEG, Lemma 4 shows that it does not have a potential function.
If it is a U-LEG, Theorem 2 shows that it does have a potential function, proving statement 4. 񮽙
We are also able to prove the existence of pure-strategy Nash equilibria for classes of graphs, and node and edge functions that Theorem 3 shows cannot have potential functions.
The following constructive proof has classes of B-LEGs and ULEGs as special cases:Theorem 4 If a local-effect game satisfies 1.
∀A ∈ A, ∀B ∈ neigh(A), ∀x, F A,A (x) ≤ F A,B (x) 2.
∀A, B ∈ A, ∀x ≥ 1, F A,B (x + 1) − F A,B (x) ≤ F A,B (x) − F A,B (x − 1),then there exists a pure-strategy Nash equilibrium in which agents choose nodes that constitute an independent set.Sketch of Proof.
This proof proceeds by induction, building up a Nash equilibrium one agent at a time, and with each agent making a myopic best response to the previous distribution.
In the case of a single agent, it is clearly an equilibrium for him to select the best node.
Define D i as the distribution of agents at induction step i. Assume that n − 1 agents have each selected the best node in turn, resulting in a distribution D n−1 which is a Nash equilibrium and also an independent set.
We must show that when an additional agent n chooses the best node the resulting distribution D n is still an independent set, and still a Nash equilibrium.
First, we show that the new distribution is an independent set.
Assume for the purposes of contradiction that it was best for n to choose a node that does not belong to the independent set.
Then it must be the case that the selected node has at least one neighbor which has been chosen by one or more other agents.
Let the node selected by n be A, and let B be some neighboring node.
From condition 2 in the theorem (linearity/sublinearity), we can infer that:F B,B (D n−1 (B) + 1) ≤ F B,B (D n−1 (B)) + F B,B (1) (15)From condition 1 in the theorem (functional dominance), we know that:F B,B (D n−1 (B)) ≤ F B,A (D n−1 (B))(16) Thus we can use equation (16) to weaken the bound in equation (15) to get:F B,B (D n−1 (B) + 1) ≤ F B,A (D n−1 (B)) + F B,B (1) (17)Define the utility at inductive step i for an agent taking action X, and disregarding any local effect from action Y :U i X,∼Y (z) = F X,X (z) + 񮽙 W ∈neigh(X)|W 񮽙 =Y F W,X (D i (W )).
At some step i in the induction, D i (B) = 0 and D i (A) = 0, but D i+1 (B) = 1.
From the fact that the distribution of agents resulted from myopic choices (stated in the induction hypothesis), we know that: (18) because D i (B) = 0 anyway.
From the monotonicity of local-effect functions, and the fact that i ≤ n we can write:F B,B (1) ≤ U i A,∼B (1) (18) We can use U A,∼B (1) in equationU i A,∼B (1) ≤ U n A,∼B (1) (19)We can use equation (19) to weaken the bound given in equation (18):F B,B (1) ≤ U n A,∼B (1) (20)Finally, we can use equation (20) to further weaken the bound given in equation (17).
This gives us: (21) contradicts our assumption that agent n would myopically choose A over B; therefore D n must be an independent set.
Now we show that D 񮽙 is a Nash equilibrium.
Let C be the node that the new agent i selected in making his myopic response to the distribution D. From symmetry of cost functions we know that no agent can profitably deviate from node C: if so, i would have chosen a different node in the first place.
Consider an agent j who chose a node V 񮽙 = C. Agent j's payoff does not change from distribution D to distribution D 񮽙 , because D 񮽙 is an independent set, and so F C,V (·) = 0 (there are no local effects between nodes C and V .
Since distribution D was a Nash equilibrium (inductive hypothesis) j will not deviate from a new distribution D 񮽙 that differs only in that node C is more costly. 񮽙
F B,B (D n−1 (B)+1) ≤ F B,A (D n−1 (B))+U n A,∼B (1) (21) Equation Section 3 shows that there are many cases in which localeffect games have pure-strategy Nash equilibria.
Myopic best response has been shown to be an effective technique for computing pure strategy equilibria in a variety of settings [10].
In this section we show that this simple algorithm can compute pure strategy equilibria for very large local-effect games that are not covered by any of the positive results in section 3 and that do not have potential functions.
We present five different graph structures with similar local-effect functions, and show sample equilibria.
We should note that we have been able to find equilibria experimentally for most B-LEGs 1 with different graph structure and different localeffect functions that we have tried, and that convergence occurs within a second in most cases.
As with our theoretical results, we do not claim that these equilibria are unique; indeed, because agents' cost functions are symmetric, a new equilibrium can always be constructed from a given equilibrium by swapping action choices between pairs of agents.
Furthermore, we have observed many cases where multiple structurally different equilibria exist in the same local-effect game.All games shown here are B-LEGs with ∀A, ∀B F A,B (x) = k A,B log(x + 1).
We use one k n for all node functions and another k e for all edge functions (i.e., ∀A, ∀B 񮽙 = A k A,A = k B,B and ∀A, ∀B 񮽙 = A, ∀C 񮽙 ∈ {A, B} k A,B = k A,C ).
We hold k e = 1 throughout, and vary k n to highlight some of the more interesting equilibria.
These equilibria are representative of average runs, and were found with a minimum of parameter manipulation.
Each node is labelled with the number of agents choosing the node in equilibrium.
Fig.
1 shows a T structure representative of a simple location problem.
Fig. 2, which we call 'arbitrary' in what follows, is interesting because there are 2 nodes with 2 neighbors, 2 with 3 neighbors and 2 with 4 neighbors.
This setting could represent a role formation game.
Fig. 3 shows a binary tree structure; observe that most agents select leaf nodes because they have only one neighbor, and thus the parents of leaves are chosen by few agents.
Fig. 4 shows a two-dimensional grid, representative of our coffee house location problem.
Observe that the corners are most desirable, as they have only two neighbors; nodes neighboring corners are thus under-populated, leading to another concentration of agents in the middle of each edge.
It is also interesting that agents concentrate in the central node, even though it has four neighbors, because its neighbors are relatively under-populated.
Fig. 5 shows what happens to the game from Fig. 4 when we remove a single node (consider the same location problem when one node becomes unavailable).
Observe that agents generally cluster around the missing node, except for one neighboring node that is entirely unpopulated, as a result of the large local effects acting upon it.The amount of time it took to reach convergence in each graph is shown in Fig. 4, starting in each case with a uniform distribution of agents across the actions.
Finally, since the 'arbitrary' graph in Fig. 2 took the longest to converge (34% of the agents moved before convergence occurred) we examine this graph in more detail in Fig. 4.
Observe that as we vary the number of agents, the number of steps required for convergence increases roughly linearly.
Local-effect games exploit context-specific independence between players' payoff functions.
Finding a potential function is a good technique for finding equilibria; we identify all the local-effect games for which potential functions exist, and provide the potential function in each case.
We also give a positive theoretical result for a broad class of games that do not have potential functions.
Furthermore, we can show that myopic best response dynamics converge quickly in other cases which do not have potential functions, and are also not covered by our positive theoretical results.
