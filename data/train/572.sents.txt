This paper presents a dynamic program analysis algorithm that can detect deadlock potentials in a multi-threaded program by examining a single execution trace, obtained by running an instrumented version of the program.
The algorithm is interesting because it can identify deadlock potentials even though no deadlocks occur in the examined execution, and therefore it scales very well in contrast to more formal approaches to deadlock detection.
It is an improvement of an existing algorithm in that it reduces the number of false positives (false warnings).
The paper describes an implementation and an application to three case studies.
The Java programming language [2] explicitly supports concurrent programming through a selection of concurrency language concepts, such as threads and monitors.
Threads execute in parallel, and communicate via shared objects that can be locked using synchronized access to achieve mutual exclusion.
However, with concurrent programming comes a new set of problems that can hamper the quality of the software.
Deadlocks form such a problem category.
That deadlocks pose a common problem is emphasized by the following statement in [23]: "Among the most central and subtle liveness failures is deadlock.
Without care, just about any design using synchronization on multiple cooperating objects can contain the possibility of deadlock".
In this paper we present a dynamic program analysis algorithm that can detect the potential for deadlocks in a program by analyzing a trace (log file) generated from a successful deadlock free execution of the program.
The algorithm is interesting because it catches existing deadlock potentials with very high probability even when no actual deadlocks occur during test runs.
A basic version of this algorithm has previously been implemented in the commercial tool Visual Threads [16].
This basic algorithm, however, can give false positives (as well as false negatives), putting a burden on the user to refute such.
Our goal is to reduce the amount of false positives reported by the algorithm, and for that purpose we have modified it as reported in this paper.
Detection of errors in concurrent programs by analysis of successful runs was first suggested for low-level data races in [26].
Other forms of data races have later shown to be detectable using related forms of analysis, such as high-level data races [4] and atomicity violations [5].
Two types of deadlocks have been discussed in the literature [27] [22]: resource deadlocks and communication deadlocks.
In resource deadlocks, a process which requests resources must wait until it acquires all the requested resources before it can proceed with its computation.
A set of processes is resource deadlocked if each process in the set requests a resource held by another process in the set, forming a cycle of lock requests.
In communication deadlocks, messages are the resources for which processes wait.
In this paper we focus only on resource deadlocks.
In Java, threads can communicate via shared objects by for example calling methods on those objects.
In order to avoid data races in these situations (where several threads access a shared object simultaneously), objects can be locked using the synchronized statement, or by declaring methods on the shared objects synchronized, which is equivalent.
For example, a thread t can obtain a lock on an object A and then execute a statement S while having that lock by executing the following statement: synchronized(A){S}.
During the execution of S, no other thread can obtain a lock on A.
The lock is released when the scope of the synchronized statement is left; that is, when execution passes the curly bracket: '}'.
Java also provides the wait and notify primitives in support for user controlled interleaving between threads.
While the synchronized primitive is the main source for resource deadlocks in Java, the wait and notify primitives are the main source for communication deadlocks.
Since this paper focuses on resource deadlocks, we shall in the following focus on Java's capability of creating and executing threads and on the synchronized statement.The difficulty in detecting deadlocks comes from the fact that concurrent programs typically are non-deterministic: several executions of the same program on the same input may yield different behaviors due to slight differences in the way threads are scheduled.
Various technologies have been developed by the formal methods community to circumvent this problem, such as static analysis and model checking.
Static analysis, such as performed by tools like JLint [3], PolySpace [25] and ESC [11], analyze the source code without executing it.
These techniques are very efficient, but they often yield many false positives (false warnings) and additionally cannot well analyze programs where the object structure is very dynamic.
Model checking has been applied directly to software (in contrast to only designs), for example in the Java PathFinder system (JPF) developed by NASA [18,29], and in similar systems [14,21,10,6,28,24,12].
A model checker explores all possible execution paths of the program, and will therefore theoretically eventually expose a potential deadlock.
This process is, however, quite resource demanding, in memory consumption as well in execution time, especially for large realistic programs.
Static analysis and model checking are both typically complete (no false negatives), and model checking in addition is typically sound (no false positives).
The algorithm presented in this paper is neither sound nor complete, but it scales and it is very effective: it finds bugs with high probability and it yields few false positives.
The technique is based on trace analysis: a program is instrumented to log synchronization events when executed.
The algorithm then examines the log file, building a lock graph, which reveals deadlock potentials by containing cycles.
The algorithm has been implemented in the Java PathExplorer tool [20], which in addition analyzes Java programs for various forms of data races [26,4] and conformance with temporal logic properties [7].
Although the implementation is Java specific, the principles and theory presented are universal and apply in full to multi-threaded programs written in languages like C and C++ as well.
In fact, two of the case studies involve C++ programs.
In this case the programs must currently be manually instrumented.
The algorithm was first described in [8].
Some additional closely related work specifically requires mentioning.
In earlier work we presented the GoodLock algorithm [17] which attempts to improve the basic lock graph algorithm presented in [16] by reducing false positives in the presence of gate locks (a common lock taken first by involved threads).
This algorithm was based on building acyclic lock trees (rather than cyclic lock graphs as in [16]) but it could only detect deadlocks between pairs of threads.
The algorithm presented in this paper also tries to reduce false positives in presence of gate locks, but can detect deadlocks between any number of threads, and builds directly on the cyclic graph model in [16].
In addition, the algorithm also reduces false positives arising from code segments that cannot possibly execute concurrently.
In parallel work [1], included in these proceedings, an algorithm extending the GoodLock algorithm is suggested for reducing false positives, also in presence of gate locks.
This algorithm uses a combination of acyclic lock trees and cyclic lock graphs to represent locking patterns in a program run.
In that work a framework is furthermore suggested for using static analysis in combination with dynamic analysis to detect deadlocks.
In these pieces of work a single execution trace is used as a basis for the dynamic analysis.
Also presented at PADTAD'05 was work by IBM [13] where several execution traces, generated from several runs of the program being tested, are used to create a single locking model that is then analyzed.
This approach is useful to reduce false negatives (missed errors).
The paper is organized as follows.
Section 2 introduces preliminary concepts and notation used throughout the rest of the paper.
Section 3 introduces an example that illustrates the notion of deadlock and the different forms of false positives that are possible.
Section 4 presents the basic algorithm suggested in [16] (the algorithm is only explained in few words in [16]).
The subsequent two sections 5 and 6 suggest modifications, each reducing false positives.
Section 7 shortly describes the implementation of the algorithm and presents the results of three case studies.
Finally, Section 8 concludes the paper.
A directed graph is a pair G = (S, R) of sets satisfying R ⊆ S × S.
The set R is called the edge set of G, and its elements are called edges.
A path p is a non-empty graph G = (S, R) of the form S = {x 1 , x 2 , . . . , x k } and R = {(x 1 , x 2 ), (x 2 , x 3 ), . . . , (x k−1 , x k )}, where the x i are all distinct, except that x k may be equal to x 1 , in which case the path is a cycle.
The nodes x 0 and x k are linked by p; we often refer to a path by the natural sequence of its nodes, writing, say, p = x 1 , x 2 , . . . , x k and calling p a path from x 1 to x k .
In case where the edges are labeled with elements in W , G is triplet (S, W, R) and called a labeled graph with R ⊆ S × W × S.
A labeled path, respectively cycle, is a labeled graph with the obvious meaning.
Given a sequence σ = x 1 , x 2 , . . . , x n , we refer to an element at position i in σ by σ [i] and the length of σ by |σ|.
We let <> denote the empty sequence, and the concatenation of two sequences σ 1 and σ 2 is denoted by σ 1 σ 2 .
We denote by σ i the prefix x 1 , . . . , We shall with an example illustrate the three categories of false positives that the basic algorithm reports, but which the improved algorithm will not report.
The first category, single threaded cycles, refers to cycles that are created by one single thread.
Guarded cycles refer to cycles that are guarded by a gate lock "taken higher" up by all involved threads.
Finally, thread segmented cycles refer to cycles between thread segments that cannot possibly execute concurrently.
The program in Figure 1 illustrates these three situations, and a true positive.
The real deadlock potential exists between threads T 2 and T 3 , corresponding to a cycle on L 1 and L 2 .
The single threaded cycle within T 1 clearly does not represent a deadlock.
The guarded cycle between T 1 and T 2 does not represent a deadlock since both threads must acquire the gate lock G first.
Finally, the thread segmented cycle between T 1 and T 3 does not represent a deadlock since T 3 will execute before T 1 executes its last two synchronization statements.When analyzing such a program for deadlock potentials, we are interested in observing all lock acquisitions and releases, and all thread starts and joins.
The program can be instrumented to emit such events.
A lock trace σ = e 1 , e 2 , . . . , e n is a finite sequence of lock and unlock events and start and join events.
Let E σ denote the set of events occurring in σ.
Let T σ denote the set of threads occurring in E σ , and let L σ denote the set of locks occurring in E σ .
We assume for convenience that the trace is reentrant free in the sense that an already acquired lock is never re-acquired by the same thread (or any other thread of course) before being released.
Note that Java supports reentrant locks by allowing a lock to be re-taken by a thread that already has the lock.
However, the instrumentation can generate reentrant free traces if it is recorded how many times a lock has been acquired nested by a thread.
Normally a counter is introduced that is incremented for each lock operation and decremented for each unlock operation.
A lock operation is now only reported if the counter is zero (it is free before being taken), and an unlock operation is only reported if the counter is 0 again after the unlock (it becomes free again).
For illustration purposes we shall assume a non-deadlocking execution trace σ for this program.
It doesn't matter which one since all non-deadlocking traces will reveal all four cycles in the program using the basic algorithm.
We shall assume the following trace of line numbered events (the line number is the first argument), which first, after having started T 1 and T 2 from the M ain thread, executes T 1 until the join statement, then executes T 2 to the end, then T 3 to the end, and then continues with T 1 after it has joined on T 3 's termination.
The line numbers are given for illustration purposes, and are actually recorded in the implementation in order to provide the user with useful error messages.
In addition to the lock and unlock events l(lno, t, o) and u(lno, t, o) for line numbers lno, threads t and locks o, the trace also contains events for thread start, s(lno, t 1 , t 2 ) and thread join, j(lno, t 1 , t 2 ), meaning respectively that t 1 starts or joins t 2 in line number lno.
σ = s(1, M ain, T1), s(2, M ain, T2), l(3, T1, G), l(4, T1, L1), l(5, T1, L2), u(5, T1, L2), u(6, T1, L1), u(7, T1, G), s(9, T1, T3), l(14, T2, G), l(15, T2, L2), l(16, T2, L1), u(16, T2, L1), u(17, T2, L2), u(18, T2, G), l(19, T3, L1), l(20, T3, L2), u(20, T3, L2), u(21, T3, L1), j(10, T1, T3), l(11, T1, L2), l(12, T1, L1), u(12, T1, L1), u(13, T1, L2)Occasionally line numbers will be left out when referring to events.
6 In essence, the detection algorithm consists of finding cycles in a lock graph.
In the context of multi-threaded programs, the basic algorithm sketched in [16] works as follows.
The multi-threaded program under observation is executed, while just lock and unlock events are observed.
A graph of locks is built, with edges between locks symbolizing locking orders.
Any cycle in the graph signifies a potential for a deadlock.
Hence, we shall initially restrict ourselves to traces including only lock and unlock events (no start or join events).
In order to define the lock graph, we introduce a notion that we call a lock context of a trace σ in position i, denoted by C L (σ, i).
It is a mapping from each thread to the set of locks owned by that thread at that position.
Formally, for a thread t ∈ T σ we have the following:C L (σ, i)(t) = {o | ∃j : j ≤ i ∧ σ[j] = l(t, o) ∧ ¬∃k : j < k ≤ i ∧ σ[k] = u(t, o)}.
Bellow we give a definition that allows to build the lock graph G L with respect to an execution trace σ.
An edge in G L between two locks l 1 and l 2 means that there exists a thread t which owns the object l 1 while taking the object l 2 .
Definition 1 (Lock graph) Given an execution trace σ = e 1 , e 2 , . . . , e n .
We say that the lock graph of σ is the minimal directed graph G L = (L, R) such that : L is the set of locks L σ , and R ⊆ L × L is defined by (l 1 , l 2 ) ∈ R if there exists a thread t ∈ T σ and a position i ≥ 2 in σ s. t.σ[i] = l(t, l 2 ) and l 1 ∈ C L (σ, i − 1)(t).
In Figure 2 we give an algorithm for constructing the lock graph from a lock trace.
In this algorithm, we also use the context C L which is exactly the same as in the definition 1.
The only difference is that we don't need to explicitly use the two parameters σ and i.
The set of cycles in the graph G L , denoted by cylces(G L ), represents the potential deadlock situations in the program.
The lock graph for the example in Figure 1 is also shown in Figure 2.
The numbers indicate line numbers where source respectively target locks are taken.
In this section we present a solution that removes false positives stemming from single threaded cycles and guarded cycles.
In [17] we suggested a solution, the GoodLock algorithm, based on building synchronization trees.
However, this solution could only detect deadlocks between pairs of threads.
The algorithm to be presented here is not limited in this sense.
The solution is to extend the lock graph by labeling each edge between locks with information about which thread causes the addition of the edge and what gate locks were held by that thread when the target lock was taken.
A definition of valid cycles will then include this information to filter out false positives.
First, we define the extended lock graph.Definition 2 (Guarded lock graph) Given a trace σ = e 1 , e 2 , . . . , e n .
We say that the guarded lock graph of σ is the minimal directed labeled graph G L =Input: An execution trace σ GL is a graph; CL : [Tσ → 2 Lσ ] is a lock context; for(i = 1 .
.
|σ|) do case σ[i] of l(t, o) → GL := GL {(o , o) | o ∈ CL(t)}; CL := CL † [t → CL(t) {o}]; u(t, o) → CL := CL † [t → CL(t)\{o}] end;for each c in cycles(GL) do print ("deadlock potential:",c); (L, W, R) such that: L is the set of locks L σ , W ⊆ T σ × 2 Lis the set of labels, each containing a thread id and a lock set, andR ⊆ L × W × L is defined by (l 1 , (t, g), l 2 ) ∈ R if there exists a thread t ∈ T σ and a position i ≥ 2 in σ s.t. σ[i] = l(t, l 2 ) and l 1 ∈ C L (σ, i − 1)(t) and g = C L (σ, i − 1)(t).
Each edge (l 1 , (t, g), l 2 ) in R is labeled with the thread t that took the locks l 1 and l 2 , and a lock set g, indicating what locks t owned when taking l 2 .
In order for a cycle to be valid, and hence regarded as a true positive, the threads and guard sets occurring in labels of the cycle must be valid in the following sense.Definition 3 (Valid threads and guards) Let G L be a guarded lock graph of some execution trace and c = (L, W, R) a cycle in cycles(G L ), we say that:-threads of c are valid if: forall e, e ∈ R e = e ⇒ thread(e) = thread(e ) -guards of c are valid if: forall e, e ∈ R e = e ⇒ guards(e) ∩ guards(e ) = ∅ where, for an edge e ∈ R, thread(e), resp.
guards(e), gives the first, resp.
second, component of the label (t, g) of e = (l 1 , (t, g), l 2 ).
For a cycle to be valid, the threads involved must differ.
This eliminates single threaded cycles.
Furthermore, the lock sets on the edges in the cycle must not overlap.
This eliminates cycles that are guarded by the same lock taken "higher up" by at least two of the threads involved in the cycle.
Assume namely that such a gate lock exists, then it will belong to the lock sets of several edges in the cycle, and hence they will overlap at least on this lock.
This corresponds to the fact that a deadlock cannot happen in this situation.
Valid cycles are now defined as follows:Definition 4 (Unguarded cycles) Let σ be an execution trace and G L its guarded lock graph.
We say that a cycle c ∈ cycles(G L ) is an unguarded cycle if the guards of c are valid and threads of c are also valid.
We denote by cycles g (G L ) the set of unguarded cycles in cycles(G L ).
We shall in this section not present an explicit algorithm for constructing this graph, since its concerns a relatively simple modification to the basic algorithm -the statement that updates the lock graph becomes:G L := G L {(o , (t, C L (t)), o) | o ∈ C L (t)}adding the labels (t, C L (t)) to the edges.
Furthermore, cycles to be reported should be drawn from: cycles g (G L ).
Let us illustrate the algorithm with an example.
We consider again the execution trace σ from Section 3.
The guarded graph for this trace is shown in Figure 3.
The graph contains the same number of edges as the basic graph in Figure 2.
However, now edges are labeled with a thread and a guard set.
In particular, we notice that the gate lock G occurs in the guard set of edges (4, 5) and (15,16).
This prevents this guarded cycle from being included in the set of valid cycles since it is not guard valid: the guard sets overlap in G. Also the single threaded cycle (4, 5) ↔ (11, 12) is eliminated because it is not thread valid: the same thread T 1 occurs on both edges.
In the previous section we saw the specification of an algorithm that removes false positives stemming from single threaded cycles and guarded cycles.
In this section we present the full algorithm that in addition removes false positives stemming from segmented cycles.
We assume that traces now also contain start and join events.
Recall the example in Figure 1 and that the basic algorithm reports a cycle between threads T 1 (line 11-12) and T 3 (line 19-20) on locks L 1 and L 2 .
However, a deadlock is impossible since thread T 3 is joined on by T 1 in line 10.
Hence, the two code segments: line 11-12 and line 19-20 can never run in parallel.
The algorithm to be presented will prevent such cycles from being reported by formally introducing such a notion of segments that cannot execute in parallel.
A new directed segmentation graph will record which segments execute before others.
The lock graph is then extended with extra label information, that specifies what segments locks are acquired in, and the validity of a cycle now incorporates a check that the lock acquisitions are really occurring in parallel executing segments.
The idea of using segmentation in runtime analysis was initially suggested in [16] to reduce the amount of false positives in data race analysis using the Eraser algorithm [26].
We use it in a similar manner here to reduce false positives in deadlock detection.More specifically, the solution is during execution to associate segment identifiers (natural numbers, starting from 0) to segments of the code that are separated by statements that start or join other threads.
For example, if a thread t 1 currently is in segment s and starts another thread t 2 , and the next free segment is n + 1, then t 1 will continue in segment n + 1 and t 2 will start in segment n + 2.
From then on the next free segment will be n + 3.
It is furthermore recorded in the segmentation graph that segment s executes before n + 1 as well as before n + 2.
In a similar way, if a thread t 1 currently is in segment s 1 and joins another thread t 2 that is in segment s 2 , and the next free segment is n + 1, then t 1 will continue in segment n + 1, t 2 will be terminated, and from then on the next free segment will be n + 2.
It is recorded that s 1 as well as s 2 execute before n + 1.
Figure 5 illustrates the segmentation graph for the program example in Figure 1.
In order to give a formal definition of the segmentation we need to define two functions.
The first one, C S (σ), segmentation context of the trace σ, gives for each position i of the execution trace σ, the current segment of each thread t at that position.
CS(σ) = f0(σ, C init S , 1, 0), where the function f0 is defined by left-to-right recursion over the trace σ as follows:f0(e σ, CS, i, n) =                        f0(σ, CS, i + 1, n) if e ∈ {l(t,o),u(t,o)}, f0(σ, CS †[i → CS[i − 1] † t1 → n + 1 t2 → n + 2 , i + 1, n + 2) if e = s(t1, t2), f0(σ, CS †[i → CS[i − 1] †[t1 → n + 1], i + 1, n + 1) if e = j(t1, t2).
f0(<>, CS, i, n) = CSThe second function needed, # alloc , gives the number of segments allocated in position i of σ.
This function is used to calculate what is the next segment to be assigned to a new execution block, and is dependent on the number of start events s(t 1 , t 2 ) and join events j(t 1 , t 2 ) that occur in the trace up and until position i, recalling that each start event causes two new segments to be allocated.
Formally we define it as follows :# alloc (σ, i) = |σ i ↓ s | * 2 + |σ i ↓ j |.
We can now define the notion of a directed segmentation graph, which defines an ordering between segments.
Informally, assume that in trace position i a thread t 1 , being in segment s 1 = C S (σ)(i − 1)(t 1 ), executes a start of a thread t 2 .
Then t 1 continues in segment n = # alloc (σ, i − 1) + 1 and t 2 continues in segment n + 1.
Consequently, (s 1 , n) as well as (s 1 , n + 1) belongs to the graph, meaning that s 1 executes before n as well as before n + 1.
Similarly, assume that a thread t 1 in position i, being in segment s 1 = C S (σ)(i − 1)(t 1 ), executes a join of a thread t 2 , being in segment s 2 = C S (σ)(i − 1)(t 2 ).
Then t 1 continues in segment n = # alloc (σ, i−1)+1 while t 2 terminates.
Consequently (s 1 , n) as well as (s 2 , n) belongs to the graph, meaning that s 1 as well as s 2 executes before n.
The formal definition of the segmentation graph is as follows.Definition 5 (Segmentation graph) Given an execution trace σ = e 1 , . . . , e n .
We say that a segmentation graph of σ is the directed graph G S = (N , R) where: N = {n | 0 ≤ n ≤ # alloc (σ, |σ|)} is the set of segments, and R ⊆ N × N is the relation given by (s 1 , s 2 ) ∈ R if there exists a positioni ≥ 1 s.t. σ[i] = s(t 1 , t 2 ) ∧ s 1 = C S (σ)(i − 1)(t 1 ) ∧ (s 2 = # alloc (σ, i − 1) + 1 ∨ s 2 = # alloc (σ, i − 1) + 2), or σ[i] = j(t 1 , t 2 ) ∧ (s 1 = C S (σ)(i − 1)(t 1 ) ∨ s 1 = C S (σ)(i − 1)(t 2 )) ∧ s 2 = # alloc (σ, i − 1) + 1.
The following relation happens-before reflects how the segments are related in time during execution.Definition 6 (Happens-Before relation) Let G S = (N , R) be a segmentation graph, and G * S = (N , R * ) its transitive closure.
Then given two segments s 1 and s 2 , we say that s 1 happens before s 2 , denoted by s 1 s 2 , if (s 1 , s 2 ) ∈ R * .
Note that for two given segments s 1 and s 2 , if neither s 1 s 2 nor s 2 s 1 , then we say that s 1 happens in parallel with s 2 .
Before we can finally define what is a lock graph with segment information, we need to redefine the notion of lock context, C L (σ, i), of a trace σ and a position i, that was defined on page 6.
In the previous definition it was a mapping from each thread to the set of locks owned by that thread at that position.
Now we add information about what segment each lock was taken in.
Formally, for a thread t ∈ T σ we have the following :C L (σ, i)(t) = {(o, s) | ∃j : j ≤ i ∧ σ[j] = l(t, o) ∧ ¬(∃k : j < k ≤ i ∧ σ[k] = u(t, o)) ∧ C S (σ)(j)(t) = s}An edge in G L between two locks l 1 and l 2 means, as before, that there exists a thread t which owns an object l 1 while taking the object l 2 .
The edge is as before labeled with t as well as the set of (gate) locks.
In addition, the edge is now further labeled with the segments s 1 and s 2 in which the locks l 1 and l 2 were taken by t.Definition 7 (Segmented and guarded lock graph) Given an execution trace σ = e 1 , e 2 , . . . , e n .
We say that the segmented and guarded lock graph of σ is the minimal directed graph G L = (L σ , W, R) such that:-W ⊆ N × (T σ × 2 Lσ ) × N is the set of labels (s 1 , (t, g), s 2 ), each containing the segment s 1 that the source lock was taken in, a thread id t, a lock set g (these two being the labels of the guarded lock graph in the previous section), and the segment s 2 that the target lock was taken in, Each edge (l 1 , (s 1 , (t, g), s 2 ), l 2 ) in R is labeled with the thread t that took the locks l 1 and l 2 , and a lock set g, indicating what locks t owned when taking l 2 .
The segments s 1 and s 2 indicate in which segments respectively l 1 and l 2 were taken.-R ⊆ L σ × W × L σ is defined by (l 1 , (s 1 , (t, g), s 2 ), l 2 ) ∈ R ifIn order for a cycle to be valid, and hence regarded as a true positive, the threads and guard sets occurring in labels of the cycle must be valid as before.In addition, the segments in which locks are taken must now allow for a deadlock to actually happen.
Consider for example a cycle between two threads t 1 and t 2 on two locks l 1 and l 2 .
Assume further that t 1 takes l 1 in segment x 1 and then l 2 in segment x 2 while t 2 takes them in opposite order, in segments y 1 and y 2 respectively.
Then it must be possible for t 1 and t 2 to each take their first lock in order for a deadlock to occur.
In other words, x 2 must not happen before y 1 and y 2 must not happen before x 1 .
This is expressed in the following definition, which repeats the definitions from Definition 3.
R, e = e ⇒ ¬ (seg 2 (e 1 ) seg 1 (e 2 ))where, for an edge e = (l 1 , (s 1 , (t, g), s 2 ), l 2 ) ∈ R, thread(e) = t, guards(e) = g, seg 1 (e) = s 1 and seg 2 (e) = s 2 .
Valid cycles are now defined as follows.Definition 9 (Unsegmented and unguarded cycles) Let σ be an execution trace and G L its segmented and guarded lock graph.
We say that a cycle c ∈ cycles(G L ) is an unsegmented and unguarded cycle if the guards of c are valid, the threads of c are valid, and the segments of c are valid.
We denote by cycles s (G L ) the set of unsegmented and unguarded cycles in cycles(G L ).
Figure 4 presents an algorithm for constructing the segmentation graph and lock graph from an execution trace.
The set of cycles in the graph G L , denoted by cylces s (G L ), see Definition 9, represents the potential deadlock situations in the program.
The segmentation graph (G S ) and lock graph (G L ) have the structure as outlined in Definition 5 and Definition 7 respectively.
The lock context (C L ) maps each thread to the set of locks owned by that thread at any point in time.
Associated with each such lock is the segment in which it was acquired.
The segment context (C S ) maps each thread to the segment in which it is currently executing.
The algorithm should after this explanation and the previously given abstract definitions be self explanatory.
Consider again the trace σ from Section 3.
The segmented and guarded lock graph and the segmentation graph for this trace are both shown in Figure 5.
The segmentation graph is for illustrative purposes augmented with the statements that caused the graph to be updated.
We see in particular that segment 6 of thread T 3 executes before segment 7 of thread T 1 , written as 6 7.
Segment 6 is the one in which T 3 executes lines 19 and 20, while segment 7 is the one in which T 1 executes lines 11 and 12.
The lock graph contains the same number of edges as the guarded graph in Figure 3, and the same (thread,guard set) labels.
However, now edges are additionally labeled with the segments in which locks are taken.
This makes the cycle (19, 20) ↔ (11, 12) segment invalid since the target segment of the first edge (6) executes before the source segment of the second edge (7).
The algorithm presented in the previous section has been implemented in the Java PathExplorer (JPaX) tool [20].
JPaX consists of two main modules, an nization problems.
A synchronization problem can most obviously be missed if one or more of the synchronization statements involved in the problem do not get executed.
To avoid being entirely in the dark in these situations, we added a coverage module to the system that records what lock-related instructions are instrumented and which of these that are actually executed.JPaX's deadlock analyzer has been applied to three NASA case studies: a planetary rover controller for a rover named K9 programmed in 35 thousand lines of C++; a 7,5 thousand line Java version of the K9 rover controller used as part of an attempt to evaluate Java verification tools; and a planner named Europa programmed in approximately 5-10 thousand lines of C++.
In the C++ scenarios ASCII log files were generated which were then read and analyzed by the tool.
The Java version of the K9 controller was in particular created to evaluate a range of program verification technologies, among them JPaX, as described in [9]; the other technologies included static analysis and model checking.
In this Java experiment JPaX generally came out well in the comparison with the other tools, as being fast and effective.
Errors were seeded by a control team and the study groups had as task to detect the errors with the different tools.
The deadlock analysis tool found the seeded deadlocks usually during the first run of the tool.
In the C++ version of the K9 rover controller the tool found a real deadlock potential that was unknown to the programmer.
Also the first time the tool was run.
This experiment was performed by hand instrumenting lock and unlock operations in the program, whereas the observer module could be used unmodified.
In the planner Europa, the tool similarly found a real deadlock potential that was unknown to the programming team, also in the first run of the tool.
This result caused the team to request an integration of the observer part into their development suite for future use.The presented algorithm can miss (and hence not report) true positives in some rare cases, where for example a particular execution path causes a gate lock to prevent an error message from being issued, but where another path might contain a deadlock based on the same cycle.
Furthermore, it might be argued that cyclic lock patterns represent bad programming style.
For this reason, the best application of the algorithm might be to augment warnings given by the basic algorithm with additional information.
An algorithm has been presented for detecting deadlock potentials in concurrent programs by analyzing execution traces.
The algorithm extends an existing algorithm by reducing the amount of false positives reported, and has been implemented in the JPaX tool.
Although JPaX analyzes Java programs, it can be applied to applications written in other languages by replacing the instrumentation module.
The advantage of trace analysis is that it scales well, in contrast to more formal methods, and in addition can detect errors that for example static analysis cannot properly detect.
In current work, we further approach the problem of false positives by developing a framework for generating test cases from warnings issued by this tool.
Such test cases will then directly expose the possible deadlocks.
An experiment in this direction is described in [17] where a model checker is used to "investigate" deadlock and data race warnings identified using dynamic analysis.
Additional current work attempts to extend the capabilities of JPaX with new algorithms for detecting other kinds of concurrency errors, such as various forms of data races and communication deadlocks.
