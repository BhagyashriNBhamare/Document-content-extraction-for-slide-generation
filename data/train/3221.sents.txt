Spatial-temporal prediction is a fundamental problem for constructing smart city, which is useful for tasks such as traffic control, taxi dispatching, and environment policy making.
Due to data collection mechanism, it is common to see data collection with unbalanced spatial distributions.
For example, some cities may release taxi data for multiple years while others only release a few days of data; some regions may have constant water quality data monitored by sensors whereas some regions only have a small collection of water samples.
In this paper, we tackle the problem of spatial-temporal prediction for the cities with only a short period of data collection.
We aim to utilize the long-period data from other cities via transfer learning.
Different from previous studies that transfer knowledge from one single source city to a target city, we are the first to leverage information from multiple cities to increase the stability of transfer.
Specifically, our proposed model is designed as a spatial-temporal network with a meta-learning paradigm.
The meta-learning paradigm learns a well-generalized initialization of the spatial-temporal network, which can be effectively adapted to target cities.
In addition, a pattern-based spatial-temporal memory is designed to distill long-term temporal information (i.e., periodic-ity).
We conduct extensive experiments on two tasks: traffic (taxi and bike) prediction and water quality prediction.
The experiments demonstrate the effectiveness of our proposed model over several competitive baseline models.
Recently, the construction of smart cities significantly changes urban management and services [12,13,25,28,42,43].
One of the most fundamental techniques in building smart city is accurate spatial-temporal prediction.
For example, a traffic prediction system can help the city pre-allocate transportation resources and control traffic signal intelligently.
An accurate environment prediction system can help the government develop environment policy and then improve the public's health.Traditionally, basic time series models (e.g., ARIMA, Kalman Filtering and their variants) [10,15,19], regression models with spatial-temporal regularizations [6,44] and external context features [30,35] are used for spatial-temporal prediction.
Recently, advanced machine learning methods (e.g., deep neural network based models) significantly improve the performance of spatial-temporal prediction [34,35,41] by characterizing non-linear spatial-temporal correlations more accurately.
Unfortunately, the superior performance of these models is conditioned on large-scale training data which are probably inaccessible in real-world applications.
For example, there may exist only a few days of GPS traces for traffic prediction in some cities.Transfer learning has been studied as an effective solution to address the data insufficiency problem, by leveraging knowledge from those cities with abundant data (e.g., GPS traces covering a few years).
In [29], the authors proposed to transfer semantically-related dictionaries learned from a data-rich city, i.e., a source city, to predict the air quality category in a data-insufficient city, i.e., a target city.
The method proposed in [27] aligns similar regions across source and target cities for finer-grained transfer.
However, these methods, transferring the knowledge from only a single source city, would cause unstable results and the risk of negative transfer.
If the underlying data distributions are significantly different between cities, the knowledge transfer will make no contribution or even hurt the performance.To reduce the risk, in this paper, we focus on transferring knowledge from multiple source cities for the spatial-temporal prediction in a target city.
Compared with single city, the knowledge extracted from multiple cities covers more comprehensive spatial-temporal correlations of a city, e.g., temporal dependency, spatial closeness, and region functionality, and thus increases the stability of transfer.
However, this problem faces two key challenges.
• How to adapt the knowledge to meet various scenarios of spatial-temporal correlations in a target city?
The spatialtemporal correlations in the limited data of a target city may vary considerably from city to city and even from time to time.
For example, the knowledge to be transferred to New York is expected to differ from that to Boston.
In addition, the knowledge to be transferred within the same city also differs from weekdays to weekends.
Thus a sufficiently flexible algorithm capable of adapting the knowledge learned from multiple source cities to various scenarios is required.
• How to capture and borrow long-period spatial-temporal patterns from source cities?
It is difficult to capture long-term spatial-temporal patterns (e.g., periodicity) accurately in a target city with limited data due to the effects of special events (e.g. holiday) or missing values.
These patterns as indicators of region functionality, however, are crucial for spatial-temporal prediction [33,45].
Take the traffic demand prediction as an instance.
The traffic demand in residential areas is periodically high in the morning when people transit to work.
Thus, it is promising but challenging to transfer such long-term patterns from source cities to a target city.To address the challenges, we propose a novel framework for spatial-temporal prediction, namely MetaST.
It is the first to incorporate the meta-learning paradigm into spatial-temporal networks (ST-net).
The ST-net consists of a local CNN and an LSTM which jointly capture spatial-temporal features and correlations.
With the meta-learning paradigm, we solve the first challenge by learning a well-generalized initialization of the ST-net from a large number of prediction tasks sampled from multiple source cities, which covers comprehensive spatial-temporal scenarios.
Subsequently, the initialization can easily be adapted to a target city via fine-tuning, even when only few training samples are accessible.
Second, we learn a global pattern-based spatial-temporal memory from all source cities, and transfer it to a target city to support long-term patterns.
The memory, describing and storing long-term spatial-temporal patterns, is jointly trained with the ST-net in an end-to-end manner.We evaluate the proposed framework on several datasets including taxi volume, bike volume, and water quality.
The results show that our proposed MetaST consistently outperforms several baseline models.
We summarize our contributions as follows.
• To the best of our knowledge, we are the first to study the problem of transferring knowledge from multiple cities for the spatialtemporal prediction in a target city.
• We propose a novel MetaST framework to solve the problem by combining a spatial-temporal network with the meta-learning paradigm.
Moreover, we learn from all source cities a global memory encrypting long-term spatial-temporal patterns, and transfer it to further improve the spatial-temporal prediction in a target city.
• We empirically demonstrate the effectiveness of our proposedMetaST framework on three real-world spatial-temporal datasets.The rest of this paper is organized as follows.
We first review and discuss the related work in Section 2.
Then, we define some notations and formulate the problem in Section 3.
After that, we introduce details of the framework of MetaST in Section 4.
We apply our model on three real-world datasets from two different domains and conduct extensive experiments in Section 5.
Finally, we conclude our paper in Section 6.
In this section, we briefly review the works in two categories: some representative works for spatial-temporal prediction and knowledge transferring.
The earliest spatial-temporal prediction models are based on basic time series models (e.g., ARIMA, Kalman Filtering) [10,15,19].
Recent studies further utilize external context data (e.g., weather condition, venue types, holiday, event information) [26,30,35] to enhance the prediction accuracy.
Also, spatial correlation is taken into consideration by designing regularization of spatial smoothness [21,31,44].
Recently, various deep learning methods have been used to capture complex non-linear spatial-temporal correlations and predict spatial-temporal series, such as stacked fully connected network [24,35], convolutional neural network (CNN) [23,41] and recurrent neural network (RNN) [39].
Several hybrid models have been proposed to model both spatial and temporal information [7,33,34].
These methods combine CNN and RNN, and achieve the state-of-the-art performance on spatial-temporal prediction.
In addition, based on the road network structure, another type of hybird models combines graph aggregation mechanism and RNN for spatial-temporal prediction [9,38,40] Different from previous studies of deep spatial-temporal prediction which all rely on a large set of training samples, we aim to transfer learned knowledge from source cities to improve the performance of spatial-temporal prediction in a target city with limited data samples.
Transfer learning and its related fields utilize previously learned knowledge to facilitate learning in new tasks when labeled data is scarce [16,17].
Previous transfer learning methods transfer different information from a source domain to a target domain, such as parameters [32], instances [1], manifold structures [3,4], deep hidden feature representations [22,37].
Recently, meta-learning (a.k.a., learning to learn) transfers shared knowledge from multiple training tasks to a new task for quick adaptation.
These techniques include learning a widely generalizable initialization [2,11], optimization trace [18], metric space [20], transfer learning skills [36].
However, only a few attempts have been made on transferring knowledge on the space.
[29] proposes a multi-modal transfer learning framework for predicting air quality category, which combines multi-modal data by learning a semantically coupled dictionary for multiple modalities in a source city.
However, this method works on multimodal features instead of spatial-temporal sequences we focus on.
Therefore, it cannot be applied to solve the problem.
For predicting traffic flow, [27] leverages the similarity of check-in records/spatial-temporal sequences between a source city and a target city to construct the similarity regularization for knowledge transfer.
Different from this method that intelligently learns the correlation which could be linear or non-linear.
Compared with both methods above, in addition, our model transfers the shared knowledge from multiple cities to a new city, which increase the stability of transfer and prediction.
In this section, we define some notations used in this paper and formally define the setup of our problem.
Definition 1 (Region) Following previous works [34,41], we spatially divide a city c into an I c × J c grid map which contains I c rows and J c columns.
We treat each grid as a region r c , and define the set of all regions as R c .
Definition 2 (Spatial-Temporal Series) In city c, we denote the current/latest timestamp as k c , and the time range as a set K c = {k c −|K c |+1, ..., k c } consisting of |K c | evenly split non-overlapping time intervals.
Then, the spatial-temporal series in city c is represented asY c = {y r c ,k c |r c ∈ R c , k c ∈ K c },(1)where y r c ,k c is the spatial-temporal information to be predicted (e.g., traffic demand, air quality, climate value).
Problem Definition Suppose that we have a set of source cities C s = {c 1 , ..., c S } and a target city c t with insufficient data (i.e., ∀s ∈ {1,· · ·, S }, |K c s | ≫ |K c t |), our goal is to predict the spatialtemporal information of the next timestamp k c t + 1 in the testing dataset of the target city c t , i.e.,y * r c t ,k c t +1 = arg max y rc t ,kc t +1 p(y r c t ,k c t +1 |Y c t , f θ 0 ),(2)where f represents the ST-net which serves as the base model to predict the spatial-temporal series.
Detailed discussion about STnet is in given Section 4.1.
More importantly, in the meta-learning paradigm, θ 0 denotes the initialization for all parameters of the ST-net, which is adapted fromY c 1 , · · · , Y c S .
In this section, we elaborate our proposed method MetaST.
In particular, we first introduce the ST-net as the base model f for spatial-temporal prediction, and then present our proposed spatialtemporal meta-learning framework for knowledge transfer.
Recently, hybrid models combining convolution neural networks (CNN) [8] and LSTM [5] have achieved the state-of-the-art performances on spatial-temporal prediction.
Thus, following [34], we adopt a CNN to capture the spatial dependency between regions, and an LSTM to model the temporal evolvement of each region.
In city c, for each region r c at time k c , we regard the spatialtemporal value of this region and its surrounding neighbors as an N × N image with v channels Y r c ,k c ∈ R N ×N ×v , where region r c is in the center of this image.
For instance, when N=3, we are considering a center cell as well as 8 adjacent grid cells of the cell, which is a 3*3 size neighborhood.
The number of channels v depends on a specific task.
For example, in taxi volume prediction, we jointly predict taxi pick-up volume and drop-off volume, so that the number of channels equals two, i.e.,v = 2.
Taking Y r c ,k c as input Y 0 r c ,k c, a local CNN computes the q-th layer progressively:Y q r c ,k c = ReLU(W q r * Y q−1 r c ,k c + b q r ),(3)where * represents the convolution operation, W q r and b q r are learnable parameters.
After Q convolutional layers, a fully connected layer following a flatten layer is used to infer the spatial representation of region r c as s r c ,k c eventually.Then, for predicting y r c ,k c +1 , we model the temporal unfolding of region r c by passing all the spatial representations along the time span {k c − |K c | + 1, ..., k c } through an LSTM, which can be formulated asi r c ,k c = σ (U i [s r c ,k c ; e r c ,k c ] + W i h r c ,k c −1 + b i ), f r c ,k c = σ (U f [s r c ,k c ; e r c ,k c ] + W f h r c ,k c −1 + b f ), d r c ,k c = σ (U d [s r c ,k c ; e r c ,k c ] + W d h r c ,k c −1 + b d ), ˆ c r c ,k c = tanh(U c [s r c ,k c ; e r c ,k c ] + W c h r c ,k c −1 + b c ), c r c ,k c = f r c ,k c • c r c ,k c −1 + i r c ,k c • ˆ c r c ,k c , h r c ,k c = tanh(c r c ,k c ) • d r c ,k c ,(4)where • denotes Hadamard product, U j , W j , andb j (j ∈ {i, f , d, c})are learnable parameters, i r c ,k c , f r c ,k c , and d r c ,k c are forget gate vector, input gate vector, and output gate vector of the i-th context feature, respectively.
h r c ,k c denotes the spatial-temporal representation of region r c , and |K c | is the number of time steps we use to consider the temporal information.
Note that e r c ,k c represents other external features (e.g., weather, holiday) that can be incorporated, if applicable.
By doing these, h r c ,k c encodes both the spatial and temporal information of region r c .
As a result, the value of the next time step of spatial-temporal series, i.e., ˆ y r c ,k c +1 , can be predicted byˆ y r c ,k c +1 = tanh(W n h r c ,k c + b n ),(5)where W n and b n are learnable parameters.
The output is scaled to (-1,1) via a tanh(·) function, to be consistent with the normalized spatial-temporal values.
We later denormalize the prediction to get the actual demand values.
We formulate the loss function of ST-net for each city c as:L c = r c k c ( ˆ y r c ,k c +1 − y r c ,k c +1 ) 2 ,(6)so as to enforce the estimated spatial-temporal value to be as close to the ground-truth y r c ,k c +1 as possible.
As introduced previously, we denote all the parameters of the ST-net as θ , and the ST-net parameterized by θ as f θ .
For better illustration, we visualize the structure of the spatial-temporal network (ST-net) in Figure 1.
Next, we propose a meta-learning framework that enables our ST-net model to borrow knowledge from multiple cities.
The framework consists of two parts: adapting the initialization and learning the spatial-temporal memory.
We present the whole framework in Figure 2.4.2.1 Adapting the Initialization.
As we described before, we are supposed to increase the stability of prediction by transferring knowledge from multiple source cities.
Since the spatial-temporal correlation of limited data in a target city may vary considerably from city to city and even from time to time.
For example, in traffic prediction, the knowledge to be transferred to Boston with limited weekend data is expected to differ from that to Chicago with limited weekday data.
Thus, the extracted knowledge from multiple cities is expected to include comprehensive spatial-temporal correlations such as spatial closeness and temporal dependency, so that we can adapt the knowledge to a target city with limited data under different scenarios.In ST-net, the parameters θ are exactly the knowledge which encrypts spatial-temporal correlations.
To effectively adapt the parameters to a target city, as suggested in model-agnostic metalearning (MAML) [2], initialization of θ from multiple source cities, i.e., θ 0 , so that the ST-net initialized by θ 0 achieves the minimum of the average of generalization losses over all source cities, i.e.,θ 0 = min θ 0 c s ∈ C s L ′ c s (f θ 0 −α ∇ θ L cs (f θ ) ).
(7)Here we would note that L c s (f θ cs ) denotes the training loss on the training set of a city c s sampled from C s , i.e., D c s (refer to S-train in Figure 2).
We illustrate the iterative update of the parameters θ c s during the training process (shown as the yellow solid arrow in Figure 2), by showing one exemplar gradient descent, i.e.,θ c s = θ 0 − α ∇ θ L c s (f θ ).
(8)In practice, we can use several steps of gradient descent to update from the initialization θ 0 to θ c s .
For each city c s , the training process is repeated on batches of series sampled from D c s .
Since Eq.
(7) Figure 2).
By optimizing the problem in Eq.
(7) using stochastic gradient descent (shown as the purple solid arrow in Figure 2), we obtain an initialization which can generalize well on different source cities.
Therefore, it is widely expected that transferring the initialization θ 0 to a target city c t would also bring superior generalization performance, which we will detail in the end of this section.
In spatial-temporal prediction, long-term spatial-temporal patterns (e.g., periodic patterns) play an important role [33,45].
These patterns reflect the spatial functionality of each region and can be regarded as the global property shared by different cities.
An example of spatial-temporal patterns and their corresponding regions are shown in Figure 3.
In this figure, one region around NYU-Tardon in New York City and another one around Georgetown University in Washington DC are selected.
The averaged 5-days' taxi demand distributions of both regions are daily periodic and similar, whose value are higher in the afternoon when students and faculties go back to home.
The similarity of distributions between different cities verifies our assumption, i.e., spatial functionality is globally shared.
However, in a target city, these patterns are hard to be captured with limited data due to missing values or the effects of special events (e.g., holidays).
Thus, we propose a global memory, named ST-mem, to store long-term spatial-temporal patterns and further transfer to improve prediction accuracy in target cities.
The framework of ST-Mem is illustrated in Figure 4.
Based on spatial-temporal patterns, we first cluster all the regions in source cities to G categories.
The categories G of regions represent different region functionalities.
For region r c , the clustering results are denoted as o r c ∈ R G .
If region r c belongs to cluster д, o r c (д) = 1, otherwise o r c (д) = 0.
Then, we construct a parameterized spatial-temporal memory M ∈ R G×d .
Each row of the memory stores the pattern representation of a category, and the dimension of the pattern representation is d.Next, we utilize the knowledge of patterns stored in memory M, and distill this knowledge for prediction via attention mechanism [14].
Since we only have short-term data in a target city, we use the representation of short-term data to query ST-mem.
In particular, we linearly project the spatial-temporal representation h r c ,k c of ST-net to get the query vector for the attention mechanism, which is formulated as:v r c ,k c = W l h r c ,k c + b l .
(9)Then, we use the query vector v r c ,k c ∈ R d to calculate the similarity score between it and the pattern representation for each category д.
Formally, the similarity score is defined asp r c ,k c (д) = exp(⟨v r c ,k c , M(д)⟩) G д ′ =1 exp(⟨v r c ,k c , M(д ′ )⟩) ,(10)where M(д) means the д-th row of memory (i.e., for the д-th pattern category).
We calculate the representation of spatial-temporal pattern z r c ,k c as:z r c ,k c = G д=1 p r c ,k c (д) * M(д).
(11)Then, we concatenate the representation z r c ,k c of spatial-temporal patterns with the representation h r c ,k c of ST-net.
And the input of the final layer h r c ,k c in Eq.
(5) is replaced by the enhanced representation i.e.,ˆ y r c ,k c +1 = tanh(W ′ n [h r c ,k c ; z r c ,k c ] + b ′ n ).
(12)where W ′ n and b ′ n are learnable parameters.
In order to learn the memory M, we construct the clustering loss of city c s , which enforce the attention scores to be consistent with Figure 2: The framework of proposed MetaST.
ST-net and ST-mem mean spatial-temporal network and spatial-temporal memory.
S-train and S-test, T-train and T-test represent the training and testing set of source tasks (i.e., source cities) and target tasks (i.e., source cities), respectively.
In the process of knowledge transfer, the parameters of ST-net will be updated by the training set in target city (i.e., T-train), while the parameters of ST-mem are fixed.
Georgetown NYU-Tandon L clu = − r c k c o r c log(p r c ,k c ).
(13)Additionally, the memory M is also updated when we train the MetaST framework, together with the initialization θ 0 .
Thus, we revise the loss function in Eq.
(7) by adding the clustering loss.
Then, our final objective function is:θ 0 , M = min θ 0 , M c s ∈ C s γ L clu (f θ cs ) + L ′ c s (f θ cs ),(14)where γ is a trade-off hypeparameter and is used to balance the effect of each part.
using testing set D ′ c s of each city c s , the memory M and initialization θ 0 are updated by gradient descent.
Note that, as we discussed before, the spatial-temporal patterns are common property between cities.
We do not update memory M when training a specific task (i.e., Eq.
(8)).
In Figure 2, the purple solid arrow indicates the process of meta-update.
In Eq.
(14), the initialization θ 0 and memory M are mutually constrained.
Since the memory M provides region-level relationship via spatial-temporal patterns, it can also help learn the initialization θ 0 of ST-net.
θ c s = θ 0 − α ∇ θ L c s (f θ ) is defined in Eq.
(8).
By To improve the prediction in target cities, we transfer the ST-mem M and initialization θ 0 of ST-net.
The black dotted line in Figure 2 shows the process of knowledge transfer.
For each new city c t sampled from C t , the memory is fixed and the parameters θ c t are trained with initialization θ 0 and training samples D c t (i.e., T-train in Figure 2), Input: Set of target cities C t ; Set of source cities C s ; hyperparameter γ Output: Spatial-temporal predictions of each target city 1 Randomly initialize θ 0 and M; 2 Cluster all regions in C s and get o r c for each region r c ;/ which is defined as:θ c t = θ 0 − α ∇ θ L c t (f θ ),(15)where L c t is the loss function of training set in target city t and the formulation is:L c t = r t k t ( ˆ y r t ,k t +1 − y r t ,k t +1 ) 2 .
(16)The predicted valuê y r t ,k t +1 is calculated via Eq.
(12).
Hence, we distill knowledge of spatial-temporal patterns from source cities to target city via ST-mem M. Finally, we evaluate the model f θ c t on testing set D ′ c t (i.e., T-test in Figure 2) of city c t and get the prediction value of this city.
The whole framework of MetaST is shown in Algorithm 1.
In this section, we conduct extensive experiments for two domain applications to answer the following research questions:• Whether MetaST can outperform baseline methods for inference tasks, i.e., traffic volume prediction in and water quality (pH value) prediction?
• How do various hyper-parameters, e.g., the dimensions of each cluster in ST-mem or trade-off factor, impact the model's performance?
• Whether ST-mem can detect distinguished spatial-temporal patterns?
5.1.1 Problem Overview.
We first conduct experiments on two traffic prediction tasks, i.e., taxi volume prediction and bike volume prediction.
Similar as the previous traffic prediction task in [33,41], each individual trip departs from a region, and then arrives at the destination region.
Thus, our task is to predict the pick-up (start) and drop-off (end) volume of taxi (and bike) at each time interval for each region.
The time inveral of traffic prediction task is one hour.
We use Root Mean Square Error (RMSE) to evaluate our model, which is defined as:RMSE = 1 |N | r t k t ( ˆ y r t ,k t +1 − y r t ,k t +1 ) 2 2 ,(17)wherê y r t ,k t +1 and y r t ,k t +1 represent predicted value and actual value, respectively.
|N | means the number of all samples in testing set.
For taxi volume prediction, we collect five representative mobility datasets from five different cities to evaluate the performance of our proposed model, i.e., New York City (NYC) 1 , Washington DC (DC), Chicago (CHI), Porto 2 , and Boston (BOS).
We use NYC, DC, Porto as the source cities and CHI, BOS as the target cities.
Note that the Boston data does not have drop-off records, and thus we only report the results on predicting pick-up volume.For bike volume prediction, we collect three datasets from four cities, i.e., NYC 3 , DC 4 , and CHI 5 .
NYC and DC are used as source cities, and CHI are used as target city.
All trips in the above datasets contain time and geographic coordinates of pick-up and drop-off.
For each city above, as discussed before, we spatially divide them to a grid map.
The grid map size of NYC, DC, CHI, BOS, Porto is 10 × 20, 16 × 16, 15 × 18, 18 × 15, 20 × 10, respectively.
Detailed statistics of these datasets are listed in Table 1.
In addition, for each source city, we select 80% data for training and validation, and the rest for testing.
For each target city, we select the 1-day, 3-day and 7-day data for training, and the rest for testing.
We compare our model with the following two categories of methods: non-transfer methods and transfer methods.
Note that, for non-transfer baselines, we only use the training data of target cities (limited training data) to train the model and use the testing data to evaluate it.
For transfer baselines, we transfer the learned knowledge from source cities to improve the prediction accuracy.
Non-transfer baselines:• Historical Average (HA): For each region, HA predicts spatialtemporal value based on the average value of the previous relative time.
For example, if we want to predict the pick-up volume at 9:00am-10:00am, HA is the average value of all time intervals from 9:00am to 10:00am in training data.
• ARIMA: Auto-Regressive Integrated Moving Average (ARIMA)is a traditional time-series prediction model, which considers the temporal relationship of data.
• ST-net: This method simply use the spatial-temporal neural network defined in Section 4.1 to predict traffic volume.
Both pick-up and drop-off volume are predicted together.Transfer baselines:• Fine-tuning Methods: We include two types of fine-tuning methods: (1) Single-source fine-tuning (Single-FT): train ST-net in one source city (e.g., NYC, DC or Porto in taxi data) and finetune the model for target cities; and (2) multi-source fine-tune (Multi-FT): mix all samples from all source cities and fine-tune the model in target cities.
• RegionTrans [27]: RegionTrans transfers knowledge from one city to another city for traffic flow prediction.
Since we do not have auxiliary data, we compare the S-Match of RegionTrans.
For each region in target city, RegionTrans uses short period data to calculate the linear similarity value with each region in source city.
Then, the similarity is used as regularization for fine-tuning.
For fair comparison, the base model of RegionTrans (i.e., the ST-net) is same as MetaST.
• MAML [2]: an state-of-the-art meta-learning method, which learns a better initialization from multiple tasks to supervise the target task.
MAML uses the same base model (i.e., the ST-net) as MetaST.
Hyperparameter Setting.
For ST-net, we set the number of filters in CNN as 64, the size of map in CNN as 7×7, the number of steps in LSTM as 8, and the dimension of hidden state of LSTM as 128.
In the training process of taxi volume prediction, we set the learning rate of inner loop and outer loop as 10 −5 and 10 −5 respectively.
For bike volume prediction, we set the learning rate of inner loop and outer loop as 10 −5 and 10 −6 respectively.
The parameter γ is set as 10 −4 .
The number of updates for each task is set as 5.
All the models are trained by Adam.
The training batch size for each meta-iteration is set as 128, and the maximum of iteration of meta-learning is set as 20000.
Spatial-temporal Clustering.
In addition, since the pattern of traffic volume usually repeats every day.
Thus, in this work, we use averaged 24-hour patterns of each region to represent its spatialtemporal pattern.
We use K-means to cluster these patterns to 4 groups.
Furthermore, in this work, we do not use other external features, which means that [ˆ y r c ,k c ; e r c ,k c ] in Eq.
(4) equals tô y r c ,k c .
We set the size of pattern representation in memory as 8.5.1.5 Results.
We implement our model and compare it with the baselines on taxi and bike-sharing datasets.
We run 20 testing times and report the average values.
The results are shown in Table 2 and Table 3, respectively.
According to these tables, we draw the following conclusions.
• Comparing with ST-net and some single-FT models, in some cases (e.g., 1-day training data), traditional time-series prediction methods (i.e., HA and ARIMA) achieves competitive performance in this problem.
The reason is that traffic data show a strong daily periodicity, so that if we only have limited traffic data, we can still use periodicity to predict traffic volume.
• Comparing with ST-net, all transfer learning models (i.e., finetune models (including Single-FT and Multi-FT models), MAML, RegionTrans, MetaST) significantly improves the performance (i.e., lower the RMSE values).
The results indicate that (1) it is difficult to train a model from random initialization with limited data; (2) the knowledge transfer between cities is effective for prediction.
• In most cases, Multi-FT outperforms Single-FT.
One possible reason is that Multi-FT increases the diversity of source domain.
In other cases (e.g., Chicago pick-up prediction with 3-day training data), the best performance of Single-FT outperforms Multi-FT.
The results implicitly indicates that if there exists a source city that is optimally transferable to the target city, simply mixing other cities may hurt the performance.
• RegionTrans models only slightly outperform their corresponding fine-tuning models (i.e., RegionTrans from NYC to Chicago v.s., Single-FT from NYC to Chicago).
The results suggest that regional linear similarity regularization may not capture complex relationship between regions.
In addition, since the data from different cities are collected from different time, regional similarity calculations may be inaccurate.
Thus, it is not an effective and flexible way to transfer knowledge via regional similarity regularization.
• MAML and MetaST achieve better performance than fine-tuning methods and RegionTrans.
This is because fine-tuning methods and RegionTrans cannot be adapted to different scenarios, and thereby decreasing the stability of transfer.
However, MAML and MetaST not only learn the initialization based on multiple cities, but also achieve the best performance in every scenario sampled from these cities.
• Our proposed MetaST achieves the best performance in all experimental settings.
Comparing with MAML, the averaged relative improvement is 5.0%.
This is because our model can also capture and transfer long-term information, besides learning a better initialization.
Moreover, the long-term pattern memory helps learn a further enhanced initialization.
The stability of knowledge transfer increases to the highest degree.
• Finally, we compare the results under different training data size in target city (i.e., 1-day, 3-day, and 7-day data).
For every learning models (except HA and ARIMA), the performance improves with more training data.
Our proposed MetaST still outperforms all baselines.
For the the dimension d of pattern representation, we change the dimension of pattern representation from 4 to 32 in spatial-temporal memory.
The performance of Chicago taxi and bike volume prediction are shown in Figure 5a and Figure 5c, respectively.
We find that the performance increases in the beginning but decreases later.
One potential reason is that the spatial-temporal memory provides too little information when the dimension is too small, while it can include too much irrelevant information when the dimension is too large.
Both of the scenarios hurt the performance.
Another experiment of trade-off factor γ also demonstrates similar assumption.
We change the parameter γ in Eq.
(14) from 10 −6 to 10 −2 .
Higher value of γ means higher importance of spatial-temporal memory.
The results of Chicago taxi and bike volume prediction are shown in Figure 5b and Figure 5d, respectively.
We can see the similar change of the performance, increasing at first but decreasing later.
-9:00pm (Pattern 3 is activated).
In R4, the volume distribution has two peaks (Pattern 4 is activated).
One peak is around 9:00am -10:00am, another one is 8:00pm -9:00pm.
The results indicate that the memory can distinguish regions with different patterns.
5.2.1 Problem Overview.
The second application studied in this work is water quality prediction task.
We also conduct a water quality prediction experiment.
In this scenario, the water quality is represented by pH value of water, because pH value is easier to measure than other chemical metrics of water quality.
We aim at predicting pH value in a specific location of next month (i.e., the time interval of water quality prediction is one month), as the changing of pH indicates the relative changes in the chemical composition in water.
RMSE is still used as the evaluation metric in this task.
Note that, in the water quality prediction task, the areas are treated as the cities in previous descriptions.
In addition, due to the sparsity of sampling points, we split each area into a grid region map, the size of each grid being 0.5°of latitude by 0.5°of longitude.
Thus, the map sizes of all the six areas are 25×50, 30×25, 35×25, 30×25, 50×25, 45×25, respectively.
The pH value of each region is represented by the median value of all sampling points in this region.
We select Pacific, West, Midwest as source areas, and Northeast, Southwest, South as target areas.
We use the same baselines as in the experiments for traffic prediction.
Both non-transfer methods and transfer methods are used to evaluated our algorithm.
Note that, when calculating HA, the relative time is monthly.
For example, if we want to predict the water quality at May, HA is the average value of all pH values at May in training data.
Hyperparameter Setting.
Similar as the traffic prediction application, we do have external features in the water quality prediction task.
For the learning process of spatial-temporal framework, we set the maximum of iterations as 5000, the number of filters in CNN as 32, the dimension of hidden states of LSTM as 64 and the size of memory representation as 4.
Other hyperparameters are the same as traffic prediction.
Spatial-temporal Clustering.
By analyzing the data, pH in the current month is strongly correlated with pH in the same month of previous year.
Thus, we use the 12-month periodic pattern of each region.
Similar as traffic prediction task, K-means is also used to cluster these patterns to 3 groups.
DTW distance is used to measure the distance of K-means.
• Comparing with Multi-FT model, the performance of MAML only slightly improves in most cases.
The potential reason is that the regions in the source areas may be homogeneous in shortterm performance.
Thus, compared to MAML which learning a initialization, simply mixing all samples (i.e., Multi-FT) may not significantly hurt the performance significantly.
• MetaST achieves the best performance compared with all baselines with the averaged relative improvement as 7.7%.
Since MetaST provides more detailed long-term information by spatialtemporal memory and distills the long-term information to target city, which explicitly increases the diversity of regions in source domain.5.2.6 Parameter Sensitivity.
Following the same step of traffic prediction task, we investigate the effect of the dimension d of pattern representation and the trade-off factor γ of two losses in the joint objective on MetaST performance.
The performance of d from 2 to 32 and γ from 10 −7 to 10 −2 on water quality value prediction is shown in Figure 7a and Figure 7b, respectively.
Both Figure 7a and Figure 7b are evaluated on Northeast water quality prediction with 3-year training data.
Accordingly, MetaST achieves the best performance when d = 4 and γ = 10 −4 .
Similar as the reasons in traffic prediction, the results indicate that suitable selection of d and γ lead to the best performance.
In this paper, we study the problem of transferring knowledge from multiple cities for spatial-temporal prediction.
We propose a novel MetaST model which leverages learned knowledge from multiple cities to help with the prediction in target data-scarce cities.
Specifically, the proposed model learns a well-generalized initialization of spatial-temporal prediction model for easier adaptation.
Then, MetaST a global pattern-based spatial-temporal memory from all source cities.
We test our model on two spatial-temporal prediction problem from two different domains: traffic prediction and environment prediction.
The results show the effectiveness and of our proposed model.
For future work, we plan to investigate from two directions: (1) We plan to further consider network structure (e.g., road structure) and combine it with our proposed model.
For example, a simple extension is that we can use graph convolutional network as our base model; (2) We plan to explain the black-box transfer learning framework, and analyze which information is transferred (e.g., spatial correlation, region functionality).
We thank Xiuwen Yi for feedback on an early draft of this paper.
The work was supported in part by NSF awards #1652525, #1618448, and #1639150.
The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agencies.
