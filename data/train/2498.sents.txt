The next decade of computing workloads is expected to be dominated by soft-real time applications such as mul-timedia and machine vision.
Such workloads are characterized by transient spikes requiring over provisioning of compute servers, adversely affecting the cost, energy usage , and environmental impact of data centers.
In many of these applications, although deadlines need to be met to provide QoS guarantees, other quality parameters of the application (for example, visual quality in video processing) can be tuned in conjunction with hardware parameters (for example, DVFS) to give acceptable performance under overload conditions.
In this paper, we experimentally demonstrate a predictive control approach for improving overload capacity and energy efficiency by incorporating control variables from both the hardware and the application layer.
Further, we illustrate the impact of the choice of multiprocessor real-time scheduling algorithms on the performance of the controller for heterogeneous workloads.
The next decade of computing is expected to be driven by the increasing pervasiveness of personal mobile computing devices and cyber physical systems.
Many of the next generation applications in entertainment, human computer interaction, infrastructure, security and medical systems are computationally intensive, always-on, and are characterized by periodic tasks with soft real time (SRT) requirements.
While failure to meet deadlines is not catastrophic in SRT systems, missing deadlines can result in an unacceptable degradation in the quality of service (QoS).
To ensure acceptable QoS under dynamically changing operating conditions such as changes in the workload, energy availability, and thermal constraints, systems are typically designed for worst case conditions.
Unfortunately, such overdesigning of systems increases costs and overall power consumption.
A possible solution to this problem is run-time adaptation of the system to handle dynamically changing operating conditions.
Previous research on cross-layer runtime adaptation has focused on open-loop control where the output has no effect on the system input and hence can only counteract against disturbances for which it has been designed [39,10,19].
In contrast in closed loop control, feedback is used to determine if real-time requirements are in met in the presence of unmodeled disturbances.
However, existing research on closed loop control for real-time workloads have been limited to the use of control inputs derived from a single layer of the computing stack such as processor DVFS or scheduling policies.In this paper we show that a higher overload capacity and better energy efficient operation of the system is possible if the control inputs are derived from all parts of the computing stack.
We note that in many of the applications described above, although deadlines need to be met to provide QoS guarantees, other quality parameters of the application (for example, visual quality in video processing) can be tuned in conjunction with hardware parameters (for example, DVFS) to give acceptable performance under overload conditions.
We formulate the real-time task execution as a Multiple-Input, SingleOutput (MISO) optimal control problem involving tracking a desired system utilization set point with control inputs derived from across the computing stack.
We assume that an arbitrary number of SRT tasks may join and leave the system at arbitrary times.
The tasks are scheduled on multiple cores by a dynamic priority multiprocessor scheduling algorithm.
Note that utilization above the set-point results in tasks missing deadlines while utilization under the set-point results in energy inefficient operation.Our cross-stack control framework is shown in Fig- ure 1.
We use a model predictive controller (MPC) to realize optimal control.
MPCs use an internal system Figure 1: Schematic representation of our cross-layer control framework model to predict the future trajectory of the output variables.
Based on a history of past control moves, a constrained optimization is solved on-line to determine the future input trajectory such that the output variables track a reference trajectory over a receding horizon.
MPCs are easy to tune, can handle multiple control variables, and constraints on both the dependent and independent variables.Following initial design using MATLAB, we experimentally demonstrate the operation of our controller on a video encoder application (x264) and a computer vision application (bodytrack) executing on a dual socket quadcore Xeon processor with a total of 8 processing cores.
All tasks including the application and the controller are scheduled by real-time dynamic task schedulers implemented in Linux using the Litmus-RT patch [13].
We evaluate the performance and energy saving of the crosslayer control for homogeneous workloads.
Further, we illustrate the impact of the choice of multiprocessor realtime scheduling algorithms on the performance of the controller for heterogeneous workloads.The rest of the paper is organized as follows -Section 2 gives a brief overview of related work.
Section 3 describes our control framework and Section 4, the evaluation methodology.
Section 5 presents the experimental setup and results.
Section 6 concludes the paper.
Most of the existing research on run-time power management targets exclusively either the hardware layer [33,31,37,29,38,2,6,17], or the application layer [3,32,5,21,4,28,34,35,22,25,26,20] or the system software layer [24,27,36,11].
Among the cross-layer open-loop approaches , the Illinois Grace project [39] uses a hierarchical adaptation at all system layers including application (frame rate and dithering for video decoding), soft real time scheduling (CPU time allocation) and CPU (DVFS) for power optimization.
The optimization problem involves maximizing quality and minimizing power with energy, processor utilization, frequency and quality of service as constraints.
Bitirgen et al. proposed a framework that manages multiple shared multicore resources in a coordinated fashion to guarantee performance objectives [10].
They formulate global resource allocation as a machine learning problem.
Hoffman, et al. [19] proposed PTRADE, a framework that coordinates a number of different hardware resource in a computing system.
PTRADE consists of two interfaces which communicates an application's performance goals and current performance, and a runtime system which determines how to optimize system performance by tuning hardware resources.
However PTRADE only works on the hardware layer.
Cucinotta, et al. [14] have proposed an adaptive resource allocation mechanism organized in two feedback loops.
The internal loop is responsible for updating the execution budget for soft real-time multimedia task so that timing constraints of the application are satisfied.
The external loop operates on the QoS level of the applications and on the power level of the resources in open loop to strike a good trade-off between the global QoS and the energy consumption.
We use a single closed loop model predictive controller to meet timing constraints while adapting power and QoS.
A multicore real-time system consists of m cores and N periodic tasks.
Under a periodic task model, each task consists of a sequence of jobs which are released periodically.
We use Global and Cluster Earliest Deadline First (G-EDF and C-EDF) scheduling algorithms to assign tasks to the cores.
Previous research has shown that for SRT tasks scheduled by EDF executing on m processors, a utilization level of m is possible with bounded tardiness [16].
In EDF, tasks with earlier deadlines are selected to run at the next scheduling point.
G-EDF uses a single unified task scheduler, ready queue, and release queue to handle all tasks.
At any instant, the task scheduler picks at most m jobs with the earliest deadlines to execute on m processors.
There is no restriction imposed on where a task can execute.
In C-EDF, all cores that share a specific cache level (L2 or L3) are defined to be a cluster; tasks are allowed to migrate within a cluster, but not across clusters; tasks assigned to a cluster are scheduled globally within the cluster under the EDF algorithm.
Typically, better load balancing is achieved with G-EDF while C-EDF promotes better data locality.
We model our system as a standard linearized, discretetime, state space model in the form below [8]:x(k + 1) = Ax(k) + B u u(k) + B v v(k) + B d d(k) y m (k) = C m x(k) + D vm v(k) + D dm d(k)(1)In Equation 1, x(k) is the n x -dimensional state vector of the plant, u(k) is the n u dimensional vector of manipulated variables, v(k) is the n v dimensional vector of measured disturbances, d(k) is the n d dimensional vector of unmeasured disturbances entering the system, and y m (k) is the n y dimensional vector of measured outputs.
The unmeasured disturbance d(k) is modeled as the output of an LTI systemx d (k + 1) = ¯ Ax d (k) + ¯ Bn d (k) d(k) = ¯ Cx d (k) + ¯ Dn d (k)(2)Where n d (k) is the random Gaussian noise with zero mean and unit covariance matrix.
The values of the set-points, measured disturbances, and constraints are specified over a finite prediction horizon P; the controller computes future inputs for a control horizon M (1 ≤ M ≤ P).
Assuming that the estimates x(k) and x d (k) are available at time k from state estimation, the future inputs at time k are obtained by solving the optimization problem [8] min ∆u(k|k),...,∆u(m−1+k|k),ε { p−1 ∑ i=0 [ n y ∑ j=1 |w y i+1, j (y j (k + i + 1|k) − r j (k + i + 1))| 2 + n u ∑ j=1 |w ∆u i, j ∆u j (k + i|k)| 2 ] + ρ ε ε 2 }(3)subject to the constraints,u jmin (i) − εV u jmin (i) ≤ u j (k + i|k) ≤ u jmax (i) + εV u jmax (i) ∆u jmin (i) − εV ∆u jmin (i) ≤ ∆u j (k + i|k) ≤ ∆u jmax (i) + εV ∆u jmax (i) y jmin (i) − εV y jmin (i) ≤ y j (k + i|k) ≤ y jmax (i) + εV y jmax (i) , i = 0, ..., p − 1 ∆u(k + h|k) = 0, h = M, ..., P − 1 ε ≥ 0(4)Here, r(k) is the value of the reference variable at time k, w ∆u i, j , w y i, j are non-negative weights for the corresponding variables.
A smaller w indicates a lower importance of the corresponding variable in the overall cost function.
u j,min , u j,max , ∆u j,min , ∆u j,max , y j,min , and y j,max are the lower/upper bounds of the corresponding variables.
The weight ρ ε of the variable ε penalizes the violation of constraints.
The relaxation vectors V u min , V u max , V ∆u min , V ∆u max , V y in , and V y max represent the penalty for relaxing the corresponding constraints; the larger the V, the softer the constraint.
If all bounds are infinite and the slack variables are removed, the problem can be solved analytically; else a Quadratic Programming (QP) solver is used.
Since the output constraints are always soft, the QP problem is never infeasible [8].
Note that only ∆u(k|k) is actually used to compute u(k).
The remaining samples ∆u(k + i|k) are discarded and a new optimization problem based on y m (k + 1) is solved the the next sampling step k + 1.
Since the states x(k) and x d (k) are not directly measurable, predictions are obtained from a state estimator.
The estimates are computed from the measured output y m (k) by the linear state observerˆxobserverˆ observerˆx(k|k) ˆ x d (k|k) = ˆ x(k|k − 1) ˆ x d (k|k − 1) + G(y m (k) − ˆ y m (k)) (5) ˆ y m (k) = C m ˆ x(k|k −1)+D vm v(k)+D dm ¯ C ˆ x d (k|k −1) (6)The gain G is designed using Kalman filtering techniques [8].
We use two soft real-time benchmarks from the Parsec benchmark suite [9] -x264 and bodytrack.
Both benchmarks were modified to confirm to an implicit deadline periodic workload model.
The x264 application is an H.264/AVC (Advanced Video Coding) video encoder.
The encoder grabs video frames periodically and encodes based on the MP4 video format specification.
The video frame resolution level ranges from 1 4 HD (230,400 Pixels per image) to full HD (921,600 Pixels per image), and is chosen as the application quality tuning knob determining the visual quality.
The bodytrack computer vision application tracks a humans movement through an image sequence periodically from multiple cameras [7] [15].
An annealed particle filter is used to track the movement of a human through the scene.The graphic output of bodytrack generates conic cylinders to represent 10 body components including torso, head and limbs.
The number of annealing layers ranging from 1 -5, and the number of particles ranging from 100 -4000, are chosen as the application quality tuning knobs.
As a measure of visual quality, the relative mean square error in the magnitude of the position vectors of the body parts for different values of the tuning knobs is used [20].
For the values of the application quality tuning knobs, the relative mean square error is less than 56%.
The benchmarks are modified such that the resolution can be updated on a per-frame basis using a global variable, with appropriate initializations redone each time the global variable is updated.
We experimentally demonstrate the operation of our cross-stack predictive control framework on a dual socket quad-core Intel Clovertown server.
This server is equipped with an Intel Xeon processor X5365 with 8MB on-die L2 cache 1.333 GHz FSB and a 16 GB main memory.
The processor supports four DVFS level: 3.0, 2.67, 2.33 and 2.0GHz.
The operating system is Linux 2.6.36 kernel patched with Litmus-RT-2011.
Litmus-RT implements several real-time multiprocessor scheduling and synchronization algorithms for Linux [13].
Each soft real-time task is mapped to a single thread and is independent of other tasks.
In our work, the x264 encoder grabs video frames periodically at 25 fps and bodytrack processes a new frame at 20 fps.
Actuators update the processor operational frequency and the application quality tuning knob values.
Prior to applying the manipulated variables to the hardware and the application stack, the actuators filter these through a modulator to allow for fine-grained control.
We use a first order delta-sigma modulator for the frequency actuator and a pulse width modulator for the application tuning knob actuator.
Compared to the pulse width modulator, the first order delta-sigma modulator provides higher accuracy but incurs larger overhead due to oversampling.
Hence first order delta-sigma modulators are more suitable for frequency actuators due to the small transition latency for DVFS (10 µs).
However, the latency associated with the application tuning knobs may be up to 500 µs, precluding the use of oversampled techniques.In each control period, the actuator reads the frequency and application tuning knob values from the controller, filter these through the modulator, and then writes the modulated values to the hardware and the application stack.
Frequency actuator utilizes a Linux kernel subsystem called cpufreq to dynamically scale values of the operational frequency.
Application quality actuator updates the tuning knobs, which are global variables protected by a real-time Flexible Multiprocessor Lock Protocol (FMLP) read-write lock [12].
FMLP is used to prevent deadlock and priority inversion in multiprocessor systems.
In every control period, the MPC controller reads the system utilization from a sensor implemented as a custom Linux system call to calculate average percore execution time over one control period.
For both benchmarks, we obtain the system utilization for randomly generated combination of inputs including CPU frequency, application quality, and number of tasks for 400 control periods.
The Hubble video [1] and the camera image sequence input from the Parsec benchmarks are used in executing x264 and bodytrack respectively.
We use the first half of working data for data modeling and the other half of data for validation.
We use n4sid algorithm from the MATLAB System Identification Toolbox [23] to generate the state space models given in Equation 1.
For our model, n x = 1, n u = 2 (frequency and application quality), n v = 1 (number of tasks), n d = 1 (job level variations in the execution time), and n y = 1 (system utilization).
The first-order model has a fit of 84.8% for x264 and 87.4% for bodytrack.
The Model Predictive Controller is designed using the MATLAB MPC Toolbox [8].
The tunable parameters of the MPC controller include control horizon, prediction horizon, input and output weights, blocking modes, and disturbance model.
The disturbance model is obtained by low-pass filtering a Gaussian white noise.
We manually tune these parameters one at a time to obtain a good step response for the controller.
The optimized controller parameters for both x264 and bodytrack are shown in Table 1.
The control interval is chosen as 1 second, which is about 1/20-th of the open loop settling time.
The closed loop poles of the unconstrained controller lie within the unit circle.
The controller is implemented as a real-time task.
Four our m = 8 core system, we set the task utilization set point arbitrarily to 4.
Note that in a production system, Figure 2: Average FPS versus number of tasks -under no control, MPC control with DVFS-only, MPC control with application quality-only, and cross-layer MPC control the choice of the set-point is dictated by the processor capacity required to run non-real time background tasks.
We demonstrate the need for the controller by measuring the average frame rate both with and without feedback control, as the workload is varied from light to heavy.
A G-EDF scheduler is used to schedule all the tasks.
As seen from Figure 2, in the absence of the controller, the frame rate drops beyond 11 tasks for x264 and 8 tasks for bodytrack.
For our 8 core system, the lowered frame rate indicates that the system is in overload.
However, unlike the non-control case, the feedback controller is able to maintain a constant frame rate by automatically adjusting the processor frequency and the application quality.
Figure 2 also shows the advantage of a cross-layer approach to feedback control as compared to deriving the control variables from a single layer of the computing stack.
For both x264 and bodytrack using DVFS-only or application quality-only as the control variable, results in a sharper drop in the frame rate with a heavier task load as compared to the cross-layer control.For the bodytrack application, Figure 3 shows the controller s step response to a change in the number of tasks from 5 to 9.
As expected, the controller responds to a higher load by increasing the frequency while decreasing the visual quality to maintain the set-point within 5% with a peak overshoot of 29.7% and a settling time of 3.8 seconds.
Since typical task change period is of the order of tens of seconds, this settling time suffices.To evaluate the power savings obtained by our crosslayer control approach, we compare the average power consumption of the controller to the non-control case where the cores run at maximum frequency and the tasks operate at maximum application quality.
The power savings are evaluated based on the power model described in [18], with the power proportional to the cube of the operating frequency.
For a pseudo-random number of homogeneous input tasks, our model predictive control approach shows an average power saving of 31% compared to the non-control implementation for x264 and an average power saving of 26% for bodytrack.
The power saving is obtained at an average application quality of 70% for x264 and 65% for bodytrack.
We also investigate the choice of the real-time scheduling algorithms on the performance of the the cross-layer feedback controller when the system hosts heterogeneous tasks from multiple applications (x264 and bodytrack).
In global-EDF scheduling, tasks from both the applications are scheduled globally across all 8 cores.
In clustered-EDF scheduling, the applications run on separate clusters with tasks from a single application assigned to a cluster of 4 cores sharing the L2 cache.
In both cases, separate controllers are designed for the two applications.
Unfortunately, our hardware platform does not allow independent control of the core frequencies, limiting us to application quality as the only control variable for this experiment.
Figure 3: Experimental evaluation of model predictive control system step response for bodytrack.
At t = 50s, the number of tasks changes from 5 to 9.
unbalanced workload, where the applications have dissimilar number of tasks, we note that G-EDF with its superior load balancing capability performs better.
However, for a balanced but heavy workload with large number of tasks for both applications, load balancing is less of any issue.
For this case, C-EDF with its better data locality performs better.
Run-time characteristics of the two workloads depends on the video inputs.
Since the x264 controller was designed using a single video input, we investigate the performance of the controller for other types of video inputs.
To characterize the similarity of two videos, we compare the probability distributions of the average execution times over a control period using the KolmogorovSmirnov (KS) [30] test.
For 10 highly viewed test videos drawn from YouTube with content ranging from music, sports, movie clips, news reports, and documentaries, we observe that the controller performs well if the test video has a similar KS statistic to the input video.
We note that for 8 videos out of 10 the controller shows acceptable performance.
As a part of future work, we could implement a gain-scheduling approach, where separate controllers are designed for videos with significant difference in the KS statistic.
A video classifier would periodically evaluate the video content and load the appropriate controller.
The periodic classification approach could also be used to handle videos where the execution characteristic changes with time.
A similar gain scheduling approach can also be applied to bodytrack.
The controller overheads include 1) computation cost of the MPC controller, 2) overheads due to DVFS and 3) real-time synchronization cost in modifying shared global variables in the application.
The MPC controller uses a quadratic programming (QP) solver whose computation complexity is polynomial time in the product of number of control outputs and and prediction horizon.
In one control period (1 second in our experiments), the core frequency is changed 20 times by the sigmadelta modulator.
The overall DVFS overhead is measured using high resolution Linux timers and accumulated through all the subintervals within a control period.
The synchronization occurs when the application parameters are updated.
Our measurements indicate that for both x264 and bodytrack, the overheads associated with DVFS dominates, and the total overhead is less than 0.4% of one control period.
In this paper we have demonstrated that a cross-layer approach to control enables the system to track large variations in the number of tasks allowing operation under heavily overloaded conditions while meeting timing requirements for soft real-time workloads.
Moreover, the use of DVFS and application quality as control variables allows operation at a lower average power (and thereby lower energy for fixed run-time workloads) while meeting real-time constraints as compared to non cross-layer control approaches.
Additionally, we show that the depending on the workload, the choice of the real-time scheduling algorithm impacts the performance of the controller.
Also, the model predictive approach to control readily incorporates practical constraints on the output and control variables.
Since the controllers are independent and have low overhead, the proposed framework scales well with the number of tasks and with multiple applications.
Future extensions of our work would include gain scheduling for handling input dependent workload behavior and additional hardware and application parameters for a richer control of the system powerperformance trajectories.
The authors would like to thank Dr. Tyrone Vincent for helpful suggestions.
