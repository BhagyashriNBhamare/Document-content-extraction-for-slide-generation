Source classification has been widely studied in conventional coding of image and video signals.
This paper explores the idea of exploiting so-called classification gain in Wyner-Ziv (WZ) video coding.
We first provide theoretical analysis of how source classification can lead to improved Rate-Distortion tradeoff in WZ coding and quantify the classification gain by the ratio of weighted arithmetic mean to weighted geometric mean over sub-sources.
Then we present a practical WZ video coding algorithm based on the source classification principle.
The statistics of both spatial and temporal correlation are taken into account in our classification strategy.
Specifically , the subsource with the steepest R-D slope is identified to be the class of signif icant wavelet coefficients of the blocks that are poorly motion-compensated in WZ frames.
In such classification-based approach, rate control is performed at the decoder which can be viewed as the dual to conventional video coding where R-D optimization stays with the encoder.
By combining powerful LDPC codes (for generating coded information) with advanced temporal interpolation (for generating side information), we have observed that the new Wyner-Ziv coder achieves highly encouraging performance for the test sequences used in our experiments.
For example, the gap between H264 JM11.0 (I-B-I-B...) and the proposed WZ video coder is dramatically reduced for f oreman and hall QCIF sequences when compared with the best reported results in the literature.
Recent advances in sensor networks have spurred renewed interests in so-called distributed source coding (DSC) problem.
17,27 More than twenty years after Slepian and Wolf's theorem 24 on lossless distributed coding, practical SW coding algorithms for binary sources appeared -e.g., syndrome based, 18 Turbo codes based 1, 8 and lowdensity parity-check (LDPC) based.
14 Meantime, much progress has been made on developing practical WynerZiv (WZ) coding 26 algorithms (e.g., nested lattice codes 13,22,28,32 ) which are the lossy counterpart of SW coding.
The gap between theoretical limits (SW and WZ bounds) and practical algorithms has been almost closed for the class of idealistic sources.However, significant challenges remain on the design of DSC algorithms for practical sources such as video.
In so-called WZ video coding, 3, 4, 21 a down-sampled version of video (called "key frames") is coded by standard intraframe coders and distributed coding is applied to the remaining frames (called "WZ frames").
Unfortunately the efficiency of very best WZ video coding algorithms is still dramatically lower than that of H264 coders which represent the state-of-the-art in conventional motion-compensated predictive (MCP) coding (refer to the reviewing article 9 and sessions on DVC in ICIP '2004-2007).
For example, the rate-distortion (R-D) performance of WZ video coder is still over 2dB lower than that of H263+ coder 9 (note that H264 achieves over 20% bit savings over H263 on typical QCIF sequences 10 ).
Another more recent study 6 also reported at least 5dB gap between H264 coder and DVC (both LDPC and Turbo codes are considered in that work).
Such pessimistic findings suggest that the design of WZ video coding systems calls for a radically different approach.In this paper, we explore a new direction in WZ video coding -i.e., to classify video data into several subsources and identify the one with the steepest WZ R-D slope.
Our approach is partially motivated by the success of classification-based approaches in still image coding (e.g., EZW, 23 SPIHT, 20 forward classification 7 and backward classification 19 ).
In parallel to classification gain defined for image coding in, 7 we provide a theoretical analysis of how source classification could also lead to potential gain in WZ coding.
For idealistic Gaussian sources whose WZ R-D function is known, we can rigorously show that the classification gain is nonnegative.
Such theoretical justification serves as the basis for designing practical WZ video coding algorithms to exploit the potential classification gain.
Figure 1.
The diagram of our proposed WZ video coding system: the double-dashed line indicate the feedback channel to provide encoder the classification information from the decoder (bold-type components highlight the innovations of this system).
In our new WZ coding system (refer to Fig. 1), video source is divided into four classes based on spatial correlation (significance of wavelet coefficients) and temporal correlation (accuracy of interpolated WZ frames).
It follows from our theoretical results that bits should be allocated to the class of significant wavelet coefficients within the blocks of WZ frames that are not well motion compensated at the decoder.
Such rate control does require a feedback channel to inform encoder which blocks require the transmission of coded information (CI) but at a minimal rate of 1 bit/block (similar rate control strategy was also adopted in previous WZ video coding systems 9 and it is argued that such strategy has the advantage of keeping encoder unchanged and decoder highly flexible).
However, since decoder does not have access to the original WZ frames, generation of block-based classification information is nontrivial.
We propose a classification strategy using key frames only based on the scale invariant assumption of temporal correlation structure.Since motion compensation (MC) in WZ video coding is performed at the decoder instead of encoder, the constraint on motion field representation is removed.
Therefore, sophisticated temporal interpolation schemes such as temporal interpolation based on explicit 25 and implicit 11 MC can be used to generate highly accurate side information (SI).
We note that the accuracy of SI plays a critical role in DVC -on one hand, it directly determines the distortion upper bound at the decoder when no bit is received (D * W Z (0)); on the other hand, it indirectly affect the rate at the encoder through the virtual correlation channel.
For instance, if more accurate SI leads to a smaller cross-channel probability P e , then the channel codes of a higher rate (e.g., irregular LDPC 14, 30 ) could be used to achieve higher coding efficiency.
We have found even ad-hoc averaging of the interpolation results by explicit and implicit MC achieved noticeable PSNR improvements.
Let X I = {x ap , p = 0, 1, 2, ..., } (a is a positive integer) denote key frames and X W Z = {x ap+r , r = 1, 2, 3, ..., a−1} denote WZ frames.
If we write SI (interpolated WZ frames from key frames) by y t = ˆ x t , t = ap+r, the correlation model might be given by y t = x t + z t where z t characterizes the errors of temporal interpolation.
If x t , z t observe stationary Gaussian distributions, the WZ Rate-Distortion function is known (e.g., refer to the tutorial paper 27 )R * W Z (D) = R x|y (D) = 1 2 log + [ σ 2 xz D ].
(1)where log + x = max(log 2 x, 0) andσ 2 xz = σ 2 x σ 2 z σ 2 x +σ 2 z (i.e., the harmonic mean of σ 2 x and σ 2 z ).
Indeed, most existing WZ video coding algorithms 2-4 can be viewed as assuming a stationary Gaussian correlation model.
However, in practice both x t and z t manifest nonstationary properties due to the spatio-temporally varying nature of object and motion characteristics.To see how the nonstationarity of a source could affect the WZ R-D performance, we consider the following simplified two-class model:x t ∼ N (0, σ 2 x,0) with probability of p N (0, σ 2x,1 ) with probability of qwhere x t denotes the wavelet transform (WT) of WZ frames and q = 1−p is the probability of significant wavelet coefficients (σ x,0 << σ x,1 ).
Such two-class model is closely related to classification-based image coders in the literature (e.g., refer to the quantification of classification gain 7 ).
Additionally, we propose to characterize z t by a similar two-class mixture model:z t ∼ N (0, σ 2 z,0) with probability of p N (0, σ 2 z,1 ) with probability of qwhere z t denotes the interpolation errors of WZ frames and q = 1 − p is the probability of significant errors (e.g., due to fast and deformable motion).
Despite the crudeness of two-class models, we argue they are sufficient for analyzing the gain associated with classification in DSC.
Instead of modeling the video by a stationary source, we can decompose it into four subsources based on σ x , σ z and formulate the following R-D optimization problem:min D = k a k D k (R k ) subject to the constraint k a k R k = R (note that k a k = 1 -in our case, a 1 = pp , a 2 = pq , a 3 = qp , a 4 = qq ).
For the (2i + j)-th subsource (i, j = 0/1), its WZ R-D function is given by 1 2 log + [ σ 2 2i+j D ] where σ 2 2i+j = σ 2 x,i σ 2 z,j σ 2 x +σ 2 z .
Similar to the derivation in image coding, 7 we can use Lagrangian multiplier method to derive the optimal rate-allocation strategyR k = R + 1 2 log 2 σ 2 k l (σ 2 l ) a l .
(4)and the optimal distortion is given byD * (R) = 2 −2R σ 2 gm .
(5)where σ 2 gm = k (σ 2 k ) a k denotes the weighted geometric mean of the variance of mixture sources.
Since in the stationary Gaussian model the variance of a mixture source is given by the weighted arithmetic mean -i.e.,σ 2 x = qσ 2 x,1 + pσ 2 x,0 , σ 2 z = q σ 2 z,1 + p σ 2 z,0, we can quantify the classification gain in DSC similar to that in the conventional source coding 7G W Z c = 10 log 10 σ 2 xz σ 2 gm (dB).
(6) It is easy to observe G W Z cis non-negative due to the fact that the geometric mean is upper bounded by the arithmetic mean (a detailed proof can be found in the Appendix).
Although the above result appears similar to the classification gain formula in image coding, 7 we note that the harmonic meanσ 2 xz in WZ R-D function R * W Z (D) plays a subtle here.
Since σ 2 xz ≤ min{σ 2 x , σ 2 z }, we conclude that the R-D slope of R * W Z (D)becomes steep if and only if both σ 2 x and σ 2 z are large.
Such observation suggests that spatial and temporal correlation of the video source, which affect σ 2 x and σ 2 z respectively, are both important to the R-D performance of WZ video coders.
In particular, classification based on σ 2 z is nontrivial because decoder does not have access to the original WZ frames (i.e., how do we know whether σ 2 z (variance of z t = ˆ x t − x t ) is large or not without the knowledge of x t ?)
.
We will elaborate on this issue next and propose a source classification strategy based on the information of key frames only.
Let us study the classification based on σ 2 z first.
One primary challenge is: original (x t ) and interpolated (y t = ˆ x t ) WZ frames are only available at the encoder and decoder respectively.
Therefore, it is nontrivial to estimate the variance of z t = y t − x t at the decoder without the knowledge about x t .
One way of getting around this difficulty for a = 2 is to assume scale invariant property of z t (conceptually similar to the idea used in new edge directed interpolation 12 ).
Specifically, we will treat key frames x 2t as a coarse-scale representation of x t and apply temporal interpolation to them.
Based on the interpolated frames y 2t = ˆ x 2t = f (x 2t−2 , x 2t+2 ), we can have the estimation of z t at the coarse scale -i.e., z 2t = y 2t − x 2t .
The variance of z 2t will be used as the approximation of σ 2 z at odd-indexed frame 2t − 1 (refer to Fig. 2).
Then blocks of large variance σ 2 z > th (th is a pre-selected threshold) are declared to be poorly-MC ones (class σ 2 z,1 ) and their positions are stored into a binary saliency map and transmitted to the encoder through the feedback channel (the required bandwidth is small -99bits/frame for QCIF sequence when M B = 16).
Figure 2.
a) Estimating σ 2 z at the decoder from key frames based on scale-invariant property of z t : the variance estimation problem at the fine scale (denoted by dashed arrows) is approximated by a dual problem at the coarse scale (denoted by solid arrows); b) Oracle (fine-scale) and actual (coarse-scale) saliency maps for hall and f oreman sequences.Theoretical results in Eq.
(4) imply that few bits should be allocated to the class of well-MC blocks (R k → 0 as σ z,0 → 0); therefore we can simply skip them in WZ coding.
For poorly-MC blocks, we apply WT and further divide the high frequency-band coefficients into significant (class σ 2 x,1 ) and insignificant (class σ 2 x,0 ) coefficients.
Although more sophisticated classification schemes exist, we choose significance-based for its simplicity in implementation.
Using similar arguments, we conclude that the class of insignificant coefficients can be skipped (R k → 0 as σ x,0 → 0).
Therefore, only the class of significant coefficients in poorly-MC blocks need to be coded (R k > 0 for class σ x,1 , σ z,1 ).
Specifically, our WZ encoding strategy for significant coefficients of poorly-MC blocks consists of two stages: 1) where are the significant coefficients?
We assume significance maps S x , S y are correlated where S x = {(i, j) : |x(i, j)| > δ} (S y is defined similarly); therefore we can use H(S x |S y ) ≤ H(S x ) to achieve SW lossless compression of S x .
2) what are the significant coefficients?
Conditioned on S x , intensity values of significant coefficientsy s = x s + z (x s = {x(i, j) : (i, j) ∈ S x }) are correlated through a virtual Gaussian channel z ∼ N (0, σ 2z,1 ); therefore we can approach R x|y (D) instead of R x (D) by WZ lossy coding.
Such two-stage encoding is conceptually similar to the well-known zerotree-based wavelet image coding algorithms such as EZW 23 and SPIHT 20 though the compression of significance map and intensity values is achieved by channel coding techniques in DSC scenario.
Since significance map is binary, many existing DSC techniques for memoryless binary source can be adapted to handle S x .
In the simplest case, the virtual correlation channel between S x and S y is specified by a bounded hamming distance -i.e., D[S x , S y ] ≤ d, then we can use a block code (n, k, d min ) where d min = 2d + 1 (i.e., to transmit HS x instead of S x where H m×n , m = n − k < n is the parity check matrix).
More powerful channel codes (e.g., trellis codes, 16 Turbo codes 1, 8 and LDPC 14 ) have been successfully applied to distributed coding of correlated binary source.
We have adopted LDPC-based scheme 14 since it has achieved the best performance in the literature and there exists a rich class of high-rate LDPC codes 30 (note that a higher rate k n implies a higher compression ratio R since R = n n−k ).
To satisfy the binary symmetric channel (BSC) condition (crossover probability p e is given by D[S x , S y ]/length(S x )), standard interleaving techniques 5 are used to transform burst errors into random ones.
In our experiments, we have adopted a class of LDPC codes with the rate of 1/2 for p e ≤ 0.10.
Conditioned on the significance map S x , WZ coding is applied to the set of coefficients x s only.
In the simplest case (scalar quantization), we can concatenate a uniform quantizer with a SW lossless coding as used in.
2,9 More sophisticated quantization schemes often involve nested lattice 22,28,32 or trellis coded quantization.
13 In view of relatively minor role of quantization in wavelet-based image coders, we opt to only implement WZ coding based on uniform quantization in our baseline scheme.
For given LDPC codes with appropriate rates chosen for the virtual correlation channels, the total bit rate of our new WZ video coding scheme is jointly determined by the two thresholds: one related to σ z for poorly-MC blocks (th) and the other related to σ x for significance testing (δ).
More systematic study on successive rate control (e.g., layered WZ video coding 29 is outside the scope of this work.
Unlike traditional MCP video coders in which decoder is often fixed and encoder has great flexibility, decoder is highly flexible in WZ video coding systems.
The final distortion given by WZ decoder is determined by the joint exploitation of SI and received parity bits or coded information (CI).
To justify the importance of SI in WZ video coding, we note that: 1) SI directly determines the distortion of WZ decoder at R = 0 (the starting point of WZ R-D curve D * W Z (0)); 2) more accurate SI can reduce σ z which leads to an improved R-D tradeoff according to Eq.
(6).
Since SI is generated by interpolating WZ frames from the key frames, how to effectively exploit temporal redundancy is critical to the accuracy of SI.
Especially since there is no rate constraint on motion representation in DVC, temporal interpolation can be based on sophisticated motion models with arbitrary density and accuracy.We have compared two competing approaches here: explicit MC based such as multi-hypothesis motion compensation temporal interpolation (MMCTI) 25 with subpixel accuracy and translation invariant enhancement (a variant of overlapped block motion compensation 15 ) and implicit MC-based such as our Least-Square based approach.
11 It has been found that explicit MC based approach is more effective on video sequences containing fast motion (e.g., f ootball) while implicit MC based approach is preferred on slow-motion sequences (e.g., container).
For genetic sequences, we have found that averaging the interpolated results by two approaches often achieves even further MSE due to their complementary properties.
More sophisticated fusion strategy is possible but outside the scope of this work.Based on the interpolated WZ frames, we first obtain S y (significance map of high-activity blocks) and apply LDPC-based decoding algorithm 14 to recover S x .
When the parameter of LDPC code matches the underlying correlation channel between S x and S y , the decoding error probability is infinitesimal (more parity bits can be requested upon the detection of decoding failure).
Then we apply WZ decoder to the set of significant coefficients y s to recover x s (conditioned on S x ).
For idealistic source (e.g., i.i.d Gaussian), good lossy WZ coding scheme exists -for example, combined trellis-coded quantization (TCQ) and low-density parity codes (LDPC) in 31 has achieved R-D performance within 0.7dB of the WZ bound.
For simplicity, we consider a simplified correlation model between x and y * -i.e., y = x + z where z ∼ N (0, σ 2 z ).
* To simplify the notation, we have omitted superscript s from x s , y s and subscript 1 from σ z,1 here.The decoding of x based on y and I = Q(x) can be formulated as a minimum MSE (MMSE) estimation problem.
31 The Bayesian MMSE estimator is given byE[x|y, I] = x xP (x|y, I)dx = x xP (x, I|y) P (I|y) dx = 1 C x xP (I|x)P (x|y)dx,(7)whereC = P (I|y) = x P (x, I|y)dx = x P (I|x)P (x|y)dxis the normalizing constant and we have made the assumption that y → x → I forms a Markov chain.
31 The two conditional probabilities in Eq.
(7) can be calculated as follows.
For any real value x ∈ R, P (I|x) is simply a binary indicator function 1 Q(x)=I ; by contrast, P (x|y) ∼ N (y, σ 2 z ) is specified by the correlation model.
Since the variance σ 2 z is generally unknown in practice, we have derived an iterative algorithm for estimating it from the given data.The basic idea behind our iterative estimation is to observe that x and σ z are a pair of peer latent variables.
Knowing x easily leads to the maximum likelihood (ML) estimation of σ z and vice versa.
When neither is known, it is natural to resort to variational Bayesian techniques to solve such chicken-and-egg problem.
Given variance estimation at iteration n, we can obtain MMSE estimation of x (n) by Eq.
(7); then the variance estimation is updated by σ(n+1) z = |x (n) − y|.
Starting with an initial guess of σ (0) z (we typically set it to be 10), we can alternate the estimation of two missing variables until it converges.
Since the convergence is usually difficult to prove, we have adopted an ad-hoc stopping rule -terminate after three iterations.
We have found that despite the iterations involved, WZ decoding based on empirical Bayesian estimation of σ z remains computationally efficient.
The computational bottleneck of WZ decoder is still at the step of SI generation.
In this section, we report our experimental results to demonstrate the potential of proposed classification-based WZ video coding algorithm.
The test sequences are chosen to be QCIF-resolution f oreman (fast motion) and hall (slow motion).
For these two sequences, previously known WZ video coding algorithm significantly falls behind H.264 as reported in.
6 The source codes of H.264 codec (JM11.0) are downloaded from http: //iphome.hhi.de/suehring/tml/download/.
In our experiment, a similar setting to transform-domain WZ video coding 2 is adopted: even frames are coded as I-frames and odd frames are B-frames; decoded I-frames at the decoder are used to interpolate the even (WZ) frames as SI; the R-D function is calculated for odd-frames only (they are B-frames in H264 and WZ frames in DVC).
The MATLAB codes accompanying this paper can be accessed at http://www.csee.wvu.edu/~xinl/code/WZVC.zip.The implementation details of our new WZ video coding algorithm are as follows.
Each WZ frame is decomposed into 16 × 16 macroblocks (MBs) and block-based classification is based on the 9 × 11 binary saliency map transmitted by feedback channel.
For salient MBs, a 3-level wavelet transform with Daubechies' 9-7 filter is applied.
The thresholds for saliency detection th and significance testing δ jointly determine the rate of CI (quantization stepsize of uniform quantizer ∆ is fixed to be 8 in our experiments).
Both significance map and indexes of quantized significant coefficients are coded by LDPC-based SW coding algorithms.
14 The class of irregular LDPC codes with rate of 1/2 are adopted to match both correlation channels (location and intensity).
Interpolated WZ frames (SI) are taken as the average of two temporal interpolation schemes based on implicit and explicit MC.
SI is first used along with received bits to decode significance map and indexes of quantized significant coefficients (we make sure zero BER is achieved in our simulations).
Then SI and decoded location/intensity information are jointly exploited to further reduce the distortion of significant coefficients.To illustrate how the proposed WZ video coding algorithm works, we take the first 30 frames of f oreman QCIF sequence as an example.
For the parameter setting of th = 6, δ = 9, approximately 18.3% of MBs are declared poorly-MC (refer to Fig. 2b); the cross-channel probabilities for significance map and indexes of quantized significant coefficients are 0.0649 and 0.0739 respectively.
A LDPC code 14 of rate 1/2 (n = 10000, k = 5000) is used for lossless SW encoding of both location and intensity information (some zeros are padded to make the length of binary bit stream multiples of n = 10000).
The parameters associated with the used LDPC codes areλ(x) = 0.234029x + 0.212425x 2 + 0.146898x 5 + 0.102840x 6 + 0.303808x 19 , ρ(x) = 0.71875x 7 + 0.28125x 8 .
We have verified no bit error appears at the decoder (our choice of LDPC codes is relatively conservative; in fact more bit errors can be tolerated).
The SI is generated by the average of two interpolation results: explicit MC and implicit MC (refer to Fig. 3a).
It can be observed that even ad-hoc averaging can reduce MSE by as much as 1dB due to the complementary property of interpolated WZ frames.
Fig. 3b shows how the received parity bits can further lower down the MSE value by another 2.31dB.
To demonstrate the performance of our WZ video codec, we have compared ours with the current state-ofthe-art codec (H.264/JVT JM11.0) on the first 30 frames of f oreman and hall † QCIF sequences.
The R-D curve for H.264 codec is generated by setting the QP of B-frame to 17, 19, 24, 29 (we manually record the average number of bits per frame); the R-D curve for our own WZ video codec is generated by adjusting two threshold parameters (th, δ).
Similar to the comparison between H264 and DVC, 6 we have also included H264 intra-frame coding as the benchmark to facilitate the evaluation (readers are suggested to compare our results with Fig. 4 in a recent study 6 ).
It can be seen from Fig. 4 that the proposed WZ video coder falls behind H264 Inter-frame coding by 2 − 4dB for f oreman sequence and less than 2dB for hall sequence.
Given the conservative use of LDPC codes (they can correct more errors than p e = 0.06 − 0.08) and ad-hoc fusion strategy in SI generation, we believe this gap can be further reduced.
When compared with the results reported in the previous work 2 using the same GOP structure (I-B-I-B...), we have achieved noticeable gain -for instance, at the bit rate of 150Kbps (5000 bits per frame), transform-domain WZ video coder 2 achieves 37.5dB on f oreman QCIF while ours reaches 39.3dB.In the last experiment, we want to illustrate the impact of motion characteristics on the performance of WZ video coding.
Two other QCIF sequences: container (slow and rigid motion) and f ootball (fast and deformable motion) are selected for this purpose.
When motion is slow, temporal interpolation based on implicit MC 11 achieves high accuracy, which gives rise to virtual correlation channel with very small σ 2 z .
However, as motion becomes fast and deformable, temporal interpolation becomes much more difficult.
When the characteristics of virtual correlation channel gets worse, more zero bits can be padded to lower the p e value though at the price of coding efficiency loss.
Fig. 5 Figure 4.
PSNR performance comparison between H264 Inter-frame coding ('+'), H264 Intra-frame coding ('*') and the proposed WZ video coding ('o') for f oreman (left) and hall (right).
video coder.
It is interesting to note how the performance of WZ video coder heavily depends on the accuracy of SI.
Unlike conventional video coding, MC in WZ coding does not have access to original frames but involve no overhead on motion representation, which favors the class of slow and rigid motion (noticeable gain over H264 Inter can be observed on the container sequence).
In this paper, we address the importance of source classification in WZ video coding.
Using simplified source models, we provide theoretical analysis of decomposing a source into several subsources and quantify the classification gain in DSC which is dual to that in conventional source coding.
To exploit the potential classification gain, we propose a new WZ video coding system which identifies the class of signif icant wavelet coefficients in poorly motion-compensated blocks as the class with the steepest R-D slope.
The location and intensity information of the selected coefficients are coded by lossless SW encoder using irregular LDPC codes.
Decoder sequentially decode location and intensity information and final reconstruction result is refined by iterative MMSE estimation.
Highly encouraging experimental results are reported to support the effectiveness of the proposed WZ video coding system.Several open issues remain to be explored in the future.
First, estimation of σ 2 z (measurement of MC accuracy) at the decoder deserves further investigation.
As we can see from Fig. 2b, classification errors exist especially for the last three frames of fast-motion sequence such as f oreman.
Such errors are caused by the invalidity of scaleinvariant assumption we made about z t .
More robust classification information about σ 2 z at the decoder should further improve the coding efficiency of the system.
Second, the generation of SI is still suboptimal because motion-compensated temporal interpolation (MCTI) problem appears under-studied in the literature.
We have found explicit and implicit MC-based approaches are suitable for sequences containing fast and slow motion respectively, which explains the effectiveness of ad-hoc averaging strategy adopted by this work.
Intuitively, optimal MCTI solution should rely on more intelligent fusion of interpolation results from different MC models.
However, without the access to the original WZ frames (only available at the encoder), smart fusion remains a tantalizing issue but important to the quality of SI.
Third, the matching between conceived virtual correlation channel and the rate of LDPC codes has not been addressed in this paper.
There still lacks a rigorous R-D optimization framework at the decoder to control the rate through feedback channel based on the statistics of virtual correlation channel.
The author wants to thank Prof. Zixiang Xiong at Texas A&M University for providing him a copy of the implementation of LDPC-based DSC algorithm.
14 xIn this Appendix, we provide a rigorous proof about the nonnegativity of classification gain in WZ coding.
For notational simplicity, we only consider the case of K = 2 where source x is divided into two subsources (K = 4 can be handled in a similar fashion).
When K = 2, the targeted inequality σ 2 xz ≥ σ 2 gm boils down towe first use the inequality that geometric mean is upper bounded by arithmetic mean -i.e.,Then in order to show the RHS of Eq.
(9) is upper bounded by the LHS of Eq.
(8), we note their difference can be written as In this Appendix, we provide a rigorous proof about the nonnegativity of classification gain in WZ coding.
For notational simplicity, we only consider the case of K = 2 where source x is divided into two subsources (K = 4 can be handled in a similar fashion).
When K = 2, the targeted inequality σ 2 xz ≥ σ 2 gm boils down towe first use the inequality that geometric mean is upper bounded by arithmetic mean -i.e.,Then in order to show the RHS of Eq.
(9) is upper bounded by the LHS of Eq.
(8), we note their difference can be written as
