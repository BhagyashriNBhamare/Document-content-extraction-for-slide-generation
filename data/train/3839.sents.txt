We build a system that provides succinct non-interactive zero-knowledge proofs (zk-SNARKs) for program executions on a von Neumann RISC architecture.
The system has two components: a cryptographic proof system for verifying satisfiability of arithmetic circuits, and a circuit generator to translate program executions to such circuits.
Our design of both components improves in functionality and efficiency over prior work, as follows.
Our circuit generator is the first to be universal: it does not need to know the program, but only a bound on its running time.
Moreover, the size of the output circuit depends additively (rather than multiplicatively) on program size, allowing verification of larger programs.
The cryptographic proof system improves proving and verification times, by leveraging new algorithms and a pairing library tailored to the protocol.
We evaluated our system for programs with up to 10,000 instructions, running for up to 32,000 machine steps, each of which can arbitrarily access random-access memory; and also demonstrated it executing programs that use just-in-time compilation.
Our proofs are 230 bytes long at 80 bits of security, or 288 bytes long at 128 bits of security.
Typical verification time is 5 ms, regardless of the original program's running time.
Consider the setting where a client owns a public input x, a server owns a private input w, and the client wishes to learn z := F(x, w) for a program F known to both parties.
For instance, x may be a query, w a confidential database, and F the program that executes the query on the database.
Security.
The client is concerned about integrity of computation: how can he ascertain that the server reports the correct output z?
In contrast, the server is concerned about confidentiality of his own input: how can he prevent the client from learning information about w?Cryptography offers a powerful tool to address these security concerns: zero-knowledge proofs [43].
The server, acting as the prover, attempts to convince the client, acting as the verifier, that the following NP statement is true: "there exists w such that z = F(x, w)".
Indeed:• The soundness property of the proof system guarantees that, if the NP statement is false, the prover cannot convince the verifier (with high probability).
Thus, soundness addresses the client's integrity concern.
• The zero-knowledge property of the proof system guarantees that, if the NP statement is true, the prover can convince the verifier without leaking any information about w (beyond was is leaked by the output z).
Thus, zero knowledge addresses the server's confidentiality.
Moreover, the client sometimes not only seeks soundness but also proof of knowledge [43,11], which guarantees that, whenever he is convinced, not only can he deduce that a witness w exists, but also that the server knows one such witness.
This stronger property is often necessary to security if F encodes cryptographic computations, and is satisfied by most zero-knowledge proof systems.Efficiency.
Besides the aforementioned security desiderata, many settings also call for efficiency desiderata.
The client may be either unable or unwilling to engage in lengthy interactions with the server, or to perform large computations beyond the "bare minimum" of sending the input x and receiving the output z. For instance, the client may be a computationally-weak device with intermittent connectivity (e.g., a smartphone).
Thus, it is desirable for the proof to be non-interactive [25,55,23]: the server just send the claimed output˜zoutput˜ output˜z, along with a non-interactive proof string π that attests that˜zthat˜ that˜z is the correct output.
Moreover, it is also desirable for the proof to be succinct: π has size O λ (1) and can be verified in time O λ (|F| + |x| + |z|), where O λ (·) is some polynomial in a security parameter λ ; in other words, π is very short and easy to verify (i.e., verification time does not depend on |w|, nor F's running time).
zk-SNARKs.
A proof system achieving the above security and efficiency desiderata is called a (publiclyverifiable) zero-knowledge Succinct Non-interactive ARgument of Knowledge (zk-SNARK).
zk-SNARK constructions can be applied to a wide range of security applications, provided these constructions deliver good enough efficiency, and support rich enough functionality (i.e., the class of programs F that is supported).
Remark 1.1.
In the zero-knowledge setting above, the client does not have the server's input, and so cannot conduct the computation on his own.
Hence, it is not meaningful to compare "efficiency of outsourced computation at the server" and "efficiency of native execution at the client", because the latter was never an option.
Noninteractive zero-knowledge proofs (and zk-SNARKs) are useful regardless of cross-over points.Our goal in this paper is to construct a zk-SNARK implementation supporting executions on a universal von Neumann RISC machine.
zk-SNARKs.
Many works have obtained zk-SNARK constructions [45,51,38,22,56,16,52,27].
Three of these [56,16,27] provide implementations, and thus we briefly recall them.
Parno et al. [56] present two main contributions.
• A zk-SNARK, with essentially-optimal asymptotics, for arithmetic circuit satisfiability, based on quadratic arithmetic programs (QAPs) [38].
They accompany their construction with an implementation.
• A compiler that maps C programs with fixed memory accesses and bounded control flow (e.g., array accesses and loop iteration bounds are compile-time constants) into corresponding arithmetic circuits.
Ben-Sasson et al. [16] present three main contributions.
• Also a QAP-based zk-SNARK with essentiallyoptimal asymptotics for arithmetic circuit satisfiability, and a corresponding implementation.
Their construction follows the linear-interactive proofs of [22].
• A simple RISC architecture, TinyRAM, along with a circuit generator for generating arithmetic circuits that verify correct execution of TinyRAM programs.
• A compiler that, given a C program, produces a corresponding TinyRAM program.
Finally, Braun et al. [27] re-implemented the protocol of [56] and combined it with a circuit generator that incorporates memory-checking techniques [24] to support random-access memory [14].
Outsourcing computation to powerful servers.
Numerous works [63,65,66,64,32,68,71,67,27] seek to verifiably outsource computation to untrusted powerful servers, e.g., in order to make use of cheaper cycles or storage.
(See Appendix A for a summary.)
We stress that verifiable outsourcing of computations is not our goal.
Rather, as mentioned, we study functionality and efficiency aspects of non-interactive zero-knowledge proofs, which are useful even when applied to relatively-small computations, and even with high overheads.Compared to most protocols to outsource computations, known zk-SNARKs use "heavyweight" techniques, such as probabilistically-checkable proofs [6] and expensive pairing-based cryptography.
The optimal choice of protocol, and whether it actually pays off compared to local native execution, are complex, computation-dependent questions [71], and we leave to future work the question of whether zk-SNARKs are useful for the goal of outsourcing computations.
Recent work has made tremendous progress in taking zk-SNARKs from asymptotic theory into concrete implementations.
Yet, known implementations suffer from several limitations.Per-program key generation.
As in any non-interactive zero-knowledge proof, a zk-SNARK requires a one-time trusted setup of public parameters: a key generator samples a proving key (used to generate proofs) and a verification key (used to check proofs).
However, current zk-SNARK implementations [56,16] require the setup phase to depend on the program F, which is hard-coded in the keys.
Key generation is costly (quasilinear in F's runtime) and is thus difficult to amortize if conducted anew for each program.
More importantly, per-program key generation requires, for each new choice of program, a trusted party's help.Limited support for high-level languages.
Known circuit generators have limited functionality or efficiency: (i) [56]'s circuit generator only supports programs without data dependencies, since memory accesses and loop iteration bounds cannot depend on a program's input; (ii) [27]'s circuit generator allows data-dependent memory accesses, but each such access requires expensive hashing to verify Merkle-tree authentication paths; (iii) [16]'s circuit generator supports arbitrary programs but its circuit size scales inefficiently with program size (namely, it has size Ω(񮽙T ) for 񮽙-instruction T -step TinyRAM programs).
Moreover, while there are techniques that mitigate some of the above limitations [72], these only apply in special cases, and not do address general data dependencies, a common occurrence in many programs.Generic sub-algorithms.
The aforementioned zk-SNARKs use several sub-algorithms, and in particular elliptic curves and pairings.
Protocol-specific optimizations are a key ingredient in fast implementations of pairing-based protocols [59], yet prior implementations only utilize off-the-shelf cryptographic libraries, and miss key optimization opportunities.
We present two main contributions: a new circuit generator and a new zk-SNARK for circuits.
These can be used independently, or combined to obtain an overall system.
We design and build a new circuit generator that incorporates the following two main improvements.
(1) Our circuit generator is universal: when given input bounds 񮽙, n, T , it produces a circuit that can verify the execution of any program with ≤ 񮽙 instructions, on any input of size ≤ n, for ≤ T steps.
Instead, all prior circuit generators [66,64,56,16,27] hardcoded the program in the circuit.
Combined with a zk-SNARK for circuits (or any NP proof system for circuits), we achieve a notable conceptual advance: once-and-for-all key generation that allows verifying all programs up to a given size.
This removes major issues in all prior systems: expensive per-program key generation, and the thorny issue of conducting it anew in a trusted way for every program.Our circuit generator supports a universal machine that, like modern computers, follows the von Neumann paradigm (program and data lie in the same read/write address space).
Concretely, it supports a von Neumann RISC architecture called vnTinyRAM, a modification of TinyRAM [17].
Thus, we also support programs leveraging techniques such as just-in-time compilation or selfmodifying code [36,58].
To compile C programs to the vnTinyRAM machine language, we ported the GCC compiler to this architecture, building on the work of [16].
See Figure 1 for a functionality comparison with prior circuit generators (for details, see [27, §2]).
Supported functionality [66,64,56] [16] [27] this work side-effect free comp.
(2) Our circuit generator efficiently handles larger arbitrary programs: the size of the generated circuit C 񮽙,n,T is O 񮽙 (񮽙 + n + T ) · log(񮽙 + n + T ) 񮽙 gates.
Thus, the dependence on program size is additive, instead of multiplicative as in [16], where the generated (non-universal) circuit has size Θ 񮽙 (n + T ) · (log(n + T )+񮽙) 񮽙 .
As Figure 2 shows, our efficiency improvement compared to [16] is not merely asymptotic but yields sizable concrete savings: as program size 񮽙 increases, our amortized per-cycle gate count is essentially unchanged, while that of [16] grows without bound, becoming orders of magnitudes more expensive.
[16] this work 񮽙 = 10 3 1,872 1,368 1.4× 񮽙 = 10 4 10,872 1,371 7.9× 񮽙 = 10 5 100,872 1,400 72.1× 񮽙 = 10 6 1,000,872 1,694 590.8× Figure 2: Per-cycle gate count improvements over [16].񮽙 񮽙 񮽙 񮽙
data-dep.
mem.
accesses × 񮽙 񮽙 񮽙 data-dep.
contr.
flow × 񮽙 × 񮽙 self-modifying code × × × 񮽙 universality × × × 񮽙n = 10 2 |C 񮽙,n,T |/T improvement T = 2 20An efficiency comparison with other non-universal circuit generators [66,64,56,27] is not well-defined.
First, they support more restricted classes of programs, so a programmer must "write around" the limited functionality.
Second, their efficiency is not easily specified, since the output circuit is ad hoc for the given program, and the only way to know its size is to actually run the circuit generator.
We expect, and find, that such circuit generators perform better than ours for programs that are already "close to a circuit", and worse for programs rich in data-dependent memory accesses and control flow.
Our third contribution is a high-performance implementation of a zk-SNARK for arithmetic circuits.
(3) We improve upon and implement the protocol of Parno et al. [56].
Unlike previous zk-SNARK implementations [56,16,27], we do not use off-the-shelf cryptographic libraries.
Rather, we create a tailored implementation of the requisite components: the underlying finite-field arithmetic, elliptic-curve group arithmetic, pairing-based checks, and so on.To facilitate comparison with prior work, we instantiate our techniques for two specific algebraic setups: we provide an instantiation based on Edwards curves [33] at 80 bits of security (as in [16]), and an instantiation based on Barreto-Naehrig curves [9] at 128 bits of security (as in [56,27]).
On our reference platform (a typical desktop), proof verification is fast: at 80-bit security, for an n-byte input to the circuit, verification takes 4.7 + 0.0004 · n milliseconds, regardless of circuit size; at 128-bit security, it takes 4.8 + 0.0005 · n.
The constant term dominates for small inputs, and corresponds to the verifier's pairing-based checks; in both cases, it is less than half the time for separately evaluating the 12 requisite pairings of the checks.
We achieve this saving by merging parts of the pairings' computation in a protocol-dependent way -another reason for a custom implementation of the underlying math.Key generation and proof generation entail a per-gate cost.
For example, for a circuit with 16 million gates: at 80 bits of security, key generation takes 81 µs per gate and proving takes 109 µs per gate; at 128 bits of security, these per-gate costs mildly increase to 100 µs and 144 µs.As in previous zk-SNARK implementations, proofs have constant size (independent of the circuit or input size); for us, they are 230 bytes at 80 bits of security, and 288 bytes at 128 bits of security.Compared to previous implementations of zk-SNARKs for circuits [56,16,27], our implementation improves both proving and verification times, e.g., see Figure 3.
128 bits of security [16] this impr.
[ Figure 3: Comparison with prior zk-SNARKs for a 1-million-gate arithmetic circuit and a 1000-bit input, running on our benchmarking machine, using software provided by the respective authors.
Since [27] is a re-implementation of [56], we only include the latter's performance.
(N = 5 and std < 2%) Our new circuit generator and our new zk-SNARK for circuits can be used independently.
For instance, the circuit generator can (up to interface matching) replace the circuit generators in [66,64,56,16,27], thus granting these systems universality.
Similarly, our zk-SNARK for circuits can replace the underlying zk-SNARKs in [56,16,27], or be used directly in applications where a suitable circuit is already specified.
Combining these two components, we obtain a full system: a zk-SNARK for proving/verifying correctness of vnTinyRAM computations; see Figure 4 and Figure 5 for diagrams of this system.
We evaluated this overall system for programs with up to 10,000 instructions, running for up to 32,000 steps.
Verification time is, again, only few milliseconds, independent of the running time of the vnTinyRAM program, even when program size and input size are kilobytes.
Proofs, as mentioned, have a small constant size.
Key generation and proof generation entail a per-cycle cost, with a dependence on program size that "tapers off" as computation length increases.
For instance, at 128-bit security and vnTinyRAM with a word size of 32 bits, key generation takes 210 ms per cycle and proving takes 100 ms per cycle, for 8K-instruction programs.JIT case study: efficient memcpy.
Besides evaluating individual components, we give an example demonstrating the rich functionality supported by the integrated system.
We wrote a vnTinyRAM implementation of memcpy that leverages just-in-time compilation (in par- Given a finite field F, an F-arithmetic circuit takes inputs that are elements in F, and its gates output elements in F.
The circuits we consider only have bilinear gates.
1Definition 2.1.
Let n, h, l respectively denote the input, witness, and output size.
The circuit satisfaction problem of a circuit C : F n × F h → F l with bilinear gates is defined by the relationR C = {(񮽙 x,, a) ∈ F n × F h : C(񮽙 x,, a) = 0 l } and language L C = {񮽙 x ∈ F n : ∃񮽙 a ∈ F h , C(񮽙 x,, a) = 0 l }.
All the arithmetic circuits we consider are over prime fields F p .
In this case, when passing boolean strings as inputs to arithmetic circuits, we pack the string's bits into as few field elements as possible: given s ∈ {0,1} m , we use [[s]] m p to denote the vector 񮽙 x ∈ F |m| p p , where |m| p := 񮽙m/񮽙log p񮽙񮽙, such that the binary representation of x i ∈ F p is the i-th block of 񮽙log p񮽙 bits in s (padded with 0's if needed).
We extend the notation [[s]] m p to binary strings s ∈ {0,1} n with n < m bits via padding:[[s]] m p := [[s0 m−n ]] m p .
Our zk-SNARK leverages quadratic arithmetic programs (QAPs), introduced by Gennaro et al. [38].
1 ,...,x m ∈ F is bilinear if the output is 񮽙񮽙 a, (1, x 1 ,...,x m )񮽙 · · 񮽙 b, (1, x 1 ,...,x m )񮽙 for some 񮽙 a, 񮽙 b ∈ F m+1 .
In particular, these include addition, multiplication, and constant gates.Like a circuit, a QAP induces a satisfaction problem:Definition 2.3.
The satisfaction problem of a size-m QAP ( 񮽙 A, 񮽙 B, 񮽙 C, Z) is the relation R ( 񮽙 A, 񮽙 B, 񮽙 C,Z) of pairs (񮽙 x,񮽙 s) such that (i) 񮽙 x ∈ F n , 񮽙 s ∈ F m ,and n ≤ m; (ii) x i = s i for i ∈ [n] (i.e., 񮽙 s extends 񮽙 x); and (iii) the polynomial Z(z) divides the following one:(A 0 (z) + ∑ m i=1 s i A i (z)) · (B 0 (z) + ∑ m i=1 s i B i (z)) − (C 0 (z) + ∑ m i=1 s i C i (z)) .
We denote byL ( 񮽙 A, 񮽙 B, 񮽙 C,Z) the language of R ( 񮽙 A, 񮽙 B, 񮽙 C,Z) .
Gennaro et al. [38] showed that circuit satisfiability can be efficiently reduced to QAP satisfiability (which can then be proved and verified using zk-SNARKs):Lemma 2.4.
There exist two polynomial-time algorithms QAPinst, QAPwit that work as follows.
For any circuit C : F n × F h → F l= b + l + 1.
• COMPLETENESS.
For any (񮽙 x,, a) ∈ R C , it holds that (񮽙 x,񮽙 s) ∈ R ( 񮽙 A, 񮽙 B, 񮽙 C,Z) , where 񮽙 s := QAPwit(C,, x,, a).
• PROOF OF KNOWLEDGE.
For any (񮽙 x,񮽙 s) ∈ R ( 񮽙 A, 񮽙 B, 񮽙 C,Z) , it holds that (񮽙 x,, a) ∈ R C , where 񮽙 a is a prefix of 񮽙 s.• NON-DEGENERACY.
The polynomials A 0 ,.
.
.
,A n are nonzero and distinct.
Let G 1 and G 2 be two cyclic groups of order r.
We denote elements of G 1 , G 2 via calligraphic letters such as P, Q.
We write G 1 and G 2 in additive notation.
Let P 1 be a generator of G 1 , i.e., G 1 = {αP 1 } α∈F r (α is also viewed as an integer, hence αP 1 is welldefined); let P 2 be a generator for G 2 .
A pairing is an efficient map e :G 1 × G 2 → G T ,where G T is also a cyclic group of order r (which we write in multiplicative notation), satisfying the following properties: (i) bilinearity: for every nonzero elements α, β ∈ F r , it holds thate(αP 1 , β P 2 ) = e(P 1 , P 2 ) αβ ; (ii) non-degeneracy: e(P 1 , P 2 )is not the identity in G T .
A (preprocessing) zk-SNARK for F-arithmetic circuit satisfiability (see, e.g., [22]) is a triple of polynomialtime algorithms (G, P,V ), called key generator, prover, and verifier.
The key generator G, given a security parameter λ and an F-arithmetic circuit C :F n × F h → F l ,samples a proving key pk and a verification key vk; these are the proof system's public parameters, which need to be generated only once per circuit.
After that, anyone can use pk to generate non-interactive proofs for the language L C , and anyone can use the vk to check these proofs.
Namely, given pk and any (񮽙 x,, a) ∈ R C , the honest prover P(pk,, x,, a) produces a proof π attesting that 񮽙 x ∈ L C ; the verifier V (vk,, x, π) checks that π is a valid proof for񮽙 x ∈ L C .
A proof π is both a proof of knowledge, and a (statistical) zero-knowledge proof.
The succinctness property requires that π has length O λ (1) and V runs in time O λ (|񮽙 x|), where O λ hides a (fixed) polynomial in λ .
Constructions.
Several zk-SNARK constructions are known [45,51,38,22,56,16,52].
The most efficient ones are based on quadratic span programs (QSPs) [38,52] or quadratic arithmetic programs (QAPs) [38,22,56,16].
We focused on QAP-based constructions, because QAPs allow for tighter reductions from arithmetic circuits (see Lemma 2.4).
Concretely, we build on the QAP-based zk-SNARK protocol of Parno et al. [56] (see Section 4).
Remark 2.5 (full succinctness).
The key generator G takes C as input, and so its complexity is linear in |C|.
One could require G to not take C as input, and have its output keys work for all (polynomial-size) circuits C; then, G's running time would be independent of C.
A zk-SNARK satisfying this stronger property is fully succinct.
Theoretical constructions of such zk-SNARKs are known, based on various cryptographic assumptions [54,69,21].
Despite achieving essentially-optimal asymptotics [6,18,15,14,21] no implementations of them have been reported to date.
Ben-Sasson et al. [16] introduced TinyRAM, a Harvard RISC architecture with word-addressable memory.
We modify TinyRAM to obtain vnTinyRAM, which differs from it in two main ways.
First, vnTinyRAM follows the von Neumann paradigm, whereby program and data are stored in the same read-write address space; programs may use runtime code generation.
Second, vnTinyRAM has byte-addressable memory, along with instructions to load/store bytes or words.
2 Besides the above main differences, vnTinyRAM is very similar to TinyRAM.
Namely, it is parametrized by the word size, denoted W , and the number of registers, denoted K.
The CPU state of the machine consists of (i) a W -bit program counter; (ii) K general-purpose W -bit registers; (iii) a 1-bit condition flag.
The full state of the machine also includes memory, which is a linear array of 2 W bytes, and two tapes, each with a string of W -bit words, and read-only in one direction.
One tape is for a primary input and the other for an auxiliary input (treated as nondeterministic, untrusted advice).
In memory, an instruction is represented as a double word (one word for an immediate, and another for opcode, etc.).
Thus, a program is a list of address/double-word pairs specifying the initial contents of memory; all other memory locations assume the initial value of 0.
We define the language of accepting computations: A circuit generator translates the correctness of suitablybounded program executions into circuit satisfiability: given input bounds 񮽙, n, T , it produces a circuit that can verify the execution of any program with ≤ 񮽙 instructions, on any input of size ≤ n, for ≤ T steps.
More precisely, using the notations [[s]] p (for packing the binary string s into field elements) and |s| p (for computing the number of field elements required to pack s) introduced in Section 2.1, we define a (universal) circuit generator for vnTinyRAM as follows.Definition 3.1.
A (universal) circuit generator of efficiency f (·) over a prime field F p is a polynomial-time algorithm circ, together with an efficient witness map wit, working as follows.
For any program size bound 񮽙, time bound T , and primary-input size bound n, C := circ(񮽙, n, T ) is an F p -arithmetic circuit C : F m p × F h p → F l p, for m := |񮽙2W | p + |nW | p and some h, l, where W is the word size (cf. Section 2.5).
• EFFICIENCY.
The circuit C has f (񮽙, n, T ) gates.
• COMPLETENESS.
Given any program , primary input , and witness such that񮽙 ( , ), 񮽙 ∈ R 񮽙,n,T , it holds that (񮽙 x,, a) ∈ R C , where 񮽙 x := [[ ]] 񮽙2W p • [[ ]]nW p and 񮽙 a := wit(񮽙, n, T, , , ).
• PROOF OF KNOWLEDGE.
There is a polynomial-time algorithm such that, given any (񮽙 x,, a) ∈ R C , outputs a witness for ( , ) ∈ L 񮽙,n,T .
The circuit C output by circ is universal because it does not depend on the program or primary input , but only on their respective size bounds 񮽙 and n (as well as the time bound T ).
When combined with any proof system for circuit satisfiability (e.g., our zk-SNARK), this fact enables the generation of the proof systems' parameters to be universal as well.
Namely, it is possible to generate keys for all bound choices (e.g., in powers of 2) up to some constant, once and for all; afterwards, one can pick the keys corresponding to bounds fitting a given computation.
This avoids expensive per-program key generation and, more importantly, the need for a trusted party to conduct key generation anew for every program.We construct a universal circuit generator with the following efficiency:Theorem 3.2.
There is a circuit generator of efficiency f (񮽙, n, T ) = O 񮽙 (񮽙 + n + T ) · log(񮽙 + n + T ) 񮽙 over any prime field F p of size p > 2 2W , where W is the word size (cf. Section 2.5).
(In our case, the condition p > 2 2W is always fulfilled.)
Most of the difficulties that arise when designing a circuit generator have to do with data dependencies.
A circuit's topology does not depend on its inputs but, in contrast, program flow and memory accesses depend on the choice of program and the program's inputs.
Thus, a circuit tasked with verifying program executions must be "ready" to support a multitude of program flows and memory accesses, despite the fact that its topology has already been fixed.
Various techniques have been applied to the design of circuit generators.Program analysis.
In the extreme, if both the program and its inputs ( , ) are known in advance, designing a circuit generator is simple: construct a circuit that evaluates on ( , ) by preparing the circuit's topology to match the pre-determined program flow and memory accesses.
But now suppose that only is known in advance, but not its inputs ( , ).
In this case, by analyzing piece by piece (e.g., separately examine the various loops, branches, and so on), one could try to design a circuit C that can handle different choices of inputs.
Most prior circuit generators [66,64,56,27] take this approach.However, this approach suffers from several limitations.
First, the class of supported programs is not rich, because support for data dependencies is limited.
E.g., [56] requires array accesses and loop iteration bounds to be compile-time constants; also, while [27] supports datadependent memory accesses, most program flow is also restricted to be known (or bounded) at compile-time; mitigations are possible, but only in special cases [72].
Second, and more importantly, this approach does not seem to allow for designing universal circuit generators, because the program is not known in advance and thus there is no program to analyze.
Computers are universal random-access machines (RAMs), so one approach of designing a universal circuit is to mimic a computer's execution, building a layered circuit as follows.
The i-th layer contains the entire state of the machine (CPU state and random-access memory) at time step i, and layer i + 1 is computed from it by evaluating the transition function of the machine, handling any accesses to memory via multiplexing.
While this approach supports arbitrary program flow, memory accesses are inefficiently supported; indeed, if memory has S addresses, the resulting circuit is huge: it has size Ω(T S).
Nondeterministic routing.
Ben-Sasson et al. [14] suggested using nondeterministic routing on a Beneš network to support memory accesses efficiently; Our circuit generator builds on the techniques of [14,16], so we briefly review the main idea behind nondeterministic routing.Following [14], Ben-Sasson et al. [16] introduced a simple computer architecture, called TinyRAM, and constructed a routing-based circuit generator for TinyRAM.
They define the following notions.
A CPU state, denoted S, is the CPU's contents (e.g., program counter, registers, flags) at a given time step.
An execution trace for a program , time bound T , and primary input is a sequence tr = (S 1 ,.
.
.
,S T ) of CPU states.
An execution trace tr is valid if there is an auxiliary input such that the execution trace induced by running on inputs ( , ) is tr.We seek an arithmetic circuit C for verifying that tr is valid.
We break this down by splitting validity into three sub-properties: (i) validity of instruction fetch (for each time step, the correct instruction is fetched); (ii) validity of instruction execution (for each time step, the fetched instruction is correctly executed); and (iii) validity of memory accesses (each load from an address retrieves the value of the last store to that address).
The first two properties are verified as follows.
Construct a circuit C so that, for any two CPU states S and S 񮽙 , C (S, S 񮽙 , g) is satisfied for some "guess" g if and only if S 񮽙 can be reached from S (by fetching from the instruction indicated by the program counter in S and then executing it), for some state of memory.
Then, properties (i) and (ii) hold if C (S i , S i+1 , ·) is satisfiable for i = 1,.
.
.
,T − 1.
Thus, C contains T − 1 copies of C , each wired to a pair of adjacent states in tr.The third property is verified via nondeterministic routing.
Assume that C also gets as input MemSort(tr), which equals to the sorting of tr by accessed memory addresses (breaking ties via timestamps), and write a circuit C mem so that validity of memory accesses holds if C mem is satisfied by each pair of adjacent states in MemSort(tr).
(Roughly, C mem checks consistency of "load-after-load", "load-afterstore", and so on.)
However, C merely gets some auxiliary input tr * , which purports to be MemSort(tr).
So C works as follows: (a) C has T − 1 copies of C mem , each wired to a pair of adjacent states in tr * ; (b) C separately verifies that tr * = MemSort(tr) by routing on a O(T log T )-node Beneš network.
The switches of the routing network are set according to non-deterministic guesses (i.e., additional values in the auxiliary input), and the routing network merely verifies that the switch settings induce a permutation; this allows for a very tight reduction.
(Known constructions that compute the correct permutation hide large constants in big-oh notation [1].)
Past inefficiencies.
After filling in additional details, the construction of [16] reviewed above gives a circuit of size Θ 񮽙 (n + T ) · (log(n + T ) + 񮽙) 񮽙 = Ω(񮽙 · T ).
The Ω(񮽙 · T ) arises from the fact that all of the 񮽙 instructions in are hardcoded into each of the T − 1 copies of C .
Thus, besides being non-universal, the circuit scales inefficiently as 񮽙 grows (e.g., for 񮽙 = 10 4 , C 's size is already dominated by 's size).
In comparison to [16], our circuit generator is universal and, moreover, its size only grows with 񮽙 + T (additive dependence on program size) instead of with 񮽙 · T (multiplicative dependence).
As our evaluation demonstrates (see Section 5.1), the size improvement actually translates into significant savings in practice.Instead of hardcoding the program into each copy of the circuit C , we follow the von Neumann paradigm, where the program lies in the same read/write memory space as data.
We ensure that is loaded into the initial state of memory, using a dedicated circuit; we then verify instruction fetch via the same routing network that is used for checking data loads/stores.
While the idea is intuitive, realizing it involves numerous technical difficulties, some of which are described below.Routing instructions and data.
We extend an execution trace to not only include CPU states but also instructions: tr = (S 1 , I 1 ,.
.
.
,S T , I T ) where S i is the i-th CPU state, and I i is the i-th executed instruction.
We seek an arithmetic circuit C that checks tr, in this "extended" format, for the same three properties as above: (i) validity of instruction fetch; (ii) validity of instruction execution; (iii) validity of memory accesses.As in [16], checking that tr satisfies property (ii) is quite straightforward.
Construct a circuit C exe so that, given two CPU states S, S 񮽙 and an instruction I, C exe (S, S 񮽙 , I, g) is satisfied, for some guess g, if and only if S 񮽙 can be reached from S, by executing I, for some state of memory.
Then, C contains T − 1 copies of C exe , each wired to adjacent CPU states and an instruction, i.e., the i-th copy is C exe (S i , S i+1 , I i , g i ).
Unlike [16], though, we verify properties (i) and (iii) jointly, via the same routing network.
The auxiliary input now contains tr * = (A 1 ,.
.
.
,A 2T ), purportedly equal to the memory-sorted list of both instructions fetches and CPU states.
(Since the program lies in the same read-write memory as data, an instruction fetch from is merely a special type of memory load.)
Thus, to check that tr satisfies properties (i) and (iii), we design C to (a) verify that tr * = MemSort(tr) via nondeterministic routing, and (b) verify validity of all (i.e., instruction and data) memory accesses, via a new circuit C 񮽙 mem applied to each pair of adjacent items A i , A i+1 in tr * .
Thus, in this approach, is never replicated T times; rather, the fetching of its instructions is verified together with all other memory accesses, one instruction fetch at a time.Multiple memory-access types.
Each copy of C 񮽙 mem inspects a pair of items in tr * and (assuming tr * = MemSort(tr)) must ensure consistency of "load-afterload", "load-after-store", and so on.
However, unlike in [16], the byte-addressable memory of vnTinyRAM is accessed in different-sized blocks: instruction-size blocks for instruction fetch; word-size blocks when loading/storing words; and byte-size blocks when loading/storing bytes.
The consistency checks in C 񮽙 mem must handle "aliasing", i.e., accesses to the same point in memory via different addresses and block sizes.We tackle this difficulty as follows.
Double-word blocks are the largest blocks in which memory is accessed (as instructions are encoded as double words; cf. Section 2.5).
We thus let each item in tr * always specify a double-word, even if the item's memory access was with respect to a smaller-sized block (e.g., word or byte).
With this modification, we can let C 񮽙 mem perform consistency checks "at the double-word level", and handling word/byte accesses by mapping them to double-word accesses with suitable shifting and masking.Booting the machine.
We have so far assumed that the program , given as input to C, already appears in memory.
However, the circuit C sketched so far only verifies the validity of tr with respect to a machine whose memory is initialized to some state, corresponding to the execution of some program.
But C must verify correct execution of, specifically, , and so it must also verify that memory is initialized to contain .
Since C does not explicitly maintain memory (not even the initial one) and only implicitly reasons about memory via the routing network, it is not clear how C can perform this check.We tackle this difficulty as follows.
We further modify the the execution trace tr, by extending it with an initial boot section, preceding the beginning of the computation, during which the input program is stored into memory, one instruction i at a time.
This extends the length of both tr and tr * from 2T to 񮽙 + 2T , for 񮽙-instruction programs, and introduces a new type of item, "boot input store", in tr * .
Similarly, the routing network is now responsible for routing 񮽙 + 2T , rather than 2T , packets.Further optimizations.
The above construction sketch (depicted in Figure 6) is only intuitive, and does not discuss other optimizations that ultimately yield the performance that we report in Section 5.1.
For example, while [16] rely on Beneš networks, we rely on arbitrary-size Waksman networks [10], which only require N(log N − 0.91) switches to route N packets, instead of 2 񮽙log N񮽙 (񮽙log N񮽙 − 0.5).
Besides being closer to the information-theoretic lower bound of N(log N − 1.443), such networks eliminate costly rounding effects in [16], where the size of the network is doubled if N is just above a power of 2.
Compiling to vnTinyRAM.
To enable verification of higher-level programs, written in C, we ported the GCC compiler to the vnTinyRAM architecture, by modifying the Harvard-architecture, word-addressible TinyRAM C compiler of [16].
Given a C program, written in the same subset of C as in [16], the compiler produces the initial memory map representing a program .
This also served to validate the vnTinyRAM architectural choices (e.g., the move to byte-addressing significantly, and added instructions, improved efficiency for many programs).
We discuss our second main contribution: a highperformance implementation of a zk-SNARK for arithmetic circuit satisfiability.
Our approach is to tailor the requisite mathematical algorithms to the specific zk-SNARK protocol at hand.
While our techniques can be instantiated in many algebraic setups and security levels, we demonstrate them in two specific settings, to facilitate comparison with prior work.
See Section 2.4 for an informal definition of a zk-SNARK for arithmetic circuit satisfiability.
We improve upon and implement the zk-SNARK of Parno et al. [56].
For completeness the "PGHR protocol" is summarized in the full version of this paper, which provides pseudocode for its key generator G, prover P, and verifier V .
The construction is based on QAPs, introduced in Section 2.2.
Like most other zk-SNARKs, the PGHR protocol relies on a pairing, which is specified by a prime r ∈ N, three cyclic groups G 1 , G 2 , G T of order r, and a bilinear map e :G 1 × G 2 → G T .
(See Section 2.3.)
A pairing is typically instantiated via a pairing-friendly elliptic curve.
Concretely, suppose that one uses a curve E defined over F q , with embedding degree k with respect to r, to instantiate the pairing.
Then G T is set to µ r , the subgroup of r-th roots of unity in F * q k .
The instantiation of G 1 and G 2 depends on the choice of e; typically, G 1 is instantiated as an order-r subgroup of E(F q ), while, for efficiency reasons [7,8], G 2 as an orderr subgroup of E 񮽙 (F k/d ) where E 񮽙 is a d-th twist of E. Finally, the pairing e is typically a two-stage function e(P, Q) := FE(ML(P, Q)), where ML :G 1 × G 2 → F k qis known as Miller loop, and FE : F k q → F k q is known as final exponentiation and maps α to FE(α) := α (q k −1)/r .
As mentioned, we instantiate our techniques based on two different curves: an Edwards curve for the 80-bit security level (as in [16]) and a Barreto-Naehrig curve for the 128-bits security level (as in [56,27]).
We selected both the Edwards curve and Barreto-Naehrig curve so that r − 1 has high 2-adic order (i.e., r − 1 is divisible by a large power of 2), because this was shown to improve the efficiency of the key generator and the prover [16].
The verifier V takes as input a verification key vk, input 񮽙 x ∈ F n r , and proof π, and checks if π is a valid proof for the statement "񮽙 x ∈ L C ".
The computation of V consists of two parts.
First, use vk IC,0 ,.
.
.
,vk IC,n ∈ G 1 (part of vk) and input 񮽙 x to compute vk 񮽙 x := vk IC,0 + ∑ n i=1 x i vk IC,i .
Second, use vk, vk 񮽙 x , and π, to compute 12 pairings and perform the required checks.
In other words, V performs O(n) scalar multiplications in G 1 , followed by O(1) pairing evaluations.With regard to V 's first part, variable-base multi-scalar multiplication techniques can be used to reduce the number of G 1 operations needed to compute vk 񮽙 x [16,56].
With regard to V 's second part, even if the pairing evaluations take constant time (independent of the input size n), these evaluations are very expensive and dominate for small n.
Our focus here is to minimize the cost of these pairing evaluations.When only making "black-box" use of a pairing, the verifier must evaluate 12 pairings, amounting to 12 Miller loops plus 12 final exponentiations.
The straightforward approach is to compute these using a generic highperformance pairing library.
We proceed differently: we obtain high-performance implementations of subcomponents of a pairing, and then tailor their use specifically to V 's protocol.Namely, first, we obtain state-of-the-art implementations of a Miller loop and final exponentiation.
We utilize optimal pairings [70] to minimize the number of loop iterations in each Miller loop, and, to efficiently evaluate each Miller loop, rely on the formulas of [3] (for Edwards curves) and [20] (for BN curves).
As for final exponentiation, we use multiple techniques to speed it up: [62,44,35,50].
Next, building on the above foundation, we incorporate in V the following optimizations.
(1) Sharing Miller loops and final exponentiations.
The verifier V computes two products of two pairings.
We leverage the fact that a product of pairings can be evaluated faster than evaluating each pairing separately and then multiplying the results [60].
Concretely, in a product of m pairings, the Miller loop iterations for evaluating each factor can be carried out in "lock-step" so to share a single Miller accumulator variable, using one F q k squaring per loop instead of m.In a similar vein, one can perform a single final exponentiation on the product of the outputs of the m Miller loops, instead of m final exponentiations and then multiplying the results.
In fact, since the output of the pairing can be inverted for free (as the element is unitary so that inverting equals conjugating [61]), the idea of "sharing" final exponentiations extends to a ratio of pairing products.
Thus, in the verifier we only need to perform 5, instead of 12, final exponentiations.Our implementation incorporates both of the above techniques.
For example, at the 80-bit security level, separately computing 12 optimal pairings costs 13.6 ms, but the above techniques reduce the time to only 8.1 ms. We decrease this further as discussed next.
(2) Precomputation by processing the verification key.
Of the 12 pairings the verifier needs to evaluate, only one is such that both of its inputs come from the proof π.
The other 11 pairings have one fixed input, either a generator of G 1 or G 2 , or coming from the verification key vk.When one input to a pairing is fixed, precomputation techniques apply [60], especially in the case when the fixed input is the base point in Miller's algorithm.
In V , this holds for 9 out of the 11 pairing evaluations.
We thus split the verifier's computation into an offline phase, which consists of a one-time precomputation that only depends on vk, and a many-time online phase, which depends on the precomputed values, input 񮽙 x, and proof π.
The result of the offline phase is a processed verification key vk * .
While vk * is longer than vk, it allows the online phase to be faster.E.g., at the 80-bit security level, vk * decreases the total cost of pairing checks from 8.1 ms to 4.7 ms. The prover P takes as input a proving key pk (which includes the circuit C : F n r × F h r → F l r ), input 񮽙 x ∈ F n r , and witness 񮽙 a ∈ F r .
The prover P is tasked to produce a proof π, attesting that 񮽙 x ∈ L C .
The computation of P consists of two main parts.
First, compute the coefficients 񮽙 h of the polynomial H(z) := A(z)B(z)−C(z) Z(z), where A, B,C ∈ F r [z] are derived from the QAP instance ( 񮽙 A, 񮽙 B, 񮽙 C, Z) := QAPinst(C) and QAP witness񮽙 s := QAPwit(C,, x,, a).
Second, use the coefficients 񮽙 h, QAP witness 񮽙 s, and public key pk to compute π.With regard to the first part of P, the coefficients 񮽙 h can be efficiently computed via FFT techniques [16,56]; our implementation follows [16], and leverages the high 2-adic order of r − 1 for both of the elliptic curves we use.
With regard to P's second part, computing π requires solving large instances of the following problem: given elements Q 1 ,.
.
.
,Q n all in G 1 (or all in G 2 ) and scalars α 1 ,.
.
.
,α n ∈ F r , compute 񮽙񮽙 α, 񮽙 Q񮽙 := α 1 Q 1 + ·· · + α n Q n .
Previous work [56,16] has leveraged generic multi-scalar multiplication to compute π.
We observe that these algorithms can be tailored to the specific scalar distributions arising in P.
In P, the vector 񮽙 α is one of two types:(i) 񮽙 α ∈ F d+1 rand represents the coefficients of the degree-d polynomial H; or (ii) 񮽙 α = (1 •񮽙 s • δ 1 • δ 2 • δ 3 ) ∈ F 4+m r , for random δ 1 , δ 2 , δ 3 ∈ F r .
In case i, the entries in of 񮽙 α are random-looking.
We use the Bos-Coster algorithm [26] due to its lesser memory requirements (as compared to, e.g., [57]).
We follow [19]'s suggestions and achieve an assembly-optimized heap to implement the Bos-Coster algorithm.In case ii, the entries in 񮽙 s depend on the input (C,, x,, a) to QAPwit; in turn, (C,, x,, a) depends on our circuit generator (Section 3).
Using the above algorithm "as is" is inefficient: the algorithm works well when all the scalars have roughly the same bit complexity, but the entries in 񮽙 c have very different bit complexity.
Indeed, 񮽙 α equals to 񮽙 s augmented with a few entries; and 񮽙 s, the QAP witness, can be thought of as the list of wire values in C when computing on (񮽙 x,, a); the bit complexity of a wire value depends on whether it is storing a boolean value, a word value, and so on.
We observe that there are only a few "types" of values, so that the entries of 񮽙 α can be clustered into few groups of scalars with approximately the same bit complexity; we then apply the algorithm of [26] to each such group.
The key generator G takes as input a circuit C : F n r × F h r → F l r , and is tasked to compute a proving key pk and a verification key vk.
The computation of G consists of two main parts.
First, evaluate each A i , B i ,C i at a random element τ, where ( 񮽙 A, 񮽙 B, 񮽙 C, Z) := QAPinst(C) is the QAP instance.
Second, use these evaluations to compute pk and vk.With regard to G's first part, we follow [16] and again leverage the fact that F r has a primitive root of unity of large order.
With regard to G's second part, it is dominated by the cost of computing pk, which requires solving large instances of the following problem: given an element P in G 1 or G 2 and scalars α 1 ,.
.
.
,α n ∈ F r , compute α 1 P,.
.
.
,α n P. Previous work [56,16], used fixed-base windowing [28] to efficiently compute such fixed-base multi-scalar multiplications.In our implementation, we achieve additional efficiency, in space rather than in time.
Specifically, we leverage a structural property of QAPs derived from arithmetic circuits, in order to reduce the size of the proving key pk, as we now explain.
Lemma 2.4 states that an Farithmetic circuit C : F n × F h → F l , with α wires and β gates, can be converted into a corresponding QAP of size m = α and degree d ≈ β over F. Roughly, this is achieved in two steps.
First, construct three matrices A, B, C ∈ F (m+1)×d that encode C's topology: for each j ∈ [d], the j-th column of A, B respectively encodes the "left" and "right" coefficients of the j-th bilinear gate in C, while the j-th column of C encodes the coefficients of the gate's output.
Second, letting S ⊂ F be a set of size d, define Z(z) := ∏ ω∈S (z − ω) and, for i ∈ {0,.
.
.
,m}, let A i be the low-degree extension of the i-th row of A; similarly define each B i and C i .
All prior QAP-based zk-SNARK implementations exploit the fact that columns in the matrices A, B, C are very sparse.In contrast, we also leverage a different kind of sparsity: we observe that it is common for entire rows of A, B, C to be all zeroes, causing the corresponding lowdegree extensions to be zero polynomials.
3 For instance, our circuit generator typically outputs a circuit for which the percentage of non-zero polynomials in 񮽙 A, 񮽙 B, 񮽙 C is only about 52%, 15%, 71% respectively.
The fact that many polynomials in 񮽙 A, 񮽙 B, 񮽙 C evaluate to zero can be used towards reducing the size of pk, by switching from a dense representation to a sparse one.In fact, we have engineered our circuit generator to reduce the number of non-zero polynomials in 񮽙 B as much as possible, because computations associated to evaluations of 񮽙 B are conducted with respect to more expensive G 2 arithmetic, which we want to avoid as much as possible.
We evaluated our system on a desktop computer with a 3.40 GHz Intel Core i7-4770 CPU (with Turbo Boost disabled) and 32 GB of RAM.
All experiments, except the largest in Figure 8 and 9, used a small fraction of the RAM.
For the two largest experiments in Figure 9 we added a Crucial M4 solid state disk for swap space.
(While our code supports multi-threading, our experiments are in single-thread mode, for comparison with prior work.)
In Section 3 we described our universal circuit generator; we now benchmark its performance.Parameters.
The circuit supports vnTinyRAM, which is parametrized by two quantities: the word size W and the number of registers K (see Section 2.5).
We report performance for a machine with K = 16 registers, and two choices of word size: W = 16 and W = 32.
Methodology.
Theorem 3.2 provides an asymptotic efficiency guarantee: it states that our circuit generator has efficiency f (񮽙, n, T ) = O 񮽙 (񮽙 + n + T ) · log(񮽙 + n + T ) 񮽙 .
To understand concrete efficiency, we "uncover" the constants hidden in the big-oh notation.
By studying the number of gates in various subcircuits of the generated circuit C := circ(񮽙, n, T ), we computed the following (quite tight) upper bound on C's size:(12 + 2W ) · 񮽙 + (12 +W ) · n + |C exe | · T + (|C mem | + 4 log H − 1.82) · Hwhere H := (񮽙 + n + 2T ) is the "height" of the routing network, and• for (W, K) = (16,16): |C exe | = 777 and |C mem | = 211;• for (W, K) = (32,16): |C exe | = 1114 and |C mem | = 355.
In Figure 7, we give per-cycle gate counts (i.e., |C|/|T |) for various choices of (񮽙, n, T ); we also give sub-counts divided among program/input boot, CPU execution, memory checking, and routing.
(See the full version of this paper for an extended table with additional data.)
Discussion.
We first go through the size expression, to understand it: The first two terms, (12 + 2W ) · 񮽙 + (12 + W ) · n, correspond to the pre-execution boot phase, during which an 񮽙-instruction program and an n-word primary input are loaded into the machine.
The term |C exe | · T corresponds to the T copies of C exe used to verify each CPU transition, given the fetched instruction and two CPU states.
The term |C mem | · H corresponds to the H copies of C mem used to verify consistency on the memory-sorted trace.
Finally, the term (4 log H − 1.82) · H corresponds to the routing network for routing H packets (two gates for each of (2 log H − 0.91) · H binary switches).
Note that H = (񮽙 + n + 2T ) because boot needs 񮽙 + n memory stores (one for each program instruction and primary input word) and execution needs 2T memory accesses (1 instruction fetch and 1 data store/load per execution cycle).
The gate counts in Figure 7 demonstrate the additive (instead of multiplicative) dependence on program size of our universal circuit pays off.
For example, for (W, K) = (32,16), a 100-fold increase in program size, from 񮽙 = 10 3 to 񮽙 = 10 5 , barely impacts the per-cycle gate count: for T = 2 20 , it increases from 1,992.5 to only 2,041.5.
Indeed, the cost of program size is incurred, once and for all, during the machine boot; Figure 7 shows that the per-cycle cost of machine boot diminishes as T grows.Second, less than half of C's gates are dedicated to verifying accesses to random-access memory, while the majority of gates are dedicated to verifying execution of the CPU; indeed, almost always, |C exe |T > 1 2 |C|.
Put otherwise, C, which verifies an automaton with randomaccess memory (vnTinyRAM), has size that is less than twice that for verifying an automaton with the same CPU but no random-access memory at all.
Moreover, note that the size of C exe appears quite tight: for example, with (W, K) = (32,16), it has size 1114, not much larger than the size of the CPU state (545 bits).
In Section 4 we described our zk-SNARK implementation; we now benchmark its performance.Methodology.
We provide performance characteristics for each of the zk-SNARK algorithms, G, P and V , at the 80-bit and 128-bit security levels.
( 1) The key generator G takes as input an arithmetic circuit C :F n r × F h r → F l r .
Its efficiency mostly depends on the number of gates and wires in C, because these affect the size and degree of the corresponding QAP (see Lemma 2.4).
Thus, we evaluate G on a circuit with 2 i gates and 2 i wires for i ∈ {10,12,.
.
.
,24} (and fixed n = h = l = 100).
In Figure 8 we report the resulting running times and key sizes, as per-gate costs.
(2) The prover P takes as input a proving key pk, input 񮽙 x ∈ F n r , and witness 񮽙 a ∈ F h r .
Its efficiency mostly depends on the number of gates and wires in C (the circuit used to generate pk); we thus evaluate P on the proving keys output by G, for the same circuits as above.
In Figure 8 we report the times, as per-gate costs, and proof sizes.
(3) The verifier V takes as input a verification key vk, input 񮽙 x ∈ F n r , and proof π.
Its efficiency depends only on 񮽙 x (since the size of 񮽙 x determines that of vk).
Thus, we evaluate V on a random input 񮽙 x ∈ F n r of 2 i bytes for i ∈ {2,4,.
.
.
,20}.
In Figure 8 we report the resulting running times, along with corresponding key sizes.
Discussion.
The data demonstrates that our zk-SNARK implementation works and scales as expected, as long as sufficient memory is available (e.g., on a desktop computer with 32GB of DRAM: up to 16 million gates).
Key generation takes about 10 ms per gate of C; the size of a proving key is about 300 B per gate, and the size of a verification key is about 1B per byte of input to C. Running the prover takes 11 ms to 14 ms per gate.
For an n-byte input, proof verification time is c 1 n + c 0 , where c 0 is a few milliseconds and c 1 is a few tenths of microseconds.
As discussed, our circuit generator (Section 3) and zk-SNARK for circuits (Section 4) can be used in-Per-cycle gate count of C := circ(񮽙, n, T ) with vnTinyRAM parameters (W, K) n = 10 2 , K = 16 dependently, or combined to obtain a zk-SNARK for vnTinyRAM.
For completeness, the paper's full version we spell out how these two components can be combined.W = 16 W = 32 |C|/T |C|/T dividedHere we report measured performance of this combined system, at the 128-bit security level, and for a word size W = 32 and number of registers K = 16.
Methodology.
A zk-SNARK for vnTinyRAM is a triple of algorithms (KeyGen, Prove, Verify).
Given bounds 񮽙, n, T (for program size, input size, and time), the efficiency of KeyGen and Prove depends on 񮽙, n, T , while that of Verify essentially depends only on 񮽙, n. Thus, we benchmark the system as follows.
We evaluate KeyGen and Prove for various choices of 񮽙 and T , while keeping n = 100.
Instead, since the efficiency of Verify does not depend on T , we evaluate Verify, for various choices of 񮽙 and n, on random 񮽙-instruction programs and n-word inputs.
In Figure 9, we report the following measurements: KeyGen's running time, the sizes of the keys pk and vk, Prove's runtime, the (constant) proof size, and Verify's running time.
For quantities growing with T , we divide by T and report the per-cycle cost.Discussion.
The measurements demonstrate that, on a desktop computer, our zk-SNARK for vnTinyRAM scales up to computations of 32,000 machine cycles, for programs with up to 10,000 instructions.
Key generation takes about 200 ms per cycle; the size of a proving key is 500 KB to 650 KB per cycle, and the size of a verification key is a few kilobytes.
Running the prover takes 100 ms to 200 ms per cycle.
Verification times remain a few ms , even for inputs and programs of several kilobytes.Program-specific vk.
The time complexity of Verify is O(񮽙 + n), so verification time grows with program size.
This is inevitable, because Verify must read a program (of at most 񮽙 instructions) and input (of at most n words) in order to check, via the given proof π, if ( , ) ∈ L 񮽙,n,T (cf. Definition 2.6).
However, this is inconvenient, e.g., when one has to verify many proofs relative to different inputs to the same program .
In our zk-SNARK it is possible to amortize this cost as follows.
Given vk and , one can derive, in time O(񮽙), a program-specific verification key vk , which can be used to verify proofs relative to any input to .
Subsequently, the time complexity of Verify for any input (to ) is O(n), independent of 񮽙.
Universality is the main innovative feature of our circuit generator.
No previous circuit generator achieves univer-128 bits of security W = 32, K = 16 sality.
(See Figure 1 and Section 3.)
Putting universality aside and focusing on efficiency instead, a comparison with previous circuit generators is a multi-faceted problem.
On one hand, due to a shared core of techniques, a comparison with [16]'s circuit generator is straightforward, and shows significant improvements in circuit size, especially as program size grows.
See Section 1.4.1 and Figure 2 (the figure is for W, K = 16).񮽙
= 2K 񮽙 = 4K 񮽙 = 6K 񮽙 = 8K 񮽙 = 10K KeyGen time/T n = 100 T =Instead, a comparison with other circuit generators [66,64,56,27] is complex.
First, they support a smaller class of programs (see Figure 1), so a programmer must "write around" the limited functionality, somehow.
And second, their efficiency is not easily specified: due to the program-analysis techniques (see Section 3.1) the output circuit is ad hoc for the given program, and the only way to know its size is to actually run the circuit generator.Compared to [66,64,56,27], our circuit generator performs better for programs that are rich in memory accesses and control flow, and worse for programs that are more "circuit like".
Comparison with [66,64,56].
The circuit generators in [66,64,56] restrict loop iteration bounds and memory accesses to be known at compile time; if a program does not respect these restrictions, it must be first somehow mapped to another one that does.
For simplicity, we take [56]'s circuit generator (the latest one) as representative and, to illustrate the differences between [56]'s and our circuit generator, we consider two "extremes".
On one extreme, we wrote a simple C program multiplying two 10 × 10 matrices of 16-bit integers.
The circuit generator in [56] produces a circuit with 1100 gates; instead, our circuit generator (when given the corresponding vnTinyRAM assembly) produces a much larger circuit: one with ≈ 10 7 gates.On the other extreme, we consider a program making many random accesses to memory: pointer-chasing.
Given a permutation π of [N], start position i ∈ [N], and an integer k, the program outputs π k (i), the element obtained by starting from i and following "pointers" for k times.
Since no information about π is known at compile time, the only way of obtaining π( j), the pointer to follow, in [56] is via a linear scan.
On a simple C program that does one linear scan of π to obtain each new pointer, [56]'s generator outputs a circuit with 2Nk + 1 gates (each of the k array accesses costs 2N gates).
In vnTinyRAM, the corresponding program consists of 9 instructions, and the input to it is N + 3 words.
Booting vnTinyRAM with and requires 9 + N + 3 "boot stores" (see Section 3.2), and takes 5 + 4k cycles to execute (independent of N).
Say that we fix k = 10; then, in our circuit generator (with W = 32 and K = 16), each cycle costs about 2000 gates, and can perform a random access to memory.
Thus, pointer chasing in our case is cheaper than in [56] already for N > 5000, and the multiplicative saving, which is about 20N 2000·(5+40) = N 4500 , grows unbounded as N increases.Comparison with [27].
The circuit generator of [27] is also based on program analysis, but provides an additional feature that allows data-dependent memory accesses: a program may access memory by guessing the value and verifying its validity via a subcircuit that checks Merkletree authentication paths.
In [27], memory consists of 2 30 cells, and each access costs many gates: 140K for a load, and 280K for a store.
In comparison, in our circuit generator for vnTinyRAM (with word size W = 32 so that memory has 2 32 cells), each memory store/load costs less than 1000 gates out of about 2000 per cycle (see Section 5.1).
Besides the aforementioned feature, [27] rely on program analysis, and (as in [66,64,56]) only support bounded control flow.
Thus, [27] performs better than our circuit generator for programs with bounded control flow and few data-dependent accesses to memory.
Addressing the other component of our system, the zk-SNARK for circuits: Figure 3 compares our implementation with prior ones, on a 1-million-gate circuit with a 1000-byte input.
As shown, we mildly improve the key generation time and, more importantly, significantly improve the "online" costs of proving and verification.
We have presented two main contributions: (i) a circuit generator for a von Neumann RISC architecture that is universal and scales additively with program size; and (ii) a high-performance zk-SNARK for arithmetic circuit satisfiability.
These two components can be used independently to the benefit of other systems, or combined into a zk-SNARK that can prove/verify correctness of computations on this architecture.
The benefits of universality.
Universality attains the conceptual advance of once-and-for-all key generation, allowing verifying all programs up to a given size.
This removes major issues in prior systems: expensive perprogram key generation and the thorny issue of conducting it anew in a trusted way for every program.
The price of universality.
The price of universality is still very high.
Going forward, and aiming for widespread use in security applications, more work is required to slash costs of key generation and proving so to scale up to larger computations: e.g., billion-gate circuits, or millions of vnTinyRAM cycles, and beyond.
An interesting open problem is whether the "program analysis" techniques underlying most prior circuit generators [66,64,56,27], typically more efficient for restricted classes of programs, can be used to construct universal circuits.
Beyond vnTinyRAM.
Finally, going beyond the foundation of a von Neumann RISC architecture, more work lies ahead towards a richer architecture (e.g., efficient support for floating-point arithmetic and cryptographic acceleration), code libraries, and tighter compilers.
The function memcpy is a standard C function that works as follows: given as input two array pointers and a length, memcpy copies the contents of one array to the other.
Of course, with no data dependencies, copying data in a circuit is trivial: you just connect the appropriate wires.
However, when the array addresses and their lengths are unknown, and memcpy is invoked as a subroutine in a larger program, the trivial solution does not work, and an efficient implementation is needed.A naive implementation of memcpy iterates, via a loop, over each array position i and copies the i-th value from one array to the other.
In vnTinyRAM each such loop iteration costs 6 instructions; 2 of these are to increase the iteration counter and jump back to the start of the loop.
Thus, for m-long arrays, copying takes 6m instructions (discounting loop initialization).
But, in vnTinyRAM, one can do better: loop unrolling can be used to avoid paying for the 2 "control" instructions.
Asymptotically, the optimal number of unrollings depends on the array length: it is Θ( √ m).
Thus, optimal unrolling requires dynamic code generation on a von Neumann architecture.
We wrote a 54-instruction vnTinyRAM program for memcpy that uses dynamic loop unrolling to achieve an efficiency of ≈ 4m + 11.5 √ m cycles for m-long arrays.
For m ≥ 600, we get 1.25× speed-up over the naive implementation, and 1.4× speed-up for m ≥ 3000.
We thank Daniel Genkin, Raluca Ada Popa, Ron Rivest, and Nickolai Zeldovich for helpful comments and discussions, and Lior Greenblatt, Shaul Kfir, Michael Riabzev, and Gil Timnat for programming assistance.
