We present a novel application of deep learning in networking.
The envisioned system can learn the original flow characteristics such as a burst size and inter-burst gaps conceived at the source from packet sampling done at a receiver Wi-Fi node.
This problem is challenging because CSMA introduces complex, irregular alterations to the origin pattern of the flow in the presence of competing flows.
Our approach is semi-supervised learning.
We first work through multiple layers of feature extraction and subsampling from unlabeled flow measurements.
We use a feature extractor based on sparse coding and dictionary learning, and our subsampler performs overlapping max pooling.
Given the layers of learned feature mapping, we train SVM classifiers with deep feature representation resulted at the top layer.
The proposed scheme has been evaluated empirically in a custom wireless simulator and OPNET.
The results are promising that we achieve superior classification performance over ARMAX, Na¨ıveNa¨ıve Bayes classifiers, and Gaussian mixture models optimized by the EM algorithm.
Machine learning plays an increasingly important role in the complex, data-intensive tasks required by today's sensing and computing systems.
A flow is a sequence of data packets sharing the same context (e.g., TCP connection, media stream) sent from a source to its destination.
Accurate knowledge about the flow characteristics such as a burst size (in number of packets or bytes) and interburst gap, as were originated at the source, can be used beneficially to manage scarce networking resources.
One motivating example would be software-defined networking (SDN) [3], which can leverage detailed flow knowledge to program routers and access points (APs) for scheduling a congested data traffic or mitigating wireless interferences more intelligently.
This paper describes our first work in developing inference schemes to learn the original properties of a flow from packet sampling at a receiver that is not necessarily the destination of the flow.
We focus on the case where the source and the receiver are Wi-Fi nodes, and there are other Wi-Fi nodes that transmit their own flows.
In particular, the receiver for our case is a network node such as a Wi-Fi AP that forwards or broadcasts packets, being a spot of aggregating different flows.
The key challenge is how to unravel the work of CSMA that introduces a complicated mixture of competing flows.
We believe that the approach of this paper can be extended for various other wireless and wired networks.
Figure 1 explains our origin flow inference problem.
WiFi node A is the source of flow f A transmitted to Node B, a Wi-Fi AP.
We denote x A|B a sample of f A measured by B.
We use vector notation f to represent an origin flow pattern over time, and x its measurement.
(Section 2 will explain how we describe patterns of a flow in detail; for now, consider f and x finite sequences of numbers.)
Notice that there are other Wi-Fi nodes in the channel, namely nodes C, D, E, F, and G, that transmit own flows, creating contentions.Distributed Coordination Function (DCF) provides the fundamental mechanism to access wireless media for the IEEE 802.11 Wi-Fi [1].
DCF employs Carrier Sense Multiple Access (CSMA) with a random backoff drawn from an exponentially growing window.
Mixed with other transmissions, the sample x A|B could hardly preserve the original patterns in f A .
For example, the received packet burst lengths and gaps between bursts can be altered significantly.
The exactness of such alteration is difficult to estimate, but there are both linear (e.g., geometric increase of burst lengths) and nonlinear (e.g., packet loss, retransmission, timeout) distortions.
Among all possible causes, the main culprit should be CSMA.
Figure 1: Flow inference problem illustratedWe aim to solve the following.1.
Classify received frame/packet pattern sampled at a receiver Wi-Fi node to the origin flow pattern; 2.
Infer the original properties of a flow such as burst sizes and inter-burst gaps originated at the source.We clarify several points.
First, the origin flow pattern conveys context of application-level data.
This is depicted under node A in Figure 1.
f A instantiates a pattern of the data formation mostly passed from the application layer (and the lesser from Transport/IP/MAC) to the transmit unit.
Thus, our inference problem can lead to important understanding of application context mining.
Secondly, our primary work domain is the MAC layer.
We deduce observable patterns of a conventional TCP/UDP/IP flow from measuring directly the 802.11 MAC frames over time.
Lastly, a sampled flow pattern at best is the origin flow pattern shifted (delayed) in time.
For our inference to be effective, it is crucial to learn invariance such as some preserved original burst lengths that can spread widely over time.
Traffic monitoring capabilities are crucial for network management and security.
Wireless bandwidth is among the most precious networking resources.
Accurate origin flow inference can help derive efficient scheduling for wireless channels.
The inferred information can also be used to classify legitimate traffic from malicious attacks.
Programming network nodes.
Software-defined networking (SDN) is an emerging paradigm to build highly dynamic networks.
Inferred origin traffic information can help program SDN nodes.
For example, we can improve transmit-receive scheduling and avoid interferences.
Resource provisioning.
The state-of-the-art networks can provision almost all networking resources elastically.
The origin traffic inference will reveal the original properties of a flow that resource provisions such as communication bandwidth, flow cache, and compute cycles should strive to satisfy.Queue management.
A network node (e.g., router, AP, switch) can leverage the source sending rates of large flows to manage its receive buffers and scheduling mechanisms dynamically.
With knowledge on origin characteristics of a flow, networks can improve overall fairness.
The main contribution of our work is to demonstrate the effectiveness of learning algorithms applied to an important networking problem mostly studied under parametric, model-based frameworks.
Our approach is semisupervised learning.
We set up and train deep, unsupervised feature learning that constitutes multiple layers of sparse coding and pooling units.
Given the learned feature mapping, we train classifiers in supervised learning.
We have identified the key attributes for successful learning approaches to enhance our baseline such as forcing incoherency for sparse coding dictionary to extract more discriminative features, dense arrangement of sparse coding units, and max pooling on overlapping intervals.
We have also explored and experimented with other learning methods from classical autoregressive time-series prediction and Na¨ıveNa¨ıve Bayes classifiers to the EM-optimized Gaussian mixtures.
Our evaluation empirically confirms superior performance of the proposed learning methods in recovering the original properties of a flow.
There is considerable work in model-based estimation for origin flow properties.
Basu and Mukherjee [5] discuss numerous time-series models for Internet data traffic, including the autoregressive moving average process helpful for some of our formulation in Sections 2 and 3.
Claffy et al. [9] present one of the earliest work to infer the original packet size distribution of a flow from packet sampling at routers.
Duffield et al. [12] analyze methods to infer the original frequencies of flow lengths from sparse packet sampling.The way sparse representations are used in computer vision and pattern recognition has inspired our method.
Wright et al. [27] have developed a face recognition system that performs classification with sparse representation of features, which is based on a similar idea as ours.
The idea of pooling sparse representations of features provides an important primitive to construct higher-level features as studied by Raina et al. [22], although pooling techniques date back to Riesenhuber and Poggio [24].
Coates and Ng [10] propose to pool over multiple features for deep learning.Heisele, Ho, and Poggio [14] explain useful techniques of applying SVM for multi-class classification, which is inherent in our origin flow pattern inference problem.
There are a number of existing techniques to learn incoherent dictionary atoms.
Ramirez et al. [23], Zhang & Li [28], and Lin et al. [18] have proposed similar ideas that force orthonormal dictionary columns as we maximize incoherency among dictionary columns in §5.1.
Our idea of accompanying sparsity relaxation ( §5.2) for sparse coding with forced incoherent dictionary atoms is new.
Section 2 explains the time-series representation and processing of a flow.
In Section 3, we explore supervised learning methods for the origin flow inference.
Section 4 describes our baseline semi-supervised learning method.
We propose several enhancements to the baseline method in Section 5 and evaluate the learning methods with a custom simulator and OPNET in Section 6.
The paper concludes in Section 7.
The runs-and-gaps model [16] gives a concise way to describe a flow.
In Figure 2, characteristic patterns of an example flow are captured by packet runs and gaps measurable over time.
As indicated earlier, we perform our flow measurements directly at the MAC layer rather than at the transport or IP layers by sampling and processing Wi-Fi frames.
Here, an important parameter is the unit interval T s or sampling period during which each element w t is sampled and recorded.
The total measurement time or observation window is N × T s .
Alternatively, we have vector x = [x 1 x 2 ... x t ... x N ] for w where x t is the corresponding byte count of the total payload at time t. Hence, a zero in x (or w) indicates a gap.
If w 7 = 3 and x 7 = 1, 492, we have 3 packets for the flow at t = 7, and the sum of the payloads from the 3 packets is 1,492 bytes.
We will call either w or x a measurable input vector for inference, which contains extractable features.
While both w and x carry unique information, we mainly work with x throughout this paper.We designate an origin flow (pattern) with another vector f. Just like x, f is a sequence of byte counts uniformly sampled, but the difference is that f reflects the initial pattern (or signature) originated at its source.
Note f ∈ R M whereas x ∈ R N , and M and N are not necessarily equal.
We use notation x i,k to refer kth measurement on flow i since there can be many measurements on f i .
We also use f i,k to designate the kth instance of origin flow i because there could be many origin patterns, or the pattern can be a stochastic process and changes dynamically over time.
In summary, f, w, and x are all finite time-series representations of a flow.Consider sampling and processing of three example flows in Fig. 3 at a receiver.
The receive buffer first timestamps each arriving data frame and marks with flow ID.
At t = 1, the received frame for flow 1 contains 2 packets whose payload sizes are 50 and 50 bytes, denoted in (2, 50/50B).
At t = 6, flow 3 has two received frames.
The first frame contains 2 packets with sizes 100 and 400 bytes whereas the second frame contains only one packet with 1,000 bytes.
The example results in the following:1.
The core of an inference system comprises a feature extractor (FE) and a classifier (CL) that need to be trained.
Figure 4 Figure 4: Supervised learning framework maps an input x to its feature y and CL : y → ˆ l that performs classification on extracted features of the input.
The inference system learns the mappings FE and CL from training examples and their labels.
Once trained, when an unknown data x comes in, the system makes an inference by classifying it to a classîclassˆclassî.񮽙񮽙񮽙񮽙񮽙񮽙񮽙񮽙񮽙
{xi, li} T i=1 񮽙񮽙񮽙񮽙񮽙񮽙񮽙񮽙񮽙񮽙 x ˆ l ySupervised learning for the origin flow inference problem considers a training dataset{x i , �f l i , l i �} T i=1collected at the Wi-Fi receiver of interest.
x i is a time-series representation of flow l i sampled at the receiver.
We also make f l i available, the corresponding origin flow timeseries representation.
So, when a measured sample x is classified as l j , we can infer the original flow properties from looking up f l j 's.
We now explore supervised learning methods.
We note that most of these methods naturally lead to binary classifiers.
Our origin flow inference problem, however, is a multi-class classification.
We will revisit this issue in §4.3.
For clarity of explanation, this section accompanies binary classification.
Autoregressive moving average with exogenous inputs (ARMAX) [19] is a widely-studied model for linear system identification.
ARMAX models the current output of a system with the previous (delayed) output and input values.
With ARMAX, we can directly estimate the origin flow time-seriesf = [ f 1 f 2 ... f t−1 f t ] from the measurement x = [x 0 x 1 ... x t−2 x t−1 ] in a linear difference equation: f t + a 1 f t−1 + ... + a n f t−n = b 1 x t−1 + ... + b m x t−m + ε.Note that ε gives the model error, which itself can be written elaborately over time,i.e., c 1 ε t−1 + ... + c m ε t−m .
The ARMAX matrix form is ⎡ ⎢ ⎢ ⎢ ⎢ ⎣ f t f t−1 . . . f 1 ⎤ ⎥ ⎥ ⎥ ⎥ ⎦ � �� � f = ⎡ ⎢ ⎢ ⎣ f t−1 ··· f t−n x t−1 ··· x t−m . . . . . . . . . . . .
f 0 ··· f 1−n x 0 ··· x 1−m ⎤ ⎥ ⎥ ⎦ � �� � Φ Φ Φ ⎡ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣ −a 1 . . . −a n b 1 . . . b m ⎤ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎦ � �� � θ θ θUnder supervised learning, if we have many training ex-amples {x i , �f l i , l i �} T i=1, we will have a massively overconstrained system for our inference problem.
Least squares can train θ θ θ .
However, when the normal equationˆθ equationˆ equationˆθ θ θ = (Φ Φ Φ T Φ Φ Φ) −1 Φ Φ Φ T y becomes unstable, the recursive least squares via Kalman filtering [8] can be used instead.Na¨ıveNa¨ıve Bayes Classifier.
The key for Na¨ıveNa¨ıve Bayes is to define a good feature extractor for a flow measurement x.
We use a feature y = � ˆ μ run sizê μ gap length � by computing the sample mean values of run size (bytes) and gap length (unit intervals) from x.
The classifier is constructed from computing empirical conditional distribution p(y|l i ) of the train dataset.
In runtime, the trained classifiers infer the origin flow:l i if p(l i |y) ≥ p(l j |y) ⇔ p(y|l i )p(l i )/p(y|l j )p(l j ) ≥ 1.
Here, we use a simple decision rule that compares the learned likelihood ratios p(y|l i ) and p(y|l j ) for binary classification.
Support vector machine (SVM).
Boser, Guyon & Vapnik [6] first proposed SVM.
SVM is a binary classification model searching for a hyperplane that maximizes separation between two classes.
The hyperplane is orthogonal to the shortest line connecting the convex hulls of the classes.
Support vectors are the data points along the shortest line.
The hyperplane has the formh(x) = ∑ T i=1 α i l i x i · x + b, where x i is a training example for flow i, and α i , b the solution of a quadratic programming (QP) problem.
Class label l i ∈ {−1, 1} for each x i must be provided during the training.
Classification of a runtime input x computes sign(h(x)).
The SVM kernel trick can work with nonlinearity of data.
A kernel function K(.)
(e.g., radial basis, sigmoid) maps the input x to a higher dimensional feature space where a better margin is possible.
The hyperplane with the kernel trick becomes h kern (x) = ∑ T i=1 α i l i K(x i , x) + b. Gaussian mixture model (GMM).
Strictly speaking, GMM is an unsupervised feature learning method that is later paired with supervised classifier training.
GMM assumes the probability density of input data as a weighted sum of K Gaussian distributions.
GMM can be thought as a model-based version for K-means clustering.
Parameterized by {w j , μ j , Σ j } K j=1 , the feature for an input x is a combination of posterior membership probabilities evaluated by the Gaussians.
For jth Gaussian, we havep j (x) = 1 (2π) N/2 |Σ j | 1/2 · exp � − 1 2 (x − μ j ) � Σ −1 j (x − μ j ) �Expectation maximization (EM) [11] trains GMMs iteratively.
In E-step, EM creates a function evaluating the expected log-likelihood with the current estimate of the parameters.
M-step computes new parameter values that maximizes the expected log-likelihood of the E-step.
Deep learning refers to multiple layers of extracting features and nonlinear aggregation of the extracted features.This section presents our deep learning approach for the origin flow inference problem.
We propose an inference system based on semisupervised learning.
At the first stage, the system performs unsupervised feature learning over multiple layers.1.
Do sparse coding and dictionary learning with unlabeled training dataset 2.
Pool sparse representations of the training dataset to reduce the number of features 3.
Pass the resulting features (i.e., pooled sparse representations) to next layer and repeat by treating current layer's features as input data for next layer Given multiple layers of the learned dictionaries and features, the system next performs supervised learning.1.
Do multi-layer sparse coding and pooling with labeled training dataset 2.
Train (linear) SVM classifiers with the final form of feature vector resulted at the top layerAt runtime, the system takes a sample measurement of a flow, performs the multi-layer inference (i.e., sparse coding and pooling), and predicts the origin flow pattern and properties.
We use sparse coding [20] as the primary means to extract features from the sampled time-series data.
Con-sider unlabeled dataset {x k } T k=1 with each x k ∈ R N .
We pack {x k } T k=1 to the columns of X = 񮽙 x � 1 x � 2 ... x � T 񮽙 .
Note X ∈ R N×T .
Sparse coding requires a dictionary D ∈ R N×P learned from X.
We adopt K-SVD [4] that learns D in the following optimizationmin D,Y �X − DY� 2 F s.t. �y k � 0 ≤ K ∀k(1)Here, the columns of Y ∈ R P×T or {y k } T k=1 , are the sparse representations of {x k } T k=1 .
(Note y k ∈ R P .)
K-SVD is a fast iterative algorithm and requires to compute sparse code y k for each x k with current D.
We use orthogonal matching pursuit (OMP) [21] for computing sparse codes.
Our choice of OMP is merely based on its computational efficiency, and there are other algorithms such as LASSO [26] and LARS [13] that also work well.The columns of D, {d j } P j=1 , are dictionary atoms.
Hence, each element in vector y reflects a degree of membership to the corresponding dictionary atom.
To represent unbiased membership, dictionary atoms are normalized such that 񮽙 񮽙 d j 񮽙 񮽙 2 � 2 = 1.
To make every d j meaningful, we need more training samples than dictionary atoms, so T ≥ P. For discriminative convenience, D is overcomplete-i.e., P > N.
This means that sparse code y has a higher dimensionality than x, but y is Ksparse, that is, only K � N entries of y are nonzero.
Every input vector x k is mapped to the corresponding feature vector y k via sparse coding.
If all feature vectors were used straightforwardly, we could overwhelm the unsupervised feature learning process.
It is customary to reduce the number of extracted features by subsampling (or summarizing over) feature vectors-note, this is by no means to discard any useful information.Pooling, popular in convolutional neural networks [17], operates over multiple (sparse) feature representations and aggregates to a higher level of features in reduced dimension.
An important property of pooled feature representation is translation invariance [24].
We use max pooling [7] that takes the maximum value for the elements in the same position over a group of feature vectors.
For example, consider max pooling of L sparse codes {y 1 , y 2 ,...,y L } that yields z = max pool(y 1 , y 2 ,..., y L ) in Figure 5.
2 -gives the final feature representation for {x 1 , x 2 , x 3 , x 4 } in this 2-layer deep learning.In general, a depth or the number of layers reflects the coverage of deep learning.
Layer 1 extracts small, local features over multiple intervals spanned by consecutive input vectors.
The resulting feature representations are subsampled with max pooling before passed to layer 2.
Layer 2 builds larger features using its own dictionary.
Because the feature coverage by layer 1 coding and pooling is over a subregion for the layer 2 coverage, the features aggregated at layer 2 are novel and could not be seen at layer 1.
We embrace the supervised learning that largely consists of training SVM classifiers.
The SVM classification framework is generic and can directly work on x without any feature extraction or pooling.
SVMs could be trained with a single-layer sparse representation y (1) subject to x = D (1) y (1) .
Under our 2-layer deep learning setup, we train linear SVM classifiers using the final pooled feature vectors z (2) .
Considering there are many data patterns generated by applications, the origin flow inference is a multiclass classification problem.
There are two approaches for SVM, which is inherently a binary classifier, to classify q origin flow patterns.
The first approach is to train all q(q−1) 2 1-vs-1 SVMs exhaustively.
Each SVM is dedicated to distinguish between any pair out of q origin flows and infers the original flow properties mapped by the classification result.The second approach is to train q 1-vs-all SVMs.
For flow i, training 1-vs-all SVM will require two datasets X i with label l i = 1 consisting of measured patterns of flow i only and X \i with label l j = −1 containing measurements for all other flows j ∀ j � = i. Ideally, X \i should contain unbiased mix of the other flows.
Our empirical evaluation in Section 6 considers the 1-vs-all approach.
Dictionary learning algorithms address the performance of sparse coding in two aspects: 1) reconstructive accuracy and 2) discriminative ability of the learned dictionary atoms (i.e., the column vectors of D).
We emphasize the latter aspect because our primary objective is classification rather than compressing data.
Discriminative ability of a dictionary is related to making its atoms as incoherent as possible.
Sparse coding with a dictionary consisting of more incoherent column vectors should improve the margin of an SVM, which results in a better classification performance.The maximally incoherent D is constrained such that D T D = I.
In other words, an incoherent dictionary matrix has orthonormal columns.
This is equivalent to minimizing񮽙 񮽙 D T D − I 񮽙 񮽙 2 F.
We can also think of having the twoconditions d T k d j = 0 ∀k � = j (orthogonal columns) and 񮽙 񮽙 d T k d k 񮽙 񮽙 2 = 1 (normalized).
Since we use K-SVD, we add the incoherence optimization term to Equation (1) minD,Y �X − DY� 2 F + γ 񮽙 񮽙 D T D − I 񮽙 񮽙 2 F s.t. �y k � 0 ≤ K ∀k (2)The new optimization here, however, is not a trivial task.For the time being, we propose a two-stage algorithm presented below instead.
In the outer for loop, we run K-SVD unmodified.
The resulting D then enters the inner while loop that implements the gradient descent algorithm [25] to regularize the incoherence term in Eq.
(2).
γ is the step size for gradient search and decayed by 0 < δ < 1 within the inner loop until initialized back to the default value γ 0 in the outer loop after running K-SVD with the next training vector.
Strictly speaking, the way we force the dictionary incoherence is flawed.
The gradient descent takes over after K-SVD, but K-SVD and the gradient descent regularization have to take place jointly as Equation (2) suggests.
For this reason, the resulting effect of the outer loop computation perturbs the K-SVD optimization.
In other words, improving the dictionary incoherence comes with the cost of reconstructive accuracy.As a result, using the same value of K for sparse coding may be too tight to meet the minimal error criterion.
Therefore, we must relax the original sparsity K for sparse coding to K � such that K � > K.
We do sparsity relaxation as follows.
Let D � represent the incoherent dictionary resulted from Algorithm 1.
We repeat sparse coding withD � to find Y � min Y � 񮽙 񮽙 X − D � Y � 񮽙 񮽙 2 F s.t. 񮽙 񮽙 y � k 񮽙 񮽙 0 ≤ K � ∀k The baseline deep learning scheme in Figure 6 does batch sparse coding of {x 1 , x 2 , x 3 , x 4 } and max pooling of {y 1 , y 2 } and {y 3 , y 4 }.
We can enhance this baseline by performing sparse coding on shifted x k 's and max pooling over the resulting, overlapping sparse codes.
This is illustrated in Figure 7.
The overlapping intervals are formed by shifting (i.e., delaying) the elements in x k 's altogether by τ.
Note that τ = 1 gives the fully overlapped intervals while there is no overlapping for τ = 4 · N, which equals the baseline.
(In our evaluation, we use a 95% overlap between consecutive x's.)
Dense sparse coding can substantially reduce chances to miss a feature with increased cost of computing.
Overlapping pooling further improves on the translational invariance of a feature.
Also, according to Krizhevsky et al. [15], overlapping pooling reduces overfit in classifiers.
Figure 7: Enhanced 2-layer deep learning with dense sparse coding and overlapping max pooling We evaluate the proposed baseline and enhanced inference schemes in comparison to classical machine learning approaches described in Section 3.
We have implemented a simple setup featuring three Wi-Fi nodes in a custom MATLAB simulator and used OPNET Modeler to test more elaborated, seven Wi-Fi node scenario.
We generate flows based on the runs-and-gaps model explained in Section 2.
The triplet �t r , s r ,t g � describes the generative pattern of a flow, where t r and t g are the run and gap lengths in number of unit intervals (T s ), and s r denotes the size of payload in bytes generated per each unit interval of a run.
A flow type can be constant, stochastic, or mixed.
A constant flow has deterministic t r , s r , and t g values.
We consider 10 origin flows summarized in Table 1.
Notice we also use the normal (N) and uniform (U) distributions.
We round fractions, discard negative numbers drawn from a normal distribution and regenerate.
Using T s = 10 msec, we generate 2,000 instances of time series for each flow.
We use the first 1,000 instances for training and the other 1,000 for testing.
Each instance is a vector Stochastic �U(4, 10), Pareto(100, 2), Exp(0.5)� Flow 8Stochastic �N(10, 5), Pareto(40, 1), N(10, 5)� Flow 9Mixed �1, Pareto(100, 2), 1� Flow 10 Mixed �1, Pareto(100, 2), Exp(0.25)� of 500 elements.
We precompute the mean run and gap lengths from the generated origin flow patterns in the training dataset.
This is convenient because we enable simple lookup (of the precomputed values) based on the classification result of a measured flow in order to estimate the origin run and gap properties.
In Figure 8, we have񮽙 s 1 1 s 1 2 0 0 0 s 2 1 0 0 0 0 0 s 3 1 s 3 2 s 3 3 0 0 ... 񮽙 , wheres 1 = ∑ 2 k=1 s 1 k , s 2 = ∑ 1 k=1 s 2 k , s 3 = ∑ 3 k=1 s 3 kgive total bytes of the three bursts.
We can then compute the mean burst size for this pattern.
We also compute {t 1 r ,t 2 r ,t 3 r ,...},{t 1 g ,t 2 g ,t 3 g ,...}, and their mean values.
We are foremost interested in the accuracy of classifying a measured pattern x to its ground-truth origin flow pattern f.
We compute two metrics, recall (true positive rate) and false alarm (false positive rate), to evaluate classification performance: Without false alarm rate, we cannot truly assess the probability of detection for a classifier using a computed recall value because the classifier can be configured to declare positive only, automatically achieving to guess all positives correctly.
Classification leads to inferring other important properties of a flow from its training dataset records.
As our secondary evaluation metrics, we calculate errors in estimating the original mean burst size and mean gap length of the flow.
Recall = ∑ f C = f j ∀ j � = i.Node C can change its flow pattern from f j to f k , while node A still running f i , but f k is chosen such that k � = i. Wi-Fi setup.
We have implemented a custom discreteevent simulator in MATLAB, assuming the IEEE 802.11g our baseline Wi-Fi system.
At its core, our CSMA implementation is based on an open-source wireless simulator [2].
The backoff mechanism works as follows.
The contention window CW is initialized to aCW min.
In case of timeout, CSMA doubles CW, otherwise waits until the channel becomes idle with an additional DCF interframe space (DIFS) duration.
CSMA chooses a uniformly random wait time between [1, CW].
CW can grow up to aCW max of 1,023 slots.
CW is decremented only when the media is sensed idle.
RTS and CTS are disabled.
The Wi-Fi configuration is summarized in Table 2.
Inference schemes.
We have implemented all of the inference schemes in MATLAB.
We consider ARMAX- least squares, Na¨ıveNa¨ıve Bayes classifiers, Gaussian mixture models (GMM), and the two deep learning methods we proposed.
The baseline deep learning method has 2 layers implemented as described in Section 4.
The enhanced deep learning method also has 2 layers, but we additionally have implemented incoherent dictionary training, dense sparse coding, and overlapping max pooling as described in Section 5.
We call the size of vector x observed length or observation window size and have varied 100, 200, 300, and 500.
Training.
As mentioned in §6.1.1, the training dataset for each flow has 1,000 instances.
For flow i, we transmit training examples {f i,k } 1000 k=1 serially.
(Note the notation f i,k for kth instance of flow i.) We consider 1-vs-all linear SVM classifiers for all inference schemes.We train ARMAX with n previously transmitted origin flow patterns and m previous inputs-i.e., for flow i, we feed {f i,k−1 ,...,f i,k−n } and {x i,k−1 ,..., x i,k−m }-at time k.
After trying out various configurations, we choose n = 2 and m = 3.
The least squares directly estimatê f given x. SVMs for ARMAX are trained withˆfswithˆwithˆfs.For Na¨ıveNa¨ıve Bayes, we extract the statistic y = 񮽙ˆμ񮽙ˆ 񮽙ˆμ run sizê μ gap length 񮽙 from x by averaging run burst sizes and gap lengths and use y as a feature with label l i for flow i to build empirical distributions p(y|x, l i ).
Note training Na¨ıveNa¨ıve Bayes yields classifiers, so we do not need to train any SVMs for Na¨ıveNa¨ıve Bayes.
We use K = 10 GMMs.
Like Bayes, we use the same static y from x as a feature to train GMMs via the EM algorithm.
However, unlike Bayes, GMMs do not yield classifiers.
We train SVMs with the membership probabilities from the trained K Gaussians evaluated on y given l i .
The proposed deep learning methods produce a maxpooled sparse representation z (2) at the top of layer 2 for given x.
We use labeled z (2) 's to train SVMs.Results.
Figure 10 presents classification recall and false alarm rate of each inference scheme for Scenario 1.
Overall, deep learning (DL) yields consistently higher recall at lower false alarm.
When using a small observation window length to sample x, the recall gap between the enhanced and baseline deep learning methods is noticeably larger than the case of using a large observation window.
This is because dense sparse coding and overlapping max pooling in the enhanced deep learning scheme substantially reduce the probability of missing a feature.
A possible explanation for poor ARMAX performance could be that CSMA introduces significant nonlinear distortions.
GMMs are on par with our baseline deep learning.
If optimized to their limits, GMMs seem to be a reasonable alternative to deep learning for classification.
This is not surprising since GMMs are really a form of K-SVD.
(Note also that our effort to fine-tune GMMs was only fair as our focus in this paper was on deep learning.)
After classification, we predict the original mean burst size and gap length of a flow based on lookup of the precomputed values from the training dataset (see explanation in §6.1.2).
The estimation errors in Table 3 are the best case, obtained with the maximum observation window size of 5 seconds that we have tried.
Figure 11 illustrates Scenario 2 featuring seven Wi-Fi nodes simulated in OPNET.
This scenario is important for several reasons.
First, we can configure more realistic application profiles for simulated nodes.
We can also scale the simulation.
Lastly, we can validate our schemes with OPNET's built-in Wi-Fi protocols, particularly the IEEE 802.11g, which should be more complete than our MATLAB simulator.
Scenario 2 preserves nodes A, B, C and their activities the same as Scenario 1.
There are five additional Wi-Fi nodes that communicate in typical Internet styles as summarized in Table 4.
We test the same inference schemes and keep the training methodology of Scenario 1.
In Figure 12, we plot classification recall and false alarm rate of each scheme evaluated under Scenario 2.
With more nodes and increased traffic, the overall classification performance is worse.
Again, we can clearly see the benefits of dense sparse coding and overlapping pooling for enhanced deep learning that consistently outperforms the other schemes over various observation window sizes.
For a small observation window in particular, recall for enhanced deep learning is substantially higher while achieving the lowest false alarm rate.
Table 3 shows the estimation errors (in parenthesis) to predict original properties of the flows, the mean burst size and mean gap length, after classification.
We have addressed the problem of inferring the original properties of a flow sampled from a received Wi-Fi traffic mix.
This inverse problem is challenging because CSMA significantly changes the origin pattern of the flow while scheduling with other flows in competition.
Machine learning can provide tools to harness complexity and nonlinearity, but it requires to apply adept domain knowledge or application-specific insights to configure the overall learning pipeline and fine-tune all model parameters to their meticulous detail.
Learned from our initial, unsuccessful attempt to straightforwardly integrate sparse coding and dictionary learning into SVM classification, we have set up multiple layers of sparse feature extraction and max pooling that enable deep learning from received flow patterns.
Multilayer sparse coding allows us to learn local, atomic features such as run and gap sizes of a flow accurately at the lowest layer and global features such as periodicity in traffic patterns at higher layers.
Max pooling summarizes often too many extracted features while providing translation invariance.
We have explained how the proposed approaches incorporate these ideas and validated their superior performance.In summary, contributions of this paper include a novel formulation of an inverse problem to recover origin flow patterns in Wi-Fi, identification of the key attributes for successful machine learning approaches to solve such inverse problems (i.e., the use of sparse representation of features, multi-layer inference, and pooling), and demonstration of the sound working of these methods in recovering original flow properties.
We have chosen not to discuss possible applications of this paper in security and network anomaly detection.
We plan to address such applications in our future work.
We thank anonymous reviewers of ICAC for their valuable comments in revising the final version of this paper.
This material is based on research sponsored in part by Intel Corporation.
