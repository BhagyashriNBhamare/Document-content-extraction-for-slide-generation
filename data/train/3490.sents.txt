Recent work has shown that inaudible signals (at ultra-sound frequencies) can be designed in a way that they become audible to microphones.
Designed well, this can empower an adversary to stand on the road and silently control Amazon Echo and Google Home-like devices in people's homes.
A voice command like "Alexa, open the garage door" can be a serious threat.
While recent work has demonstrated feasibility, two issues remain open: (1) The attacks can only be launched from within 5 f t of Amazon Echo, and increasing this range makes the attack audible.
(2) There is no clear solution against these ultrasound attacks, since they exploit a recently discovered loophole in hardware non-linearity.
This paper is an attempt to close both these gaps.
We begin by developing an attack that achieves 25 f t range, limited by the power of our amplifier.
We then develop a defense against this class of voice attacks that exploit non-linearity.
Our core ideas emerge from a careful forensics on voice, i.e., finding indelible traces of non-linearity in recorded voice signals.
Our system, LipRead, demonstrates the inaudible attack in various conditions, followed by defenses that only require software changes to the microphone.
A number of recent research papers have focused on the topic of inaudible voice commands [37,48,39].
Backdoor [37] showed how hardware non-linearities in microphones can be exploited, such that inaudible ultrasound signals can become audible to any microphone.
DolphinAttack [48] developed on Backdoor to demonstrate that no software is needed at the microphone, i.e., a voice enabled device like Amazon Echo can be made to respond to inaudible voice commands.
A similar paper independently emerged in arXiv [39], with a video demonstration of such an attack [3].
These attacks are becoming increasingly relevant, particularly with the proliferation of voice enabled devices including Amazon Echo, Google Home, Apple Home Pod, Samsung refrigerators, etc.While creative and exciting, these attacks are still deficient on an important parameter: range.
DolphinAttack can launch from a distance of 5 f t to Amazon Echo [48] while the attack in [39] achieves 10 f t by becoming partially audible.
In attempting to enhance range, we realized strong tradeoffs with inaudibility, i.e., the output of the speaker no longer remains silent.
This implies that currently known attacks are viable in short ranges, such as Alice's friend visiting Alice's home and silently attacking her Amazon Echo [11,48].
However, the general, and perhaps more alarming attack, is the one in which the attacker parks his car on the road and controls voice-enabled devices in the neighborhood, and even a person standing next to him does not hear it.
This paper is an attempt to achieve such an attack radius, followed by defenses against them.
We formulate the core problem next and outline our intuitions and techniques for solving them.Briefly, non-linearity is a hardware property that makes high frequency signals arriving at a microphone, say s hi , get shifted to lower frequencies s low (see Figure 1).
If s hi is designed carefully, then s low can be almost identical to s hi but shifted to within the audibility cutoff of 20kHz inside the microphone.
As a result, even though humans do not hear s hi , non-linearity in microphones produces s low , which then become legitimate voice commands to devices like Amazon Echo.
This is the root opportunity that empowers today's attacks.
Voice commands transmitted over inaudible ultrasound frequencies get shifted into the lower audible bands after passing through the non-linear microphone hardware.Two important points need mention at this point.
(1) Non-linearity triggers at high frequencies and at high power -if s hi is a soft signal, then the non-linear effects do not surface.
(2) Non-linearity is fundamental to acoustic hardware and is equally present in speakers as in microphones.
Thus, when s hi is played through speak-ers, it will also undergo the frequency shift, producing an audible s low .
Dolphin and other attacks sidestep this problem by operating at low power, thereby forcing the output of the speaker to be almost inaudible.
This inherently limits the range of the attack to 5 f t; any attempt to increase this range will result in audibility.This paper breaks away from the zero sum game between range and audibility by an alternative transmitter design.
Our core idea is to use multiple speakers, and stripe segments of the voice signal across them such that leakage from each speaker is narrow band, and confined to low frequencies.
This still produces a garbled, audible sound.
To achieve true inaudibility, we solve a min-max optimization problem on the length of the voice segments.
The optimization picks the segment lengths in a way such that the aggregate leakage function is completely below the human auditory response curve (i.e., the minimum separation between the leakage and the human audibility curve is maximized).
This ensures, by design, the attack is inaudible.Defending against this class of non-linearity attacks is not difficult if one were to assume hardware changes to the receiver (e.g., Amazon Echo or Google Home).
An additional ultrasound microphone will suffice since it can detect the s hi signals in air.
However, with software changes alone, the problem becomes a question of forensics, i.e., can the shifted signal s low be discriminated from the same legitimate voice command, s leg .
In other words, does non-linearity leave an indelible trace on s low that would otherwise not be present in s leg .
Our defense relies on the observation that voice signals exhibit well-understood structure, composed of fundamental frequencies and harmonics.
When this structure passes through non-linearity, part of it remains preserved in the shifted and blended low frequency signals.
In contrast, legitimate human voice projects almost no energy in these low frequency bands.
An attacker that injects distortion to hide the traces of voice, either pollutes the core voice command, or raises the energy floor in these bands.
This forces the attacker into a zero-sum game, disallowing him from erasing the traces of non-linearity without raising suspicion.Our measurements confirm the possibility to detect voice traces, i.e., even though non-linearity superimposes many harmonics and noise signals on top of each other, and attenuates them significantly, cross-correlation still reveals the latent voice fingerprint.
Of course, various intermediate steps of contour tracking, filtering, frequency-selective compensation, and phoneme correlation are necessary to extract out the evidence.
Nonetheless, our final classifier is transparent and does not require any training at all, but succeeds for voice signals only, as opposed to the general class of inaudible microphone attacks (such as jamming [37]).
We leave this broader problem to future work.Our overall system LipRead is built on multiple platforms.
For the inaudible attack at long ranges, we have developed an ultrasound speaker array powered by our custom-made amplifier.
The attacker types a command on the laptop, MATLAB converts the command to a voice signal, and the laptop sends this through our amplifier to the speaker.
We demonstrate controlling Amazon Echo, iPhone Siri, and Samsung devices from a distance of 25 f t, limited by the power of our amplifier.
For defense, we record signals from Android Samsung S6 phones, as well as from off-the-shelf microphone chips (popular in today's devices).
We attack the system with various ultrasound commands, both from literature as well as our own.
LipRead demonstrates defense against all attacks with 97% precision and 98% recall.
The performance remains robust across varying parameters, including multipath, power, attack location, and various signal manipulations.Current limitations: Our long-range attacks have been launched from within a large room, or from outside a house with open windows.
When doors and windows were closed, the attack was unsuccessful since our highfrequency signals attenuated while passing through the wall/glass.
We believe this is a function of power, however, a deeper treatment is necessary around this question.
In particular: (1) Will high power amplifiers be powerful enough for high-frequency signals to penetrate such barriers?
(2) Will high-power and high-frequency signals trigger non-linearity inside human ears?
(3) Are there other leakages that will emerge in such high power and high frequency regimes.
We leave these questions to future work.In sum, our core contributions may be summarized as follows:• A transmitter design that breaks away from the tradeoff between attack range and audibility.
The core ideas pertain to carefully striping frequency bands across an array of speakers, such that individual speakers are silent but the microphone is activated.
• A defense that identifies human voice traces at very low frequencies (where such traces should not be present) and uses them to protect against attacks that attempt to erase or disturb these traces.The subsequent sections elaborate on these ideas, beginning with some relevant background on non-linearity, followed by threat model, attack design, and defense.
Microphones and speakers are in general designed to be linear systems, meaning that the output signals are linear combinations of the input.
In the case of power amplifiers inside microphones and speakers, if the input sound signal is s(t), then the output should ideally be:s out (t) = A 1 s(t)where A 1 is the amplifier gain.
In practice, however, acoustic components in microphones and speakers (like diaphragms, amplifiers, etc.) are linear only in the audible frequency range (< 20kHz).
In ultrasound bands (> 25kHz), the responses exhibit non-linearity [28,19,16,38,22].
Thus, for ultrasound signals, the output of the amplifier becomes:s out (t) = ∞ ∑ i=1 A i s i (t) = A 1 s(t) + A 2 s 2 (t) + A 3 s 3 (t) + ... ≈ A 1 s(t) + A 2 s 2 (t)(1)Higher order terms are typically extremely weak since A 4+ A 3 A 2 and hence can be ignored.Recent work [37] has shown ways to exploit this phenomenon, i.e., it is possible to play ultrasound signals that cannot be heard by humans but can be directly recorded by any microphone.
Specifically, an ultrasound speaker can play two inaudible tones: s 1 (t) = cos(2π f 1 t) at frequency f 1 = 38kHz and s 2 = cos(2π f 2 t) at frequency f 2 = 40kHz.
Once the combined signal s hi (t) = s 1 (t) + s 2 (t) passes through the microphone's nonlinear hardware, the output becomes:s out (t) = A 1 s hi (t) + A 2 s 2 hi (t) = A 1 (s 1 (t) + s 2 (t)) + A 2 (s 1 (t) + s 2 (t)) 2 = A 1 cos(2π f 1 t) + A 1 cos(2π f 2 t) + A 2 cos 2 (2π f 1 t) + A 2 cos 2 (2π f 2 t) + 2A 2 cos(2π f 1 t) cos(2π f 2 t)The above signal has frequency components at f 1 , f 2 , 2 f 1 , 2 f 2 , f 2 + f 1 , and f 2 − f 1 .
This can be seen by expanding the equation:s out (t) = A 1 cos(2π f 1 t) + A 1 cos(2π f 2 t) + A 2 + 0.5A 2 cos(2π2 f 1 t) + 0.5A 2 cos(2π2 f 2 t) + A 2 cos(2π( f 1 + f 2 )t) + A 2 cos(2π( f 2 − f 1 )t)Before digitizing and recording the signal, the microphone applies a low pass filter to remove frequency components above the microphone's cutoff of 24KHz.
Observe that f 1 , f 2 , 2 f 1 , 2 f 2 , andf 1 + f 2 are all > 24kHz.
Hence, what remains (as acceptable signal) is:s low (t) = A 2 + A 2 cos(2π( f 2 − f 1 )t)(2)This is essentially a f 2 − f 1 = 2kHz tone which will be recorded by the microphone.
However, this demonstrates the core opportunity, i.e., by sending a completely inaudible signal, we are able to generate an audible "copy" of it inside any unmodified off-the-shelf microphone.
We begin by explaining how the above non-linearity can be exploited to send inaudible commands to voice enabled devices (VEDs) at a short range.
We identify deficiencies in such an attack and then design the longer range, truly inaudible attack.
Let v(t) be a baseband voice signal that once decoded translates to the command: "Alexa, mute yourself".
An attacker moves this baseband signal to a high frequency f hi = 40kHz (by modulating a carrier signal), and plays it through an ultrasound speaker.
The attacker also plays a tone at f hi = 40kHz.
The played signal is:s hi (t) = cos(2π f hi t) + v(t) cos(2π f hi t)(3)After this signal passes through the non-linear hardware and low-pass filter of the microphone, the microphone will record:s low (t) = A 2 2 1 + v 2 (t) + 2v(t)(4)This shifted signal contains a strong component of v(t) (due to more power in the speech components), and hence, gets decoded correctly by almost all microphones.What happens to v 2 (t)?
Figure 2 shows the power spectrum V ( f ) corresponding to the voice command v(t) ="Alexa, mute yourself".
Here the power spectrum corresponding to v 2 (t) which is equal to V ( f ) * V ( f ) where ( * ) is the convolution operation.
Observe that the spectrum of the human voice is between [50 − 8000]Hz and the relatively weak components of v 2 (t) line up underneath the voice frequencies after convolution.
A component of v 2 (t) also falls at DC, however, degrades sharply.
The overall weak presence of v 2 (t) leaves the v(t) signal mostly unharmed, allowing VEDs to decode the command correctly.
However, to help v(t) enter the microphone through the "non-linear inlet", s hi (t) must be transmitted at sufficiently high power.
Otherwise, s low (t) will be buried in noise (due to small A 2 ).
Unfortunately, increasing the transmit power at the speaker triggers non-linearities at the speaker's own diaphragm and amplifier, resulting in an audible s low (t) at the output of the speaker.
Since s low (t) contains the voice command v(t), the attack becomes audible.
Past attacks sidestep this problem by operating at low power, thereby forcing the output of the speaker to be almost inaudible [49].
This inherently limits the radius of attack to a short range of 5 f t. Attempts to increase this range results in audibility, defeating the purpose of the attack.
Before developing the long range attack, we concisely present the assumptions and constraints on the attacker.Threat Model: We assume that:• The attacker cannot enter the home to launch the attack, otherwise, the above short range attack suffices.
• The attacker cannot leak any audible signals (even in a beamformed manner), otherwise such inaudible attacks are not needed in the first place.
• The attacker is resourceful in terms of hardware and energy (perhaps the attacking speaker can be carried in his car or placed at his balcony, pointed at VEDs in surrounding apartments or pedestrians).
• In case the receiver device (e.g., Google Home) is voice fingerprinted, we assume the attacker can synthesize the legitimate user's voice signal using known techniques [46,5] to launch the attack.
• The attacker cannot estimate the precise channel impulse response (CIR) from its speaker to the voice enabled device (VED) that it intends to attack.Core Attack Method: LipRead develops a new speaker design that facilitates considerably longer attack range, while eliminating the audible leakage at the speaker.
Instead of using one ultrasound speaker, LipRead uses multiple of them, physically separated in space.
Then, LipRead splices the spectrum of the voice command V ( f ) into carefully selected segments and plays each segment on a different speaker, thereby limiting the leakage from each speaker.
To better understand the motivation, let us first consider using two ultrasound speakers.
Instead of playing s hi (t) = cos(2π f hi t) + v(t) cos(2π f hi t) on one speaker, we now play s 1 (t) = cos(2π f hi t) on the first speaker and s 2 (t) = v(t) cos(2π f hi t) on the second speaker where f hi = 40kHz.
In this case, the 2 speakers will output:s out1 = cos(2π f hi t) + cos 2 (2π f hi t) s out2 = v(t) cos(2π f hi t) + v 2 (t) cos 2 (2π f hi t)(5)For simplicity, we ignore the terms A 1 and A 2 (since they do not affect our understanding of frequency components).
Thus, when s out1 and s out2 emerge from the two speakers, human ears filter out all frequencies > 20kHz.
What remains audible is only:s low1 = 1/2 s low2 = v 2 (t)/2Observe that neither s low1 nor s low2 contains the voice signal v(t), hence the actual attack command is no longer audible with two speakers.
However, the microphone under attack will still receive the aggregate ultrasound signal from the two speakers, s hi (t) = s 1 (t) + s 2 (t), and its own non-linearity will cause a "copy" of v(t) to get shifted into the audible range (recall Equation 4).
Thus, this 2-speaker attack activates VEDs from greater distances, while the actual voice command remains inaudible to bystanders.Although the voice signal v(t) is inaudible, signal v 2 (t) still leaks and becomes audible (especially at higher power).
This undermines the attack.Suppressing v 2 (t) Leakage: To suppress the audibility of v 2 (t), LipRead expands to N ultrasound speakers.
It first partitions the audio spectrum Fig. 4.
This can be achieved by computing an FFT of the signal v(t) to obtain V ( f ).
V ( f ) is then multiplied with a rectangle function rect(V ( f ) of the command signal v(t), ranging from f 0 to f N , into N frequency bins: [ f 0 , f 1 ], [ f 1 , f 2 ], · · · , [ f N−1 , f N ] as shown inf i , f i+1 ) which gives a filtered V [ f i , f i+1 ] ( f ).
An IFFT is then used to gener- ate v [ f i , f i+1 ] (t)which is multiplied by an ultrasound tone cos(2π f hi t) and outputted on the i th ultrasound speaker as shown in Fig. 4.
In this case, the audible leakage from i th ultrasound speaker will be s low,0 0.5 1 1.5 2 ! "
!
# !
$ !
% !
& ! '
!
( ! )
!
* 0 0.5 1 1.5 2 0 0.5 1 1.5 2 0 0.5 1 1.5 2 !"
!
# 0 0.5 1 1.5 2 !
# !
$ !
$ !
% !
% !
& 0 0.5 1 1.5 2 0 0.5 1 1.5 2 0 0.5 1 1.5 2 0 0.5 1 1.5 2 !
& !'
!'
!
( !
( !)
!)
!
* +(!)
+ [/ 0 ,/i (t) = v 2 [ f i , f i+1 ] (t).
In the frequency domain, we can write this leakage as:S low,i ( f ) = V [ f i , f i+1 ] ( f ) * V [ f i , f i+1 ] ( f )This leakage has two important properties:(1) E |S low,i ( f )| 2 ≤ E |V ( f ) * V ( f )| 2 (2) BW (S low,i ( f )) ≤ BW (V ( f ) * V ( f ))where E[|.
| 2 ] is the power of audible leakage and BW (.)
is the bandwidth of the audible leakage due to nonlinearities at each speaker.
The above properties imply that splicing the spectrum into multiple speakers reduces the audible leakage from any given speaker.
It also reduces the bandwidth and hence concentrates the audible leakage in a smaller band below 50 Hz.While per-speaker leakage is smaller, they can still add up to become audible.
The total leakage power can be written as:L( f ) = N ∑ i=1 V [ f i , f i+1 ] ( f ) * V [ f i , f i+1 ] ( f ) 2To achieve true inaudibility, we need to ensure that the total leakage is not audible.
To address this challenge, we leverage the fact that humans cannot hear the sound if the sound intensity falls below certain threshold, which is frequency dependent.
This is known as the "Threshold of Hearing Curve", T ( f ).
Fig. 5 shows T ( f ) in dB as function of frequency.
Any sound with intensity below the threshold of hearing will be inaudible.
Frequency in Hz Threshold of Hearing Curve LipRead aims to push the total leakage spectrum, L( f ), below the "Threshold of Hearing Curve" T ( f ).
To this end, LipRead finds the best partitioning of the spectrum, such that the leakage is below the threshold of hearing.
If multiple partitions satisfy this constraint, LipRead picks the one that has the largest gap from the threshold of hearing curve.
Formally, we solve the below optimization problem:maximize { f 1 , f 2 ,··· , f N−1 } min f [T ( f ) − L( f )] subject to f 0 ≤ f 1 ≤ f 2 ≤ · · · ≤ f N(6)The solution partitions the frequency spectrum to ensure that the leakage energy is below the hearing threshold for every frequency bin.
This ensures inaudibility at any human ear.Increasing Attack Range: It should be possible to increase attack range with more speakers, while also limiting audible leakage below the required hearing threshold.
This holds in principle due to the following reason.
For a desired attack range, say r, we can compute the minimum power density (i.e., power per frequency) necessary to invoke the VED.
This power P r needs to be high since the non-linear channel will strongly attenuate it by the factor A 2 .
Now consider the worst case where a voice command has equal magnitude in all frequencies.
Given each frequency needs power P r and each speaker's output needs to be below threshold of hearing for all frequencies, we can run our min-max optimization for increasing values of N, where N is the number of speakers.
The minimum N that gives a feasible solution is the answer.
Of course, this is the upper bound; for a specific voice signal, N will be lower.Increasing speakers can be viewed as beamforming the energy towards the VED.
In the extreme case for example, every speaker will play one frequency tone, resulting in a strong DC component at the speaker's output which would still be inaudible.
In practice, our experiments are bottlenecked by ADCs, amplifiers, speakers, etc., hence we will report results with an array of 61 small ultrasound speakers.
Recognizing inaudible voice attacks is essentially a problem of acoustic forensics, i.e., detecting evidence of nonlinearity in the signal received at the microphone.
Of course, we assume the attacker knows our defense techniques and hence will try to remove any such evidence.
Thus, the core question comes down to: is there any trace of non-linearity that just cannot be removed or masked?To quantify this, let v(t) denote a human voice command signal, say "Alexa, mute yourself".
When a human issues this command, the recorded signal s leg = v(t)+n(t), where n(t) is noise from the microphone.
When an attacker plays this signal over ultrasound (to launch the non-linear attack), the recorded signal s nl is: Figure 6 shows an example of s leg and s nl .
Evidently, both are very similar, and both invoke the same response in VEDs (i.e., the text-to-speech converter outputs the same text for both s leg and s nl ).
A defense mechanism would need to examine any incoming signal s and tell if it is low-frequency legitimate or a shifted copy of the high-frequency attack.s nl = A 2 2 (1 + 2v(t) + v 2 (t)) + n(t)(7) Before we describe LipRead's defense, we mention a few other possible defenses which we have explored before converging on our final defense system.
We concisely summarize 4 of these ideas.
One solution is to solve for s(t) = A 2 2 (1 + 2 ˆ v(t) + ˆ v 2 (t)), and test if the resultingˆvresultingˆ resultingˆv(t) produces the same text-tospeech (T2S) output as s(t).
However, this proved to be a fallacious argument because, if such a ˆ v(t) exists, it will always produce the same T2S output as s(t).
This is because such a ˆ v(t) would be a cleaner version of the voice command (without the non-linear component); if the polluted version s passes the T2S test, the cleaner version obviously will.Energy at Low Frequencies from v 2 (t): Another solution is to extract portions of s(t) from the lower frequencies -since regular voice signals do not contain sub-50Hz components, energy detection should offer evidence.
Unfortunately, environmental noise (e.g., fans, A/C machines, wind) leaves non-marginal residue in these low bands.
Moreover, an attacker could deliberately reduce the power of its signal so that its leakage into sub-50Hz is small.
Our experiments showed nonmarginal false positives in the presence of environmental sound and soft attack signals.
The air absorbs ultrasound frequencies far more than voice (which translates to sharper reduction in amplitude as the ultrasound signal propagates).
Measured across different microphones separated by ≈ 7.3cm in Amazon Echo and Google Home, the amplitude difference should be far greater for ultrasound.
We designed a defense that utilized the maximum amplitude slope between microphone pairs -this proved to be a robust discriminator between s leg and s nl .
However, we were also able to point two (reasonably synchronized) ultrasound beams from opposite directions.
This reduced the amplitude gradient, making it comparable to legitimate voice signals (Alexa treated the signals as multipath).
In the realworld, we envisioned 2 attackers launching this attack by standing at 2 opposite sides of a house.
Finally, this solution would require an array of microphones on the voice enabled device.
Hence, it is inapplicable to one or two microphone systems (like phones, wearables, refrigerators).
Given that long range attacks need to use at least 2 speakers (to bypass speaker non-linearity), we designed an angle-of-arrival (AoA) based technique to estimate the physical separation of speakers.
In comparison to human voice, the source separation consistently showed success, so long as the speakers are more than 2cm apart.
While practical attacks would certainly require multiple speakers, easily making them 2cm apart, we aimed at solving the short range attack as well (i.e., where the attack is launched from a single speaker).
Put differently, the right evidence of non-linearity should be one that is present regardless of the number of speakers used.
Our final defense is to search for traces of v 2 (t) in sub50Hz.
However, we now focus on exploiting the structure of human voice.
The core observation is simple: voice signals exhibit well-understood patterns of fundamental frequencies, added to multiple higher order harmonics (see Figure 6).
We expect this structure to partly reflect in the sub-50Hz band of s(t) (that contains v 2 (t)), and hence correlate with carefully extracted spectrum above-50Hz (which contains the dominant v(t)).
With appropriate signal scrubbing, we expect the correlation to emerge reliably, however, if the attacker attempts to disrupt correlation by injecting sub-50Hz noise, the stronger energy in this low band should give away the attack.
We intend to force the attacker into this zero sum game.Key Question: Why Should v 2 (t) Correlate?
Figure 7(a) shows a simplified abstraction of a legitimate voice spectrum, with a narrow fundamental frequency band around f j and harmonics at integer multiples n f j .
The lower bound on f j is > 50Hz [41].
Now recall that when this voice spectrum undergoes non-linearity, each of f j and n f j will self-convolve to produce "copies" of themselves around DC (Figure 7(b)).
Of course, the A 2 term from non-linearity strongly attenuates this "copy".
However, given the fundamental band around f j and the harmonics around n f j are very similar in structure, each of ≈ 20Hz bandwidth, the energy between [0, 20kHz] superimposes.
This can be expressed as:E [0,20] ≈ E A 2 N ∑ n=1 |V [n f j −20, n f j +20] * V [n f j −20, n f j +20] | 2 (8)The net result is distinct traces of energy in sub-20Hz bands, and importantly, this energy variation (over time) mimics that of f j .
For a legitimate attack, on the other hand, the sub-20Hz is dominantly uncorrelated hardware and environmental noise.
Figure 8(a) and (b) zoom into sub-50Hz and compare the traces of energy for s leg and s nl , respectively.
The s nl signal clearly shows more energy concentration, particularly when the actual voice signal is strong.
Figure 9 plots the power in the sub-50Hz band with increasing voice loudness levels for both s leg and s nl .
Note that loudness level is expressed in dBSpl, where Spl denotes "sound pressure level", the standard metric for measuring sound.
Evidently, non-linearity shows increasing power due to the self-convolved spectrum overlapping in the lower band.
Legitimate voice signals generate significantly less energy in these bands, thereby remaining flat for higher loudness.
The width of the fundamental frequencies and harmonics are time-varying, however, at any given time, if it is B Hz, then the self-convolved signal gets shifted into [0, B]Hz as well.
Note that this is independent of the actual values of center frequencies, f j and n f j .
Now, let s <B (t) denote the sub-B Hz signal received by the microphone and s >B (t) be the signal above B Hz that contains the voice command.
LipRead seeks to correlate the energy variation over time in s <B (t) with the energy variation at the fundamental frequency, f j in s >B (t).
We track the fundamental frequency in s >B (t) using standard acoustic libraries, but then average the power around B Hz of this frequency.
This produces a power profile over time, P f j .
For s <B (t), we also track the average power over time.
However, to avoid weak signals and disruption from noise, we remove time windows in which f j 's power is below its average.
We stitch together the remaining windows from both P f j and s <B (t) and compute their correlation co-efficient.
We use an average value of B = 20Hz.
Figure 10 shows the correlation for increasing loudness levels of the recorded signal (loudness below 60dBSpl is not audible).
The comparison is against a legitimate voice command.
Evidently, we recorded consistent correlation gap, implying that non-linearity is leaving some trace in the low-frequency bands, and this trace preserves some structure of the actual voice signal.
Of course, we have not yet accounted for the possibility that the attacker can inject noise to disrupt correlation.
The natural question for the attacker is how to modify/add signals such that the correlation gap gets narrowed.
Several possibilities arise:(1) Signal −v 2 (t) can be added to the speaker in the low frequency band and transmitted with the high frequency ultrasound v(t).
Given that ultrasound will produce v 2 (t) after non-linearity, and −v 2 (t) will remain as is, the two should interact at the microphone and cancel.
Unfortunately, channels for low frequencies and ultrasound are different and unknown, hence it is almost impossible to design the precise −v 2 (t) signal.
Of course, we will still attempt to attack with such a deliberately shaped signal.
(2) Assuming the ultrasound v(t) has been up-converted to [40,44]kHz, the attacker could potentially concatenate spurious frequencies from say [44,46]kHz.
These frequencies would also self-convolve and get "copied" around DC.
This certainly affects correlation since these spurious frequencies would not correlate well (in fact, they can be designed to not correlate).
The attacker's hope should be to lower correlation while maintaining a low energy footprint below 20Hz.
The attacker can use the above approaches to try to defeat the zero-sum game.
Figure 11 plots results from 4000 attempts to achieve low correlation and low energy.
Of these, 3500 are random noises injected in legitimate voice commands, while the remaining 500 are more carefully designed distortions (such as frequency concatenation, phase distortions, low frequency injection, etc.).
Of course, in all these cases, the distorted signal was still correct, i.e., the VED device responded as it should.On the other hand, 450 different legitimate words were spoken by different humans (shown as hollow dots), at various loudness levels, and accents, and styles.
Clusters emerge suggesting promise of separation.
However, some commands were still too close, implying the need for greater margin of separation.Correlation coeff.
Leveraging Amplitude Skew from v 2 (t) In order to increase the separation margin, LipRead leverages the amplitude skew resulting from v 2 (t).
Specifically, two observations emerge: (1) When the harmonics in voice signals self-convolve to form v 2 (t), they fall at the same frequencies of the harmonics (since the gaps between the harmonics are quite homogeneous).
tive amplitude.
Combining these together, we postulated that amplitudes of the harmonics would be positively biased, especially for those that are strong (since v 2 (t) will be relatively stronger at that location).
In contrast, amplitudes of legitimate voice signals should be well balanced on the positive and negative.
Figure 12(a,b) shows one contrast between a legitimate voice s leg and the recorded attack signal s nl .
In pursuit of this opportunity, we extract the ratio of the maximum and minimum amplitude (we average over the top 10% for robustness against outliers).
Using this as the third dimension for separation, Figure 12(c) re-plots the s leg and s nl clusters.
While the separation margin is close, combining it with correlation and power, the separation becomes satisfactory.
LipRead leverages 3 features to detect an attack: power in sub-50Hz, correlation coefficient, and amplitude skew.
Analyzing the False Acceptance Rate (FAR) and False Rejection Rate (FRR), as a function of these 3 parameters, we have converged on a ellipsoidal-based separation technique.
To determine the optimal decision boundary, we compute False Acceptance Rate (FAR) and False Rejection Rate (FRR) for each candidate ellipsoid.
Our aim is to pick the parameters of the ellipse that minimize both FAR and FRR.
Figure 13 plots the FAR and FRR as intersecting planes in a logarithmic scale (Note that we show only two features since it is not possible to visualize the 4D graph).
The coordinate with minimum value along the canyon -indicating the equal error rates -gives the optimal selection of ellipsoid.
Since it targets speech commands, this classifier is designed offline, one-time, and need not be trained for each device or individual.
We evaluate LipRead on 3 main metrics: (1) attack range, (2) inaudibility of the attack, and the recorded sound quality (i.e., whether the attacker's command sounds human-like), and (3) accuracy of the defense under various environments.
We summarize our findings below.
• We test our attack prototype with 984 commands to Amazon Echo and 200 commands to smartphones -the attacks are launched from various distances with 130 different background noises.
Figure 15 shows attack success at 24 f t for Amazon Echo and 30 f t for smartphones at a power of 6watt.
• We record 12 hours of microphone data -5 hours of human voice commands and 7 hours of attack commands through ultrasound speakers.
Figure 16(c) shows that attack words are recognized by VEDs with equal accuracy as legitimate human words.
Figure 16(b) confirms that all attacks are inaudible, i.e., the leakage from our speaker array is 5-10dB below human hearing threshold.
• Figure 17(a) shows the precision and recall of our defense technique, as 98% and 99%, respectively, when the attacker does not manipulate the attack command.
Importantly, precision and recall remain steady even under signal manipulation.Before elaborating on these results, we first describe our evaluation platforms and methodology.
(1) Attack speakers: Figure 14(b) shows our customdesigned speaker system consisting of 61 ultrasonic piezoelectric speakers arranged as a hexagonal planar array.
The elements of the array are internally connected in two separate clusters.
A dual channel waveform generator (Keysight 33500b series [4]) drives the first cluster with the voice signal, modulated at the center frequency of 40kHz.
This cluster forms smaller sub-clusters to transmit separate segments of the spliced spectrum.
The second cluster transmits the pure 40kHz tone through each speaker.
The signals are amplified to 30 Volts using a custom-made NE5534AP op-amp based amplifier circuit.
This prototype is limited to a maximum power of 6watt because of the power ratings of the operational amplifiers.
More powerful amplifiers are certainly available to a resourceful attacker.
(2) Target VEDs: We test our attack on 3 different VEDs -Amazon Echo, Samsung S6 smartphone running Android v7.0, and Siri on an iPhone 5S running iOS v10.3.
Unlike Echo, Samsung S-voice and Siri requires personalization of the wake-word with user's voice -adding a layer of security through voice authentication.
However, voice synthesis is known to be possible [46,5], and we assume that the synthesized wake-word is already available to the attacker.Experiment setup: We run our experiments in a lab space occupied by 5 members and also in an open corridor.
We place the VEDs and the ultrasonic speaker at various distances ranging up to 30 f t.
During each attack, we play varying degrees of interfering signals from 6 speakers scattered across the area, emulating natural home/office noises.
The attack signals were designed by first collecting real human voice commands from 10 different individuals; MATLAB is used to modulate them to ultrasound frequencies.
For speech quality of the attack signals, we used the open-source Sphinx4 speech processing tool [1].
Activation distance: This experiment attempts to activate the VEDs from various distances.
We repeatedly play the inaudible wake-word from the ultrasound speaker system at regular intervals and count the fraction of successful activation.
Figure 15(a) shows the activation hit rate against increasing distance -higher hit-rates indicate success with less number of attempts.
The average distance achieved for 50% hit rate is 24 f t, while the maximum for Siri and Samsung S-voice are measured to be 27 and 30 f t respectively.
Figure 15(b) plots the attack range again, but for the entire voice command.
We declare "success" if the text to speech translation produces every single word in the command.
The range degrades slightly due to the stronger need to decode every word correctly.
Figure 16(a) reports the attack range to Echo for increasing input power to the speaker system.
As expected, the range continues to increase, limited by the power of our 6Watt amplifiers.
More powerful amplifiers would certainly enhance the attack range, however, for the purposes of prototyping, we designed our hardware in the lower power regime.Leakage audibility: Figure 16(b) plots the efficacy of our spectrum splicing optimization, i.e., how effectively does LipRead achieve speaker-side inaudibility for different ultrasound commands.
Observe that without splicing (i.e., "no partition"), the ultrasound voice signal is almost 5dB above the human hearing threshold.
As the number of segments increase, audibility falls below the hearing curve.
With 60 speakers in our array, we use 6 segments, each played through 5 speakers; the remaining 31 were used for the second cos(2π f c t) signal.
Note that the graph plots the minimum gap between the hearing threshold and the audio playback, implying that this is a conservative worst case analysis.
Finally, we show results from 20 example attack commands -the other commands are below the threshold.Received speech quality: Given 6 speakers were transmitting each spliced segment of the voice command, we intend to understand if this distorts speech quality.
Figure 16(c) plots the word recognition accuracy via Sphinx [1], an automatic speech recognition software.
Evidently, LipRead's attack quality is comparable to human quality, implying that our multi-speaker beamforming preserves the speech's structure.
In other words, speech quality is not the bottleneck for attack range.
Metrics: Our defense technique essentially attempts to classify the attack scenarios distinctly from the legitimate voice commands.
We report the "Recall' and "Precision" of this classifier for various sound pressure levels (measured in dBSPL), varying degrees of ambient sounds as interference, and deliberate signal manipulation.
Recall that our metrics refer to:• Precision: What fraction of our detected attacks are correct?
• Recall: What fraction of the attacks did we detect?We now present the graphs beginning with the basic classification performance.Basic attack detection: Figure 17(a) shows the attack detection performance in normal home environment without significant interference.
The average precision and recall of the system is 99% across various loudness of the received voice.
This result indicates best case performance of our system with minimum false alarm.Impact of ambient noise: In this section we test our defense system for common household sounds that can potentially mix with the received voice signal and change its features leading to misclassification.
To this end, we played 130 noise sounds through multiple speakers while recording attack and legitimate voice signals with a smartphone.
We replayed the noises at 4 different sound pressure levels starting from a typical value of 50 dBSPL to extremely loud 80 dBSPL, while the voice loudness is kept constant at 65 dBSpl.
Figure 17(b) reports the precision and recall for this experiment.
The recall remains close to 1 for all these noise levels, indicating that we do not miss attacks.
However, at higher interference levels, the precision slightly degrades since the false detection rate increases a bit when noise levels are extremely high which is not common in practice.
Impact of injected noise: Next, we test the defense performance against deliberate attempts to eliminate nonlinearity features from the attack signal.
Here the attackers strategy is to eliminate the v 2 (t) correlation by injecting noise in the attack signal.
We considered four different categories of noise -white Gaussian noise to raise the noise floor, band-limited noise on the Sub-50Hz region, water-filling noise power at low frequencies to mask the correlated power variations, and intermittent frequencies below 50 Hz.
As shown, in Figure 17(c), the process does not significantly impact the performance because of the power-correlation trade-off exploited by the defense classifier.
Figure 17(d) shows that the overall accuracy of the system is also above 99% across all experiments.
We discuss several dimensions of improvement.Lack of formal guarantee: We have not formally proved our defense.
Although LipRead is systematic and transparent (i.e., we understand why it should succeed) it still leaves the possibility that an attack may breach the defense.
Our attempts to mathematically model the self-convolution and correlation did not succeed since frequency and phase responses for general voice commands were difficult to model, as were real-world noises.
A deeper treatment is necessary, perhaps with help from speech experts who can model the phase variabilities in speech.
We leave this to future work.Generalizing to any signal: Our defense is designed for the class of voice signals, which applies well to inaudible voice attacks.
A better defense should find the true trace of non-linearity, not just for the special case of voice.
This remains an open problem.Is air non-linear as well?
There is literature that claims air is also a non-linear medium [17,10,45].
When excited by adequately powerful ultrasound signals, selfconvolution occurs, ultimately making sounds audible.
Authors in [36,2] are designing acoustic spotlighting systems where the idea is to make ultrasound signals audible only along a direction.
We have encountered traces of air non-linearity, although in rare occasions.
This certainly call for a separate treatment in the future.
Through-wall attack: Due to the limited maximum power (6watt) of our amplifiers, we tested our system in non-blocking scenarios.
If the target device is partially blocked (e.g. furnitures in the room blocking line-ofsight), the SNR reduces and our attack range will reduce.
This level of power has not allowed us to launch throughwall attacks yet.
We leave this to future work.
Attack on Voice Recognition Systems: Recent research [11,42] shows that spoken words can be mangled such that they are unrecognizable to humans, yet decodable by voice recognition (VR) systems.
GVS-Attack [14] exploits this by creating a smartphone app that gives adversarial commands to its voice assistant.
More recently, BackDoor [37] has taken advantage of the microphone's nonlinearity to design ultrasonic sounds which are inaudible to humans, but becomes recordable inside the off-the-shelf microphones.
The application includes preventing acoustic eavesdropping with inaudible jamming signals.
As follow up, [48,39] show that the principles of BackDoor can be used to send inaudible attack commands to a VED, but requires physical proximity to remain audible.
LipRead demonstrates the feasibility to increase the inaudible attack range, but more importantly, designs a defense against the inaudible attacks.In past, researchers use near-ultrasound [27,32,40,9,21,30] and exploited aliasing to record inaudible sound with microphone.
A number of papers use other sound to camouflage audible signal in order to make it indistinguishable to human [24,20,12].
CovertBand [33] use music to hide audible harmonic components at the speaker.
LipRead, on the other hand, use high frequency ultrasound as inaudible signal and leverages hardware nonlinearity to make them recordable to microphone.Acoustic Non-linearity: A body of research [17,10,45], inspired by Westervelt's seminal theory [44,43] on nonlinear Acoustics, studies the distortions of sound while moving through nonlinear mediums including the air.
This raises the possibility that ultrasonic sound can naturally self-demodulate in the air to generate audible sounds, making it possible to develop a highly directional speaker [17,10,45].
Recently, AudioSpotlight [2], SoundLazer [7,6], and other projects [47,8,34] have rolled out commercial products based on this concept.
Ultrasonic hearing aids [29,13,15,35,31] and headphones [25] explore the human body as a nonlinear medium to enable voice transfer through bone conduction.
Our work, however, is opposite of these effortswe attempt to retain the inaudible nature of ultrasound while making it recordable inside electronic circuits.Speaker Linearization: A number of research [23,26,18] studies the possibility of adaptive linearization of general speakers.
Through simulations, the authors have shown that by pre-processing the input signal, they can achieve as much as 27dB reduction [18] of the nonlinear distortion in the noise-free case.
Their techniques are not yet readily applicable to real speakers, since they have all assumed very weak nonlinearities, and over-simplified electrical and mechanical structures of speakers.
With real speakers, especially ultrasonic piezoelectric speakers, it is difficult to fully characterize the parameters of the nonlinear model.
Of course, if future techniques can fully characterize such models, our system can be made to achieve longer range with fewer speakers.
This paper builds on existing work to show that inaudible voice commands are viable from distances of 25+ f t. Of course, careful design is necessary to ensure the attack is truly inaudible -small leakages from the attacker's speakers can raise suspicion, defeating the attack.
This paper also develops a defense against inaudible voice commands that exploit microphone nonlinearity.
We show that non-linearity leaves traces in the recorded voice signal, that are difficult to erase even with deliberate signal manipulation.
Our future work is aimed at solving the broader class of non-linearity attacks for any signals, not just voice.
We sincerely thank our shepherd Prof. Shyamnath Gollakota and the anonymous reviewers for their valuable feedback.
We are grateful to the Joan and Lalit Bahl Fellowship, Qualcomm, IBM, and NSF (award number: 1619313) for partially funding this research.
