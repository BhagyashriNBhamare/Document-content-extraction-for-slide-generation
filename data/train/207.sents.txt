We provide methods for transforming an encryption scheme susceptible to decryption errors into one that is immune to these errors.
Immunity to decryption errors is vital when constructing non-malleable and chosen ciphertext secure encryption schemes via current techniques; in addition, it may help defend against certain cryptanalytic techniques, such as the attack of Proos [36] on the NTRU scheme.
When decryption errors are very infrequent, our transformation is extremely simple and efficient, almost free.
To deal with significant error probabilities, we apply amplification techniques translated from a related information theoretic setting.
These techniques allow us to correct even very weak encryption schemes where in addition to decryption errors, an adversary has substantial probability of breaking the scheme by decrypting random messages (without knowledge of the secret key).
In other words, under these weak encryption schemes, the only guaranteed difference between the legitimate recipient and the adversary is in the frequency of decryption errors.
All the above transformations work in a standard cryptographic model; specifically, they do not rely on a random oracle.
We also consider the random oracle model, where we give a simple transformation from a one-way encryption scheme which is error-prone into one that is immune to errors.
We conclude that error-prone cryptosystems can be used in order to create more secure cryptosystems.
In their seminal paper on semantic security Goldwasser and Micali defined a public key encryption scheme as one where the decryption is perfect, i.e., given a properly formed ciphertext the answer is always the unique corresponding plaintext [21].
More formally, let the encryption algorithm be E and the corresponding decryption algorithm be D.
If E maps a message m with random coins r to a ciphertext c = E(m, r), then it is always the case that D(E(m, r)) = m. However, some cryptosystems do not satisfy this condition, two notable examples being the Ajtai-Dwork cryptosystem [1] and NTRU [23].
(In fact, sometimes a cryptosystem is deliberately designed to have ambiguous decryption; see more in Section 6.)
One might think that an encryption scheme with small probability of decryption error is merely an aesthetic nuisance, since the event of a decryption error can be compared to the event of an adversary guessing the secret key, which should be rare.
However, serious difficulties arise in trying to construct cryptosystems secure under more stringent notions of security, such as non-malleability and chosen-ciphertext immunity, based on systems with ambiguous decryption.
In fact, all known "bootstrapping" methods for constructing strong cryptosystems fail when the underlying one is Incumbent of the Judith Kleeman Professorial Chair.
Research supported in part by a grant from the Israel Science Foundation.
Part of this work was done while visiting Microsoft Research, SVC.
Most of this research was performed while at AT&T Labs -Research and while visiting the Institute for Advanced Study, Princeton, NJ.
susceptible to errors 3 .
Furthermore, Proos was able to exploit decryption errors in his attack on the NTRU scheme [36].
Our goal in this work is to discuss general methods for eliminating errors and constructing secure cryptosystems based on less than perfect underlying schemes.
The literature contains constructions for cryptographic primitives in two well studied models: the random oracle world as described below, and the real world, where the assumption of a random oracle may not be justified.
In general it is more difficult and involved to provide and prove correct constructions in the real world model.If one makes the simplifying assumption that a specific function behaves as an idealized random function (random oracle), then it is possible to obtain simple and efficient constructions of public-key encryption schemes that are secure against chosen ciphertext attacks in the post-processing mode ("cca-post", also known as CCA2); these include OAEP and its variants [6,3,35,16,7], FujisakiOkamoto [15] and REACT [34] 4 .
However, it is not known if any one of these methods (or some other method) can be used to convert every public-key cryptosystem -including systems with decryption errors -that is semantically secure (or that satisfies even some weaker property such as one-wayness on the messages) against chosen plaintext attacks into one that is secure against stronger attacks, such as cca-post attacks (see below for more information on attacks).
Among the problems in applying these approaches are that in the underlying "input" cryptosystem (1) there can exist ciphertexts which are valid encryptions of two different plaintext messages; and (2) the decryption mechanism may sometimes fail to return "invalid" on an invalid ciphertext.
As mentioned above, these problems were exploited by Proos [36] to attack various paddings of NTRU [33].
In the real world we have no idealized function, and we must do with what nature gives us.
An important idea used either explicitly or at least implicitly in the construction of chosen ciphertext secure cryptosystem in the real world is to add some redundancy to the encryption and provide a proof of consistency of the ciphertext.
The most general form of the proof of consistency is via a non-interactive zero-knowledge proof system (NIZKs) [12,30,32,37], but there are also more specific methods [10,11].
Here too a cryptosystem with possible decryption errors may cause problems in the construction.
Take for instance the method that is based on a pair of keys together with a NIZK of consistency (this is the one suggested by Naor and Yung [32] and also a subsystem of the Dolev, Dwork, and Naor scheme [12]).
A central idea in the proof of security is that knowing any of several private keys is sufficient for the decryption, and which one (of the several) is known is indistinguishable to the adversary.
However, if there is no unique decryption, then seeing which plaintext is returned may leak which key is known, and the proof of security collapses.
We suggest methods for dealing with errors in both worlds described above:In the land of random oracles: We provide a generic and efficient method for converting any publickey cryptosystem where decryption errors may occur, but where an adversary cannot retrieve the plaintext of a randomly chosen message (sometimes known as one-way cryptosystem), into one that is secure against chosen ciphertext attack in the post-processing mode.
This is done in Section 5.
The real world: We show two transformations from cryptosystem with errors to ones without.
When decryption errors are very infrequent, our transformation is extremely simple and efficient, almost free.
The case of of significant error probabilities is technically more involved.
Our transformation for this case corrects even very weak encryption schemes where in addition to decryption errors, an adversary has substantial probability of breaking the scheme by decrypting random messages (without knowledge of the secret key).
In other words, under these weak encryption schemes, the only guaranteed difference between the legitimate recipient (holder of the secret key) and the adversary is in the frequency of decryption errors: the legitimate recipient experiences fewer errors than does the adversary.To demonstrate the subtleties of this task, consider the case where the legitimate recipient decrypts correctly with probability 9/10 (and let us assume for simplicity that otherwise he gets an error message), but the adversary decrypts correctly with probability 1/10.
A natural approach is to use error correcting codes, setting the parameters in such a way that the legitimate recipient will have enough information to decode, whereas the adversary will get no information.
This approach indeed works in the information theoretic counterpart of a channel where the receiver gets the piece of information with certain probability and the eavesdropper with another.
But it is not clear how to carry it through in the computational setting.
Therefore, the solutions given in this paper use a different approach: we apply amplification techniques translated from the related information theoretic setting of [38].
We note that here, too, the computational setting introduces additional complications.The conclusion we reach is that once provided with noninteractive zero knowledge proof systems, one can convert any public-key cryptosystem with decryption errors into one that is secure against chosen ciphertext attack in the postprocessing mode.Related Work: In addition to the work mentioned above we should point out two specific papers that converted an error-prone scheme into an error free one.
Goldreich, Goldwasser and Halevi [19] showed how to eliminate decryption errors in the Ajtai-Dwork [1] cryptosystem.
Our methods, especially those of Section 3, can be seen as a general way of achieving that goal.
In the papers of Howgrave-Graham et al. [25,26] the problem of constructing an CCA-post-secure NTRU-based method in the random oracles world is considered.
We will abbreviate "probabilistic polynomial time Turing Machine" with PPTM.
We use the notation poly(·) to refer to some polynomially bounded function and neg(·) to refer to some function that is smaller than 1/p(·) for any polynomial p(·) (for all sufficiently large inputs).
For any integer n, we let U n denote the uniform distribution over {0, 1} n .
We let the operation ⊕ on two bit-strings denote their bit-wise XOR.
A public-key encryption scheme consists of three probabilistic polynomial time algorithms (G, E, D), for key generation, encryption and decryption respectively.
For simplicity we fix n to be both the security parameter and input length, and assume that the message space is {0, 1} n .
Algorithm G, for the key-generating is given 1 n as input (as well as internal random coins), and outputs the public key and secret key pair air (pk, sk).
We have that |pk| = |sk| = poly(n).
E and D are, respectively, the encryption and decryption algorithms.
E takes as input a public key pk, an n-bit plaintext message m, and uses internal random coins.
We refer to the output c ∈ E pk (m) as the ciphertext.
When we want to refer to E's additional poly(n)-long random input r explicitly, we will use the notation E pk (m; r).
Finally, D takes as input a secret key sk and a ciphertext.
The output of D is either a message m (which may fail to equal the original message m) or ⊥ to indicate invalid (we are deliberately not attaching semantics to a response of "invalid").
The standard definition of public-key encryption schemes requires perfect correctness.
Namely, that if the input c to D sk is well constructed using E sk , then the output D sk (c) is supposed to retrieve the original plaintext.
We make this explicit in the next definition.
Definition 1.
A public-key encryption scheme (G, E, D) is perfectly correct if the following holds:-For every message m of length n, for every pair (pk, sk) generated by G on input 1 n , and all possible coin tosses of E and D, it should hold that D sk (E pk (m)) = m.Although we allowed D to output ⊥ we made no assumption on the probability of ⊥ being the output in case the ciphertext is indeed invalid (where invalid means that there do not exist m and r such that c = E pk (m; r)).
We now want to relax the notion of public key-encryption so as to allow decryption errors.
We define an encryption scheme to be α-correct, if the probability of decryption error is at most 1 − α.Definition 2.
For any function α : IN → [0, 1], a public-key (G, E, D) encryption scheme is α- correct if Pr[D sk (E pk (m)) = m] ≤ 1 − α(n),where the probability is taken over the random coins of G used to generate (pk, sk) on input 1 n , over the choice of m ∈ U n , and over the random coins of E and D.In the above definition the error probability is taken over the random choice of the message (uniformly at random), the randomness of the encryption and decryption and the choice of the key.In particular, some keys may be completely useless as they don't allow decryption at all.
We now consider the case that the bound on the decryption error holds for all keys or for all but a negligible fraction of the keys.
These definitions are relevant here for two reasons: (1) Our transformations will be a bit more efficient if we only try to immunize against this kind of errors.
(In the sense that the key of the revised scheme will only include a single key of the original scheme.)
(2) Our transformations will produce schemes that are "almost-all-keys perfectly correct" rather than perfectly correct encryptions.
This means that decryption errors can only occur with a negligible probability over the choice of the key.
Note that such errors are usually much less harmful, and in particular such schemes can be made non-malleable using "standard" techniques (unlike the case where errors may occur for a substantial fraction of the keys).
-(G, E, D) is all-keys α-correct if for every pair (pk, sk) generated by G on input 1 n , Pr[D sk (E pk (m)) = m] ≤ 1 − α(n),where the probability is taken over the choice of m ∈ U n , and over the random coins of E and D.-(G, E, D) is almost-all-keys α-correct if with probability (1 − neg(n)) over the random coins of G used to generate (pk, sk) on input 1 n , Pr[D sk (E pk (m)) = m] ≤ 1−α(n),where the probability is taken over the choice of m ∈ U n , and over the random coins of E and D. -(G, E, D) is almost-all-keys perfectly correct if with probability (1 − neg(n)) over the random coins of G used to generate (pk, sk) on input 1 n , Pr[D sk (E pk (m)) = m] = 0, where the probability is taken over the choice of m ∈ U n , and over the random coins of E and D. Semantic security [21] has established itself as essentially the minimal desired notion of security for encryption schemes.
Intuitively, a public-key encryption scheme is semantically secure if anything that a polynomial-time adversary can compute about the plaintext m given the ciphertext c = E pk (m), it can also compute without access to c. Semantic security was shown in [21] to be equivalent to the indistinguishability of ciphertexts, which intuitively means that ciphertexts which correspond to different plaintexts are indistinguishable.
Three basic modes of attack for which semantic security was considered are: chosen plaintext attack (which for public-key encryption essentially amounts to giving the adversary the public-key pk and allowing the adversary to decide the challenge distribution), and chosen ciphertext attack in the preprocessing and the postprocessing modes (in both the adversary also gets access to a decryption oracle; in the preprocessing mode this access ends when the ciphertext challenge is published).
Semantic security under these attacks is denoted IND-CPA, IND-CCA-Post and IND-CCA-Pre respectively.
An even stronger notion of security than semantic security is that of non-malleability [12].
Intuitively, here the adversary should not even gain a (non-negligible) advantage in creating an encryption of a message that relates to m. Non malleability with respect to the above attacks is denoted NM-CPA, NM-CCA-Post and NM-CCA-Pre respectively.
For the formal definitions of the above notions we rely on [12].
Both semantic security and non-malleability were originally defined for perfectly correct encryption schemes.
Nevertheless they are just as meaningful for schemes with decryption errors.
Section 3 gives a very simple way of eliminating decryption errors (as long as they are very rare) while preserving each one of the above six notions of security.
Section 4 shows how to immunize much weaker encryption schemes.
Here decryption errors will be more likely (may even happen with probability 1 − poly).
In addition, we will make much weaker security assumptions: we will only bound the success probability of the adversary in "inverting E" and completely retrieving the plaintext message m. (Therefore, the only advantage the legitimate recipient has over the adversary is in the probability of decryption.)
This notion of weak security is captured by the following definition.Definition 4.
For any function β : IN → [0, 1], a public-key encryption scheme is β-one-way (β- OW) if for every PPTM A, Pr[A((E pk (m)) = m] ≤ β(n) + neg(n),where the probability is taken over the random coins of G used to generate (pk, sk) on input 1 n , over the choice of m ∈ U n , and over the random coins of E and A.We note that unlike semantic security and non-malleability, this notion of security allows the encryption scheme E to be deterministic.Pseudorandom Generators One of the transformations of this paper uses pseudorandom generators as a main tool.
Pseudorandom generators can be obtained from any one-way function [24]; one-way functions, in turn, are an essential ingredient in cryptography [27].
A pseudorandom generator is a function prg : {0, 1} * → {0, 1} * such that on n-bit input x, the output prg(x) is (n) > n bits long and such that prg(U n ) is computationally indistinguishable from U (n) .
See [18,17] for a formal definition.
This section describes a very efficient way for eliminating decryption errors when errors are very rare.
If errors are too frequent to apply this technique directly, then one can first apply the amplification methods described in Section 4.
Let E be an encryption scheme where for every message m, the probability over the randomness r of E that D sk (E pk (m; r)) = m is tiny.
To correct this scheme we use the "reverse randomization" trick from the construction of Zaps [13] and commitment protocols [31] (which can be traced back to Lautemann's proof that BPP is in the polynomial time hierarchy [29]).
The idea is very simple: by assumption, only a tiny fraction of "bad" random strings r lead to ciphertexts with decryption errors.
Thus, we will arrange that the ciphertexts are constructed using only a rather small fraction of the possible values for r; the particular set of values will depend on the choice of public key.
Very minimal independence in the selection of this subset will already assure that we are avoiding the bad strings with very high probability.
In addition, the subset will be constructed to be pseudorandom, which will guarantee that the semantic security of the original scheme is preserved.
Finally, the construction will ensure that the error probability is only on the choice of encryption key -if the encryption key is good, no ciphertext created with this encryption key will suffer a decryption error.
The only significant computational cost incurred by this transformation is a single invocation of a pseudorandom generator (and in fact, this may already be performed to save on random bits, in which case the transformation is essentially for free).
For simplicity we state the next construction (and the corresponding theorem) under the assumption that the decryption algorithm D is deterministic.
In the case of chosen-plaintext attack (which is probably the most interesting setting of the theorem), this can be obtained simply by fixing the randomness of D as part of the key.
The case of chosen-ciphertext attacks is a bit more delicate but still the construction can be easily extended to randomized D.Construction 1 Let (G, E, D) be any public-key encryption scheme.
Let (n) be the (polynomially bounded) number of bits used by E to encrypt n-bit messages.
Without loss of generality assume that (n) > n (as E can always ignore part of its random input).
Let prg be a pseudorandom generator that expands n bits to (n) bits.Define the public-key encryption scheme (G , E , D ) as follows: on input 1 n , the generation algorithm G outputs ((pk, ¯ r), sk) where (pk, sk) is obtained by invoking G on the same input and ¯ r ∈ U (n) .
On an n-bit input m, the encryption function E uses an n-bit random string s and outputs Proof.
For any fixed value of ¯ r, the distribution prg(U n ) ⊕ ¯ r is pseudorandom.
Therefore, it easily follows that (G , E , D ) is NN-AAA secure (otherwise we could construct a distinguisher that breaks the pseudoraondom generator).
E pk (m; prg(s) ⊕ ¯ r).
The decryption function D is identical to D.It remains to prove the correctness of (G , E , D ), i.e. that with high probability over the choice of keys the scheme is perfectly correct.
First, with probability at least (1 − 2 −n ) over the choice of (pk, sk), the value Pr m,r [D sk (E pk (m; r)) = m] is at most 2 −3n .
Assume that (pk, sk) satisfies this property.
Since ¯ r is uniformly distributed we also have that Pr m,s,¯ r [D sk (E pk (m; prg(s) ⊕ ¯ r)) = m] ≤ 2 −3n .
As m and s are only n-bit long, we get by a union bound that the probability over ¯ r that for some m and s a decryption error D sk (E pk (m; prg(s) ⊕ ¯ r)) = m will occur is at most 2 −n .
We can therefore conclude that for all but at most a 2 −n+1 fraction of (G , E , D ) keys ((pk, ¯ r), sk) the scheme is perfectly correct.Remark 1.
The existence of the pseudorandom generator needed for Construction 1, follows from the security of (G, E, D) (under any one of the notions considered by the theorem).
This is because the security of (G, E, D) implies the existence of one-way functions [27] which in turn imply the existence of pseudorandom generators [24].
Consider the construction of [12] for NM-CCA-post secure public key cryptosystems.
This requires (i) a perfectly correct public-key cryptosystem which is semantically secure against chosen plaintext attacks (ii) A non-interactive zero-knowledge (NIZK) proof system for NP (that is for some specific language in NP) (iii) other primitives that can be based on one-way functions.
Furthermore, if we replace in that construction the perfectly correct cryptosystem with one that is almost-all-keys-perfectly-correct, then all that happens is that the resulting construction is also of a similar nature.
Therefore we can conclude Corollary 1 If (1−2 −4n )-correct public-key encryption schemes semantically secure against chosen plaintext attacks exist and NIZK proof system for NP exist, then almost-all-key perfectly correct public-key encryption schemes which are NM-CCA-post secure public key cryptosystems exist.
We now consider much weaker encryption schemes than in Section 3.
Here the encryption may only be α-correct and β-OW where α and β may be as small as 1/poly.
Naturally, α has to be larger than β as otherwise the legitimate recipient of a message will have no advantage over the adversary (and such a scheme is useless and trivial to construct).
The transformation given here works under the assumption that β < α 4 /c for some fixed constant c.
An interesting open problem is to give a transformation that works for even smaller gaps.
Nevertheless, as we discuss below, having the transformation work for a gap β − α that is larger than an arbitrary constant, may involve improving the corresponding transformation in the related information-theoretic setting of [38].
Sahai and Vadhan [38], give an efficient transformation of a pair of distributions (X 0 , X 1 ) (encoded by the circuits that sample them) into a new pair of distributions (Y 0 , Y 1 ).
The transformation "polarizes" the statistical distance between X 0 and X 1 .
If this distance is below some threshold β then the statistical distance between Y 0 and Y 1 is exponentially small.
If on the other hand the distance between X 0 and X 1 is larger than another threshold α then the statistical distance between Y 0 and Y 1 is exponentially close to 1.
The condition for which this transformation works is that β < α 2 .
What is the relation between this problem and ours?
Consider an α-correct and β-OW encryption scheme, for one-bit messages.
Let X 0 be the distribution of encryptions of 0 and X 1 the distribution of encryptions of 1.
Intuitively we have that the legitimate recipient can distinguish these distributions with advantage α − (1 − α) = 2α − 1 (recall that α > 1/2), while the adversary cannot distinguish the distributions with advantage better than 2β −1 < 2α−1.
Our transformation produces a new encryption scheme; let Y 0 and Y 1 be the corresponding distributions.
We now have that the ability of the adversary to distinguish between Y 0 and Y 1 shrinks (to negligible), whereas the legitimate recipient distinguishes with probability that is exponentially close to 1.
In fact, this intuitive similarity can be formalized to show that any transformation in the computational setting that is "sufficiently black box" implies a transformation in the statistical setting.
This in particular implies that for our transformations to work for any constant gap α − β, we may need to improve the transformation of [38] (or to use non black-box techniques).
What about the other direction?
It seems much harder in general to translate transformations from the statistical setting to the computational one.
Nevertheless, the transformations given in this section are heavily influenced by [38].
However, the computational versions of the amplification tools used in [38] are significantly weaker, which imposes additional complications and implies somewhat weaker bounds than those of [38].
To improve an α-correct and β-OW encryption scheme (G, E, D), we will use three basic transformations:Parallel Repetition The encryption E k of a k-tuple of messages m 1 , . . . , m k will be defined as E k (m 1 , . . . , m k ) = E(m 1 ), . . . , E(m k ).
A negative effect of this transformation is that the probability of correct decryption of the entire k-tuple is reduced to α k .
The gain of the transformation is that the probability of the adversary to break the one-wayness of E k will also decrease below β (usually in an exponential rate as well).
To bound this probability we apply a result of Bellare et al. [4] on the amplification of games in parallel execution.
To conclude, this transformation makes decryption harder both for the legitimate recipient and for the adversary.
As the adversary has a weaker starting point (success probability β α), it will be hurt more by the transformation.
Hard Core Bit Here we will transform an encryption scheme for strings to one that encrypts single bits.
This will employ a hard core predicate in a rather standard fashion.
The gain from this transformation is in turning the one-wayness of an encryption scheme into indistinguishability (which is easier to work with and is also our final goal).
Direct Product The encryption E ⊗k of a message m will be the concatenation of k independent encryptions of m under E.
This transformation has the reverse affect to E k : Decryption becomes easier both for the legitimate recipient and for the adversary.
As the legitimate recipient has a better starting point (success probability α β), it will gain more by the transformation.In the formal definition of E k and E ⊗k , we use independently generated keys for each one of the invocations of E by these schemes.
This is necessary as a large fraction of the keys of E may be completely useless (i.e., do not allow decryption at all or completely reveal the message).
So in order to amplify the security and correctness, we should use more than a single key.
This can be avoided if we assume that (G, E, D) is α-correct and β-OW even after we fix the key of E (for all but negligible fraction of the keys).
In such a case, the transformations of this paper will become much more efficient (in terms of key size).
We now turn to the formal definition of the basic transformations.
Definition 5.
Let (G, E, D) be any public-key encryption scheme, and let k : IN → IN be any polynomially bounded function.
Define (G k , E k , D k ) as follows: On input 1 n , the key-generating algorithm G k invokes G, with input 1 n , k = k(n) times using independent random coins for each invocation.
The output of G k is ( ¯ pk, ¯ sk) where ¯ pk = pk 1 , . . . pk k , ¯ sk = sk 1 , . . . sk k , and (pk i , sk i ) is the output of G in its i th invocation.
On input ¯ m = m 1 , . . . m k the output E k ¯ pk ( ¯ m) is defined by E k ¯ pk ( ¯ m) = E pk 1 (m 1 ), . . . E pk k (m k ),1/poly, then (G k , E k , D k ) is α k -correct and β -OW for any β > 1/poly that satisfies β > 32/(1 − β) · e −k(1−β) 2 /256 .
Proof.
The correctness of (G k , E k , D k ) follows immediately from the definition.
The security is much more delicate.
Fortunately, it can be obtained as a simple corollary of a theorem of Bellare, Impagliazzo, and Naor regarding error probability in parallel execution of protocols of up to three rounds ([4] Theorem 4.1).
Thus, we need to translate the breaking of (G k , E k , D k ) into winning the parallel execution of a game that is composed of at most three messages.
Specifically, consider the following game between P and (an honest) V , where V invokes G to select (pk, sk), it selects a uniform message m and sends pk and E pk (m) to P .
In return, P sends a message m and wins if m = m .
From the one-wayness of (G, E, D) we get that the best efficient strategy of P can win with probability at most β + neg.
Note that the probability of winning the k-times parallel repetition of this game is the same as breaking the one-wayness of (G k , E k , D k ).
The lemma now follows from Theorem 4.1 of [4].
For concreteness we will use the Goldreich-Levin (inner product) bit [20].
This could be replaced with hard-core bits implied by other error-correcting codes that have strong list-decoding properties.Definition 6.
Let (G, E, D) be any public-key encryption scheme, where the encryption function operates on plaintexts of length ≥ 1, and let k : IN → IN be any polynomially bounded function.
Define (G , E , D ) as follows: G is simply identical to G. On a one-bit message σ, the encryption function E pk samples two -bit strings m and r uniformly at random and outputs E pk (m), r, m, r⊕ σ, where m, r is the inner product of m and r (mod 2).
On input c, r, σ the decryption functionD pk evaluates m = D pk (c).
If m = ⊥, then D pk outputs m , r ⊕ σ , otherwise D pk outputs a random bit.
Lemma 2.
Let (G, E, D) be any public-key encryption scheme.
If (G, E, D) is α-correct and β- OW, then (G , E , D ) is (1/2+α/2)-correct and 1/2+O( √ β)-OW.
In particular, if β is negligible then (G , E , D ) is IND-CPA secure.Proof.
For correctness, note that if m = D pk (c) = m (as in Definition 6), then D pk decrypts correctly with probability one.
Otherwise D pk decrypts correctly with probability half (since the probability over r that for any m = m we have that m , r = m, r is half).
We can therefore conclude that the probability of correct decryption is at least α · 1 + (1 − α) · 1/2 = 1/2 + α/2.
For security, let us first assume that β is negligible.
In this case (G , E , D ) is (1/2)-OW and equivalently is IND-CPA secure.
Assume for the sake of contradiction that there exists an efficient adversary that decrypts D pk with probability 1/2 + 1/poly without access to sk.
In this case, there is an efficient adversary that given E pk (m) and r guesses m, r with probability 1/2 + 1/poly.
Now we obtain from [20] that there exists an efficient adversary that given E pk (m) outputs m with probability 1/poly.
This contradicts the assumption that (G, E, D) is neg-OW.
Finally, let us consider the case where β is non-negligible.
Assume for the sake of contradiction that there exists an efficient adversary that decrypts D pk with probability 1/2 + , where = c · √ β for some large constant c (note that > 1/poly).
This again implies the existence of an efficient adversary that given E pk (m) and r guesses m, r with the same probability.
Using a tight enough version of the reconstruction algorithm for the Goldreich-Levin hard-core bit, we can conclude that there exists an efficient adversary that given E pk (m) computes a list of O(1// 2 ) candidates that include m with probability 1/2.
This means that this adversary can also guess m with probability Ω( 2 ) which can be made say 2β by setting the constant c to be large enough.
This contradicts the β-one-wayness of (G, E, D) and completes the proof of the lemma.
Definition 7.
Let (G, E, D) be any public-key encryption scheme, and let k : IN → IN be any polynomially bounded function.
Define (G ⊗k , E ⊗k , D ⊗k ) as follows: On input 1 n , the key-generating algorithm G ⊗k invokes G, with input 1 n , k = k(n) times using independent random coins for each invocation.
The output of G ⊗k is ( ¯ pk, ¯ sk) where ¯ pk = pk 1 , . . . pk k , ¯ sk = sk 1 , . . . sk k , and (pk i , sk i ) is the output of G in its i th invocation.
On input m the output E ⊗k ¯ pk (m) is defined by We will use the direct product transformation only for encryptions of single bits.
In this case, it is convenient to express correctness and security in terms of the advantage over half.E ⊗k ¯ pk (m) = E pk 1 (m), . . . E pk k (m),Lemma 3.
Let (G, E, D) be any public-key encryption scheme over the message space {0, 1}, and let k : IN → IN be any polynomially bounded function.
If (G, E, D) is (1/2+α)-correct and (1/2+β)-OW, then (G ⊗k , E ⊗k , D ⊗k ) is (1/2 + kβ)-OW and for every > 0, it is (1 − )-correct as long as k > c · 1/α 2 · log 1// for some fixed constant c.Proof.
The one-wayness of (G ⊗k , E ⊗k , D ⊗k ) is obtained by a standard hybrid argument.
Correctness is also simple to show using Chernoff bound.
We note that we assume here that decryption errors occur with roughly the same probability for encryptions of zero and encryptions of one.
For example, it is sufficient to assume that both Pr [D sk (E pk (0)) = 0] > 1/2 + α/2 and Pr[D sk (E pk (1)) = 1] > 1/2 + α/2.
This is with no loss of generality as biases of D (towards outputting zero or towards one) can always be corrected.
The three basic transformations defined above can be combined in various ways to improve α-correct and β-OW encryption schemes.
The most efficient combination depends on the particular values of α and β.
We will not attempt to optimize the efficiency of our transformations but rather to demonstrate their effectiveness.
For that we consider two settings of the parameters: (1) β is an arbitrary constant smaller than one and α is also a constant smaller than one (that depends on β).
(2) α is as small as 1/poly and β is non-negligible (β = Ω(α 4 )).
Theorem 2.
For any constant β < 1 there exists a constant α < 1 such that if there exists an α-correct and β-OW public-key encryption scheme then there exists an almost-all-keys perfectlycorrect IND-CPA secure public-key encryption scheme.Proof.
Set α to be a constant such that e −(1−β) 2 /256 < α 8 and let (G 0 , E 0 , D 0 ) be an α-correct and β-OW public-key encryption scheme.
Define the following systems:-(G 1 , E 1 , D 1 ) = (G k 1 0 , E k 1 0 , D k 1 0 ) where k 1 = log α (1/n).
Lemma 1 implies that (G 1 , E 1 , D 1 ) is (1/n)-correct and O(1/n 8 )-OW.
-(G 2 , E 2 , D 2 ) = (G 1 , E 1 , D 1 ).
Lemma 2 implies that (G 2 , E 2 , D 2 ) is (1/2 + n/2)-correct and (1/2 + O(1/n 4 ))-OW.
-(G 3 , E 3 , D 3 ) = (G ⊗k 2 2 , E ⊗k 2 2 , D ⊗k 2 2 ) where k 2 = O(n 3 ), for which Lemma 3 implies that (G 3 , E 3 , D 3 ) is (1 − 2 −5n )-correct and (1/2 + O(1/n))-OW.
-(G 4 , E 4 , D 4 ) = (G n 3 , E n 3 , D n 0 ).
Lemma 1 implies that (G 1 , E 1 , D 1 ) is (1 − 2 −5n ) n -correct, which means that it is also (1 − n · 2 −5n )-correct.
In addition it is (1/p)-OW for any polynomial p. Thus it is also neg-OW.
-(G 5 , E 5 , D 5 ) = (G 4 , E 4 , D 4 ).
Lemma 2 implies that (G 5 , E 5 , D 5 ) is (1 − (n/2) · 2 −5n )-correct and IND-CPA secure.Theorem 2 now follows as a corollary of Theorem 1.
Theorem 3.
There exists some positive constant c such that for any functions α > 1/poly and β < α 4 /c the following holds: If there exists an α-correct and β-OW public-key encryption scheme then there exists an almost-all-keys perfectly-correct IND-CPA secure public-key encryption scheme.Proof.
Let (G 0 , E 0 , D 0 ) be an α-correct and β-OW public-key encryption scheme.
The conditions of the theorem imply that it is also (α 4 /c)-OW.Define (G 1 , E 1 , D 1 ) = (G 0 , E 0 , D 0 ).
Lemma 2 implies that (G 1 , E 1 , D 1 ) is (1/2 + α/2)-correct and (1/2 + O(α 2 / √ c))-OW.
Define (G 2 , E 2 , D 2 ) = (G ⊗k 1 , E ⊗k 1 , D ⊗k 1 ).
For any constant > 0 we can let k = O(1/α 2 ) (with the constant hidden in the big O notation depending on ), such that Lemma 3 will imply that(G 2 , E 2 , D 2 ) is (1 − )-correct and (1/2 + O(1/ √ c))-OW.Setting c to be a large enough constant implies that (G 2 , E 2 , D 2 ) is (3/4)-OW.
In other words, for any constant > 0, if c is a large enough constant, there exists a (1 − )-correct and (3/4)-OW encryption scheme.
Theorem 3 now follows as a corollary of Theorem 2.
As discussed in the introduction, one of the main motivations in dealing with decryption errors is obtaining non-malleability and chosen ciphertext security.
As with Corollary 1 we now get from Theorem 3 the following corollary.Corollary 2 There exists some positive constant c such that for any functions α > 1/poly and β < α 4 /c the following holds: If there exists an α-correct and β-OW public-key encryption scheme and NIZK proof system for NP exist, then then there exists an almost-all-keys perfectly-correct NM-CCA-post secure public-key encryption scheme.
In this section we provide an integrated construction for transforming error-prone public-key encryption schemes with some negligible probability of error that are not necessarily secure against chosen ciphertext attacks into schemes that enjoy non-malleability against a chosen ciphertext attack of the post-processing kind.
The advantage over the construction of Section 3 is that it works for any negligible probability of error (no need to first decrease the error probability to 2 −Ω(n) where n is the message length).
Let (G, E, D) be a public-key encryption scheme that for public key pk maps a message m ∈ {0, 1} n and random coins string r ∈ {0, 1} into a ciphertext c = E pk (m, r) (since we may start with a scheme that is not necessarily semantically secure, we consider also the case of deterministic encryption, so may be 0).
The decryption algorithm D is given ciphertext c as well as the secret key sk and attempts to retrieve m.
We assume without loss of generality that D is deterministic 5 .
The output of D is either a message m (which may fail to equal m) or ⊥ to indicate invalid (we are deliberately not attaching semantics to a response of "invalid").
The properties that we assume E satisfies are:α correctness and few bad pairs For a random message m and random r we havePr[D sk (E pk (m, r)) = m] ≤ 1 − α(n)where 1 − α(n) is negligible.
The probability is over the choice of m, r.
We call a pair (m, r) where D sk (E pk (m, r)) = m a bad pair.
The set of bad pairs is sparse in {0, 1} n+ One-wayness For any polynomial time adversary A and for c = E pk (m, r) for random m and r we have Pr m,r [A(c, pk) = m] is negligible.
In other words, E satisfies the one-way requirement.In addition to the public-key cryptosystem E satisfing the above conditions, we require (i) a shared-key encryption scheme F S which is NM-CCA-post secure.
The keys S are of length k bits.
Note that such schemes are easy to construct from pseudo-random functions (see [12]); and (ii) Four functions H 1 : {0, 1} n/2 → {0, 1} n/2 , H 2 : {0, 1} n/2 → {0, 1} n/2 , H 3 : {0, 1} n/2 → {0, 1} and H 4 : {0, 1} n/2 → {0, 1} k which will be modelled as ideal random functions.
We assume that n is sufficiently large so that 2 n/2 is infeasible.Construction 2 Let (G, E, D) be a public-key encryption scheme, H 1 , H 2 , H 3 , H 4 be idealized random functions as above and F S be shared-key encryption scheme as above.Generation G operates the same as G and generates a public key pk and secret key sk.
Encryption E : Choose t ∈ R {0, 1} n/2 .
Compute z = H 1 (t) and w = H 2 (z) ⊕ t and r = H 3 (z • w).
The encrypted message is composed of two parts (c 1 , c 2 ): -The generated c 1 = E pk (z • w, r) -The plaintext m itself is encrypted with the shared-key encryption scheme F s with key s = H 4 (t), i.e. c 2 = F s (m).
Decryption D : Given ciphertext (c 1 , c 2 ):1.
Apply D to c 1 and obtain candidates for z and w. Set t = H 2 (z) ⊕ w and r = H 3 (z • w).2.
Check that H 1 (t) = z and that for r = H 3 (z • w) we have that c 1 = E(z • w, r).3.
Check, using s = H 4 (t), that c 2 is a valid ciphertext under F s .
4.
If any of the tests fails, output invalid (⊥).
Otherwise, output the decryption of c 2 using s.Note that once t ∈ {0, 1} n/2 has been chosen, there is unique ciphertext (c 1 , c 2 ) generated from t and encrypting m, which we denote E pk (m, t).
Furthermore, for any ciphertext, once the corresponding t ∈ {0, 1} n/2 is known, it is easy to decrypt the ciphertext without access to sk.
This is the key for obtaining security against chosen ciphertext attacks (since it is possible to follow the adversary calls to H 1 ).
Why does this process immunize against decryption errors?
The point is not that the decryption errors have disappeared, but that it is hard to find them.
We can partition all strings (of length equal to |E pk (z • w, r)|) into those that are in the range of E (i.e., such that there exist m and r such that the string is equal to E pk (m, r)) and those that are not.
Consider a candidate ciphertext (c 1 , c 2 ) that is given to the decryption procedure D .
If the prefix of the ciphertext (i.e. c 1 ) is not in the range of E, then it is going to be rejected by D (at Step 2).
So the security rests on the hardness of finding among the bad pairs (z • w, r) one where r = H 3 (z • w) and H 1 (H 2 (z) ⊕ w) = z.
This is difficult for any fixed (but sparse) set of bad pairs and a random set of functions H 1 , H 2 , and H 3 even for an all powerful adversary who is simply restricted in the number of calls to H 1 , H 2 , and H 3 .
In particular, as we will explain, if there are q 1 calls to H 1 and q 2 calls to H 2 then the probability that the adversary finds a bad pair that passes the test is bounded by q 1 (1 − α) + q 1 q 2 /2 n/2 .
The first term comes from the "natural" method for constructing a pair that satisfies the constraints: Choose an arbitrary y. Apply H 1 to y and call the result z, so that z = H 1 (y).
Define w = H 2 (z)⊕y.
Then r = H 3 (z • w), and we have the pair (z • w, r) satisfying the necessary constraints.
Note that the pair is completely determined by y, once the random oracles are fixed, and the pair is random, because the oracles are random.
So for any method of chosing y the probability of hitting a bad pair is (1 − α).
This gives us the first term.
For the second term, suppose during its history the adversary invokes H 2 a total of q 2 times, say, on inputs x 1 , x 2 , . . . , x q 2 .
Let y be arbitrary.
Define w i = y ⊕ H 2 (x i ), for i = 1, . . . , q 2 .
We now check to see if H 1 (y) ∈ {x 1 , . . . , x q 2 }.
Suppose indeed that H 1 (y) = x i (an event that occurs with probability at most q 2 /2 n/2 ).
Let z = x i .
Then we have that z = H 1 (y) = H 1 (w i ⊕ H 2 (x i )) = H 1 (w i ⊕ H 2 (z)).
We let r = H 3 (z ⊕ w i ) and again we have a pair satisfying the constraints.
The total number of pairs we can hope to generate this way is q 1 q 2 /2 n/2 .
Why does this process protect against chosen ciphertext attacks?
This is very much for the same reason that the Fujisaki-Okamoto [15] scheme is secure.
Note that hardness of finding a bad pair is true also for someone knowing the private key sk of E, that is even the creator of the cryptosystem cannot find a bad pair.
Therefore, even under a chosen ciphertext attack w.h.p. a bad pair will not be found.
So w.h.p. on all queries given during the attack there is only one response.
Furthermore, this response can be given by someone who is aware of the attacker's calls to H 1 (by going over all candidates for t).
The addition of the function H 4 and the shared key scheme F S transforms the system from a one-way scheme into one that is non-malleably secure against chosen ciphertext attacks.
From these sketched arguments we get: We have shown how to eliminate decryption errors in encryption schemes (and even handle nonnegligible success probability of the adversary).
It is interesting to note that sometimes such ambiguity is actually desirable.
This is the case with deniable encryption [8], where the goal is, in order to protect the privacy of the conversation, to allow a sender to claim that the plaintext corresponding to a given ciphertext is different than the one actually sent.As discussed in Section 4, an interesting open problem is to give a transformation that deals with α-correct and β-OW encryption schemes when the gap between α and β is very small.
For example, we may hope to have β − α be an arbitrary constant or even 1/poly.
Nevertheless, as discussed there, having such a strong transformation may involve improving the corresponding transformation in the related information-theoretic setting of [38].
We thank Eran Tromer for initially pointing us to Proos's work, Shafi Goldwasser for raising our interest in the problem and Russell Impagliazzo, Adam Smith and Salil Vadhan for conversations concerning amplification.
We thank the anonymous referees for helpful comments.
