Recent studies have indicated the significance of supporting real-time group editing in "Wiki" applications, whose collaboration environments have their dynamic and large-scale nature.
Correct capture of causal relationships between operations from different users is crucial in order to preserve consistency of object copies.
This challenge was resolved by employing vector logical clock.
But since its size is equal to the number of cooperating sites, it has low efficiency when dealing with a collaborative environment involving a large number of participants.
In this paper, we propose a direct causal vector (DCV) approach for solving causality detection issues in real-time group editors.
DCV timestamp does not record the causality information that can be deduced from the transitivity of causal relation.
As a result, it can automatically reduce its own size when people leave the collaboration session and always keep small.
We prove that DCV approach is well fit for capturing causality in wiki like large-scale dynamic collaboration environments.
Real-time group editors enable a group of users to view and edit the same document (e.g., text, graphic and multimedia document) simultaneously from geographically dispersed sites connected by communication networks such as the Internet [2,7].
This category of groupwares have some unique characteristics which make them distinct from other kinds of collaborative work [2,4,7,8,22]: 1.
real-time: the response to local user actions must be quick and the latency for reflecting remote user actions must be low; 2.
unconstrained: cooperating users are able to freely edit any part of the document at any time, synchronously or not.
3.
distributed: cooperating users may operate different machines connected by different communication networks with nondeterministic latency.A replicated approach has been proposed to meet the requirements for good responsiveness and unconstrained collaboration.
Documents are replicated at each cooperating site, and user operations are first executed on their local replicas immediately, and then propagated to all other cooperating sites for group awareness.
To ensure that the document replicas at each cooperating sites can always exactly reflect the initial intentions of each cooperating users, and can eventually arrive at the same consistent status at the end of collaborative session, whenever to synchronize a remote operation, it must take into account the impact of all the concurrent operations executed previously.
Thus, precise capture of causality is crucial in real-time group editors [2,7,8].
Vector logical clock is currently the most widely used causality detection technique [2,7,9,17,18,19].
However, it has only been proved to work well in small collaboration environment (less than ten participants).
Our recent studies have indicated the significance of supporting real-time group editing in "Wiki" applications, whose collaboration environments have their dynamic and large-scale nature.
Vector logical clock is not fit for such collaboration environments.
Is there any other causality detection solution?
This is the focus of this paper.
The Internet has fostered an unconventional and powerful style of collaboration: "wiki" web sites.
A wiki is such a website -every visitor is allowed and able to add new pages to it, remove existing pages, or otherwise edit and change the content of existing pages, using just web browsers [25].
By working on the same wiki website, geographically dispersed users can easily collaborate and share knowledge with each other.
Wiki web sites, as a novel and convenient collaboration medium, is becoming more and more popular, which could be evidenced by an increasing number of wiki applications, such as Wikipedia [26], WikiNews [24], WikiTravel [28] and StrategyWiki [23].
Existing wikis only support asynchronous collaboration.
People collaborate with each other in a Copy-Modify-Merge manner: each wikipedian checks out a separate working copy of wiki pages from the the wiki server; then modifies her/his working copy independently; and finally merges her/his working copy with those from other wikipedians [23,24,26,28].
Our recent study means to, by adapting existing single-user wiki page editors to full-featured real-time group editors, support wiki users synchronous collaboration.Supporting both synchronous and asynchronous collaboration allows more flexible collaboration among users.
Wiki users can collaborate with each other more closely and more effectively.
Consider the following scenario: a wiki user, named Bob, poor at language expression, just drafts his ideas on the wiki page; at the same time another wiki user help to revise his expression; if there is misunderstanding, Bob will immediately notice and correct it.
It could save Bob a lot of time without carefully choosing and organizing his words.Another notable benefit is that it could help to eliminate editing conflicts.
In existing wikis, we have more than once experienced that we made a large number of changes to a paragraph of text, only to have them all silently discarded when someone else, editing the same paragraph at the same time, saved their modifications after me.
Although this does not happen very often, they are really frustrating.
As has been mentioned before, wiki systems are gaining more and more populations.
As the wiki systems grow, so do the opportunities for conflict.
How to help reducing the coordination costs?
It has become a problem faced by many wiki designers and researchers [1].
An unique feature of real-time group editors is real-time workspace awareness.
It could help people detect editing conflicts as early as possible.
Historical studies have indicated that when concurrently working on the same object, if people are able to see others in real time, it is less likely that their actions seriously conflict with each other [3].
The collaborative environments in wikis are typically largescale and dynamic collaboration environments.
In wiki applications, each wiki page represents a collaboration session.
People viewing or editing one wiki page all are participants of corresponding wiki collaboration session.
The number of participants of a wiki collaboration session could be very large (i.e. hundreds, thousands or more).
Take Wikipedia as an example.
Many of its wiki pages have over thousands of hundreds of visitors a day [27].
Another feature of wiki collaboration environments is dynamic.
In wiki applications like Wikipedia, every minute there are hundreds of users join and leave [27].
People usually leave a wiki collaboration session (wiki page) by simply closing the web browser or navigating to another web page.
There is not any notification.
Most existing real-time group editors employ vector logical clock to help detect causality [2,7,9,17,18,19].
In these implementations, a fixed sized state vector is attached to each operation o, named vector logical clock timestamp, in which each item corresponds to a collaboration participant, and records the number of operations generated by that participant that are causally preceding o. By comparing their vector logical clock timestamps, causal relationship between any two operations can be easily determined.This approach works well when the collaboration group is small.
However, the size of vector logical clock linearly depends on the number of participants.
If there are hundreds, thousands or even more participants, problem occurs.
The timestamp attached to each operation will become huge in size, even much larger than the operation itself, which could add an intolerable cost to network transmission, local storage as well as causality detection complexity, and as a result, seriously affect the performance of the groupware system.
Moreover, many large-scale collaboration environments (i.e. Wikipedia) are open.
They tend to have a nondeterministic number of participants.
In such collaboration environments, it is not practical to timestamp operations with a fixed size state vectors.Some previous work tries to solve this problem by [11]: 1.
redesigning the vector logical clock, using associative vectors indexed by participant identifier, thus allowing the system to dynamically add new timestamp items or discard old timestamp items during the collaboration session; and 2.
allocating timestamp items dynamically at run-time, creating vector items just for those participants who have written, instead of pre-allocating a timestamp item for all the potential participants; and 3.
if some participants midway leave the collaboration session, watching their corresponding timestamp items and removing them once they have become insignificant.In these above approaches, since timestamp items are not pre-allocated at the beginning of the collaboration session, opening large-scale collaboration environments should no longer be a problem.
Furthermore, if the collaboration environment is not active, most participants just read instead of writing, the vector logical clock timestamp of each operation will never grow too large.
It seems that these approaches can help to significantly ease the problems about vector logical clock in large-scale collaboration environments.
Nevertheless, the trouble is that, firstly, it is difficult to determine whether a participant has really left the collaboration session or not in a large-scale collaboration environment.
We still take wiki as an example.
As mentioned before, people in wiki collaboration sessions often leave by simply closing the browser window or navigating to another page, without sending any notification to wiki server.
Thus, we can by not direct means determine whether a participant has left the collaboration session or not.
It is also not safe to assume that any participants who are not active for a predetermined time has already left the collaboration session.
People collaborate with each other over Internet.
The network is unstable.
Sometimes we do not receive any message from a participant for a long time, just because the network connection between he/she and other participants is temporary failed.
Even if we can make sure that a particular participant has left the collaboration session already, it is not always safe to remove her/his corresponding timestamp item.
A timestamp item could be safely reclaimed only after the operations that were generated by the corresponding participant have all been synchronized at all the cooperating sites.
In an unreliable and highly dynamic collaboration environment like wiki, it is usually difficult to determine the exact list of participants that are currently present in the collaboration session and thus is also difficult to determine whether a timestamp item has become insignificant or not.In the past decade, there have been several different techniques about vector logical clock compression [6,11,14,16,20,21].
But as to our knowledge, none of them can really solve all its efficiency issues in large-scale collaboration environments, without imposing any assumption on network reliability and negatively affecting the users' normal collaboration work.Noticing the limitation of vector logical clock, some existing real-time group editing systems design their own causality detection solutions [10,13,19].
Their main ideas are quite similar.
In these systems, before propagating an local operation, cooperating sites pre-transform it against some concurrent operations generated from other cooperating sites to make them appear as sequential operations.
By carefully designing the transforming and propagating rules, causality detecting issues in these systems are greatly simplified, and thus bring the possibility for much simpler causality detection solutions.
The common drawback of such approaches is that, during the pre-transforming, intention conflict among different participants may be improperly hidden, which may incurs much intolerable confusion.
Furthermore, as to our knowledge, existing systems of this category either suffer from single-point failure, or require extremely reliable and stable collaboration network.
None of them is well fit for wiki like wide-area collaboration environments.
In this paper, we develop a new causality detecting approach, named Direct Causal Vector (DCV).
This is a well scalable approach, which works well in many large-scale dynamic collaboration environments, including most existing wiki environments.The rest of this paper is organized as follows: Section 2 introduces some background concepts and makes clear the causality detection issues needed to be solved in realtime group editor systems.
Section 3 introduces the concept of direct causal vector, which is our new timestamp design.
Section 4 proposes a solution to all the issues proposed in section 2, based on our new timestamp design.
Section 5 makes some discussion on our new approach and section 6 compares it with related works.
Section 7 summarizes the contributions of this paper.
In this section, we will introduce some background concepts and articulate the causality detection issues needed to be solved in realtime group editor systems.
Following Lamport [15], in this paper, we define a causal ordering relation on operations in terms of their generation and execution sequences.
As illustrated in Figure 1.
o11, o21 and o31 are concurrent with each other.
o12 is causally dependent on three operations o11, o21 and o31.
o22 is causally dependent on four operations o11, o21, o31 and o12.
o32 is only causally dependent on o31 To achieve high responsiveness and high concurrency, a replicated architecture has been introduced and widely applied in current realtime group editor systems.
In this architecture, a document replica is maintained at each cooperating site.
Collaborators are allow to modify their own document replicas at any time.
After their local executions, operations are broadcasted to all the collaborators for synchronization.
For high usability, it is required that a realtime group editor with replicated architecture always satisfy the following properties[2, 5, 7]:1.
Convergence: When the same set of operations have been executed at all sites, all copies of the shared document are identical.
Thus, the following causality detection issues surface.Problem 1.
Given an unexecuted remote operation, how to determine whether all the operations causally preceding it have already been executed?To achieve causality preservation, we must ensure that an operation is not executed on a remote site until all the operations on which it causally depends have already been executed.
However, due to the nondeterministic communication latency, remote operations may arrive out of their natural causal order.
Thus, we must check its causality condition every time before executing a remote operation.Problem 2.
Given an unexecuted remote operation that is causally ready, how to separate all the history operations that are concurrent to it from the operation history?An operation history is a set of history operations that satisfies (1) it contains all the history operations that have the possibility of being concurrent with the future incoming remote operations and (2) if it contains an operation, all the history operations causally depend on this operation are also included.
In real-time group editor systems, an operation history could be found maintained at each cooperating site [2,7,9,17,18,19].
To achieve intention preservation, whenever executing a remote operation, the impact of concurrent operations in the operation history must all be taken into account.Problem 3.
How to determine the causal relationship between two arbitrary operations in the operation history?It is not a trivial matter to find the real intention of a remote operation.
It is also required by some concurrent control algorithms that causal relationship between two history operations be determined correctly and efficiently [2,8,18].
Causal relation is transitive, that is, if oa → o b and o b → oc, then oa → oc.
Some causal relationships can be deduced from other causal relationships by transitivity, while others can not.
By differentiating these two kinds of causal relationships, we come up with the concept of direct causal relation.
Direct causal relation represents those causal relationships that can not be deduced from other causal relationships by transitivity.
The concept of direct causal relation just excludes those causal relationships that could be deduced from other causal relationships by transitivity, thus there exists the following theorem.
in it, then oa → o b , iff (1) oa ⇒ o b , or (2) there exists a operation sequence o1, o2, ..., on in S, such that (oa ⇒ o1) ∧ (o1 ⇒ o2) ∧ ... ∧ (on−1 ⇒ on) ∧ (on ⇒ o b ).
Definition 4.
[Direct causal vector(DCV)] Given an operation o, suppose there exist only k operations that are causally preceding it directly, enumerated as o1, o2, ..., o k .
Here, o1 is the n1th operation generated at cooperating site s1; o2 is the n2th operation generated at cooperating site s2; ...; o k is the n k th operation generated at cooperating site s k .
The direct causal vector of o, denoted as DCV (o), is defined asDCV (o) = [(s1, n1), ..., (s k , n k )].
Notice that each item in the direct causal vector DCV (o) represents an operation that is causally preceding o directly.
Each operation that is causally preceding o directly must have a corresponding item in the direct causal vector DCV (o).
It must hold that ox ⇒ o iff ox ∈ DCV (o).
Thus, to determine the direct causal relationship between o1 and o2, we just need to check whether o1 exists in DCV (o2) and whether o2 exists in DCV (o1).
To illustrate the concepts of direct causal relation and direct causal vector, refer to the scenario in Figure 1 again, o11, o21 and o31 have no operation causally preceding them directly; o12 causally depends on o11, o21 and o31 directly; o22 causally depends on o12 directly.
o32 causally depends on o31 directly.
The direct causal vector of o11, o21, o31, o12, o22 and o32is [ ], [ ], [ ], [(1, 1), (2, 1), (3, 1)], [(1, 2)] and [(1, 3)] respectively.Following are some interesting properties of direct causal relationship, related with causality detection in real-time group editor systems.
To prove this property, consider an arbitrary operation ot that is causally preceding o but not directly.
According to theorem 1, there must exist another operation ox satisfying (ot → ox) ∧ (ox ⇒ o).
According to the assumption, ox has already been executed, and it was executed after it had become causally ready.
Thus ot must have been executed too.This property indicates that to decide whether an unexecuted remote operation is causally ready, we just need to check the operations causally preceding it directly.
Notice that HB ∪ o is an uninterrupted operation set, so this property can be deduced directly from the theorem 1.
These two properties indicate that, it is possible to solve the three causality detection issues in real-time group editors just through the direct causal vector timestamp of each operations.
In this section, we will look into the causal detection issues mentioned in section 2 and give a direct causal vector timestamp based solution for each of these issues.
As has been pointed out in the previous section, to solve the first causality detection issue, that is, to decide whether an unexecuted remote operation is causally ready, we only need to check whether all the operations causally preceding it directly have already been executed.As is done in many previous works, we use state vector.
Each site s maintains a state vector SVs.
For each site t in the collaboration session, there is a corresponding component in SVs, denoted as SVs [t], which holds a value corresponding to the number of operations that were generated at site t and have already been synchronized on site s.
A remote operation or received on site s is thought to be causally ready, if and only if it holds for each item (si, ni) in DCV (or) that SVs[si] ≥ ni.For illustration, refer to the scenario in Figure 1 again.
At the time when o12, whose direct causal vector timestamp is [(1, 1), (2, 2), (3, 3)], is received at site 2, only two operations, named o21 and o31, have been executed at site 2, that is, the state vector of site 2 is{SV2[1] = 0; SV2[2] = 1; SV2[3] = 1}.
It is not satisfied that SV2[1] ≥ 1, so o12is not causally ready and its synchronization must be delayed.
The synchronization of o12 is delayed until o11 has been received and synchronized at site 2.
At that time, the state vector at site 2 has changed to{SV2[1] = 1; SV2[2] = 1; SV2[3] = 1}.
It satisfies that for each item (si, ni) in DCV (o12), SV2[si]≥ ni.
Thus, we could make sure that o12 has become causally ready for synchronization.
In this subsection, we will focus on the second causality detection issue, that is, given an unexecuted remote operation or that is causally ready, separating from the operation history all the operations that are concurrent with it.Our basic idea is to check the history operations (the operations in operation history) in the reverse order of their causal order.
And we do not check a history operation until all the history operations that are causally dependent on it have been proved to be concurrent with or.Not all the history operations will be checked during the process.
But if a history operation is ignored, there must exist at least one of its direct causal successor in the operation history that could be proved to be causally preceding or.
Such operation can not be concurrent with ro, thus ensuring the correctness of our approach.Concerning a history operation o h , whose direct causal successors have all been proved to be concurrent with or.
Due to Theorem 1, it must hold that o h is either concurrent with or or directly causally preceding or.
Thus, to decide whether o h and or are concurrent with each other, we just need to check their direct causal relationship.
As has been pointed out in the previous section, the direct causal relationship between o h and or can be determined directly by checking the direct causal vector timestamp of or, thus ensuring the efficiency of our approach.We propose two data structures to facilitate the concurrent separating process: direct causal history and direct causal graph.Direct causal history (DCH) is a subset of operation history.
It contains those operations that have no causal successor in the operation history.Direct causal graph (DCG) is a graph of history operation.
For each operation in the operation history, there is a corresponding node in the direct causal graph.
Given two history operations oa and o b , there is a link from oa to o b in the direct causal graph iff o b → oa.
In the following discussion, LT (o) will be used to denote the set of history operations that an operation o links to in the direct causal graph, and LF (o) will be used to denote the number of history operations that have a link to an operation o in the direct causal graph.
To illustrate, consider the scenario in Figure 1.
At site 3, after the execution of o22, there should be six operations in its operation history: o11, o21, o31, o12, o22 and o32.
The corresponding status of DCH and DCG is displayed in Figure 2.
None of the operations o11, o21, o31, o12 and o22 is causally dependent on o32.
Thus, o32 ∈ DCH.
Similarly, o22 ∈ DCH.
Other history operations all have at least one causal successor in the operation history, o11 as an example, the operation o12 contained in the operation history is one of its causal successors, so none of them belongs to DCH.In DCG, there are six operation nodes, corresponding to the six operations in the operation history.
There are five directed edges in the graph, each corresponding to a direct causal relationship over the six history operations, i.e. there is a link from o32 to o31 in the graph because o31 ⇒ o32, there is a link from o22 to o12 in the graph because o12 ⇒ o22, etc.
Furthermore, according to the graph, we have LF (o32) = LF (o22) = 0, LF (o12) = LF (o11) = LF (o21) = 1 andLF (o31) = 2.
Following is the detail algorithm.The Concurrent Separation procedure 1 takes a causally ready unexecuted operation or as input and returns an operation set set c or that contains all the history operations that are concurrent with or.The operation set candidates is used to, during the procedure, temporarily keep the newly found history operations that are proved to have no direct causal successors in the operation history causally preceding or.
It is initialized with DCH (line 2), because (1) none of the operations in DCH have causal successors in the operation history, let alone having any causal successors in the operation history causally preceding or, and (2) the operations in DCH are the only history operations that could be proved to have no direct causal successors in the operation history causally preceding or, at the beginning of the procedure.
Based on the above analysis, to select out all the history operations concurrent with or, we begin by checking these operations.
The map structure map is used to record the number of history operations causally dependent on it directly which have been proved to be concurrent with or for each history operation.
The Concurrent Separation procedure simply repeats the checking process from line 7 to line 28 until all the concurrent history operations have been found.
In each round of checking, the Concurrent Separation procedure check whether it is causally dependent on or directly for each history operation in candidates.
If not, according to the above analysis, the history operation currently checked must be concurrent with or, so we add it into set c or (line 16), and update map for each of the history operations it causally depends on directly (line 17-26).
At the same time, we check whether some more operations could be proved to have no direct causal successors in the operation history causally preceding or.
If so, we will add such operations into candidates and prepare them for a next round of checking (line 23-25).
According to the definition of map, it is easy to see that if map[o] = LF (o), it must hold that all the history operations which causally depends on o directly have been proved to be concurrent with o.During the execution, the procedure also finish the adjustment of data structures DCH and DCG.
Initially, a new node is created in DCG and DCH for or (line 4-5).
For each operation causally preceding or directly, the procedure ensures its removement from DCH and adding to DCG a link from or to it (line 11-14).
Notice that if a history operation is causally preceding the causally ready unexecuted or directly, it must have no direct causal successor in the operation history causally preceding or.
All such operations are checked and handled during the execution of Concurrent Separation, and thus ensures the integrity of such adjustment.To illustrate the Concurrent Separation procedure, still consider the scenario in Figure 1.
Suppose a new remote operation o41, whose direct causal vector is [ (1, 1), (3, 2)], is received at site 3 shortly after the execution of o22 on that site.
Obviously, o41 is causally ready.At the beginning of Concurrent Separation(o41), the operation set candidates is initialized with the two history operations in DCH o32 and o22.In the first round of checking.
o22 is proved to be concurrent with o41.
It is put into set c o 22 .
At the same time, the value of map[o12] is adjusted to 1.
Noticing that the value of map[o12] becomes equal to LF (o12), so o12 is pushed into the operation set candidates.
o32 is proved to be causally preceding o41.
It is removed from DCH and a link is added into DCG from o41 to o32.
During the first round of checking, only one more history operations o12 is proved to have no direct causal successor in the operation history causally preceding o41, so at the end of this round of checking, the status of candidates becomes {o12}.
In the second round of checking, o12 is proved to be concurrent with o41.
The status of variable map is updated to{map[o12] = 1; map[o31] = 1; map[o11] = 1; map[o21] = 1}.
LF (o11) = 1 and LF (o21) = 1.
Two more operations o11 and o21 are proved to have no direct causal successor in the operation history causally preceding o41.
They are added into the operation set candidates.
At the end of the second round of checking, the status of candidates is {o11, o21}.
In the third round, o11 is proved to be causally preceding o41 directly, and o21 is proved to be concurrent with o41.
A link from o41 to o11 is added into DCG.
No more history operation is found that could be added into candidates.
Thus the status of candidate becomes empty at the end of the third round of checking.The execution of Concurrent Separation(o41) is completed.
set c o 41 = {o22, o12, o21} is returned as the result.
As a sideeffect of Concurrent Separation(o41), the status of DCH and DCG is adjusted as illustrated in Figure 3.
By and large, we have described our concurrent separation algorithm in full detail.
Notice that whenever a new local operation is generated, the operations in DCH exactly contains the operations it causally depends on directly.
Thus, we can build direct casual vector based timestamp for a newly generated local operation directly from the content of DCH.
Furthermore, after each execution of a local operation o l , the data structures DCH and DCG must be immediately adjusted.
A new node should be added into DCG corresponding to operation o l .
A link from o l to each operations currently in DCH operation set should be added into DCG.
And finally the status of DCH operation set should be adjusted to {o l }.
In this subsection, we will focus on the third causality detection issue: determining the causal relationship between two arbitrary operations in the operation history.
An operation history is an uninterrupted operation set.
According to Theorem 1, the causal relationship between two arbitrary operations in the operation history can be determined exactly by tracing its direct causal relationships.
However, it has low efficiency.
In worst case, it should traverse all the history operations in operation history.Our solution is based on the following observations.
Every time before executing a remote operation or, all the earlier executed operations that are concurrent with it are separated out in set c or in advance (refer to chapter 4.2).
If this result is cached, things will become much easier: given two operations oa and o b in the operation history, suppose oa was executed earlier than o b , to determine their causal relationship, we just need to check whether oa belongs to set .
Otherwise, it must be causally preceding o b .
The number of operations that an operation is concurrent with could be very large.
Accordingly, the size of set c could also be very large.
Fortunately, we do not need to keep in cache for each history operation a full version of set c .
Given an arbitrary history operation o, suppose oa and o b are two operations in set c o , and suppose oa and o b are generated at the same site, oa is generated earlier than o b .
Consider what happens if we remove o b from set c before putting it in cache.
if cache c or [SIT E(o h )] is undef ined then 4: cache c or [SIT E(o h )] ⇐ GEN SEQ(o h ) 5: end if 6: if cache c or [SIT E(o h )] > GEN SEQ(o h ) then 7: cache c or [SIT E(o h )] ⇐ GEN SEQ(o h ) 8:end if 9: end for 10: return cache c or After procedure Concurrent Separation has been successfully executed, its result set c will be passed along to procedure Build Cache.
The procedure Build Cache will remove redundancy from set c and return a condensed version of it cache c for cache use.
cache c is an associative vector indexed by cooperating site identifier.
Build Cache will create an item in cache c for a cooperating site s (an item with site s's identifier as the key) when it find in set c an operation that was generated at s (line 3-5).
Given a cooperating site s, cache c [s] records the generation sequence number of the earliest generated one of the operations in set c that are generated at s (line 6-8).
1: if E SEQ(ox) < E SEQ(oy) then 2: if oy is local operation then 3:return ox → oy 4:else 5:if cache c oy [SIT E(ox) To determine the causal relationship between two history operations ox and oy, in procedure Detect Causality, we first determine the synchronization order of these two operations (line 1).
If ox is synchronized before oy, as an example, there must be ox 񮽙 oy or ox → oy.
If oy is a local operation, it is out of question that ox must be causally preceding oy (line 2-3).
Otherwise, we check oy's related causality cache data cache c oy to see whether there is some operation that is generated at the same site of ox earlier than ox and is concurrent with oy (line 5).
If there is, it must hold that ox 񮽙 oy (line 8), otherwise, ox → oy (line 6).
As an illustration, still consider the scenario in Figure 1.
Continue with previous analysis: suppose a new remote operation o41, whose direct causal vector is [(1, 1), (3, 2)], is received at site 3 shortly after the execution of o22 on that site.Before o41's execution, procedure Concurrent Separation is first invoked to select all the history operations that are concurrent with o41 from operation history.
In the previous subsection, we have analyzed the execution process of Concurrent Separation(o41 ) and concluded that three operations o22, o12 and o21 will be returned as the result.
Later, the result operation set is passed to procedure Build Cache.
Build Cache scans the three operations o22, o12 and o21 in order.
cache c o 41 is put into the causality cache after it is computed.
Later if it is needed at site 3 to compute the causal relationship between o41 and one of the operations o11, o12, o21, o22, o31 and o32, which are all operations executed prior to o41 at site 3, the cached value cache c o 41 can be used.
Consider the causality detection between o41 and o31.
Because cache c o 41 [s3] = 0, according to the previous analysis, we can ascertain that o31 → o41.
Again consider the causality detection between o41 and o22.
Because the value of cache c o 41 [s2] is 1, which is smaller than the generation sequence number of o22 at site 2, we can safely deduce that o22 || o41.
It is easy to see that, with causality cache, the causal relationship between two arbitrary history operations in operation history can always be determined within a constant time.
In this section, we will analyze some important features of our approach.
We will prove that our approach can be well adapted to wiki like large-scale dynamic collaboration environments.We first consider the timestamp size.
Direct causal vector timestamp is a kind of dynamically sized timestamp.
It is not pre-allocated for each potential participants an item in the direct causal vector timestamp, so collaboration participants will not contribute to the size of direct causal vector timestamps until she/he begins editing the shared object.
Thus, in our approach, it should work well in large-scale open collaboration environments.A most critical feature of our approach is that, after a participant stops editing the shared object, she/he will also automatically and gradually stop contributing to the size of direct causal vector timestamps.
Refer to Figure 4 as an illustration.
There are totally three cooperating site 1, 2 and 3.
After site 1 begins to edit the shared object, it begins to affect the cost of direct causal vector timestamp in the real-time group editor system.
o22 is an operation that is generated after site 1 has begun editing the shared object.
Its direct causal vector timestamp is [(1, 1), (2, 1)].
There is a timestamp item (1, 1) corresponding to site 1.
After site 1 has stopped editing for an enough long time, at T 2, when the operation o22, which is causally dependent on o11, has been propagated to and synchronized on all the cooperating sites, it can be proved that none of the operations generated afterwards have a timestamp item corresponding to site 1 in their direct causal vector timestamp.
This will hold until site 1 is again active editing the shared object.
It could be seen in Figure 4 that, in the direct causal vector timestamps of o23 and o32, which are operations generated at site 2 and site 3 respectively after time T 2, there is no timestamp item related with site 1.
It is not difficult to conclude that the size of the direct causal vector timestamp of an operation o approximates the number of participants active at editing the shared object recently before the generation of operation o.
Now we turn to the complexity of our algorithms.
Assume that the number of participants concurrently editing the shared object never exceed L.Our approach requires that four special data structures be kept at each cooperating site: DCH, DCG, LF mapping and causality cache.
The size of DCH is never larger than L; the storage complex of DCG is O(nL); the storage complexity of LF mapping is O(n); the storage complexity of causality cache is O(nL), where n represents the size of the operation history.
To sum up, the average storage cost of our approach (total storage cost/size of HB) is O(h).
Our algorithms can detect for a remote operation whether it has become causally ready in O(L) time.
The time complexity of algorithm Concurrent Separation is O(h + L 2 ), where h is the number of history operations concurrent with the input remote operation.
With the help of causality cache, algorithm Detect Causality can detect the causal relationship between two arbitrary history operation in O(1) time.It is obvious that the complexity of our approach is not correlative with the total number of collaboration participants.
Our approach can work well in collaboration environments of any scale, as long as the concurrency degree is not too high, which means that it never happens that a huge number of people edit the shared object concurrently at a same time.
As to our experience, in existing wikis, it rarely happens that more than ten people concurrently edit the same wiki page.
Take Wikipedia as an example.
According to the statistics from wikipedia web site [27], it seldom happens that a normal wikipedia page is edited more than ten times within less than an hour.
Thus, our approach should be able to work efficiently in wiki collaboration environments.We have notice that by carefully controlling the synchronize order of remote operations at each collaborating sites, the size of direct causal vector timestamp can be kept small even in a highly concurrent environment.
This indicates the possibility of adapting our current direct causal vector approach to collaboration environments with much higher concurrency.
Due to space limitation, we will not discuss it further.
It should be part of our future work.Notice that, unlike other solutions, as are discussed in the next section, our approach does not place any constraint on the network reliability, the network performance, the network topology or the mode in which people collaborating with each other.
Various methods have been proposed to compress the size of vector clocks.
On one extreme, methods have been proposed in [14,20] to reduce the timestamp data to a single integer, but this comes at the cost of an increased computational overhead for the calculation of the vector clocks assigned to events, which is so large that it will slow down the distributed computation in an unacceptable way.
Therefore, these methods are mainly applicable for a trace-based off-line analysis of the causality relation.Other methods have been proposed to dynamically compress the size of vector clock [11,16].
These method are all based on the following observation: even though the number of processes is large, only a few of them will interact with each other frequently by passing messages.
In SinghalKshemkalyani's technique [16], vector clock compression is achieved by carrying in each message only those entries of the vector clock that have been updated after the previous communication between any pair of process.
Ratner et al. [11] employs another method: for each entry of the vector clock, it tries to achieve consensus on a value to be subtracted and an entry will be removed once it is subtracted to 0.
The main problem with these methods is that the size of the message timestamps is still linear in N (the number of communicating processes) in the worst case, as long as the collaboration is active enough.
Furthermore, the SinghalKshemkalyani technique requires that communication channels be FIFO, while Ratner et al.'s method is only adapted to a well connected network.The method proposed in [21] requires that the communication links between processes be static and known ahead of time.
It is impossible in a large-scale collaborative environment.Sun and Cai proposed an OT based method [6].
It is enforced that every operation generated at a certain cooperating site should be sent to the central site, transformed there against all the previously arrived concurrent operations, even if there exist some conflicts, and propagated to other cooperating sites in its transformed form, rather than original form.
Thus, the method that can be applied to handle conflict operations is constrained.
The MVSD method proposed in [12] no longer applies.
This method also suffers from single-point failure.
Cooperating sites can not cooperate with each other if the central site is not accessible even if they themselves are well connected.
Moreover, with this method, it is difficult to provide good performance for all the cooperating sites.There also exist some OT algorithms that do not use the vector clock [10,13,19].
In NICE [13], a central site is employed to ensure that every operation propagated to a cooperating site i has been transformed against all the concurrent operations i received before.
It suffers from similar deficiencies as the method proposed by Sun and Cai[6].
Both SOCK4 [19] and TIBOT [10] use a scalar clock.
In SOCK4, every operation is assigned a continuous serial number that is obtained from a global sequencer.
It is required that a local operation should not be broadcast until all the operations with lower serial number have been transformed against it.
In TIBOT, every site maintains a linear logical clock.
All clocks are initialized to a common value and take the same sequence of values.
The period between two consecutive clock ticks is defined as a time interval.
It is required that a local operation should not be broadcast until all the operations generated in earlier time intervals have been transformed against it.
Due to these constrains, in both SOCK4 and TIBOT, collaboration will be suspended even if only one of the clients is disconnected.
Thus, neither of them can be used in large-scale collaborative environments based on Internet like unreliable network like wiki.
The collaboration mode is also constrained.
The collaboration provided by SOCK4 and TIBOT cannot be partial, that is either all sites collaborate or each one works separately.
In this paper we propose a new approach for capturing causality in real-time group editors.
Our approach is based on a new kind of logical clock called DCV.
Compared with other approach, it is easier to adapt to wiki like large-scale, highly dynamic, and unreliable collaboration environments.Our approach enables the support of real-time group editing in wiki like applications, which should be beneficial for such category of applications to better support users' collaboration activities.
Supporting large-scale collaborations over a wide-area network can help to gain more usage and visibility for Computer-supported Cooperative Work (CSCW).
Our approach currently do not support collaboration environments with high concurrency.
We have seen the possibility of adapting it to support such collaboration environments.
It should be one of our future work to delve into it in more detail.
There exist a lot of real-time group editor related technologies that could help people better collaborate with each other, such as telepointer, radar view and etc.
How to apply these technologies to wiki like applications?
What are the effects?
These should also be part of our future work.
