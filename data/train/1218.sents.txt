The rapid adoption of XML as the standard for data representation and exchange foreshadows a massive increase in the amounts of XML data collected , maintained, and queried over the Internet or in large corporate data-stores.
Inevitably, this will result in the development of on-line decision support systems, where users and analysts interactively explore large XML data sets through a declarative query interface (e.g., XQuery or XSLT).
Given the importance of remaining interactive, such on-line systems can employ approximate query answers as an effective mechanism for reducing response time and providing users with early feedback.
This approach has been successfully used in relational systems and it becomes even more compelling in the XML world, where the evaluation of complex queries over massive tree-structured data is inherently more expensive.
In this paper, we initiate a study of approximate query answering techniques for large XML databases.
Our approach is based on a novel, conceptually simple, yet very effective XML-summarization mechanism: TREESKETCH synopses.
We demonstrate that, unlike earlier techniques focusing solely on selectivity estimation, our TREESKETCH synopses are much more effective in capturing the complete tree structure of the underlying XML database.
We propose novel construction algorithms for building TREESKETCH summaries of limited size, and describe schemes for processing general XML twig queries over a concise TREESKETCH in order to produce very fast, approximate tree-structured query answers.
To quantify the quality of such approximate answers, we propose a novel, intuitive error metric that captures the quality of the approximation in terms of both the overall structure of the XML tree and the distribution of document edges.
Experimental results on real-life and synthetic data sets verify the effectiveness of our TREESKETCH synopses in producing fast, accurate approximate answers and demonstrate their benefits over previously proposed techniques that focus solely on selectivity estimation.
In particular, TREESKETCHes yield faster, more accurate approximate answers and selectivity estimates, and are more efficient to construct.
To the best of our knowledge, ours is the first work to address the timely problem of producing fast, approximate tree-structured answers for complex XML queries.
Since its introduction six years ago, XML has evolved from a mark-up language for web documents to an emerging standard for data exchange and integration over the Internet.
Being self-describing and hierarchical in nature, the XML data model is suitable for representing a diverse range of data sources and promises to enable the next-generation of search applications that will allow users to query effectively the information available on the Web.With the rapid growth of available XML data, one can expect a proliferation of on-line decision support systems that enable the interactive exploration of large-scale XML repositories.
In a typical exploratory session, a domain expert poses successive queries in a declarative language, such as XQuery [4] or XSLT [7], and uses an appropriate visualization of the results in order to detect interesting patterns in the stored data.
Obviously, the successful deployment of decision-support systems depends crucially on their ability to provide timely feedback to users' queries.
This requirement, however, conflicts with the inherently expensive evaluation of XML queries which involve complex traversals of the data hierarchy, coupled with non-trivial predicates on the path structure and the value content.Generating approximate answers is a cost-effective solution for offsetting the high evaluation cost of XML queries.
In short, the system processes the query over a concise synopsis of the XML data and returns an approximation of the true result.
Ideally, this approximate answer is computed very fast and is accurate in the sense that it preserves with low error the statistical traits of the true result.
The user can then examine this "preview", assess the information content of the true answer, and decide whether it needs to be retrieved by executing the query over the base data.
Overall, by providing the user with fast and accurate feedback on the form of the results, the system can reduce the number of queries that need to be evaluated in order to support effectively the data exploration task.In a typical scenario, the result of an XML query is an XML fragment that is constructed by appropriate projections on the original data; an approximate answer, therefore, is an XML document that resembles the true answer in terms of hierarchical structure and value content.
Clearly, the effectiveness of an approximate answering system hinges upon the existence of accurate synopsis structures that capture the key statistical characteristics of the base XML data and can thus produce low-error approximate answers to queries that project parts of it.
Note that the problem of efficient XML summarization also arises in the context of selectivity estimation, where the synopsis is only used to estimate the size of the result.
Approximating the structure of the result, however, is a strictly more complex problem since there are documents where the same query produces results of equal size but with very different structure.
Summarizing, therefore, an XML document in order to compute approximate answers is more involved than building synopses for selectivity estimation, which in itself is known to be a hard problem [18].
1 .
Previous studies on approximate query answering [3,10] have focused on the relational model, where the result of a query is typically a multi-set of values.
The key idea is to process a query over an appropriate relational synopsis (such as, histograms, wavelets, or sample-based summaries) and compute an approximation of the true value set.
The proposed techniques and summarization methods, however, are suitable for flat relational data and are not easily extended to the case of general XML hierarchies.
As noted earlier, approximate XML query answering is closely tied to the problem of building effective XML synopses.
Recent studies have looked at the related problem of summarizing XML data for estimating the selectivity of single XPath expressions [1,12,15,16,21,22], or the number of binding tuples for twig queries [6,9,18].
Even though a selectivity estimate is essentially an approximate answer to an aggregate query (COUNT), the proposed summarization techniques do not store detailed enough information in order to approximate the structure of the query result.Buneman et al. [2] have recently introduced a query-able compression scheme for tree-structured XML data.
The proposed technique compresses the XML tree by using an appropriate bisimulation relation and evaluates an XPath query directly over the compressed instance.
The goal, therefore, is to compute an exact answer to a path query, whereas our focus is on computing an approximate answer to a twig query, which typically involves the joint evaluation of multiple path expressions.Our Contributions.
In this paper, we initiate the study of approximate query answering for XML queries.
In order to gain intuition on the complexity of the problem, this initial study focuses on approximate answers for twig queries with branching path expressions, i.e., we consider the structural part of the problem and ignore for now the value content of the document.
As we show in this paper, even this constrained version is quite complex and requires non-trivial solutions.
Our approach is based on a novel type of structural XML synopses, termed TREESKETCHes, that capture, in limited space, the key properties of the underlying path distribution and enable low-error approximate answers for a large class of interesting XML queries.
We develop a systematic query evaluation framework for generating approximate answers over concise TREESKETCH synopses and describe an efficient construction algorithm for building an accurate TREESKETCH summary within the constraints of a limited space budget.
Finally, we present experimental results on real-life and synthetic data sets that demonstrate the effectiveness of our approach and its benefits over previously proposed techniques, not only for generating approximate answers, but also for enabling accurate selectivity estimation.
To the best of our knowledge, ours is the first study to look into the problem of computing approximate answers for complex XML queries.
More concretely, the key contributions of our work can be summarized as follows:TREESKETCH Summarization Model and Query Evaluation Framework.
Our TREESKETCH summarization model is based on the novel concept of count-stability which captures very effectively the intrinsic similarity of sub-structures in an XML document.
Briefly, a TREESKETCH summary represents a clustering of document elements, where each cluster represents elements with similarly structured sub-trees.
We develop an efficient evaluation algorithm that processes a query over a concise TREESKETCH and produces another TREESKETCH synopsis that summarizes the structure of the result.
Futhermore, we discuss how the same algorithm can be used to estimate the result size of a complex twig query.Efficient TREESKETCH Construction Algorithm.
We describe an efficient heuristic algorithm that starts from a detailed summary and incrementally merges element clusters that are "close" in terms of element sub-structure.
To make our algorithm applicable on large data sets, we devise an effective heuristic that limits the number of possible merges in every step, without compromising the quality of the resulting synopsis.New Distance Metric for XML Documents.
We argue that traditional graph-theoretic distance metrics, such as tree-edit distance, are not suitable for evaluating the quality of an approximate answer relative to the true result.
To overcome this difficulty, we introduce a novel distance metric that quantifies the differences between two trees in terms of both the overall path structure and the distribution of document edges.
TREESKETCHes.
We validate our approach experimentally with an extensive study on real-life and synthetic data sets.
Our results demonstrate that TREESKETCHes perform consistently better than previously proposed summarization techniques: they enable more accurate approximate answers and selectivity estimates, and at the same time are more efficient to construct.
Moreover, our scaling experiments with large data sets show that even small-size TREESKETCHes are extremely effective in enabling low error selectivity estimates to complex twig queries (e.g., less than 5% estimation error for a 10KB summary of a 100MB input document).
Combined with the affordable construction times of TREESKETCH summaries, these results indicate that TREESKETCHes constitute an effective and viable in practice solution for the structural summarization of large XML data sets.
XML Data Model.
Following common practice, we model an XML document as a large, node-labeled tree¡ £ ¢ ¥ ¤ § ¦ © ¨ £.
Each node ¤ corresponds to an XML element and is characterized by a unique object identifier (oid) and a label (or, tag) assigned from some alphabet of string literals, that captures the element's semantics.
Edges to denote the label and set of child nodes for element node ¤ .)
As an example, Figure 1 depicts a sample XML data tree containing bibliographical data.
The document consists of author elements, each comprising a name, and several paper and book sub-elements.
Each paper contains a title, a year of publication and one or more keywords, whereas a book just gives its title.
Note that element nodes in the tree are named with the first letter of the element's tag plus a unique identifier.
Leaf elements in We consider twig queries using XPath expressions involving only the child and descendant-or-self axes (i.e., "/" and "//" operators) and may include existential branching predicates of the form "   l ", where  l is, in general, a label path whose existence is required under a given parent node in the XPath expression.
As an example, the "//a[//b]" predicate in Figure 2 specifies author tree nodes that are located at any depth under the current binding of variable IS (the document root) and have at least one book descendant.
Intuitively, the evaluation of a twig query , which contains all the elements of ¡ that appear in the bindings of different variables and in addition preserves their ancestor/descendant relationships as specified by the query paths.
Figure 2(c) shows the nesting tree for the example query of Figure 2(b).
Obviously, the nesting tree can be used to reproduce the binding tuples of a query and ultimately its result.
Abstractly, our general graph-synopsis model for an XML data tree¡ £ ¢ ¥ ¤ § ¦ © ¨ is defined by a partitioning of the element nodes in ¤ (or, equivalently, by an equivalence relation   ¤    ¤) that respects element labels; that is, if [14] and A(m )-indexes [11]), as well as statistical summaries for XML databases (including XSKETCHes [15,16] and twig-XSKETCHes [18]) are all based on the abstract "node-partitioning" idea described above.
As an example, the basic twig-XSKETCH summary mechanism, which targets selectivity-estimation of complex twig queries, augments our general graph-synopsis model with (1) per-node count information that records the size of each synopsis node's extent, (2) localized per-edge stability information, indicating whether the synopsis edge is backward-and/or forward-stable, and (3) .
¢ © ¦ © Y  then label ¢ ¥ e d label ¢ .
Limitations of Selectivity-Estimation Synopses.
Given the amount of earlier work on XML summarization and the number of alreadyexisting synopsis data structures for XML, a natural question that arises is whether there is a real need for a new summarization mechanism for approximate XML query answering.
Our key observation here is that the focus of all earlier work in the area has been on the problem of selectivity estimation (for XPath expressions [15,16] or twig queries [6,18]) and, unfortunately, even the state-of-the-art solutions for XML selectivity estimates prove to be inadequate in accurately capturing the complete tree structure of the underlying document.
We illustrate our observation with a simple example on twig-XSKETCH synopses (we focus on the twig-XSKETCH model since it also uses a graph-synopsis and it is applicable in the general case of schema-less documents.)
Consider the two XML document trees .
Note, however, that the tree structure for the binding tuples of P is in fact very different across our two example documents.
For example, looking at the edge distribution in the query result, for document Again, the key observation here is that, while twig-XSKETCHes and edge histograms provide an accurate summarization mechanism for twig selectivity estimation, they cannot model the details of the tree structure for the twig query's binding tuples; thus, we expect them to be inadequate as a general-purpose approximate query answering tool (the results of our empirical study in Section 6 clearly verify our expectations.)
Furthermore, as this paper demonstrates, our new synopses are also conceptually simpler, significantly easier to build, and provide more accurate results than twig-XSKETCHes even for the simpler selectivity estimation problem.
( ( X X X X  e  e  d  y Ò Ò Õ Õ Õ Õ  ¢ g  £  d  ¢ g    e  (d) (e) (f) Our proposed TREESKETCH synopsis data structure is a specific instantiation of the generic graph-synopsis model outlined earlier in this section.
TREESKETCHes rely on a novel, intuitive concept of localized stability, termed count stability, defined formally as follows.
It is easy to see that our notion of count stability is a refinement of the traditional Fstability relation for trees employed by both XSKETCHes [15,16] and twig-XSKETCHes [18]; in other words, the equivalence classes for the count-stability relation are generated by further partitioning the equivalence classes for F-stability.
Intuitively, our concept of count stability tries to define a class of equivalence relations where element nodes are grouped together only if the data sub-tree structures underneath them are identical.
As the following lemma shows, the count-stable graph-synopsis for a data tree ¡ is uniquely defined and, furthermore, it accurately captures the structure of¡ .
LEMMA 3.1.
Given a data tree ¡ £ ¢ ¥ ¤ § ¦ © ¨ , there exists a unique minimal (in terms of the number of equivalence classes) countstable equivalence relation «  ¤  ¬ ¤ .
Furthermore, there exists a function ­ ¯ ® W ° ² ± Y ³ µ ´from stable relations to XML trees, such that­ h ® ¶ ° ² ± Y ³ ² ´ ¢  is isomorphic to the original document tree ¡ .
Thus, the tree structure of the original document ¡ can be retrieved with zero-error from a synopsis· g ¢ 8 ¡ k if is stable.
The problem, of course, is that the size of a count-stable synopsis can become very large -it can easily be in the order of the original document size.
Given the stringent time and storage limitations typically associated with interactive approximate query answering, it is clear that perfect count-stable summaries cannot be very useful as a data-approximation tool for real-time XML data exploration.
Instead, our proposed TREESKETCH synopses try to approximately capture the underlying document-tree structure within a predefined space budget.
Intuitively, the key idea behind TREESKETCHes is to locally approximate count-stable relations in the graph-synopsis wherever structural correlations exist in the underlying data, while relaxing the count-stability requirement where such correlations are not dominant and independence/uniformity assumptions are sufficient.
Our TREESKETCH synopsis model is simply defined as follows.
Thus, instead of storing complex histograms for edge combinations in a B/F-stable neighborhood of a node (like twig-XSKETCHes [18]), our TREESKETCHes simply maintain a localized average child count for each edge in the synopsis (without requiring any stability properties for that edge).
is mapped to a point¢ 6 v d ¢ ¦ ¼ ' ¼ # ¼ ' ¦ © v º ¢ © if it has v¢ children to node j , l ¾ ½ C ¿ k ½ « » .
The recorded average edge counts essentially map all points in thisspace to point ¢ count ¢ ¦ j d ¦ f ¼ ' ¼ ' ¼ ' ¦ count ¢ ¦ j a º ©, which actually represents the centroid of the cluster.
We can thus characterize the quality of a TREESKETCH synopsis by using a metric that quantifies the quality of the induced clustering.
The metric that we adopt in our work is the squared error of the clustering, which essentially measures the euclidean distance between points and their corresponding centroid.
The squared error for a single cluster is defined asÀ # I ¢ ¯ d ~ H Á Â t ~ d © Ã Ã º ¢ 6 v¢ R Ä count ¢ ¦ j © e, while the squared errorÀ ' I ¢ ¸ i f for a synopsis¸i synopsis¸ synopsis¸i fis simply the sum of squared errors for all the induced clusters.
Note, of course, that the squared error for a count-stable synopsis is zero since all edgecount centroids are exact, i.e., the child counts for any element in a given synopsis-node extent are identical (and equal to the corresponding edge counts).
We have chosen the squared error metric since it captures a notion of weighted variance, but it is possible to use other metrics such as the Manhattan distance or the pairwise intra-cluster distance.
Irrespective of the actual choice, the existence of a workload-independent TREESKETCH-quality metric is a major difference from earlier summarization techniques which are also based on graph synopses, but quantify the quality of summaries on a per-workload basis (examples include both XSKETCHes and twig-XSKETCHes.)
As we will see later, this feature will enable fast construction times, since the quality of a summary in the space of possible TREESKETCHes can be determined very efficiently, without requiring the costly evaluation of a query workload (as in the case of XSKETCH and twig-XSKETCH construction).
In this section, we start by describing novel, efficient bottom-up construction procedures for count-stable summaries and our TREESKETCH synopses (for a given space budget).
We then introduce algorithms for approximating the results as well as the selectivities of XML twig queries over TREESKETCH synopses.
Our algorithm for constructing the complete count-stable summary of an input XML tree ¡ (termed BUILDSTABLE) is depicted in Figure 4.
In a nutshell, BUILDSTABLE processes element nodes in a post-order traversal of time; note that, for building the "child-count signature" in Step 3, only the element's child classes are necessary, and these can be easily accessed using a stack during the post-order traversal.
As already mentioned in Section 3.2, the size of an exact countstable synopsis typically renders it useless in the context of a real-  := Í  A Î    h Ï ' Î is a node in È and Ð children  Ê  µ Ñ extent   Î Ð Ò  h Ó  Ô 4.
if  ¬ Õ label  Ê  ©  × Ö Ò É  then 5.
Add node Î to È with label   Î ¶  Ò label  Ê  6. 
¬ Õ label  Ê  s  × Ö := Î 7.
for  A Î    Ë  do add edge Î  s Ø Ù  Ú Î to È 8.
endif 9.
Î :=  ¬ Õ label  Ê  ©  × Ö ; extent  A Î ¶  := extent   Î ¶  ² Û Í f Ê Ô Figure 4: Algorithm BUILDSTABLE.life approximate query processing system.
Such systems usually place tight limits on the space budget for building synopses of the underlying data collection.
Thus, there is a clear need for effectively constructing compressed TREESKETCH synopses under a given space budget, while maintaining a high-quality XML-data approximation in order to enable meaningful approximate answers.
Given the aforementioned natural analogy between TREESKETCHes and data clustering (Section 3.2), our goal of constructing an effective synopsis can be translated to computing an effective clustering of the XML elements.
Here, of course, an element cluster is "tight" if it encompasses data elements with similar sub-trees, and "tightness" can be quantified using the squared error for the clustering (as discussed in Section 3.2).
Thus, our goal is to build a TREESKETCH synopsis¸i synopsis¸ synopsis¸i f that fits within a given space budget, such that the overall square errorÀ ' I ¢ ¸ i ffor the synopsis is minimized.
The analogy with clustering also highlights the difficulty of TREESKETCH construction, since such clustering problems are known to be Ü Þ Ý -hard even in the simple case of points in a low-dimensional space [19,23].
Furthermore, TREESKETCH construction typically deals with a high-dimensional space which is defined by the clustering itself (i.e., the space itself changes as elements are assigned to clusters)!
Thus, the problem is significantly more complex and existing clustering algorithms are not directly applicable.Our approach is based on a generic bottom-up clustering paradigm: starting from the count-stable synopsis, our algorithm (termed TS-BUILD) incrementally reduces the synopsis size by merging nodes with similar sub-structures, until the budget constraint is met.
This resembles agglomerative hierarchical clustering algorithms, which start with one cluster per input data point and successively reduce the number of clusters by merging neighboring groups (according to some appropriate distance metric).
Another possible option is a top-down approach that starts from a coarse summary and gradually expands it by splitting nodes (this is actually the approach taken in the XSKETCH work [15,16,18]).
In the clustering literature, however, bottom-up algorithms have been shown to perform better than their top-down counterparts; in addition, we have experimentally verified that bottom-up TREESKETCH construction yields much better results, without significantly increasing construction time.The TSBUILD Algorithm.
We now describe our TREESKETCHconstruction algorithm in more detail.
In a nutshell, TSBUILD maintains a pool of candidate operations to be applied to the working TREESKETCH synopsis¸i Procedure TSBUILD(à , ¢ ,á T â , ã ä â ) Input: XML document à ; space budget ¢ ; upper/lower bounds for heapß ¼ # þ Y þ ù d À ' I ¢ ß ¢ ¸ k f © Ä À ' I ¢ ¸ i fto be the increase in squared error from¸ifrom¸ from¸i f to ß ¢ ¸ i f, andß ¼ À # ¿ ¥ ÿ ù d size ¢ ¸ i f Ä size ¢ ß ¢ ¸ i f ©to be the corresponding decrease in synopsis size.
The pool of candidate operations is organized in a min-heap according to the marginal-gain ratioß ¼ # þ Y þ ù ¡ ß ¼ À ' ¿ ¥ ÿ ù, i.e., the operation at the top of the heap offers the least increase in squared error per unit of space that is saved.
At each step of the construction algorithm, the operation at the top of the heap is applied, the pool is updated with new merge operations for the new node, and the þ þ ù ¦ À ' ¿ F ÿ ù metrics are recomputed for the new pool of candidate merge operations.
This process is repeated until the heap is exhausted (i.e., no merge operations are possible) or the size of the¸¹ the¸ the¸¹ f synopsis drops below the allotted space budget.The pseudo-code for our TSBUILD algorithm is shown in Fig- ure 5.
TSBUILD initializes the min-heap ¢ of candidate merge operations through function CREATEPOOL (discussed below), and then applies successive merges according to our marginal-gain criterion (Steps 5-15).
In order to limit the memory requirements of the algorithm and increase efficiency, the size of the operations heap is bounded by the supplied parameter £ â .
As operations are performed, the size of the heap is gradually reduced and when it drops below a supplied threshold ¤ â , the heap is re-generated and the process repeated.A potential performance bottleneck for the construction process is the re-computation of the more efficient by storing "sufficient" statistics in each synopsis node.
Briefly, each node stores the sum and the sum of squares for the child counts of its elements along each outgoing edge in the synopsis.
It is straightforward to show that these statistics are sufficient in order to compute the squared-error metric for the synopsisÀ ' I ¢ ¸ i fwithout accessing the base data.
In addition, in certain cases, these statistics can be combined in order to derive the statistics of new nodes (created through merge operations).
The complete details are beyond the scope of this presentation and can be found in the full paper [17].
Note that this idea is similar to the one proposed in the BIRCH clustering algorithm [23], where clusters are represented only by a collection of similar sufficient statistics throughout the computation.
In our case, however, the stored statistics do not obviate the need to access a small subset of the base data (although this can be done very efficiently, by accessing only the relevant parts of the count-stable summary).
Again, we defer the details to the full version of this paper [17].
merge operations, where  is the number of nodes in the count-stable summary and, thus, becomes prohibitively expensive as the size and complexity of the data grows.
Given that CREATEPOOL is invoked repeatedly during the TREESKETCH-construction process, this increased complexity has a significant negative impact on construction times.
On the other hand, reducing the number of operations considered increases the efficiency of the candidate-generation stage, but it also runs the risk of "polluting" the heap with less effective merge operations that can affect the quality of the generated TREESKETCHes.
To overcome this difficult problem, we adopt a heuristic that limits the number of merge operations considered while ensuring that the heap only contains operations that are likely to be beneficial.The key observation here is that a merge of two nodes and j leads to a "good" clustering of the elements involved only if and j have similarly structured sub-trees.
Thus, our TREESKETCHconstruction algorithm is much more likely to apply merge operations on the children of and j first, before merging and j themselves.
This observation suggests a bottom-up approach for populating the heap with merge operations, starting with nodes close to the leaves of the current synopsis and proceeding upward to the root.
Figure 6 shows the pseudo-code for our CREATEPOOL algorithm that implements the aforementioned heuristic.
CREATEPOOL uses the concept of a node's depth in order to examine merge operations in a bottom-up fashion.
More specifically, let be a document element.
of the operations seen thus far (this can be implemented efficiently through a double-ended heap).
Candidate generation terminates when the current depth has been exhausted and the heap holds the maximum allowed number of operations.
We now turn our attention to the problem of generating approximate answers from a concise TREESKETCH synopsis.
At an abstract level, our query evaluation algorithm, termed EVALQUERY, processes the input query (the full nesting tree can be retrieved by expanding¸¹ expanding¸ expanding¸¹ f Q ).
As noted in Section 2, the full nesting tree can be used to reconstruct the binding tuples of P and ultimately its result.
The evaluation algorithm uses the structure information of¸i of¸ of¸i f in order to identify matches of the query's path expressions, while the stored edge counts are used to approximate the cardinalities of the corresponding result sets.
Similar to any summarization method, the use of the stored information is coupled with a set of appropriate statistical assumptions that compensate the lack of detailed distribution information at certain parts of the synopsis.
As we will see, the validity of these assumptions depends on the quality of element clustering within each synopsis node and is thus directly linked to the heuristics of the TSBUILD algorithm.
Intuitively, this direct relationship between the build algorithm and the query processing framework leads to the construction of summaries that compute highly accurate approximate answers.
Figure 7 shows the pseudo-code for algorithm EVALQUERY.
, and the number of descendants along each path is computed with algorithm EVALEM-BED.
The separate invocations of EVALEMBED essentially apply an independence assumption between the different variables of the query, which translates to an independence assumption on the underlying path distribution.
We defer this point to the end of the section, where we discuss the relationship of the processing assumptions to the general TREESKETCH framework.
, then all elements in satisfy the branching predicate and the selectivity is equal to 1.
In the opposite case (all descendant counts are strictly less than 1), each count is treated as the fraction of elements in that have descendants along the corresponding embedding of the branching predicate.
Since an element satisfies the branching predicate if it is the root of at least one matching embedding, the overall selectivity is computed using the inclusion-exclusion principle on the recorded fractions (line 11).
We note that the application of the exclusion/inclusion principle essentially makes use of an independence assumption on the distribution of document edges, which, as we discuss below, is derived from the interpretation of the TREESKETCH summarization model and is closely related to the squared error of the synopsis.
Figure 4.3(c) (synopsis nodes are annotated with the corresponding query node).
As noted previously, the evaluation algorithm applies a set of independence assumptions during the processing of an input query over a concise TREESKETCH summary.
At a closer inspection, all the processing assumptions can be reduced to a basic independence assumption that de-correlates the distribution of document edges along different paths of the document.
This assumption is essentially derived from the interpretation of the TREESKETCH synopsis model: given a synopsis edge Þ n j , all elements inhave count ¢ ¦ j children in j, independent of incoming or outgoing paths (Section 3).
Obviously, this interpretation is trivially satisfied on a stable synopsis where, by virtue of count-stability, all elements in the extent of a node have the same edge counts to child nodes.
As a result, EVALQUERY will compute the exact nesting tree of a query when the accessed edges of the synopsis are count-stable.
In the general case of a compressed TREESKETCH, it is straightforward to observe that the validity of the assumption is directly related to the error of the induced element clustering: if the error is low, i.e., the clusters are tight, then the elements are closer to the centroid (which is defined by the recorded average edge counts), and the assumption becomes more valid.
In essence, there is a close relationship between the squared error of the synopsis, which quantifies the tightness of the clusters, and the quality of the generated approximate answers.
This observation provides the "missing link" between the construction algorithm and the evaluation framework: although the build process does not use a workload-based approach to ensure high-quality approximate answers, it achieves the same goal by keeping the squared error low and thus making the basic independence assumption more valid.
In this section we briefly discuss the use of TREESKETCHes for estimating the selectivity of twig queries.
As shown in earlier studies [5,13], accurate estimation for the number of bindings tuples for twig queries is a key requirement in producing effective query plans for complex declarative queries over XML data.Our proposed estimation framework uses the result of the EVAL-QUERY algorithm to efficiently compute an estimate of the query's selectivity.
More specifically, the estimation algorithm performs a single post-order traversal of the structural summary¸é summary¸ summary¸é f Q and computes, for each node, the average number of binding tuples per element in its extent.
Given the bounded size of¸i of¸ of¸i f Q , it becomes clear that the estimation process has low memory requirements and can be performed very efficiently.
In the interest of space, we do not discuss the estimation algorithm further.
The full details can be found in the full version of this paper.
In order to evaluate the effectiveness of the proposed approximate query answering framework, it is necessary to measure the degree of similarity between the approximate nesting tree between the two XML trees which essentially quantifies the error of approximation.
There are numerous proposals for distance metrics over trees, the most widely used being the tree-edit distance metric [20].
As we will see next, however, the proposed metrics essentially measure the syntactic differences between the two XML trees and thus fail to capture the semantics of approximate answers.
We note that our discussion will focus on the tree-edit distance metric, but our observations hold for other graph-theoretic metrics as well.The tree-edit distanceý ¿ F ÀThe previous example illustrates that the syntactic difference between two documents, as measured by tree-edit distance or other similar graph-theoretic metrics, is not a suitable similarity metric for approximate answers.
Intuitively, an approximate answer is useful if it preserves the statistical traits of the true answer, without necessarily being identical to it, and the distance metric should capture this type of "approximate" similarity.
Similar observations have been made in the context of approximate answers for relational queries [3,10], where the result of a query is a multi-set of values.
In short, these studies have argued convincingly that settheoretic metrics, which correspond to syntax-oriented metrics in the XML world, do not yield intuitive results when comparing two value sets (the approximate and the true answer).
This has led to the introduction of new distance metrics, such as the MAC [10] and the EMD [3], in order to measure effectively the quality of approximate answers to relational queries.A New Distance Metric for XML Trees.
We introduce a novel distance metric, termed Element Simulation Distance (ESD), that avoids the shortcomings of syntax-oriented metrics by capturing regions of approximate similarity between the compared XML trees.
To the best of our knowledge, ours is the first metric that considers both the overall path structure and the distribution of document edges, when computing the distance between two XML trees.We now describe the ESD metric in more detail.
can now be measured as the sum of distances for children of matching tags:¨ · v u ¢ ¦ j ¯ d ~ S ý ¿ F À ) 1 x T ¢ £ v S ¦ h ¤ S .
In effect, two elements are more (or less) similar if their children with matching tags are more (or less) similar themselves, which recursively extends to the whole sub-structure underneath the two elements.
.
This, however, is a common characteristic of metrics that measure the approximate distance between complex objects (e.g., a similar observation holds for the MAC and EMD metrics).
We note that it is possible to compute the ESD metric efficiently by first building the stable on the fly and then evaluating the metric on the stable synopses.
The key observation is that a stable summary preserves the path structure and the edge distributions of the original document, while containing fewer nodes.
A detailed description of the computation of ESD on stable summaries can be found in the full version of the paper [17].
In this section, we present an extensive experimental study of TREESKETCHes on real-life and synthetic data sets.
Our results verify the effectiveness, in terms of accuracy and construction time, of the TREESKETCH synopses as structural summaries for large XML data sets.
These benefits become even more apparent in a comparison to previously proposed techniques, where TREESKETCHes perform consistently better in all aspects.
Overall, this empirical study indicates that TREESKETCHes are a viable and effective solution for the structural summarization of large XML data sets in real-world applications.
Techniques.
We have experimented with two techniques.
TREESKETCHes.
We have implemented a fully functional prototype of the TREESKETCH framework that we describe in this paper.
Throughout our experiments, the construction algorithm uses an upper limit of £ operations.
Twig-XSKETCHes.
Twig-XSKETCHes [18] have been proposed as a summarization technique for estimating the selectivity of complex twig queries.
Since the original proposal focused solely on selectivity estimation, we have developed an algorithm for producing approximate answers from a twig-XSKETCHThe algorithm traverses the query tree and uses the distribution information of the recorded edge histograms in order to sample the number of descendants for each element in the approximate result tree.
For the construction of twig-XSKETCH summaries, we have used the same parameters that were reported in the original study [18].
Data Sets.
We have used four data sets in our experiments: IMDB, a real-life data set from the Internet Movie Database Project; XMark, a synthetic data set that models transactions on a on-line auction site; Swiss Prot, a real-life data set with annotations on proteins; and DBLP, a real-life data set with bibliographical data.
The main characteristics of the corresponding XML documents are summarized in Table 1.
The TX documents have been used in the twig-XSKETCH study [18], and we include them here for the comparison of TREESKETCHes against twig-XSKETCHes.
Looking at the sizes of the stable summaries, we observe that count-stability is very effective in compressing, without loss, the structural information of the original documents.
Still, processing a query over so large a summary becomes prohibitively expensive relative to the stringent time requirements of an approximate answering system.
Query Workloads.
For each data set, we evaluate the performance IMDB-TX XMark-TX SProt-TX of the generated summaries against a workload of 1000 positive queries, i.e., queries that have non-empty results sets.
Our experiments with negative workloads have shown that TREESKETCHes consistently produce empty answers as approximations and we therefore omit these workloads from our presentation in the interest of space.
The workload is generated by sampling sub-trees from the stable synopsis and converting them to twig queries.
Table 2 contains the average number of binding tuples per query in the workloads that we have generated.Evaluation Metrics.
We quantify the accuracy of approximate answers with the ESD metric which was defined in Section 5.
More specifically, we compute the ESD between the approximate and the true nesting tree of each query in the workload and report the average over all queries.
Our implementation uses a slightly revised version of MAC (kindly provided by Y. Ioannidis and V. Poosala) as the underlying set-distance metric, and limits comparisons to the binding elements of the same query variables.
As always, the complete details can be found in the full paper [17].
For experiments on selectivity estimation, we measure the accuracy of the synopses with the average absolute relative error over all queries in the workload.
More formally, if þ is the true and the estimated selectivity for a query in the workload, the absolute relative error is defined as{þ R Ä  { ß o  4  ¢ ¦ À .
The sanity bound À is used to avoid the artificially high percentages of low-count queries.
Following common practice [16,18], we set À to the 10-percentile of true query counts.
Approximate Query Answers.
In this experiment, we evaluate the effectiveness of our novel TREESKETCH synopses as a practical solution for generating approximate answers to complex twig queries.
We present a comparison against the previously proposed twig-XSKETCH synopses, focusing on two measures: the quality of the generated approximate answers, and the efficiency of the construction process.
Figure 11 shows the average ESD metric for approximate answers computed with TREESKETCHes and twig-XSKETCHes on a workload of 1000 twig queries, and for the XMark-TX, IMDB-TX, and SwissProt-TX data sets.
We note that the increased distance numbers are partly due to the underlying MAC metric, which assigns a heavy penalty if the compared element sets contain the same sub-tree in different multiplicities.
The interpretation of the results is therefore based on the relative performance of the two techniques, rather than on the absolute distances.
Clearly, our novel TREESKETCH synopses consistently produce approximate answers of lower error.
In all three data sets, the average distance for twigXSKETCHes is at least four times higher than the one for TREESKETCHes, and the error for a 10KB TREESKETCH synopsis (lowest budget) is less than the error for a 50KB twig-XSKETCH (highest budget).
The effectiveness of TREESKETCHes can be attributed to our novel clustering-based summarization model, which captures very accurately the intrinsic sub-structure similarity found in XML data.
The edge-histogram model used by twig-XSKETCHes, In terms of construction efficiency, we present a qualitative comparison between the two techniques since the twig-XSKETCH code base is not optimized for speed.
The twig-XSKETCH construction algorithm starts from a coarse label-split graph, which contains exactly one node for all elements of the same tag, and gradually expands it through incremental refinement operations (basically, node splits, and histogram refinements).
To evaluate the benefit of a candidate refinement, the algorithm measures the accuracy of the resulting twig-XSKETCH on a sample workload of twig queries (workload-based evaluation).
Our proposed TSBUILD algorithm, on the other hand, compresses the stable summary down to the available space budget, using the squared error as a workloadindependent quality metric.
Table 3 compares the construction time for TREESKETCHes and twig-XSKETCHes for the IMDB-TX, XMark-TX, and SwissProt-TX data sets.
All times are reported in minutes and were measured on an unloaded Pentium4 3GHz machine, running Linux.
For TREESKETCH synopses, we measure the time to compress the stable summary down to the smallest summary possible, the label split graph; for twig-XSKETCHes, we measure the time needed to expand the original coarse summary to 10KB of storage.
This represents a worst case scenario for TREESKETCHes since the distance from the stable summary to the label-split graph is certainly "longer" than the distance from the label-split-graph to 10KB.
Still, a qualitative comparison of the measured times indicates that TREE-SKETCH construction is much more efficient.
As we described in Section 4.2, the TSBUILD algorithm uses effective heuristics to explore limited, yet promising regions of the search space, while the squared error metric, which is workload-independent, avoids the most expensive step of the twig-XSKETCH algorithm, namely evaluating the accuracy of candidate summaries against sample workloads.We have also evaluated the accuracy of TREESKETCH-generated approximate answers for the large datasets of Table 1.
The results remain qualitatively the same as for the smaller data sets and we omit them in the interest of space.
A detailed presentation can be found in the full version of this paper [17].
Note that we were not able to evaluate the performance of the twig-XSKETCH approach on the large data sets due to the high construction times.Selectivity Estimation.
In this experiment, we evaluate the effectiveness of our proposed synopses in estimating the selectivity of complex twig queries with branching path expressions.
Fig- ure 12 shows the average relative estimation error on a workload of 1000 queries for TREESKETCHes and twig-XSKETCHes, and for the XMark-TX and SwissProt-TX data sets.
The results for the IMDB-TX data set are similar to XMark-TX and are omitted in the interest of space.
As in the previous experiment, the results show that TREESKETCHes are effective in summarizing the key properties of the underlying path distribution.
We observe that the estimation error remains well below 10% for all three data sets, even for small space budgets of 10KB-20KB that represent a small fraction of the original document sizes.
Compared to twig-XSKETCHes, our new TREESKETCH synopses produce significantly more accurate estimates and exhibit more stable behavior.
Figure 13 shows the TREESKETCH estimation error over a workload of 1000 queries and for the XMark, IMDB, SwissProt, and DBLP data sets (the large data sets of Table 1).
The results verify the effectiveness of TREESKETCHes in computing accurate selectivity estimates for complex twig queries and demonstrate their nice scaling properties in terms of data size.
In all four data sets, the estimation error drops below 5% for a space budget of 50KB, which in turn represents an extremely small fraction of the original document size.
At the same time, the construction times remain affordable given the complexity and size of the involved data sets: 38 minutes for Swiss Prot, 11 minutes for DBLP, 2.5 minutes for IMDB, while the largest XMark data set required 4 hours.
Approximate answers constitute an effective solution for offsetting the high execution cost of complex XML queries in an interactive data exploration environment.
In this paper, we have initiated the study of approximate query answering for XML data.
We have proposed the TREESKETCH synopses, a novel class of structural summaries that capture very effectively the sub-structure similarity that is commonly found in XML data sets.
We have developed a systematic evaluation algorithm for computing approximate answers over a concise TREESKETCH summary, and we have described an efficient heuristic construction algorithm for building an effective TREESKETCH for a limited space budget.
To quantify the quality of the generated approximate answers, we have proposed a novel distance metric between XML trees that avoids the shortcomings of existing graph-theoretic metrics.
Experimental results on real-life and synthetic data sets have verified the effectiveness of our approach and have demonstrated its benefits over previously proposed techniques.
