Studies in experimental economics have consistently demonstrated that Nash equilibrium is a poor description of human players' behavior in unrepeated normal-form games.
Behavioral game theory offers alternative models that more accurately describe human behavior in these settings.
These models typically depend upon the values of exogenous parameters , which are estimated based on experimental data.
We describe methods for deriving and analyzing the posterior distributions over the parameters of such models, and apply these techniques to study two popular models (Poisson-CH and QLk), the latter of which we previously showed to be the best-performing existing model in a comparison of four widely-studied behavioral models [22].
Drawing on a large set of publicly available experimental data, we derive concrete recommendations for the parameters that should be used with Poisson-CH, contradicting previous recommendations in the literature.
We also uncover anomalies in QLk that lead us to develop a new, simpler, and better-performing family of models.
It is well known that in many settings, the standard gametheoretic assumption that agents will adopt Nash equilibrium strategies-where each agent simultaneously responds optimally to all the others-is a poor predictor of actual human behavior [e.g., see 9].
The field of behavioral game theory aims to develop models that more accurately describe human behavior, as evaluated using experimental data [2].
These models typically depend upon parameters such as agents' sensitivity to utility differences and the distribution of cognitive ability in the population.
In order for behavioral models to be effective tools for prediction, it is necessary to identify "good" estimates for these parameters.
Such parameter values are also interesting for their own sake, because they can offer economic insights into human behavior.In past work, we conducted an exhaustive meta-study of behavioral game theory models, focusing on the problem of unrepeated, simultaneous-move games [22].
We evaluated four prominent models from the behavioral game theory literature: Quantal Response Equilibrium [QRE; 12], Level- k [Lk; 13, 6], Poisson-Cognitive Hierarchy [Poisson-CH; 3], and Quantal Level-k [QLk; 19].
We evaluated these models according to their out-of-sample prediction performance: we identified parameters for each model that maximized the likelihood of a training data set, and then evaluated each model in terms of the likelihood it assigned to a separate test set.
We took data from six publicly available datasets describing lab experiments in which subjects played unrepeated, simultaneous-move games against other human opponents.
In the end we observed a result that was statistically significant and quite robust: that the QLk model substantially outperformed all others on the set of all data, and also had the best or nearly the best performance on each individual dataset.While it effectively identified the best-performing existing model, our previous work offered very little insight about the models' parameter values.
For example, because we relied upon a maximum-likelihood approach, we obtained no information about the extent to which parameter values could be changed without a major drop in predictive accuracy, or even about the extent to which individual parameters influence a model's performance.
This paper shows how to answer such questions.
Specifically, it describes a Bayesian approach for gaining understanding about a behavioral model's entire parameter space.
We combine experimental data with explicitly quantified prior beliefs to derive a posterior distribution that assigns probability to parameter settings in proportion to their consistency with the data and the prior [8].
We apply this approach to analyze the posterior distributions for two models: QLk and Poisson-Cognitive Hierarchy.
Although Poisson-CH did not demonstrate competitive performance in [22], we analyze it here because it is very simple, and because the literature contains a very specific recommendation for how its parameter should be set: Camerer et al. [3] recommend setting the model's single parameter, which represents agents' mean number of steps of strategic reasoning, to 1.5.
Our own analysis sharply contradicts this recommendation, placing the 99% confidence interval almost a factor of three lower, on the range [0.51, 0.59].
We devote most of our attention to QLk, however, since we previously showed it to achieve strong performance.
Our new analysis points out several anomalies in the parameter distributions for QLk, suggesting that a simpler model could be preferable.
By exhaustively evaluating a family of variations on QLk, we identify a simpler, more predictive model based in part on the cognitive hierarchy concept.We pause to contrast our work with a particularly related paper from the economics community.
Rogers et al. [17] proposed a unifying framework that generalizes both Poisson-CH and QRE, and compared the fit of several variations within this framework.
This is similar to our search of a family of QLk variants, but there are several differences.
First, we compare out-of-sample prediction performance, not in-sample fit.
Second, Rogers et al. restricted the distributions of types to be grid, uniform, or Poisson distributions, whereas we consider unconstrained discrete distributions.
Third, they required different types to have different precisions, while we do not.
Finally, we consider level-k beliefs as well as cognitive hierarchy beliefs, whereas they compared only cognitive hierarchy belief models (although their framework in principle allows for both).
There has also been interest by various computer scientists in behavioral solution concepts as an alternative to standard economic models.
For example, Wunder et al. [23] extended the cognitive hierarchy model in their analysis of the Lemonade Stand Game, and Gao and Pfeffer [7] used quantal response equilibrium to model bounded rationality in a game where agents respond to payoffs unknown to the modeler.In the next section, we define the models that we analyze.
We then describe the framework that we used for estimating and analyzing parameters and their distributions, and the dataset and specific techniques that we used to derive our estimates.
In Section 4 we present the results of our analyses for the Poisson-CH and QLk models.
In Section 5, we describe the QLk-like variants that we evaluated, and present the results of our search.
We begin by formally defining the behavioral models that we analyze.
We then relate these models to other widely studied models that we do not consider further, due to their poor predictive performance in our previous study [22].
Stahl and Wilson [19] proposed a rich model of strategic reasoning that we refer to as the quantal level-k model (QLk).
The QLk model of human behavior incorporates two primary components: iterated strategic reasoning, and cost-proportional errors.
Iterated strategic reasoning refers to a limit on the number of levels of higher-order belief that agents can maintain.
1 Agents make cost-proportional errors if their rate of making errors increases as errors become less costly.
This can be modeled by assuming that agents best respond quantally, rather than via strict maximization.Definition (Quantal best response).
Let ui(ai, s−i) be agent i's expected utility when playing action ai against strategy profile s−i.
Then a quantal best response QBRi(s−i; λ) by agent i to s−i is a mixed strategy si such thatsi(ai) = exp[λ·ui(ai, s−i)] a i exp[λ·ui(a i , s−i)] ,(1)where λ (the precision) indicates agents' sensitivity to utility differences.Note that unlike regular best response, which is a set-valued function, quantal best response always returns a single mixed strategy.
When λ = 0, quantal response mixes uniformly over all of the agents' actions; as λ → ∞, quantal best response approaches strict best response.
In the QLk model, agents have one of three levels: level-0, level-1, or level-2.
Level-0 agents are nonstrategic, and choose their actions uniformly at random.
Level-1 agents quantally best respond to level-0 agents; that is, they believe that the rest of the population consists entirely of level-0 agents.
Similarly, level-2 agents quantally respond to level-1 agents.
Level-1 and level-2 agents can use different precisions (λ's), and furthermore level-2 agents' beliefs about level-1 agents' precision can be arbitrarily different from level-1 agents' actual precision.
Definition (QLk model).
Let Ai denote player i's action set.
Then the probability distribution π QLk i,k ∈ Π(Ai) over actions that QLk predicts for a level-k agent playing as agent i is defined as follows.π QLk i,0 (ai) = |Ai| −1 , π QLk i,1 = QBRi(π QLk −i,0 ; λ1), π QLk i,1(2) = QBRi(π QLk −i,0 ; λ 1(2) ), π QLk i,2 = QBRi(π QLk i,1(2) ; λ2),where π QLk i,1(2) is a mixed-strategy profile representing level-2 agents' (possibly incorrect) beliefs about how level-1 agents play.
The overall predicted distribution π QLk of actions is the weighted sum of the distributions for each level: π QLk i = 2 k=0 α k π QLk i,k , where α0 = 1 − α1 − α2.
The QLk model thus has five parameters: {α1, α2}, the proportions of level-1 and level-2 agents (α1 + α2 ≤ 1; any remaining agents are level-0); {λ1, λ2}, the precisions of level-1 and level-2 agents' responses; and λ 1(2) , level-2 agents' beliefs about the precision of level-1 agents.
Like QLk, the cognitive hierarchy model [3] aims to model agents with heterogeneous bounds on iterated reasoning.
It differs from the QLk model in two key ways.
First, agents use standard best response, rather than quantal response.
Second, agents best respond to the full distribution of lowerlevel types, rather than only to the strategy one level below.
More formally, every agent has an associated level m ∈ {0, 1, 2, . . .}.
Let f be a probability mass function describing the distribution of the levels in the population.
Level-0 agents play uniformly at random.
Level-m agents (m ≥ 1) best respond to the strategies that would be played in a population described by the truncated probability mass function f (j | j < m).
Camerer et al. [3] advocate a single-parameter restriction of the cognitive hierarchy model called Poisson-CH, in which f is a Poisson distribution.Definition (Poisson-CH model).
Let π P CH i,m∈ Π(Ai) be the distribution over actions predicted for an agent i with level m by the Poisson-CH model.
Let f (m) = Poisson(m; τ ).
Let BRi(s−i) denote the set of i's best responses to the strat-egy profile s−i. Let π P CH i,0:m = m =0 f ()π P CH i,,/ m =0 f () be the "truncated" distribution over actions predicted for an agent conditional on that agent's having level 0 ≤ ≤ m.
Then π P CH is defined as follows:π P CH i,0 (ai) = |Ai| −1 , π P CH i,m (ai) = |BRi(π P CH i,0:m−1 )| −1 if ai ∈ BRi(π P CH i,0:m−1 ), 0otherwise.
As with QLk, the overall predicted distribution of actions π P CH is a weighted sum of the distributions for each level:π P CH i = ∞ =0 f ()π P CH i,,.
The mean of the Poisson distribution, τ , is this model's single parameter.
We previously evaluated two other behavioral models in addition to those listed above [22].
The first, QRE [12], is a generalization of Nash equilibrium where agents respond quantally instead of best responding.
The second, Lk [13,6], is similar to QLk, except that agents best respond to the next level down rather than quantally responding.
We omit these models from our analysis, since they consistently achieved worse predictive performance than QLk in our previous comparison.
In this section, we describe this paper's first contribution, our formal framework for parameter estimation, along with the experimental data and estimation techniques we used.
We begin by noting that any behavioral game theoretic model is a mapping from a game description G and a vector of parameters θ to a distribution over action profiles in G.
In other words, a given behavioral model provides us with a way of computing Pr(a | G, θ).
Our goal is to use this behavioral model in conjunction with our experimental data, D, to predict future behavior in a given game G.
The dataset may or may not contain examples of earlier play in G.
The model parameters need to be determined based upon the data.
There are two approaches that we can take.The frequentist approach, taken by Rogers et al. [17] and Wright and Leyton-Brown [22], is to compute a point estimatê θ of the model's parameters based on our dataset, and then usê θ to compute the prediction for new games.
That is, we use the modelPr(a | G, D) = Pr(a | G, ˆ θ).
(2)The Bayesian approach is to calculate a posterior distribution over parameter values Pr(θ | D), and then use this distribution to integrate out the parameter.
This yields the alternate modelPr(a | G, D) = Pr(a | G, θ) Pr(θ | D)dθ.
(3)Observe that Equation (2) can be seen as a special case of (3), where the posterior is a point mass atˆθatˆ atˆθ.We use the posterior distribution to analyze model parameters, which is an application of Bayesian estimation.
However, on our dataset, we have observed that the frequentist approach achieves better predictive performance than the Bayesian approach.
Thus, we use point estimation to compare performance between model variants.
We describe both approaches.
We use the maximum likelihood estimate of the parameters as our point estimate:ˆ θ = arg max θ Pr(D | θ).
Our dataset consists of a set D of observations di = (Gi, ai), indicating that an action profile ai was played in game Gi.
The likelihood of a single datapoint isPr(di | θ) = Pr(Gi, ai | θ).
By the chain rule (of probabilities), this is equivalent toPr(di | θ) = Pr(ai | Gi, θ) Pr(Gi | θ).
(4)We assume that θ and G are independent; i.e., we assume that Pr(Gi | θ) = Pr(Gi).
Intuitively, this means that we assume there is a single "true" parameter value θ * for all games, rather than a separate "true" θ G i for each game Gi.
This allows us to rewrite (4) asPr(di | θ) = Pr(ai | Gi, θ) Pr(Gi).
(5)We assume that the datapoints are independent, so the likelihood of the dataset is just the product of the likelihoods of the datapoints:Pr(D | θ) = d i ∈D Pr(di | θ).
(6)Substituting (5) into (6) gives usPr(D | θ) = d i ∈D Pr(ai | Gi, θ) Pr(Gi).
(7)The probabilities Pr(Gi) are constant with respect to θ, and can therefore be disregarded when maximizing likelihood:arg max θ Pr(D | θ) = arg max θ d i ∈D Pr(ai | Gi, θ).
We derive an expression for the posterior distribution Pr(θ | D) by applying Bayes' rule, where p0(θ) is the prior:Pr(θ | D) = p0(θ) Pr(D | θ) Pr(D) .
(8)Substituting in (7), the posterior distribution isPr(θ | D) = p0(θ) d i ∈D Pr(ai | Gi, θ) Pr(Gi) Pr(D) ,and since both Pr(Gi) and Pr(D) are constant with respect to θ,Pr(θ | D) ∝ p0(θ) d i ∈D Pr(ai | Gi, θ).
(9)Codename Source Games We analyzed data from nine experimental studies, summarized in Table 1; this expands beyond the six studies we considered in our previous work [22].
We also constructed a new dataset (Combo9) containing observations from all nine source datasets.
To ensure that each was equally represented, despite their differences in size, we included exactly 400 observations from each dataset (sampled uniformly without replacement).
The precision parameter for quantal response is not scale invariant.
That is, the correct value of λ can differ depending upon the units in which payoffs are expressed.
To ensure consistent estimation of precision parameters, we renormalized all games so that their payoffs were in expected cents.
For all of the models we considered, we used a flat prior for the parameters.
Although this prior is improper, it results in a correctly-normalized posterior distribution; the posterior distribution in this case reduces to the likelihood [8].
We computed the posterior distribution for the single-parameter Poisson-CH model by grid sampling.
That is, we computed the likelihood of the Combo9 dataset for each value of τ ∈ {0.01k | k ∈ N, 0 ≤ 0.01k ≤ 10}, and then normalized by the sum of the likelihoods.The QLk model has five parameters, and is therefore too high dimensional to grid sample efficiently; approximately 5 × 10 12 samples would have been required for a grid of the same granularity as we used for Poisson-CH!
Instead, for QLk-and the other high dimensional models introduced in Section 5-we used a sequential Monte Carlo technique called annealed importance sampling, or AIS [14].
AIS allows for efficient sampling from high dimensional distributions, similarly to Markov Chain Monte Carlo (MCMC) techniques.
However, each sample point generated using AIS is independent, so AIS does not exhibit the randomwalk behavior that can plague MCMC samplers.
Briefly, the annealed importance sampling procedure is as follows.
A sample #» θ 0 is drawn from an easy-to-sample-from distribution P0.
For each Pj in a sequence of intermediate distributions P1, . . . , Pr−1 that become progressively closer to the posterior distribution, a sample #» θ j is generated by drawing a sample #» θ from a proposal distribution Q(· | #» θ j−1), and accepted with probabilityPj( #» θ )Q( #» θ j−1 | #» θ ) Pj( #» θ j−1)Q( #» θ | #» θ j−1) .
(10)Ifthe proposal is accepted, #» θ j = #» θ ; otherwise, #» θ j = #» θ j−1.
We repeat this procedure multiple times, and report the distribution of the resulting #» θ r values, with each #» θ r 's contribution weighted according toP1( #» θ 0)P2( #» θ 1) P0( #» θ 0)P1( #» θ 1) · · · Pr−1( #» θ r−2)Pr ( #» θ r−1) Pr−2( #» θ r−2)Pr−1( #» θ r−1) .
(11)For the initial sampling distribution P0, we used a product distribution over the population proportions parameters and the precision parameters.
For the population proportion parameter components we used a Dirichlet distribution Dir(1, 1, 1); this is equivalent to uniformly sampling over the simplex of all possible combinations of population proportions.
For the precision parameter components we used the renormalized non-negative half of a univariate Gaussian distribution N (0, 2 2 ) for each precision parameter; this gives a distribution that is decreasing in precision (on the assumption that higher precisions are less likely than lower ones), and with a standard deviation of 2, which was large enough to give a non-negligible probability to most previous precision estimates.The proposal distribution was a product distribution "centered" at the current value, with proportion parameters #» α sampled from Dir(20 #» αj−1), and each precision parameter λ sampled from N (λj−1, 0.2 2 ) (truncated at 0 and renormalized).
The "hyperparameters" for the Dirichlet distribution (20) and the precision distributions (0.2 2 ) were chosen by trial and error on a small subset of the data to make the acceptance rate near to the standard heuristic value of 0.5 [16].
We used 200 intermediate distributions of the formPj( #» θ ) = Pr( #» θ | D) γ j ,with the first 40 γj's spaced uniformly from 0 to 0.01, and the remaining 160 γj's spaced geometrically from 0.01 to 1, as in the original AIS description [14].
We performed 5 Metropolis updates in each distribution before moving to the next distribution in the chain.
For the model performance comparisons in Section 5, we computed the parameter point-estimates using the NelderMead simplex algorithm [15].
To reduce the danger of getting caught in a local minimum, we repeated the optimization from 500 random starting points, and chose the value which gave the highest log likelihood.
In this section, we describe the results of our analysis of posterior distributions for the two models defined in Section 2.
We start by comparing the posterior distribution for the Poisson-CH model's parameter to a previously published recommendation.
We then turn our attention to the QLk model, whose posterior distribution exposes several possible issues with the model.
Camerer et al. [3] recommended setting the τ parameter of the Poisson-CH model to 1.5.
Figure 1 gives the cumulative posterior distribution over τ for each of our datasets.
Overall, our analysis strongly contradicts Camerer et al.'s recommendation.
On Combo9, the posterior probability of 0.51 ≤ τ ≤ 0.59 is more than 99%.
Every other source dataset had a wider high posterior density region than Combo9 (indicated by the higher slope of Combo9's cumulative density [19] dataset (SW94) appears to support Camerer et al.'s recommendation (median 1.43).
However, SW94 appears to be an outlier; its high posterior density region is wider than the other distributions, and the distribution is very multimodal, likely due to SW94's small size.
Figure 2 gives the marginal cumulative posterior distributions for each of the parameters of the QLk model.
(That is, we computed the five-dimensional posterior distribution, and then extracted from it the five marginal distributions shown here.)
We found these distributions surprising for several reasons.
First, the models predict many more level-2 agents than level-1 agents.
In contrast, it is typically assumed that higher level agents are scarcer, as they perform more complex strategic reasoning.
Even more surprisingly, the model predicts that level-1 agents should have much higher precisions than level-2 agents.
This is odd if the level-2 agents are to be understood as "more rational"; indeed, precision is sometimes interpreted as a measure of rationality [e.g., see 21,7].
Third, the distribution of λ 1(2) , the precision that level-2 agents ascribe to level-1 agents, is very concentrated around very small values ([0.023, 0.034]).
This differs by two orders of magnitude from the "true" value of λ1, which is quite concentrated around its median value of 3.1.
Finally, the median value of λ1 (3.1) is more than 17 times larger than that of λ2 (0.18).
It seems unlikely that level-1 agents would be an order of magnitude more sensitive to utility differences than level-2 agents.
One interpretation is that the QLk model is essentially accurate, and these parameter values simply reflect a surprising reality.
For example, the low precision of level-2 agents and the even lower precision that they (incorrectly) ascribe to the level-1 agents may indicate that two-level strategic reasoning causes a high cognitive load, which makes agents more likely to make mistakes, both in their own actions and in their predictions.
The main appeal of this explanation is that it allows us to accept the QLk model's strong performance at face value.An alternate interpretation is that QLk fails to capture some crucial aspect of experimental subjects' strategic reasoning.
For example, if the higher-level agents reasoned about all lower levels rather than only one level below themselves, then the low value of λ 1(2) could predict well because it "simulates" a model where level-2 agents respond to a mixture of level-0 and level-1 agents.
We investigate this second possibility in the next section.
In this section, we investigate the properties of the QLk model by evaluating the predictive power of a family of systematic variations of the model.
In the end, we identify a simpler model that dominates QLk on our data, and which also yields much more reasonable marginal distributions over parameter values.Specifically, we constructed a family of models by extending or restricting the QLk model along four different axes.
QLk assumes a maximum level of 2; we varied this by considering maximum levels of 1 and 3 as well.
QLk has inhomogeneous precisions in that it allows each level to have a different precision; we varied this by also considering homogeneous precision models.
QLk allows general precision beliefs that are not restricted to be accurate; we also constructed models that make the simplifying assumption of accurate precision beliefs about lower levels' precisions.
Finally, in addition to Lk beliefs, where all other agents are assumed by a level-k agent to be level-(k − 1), we also constructed models with CH beliefs, where agents believe that the population consists of the true, truncated distribution over the lower levels.
We evaluated each combination of axis values; the 17 resulting models 2 are listed in the first part of Table 2.
In addition to the 17 exhaustive axis combinations for models with maximum levels in {1, 2, 3}, we also evaluated 12 additional axis combinations that have higher maximum levels and 8 parameters or fewer: ai-QCH4 and aiQLk4; ah-QCH and ah-QLk variations with maximum levels in {4, 5, 6, 7}; and ah-QCH and ah-QLk variations that assume a Poisson distribution over the levels rather than using an explicit tabular distribution.
These additional models are listed in the bottom part of Figure 3: Model simplicity (number of parameters) versus prediction performance.
QLk1, which has far lower performance than the other models, is omitted for scaling reasons.We evaluated the predictive performance of each model on the Combo9 dataset using 10-fold cross-validation repeated 10 times, as in [22].
The results are given in the last column of Table 2, and plotted in Figure 3.
Performance is measured by how much more likely the test data is according to the given model (with parameters chosen based on a training dataset, separate from the test set) than it is according to assuming that actions are chosen uniformly at random (u.a.r.).
E.g., the test data is 10 18.37 times more likely according to the QLk1 model's prediction than according to a uniform random prediction.All else being equal, a model with higher performance is more desirable, as is a model with fewer parameters.
We can plot an "efficient frontier" of models with the (statistically significant) highest performance for a given number of parameters or fewer; see Figure 3.
The original QLk (gi-QLk2) is not efficient in this sense; it is dominated by ah-QCH3, which has significantly better predictive performance even though it has fewer parameters (due to restricting agents to homogeneous precisions and accurate beliefs).
Our analysis thus argues that the flexibility added by inhomogeneous precisions and general precision beliefs is less important than the number of levels and the choice of population belief.Conversely, the poor performance of the Poisson variants relative to ah-QCH3 suggests that flexibility in describing the level distribution is more important than the total number of levels modeled.
Figure 4 shows the marginal posterior level weight distributions for all four models on the efficient frontier.
There is broad agreement among all models on the proportion of level-0 agents.
However, in order to get the "right" number of level-0 agents, ah-QCHp (which models the level distribution as a Poisson) must place a great deal of weight on level-1 agents as well; in contrast, the tabulardistribution models all select bimodal distributions that assign relatively little weight to level-1 agents, and more to higher-level agents (level-2 and higher).
In fact, there is a pattern in the models along the efficient frontier: this set consists exclusively of models with accurate precision beliefs, homogeneous precisions, and cognitive hierarchy beliefs.
3 This suggests that the most parsimonious way to model human behavior in normal-form games is to use a model of this form, with the tradeoff between simplicity (i.e., number of parameters) and predictive power determined solely by the number of levels modeled.To test the extent of the simplicity/power tradeoff in this family of models, we also evaluated ah-QCH4, ah-QCH5, ah-QCH6, and ah-QCH7, and for comparison purposes also evaluated every other model in our design space having 8 or fewer parameters.
For the Combo9 dataset, adding additional levels yielded small increases in predictive power until level 5, after which it yielded no further, statistically significant improvements.
Thus, Figure 3 includes ah-QCH4 and ah-QCH5 as part of the efficient frontier.Overall, we recommend that practitioners seeking a model for predicting human behavior in simultaneous-move games use a member of the ah-QCH family.
How to model the distribution of levels is less clear.
Of the models we considered, we recommend ah-QCH3.
While it is possible to achieve gains in performance on our (large) dataset by modeling additional levels, these gains are small.
Specifically, the gain in Pop'n Beliefs Precisions Prec.
Beliefs # Log-likelihood vs. u.a.r. 1 n/a n/a n/a 2 18.37 ± 0.12 gi-QLk2 2 Lk inhomo.
general 5 29 prediction from adding two parameters to ah-QCHp to yield ah-QCH3 was more than twice as great as was the gain in prediction from adding two parameters to ah-QCH3 to yield ah-QCH5.
Since more complex models are more prone to over-fitting-particularly with smaller amounts of data-we believe that ah-QCH3 offers the best tradeoff between robustness and experimental performance.
A practitioner working with a large dataset and interested in maximal prediction quality might also investigate ah-QCH5.
Another possibility, which we have begun to explore in our current work, is to use a parametric distribution of levels whose shape is a better match to the experimental data than the Poisson distribution.
We are now in a position to answer some of the questions from Section 4.2 by examining marginal posterior distributions from a member of our new model family, plotted in Figure 5.
We first note that, in contrast to QLk's multimodal, jagged parameter CDFs, the parameter CDFs for ah-QCH3 are smooth and (nearly) unimodal.
This suggests that ah-QCH3 is a much more robust model; its prediction quality is less likely to change drastically as a result of small changes in parameter values.Second, the posterior distribution for the precision parameter λ is concentrated around 0.20, which is very close to the QLk model's estimate for λ2.
This suggests that QLk's much lower estimate for λ 1(2) may have been the closest that the model could get to having the level-2 agents best respond to a mixture of level-0 and level-1 agents (as in cognitive hierarchy).
It is unclear whether the order-of-magnitude differences and counterintuitive ordering of λ1 and λ2 are similar effects where QLk's parameters are set in a way that "simulates" the assumptions of a more accurate model.
Interestingly, like QLk, the ah-QCH3 model predicts more level-2 agents than level-1.
In fact, the ah-QCH3 model predicts even fewer level-1 agents than QLk.
This provides some support for QLk's seemingly counterintuitive prediction that level-1 agents are less common than more sophisticated types.
We showed how Bayesian parameter analysis can be used to gain understanding about the sensitivity of behavioral game theoretic models to their parameters.
We derived concrete recommendations for the use of an existing model, Poisson-CH, which differed substantially from advice in the literature.
We also uncovered anomalies in the best-performing existing model (QLk) that led us to a new, simpler, betterperforming model (ah-QCH3).
More broadly, the family of accurate, homogeneous-precision QCH models allows the modeler to trade off complexity against performance along an efficient frontier of models simply by adjusting the model of the distribution of levels.In our ongoing work, we are now investigating parametric distributions of levels that match the observed distribution of levels.
This would permit a model that uses higher levels, thus yielding higher performance, without requiring more parameters.
Other promising directions include exploring applications of ah-QCH models for modeling behavior in practical settings such as markets or bargaining, and applying Bayesian analysis to additional behavioral models.
