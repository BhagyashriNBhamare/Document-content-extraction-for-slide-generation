We consider various stochastic models that incorporate the notion of risk-averseness into the standard 2-stage recourse model, and develop novel techniques for solving the algorithmic problems arising in these models.
A key notable feature of our work that distinguishes it from work in some other related models, such as the (standard) budget model and the (demand-) robust model, is that we obtain results in the black-box setting, that is, where one is given only sampling access to the underlying distribution.
Our first model, which we call the risk-averse budget model, incorporates the notion of risk-averseness via a probabilistic constraint that restricts the probability (according to the underlying distribution) with which the second-stage cost may exceed a given budget B to at most a given input threshold ρ.
We also a consider a closely-related model that we call the risk-averse robust model, where we seek to minimize the first-stage cost and the (1 − ρ)-quantile (according to the distribution) of the second-stage cost.
We obtain approximation algorithms for a variety of combinatorial optimization problems including the set cover, vertex cover, multicut on trees, and facility location problems, in the risk-averse budget and robust models with black-box distributions.
Our main contribution is to devise a fully polynomial approximation scheme for solving the LP-relaxations of a wide-variety of risk-averse budgeted problems.
Complementing this, we give a simple rounding procedure that shows that one can exploit existing LP-based approximation algorithms for the 2-stage-stochastic and/or deterministic counterpart of the problem to round the fractional solution and obtain an approximation algorithm for the risk-averse problem.
To the best of our knowledge, these are the first approximation results for problems involving probabilistic constraints and black-box distributions.
A notable feature of our scheme is that it extends easily * cswamy@math.uwaterloo.ca.
Dept. of Combinatorics and Optimization, Univ.
Waterloo, Waterloo, ON N2L 3G1.
Supported in part by NSERC grant 32760-06.
to handle a significantly richer class of risk-averse problems , where we impose a joint probabilistic budget constraint on different components of the second-stage cost.
Consequently, we also obtain approximation algorithms in the setting where we have a joint budget constraint on different portions of the second-stage cost.
Stochastic optimization models provide a means to model uncertainty in the input data where the uncertainty is modeled by a probability distribution over the possible realizations of the actual data, called scenarios.
An important and widely-used model is the 2-stage recourse model: first, given the underlying distribution over scenarios, one may take some first-stage actions to construct an anticipatory part of the solution, x, incurring an associated cost c(x).
Then, a scenario A is realized according to the distribution, and one may take additional second-stage recourse actions y A incurring a certain cost f A (x, y A ).
The goal in the standard 2-stage model is to minimize the total expected cost, c(x) + E A f A (x, y A ) .
Many applications come under this setting.
An oft-cited motivating example is the 2-stage stochastic facility location problem.
A company has to decide where to set up its facilities to serve client demands.
The demand-pattern is not known precisely at the outset, but one does have some statistical information about the demands.
The first-stage decisions consist of deciding which facilities to open initially, given the distributional information about the demands; once the client demands are realized according to this distribution, we can extend the solution by opening more facilities, incurring their recourse costs.
The recourse costs are usually higher than the original ones (e.g., because opening a facility later involves deploying resources with a small lead time), could be different for the different facilities, and could even depend on the realized scenario.A common criticism of the standard 2-stage model is that the expectation measure fails to adequately measure the "risk" associated with the first-stage decisions: two solutions with the same expected cost are valued equally.
But in realistic settings, one also considers the risk involved in the decision.
For example, in the stochastic facility location problem, given two solutions with the same expected cost, one which incurs a moderate second-stage cost in all scenarios, and one where there is a non-negligible probability that a "disaster scenario" with a huge associated cost occurs, a company would naturally prefer the former solution.Our models and results.We consider various stochastic models that incorporate risk-averseness into the standard 2-stage model and develop novel techniques for solving the algorithmic problems arising in these models.
A key notable feature of our work that distinguishes it from work in some other related models [21,11], is that we obtain results in the black-box setting, that is, where one is given only sampling access to the underlying distribution.
To better motivate our models, we first give an overview of some related models considered in the approximation-algorithms literature that also embody the idea of risk-protection, and point out why these models are ill-suited to the design of algorithms in the black-box setting.One simple and natural way of providing some assurance against the risk due to scenario-uncertainty is to provide bounds on the second-stage cost incurred in each scenario.
Two closely related models in this vein are the budget model, considered by Gupta, Ravi and Sinha [21], and the (demand-) robust model, considered by Dhamdhere, Goyal, Ravi and Singh [11].
In the budget model, one seeks to minimize the expected total cost subject to the constraint that the secondstage cost f A (x, y A ) incurred in every scenario A be at most some input budget B. (In general, one could have scenario-dependent budgets, but for simplicity we focus on the uniform-budget model.)
Gupta et al. considered the budget model in the polynomial scenario setting, where one is given explicitly a list of all scenarios (with non-zero probability) and their probabilities, thereby restricting their attention to distributions with a polynomial-size support.
In the robust model considered by Dhamdhere et al. [11], which is more in the spirit of robust optimization, the goal is to minimize c(x) + max A f A (x, y A ).
It is easy to see how the two models are related: if one "guesses" the maximum second-stage cost B incurred by the optimum, then the robust problem essentially reduces to the budget problem with budget B; that is, one can use an approximation algorithm for the budget problem to obtain a nearoptimal solution to the robust problem: scaling down the second-stage costs (and B) to make the second-stage contribution negligible) makes the objective functions of the budget and robust problems essentially identical (modulo the constant term B).
Notice that it is not clear how to even specify problems with exponentially many scenarios in the robust model.
Feige et al. [14] expanded the model of [11] by considering exponentially many scenarios, where the scenarios are implicitly specified by a cardinality constraint.
But this seems rather specialized, especially in the context of stochastic optimization; e.g., in facility location, it is rather stylized (and overly conservative) to assume that every set of k clients (for some k) may show up in the second-stage.
We will consider a more general way of specifying (exponentially many) scenarios in robust problems, where the input specifies a black-box distribution and the collection of scenarios is then given by the support of this distribution.
We shall call this model the distributionbased robust-model.
Both the budget and the (distribution-based) robust model suffer from certain common drawbacks.
A serious algorithmic limitation (see Section 7) is that for almost any (non-trivial) stochastic problem (e.g., fractional stochastic set cover with at most 3 {elements,sets,scenarios}), one cannot obtain any approximation guarantees in the black-box setting using any bounded number of samples (even allowing for a bounded budget inflation).
Intuitively, this is because there could be scenarios that occur with vanishingly small probability that one will almost never encounter in our samples, but which essentially force one to take certain first-stage actions in order to satisfy the budget constraints in the budget model, or obtain a lowcost solution in the robust model.
Notice also that both models adopt the conservative view that one needs to bound the second-stage cost in every scenario, regardless of how likely it is for the scenario to occur.
In contrast, risk-models considered in the finance and stochastic-optimization literature, such as the mean-risk model [29], value-at-risk (VaR) [31,25,33], conditional VaR [35], do factor in the probabilities of different scenarios.Our models for risk-averse stochastic optimization address the above issues, and significantly refine and extend the budget and robust models.
Our goal is to come up with a model that is sufficiently rich in modeling power to allow for black-box distributions, and in which one can obtain strong algorithmic results.
Our models are motivated by the observation that it is possible to obtain approximation guarantees in the budget model with black-box distributions, if one allows the second-stage cost to exceed the budget with some "small" probability ρ.
We can now incorporate this solution concept into the model to arrive at the following new budget model, which we call the risk-averse budget model.
We are now given a probability threshold ρ ∈ [0, 1] and a budget B, and we seek (x, {y A }) so as to minimize c(x)+E A f A (x, y A ) subject to the probabilistic constraint Pr A [f A (x, y A ) > B] ≤ ρ.
The corresponding risk-averse (distribution-based) robust model seeks to minimize c(x) + Q ρ [f A (x, y A )], where Q ρ [f A (x, y A )]is the (1−ρ)-quantile of {f A (x, y A )} A∈A (i.e., the smallest B such that Pr A [f A (x) > B] ≤ ρ).
Notice that ρ allows us to control the risk-aversion level and tradeoff risk-averseness against conservatism (as in [41]).
Taking ρ = 1 in the risk-averse budget model gives the standard 2-stage recourse model, and ρ = 0, yields the (standard) budget-and robust models.
In the sequel, we treat ρ as a constant that is not part of the input.We obtain approximation algorithms for a variety of combinatorial optimization problems (Section 5) including the set cover, vertex cover, multicut on trees, and facility location problems, in the risk-averse budget and robust models with black-box distributions.
We obtain near-optimal solutions that preserve the budget approximately and incur a small blow-up of the probability threshold.
(One should expect to inflate the budget; otherwise, by setting very high first-stage costs, one would be able to solve the decision version of an NP-hard problem!)
To the best of our knowledge, these are the first approximation results for problems with probabilistic constraints and black-box distributions.
Our results extend to various more general settings, the most noteworthy one being where we have a joint budget constraint on different portions of the second-stage cost.
We can also handle non-uniform scenario-budgets, and a generalization where the goal is to minimize c(x) plus a weighted combination of E A f A (x, y A ) and Q ρ [f A (x, y A )].
We mainly consider risk-averse budgeted problems in the sequel, since (as in the case of the (standard) budget-and robust-problems) the risk-averse robust problem reduces to the risk-averse budgeted problem (see Sections 4.1 and 5).
Our results are built on two components.
First, and this is the technically more difficult component and our main contribution, we devise a fully polynomial approximation scheme for solving the LP-relaxations of a wide-variety of risk-averse problems (Theorem 4.3).
We show that in the black-box setting, for a wide variety of 2-stage problems, for any , κ > 0, in time poly λ κρ , one can compute (with high probability) a solution to the LP-relaxation of the risk-averse budgeted problem, of cost at most (1+) times the optimum where the probability that the second-stage cost exceeds the budget B is at most ρ(1 + κ).
Here λ is the maximum ratio between the costs of the same action in stage II and stage I (e.g., opening a facility or choosing a set).
We show in Section 7 that the dependence on 1 κρ , is unavoidable in the black-box setting (as is the dependence on λ [46]).
One major difficulty faced in solving a probabilistic program such as ours, which one does not encounter for 2-stage problems, is that the feasible region of even the fractional risk-averse problem (i.e., where one can take fractional decisions) is a non-convex set.
Thus, even in the polynomial-scenario setting, it is not clear how to solve (even) the fractional risk-averse problem (in fact, this is often NP-hard).
We formulate an LP-relaxation (of even the fractional problem), where for every scenario A, we introduce a variable r A , to indicate whether the budget is exceeded in that scenario, along with two sets of decision variables to denote the decisions taken in these two cases, and impose the constraint A p A r A ≤ ρ (in addition to various problem-specific constraints).
This constraint however couples the different scenarios (notice again the contrast with the standard 2-stage recourse model), and to get around this difficulty, we use a Lagrangianrelaxation approach, where we decouple the scenarios by Lagrangifying this coupling constraint; Section 2 gives a more detailed outline of our algorithm.
A key notable feature of our scheme (and the Lagrangian-relaxation approach) is that it extends easily to handle a richer class of risk-averse problems, where we impose a joint probabilistic budget constraint on different components of the second-stage cost (e.g., facility-and assignmentcosts in risk-averse facility location).
The second component is a simple, general rounding procedure (Theorem 4.1) complementing the above scheme.
We round an LP-solution to a solution to the fractional risk-averse problem losing a certain factor in the solution cost, budget, and probability of budgetviolation.
This then allows us to use suitable LP-based algorithms for the deterministic or (non-risk-averse) 2-stage analogue of the problem to obtain a near-optimal solution to the (integer) risk-averse problem.
For example, for various covering problems, given an LP-based c-approximation algorithm for the deterministic analogue, we obtain an O(c)-approximation for the riskaverse problem using the 2c-approximation algorithm for the 2-stage problem in [38].
Our techniques, and in particular, our scheme, yield versatile tools that we believe will find application in the design of approximation algorithms for other risk-averse problems and probabilistic programs.Related work.
Stochastic optimization is a field with a vast amount of literature; (see, e.g., [3,31,36]), but these problems have only recently been studied from an approximation-algorithms perspective.
We survey the work that is most relevant to ours.
Various approximation results have been obtained in the 2-stage recourse model, but more general models, such as riskoptimization or probabilistic-programming models have received little or no attention.
As mentioned earlier, the (standard) budget model was first considered by Gupta et al. [21], who designed approximation algorithms for stochastic network design problems in this model, and Dhamdhere et al. [11] introduced the demand-robust model (which we call the robust model), obtaining algorithms for the robust versions of various combinatorial optimization problems (and [18] obtains certain improvements).
All these works focus on the polynomialscenario setting.
Feige et al. [14], and subsequently [26], considered the robust model with exponentially many scenarios that are specified implicitly via a cardinality constraint, and derived approximation algorithms in this more general model.There is a large body of work in the finance and stochastic-optimization literature, dating back to [29], that deals with risk-modeling and optimization; see e.g., [35,37] and the references therein.
Our riskaverse models are related to some models in finance.
In fact, the probabilistic constraint that we use is called a value-at-risk (VaR) constraint in the finance literature, and its use in risk-optimization is quite popular in finance models; it has even been written into some industry regulations [25,33].
Problems involving probabilistic constraints are called probabilistic or chanceconstrained programs [8] in the stochastic-optimization literature, and have been extensively studied (see, e.g., [32]).
Some recent work [5,30,13] has focused on replacing the probabilistic constraint by more tractable ones so that any solution satisfying the new constraints also satisfies the original probabilistic constraint with high probability.
Notice that this type of "relaxation" is opposite to what one aims for in the design of approximation algorithms.
Although some approximation results are obtained in [5,30,13], they are obtained under various restrictions on the random variables (continuous) and distribution (concentration-of-measure), which are not satisfied by discrete problems.
To the best of our knowledge, there is no prior work in this literature on the design of efficient algorithms with provable worst-case guarantees for discrete risk-optimization or probabilistic-programming problems.In the CS literature, [27,16] consider stochastic bin packing and knapsack with probabilistic constraints and obtained novel approximation algorithms for these problems.
These results are however obtained for specialized distributions where the item sizes are independent random variables, which is far from the black-box setting.
So et al. [41] consider the problem of minimizing the first-stage cost plus a risk-measure called the conditional VaR (CVaR) [35] and obtain approximation algorithms for various problems in the blackbox setting (using quite different methods).
In their model, the fractional problem yields a convex program, and they are able to use a nice representation theorem in [35] to convert their problem into a 2-stage problem and then adapt the methods in [6].
In our case, the non-convexity inherent in the probabilistic constraint creates various difficulties and we consequently need to work harder to obtain our result.
Two recent unpublished manuscripts- [17], which is independent of our work, and [1], which appeared after a preliminary version of our work [44] appeared on the arXiv (and cites [44])-also consider probabilistic constraints, but in (specialized) non-black-box settings.
Their problems fall into our risk-averse models, so in various cases, our general results yield guarantees for their specific problems.
Goyal and Ravi [17] observe that approximating even one-stage problems is "hard" even when scenarios consist of only two "elements", and proceed to consider various one-element-per-scenario (1-PS) problems (in the poly-scenario setting).
One-stage problems can be cast as 2-stage risk-averse budgeted problems by setting B = 0 and negligible (but positive) second-stage costs, so our results in Section 6 for 1-PS problems also apply to their problems.
Agrawal et al. [1] consider, in our terminology, the one-stage and two-stage stochastic versions of set-cover and k-center in the independentactivation (IA) model.
By exploiting independence, [1] design algorithms for stochastic k-center and one-stage set-cover that do not inflate the budget or ρ.
Section 6 shows that IA-problems (and a priori stochastic problems) can often be reduced to the 1-PS setting.
(We obtained these results after [1] appeared.)
We also note that their adaptive set-cover problem can be cast as riskaverse budgeted set cover and so in contrast to their negative result, our results imply a bicriteria decision algorithm that inflates the budget by O(ln n) and ρ by 2 (say) if the problem is feasible.The first approximation result for 2-stage recourse problems appears to be due to Dye, Stougie, and Tomasgard [12].
Starting with the work of Ravi and Sinha [34] and Immorlica et al. [24], which gave approximation algorithms for various 2-stage problems in the polynomial scenario and IA settings, various approximation results for 2-stage problems have been obtained; see, e.g., the survey [45].
Approximation algorithms in the black-box setting were first obtained by Gupta et al. [19], and subsequently by Shmoys and Swamy [38].
Multistage recourse problems in the black-box model were considered by [20,46]; both obtain approximation algorithms with guarantees that deteriorate with the number of stages.
Srinivasan [42] obtained improved guarantees for set cover and vertex cover that do not depend on the number of stages.Our approximation scheme makes use of the SAA method, which is an appealing method often used to solve stochastic problems.
The effectiveness of this method has been analyzed in [28,6,46].
Kleywegt et al. [28] prove a non-polynomial bound on the sample size required for general 2-stage problems.
Subsequently [6,46] obtained improved polynomial bounds for a large class of structured 2-stage problems.
The proof in [46], which also works for multistage programs, leverages approximate subgradients; our proof uses portions of their analysis.
The proof in [6] applies only to 2-stage programs, but shows that even approximate solutions to the SAA problem translate to approximate solutions to the original problem.2 Overview of our approachLet (RA-P): min h(x) := c(x) + E A f A (x) s.t. x ∈ F, Pr A [f A (x) > B] ≤ ρ, denote the (discrete) risk- averse problem,where F is the finite feasible region of first-stage decisions, f A (x) is the minimum value of f A (x, y A ) over all feasible recourse actions y A .
A natural sampling-based approach for attacking (RA-P), which we call the "direct sample average approximation (SAA) approach", is to sample a certain number of scenarios to estimate the scenario probabilities, and then solve the following SAA analogue of the problem (SA-P): minh(x) := c(x) + A p A f A (x) s.t. x ∈ F, Pr A [f A (x) > B] ≤ ρ := ρ(1 + κ).
Here p A is the frequency of scenario A, and Pr denotes the probability wrt.p.
One can generalize the arguments in [6], to show (see Theorem B.1) that if one constructs (SA-P) using poly I, λ κρ samples and can compute an α-approximate solutionˆxsolutionˆ solutionˆx to (SA-P), then, with high probability,h(ˆ x) ≤ α + O() · OPT (RA-P) and Pr A [f A (ˆ x) > B] ≤ ρ 1 + O(κ).
(Throughout, "with high probability" means that we can ensure a failure probability of δ with poly ln( 1 δ ) samples.)
Notice however that this only says thatˆxthatˆ thatˆx in conjunction with the optimal recourse solutions to each scenario A yields a solution of cost at most α + O() · OPT (RA-P) .
The recourse problem is often NP-hard, and so using a β-approximation algorithm for the recourse problem yields only a worse (αβ + )-approximation to the black-box problem.
This introduces an undesirable approximation gap between the poly-scenario SAA problem and the black-box true problem; e.g., for risk-averse budgeted set cover, this only yields an O(ln 2 n)-guarantee, whereas one can obtain an O(ln n)-guarantee.
Also, we still need to solve the poly-scenario risk-averse problem (SA-P), which is a challenging task, and remains challenging even if one moves to a fractional version of the problem (which would be one way of avoiding the issue of approximation gap, since the fractional recourse problem is easily solvable).
To circumvent these difficulties, we adopt a different approach where we directly attack the black-box problem (instead of approximating it via an SAA problem), and hence obtain matching performance guarantees for both black-box and poly-scenario problems.
Our approach also has the significant benefit that it also leads to approximation algorithms for more general risk-averse problems (see below).
Since even the fractional version of the problem is a non-convex optimization problem, we formulate an LP-relaxation of (even) the (fractional) black-box problem, where we introduce a variable r A for every scenario A intended to indicate if the budget is exceeded in scenario A, and impose the constraint A p A r A ≤ ρ to capture the probabilistic budget constraint.
This LP may have an exponential number of both variables and constraints (since both are indexed by scenarios), and moreover, the scenarios are now coupled by the above constraint.
To get around the difficulty posed by coupling, we Lagrangify the above constraint using a dual variable ∆ ≥ 0 to obtain a Lagrangian relaxation (LD), which has a structured 2-stage LP (2St-P) embedded in it.
Our goal now is to perform a search for the "right" value of ∆.
That is, we consider different values of ∆, computing, for each ∆, a near-optimal solution to (2St-P) (using say the SAA method), and then return the solution whose A p A r A is closest to ρ.
However, it turns out that the strong near-optimality guarantees obtained in [38,46,6] for the classes of 2-stage programs considered therein, where one obtains an FPTAS, do not apply to (2St-P); in particular, (2St-P) does not fall into the class of programs considered in [38,46], and the analysis in [38,46,6] only yields a super-polynomial sample size for obtaining a (1 + )-optimal solution to (2St-P) (see the discussion following Lemma 4.1).
The key insight here is to realize that aiming for a (1 + )-approximation is not the right notion of near-optimality for (P).
We make the crucial observation that one can instead obtain a (weak) "nearoptimality" guarantee for (P) (see Lemma 4.1) that (a) is weak enough that one can prove such a guarantee with polynomial sample size using the SAA method by leveraging the approximate-subgradients based analysis in [46], and (b) yet is strong enough that it can be exploited in the search for the "right" ∆.
Rounding this fractional solution yields (matching) approximation guarantees for various (poly-scenario and) blackbox risk-averse problems.A notable benefit of the Lagrangian-relaxation approach is that it is flexible enough to yield an approximation scheme for solving the LP-relaxation of a richer class of risk-averse problems, where there is a joint probabilistic budget constraint on different components of the second-stage cost.
For example, in risk-averse budgeted facility location, one can incorporate a constraint like Pr A [(total cost of A)> B, or (facility-cost of A)> B F , or (assignment-cost of A)> B C ] ≤ ρ (see "Facility location" in Section 5).
Obtaining an approximation result for this general risk-averse problem is significantly more challenging, due to the fact that the recourse action in a scenario is no longer determined solely by the first-stage decision (unlike before).
The "direct SAA approach" is ill-equipped to deal with this complication as its analysis crucially relies on the fact that given a first-stage decision x, both the SAA and true problems will take the same recourse action in a scenario, which is no longer true (and we do not have a good handle on the various choices available to the SAA and true problems).
In fact, an approach that decouples scenarios appears necessary to make any headway here.
Let u denote the 2 norm of u.The Lipschitz constant of a function f : R m → R is the smallest K such that |f (x) − f (y)| ≤ Kx − y.
We consider convex minimization problems min x∈P f (x), where P ⊆ R m + with P ⊆ B(0, R) = {x : x ≤ R} for a suitable R,and f is convex.Definition 3.1.
Let f : R m → R be a function.
We say that d ∈ R m is a subgradient of f at the point u if the inequality f (v) − f (u) ≥ d · (v − u) holds for every v ∈ R m .
We say thatˆdthatˆ thatˆd is an (ω, ξ)-subgradient [38] of f at the point u ∈ P if for every v ∈ P, we havef (v) − f (u) ≥ ˆ d · (v − u) − ωf (v) − ωf (u) − ξ.One can infer that, letting d x denote a subgradient of f at x, the Lipschitz constant of f is at most max x d x .
Let K > 0, and τ, > 0 be parameters withτ < 1.
Let N = log 2KR τ .
Let G τ ⊆ P be a discrete set such that for any x ∈ P, there exists x ∈ G τ with x−x ≤ τ KN .
Define G τ = G τ ∪ x+t(y −x), y +t(x− y) : x, y ∈ G τ , t = 2 −i , i = 1, . . . , N .
We call G τ and G τ , an τ KN -netand an extended τ KN -net respectively of P.
If P contains a ball of radius V (where V ≤ 1 without loss of generality), then one can construct G τ so that |G τ | = poly log( KR V τ ) [46].
The following result from [46], which we have adapted to our setting, will be our main tool for analyzing the SAA method.
f and f be two nonnegative convex functions with Lipschitz constant at most K such that at every point x ∈ G τ , there exists a vectorˆd vectorˆ vectorˆd x ∈ R m that is a subgradient of f (.)
and an8N , ξ 2N - subgradient of f (.)
at x. LetˆxLetˆ Letˆx = argmin x∈P f (x).
Then, f (ˆ x) ≤ (1 + ) min x∈P f (x) + 6τ + ξ.
Lemma 3.2.
(Chernoff-Hoeffding bound [23]) Let X 1 , . . . , X N be iid random variables with X i ∈ [0, 1] and µ = E X i .
Then, Pr 1 N i X i − µ > ≤ 2e −2 2 N .
4The risk-averse budgeted set cover problem:an illustrative example Our techniques can be used to efficiently solve the risk-averse versions of a variety of 2-stage stochastic optimization problems, both in the risk-averse budget and robust models.
In this section, we illustrate the main underlying ideas by focusing on the risk-averse budgeted set cover problem.
In the risk averse budgeted set cover problem (RSC), we are given a universe U of n elements and a collection S of m subsets of U .
The set of elements to be covered is uncertain: we are given a probability distribution {p A } A∈A of scenarios, where each scenario A specifies a subset of U to be covered.
The cost of picking a set S ∈ S in the first-stage is w I S , and is w A S in scenario A.
The goal is to determine which sets to pick in stage I and which ones to pick in each scenario so as to minimize the expected cost of picking sets, subject to Pr A [cost of scenario A > B] ≤ ρ, where ρ is a constant that is not part of the input.
Notice that the costs w A S are only revealed when we sample scenario A; thus, the "input size", denoted by I is O(m + n + S log w S + log B).
Let P = [0, 1] m .
For a point x ∈ P, define f A (x) to be the minimum value of w A · y A subject to S:e∈S y A,S ≥ 1 − S:e∈S x S for e ∈ A, and y A,S ≥ 0 for all S.
As mentioned in the Introduction, the set of feasible solutions to even the fractional risk-averse problem (where one can buy sets fractionally) is not in general a convex set.
We consider the following LPrelaxation of (even) the (fractional) problem.
Throughout we use A to index the scenarios in A, and S to index the sets in S.min S w I S x S + A,S p A w A S y A,S + w A S z A,S (RSCP) s.t.
A p A r A ≤ ρ (4.1) S:e∈S x S + y A,S + r A ≥ 1 ∀A, e ∈ A, (4.2) S:e∈S x S + y A,S + z A,S ≥ 1 ∀A, e ∈ A, (4.3) S w A S y A,S ≤ B ∀A (4.4) x S , y A,S , z A,S , r A ≥ 0 ∀A, S. (4.5)Here x denotes the first-stage decisions.
The variable r A denotes whether one exceeds the budget of B for scenario A, and the variables y A,S and z A,S denote respectively the sets picked in scenario A in the situations where one does not exceed the budget (so r A = 0) and where one does exceed the budget (so r A = 1).
Consequently, (4.4) ensures that the cost of the y A decisions does not exceed the budget B, and (4.1) ensures that the total probability mass of scenarios where one does exceed the budget is at most ρ.Let OPT denote the optimum value of (RSCP), which is at most the optimum value of fractional RSC.
We show (Theorem 4.3) that for any , κ > 0, one can efficiently compute a first-stage solution x and solutions(y A , z A , r A ) in every scenario A satisfying (4.2)-(4.5) such that w I · x + A p A w A · (y A + z A ) ≤ (1 + 2)OPT , and A p A r A ≤ ρ(1 + κ).
Complementing this, we give a simple rounding procedure (Theorem 4.1) based on the rounding theorem in [38] to convert a fractional solution to (RSCP) to an integer solution using an LPbased c-approximation algorithm for the deterministic set cover (DSC) problem, that is, an algorithm that returns a set cover of cost at most c times the optimum of the standard LP-relaxation for DSC.
We state our rounding theorem first, in order to better motivate our goal of solving (RSCP).
Theorem 4.1.
(Rounding) Let x, {(y A , z A , r A )} be a solution satisfying (4.2)-(4.5) of objective value C = w A · x + A p A w A · (y A + z A ), and let P = A p A r A .
Given any ε > 0, one can obtain(i) a solutionˆxsolutionˆ solutionˆx such that w I · ˆ x + A p A f A (ˆ x) ≤ 1 + 1 ε C and Pr A f A (ˆ x) > (1 + 1 ε )B ≤ (1 + ε)P ;(ii) an integer solution (˜ x, {˜y{˜y A }) of cost at most 2c 1 + 1 ε C such that Pr A w A ·˜y·˜y A > 2cB(1+ 1 ε ) ≤ (1+ε)P using an LP-based c-approximation algorithm for the deterministic set cover problem.
Moreover, we need only x to computê x and˜xand˜ and˜x, and can compute˜ycompute˜ compute˜y A given only˜xonly˜ only˜x (orˆxorˆ orˆx).
Proof.
SetˆxSetˆ Setˆx = 1 + 1 ε x.Consider any scenario A. Observe that (y A + z A ) yields a feasible solution to the second-stage problem for scenario A. Also, if r A < 1 1+ε , then 1 + 1 ε y A also yields a feasible solution.
Thus, we have f A (ˆ x) ≤ w A ·(y A +z A ) and if r A < 1 1+ε then we also havef A (ˆ x) ≤ 1 + 1 ε B.
So w I · x + A p A f A (ˆ x) ≤ 1 + 1 ε C and Pr A f A (ˆ x) > (1 + 1 ε )B ≤ A:r A ≥ 1 1+ε p A ≤ (1 + ε)P .
We can now roundˆxroundˆ roundˆx to an integer solution (˜ x, {˜y{˜y A }) using the Shmoys-Swamy [38] rounding procedure (which only needsˆxneedsˆ needsˆx) losing a factor of 2c in the first-and second-stage costs.
This proves part (ii).
Simple examples show that the 1+ 1 ε , 1+ε -tradeoff above is unavoidable (i.e., given our LP-relaxation (RSCP)); see Appendix A. Notice that a blow-up in the (cost and) budget is unavoidable, since the recourse problem for a scenario is an NP-hard problem.
So the main question is whether one can obtain a tradeofffree guarantee to the (fractional or integer) risk-averse problem in polytime, where the probability threshold violated by an arbitrarily small (1 + ε)-factor, and the cost and budget are inflated by a bounded (small) factor that is independent of ε.
We call x, {y A } a (c 1 , c 2 , c 3 )-solution if its cost is at most c 1 (optimum) and Pr A [f A (x, y A ) > c 2 B] ≤ c 3 ρ.
A (c 1 , c 2 )-scheme is an algorithm that for any ε > 0, returns a (c 1 , c 2 , 1 + ε)-solution in time poly I, 1 ε .
Theorem 4.2 (proved in Appendix A) shows that, even for fractional RSC in the polynomial-scenario setting, a tradeoff-free guarantee such as a (c 1 , c 2 )-scheme, would yield guarantees for the densest k-subgraph (DkS) problem and its minimization version MinDkS; this strengthens a result of [17].
Theorem 4.2.
A (c 1 , c 2 )-scheme for integer/fractional RSC (even in the polynomial-scenario setting) yields a c 1 -approximation algorithm for MinDkS, and hence, a 2c 2 1 -approximation algorithm for DkS.Solving the risk-averse problem (RSCP).
We now describe and analyze the procedure used to solve (RSCP).
First, we get around the difficulty posed by the coupling constraint (4.1) in formulation (RSCP) by taking the Lagrangian dual of (4.1) introducing a dual variable ∆.
This yields the following formulation, whose optimal value is also equal to OPT (this is easy to show using LP-duality).
max ∆≥0 −∆ρ + min x∈P h(∆; x) := w I · x + A p A g A (∆; x) (LD)where g A (∆; x) := minS w A S y A,S + z A,S + ∆r A s.t. (4.2) − (4.4), y A,S , z A,S , r A ≥ 0 for all S. (P) Let OPT (∆) = min x∈P h(∆; x).
So OPT = max ∆≥0 OPT (∆) − ∆ρ .
Let λ = max 1, max A,S (w A S /w I S ), which we assume is known.
The main result of this section is as follows.Theorem 4.3.
For any , γ, κ > 0, RiskAlg (see Fig. 1) runs in time poly I, λ κρ , log( 1 γ ), and returns with high probability a first-stage solution x, and a solution (y A , z A , r A ) in each scenario A, such that x, {(y A , z A , r A )} satisfy (4.2)-(4.5) and (i)w I · x + A p A w A · (y A + z A ) ≤ (1 + )OPT + γ; and (ii) A p A r A ≤ ρ(1 + κ).
Under the very mild assumption ( * ) that w I · x + f A (x) ≥ 1 for every A = ∅, x ∈ P, we can convert this guarantee into a (1 + 2)-multiplicative guarantee in the cost in time polyI, λ κ .
RiskAlg (, γ, κ) [ ≤ κ < 1; p (i) , cost (i) , (yA, zA, rA)are used only in the analysis.]
R1.
Fix ε = /6, ζ = γ/4, η = ρκ/16, σ = /6.
Consider the ∆ values ∆0, ∆1, . . . , ∆ k , where ∆0 = γ/4, ∆i+1 = ∆i(1 + σ) and k is the smallest value such that∆0(1 + σ) k ≥ UB.
Note that k = O ` log( UB γ )/σ ´ .
R2.
For each ∆i, construct the SAA problem minx∈P`b minx∈P` minx∈P`b h(∆; x) := w I · x + P A b pAgA(∆; x) ´ us- ing poly`I poly` poly`I, λ εη , log( ∆ i ζ ) ´samples (where b pA is the frequency of scenario A in the sampled set), and compute its optimal solution`x solution` solution`x (i) , {(y(i) A , z (i) A , r (i) A )} ´ (where (y (i) A , z (i) A , r (i) A ) is implicitly given).
By sampling n = 1 2(κ/8) 2 ρ 2 ln`4k ln`ln`4k δ ´ scenarios, for each i = 0, . . . , k, compute an estimate p (i) = P A b qAr (i) A of P A pAr (i) A , where bqA is the frequency of scenario A in the sampled set.
Let ρ = ρ(1 + 3κ/4).
R3.
If p (0) ≤ ρ then return x (0) as the first-stage solution.
[In scenario A, return (yA, zA, rA) = (y(0) A , z (0) A , r (0) A )].
R4.
Otherwise (i.e., p (0) > ρ ) find an index i such that p (i) ≥ ρ and p (i+1) ≤ ρ (we argue that such an i must exist).
Let a be such that a · p (i) + (1 − a)p (i+1) = ρ .
Return the first-stage solution x = a·x (i) +(1−a)x (i+1) .
[In scenario A, return the solution (yA, zA, rA) = a(y(i) A , z (i) A , r (i) A ) + (1 − a)(y (i+1) A , z (i+1) A , r (i+1) A).]
We show in Section 7 that the dependence on 1 κρ is unavoidable in the black-box model.
The "greedy algorithm" for deterministic set cover [10] is an LP-based ln n-approximation algorithm.
So using Theorems 4.1 and 4.3, for any , κ, ε > 0, we can efficiently compute a (c, c, 1 + κ + ε)-solution, where c = 2 ln n 1 + + 1 ε .
Algorithm RiskAlg is essentially a search procedure for the "right" value of ∆, wrapped around the SAA method, which is used in step (R2) to compute a "nearoptimal" solution to min x∈P h(∆; x) for any given ∆ ≥ 0.
As mentioned in Section 2, a key ingredient of the algorithm and analysis is to figure out a suitable notion of near-optimality to apply to the 2-stage problem min x∈P h(∆; x).
In particular, as discussed below, the results in [38,46,6] for structured 2-stage programs do not quite apply here, and obtaining an FPTAS for the problem is too strong a guarantee to aim for.The proofs in [38,46] require that one be able to compute an (ω, ξ)-subgradient of the objective function h(∆; .)
at any given point x for sufficiently small ω, ξ (see Lemma 3.1).
This can be done for their class of 2-stage programs since each component of the subgradient lies in an interval of the form [−wλ, w] and can hence be estimated up to an additive error of ωw using poly λ ω samples, which then yields an (ω, 0)-subgradient.
However, min x∈P h(∆; x) does not fall into the class of problems considered in [38,46]: for a subgradient d = (d S ) of h(∆; .)
, we can only say that d S ∈ [−w A S − ∆, w I S ], which prevents us from obtaining an (ω, ξ)-subgradient using polynomial sample size for a suitably small (ω, ξ).
(In particular, estimating d S within an additive error of ωw I S to obtain an (ω, ξ)-subgradient would require poly λ + ∆ ωw I S samples, and ∆/w I S need not be polynomially bounded.)
The proof in [6] shows that if Λ is such that g A (∆; x) − g A (∆; 0) ≤ Λw I · x for every A and x ∈ P, then poly I, Λ samples suffice to construct a suitable SAA problem.
But for our problem, we can only obtain the bound g A (∆; x)−g A (∆; 0) ≤ λw I ·x+∆, and ∆ might be large compared to w I · x.Lemma 4.1 states the precise (weak) approximation guarantee satisfied by the solution returned in step (R2).
The key insight underlying its proof (as elaborated in the analysis) is that since we allow for an additive error measured relative to ∆, it suffices to approximate each component d S of the subgradient within an additive error proportional to (w I S + ∆), and this requires only poly(λ) samples.Given Lemma 4.1, we argue that by considering polynomially many ∆ values that increase geometrically up to some upper bound UB, one can find efficiently some ∆ where the solution x, {(y A , z A , r A )} returned for ∆ is such that A p A r A is "close" to ρ.
However, this search procedure is complicated by the fact that we have two sources of error whose magnitudes we need to control: first, we only have an approximate solution x, {(y A , z A , r A )} for ∆, which also means that one cannot use any optimality conditions; second, for any ∆, we have only implicit access to the second-stage solutions {(y A , z A , r A )} computed by Lemma 4.1, so we cannot actually compute or use A p A r A in our search, but will need to estimate it via sampling.
We set UB = 16( S w I S )/ρ, so log UB is polynomially bounded.
Analysis.For the rest of this section, , γ, κ are fixed values given by Theorem 4.3.
We may assume ≤ κ < 1.
Lemma 4.1.
Using poly I, λ εη , log( ∆i ζ ) samples one can construct an SAA problem in step (R2) of RiskAlg, so that with high probability,x (i) satisfies h(∆ i ; x (i) ) ≤ (1 + ε)OPT (∆ i ) + η∆ i + ζ.We defer the proof of Lemma 4.1 to the end of the analysis.
Let γ = γ/4, β = κ/8.
Definep (i) = A p A r (i) A and cost (i) = h(∆ i ; x (i) ) = w I · x (i) + A p A g A (∆ i ; x (i) ).
By Lemma 3.2, Pr[∀i, |p (i) −p (i) | ≤ βρ] ≥ 1 − δ.Given Lemma 4.1, we assume that the high probability event "∀i, cost (i) ≤ (1+ε)OPT (∆ i )+η∆ i + ζ and |p (i) − p (i) | ≤ βρ" happens.Claim 4.1.
We have p (k) < ρ/2 and p (k) < ρ/2.
Proof of Theorem 4.3.
Let x be the first-stage solution returned by RiskAlg, and (y A , z A , r A ) be the solution returned for scenario A.
It is clear that (4.2)-(4.5) are satisfied.
Suppose first that p (0) ≤ ρ (so x = x (0) .)
Part (ii) of the theorem follows sincep (0) ≤ p (0) + βρ ≤ ρ(1 + κ).
Part (i) follows since w I · x (0) + A p A w A · (y (0) A + z (0) A ) ≤ h(γ ; x) ≤ (1 + ε)OPT (γ ) + ηγ + ζ ≤ (1 + ε)OPT + γ (1 + ε + η) + ζ.The last inequality is because for any ∆, we haveOPT (∆) ≤ OPT (0) + ∆ ≤ OPT + ∆.
Now suppose that p (0) > ρ .
In this case, there must exist an i such that p (i) ≥ ρ , and p (i+1) ≤ ρ because p (0) > ρ and p (k) < ρ (by Claim 4.1), so step C4 is well defined.
We again prove part (ii) first.
We haveA p A r A = a · p (i) + (1 − a)p (i+1) ≤ ρ + βρ ≤ ρ(1 + κ).
To prove part (i), observe that w I · x + A p A w A · (y A + z A ) ≤ a · cost (i) + (1 − a) · cost (i+1) − ∆ i a · p (i) + (1 − a) · p (i+1), which is at most(1 + ε) a · OPT (∆ i ) + (1 − a)OPT (∆ i+1 ) + η(a∆ i + (1 − a)∆ i+1 ) + ζ − ∆ i (ρ − βρ).
Now noting that ∆ i+1 = (1 + σ)∆ i , it is easy to see that OPT (∆ i+1 ) ≤ (1 + σ)OPT (∆ i ).
Also, ρ − βρ − η(1 + σ) ≥ (1 + ε + 2σ)ρ.
So the above quantity is at most (1 + ε + 2σ) OPT (∆ i ) − ∆ i ρ + ζ ≤ (1 + )OPT + γ.The running time is at most (k + 1) · polyI, λ εη , log( ∆ k ζ ) + O ln k β 2 ρ 2 , which is poly I, λ κ , log( 1 γ ) (plugging in ε, η, ζ, k).
Proof of multiplicative guarantee.
We show that by initially sampling roughly max{1/ρ, λ} times, with high probability, one can either determine that x = 0 is an optimal first-stage solution, or obtain a lower bound on OPT and then set γ appropriately in RiskAlg to obtain the multiplicative bound.
Recall that f A (x) is the minimum value of w A · y A over all y A ≥ 0 such that S:e∈S y A,S ≥ 1 − S:e∈S x S for e ∈ A. Call A = ∅ a null scenario.
Let q = A:A =∅ p A and α = min{ρ, 1/λ}.
Note that OPT ≥ q. LetˆzLetˆ Letˆz A be an optimal solution to f A (0).
Define a solution (¯ y A , ¯ z A , ¯ r A ) for scenario A as follows.
Set (¯ y A , ¯ z A , ¯ r A ) = (0, 0, 0) if A = ∅, and (0, ˆ z A , 1) if A = ∅.
We first argue that if q ≤ α, then 0, {(¯ y A , ¯ z A , ¯ r A )} is an optimal solution.
It is clear that the solution is feasible since A p A ¯ r A = q ≤ ρ.
To prove optimality, supposex * , {(y * A , z * A , r * A )}is an optimal solution.
Consider the solution where x = 0 and the solution for scenario A is (0, 0, 0) if A = ∅, and (0, z * A + y * A + x * , 1) otherwise.
This certainly gives a feasible solution.
The difference between the cost of this solution and that of the optimal solution is at most A:A =∅ p A w A · x * − w I · x * , which is nonpositive since w A ≤ λw I and q ≤ 1/λ.
It follows that setting z A = ˆ z A for a non-null scenario also gives an optimal solution.Let δ be the desired failure probability, which we may assume to be less than 1 2 without loss of generality.
We determine with high probability if q ≥ α.
We draw M = ln(1/δ) α samples and compute X =number of times a non-null scenario is sampled.
We claim that with high probability, if X > 0 then OPT ≥ LB = δ ln(1/δ) · α; in this case, we return the solution RiskAlg(, LB, κ) to obtain the desired guarantee.
Otherwise, if X = 0, we return0, {(¯ y A , ¯ z A , ¯ r A )} as the solution.
Let r = Pr[X = 0] = (1 − q) M .
So 1 − qM ≤ r ≤ e −qM .
If q ≥ ln 1 δ /M , then Pr[X = 0] ≤ δ,so with probability at least 1 − δ we say that OPT ≥ LB, which is true since OPT ≥ q ≥ α.
If q ≤ δ/M , then Pr[X = 0] ≥ 1 − δ and we return 0, {(¯ y A , ¯ z A , ¯ r A )} as the solution, which is an optimal solution since q ≤ α.
If δ/M < q < ln 1 δ /M , then we always return a correct answer since it is both true that OPT ≥ q > LB, and that 0, {(¯ y A , ¯ z A , ¯ r A )} is an optimal solution.
The proof has three parts.
First, we obtain an expression for the subgradients of h(∆; .)
and h(∆; .)
at x and prove the bound on the Lipschitz constant.
The subgradient of h(∆; .)
and h(∆; .)
at x is obtained from the optimal solutions to g A (∆; x) for every scenario A.
The dual of g A (∆; x) is given bymax e (α A,e + β A,e ) 1 − S:e∈S x S − B · θ A (D) s.t. e∈S (α A,e + β A,e ) ≤ w A S (1 + θ A ) ∀S, e∈S β A,e ≤ w A S ∀S, e α A,e ≤ ∆, α A,e , β A,e ≥ 0 ∀e, α A,e = β A,e = 0 ∀e / ∈ A.Here α A,e and β A,e are respectively the dual variables corresponding to the covering constraints (4.2) and (4.3), and θ A is the dual variable corresponding to (4.4).
Let (α * A , β * A , θ * A ) be an optimal dual solution to g A (∆; x).
As in [38], we then have that the vectors d x andˆdandˆ andˆd x with componentsd x,S = w I S − A p A e∈S α * A,e + β * A,e ˆ d x,S = w I S − A p A e∈S α * A,e + β *A,e , are respectively subgradients of h(∆; .)
and h(∆; .)
at x. Sincê d x and d x both have 2 norm at most λw I + |∆|, h(∆; .)
and h(∆; .)
have Lipschitz constant at most K = λw I + |∆|.
Next, we argue that if d is a subgradient of h(∆; .)
at some point x ∈ P, andˆdandˆ andˆd is a vector such that | ˆ d S − d S | ≤ ωw I S + ξ/2m for all S, thenˆdthenˆ thenˆd is an (ω, ξ)-subgradient of h(∆; .)
at x. Let y be any point in P.We have h(∆; y) − h(∆; x) ≥ ˆ d · (y − x) + (d − ˆ d) · (y − x).
The second term is at least S:d S ≤ ˆ d S (d S − ˆ d S )y S + S: ˆ d S >d S ( ˆ d S − d S )x S ≥ −ω S w I S y S + w I S x S − ξ ≥ −ωh(∆; y) − ωh(∆; x) − ξ.Recall from Section 3 that G τ ⊆ P is an extended τ KN -net of P, where N = log 2KR τ .
Weuse N = 8N 2 4λ ε + m η 2 ln 2|Gτ |m δ samples, which is poly I, λ εη , log( ∆ ζ ).
In the sequel, we set ω = ε/8N, ξ = η∆/2N .
Finally, we argue that with probability at least 1−δ, at every point x ∈ G τ , the vectorsˆdvectorsˆ vectorsˆd x and d x defined above are component-wise close; in particular, they satisfy | ˆ d x,S −d x,S | ≤ ωw I S +ξ/2m for all S and hence, ˆ d x is an (ω, ξ)-subgradient of h(∆; .)
at x.
So by Lemma 3.1, ifˆxifˆ ifˆx is a minimizer of h(∆; .)
over P, then = d x,S .
The sample size N is specifically chosen so that the Chernoff bound (Lemma 3.2) implies the claim about component-wise closeness with probability at least 1 − δ.h(∆; ˆ x) ≤ (1 + ε)OPT (∆) + η∆ + ζ, In the riskaverse robust set cover problem, the goal is to choose some sets x in stage I and some sets y A in each scenario A so that their union covers A, so as to min-imize w I · x + Q ρ [w A · y A ].
Recall that Q ρ [w A · y A ] is the smallest B such that Pr A [w A · y A > B] ≤ ρ.As mentioned in the Introduction, this problem can be essentially reduced to RSC by simply "guessing" B = Q ρ [w A · y A ] for an optimal solution.
We briefly describe this reduction here.
Let OPT Rob denote the optimum value of the fractional risk-averse robust problem min x∈P (w I · x + Q ρ [f A (x)]).
For a given B ≥ 0, we scale all the second-stage costs w A S and B by µ = γ λ P S w I S .
So the contribution from the second-stage cost to the objective function is now at most γ.
(Note that the "λ" for the resulting scaled problem is 1, so now the number of samples does not in fact depend on λ.)
Let OPT Rob (B) denote the optimum value of the resulting (RSCP) problem, which is a decreasing function of B. For any guess B ≥ 0, and any , γ, κ > 0, we can use RiskAlg to compute (nonnegative)x, {y A , z A , r A } in time polyI, 1 κρ , log( 1 γ ) satisfying (4.2)-(4.4) such that w I · x ≤ cost x, {(y A , z A , r A )} ≤ (1 + )OPT Rob (B) + γ and A p A r A ≤ ρ(1 + κ).
Let W be an upper bound on the optimum such that log W is polynomially bounded, e.g., W = S w I S .
We enumerate values of B in powers of (1 + ), starting at γ and ending at the smallest value that is at least W .
We use RiskAlg to compute a solution for each B, and return the one that minimizes w I · x + B. Let ¯ x, {¯ y A , ¯ z A , ¯ r A } ,· ¯ x + ¯ B ≤ w I · x + B ≤ (1 + )OPT Rob (B ) + (1 + )B * + 2γ ≤ (1 + )OPT Rob + 4γ.
We remark that the same ideas yield a similar guarantee for the LP-relaxation of a generalization of the problem, where we wish to minimize w I · x plus a weighted combination of E A w A · y A and Q ρ [w A · y A ].
We can convert the above guarantee into a purely multiplicative one, under the same assumption ( * ) stated in Theorem 4.3.
Let q = A =∅ p A .
Note that if q ≤ ρ, then OPT Rob = 0 and x = 0 is an optimal solution; otherwise OPT Rob ≥ 1.
Let δ be such that (1 + κ) δ ln(1/δ) ≤ 1.
Using ln(1/δ) ρ samples (where ρ is set in RiskAlg) we can determine with high probability if q ≤ ρ or if q > ρ.
In the former case, we return x = 0 and y A in scenario A where y A = 0 if A = ∅, and any feasible solution otherwise.
Note that w I · x + Q ρ [w A · y A ] = 0.
In the latter case, we set γ = , and execute the procedure detailed above to obtain a (1 + 5)-multiplicative guarantee.
Now one can use Theorem 4.1 as is to convert the obtained fractional solution x, {y A , z A , r A } into an integer solution, or a solution to the fractional riskaverse robust problem.
The budget-inflation can now be absorbed into the approximation ratio.
For any , κ, ε > 0, we obtain a fractional solutionˆxsolutionˆ solutionˆx such thatw I · ˆ x + Q ρ(1+κ+ε) [f A (ˆ x)] ≤ 1 + + 1 εOPT Rob , and an integer solution (˜ x, {˜y{˜y A }) such thatw I · ˜ x + Q ρ(1+κ+ε) [w A · ˜ y A ] ≤ 2c 1 + + 1 εOPT Rob using an LP-based c-approximation algorithm for deterministic set cover.
We now show that the techniques developed in Section 4 for risk-averse budgeted set cover can be used to obtain approximation algorithms for the risk-averse versions of various combinatorial-optimization problems such as covering problems-set cover, vertex cover, multicut on trees-and facility location.
This includes many of the problems considered in [19,38,11] in the standard 2-stage and demand-robust models.
In all the applications, the first step is to prove an analogue of Theorem 4.3, that is, argue that RiskAlg can be used to obtain a near-optimal solution to a suitable LP-relaxation of the problem.
(For facility location, we need to adapt the arguments slightly.)
The second step, which is more problem-specific, is to round the LP-solution to an integer solution.
Analogous to part (i) of Theorem 4.1, we first obtain a solution to the fractional risk-averse problem.
Given this, our task is now reduced to rounding a fractional solution to a standard 2-stage problem into an integral one.
For this latter step, one can use any "local" LP-based approximation algorithm for the 2-stage problem, where a local algorithm is one that preserves approximately the cost of each scenario.Our results are intended to illustrate that approximation guarantees developed for the deterministic or 2-stage version of the problem can be converted to analogous guarantees for the risk-averse budgeted problem once we have a near-optimal solution to the LPrelaxation of the risk-averse problem, and we have not sought to optimize the approximation factors.
Our approximation results also hold for non-uniform budgets, and translate to the risk-averse robust versions of our applications: an algorithm that returns a (c 1 , c 2 , c 3 )-solutionx, {y A } for the budgeted problem can be sued to obtain a solution to the robust problem where c(x) + Q ρ(1+c3) [f A (x, y A )] ≤ max{c 1 , c 2 } · OPT Rob .
We also achieve guarantees for the problem of minimizing c(x) plus a weighted combination of E A f A (x, y A ) andQ ρ [f A (x, y A )].5.1 Vertex cover and multicut on trees In the stochastic vertex cover problem, we are given a graph whose edges need to covered by vertices.
The edgeset is random and determined by a distribution; one needs to pick vertices in stage I and in each scenario so that their union forms a vertex cover for the edges revealed in the scenario.
In the stochastic multicut on trees problem, we are given a tree, and a (black-box) distribution over sets of s i -t i pairs; a feasible solution needs to choose edges in stage I and in each scenario such that the union of edges picked in stage I and in scenario A forms a multicut for the s i -t i pairs that are revealed in scenario A.
In the risk-averse budgeted versions of these problems we are given a budget B and threshold ρ, and the goal is to compute a minimumcost feasible solution such that Pr[second-stage cost > B] ≤ ρ.
Both problems are structured cases of riskaverse budgeted set cover, so one can formulate an LP-relaxation of the risk-averse problem exactly as in (RSCP) and by Theorem 4.3, obtain a near-optimal solution to the relaxation.
Since there is an LP-based 2-approximation algorithm for the deterministic versions of both problems, applying Theorem 4.1 yields the following guarantees.Theorem 5.1.
For any , κ, ε > 0, one can compute in polynomial time a 4(1 + + 1 ε ), 4(1 + + 1 ε ), 1 + κ + ε -solution for the risk-averse budgeted vertex cover and multicut on trees problems.
In the risk-averse budgeted facility location problem (RFL), we have a set of m facilities F, a client-set D, and a distribution over clientdemands.
For notational simplicity, we consider the case of {0, 1}-demands, so a scenario A ⊆ D simply specifies the clients that need to be assigned in that scenario.
We may open facilities in stage I or in a given scenario, and in each scenario A we must assign each client j ∈ A to a facility opened in stage I or in that scenario.
The costs of opening a facility i ∈ F in stage I and in a scenario A are f I i and f A i respectively; the cost of assigning a client j to a facility i is c ij , where the c ij 's form a metric.
The first-stage cost is the cost of opening facilities in stage I, and the cost of scenario A is the total facility-opening and client-assignment cost incurred in that scenario.
The goal is to minimize the total expected cost subject to the usual condition that Pr[second-stage cost > B] ≤ ρ.
We formulate the following LP-relaxation of the problem.
Throughout, i indexes the facilities in F and j the clients in D.
Here y i denotes the first-stage decisions.
Decisions (x A,ij , y A,i ) and (u A,ij , v A,i ) represent respectively the actions taken in scenario A when does not exceed the budget (r A = 0), and does exceed the budget (r A = 1).
Constraints (5.7)-(5.10) enforce that every client is assigned to an open facility (in both cases), and (5.11) is the budget constraint for a scenario.
Let OPT be the optimal value of (RFLP).
Given first-stage decisions y ∈ P := [0, 1] m , let A (y) be the minimum facility-location cost, over fractional solutions, incurred in scenario A to satisfy the clients in A.min i f I i y i + A⊆D p A i f A i y A,i + v A,i + j∈A,i c ij x A,ij + u A,ij (RFLP) s.t.
A p A r A ≤ ρ (5.6) i x A,ij + r A ≥ 1 ∀j ∈ A (5.7) i x A,ij + u A,ij ≥ 1 ∀j ∈ A (5.8) x A,ij ≤ y i + y A,i ∀j ∈ A, i(Theorem 5.2.
For any , γ, κ > 0, in time poly I, λ κρ , log( 1 γ ) , one can compute y, {(x A , y A , u A , v A , r A )}that satisfies (5.7)-(5.12) with objective value C ≤ (1 + )OPT + γ such that A p A r A ≤ ρ(1 + κ).
This can be converted to a (1 + 2)-guarantee in the cost providedf I · y + A (y) ≥ 1 for every y ∈ [0, 1] m , A = ∅.
Proof Sketch.
As in Section 4, we Lagrangify (5.6) using a dual variable ∆ ≥ 0 to obtain the problem max ∆≥0 −∆ρ + OPT (∆) where OPT (∆) = min y∈P h(∆; y), h(∆; y) = f I · y + A p A g A (∆; y), and g A (∆; y) is the minimum value of i f A i (y A,i + v A,i ) + j∈A,i c ij (x A,ij + u A,ij ) + ∆r A subject to (5.7)-(5.12) (where the y i 's are fixed now).
We argue briefly that RiskAlg can be used to compute the desired near-optimal solution; given this, the proof of the multiplicative guarantee is as in Theorem 4.3.
Proving this involves two things: (a) coming up with a bound UB such that log UB is polynomially bounded so that one can restrict the search for the right value of ∆ in RiskAlg; and (b) showing that for any ∆ ≥ 0, an optimal solution to the SAA-problem min y∈P h(∆; y) (constructed in step (R2) of RiskAlg) yields a solution to min y∈P h(∆; y) that satisfies the approximation guarantee in Lemma 4.1.
There are two notable aspects in which risk-averse facility location differs from risk-averse set cover.
First, unlike in set cover, one cannot ensure that the cost incurred in a scenario is always 0 by choosing the first-stage decisions appropriately.
Thus, the problem (RFLP) may in fact be infeasible.
This creates some complications in coming up with an upper bound UB for use in RiskAlg.
We show that one can detect by an initial sampling step that either the problem is infeasible, or come up with a suitable value for UB.
Second, due to the non-covering nature of the problem, one needs to delve deeper into the structure of the dual LP for a scenario (after Lagrangifying (5.6)) to prove the closeness-insubgradients property for the SAA objective function constructed in step (R2) and the true objective function.Assume first that we have shown (b).
Define C A = j∈A (min i c ij ) and C = j (min i c ij ).
Note that C A is the minimum possible assignment cost that one can incur in scenario A.
We may determine with high probability using O 1ρκ samples if Pr A [C A > B] > ρ or Pr A [C A > B] ≤ ρ 1 + 5κ 28 ).
In the former case, we can conclude that the problem is infeasible.
In the latter case, we set ρ = ρ 1 + 5κ 28 andˆκandˆ andˆκ such that ρ(1 + ˆ κ) = ρ(1 + κ), and call procedure RiskAlg with these values of ρ andˆκandˆ andˆκ (and the given , γ), takingUB = 32(1+ε)( P i f I i +C) 3ρκ.
It is not hard to see that with this upper bound, we have p (k) , p (k) < ρ = ρ(1+3ˆκ1+3ˆκ/4), and (as in the proof of Theorem 4.3) this suffices for the search for ∆ in RiskAlg to go through.Task (b) boils down to showing that the objective function h(∆; .)
of the SAA-problem (in step (R2)) and the true problem h(∆; .)
satisfy the conditions of Lemma 3.1.
Again, with R = √ m and V = 1 2 , we have that P ⊆ B(0, R) and contains a ball of radius V .
Lemma 5.1 proves that this holds with high probability, with K = λf I + |∆|, = ε, ξ = η∆ and τ = ζ/6 (and N = log 2KR τ as in Section 3).
Due to the non-covering nature of the formulation, we need to derive additional insights about optimal dual solutions to g A (∆; y) to prove this.
So by Lemma 3.1, the solutionˆy solutionˆ solutionˆy (i) = argmin y∈P h(∆ i ; y) obtained in step (R2) for each ∆ i satisfies the requirements of Lemma 4.1.
Lemma 5.1.
With probability at least 1 − δ, h(∆; .)
and h(∆; .)
satisfy the conditions of Lemma 3.1 with K = λf I + |∆|, = ε and ξ = η∆, and τ = ζ/6 (and N = log 2KR τ ).
Proof.
The proof dovetails the proof of Lemma 4.1.
Weuse N = 8N 2 4λ ε + m η 2 ln 2|Gτ |m δ samples (where G τ ⊆ P is an extended τ KN -net of P), which is poly I, λ εη , log( ∆ ζ ) .
Consider any y ∈ P. Let α * A,j , ψ * A,j , β * A,ij , Γ * A,ij , θ * Abe the values of the dual variables corresponding to (5.7)-(5.11) respectively in an optimal dual solution to g A (∆; y).
We choose an optimal dual solution that minimizes i,j β * A,ij .
It is easy to show that the vectorsˆdvectorsˆ vectorsˆd y = ( ˆ d y,i ) andd y = (d y,i ) given byˆdbyˆ byˆd y,i = f I i − A p A j∈A β * A,ij + Γ * A,ij and d y,i = f I i − A p A j∈A β * A,ij + Γ * A,ijare respectively subgradients of h(∆; .)
and h(∆; .)
at y.
Now we claim that for every i, j β * A,ij ≤ ∆ and j Γ * A,ij ≤ f A i .
Given this, ˆ d y , d y ≤ K where K = λf I + ∆ for any y ∈ P, so K is an upper bound on the Lipschitz constant of h(∆; .)
and h(∆; .)
.
The second inequality is a constraint of the dual.
Suppose β * A,ij > 0 for some j.
The dual enforces the constraintα * A,j + ψ * A,j ≤ c ij (1 + θ * A ) + β * A,ij + Γ *A,ij .
We claim that this must hold at equality.
By complementary slackness, we havex * A,ij = y i + y * A,iwhere (x * A , y * A , u * A , v * A )is an optimal primal solution to g A (∆; y).
So if y i > 0 then x * A,ij > 0 and complementary slackness gives the desired equality.
If y i = 0 and the above inequality is strict, then we may decrease β * A,ij while maintaining dual feasibility and optimality, which gives a contradiction to the choice of the dual solution.
Thus, since the dual also imposes that ψ * A,j ≤ c ij + Γ * A,ij , we have that β * A,ij ≤ α * A,j , so j β * A,ij ≤ j α * A,j ≤ ∆ (the last inequality follows from the dual constraint corresponding to r A ).
As in Lemma 4.1, if d is a subgradient of h(∆; .)
at y andˆdandˆ andˆd is a vector such that |ˆ d i − d i | ≤ ωf I i + ξ 2m , thenˆd thenˆ thenˆd is an (ω, ξ)-subgradient of h(∆; .)
at y.
Since E ˆ d y,i = d y,ifor every y and i, plugging in the sample size N and using the Chernoff bound (Lemma 3.2), we obtain with probability at least 1 − δ,| ˆ d y,i − d y,i | ≤ ε 8N f I i + η∆ 4mNfor all i, for every point y in the extended τ KN -net G τ of P. Thus, with probabilityat least 1 − δ, ˆ d y is an ε 8N , η∆ -subgradient of h(∆; .)
at y for every y ∈ G τ .
To round the LP-solution, as in part (i) of Theorem 4.1, we observe that if y, {(x A , y A , u A , v A , r A )} is a solution satisfying (5.7)-(5.12) of objective value C, then for any ε > 0, takingˆytakingˆ takingˆy = y 1 + 1ε gives i f i ˆ y i + A p A A (ˆ y) ≤ 1 + 1 ε C and Pr A [ A (ˆ y) > 1 + 1 ε B] ≤ (1 + ε)A p A r A .
Now one can use a local approximation algorithm for 2-stage stochastic facility location (SUFL) to roundˆyroundˆ roundˆy.Shmoys and Swamy [38] show that any LP-based c-approximation algorithm for the deterministic facility location problem (DUFL) that satisfies a certain "demand-obliviousness" property can be used to obtain a min{2c, c + 1.5}-approximation algorithm for SUFL, by using it in conjunction with the 1.5-approximation algorithm for DUFL in [4].
"Demand-obliviousness" means that the algorithm should round a fractional solution without having any knowledge about the clientdemands, and is imposed to handle the fact that one does not have the second-stage solutions explicitly.
There are some difficulties in applying this to our problem.
First, the resulting algorithm for SUFL need not be local.
Second, more significantly, even if we do obtain a local approximation algorithm for SUFL by the conversion process in [38], the resulting algorithm may be randomized if the c-approximation algorithm for DUFL is randomized.
Using such a randomized local γ-approximation algorithm for SUFL, either the one in [38] or its improvement in [42], would yield a random solution such that Pr A [expected cost of scenario A > γB] ≤ ρ(1 + κ + ε), where the expectation is over the random choices of the algorithm.
But we want to make the stronger claim that, with high probability over the random choices of the algorithm, we return a solution where Pr A [cost of A > γB] ≤ ρ(1 + κ + ε).
We take care of both these issues by imposing the following (sufficient) condition on the demand-oblivious algorithm for DUFL that is used to obtain an approximation algorithm for SUFL (via the conversion process in [38]): with probability 1, the algorithm should return a solution where each client's assignment cost is within some factor of its cost in the fractional solution.
One can use the the deterministic Shmoys-Tardos-Aardal (STA) algorithm [40], or the randomized approximation algorithm of Swamy [43], both of which satisfy this condition (and are demand-oblivious).
In particular, the STAalgorithm [40] returns a 4-approximate solution, where a client's assignment cost is blown up by a factor of at most 4.
Combining this and the algorithm of [4] in the rounding procedure of [38] yields the following theorem.Theorem 5.3.
For any , κ, ε > 0, one can compute a 5.5(1 + + 1 ε ), 5.5(1 + + 1 ε ), 1 + κ + ε -solution to risk-averse budgeted facility location in polynomial time.Proof Sketch.
Let y, {(x A , y A , u A , v A )} be the solution given by Theorem 5.2.
LetˆyLetˆLetˆy = y 1 + 1 ε , so that i f i ˆ y i + A p A A (ˆ y) ≤ 1 + 1 ε C and Pr A [ A (ˆ y) > 1 + 1 ε B] ≤ (1 + ε) A p A r A .
Suppose we have a demand-oblivious LP-based α-approximation algorithm such that with probability 1, the algorithm returns an integer solution where each client's assignment cost is at α times its cost in the fractional solution.
We utilize the rounding procedure in [38], which we sketch below for completeness, and also to demonstrate how the demandobliviousness and "distance-preservation" properties allow one to (1) obtain a local approximation algorithm for SUFL), and (2) obtain the recourse action for scenario A given onlyˆyonlyˆ onlyˆy and the rounded first-stage solution.For the first-stage decisions, we round min{1, ˆ y i /θ}, where θ = α α+1.5 , using the α-approximation algorithm to obtain the integer vector˜yvector˜ vector˜y, which gives the set of facilities opened in stage I. Let a(j) denote the open facility that is nearest to j. Let ¯ C j denote the minimum cost of assigning j fractionally to an extent of 1 to the facility-opening vector min{ˆymin{ˆy i /θ, 1} i .
By demandobliviousness, for any client-demands (d j ) j∈D , we havef I i ·˜y+·˜y+ j d j c a(j)j ≤ α f I · ˆ y θ + j d j ¯ C j ;and by distance preservation, we have c a(j)j ≤ α ¯ C j for all j.
In a scenario A, we first compute the solution (ˆ x A , ˆ y A ) that determines A (ˆ y) (which can be done efficiently).
For every client j ∈ A, one can writêx A,ij = ˆ x I A,ij + ˆ x II A,ij such thatˆxthatˆ thatˆx I A,ij ≤ ˆ y i andˆxandˆ andˆx II A,ij ≤ ˆ y A,i .
Let D A = {j ∈ A : i ˆ x I A,ij ≥ θ}.
We assign each j ∈ D A to a(j); note that c a(j)j ≤ α θ · i c ijˆxijˆ ijˆx I A,ij .
Next, we run the LP-based 1.5-approximation algorithm for DUFL on the instance with client-set A \ D A .
This determines the facilities to open in scenario A (˜ y A ) and the assignment (˜ x A,ij ) i of clients j in A \ D A .
We have f A · ˜ y + j∈A\D A i c ij˜xAij˜ ij˜xA, ij ≤ 1.5 1−θ · f A · ˆ y A + j∈A\D A i c ijˆxijˆ ijˆx II A,ij , Also, note that f I · ˜ y + A,j∈D A p A c a(j)j ≤ α θ · f I · ˆ y + A,j∈D A ,i p A c ijˆxijˆ ijˆx IA,ij .
So we obtain a solution of cost at most (α + 1.5)C and the cost of each scenario A is at most (α + 1.5) A (ˆ y).
Thus, with α = 4, we obtain a 5.5(1 + + 1 ε ), 5.5(1 + + 1 ε ), 1 + κ + ε -solution.Budget constraints on individual components of the second-stage cost.
As mentioned in Section 2, our techniques can be used to devise approximation algorithms for a fairly general risk-averse version of facility location (and other problems), where we impose the joint probabilistic budget constraint Pr A [(total cost of A)> B, or (facility-cost of A)> B F , or (assignmentcost of A)> B C ] ≤ ρ.
This has the effect of augmenting (RFLP) with the constraints i f A i y A,i ≤ B F , and j,i c ij x A,ij ≤ B C , for each scenario A. (Note that by setting a budget to ∞, we can model the absence of a particular budget constraint.)
One can model various interesting situations by setting B, B F , B C suitably.
For example, setting B F = 0, B = ∞ means that we seek a minimum-cost solution where the facilities opened in stage I are such that with probability at least 1 − ρ, we can assign the clients in a scenario A to the stage I facilities while incurring assignment cost at most B C .
Algorithm RiskAlg can be applied to solve even this more general LP, and Theorem 5.2 continues to hold here.
Note that to describe a solution, even for the fractional risk-averse problem, an algorithm must now return not just the first-stage solution y but also specify how to compute the recourse action in a scenario, and RiskAlg does indeed do this.
Rounding procedure.
The rounding procedure is similar to that in Theorem 5.3 and we highlight the main changes here.
Let y, {(x A , y A , u A , v A )} be the solution given by RiskAlg for the general risk-averse problem.
Note that in each scenario A, we can compute (x A , y A , u A , v A , r A ) efficiently.
Say that a scenario A is c-violated if at least one of its budget constraints is violated by more than a c-factor.
We assume initially that we have a rounding algorithm for DUFL that given a fractional solution, returns an integer solution whose facility-opening, client-assignment, and total-cost are at most β times the corresponding quantity in the fractional solution.
We prove later that any LP-based algorithm for DUFL can be morphed into such an algorithm.Let I A,ij + ˆ x II A,ij wherê x I A,ij ≤ ˆ y i andˆxandˆ andˆx II A,ij ≤ ˆ y A,i .
Clients in D A = {j ∈ A : i ˆ x IA,ij ≥ θ} are assigned to their nearest stage-I facilities, and we use the β-approximation algorithm to round 11−θ (ˆ x II A,•j ) j∈A\D A , ˆ y Ato obtain the facilities to open in scenario A (˜ y A ) and the assignment (˜ x A,ij ) i of clients j ∈ A \ D A .
The properties of the α-and β-approximation algorithms yield the following bounds.f I · ˜ y + A,j∈D A p A c a(j)j ≤ α θ f I · ˆ y + A,j∈D A ,i p A c ijˆxijˆ ijˆx I A,ij c a(j)j ≤ α θ i c ijˆxijˆ ijˆx I A,ij ∀A, j ∈ D A f A · ˜ y A ≤ β 1 − θ f A · ˆ y A ∀A j∈A\D A ,i c ij˜xij˜ ij˜x A,ij ≤ β 1 − θ j∈A\D A ,i c ijˆxijˆ ijˆx II A,ij ∀A and f A · ˜ y A + j∈A\D A ,i c ij˜xij˜ ij˜x A,ij ≤ β 1−θ f A · ˆ y A + j∈A\D A ,i c ijˆxijˆ ijˆx II A,ij∀A. Combining these bounds, we see that the total cost of the solution is at most (α + β)1 + 1 ε C and in each scenario A, the facility-opening, clientassignment, and total-cost are all at most (α + β) times the corresponding quantity in (ˆ x A , ˆ y A ).
Thus, if r A < 1 1+ε then these quantities are at most (α + β)1 + 1 ε {B F , B C , B} respectively.
So we obtain that Pr A [A is (α + β) 1 + + 1 ε -violated] ≤ ρ(1 + κ + ε).
Finally, we note that any LP-based γ-approximation algorithm for DUFL can be used to obtain the desired β-approximation algorithm above with β = 2γ.
Suppose (X, Y ) is the solution to a DUFL instance with facility-costs {f i } and client-assignment costs {D ij }.
Let P = i f i Y i , Q = j,i c ij X ij and R = P + Q.
We run the γ-approximation algorithm with facility costs R P {f i } and client-assignment costsR Q {D ij } to obtain an integer solution ( ˜ X, ˜ Y ).
It follows that i f i ˜ Y i ≤ γ · 2P , j,i c ij˜Xij˜ ij˜X ij ≤ γ · 2Q, so i f i ˜ Y i + j,i c ij˜Xij˜ ij˜X ij ≤ γ · 2R.
So we can obtain β ≤ 3.
Taking α = 4 and β = 2 × 1.5, we obtain a solution of cost at most 71 + + 1 ε OPT where Pr A [A is 7 1 + + 1 ε -violated] ≤ ρ(1 + κ + ε).
All of our arguments generalize to the setting with scenariodependent budgets {(B A , B A F , B A C )}.
The RSC instances constructed in the proof of Theorem 4.2 to show the difficulty of obtaining a (c 1 , c 2 )-scheme, can be easily cast as instances of other riskaverse budgeted problems-e.g., all the problems in Section 5-where each scenario consists of (at most) two "elements" (e.g., clients in RFL).
We show here that if all scenarios contain (at most) one element, then one can obtain an approximation that does not violate the probability threshold.
(Note that the examples in Appendix A showing that the guarantees of Theorem 4.1 are tight are one-element instances.)
Although the oneelement-per-scenario setting appears rather restrictive, it has (surprisingly) rich modeling power.
We uncover a close connection between the independent activation (IA) model, where each "element" is independently "activated" with probability p j , and the one-element-perscenario setting.
The IA model is a popular model in Computer Science that has been considered in various stochastic contexts [27,16,24,15,39], and our results suggest that an understanding of risk-averse problems in the one-element-per-scenario setting may yield significant dividends for stochastic problems in the IA model.
We focus on RFL for concreteness, but the same reductions apply to other problems.
Let C denote the class of all one-client-per-scenario RFL instances.
(Note that clients may have nonuniform demands).
We can show that various stochastic problems in the IA model reduce to RFL problems over C. For example, consider a priori facility location (APFL)-we have a distribution over client-sets and the goal is to find an assignment of (all) clients to (open) facilities with minimum expected cost-and its riskaverse version, where we impose also the constraint Pr IA [assignment cost of an activated client > B] ≤ ρ.
A priori stochastic problems (see [2]) in the IA model have very recently been considered from the perspective of approximation algorithms in [15,39].
Despite the contrast between (risk-averse) APFL and RFL restricted to class C-the former is a one-stage problem where we choose the entire solution in advance and pay only for facilities used by the (random) set of activated clients; in the latter problem, we pay for all facilities opened in stage I and can augment our solution in stage II-we can reduce risk-averse APFL to a RFL problem over class C. Another example is one-stage FL: minimize the facilityopening + expected client-assignment cost, subject to Pr IA [assignment cost of a client > B] ≤ ρ.
( [1] give an approximation algorithm for a set-cover version of this problem: select a min-cost collection of sets so that Pr IA [element is uncovered] ≤ ρ.
This can be encoded as non-metric one-stage FL with B = 0, and c ij = 0 or µ > 0 (which is small) depending on whether or not i covers j.) In both reductions, we create a RFL instance in class C where: (a) each client (i.e., scenario) j has non-unit demand and budget B j ; and (b) the notion of riskaversion is Pr j [second-stage assignment cost of {j} > B j ] ≤ ρ; A (c 1 , c 2 , 1)-solution to RFL is a solution of cost at most c 1 (optimum), where Pr j [{j} is c 2 -violated] ≤ ρ.
(Recall that a scenario {j} is c-violated if (at least one of) its budget constraint(s) is violated by more than a c-factor.)
Theorem 6.1.
Given a polytime algorithm for RFL (resp.
non-metric RFL) that always returns a (c 1 , c 2 , 1)-solution, for both one-stage FL and risk-averse APFL (resp.
non-metric {one-stage FL, risk-averse APFL }), one can compute an O(c 1 )-approximate solution in polytime with Pr IA [assignment cost of an activated client > c 2 B] ≤ ρ.Proof.
The reduction from both problems to RFL is quite similar, and we point out the common ingredients first.
Let {f i }, {c ij }, {p j }, B, ρ be an instance of one-stage FL or risk-averse APFL, where p j is the activation probability of client j.
We assume that the instance is feasible as this is easy to check.
Let n be the number of clients.
Let (t) = ln 1 1−t and j = (p j ).
For a client-set S, define ac(S) = Pr IA [some client in S is activated] = 1 − j∈S (1 − p j ) and (S) = j∈S j .
We have (1 − e −1 ) min{1, (S)} ≤ ac(S) = 1 − e −(S) ≤ min{1, (S)}.
Thus, ac(S) ≤ t iff (S) ≤ (t).
Let M = j j .
In both reductions, scenario {j} occurs with probability j /M in our RFL problem, and we set the probability threshold to (ρ)/M .
For one-stage FL, scenario {j} has budget B·M pj j (on the assignment cost), and client j has demand M p j // j .
We set the first-stage facility costs to {f i }, and the second-stage facility costs are set very high (e.g., M (n max i,j c ij + i f i )/ min j j ; note that we are in the poly-scenario model, so we need not worry about the inflation factor λ).
An optimal one-stage-FL solution K * , {a * (j) yields a solution to the RFL instance, where we open the facilities in K * in stage I and assign each client j to a * (j).
This is feasible because the violated scenarios in the RFL instance correspond to the clients in S := {j : c a * (j)j > B}, and ac(S) ≤ ρ implies that (S)/M ≤ (ρ)/M .
Also, clearly the RFLcost is equal to its one-stage-FL-cost.
Now consider any (c 1 , c 2 , 1)-solution to the RFL problem.
We may assume that no facilities are opened in stage II.
We obtain a one-stage-FL-solution where we open all the (stage-I) facilities opened by the RFL-solution and assign clients as in the RFL-solution.
The cost of the solution is unchanged.
If {a(j)} denotes the client assignment, then Pr IA [assignment cost of an activated client > c 2 B] = ac S := {j : c ja(j) > c 2 B} , which is at most ρ since(S)/M ≤ (ρ)/M .
For APFL, scenario {j} has budget B·pj j and client j has demand p j // j .
we set the first-stage cost of facility i to f i /M , and its second-stage cost to f i .
An optimal APFL-solution K * , {a * (j)} yields the following feasible solution to the RFL problem.
For i ∈ K * , we open i in stage I if {j : a * (j) = i} ≥ 1, and otherwise we open i in every scenario {j} for which a * (j) = i; we assign each client j to a * (j).
The RFL-cost of this solution is 1 M · i∈K * f i min 1, ({j : a * (j) = i}) + j p j c a * (j)j ≤ e/(e−1) M · OPT APFL .
The feasibility of the solution follows from the same calculations as in the one-stage-FL problem.
Suppose we have a (c 1 , c 2 , 1)-solution to RFL.
This translates to an APFL-solution where we open all the (stage-I and stage-II) facilities opened by the RFL-solution and assign clients as in the RFL-solution.
A similar calculation as above shows that the APFL-cost is at most M (RFL-cost); also, as in the one-stage-FL setting, if {a(j)} denotes the client assignment and S = {j : c a(j)j > c 2 B}, then we obtain that ac(S) ≤ ρ since (S)/M ≤ (ρ)/M .
Finally, note that we do not use "metricity" anywhere, so the same reductions apply to the set-cover versions of these problems as they can be cast as nonmetric facility-location problems.The following result for metric RFL complements the above theorem.
Its proof is deferred to the full version of this paper.Theorem 6.2.
For any > 0 and any RFL problem, one can compute a 4 + 6 e + , 3, 1 -solution in time poly input size, log( 1 ) .
We now prove various lower bounds on the sample-size required in the black-box model to obtain a bounded approximation guarantee for the risk-averse budgeted and robust problems.
Say that a solution is an (, γ)-optimal solution if its cost is at most (1 + )OPT + γ.Theorem 7.1.
For any , γ > 0, δ < 1 2 , every algorithm for risk-averse budgeted set cover that returns an (, γ)-optimal solution with failure probability at most δ using a bounded number of samples• must violate the probability threshold on some input;• requires Ω 1 κ samples if the probability-threshold is violated by at most an additive κ;• requires Ω 1 κρ samples if the probability-threshold is violated by at most a multiplicative (1 + κ)-factor.The proof of Theorem 7.1 relies on the following observation.
Consider the following problem.
We are given as input a threshold ∈ (0, 1 4 ) and a biased coin with probability q of landing heads, where the coin is given as a black-box; that is, we do not know q but may toss the coin as many times as necessary to "learn" q.
The goal is to determine if q ≤ or q > 2; if q ∈ (, 2], the algorithm may answer anything.
We prove that for any δ < 1 2 , any algorithm that ensures error probability at most δ on every input must need at least N (δ; ) = ln 1 δ − 1 /4 coin tosses for each threshold .
Lemma 7.1.
Let δ < 1 2 and A N (δ;) be an algorithm that has failure probability at most δ and uses at most N (δ; ) coin tosses for threshold .
Then, N (δ; ) ≥ N (δ; ) := ln1 δ − 1 /4 for every ∈ (0, 1 4 ).
Proof.
Suppose N (δ; ) < N (δ; ) for some ∈ (0, 1 4 ).
Let X be a random variable that denotes the number of times the coin lands heads.
If X = 0 then the algorithm must say "q ≤ " with probability at least 1 − δ, otherwise the algorithm errs with probability more than δ on q = 0.
But then for some q 0 < 1 4 slightly greater than 2, we have Pr[X = 0] > (1 − 2) N (δ;) ≥ δ 1−δ .
So A will say "q ≤ " (and hence, err) for q = q 0 , with probability more than δ.Proof of Theorem 7.1.
Given Lemma 7.1, our strategy is to construct a (very simple) RSC instance, where there is one key scenario A, whose probability determines whether or not one should take a certain first-stage decision to achieve a low cost solution with bounded budget inflation.
We show that an algorithm that always returns an (, γ)-solution can be used to distinguish whether p A ≤ κ or p A > 2κ, and hence, the algorithm must draw a certain number of samples.Suppose there is an algorithm A for risk-averse budgeted set cover that on any input (with a blackbox distribution) draws a bounded number of samples and returns an (, γ)-optimal solution with probability at least 1 − δ, δ < 1 2 , where the probability-threshold is violated by at most κ.
Consider the following risk-averse budgeted set-cover instance.
There are three elements e 1 , e 2 , e 3 , three sets S i = {e i }, i = 1, 2, 3.
The budget is B ≥ 6γ and the probability threshold is ρ ≤ 1 8(1+) .
The costs are w I Si = B for all i, and w A S1 = 0, w A S2 = w A S3 = 2B/3 for every scenario A. Let κ < 1 4 .
There are 3 scenarios: A 0 = ∅, A 1 = {e 1 , e 2 , e 3 }, A 2 = {e 2 , e 3 } with p A1 = ρ − κ, p A0 = 1 − p A1 − p A2 .
Observe that if p A2 ≤ κ, then OPT ≤ ρ · 4B/3, and every (, γ)-optimal solution must have x S1 +x S2 +x S3 ≤ 1 3 .
But if p A2 > 2κ (which is possible since ρ < 1) then any solution where the probability of exceeding the budget is at most ρ + κ must have x S2 + x S3 ≥ 1 2 , otherwise the cost in both scenarios A 1 and A 2 will exceed B. Thus, algorithm A can be used to determine if p A2 ≤ κ or p A2 > 2κ.
(This is true even if we allow the budget to be inflated by a factor c < 10 9 since we must still have x S2 + x S3 > 1 3 if p A2 > 2κ.
Choosing B 1, ρ 1, we can allow an arbitrarily large budget-inflation.)
So since A has failure probability at most δ, by Lemma 7.1, it must draw Ω 1 κ samples.
Taking κ = 0 shows that obtaining guarantees without violating the probability threshold is impossible with a bounded sample size, whereas taking κ = κρ shows that a multiplicative (1 + κ)-factor violation of the probability threshold requires Ω 1 κρ samples.
Moreover, taking ρ = 0 shows that one cannot hope to achieve any approximation guarantees in the (standard) budget model with black-box distributions.To show the impossibility of approximation in the standard robust model with a bounded sample size, consider the following set cover instance.
We have a single element e that gets "activated" with some probability p; the cost of the set S = {e} is 1 in stage I and some large number M in stage II.
If p = 0 then OPT = 0, otherwise OPT = 1.
Thus, it is easy to see that an algorithm returning an (, γ)-optimal solution can be used to distinguish between these two cases (it should set x S ≤ γ in the former case, and x S sufficiently large in the latter).
now just one set S that covers all the elements, whose first-stage cost is 1 + 1 ε and the second-stage cost is negligible but non-zero.
We set B = 0, so that the risk-averse budgeted problem becomes essentially a onestage problem (of picking sets in stage I so as to cover "most" scenarios).
In the following discussion We ignore the negligible second-stage cost incurred; all we need is that if some element of A is not covered in stage I, then the budget-constraint of scenario A is violated.
The solution x S = ε 1+ε , y A,S = 0, r A = 1 1+ε for all A is feasible to (RSCP) and has cost 1.
But if x is a solution to the fractional risk-averse problem of cost γ · OPT with Pr A [f A (x) > 0] ≤ σρ, then either γ ≥ 1 + 1 ε or σ ≥ (1 + ε).
Proof of Theorem 4.2.
Let G = (V, E), k be the input to the MinDkS problem.
Let n = |V |, m = |E|.
We create a RSC instance with m + 1 scenarios.
For each edge e = (u, v), we create two elements (e, u) and (e, v) in our universe.
For each node u ∈ V , we create a set S u := {(e, u) : e ∈ δ(u)}.
For each edge e = (u, v) ∈ E, we create a scenario A e , where we need to cover the two elements (e, u), (e, v); each such scenario A e occurs with probability 1 2m .
We set the first-stage cost of each set S u to 1, its second-stage cost to be negligible (e.g., 1 n 3 ), but non-zero.
Also, we set B = 0.
So the budget constraint of a scenario A uv is satisfied iff both S u and S v are picked (to an extent of 1) in stage I; otherwise, we incur a negligible second-stage cost for A uv .
In the sequel, we ignore this negligible second-stage cost incurred for "unsatisfied" scenarios.
Observe that the RSC problem now essentially becomes a one-stage problem of picking suitable sets in stage I.
If we now set ρ = (m − k)/2m, then it is easy to argue that any (c 1 , ·, 1)-solution to RSC yields a c 1 -approximate solution to MinDkS.
This was shown by Goyal and Ravi [17].
To strengthen their result and prove that even obtaining a (c 1 , ·)-scheme is difficult (modulo MinDkS), even when ρ is a constant, we do the following.
We create a "filler" element f in our universe, a filler set S f = {f }, and a filler scenario A 0 occurring with probability k 2m where we have to cover f (and the null scenario ∅ occurs with the remaining probability).
We give S f a very high first-stage cost (e.g., n 3 ), and its second-stage cost to be negligible but nonzero.
Note that any any (c 1 , ·, ·)-solution to RSC with c 1 ≤ n, will avoid picking S f in stage I.
We set ρ = 1 2 .
It is clear that the size of the RSC instance is poly(m, n, k).
Any solution to MinDkS translates to a solution to RSC of the same cost where we pick the sets corresponding to the nodes in the solution in stage I.
Now consider any c 1 , ·, (1 + 1 2m ) -solution to RSC (so S f is not picked in stage I).
Let k be the number of edges in the subgraph induced by the nodes corresponding to the sets picked in stage I. Then, (m−k )· 1 2m +p A0 ≤ 1 2 1+ 1 2m , so m − k + k ≤ m + 1 2 ; k is an integer, so this implies that k ≥ k.
So we obtain a c 1 -approximate solution to MinDkS in polytime.The same reduction works for fractional RSC, since as mentioned above, a scenario A uv is satisfied iff both S u and S v are picked to an extent of 1 in the (fractional) solution.Finally, Hajiaghayi and Jain [22] showed that a c 1 -approximation algorithm for MinDkS yields a 2c 2 1 -approximation algorithm for DkS.
is the corresponding SAA problem.
Let F ρ ⊆ F be the feasible region of (RA-P).
Let x * ∈ F ρ be an optimal solution to (RA-P), and O * = h(x * ) denote its value.
We prove the following theorem.Theorem B.1.
Consider k = 2 log 1 δ SAA problems (SA-P) with objective functions h (1) , . . . , h (k) , each constructed using N = poly I, λ +κρ , ln ( Proof.
The proof is along the lines of the proof of the SAA method in [6] and generalizes some of their arguments.
We argue at various places that the sample
