Network testbeds like Emulab allocate physical computers to users for the duration of an experiment.
During an experiment, a user has nearly unfettered access to the devices under his or her control.
Thus, at the end of an experiment, an allocated computer can be in an arbitrary state.
A testbed must reclaim devices and ensure they are properly configured for future experiments.
This is particularly important for security-related experiments: for example, a testbed must ensure that malware cannot persist on a device from one experiment to another.
This paper presents the prototype trusted disk-loading system (TDLS) that we have implemented for Emulab.
When Emulab allocates a PC to an experiment, the TDLS ensures that if experiment setup succeeds, the PC is configured to boot the operating system specified by the user.
The TDLS uses the Trusted Platform Module (TPM) of an allocated PC to securely communicate with Emulab's control infrastructure and attest about the PC's configuration.
The TDLS prevents state from surviving from one experiment to another, and it prevents devices in the testbed from impersonating one another.
The TDLS addresses the challenges of providing a scalable and flexible service, which allows large testbeds to support a wide range of systems research.
We describe these challenges, detail our TDLS for Emulab, and present the lessons we have learned from its construction.
Network testbeds are generally designed to help users create test environments that are realistic.
That is, in order to produce practically useful results, experimenters often want to create test environments that are like true deployment environments with respect to the properties of interest to a test.
In addition, for systems-level research, testbed users often need a great deal of freedom within the environments they create.
A systems researcher may need to install custom operating systems, use nonstandard network protocols, or perform other administrator-like tasks.To support both realism and freedom, testbeds like Emulab are designed to allocate actual physical devices as well as virtual devices to users [15].
For the duration of an experiment, a user has exclusive and essentially complete control over the devices that are allocated to him or her.
At the end of an experiment, the user releases the devices back to the testbed, and the testbed must reclaim them.
Virtual devices are straightforward: they can simply be destroyed by the testbed.
Physical devices, however, must be recovered so that they can be usefully and safely allocated to another user in the future.In this paper, we describe how Emulab securely recovers and "reconditions" physical devices that support secure remote attestation.
This includes most modern PCs, which contain Trusted Platform Module (TPM) hardware [14].
Emulab regains control over these devices in a trustworthy manner through a protocol rooted in the TPM of each device.
Once a node is brought under Emulab's control, Emulab prepares the node for a new experiment by loading the node's disk with contents chosen by the experiment's creator.
Emulab's trusted disk-loading system (TDLS) is responsible for both of these steps.
In addition to preventing unwanted state from persisting on a device from one experiment to the next, the TDLS protects Emulab against other attacks that would misconfigure of the devices allocated to an experiment.Emulab's TDLS addresses several challenges in providing a secure node-configuration service for a large testbed that supports systems-level experiments on physical devices.
The first is merely to regain control over physical nodes as they are released from experiments.
An experiment may leave a device in an arbitraryor even dangerous-state.
The TDLS regains control through a combination of power control, remote attestation, and cryptographically secure network protocols.
A second challenge comes from the size and diversity of the testbed.
The Utah Emulab site contains hundreds of PCs.
In addition, the site provides dozens of standard disk images that may be loaded onto those nodes, and users are free to create their own.
The TDLS is therefore designed to require little or no administrator action when new devices or disk images are added to a testbed.
A third challenge is to repel network-based attacks against the TDLS.
This includes preventing a device from pretending to be Emulab's trusted control server, and preventing devices in untrusted states from initiating or rejoining the trusted disk-loading protocol.
These issues are addressed through the design of the TDLS protocol and careful handling of the TPM.When Emulab creates an experiment environment for a user, the TDLS ensures that the allocated PCs are configured to boot the user-specified disk images.
The TDLS does not guarantee that the software within a disk image is "secure" by any standard, nor does it protect a PC from attacks during the execution of an experiment.
Indeed, testbed users often want to install and study insecure software!
The only job of the TDLS is to set the initial states-disk contents and boot data-of the PCs allocated to an experiment as specified by the experiment's creator.
If the PCs cannot be so configured, the TDLS will cause the creation of the experiment to fail.The main contribution of this paper is that it details the design and implementation of the trusted disk-loading system we have created for Emulab.
The TDLS is important for containing the effects of experiments, and thus important for a testbed that seeks to provide isolated, reliable, and secure services to its users.
Our current TDLS is a prototype, soon to be deployed for production use in Utah's Emulab site.
In addition, this paper summarizes the "lessons learned" from the development of our TDLS.
Our TDLS design can inform the creation of node-configuration services for network testbeds and other, similarly managed networks.
Although our TDLS was built for Emulab, we believe our implementation could be adapted for use in other testbeds that provide users with unmediated access to TPM-enabled devices.
Emulab [15] is a well-known network and distributedsystems testbed that emphasizes realistic experimentation by providing its users with physical hardware.
Users do not have physical access to the testbed; instead, users communicate with Emulab and its resources remotely via the Web, SSH, and other Internet protocols.
The testbed is managed by a trusted control server, called boss.When a user creates an experiment, Emulab allocates physical resources-real PCs running real OSes and connected by physical switching infrastructure-to the experiment.
When a machine (node) is allocated to an experiment, the creator of the experiment controls all aspects of that node: e.g., what operating system is running, what applications are installed, and how the nodes are interconnected with each other.
This control extends beyond experiment set-up.
Because a user has "root" access to his or her nodes, he or she can install and remove software at any time during an experiment.Emulab is also a shared facility.
Its physical cluster is space-shared: at any given time, multiple independent experiments may be taking place, each in its own allocation of physical resources.
Emulab isolates experiments so that they cannot observe or interfere with each other.
Emulab's resources are also time-shared.
A node that is allocated to one user's experiment at a particular point in time will be dedicated to a different user's experiment for an entirely different purpose at a future time.Because devices are time-shared, Emulab must "wash" every physical device between the time it is released by one experiment and the time it is allocated to another.
When a device is released from an experiment, however, it can be in a nearly arbitrary state.
That state might contain malware that was the subject of the justcompleted experiment, for example, and which must not be transferred to subsequent experiments.
More egregiously, a malicious user might leave a device in a state that attempts to subvert Emulab's ability to recondition the node for subsequent uses.
Consider a user who wants to transfer malware to subsequent experiments, or who wants to spy on future experiments.
Such a user might install software that participates in Emulab's disk-loading protocol, but which does not actually reload the diskthus allowing the malware or spyware to persist.Because the testbed is space-shared, other experiments will be running while Emulab prepares nodes for a new experiment.
These can also threaten Emulab's ability to recondition devices as they pass from use in one experiment to use in another.
Malware within an experiment may try to migrate onto a reloading node, or a malicious user might try to hijack the disk-reloading process to propagate malware or spyware.Emulab must ensure that the node-reloading process happens completely and correctly, without interference from (1) software on the node being reloaded or (2) any current experiments running on the testbed.
Below, we describe Emulab's standard node re-imaging mechanism and how it addresses-or falls short of addressing-the threats outlined above.
In Section 3, we describe how our new trusted disk-loading system addresses the shortcomings of the current, standard mechanism.
Emulab's standard disk-loading process involves two devices: the device being reloaded and Emulab's boss control server.
As detailed below, the reloading device is expected to contact various services running on boss to obtain the data that it needs to configure itself for use in a new experiment.
Testbed devices communicate with boss through a dedicated control network.
At Utah's Emulab site, the control network connects all the PCs in the testbed to Emulab's central servers, including boss.All PCs in Emulab are connected to power controllers (accessible to boss) and configured to boot only from the control network.
These are the primary elements that ensure that Emulab can always gain control of a node, regardless of the state it is in.
The boss server can powercycle a node, and the node will then load a known firststage boot program that allows boss to manage the node.
Typically, boss directs the node to boot from its hard drive or to reload its hard drive.Emulab uses a set of state machines [10] to track the states of nodes under its control.
Events, including some that are "self-reported" by the monitored nodes, cause nodes to transition between states, which are tracked by boss.
Trigger actions can be invoked when nodes enter states, and timeouts associated with each state allow corrective actions to be performed when a node misbehaves.
Figure 1 shows the state machine that controls disk imaging.
In the first part (the upper shaded region), Emulab regains control of the node and boots it into an environment from which the node can be re-imaged.
The node is placed in the SHUTDOWN state and Emulab uses its power-cycling capability to force the node to reboot.
The system or network card BIOS on the power-cycled node ensures that the control network interface will perform a PXE [7] boot.
The PXE BIOS uses DHCP to obtain IP information for the node along with the name of the next-stage bootloader, which it downloads via TFTP and then executes.
The DHCP request to boss causes a state transition to PXEBOOTING.The next-stage loader is pxeboot, a custom Emulab boot program.
The pxeboot loader talks to the Emulab bootinfo service to determine what the node should do next: boot from a partition on disk, or download an OS kernel and memory-based filesystem image (collectively known as an MFS) via TFTP.
In the node re-imaging case, boss tells the node to download the disk-loading MFS.
The bootinfo request to boss causes the second state transition into BOOTING.After downloading the MFS, pxeboot hands off to the MFS kernel.
A successful boot of the MFS is marked by the node explicitly reporting the RELOADSETUP state to boss via Emulab's tmcd service.
This causes the third state transition and marks the start of the second stage of re-imaging (the lower shaded box): downloading and installing a disk image.The node contacts tmcd to learn what image to load onto its disk and where to get that image.
The node then reports its state as RELOADING, causing the fourth transition, and starts the frisbee disk-imaging client [6].
On successful completion of the reload, the node reports RELOADDONE, making the fifth state transition.
Emulab reboots the node into a WAITING state for the next experiment and moves the node to a different state machine.Notice that there are no explicit failure reports during any of the steps.
Instead, each state has an associated timeout value.
If the node fails to transition from the state in a timely manner, Emulab makes a timeout (TO) transition for the node-resulting in the node being rebooted and starting the process over again.These mechanisms provide a robust process for rebooting and re-imaging nodes, but rely on certain properties of Emulab's infrastructure and assume a certain level of trust to function correctly.
A breach of that trust during re-imaging could result in information leakage between experiments, or worse, propagation of malware.
Emulab's re-imaging system can potentially be subverted, leading to a node that is not re-imaged correctly.
Consider, for example, the following threats to the first part of the process.
These threats would prevent the node from booting the disk-loading MFS.1.
Avoiding the network boot.
Because Emulab provides "raw" access to nodes, the preceding experiment may have done anything to a node.
A malicious experiment may have modified the BIOS configuration, for example, and arranged for the node to boot from its hard drive, not from the network.
When Emulab power-cycles the node, the node will boot from disk.
Software on the disk can then emulate a network boot, performing the necessary actions to force the state transitions shown in Figure 1.
Emulab will believe it is talking to a trusted disk-imaging environment, when in fact it is not.2.
Hijacking the network boot.
Even without BIOS modifications, a malicious node may still spoof Emulab.
Emulab places all nodes being re-imaged in a common VLAN, to take advantage of the disk imager's multicast features.
Unless all nodes in this VLAN are rebooted simultaneously, a lagging node could use a man-in-themiddle attack to interpose itself between boss and another node, and thereby subvert the imaging of that node.
While a hijack is unlikely once a node starts using authenticated communication with boss, 1 the initial stages (DHCP, TFTP, and bootinfo) are vulnerable, offering a window of opportunity to infect a node before it resumes communicating with boss.3.
Aborting the network boot.
Even without a hijack, a malicious node might be able to interfere with the network-boot process of another device, so that the other device falls back to booting from its hard drive.Even if a node successfully boots into the disk-loading MFS, there are attacks against the Emulab disk-imaging subsystem during the second part of the process (the lower portion of Figure 1).
These attacks are detailed in earlier work [11] and are summarized below.4.
Modifying the transferred image.
Because frisbee uses an unauthenticated, IP-based multicast protocol to distribute disk images, an adversary could transparently replace portions of an image: e.g., replace a section that contains the password file.5.
Corrupting the transferred image.
Even if an adversary lacks knowledge about the content of an image, he or she can still inject data into the transfer, corrupting the resulting disk and preventing it from being used.6.
Observing the transferred image.
IP multicast does not have any built-in limitations on group membership.
Thus, any node may join a frisbee group and obtain a copy of an image being loaded by another user, which may contain sensitive data.Emulab currently uses a variety of techniques to mitigate, but in most cases not eliminate, these threats.
When a node enters the re-imaging path, all access to that node by previous users is revoked.
This includes access via the serial console and network, so interactive attacks are eliminated.
To help ensure that nodes reach the diskloading MFS, Emulab site operators typically passwordprotect the BIOS of their testbed PCs.
Emulab's software enforces timeouts on a node's state as it transitions to the reloading MFS.
Coupled with a method for client and server authentication, and judicious use of perexperiment infrastructure and firewalls, these strategies have proven adequate to protect Emulab sites from the actions of non-malicious users.However, the overall strategy is ad hoc and provides insufficient guarantees for many types of security experimentation.
It also does not take advantage of advances in technology-in particular, the increasing availability of TPM-enabled platforms.
In this section, we describe how we make use of TPM technology to implement a new, trusted disk-loading system (TDLS) for Emulab.
A TPM [14] is a tamper-resistant microcontroller that is a standard component of many current desktop and server machines.
The TPM can perform a variety of cryptographic functions and securely store a small amount of data.
The specific capabilities we rely on are (1) its ability to provide secure key storage and (2) its ability to securely attest to the measurements of software.Every TPM contains a Storage Root Key (SRK) that is created before the TPM can be used and never leaves the chip.
A TPM can generate other symmetric and asymmetric keys, and encrypt them with the SRK, so that they can only be used by the TPM that generated them.
The encrypted keys are then exported from the TPM and can be stored anywhere.
A TPM also includes some number of Platform Configuration Registers (PCRs).
A PCR cannot be written with arbitrary values; instead, a PCR can only be extended, an operation that stores a SHA-1 hash of the current PCR value concatenated with a new value.
A PCR value is called a measurement and is a secure hash of some piece of state on the machine.An attested boot of a machine causes each stage of the boot process, starting with the BIOS, to measure the next stage of the boot chain into a PCR.
The effect is that, at any stage of the bootstrap, there is a unique set of PCR values that attest to the current state of the machine.
By remotely comparing this set of values against a precomputed set of correct values, one can be assured that the machine is in a particular state.To securely transfer a set of PCR values to a remote machine, the TPM supports a quote operation.
A quote requires a TPM-created Attestation Identity Key (AIK), the indices of the PCR registers whose values are wanted, and a nonce.
The TPM creates a list of the desired PCR values along with the nonce, and signs it with the AIK.
The quote is then returned to the remote machine, which verifies the signature and checks the PCR values.TPM-supported remote attestation in no way prevents tampering with the boot path: it only makes it possible for an outside party (Emulab) to reliably detect any tampering that does occur.
As such, it is just one element of providing the TDLS.
To support a secure boot path, we added the notion of secure states to Emulab's state-machine mechanism.
Certain operations, such as fetching image-decryption keys, are allowed only while a node is in an appropriate secure state.
A secure state can only be entered by providing a TPM-attested quote to Emulab's boss server, as described below.
If the quote is incorrect, or if a timeout period passes, the offending node is placed into a special SECVIOLATION state.
2 When a node enters this state, an email notification is sent to the testbed operators and the node is powered off.
Thus, any node that strays from the trusted boot path will be handled by the operators, and the amount of damage it can do is limited.
Figure 2 shows the state machine that drives the new TDLS.
It is similar to the state machine shown in Figure 1, but has two additional states (described below) and has several states replaced by new, secure states (indicated by double ellipses).
Note that a timeout or error from any state results in a security violation.
The first stage in the boot process is the BIOS boot.
At power-on, the TPM itself measures the BIOS and its configuration parameters.
The BIOS then measures the next stage of the bootloader, which in Emulab is PXE-based.
To support trusted booting, we modified the way that Emulab uses PXE.
PXE typically is loaded from ROM on a host's network interface.
However, current implementations do not allow the measurement of this ROM by the BIOS, and we cannot modify the ROM to measure 2 In the TDLS prototype, there is a single SECVIOLATION state.
We expect to implement multiple violation states before the TDLS is put into production.
This will help operators distinguish between certain security violations (bad quotes) and potential ones (timeouts).
the next boot stage.
This creates a break in the secure boot chain.
To avoid this problem, rather than use the NIC's PXE ROM, we perform the first-level boot from a write-protected USB flash device, which the BIOS can measure.
That code then performs the PXE boot.The previous user of a machine may still modify the BIOS (Section 2.2, Threat 1) or otherwise interfere (Threat 3) so that the machine does not boot from the USB device.
In these cases, the BIOS and first-level bootloader measurements will be incorrect.
Emulab's boss server will detect this when the node attempts to check in, or when a timeout period has passed.
The flash device contains a modified version of the gPXE [2] bootloader.
Our version of gPXE is TPMaware and can establish TLS sessions with networkbased services.
We can thus use gPXE to perform a measured network boot as described below.An important design point is that the gPXE flash device contains no node-specific data, and is thus amenable to large-scale duplication.
This is essential for managing a large set of machines.
Every time the operators of the testbed change the version of gPXE in use, the flash devices must be physically replaced and new, knowngood measurements of it must be taken.
However, by design, the functionality of gPXE is limited.
We expect that modifications to it will be extremely infrequent.gPXE uses the PXE and DHCP protocols to acquire an IP address from the Emulab boss server.
It then uses TFTP to download the next stage as specified in the DHCP information.
The downloaded next stage is measured, and the result extended into a PCR.
There is no assurance at this point that the DHCP and TFTP packets are not spoofed or tampered with (Threat 2).
If they are, however, this will be discovered in the next step.After measuring the next boot stage, gPXE attempts to perform the first secure state transition (to GPXEBOOT- ING).
This involves the node sending a TPM-attested quote to boss.
To make this quote, the node requests from boss its AIK, the PCRs to return, and a nonce.
Using the AIK and nonce, gPXE requests a quote from the TPM.
The resulting quote is unforgeable, and the nonce prevents replay of previously generated quotes (Threat 2).
To ensure that the node is talking to the real boss (i.e., that it was boss that responded to the initial DHCP request), this request is sent via a TLS session.
The boss server is authenticated via a CA certificate embedded in the boot image-in this case, gPXE.
Because the certificate is part of the gPXE image measured by the BIOS, we can be assured that any tampering with the certificate will be discovered.
Note that boss needs no strong authentication of the reloading node during this exchange, since the AIK being returned is only usable by the node that generated it.Emulab's boss server verifies the quote, comparing the returned PCR values with a set of measurements that have been precomputed and stored in Emulab's database.
The precomputed measurements describe a correct boot of a particular node, through the BIOS and gPXE, and having measured gPXE's next stage.
A correct quote allows the node to continue booting.
An incorrect quote causes Emulab to place the node into the SECVIOLATION state and power it off.
gPXE downloads and executes a version of the GRUB 2 bootloader [3] that we have enhanced to support communication with Emulab's boss and the TPM.
(In the secure boot path, GRUB replaces pxeboot.)
Similar to the standard boot path, GRUB makes DHCP and bootinfo requests, triggering transitions to the PXEBOOTING and BOOTING states.
Unlike the standard path, a failure or timeout results in a transition to SECVIOLATION.
GRUB proceeds to download and measure the secure disk-loading MFS: a minimal Linux system that we have configured to disable all network listeners.
The measurement is extended into a PCR, but not immediately reported to boss.
Reporting at this stage would have required us to make additional and extensive changes to GRUB.
After measuring and extending, GRUB transfers control to the Linux kernel in the MFS.Before starting the disk-loading subsystem, the secure disk-loading MFS produces another quote for boss to check.
This includes the updated PCR values that cover GRUB's measurement of the MFS.
The quote process is identical to that performed by gPXE previously.
It causes a secure state transition to RELOADSETUP if successful, or SECVIOLATION otherwise (Threat 2).
Once a node has performed an attested boot into the diskimaging MFS, we make use of prior work [11] that extends the Emulab disk-imaging system [6] to provide confidentiality, integrity protection, and authentication for images and their distribution (Threats 4, 5, and 6).
In our new TDLS, we improve upon that previous work by providing a trusted platform on which to run the disk-imaging client.
The TDLS also uses the TPM to implement cleaner ways of (1) assuring node identities to the server and (2) distributing image-decryption keys.To provide better node identification, for every node, we create a per-node certificate that is associated with a key pair created by each node's TPM.
The certificate (including the public key) and TPM-encrypted private key are stored in the database on boss.
When a node is running in secure disk-loading MFS, it acquires the certificate and encrypted key over an insecure channel.
The key is loaded into the TPM, and whenever a TLS session is started with boss, the client certificate associated with the key is given to boss during the handshake.This authenticated channel is used to pass the imagedecryption key from boss to the node.
It is important that this key not be released to a node until we are certain that (1) the node is the one it claims to be and (2) that it is running in a trusted environment.
We now have both those assurances.
At this point the node enters the RELOADING state and invokes frisbee to obtain the actual disk image.
After the disk has been loaded but before handing off to the OS on the disk (RELOADDONE), the TDLS "invalidates" the PCR state so that the soon-to-be-booted OS cannot produce a quote using the state of those registers.
This prevents the loaded OS, which is not trusted, from participating in the TDLS protocol.The TDLS makes an explicit hand-off using PCR 15 and a mandatory final quote to Emulab's boss server.
This PCR is set to zero by a reboot (and only by a reboot), and the TDLS includes its value in all quotes to boss.
A zero in PCR 15 is the boss-visible indicator that the node is executing the trusted disk-loading protocol.To invalidate the PCR state, the secure disk-loading MFS extends a known value into PCR 15, which sets the PCR to a non-zero value.
The MFS then produces and transmits a final quote, including this non-zero measurement, to signal that the trusted image load has completed (TPMSIGNOFF).
3 The secure disk-loading protocol ends when the diskloading MFS signs off.
It still remains, however, to boot the node from the downloaded disk.After sending its final quote, the MFS immediately reboots its node.
This re-engages the BIOS boot ( §3.2.1), which runs our modified gPXE ( §3.2.2), which securely downloads our modified GRUB ( §3.2.3), which securely contacts the bootinfo service.
In the TDLS protocol, bootinfo would tell the node to download the diskloading MFS.
Now, however, bootinfo tells the node to boot from its local disk-i.e., the image that was just downloaded.
GRUB immediately invalidates the node's PCR state, transmits the "sign-off" quote to boss, and proceeds to boot the on-disk OS.Because disk loading and disk booting are separate, an attacker might try to subvert correct booting by modifying the node between these steps.
We believe that such attacks are infeasible without physical access to the PC or compromising the Emulab software.
Even when not in the TDLS, TPM-enabled nodes use the secure boot procedure up to the GRUB stage, which mutually authenticates the node and the true Emulab boss.
Failure to boot through the secure path will be discovered through an incorrect quote or timeout.
Because of the size and dynamic nature of Emulab, it is essential to consider the tasks required to set up and maintain the TDLS.The most labor-intensive one-time task is installing USB flash devices on all machines.
Because the USBbased gPXE image contains no node-specific information, this is reduced to a task of physical replication.Another task is the creation of the two per-node TPMencrypted keys: the AIK used to produce quotes, and the TLS key (and certificate) used to authenticate a node to boss.
These steps must be performed on the nodes themselves, when they are in a secure state.
This can likely be automated, running a script in the gPXE environment and taking advantage of its ability to securely identify and communicate with boss.Likewise, the correct values of the PCRs used in quotes must be produced for each node and stored in Emulab's database.
The initial values covering the BIOS measurements must be computed on the TPM of every node, and must be harvested in the same way as the pernode keys.
Additional values covering gPXE and later stages can be computed offline by using the SHA-1 algorithm used by the TPM standard.Changes to the TDLS, or the addition of other trusted boot paths, require the collection of additional PCR values.
As long as all are based on booting through gPXE, we can compute these values offline.
To recap, Emulab needs a trusted disk-loading system because (1) users have "root" access to physical PCs; (2) Emulab serially reuses PCs over time for many experiments and users; and (3) Emulab reconditions PCs for experiments using a network server (boss).
The primary threats to conditioning a PC for a new experiment arise from (1) software left on the PC by a prior experiment and (2) network communication that attempts to hijack or abort the network-booting protocol.
The design of the TDLS is shaped by the Emulab environment, in which (1) the central boss server is trusted; (2) users access devices remotely; (3) users can create arbitrary disk images; and (4) testbed scale necessitates full automation.
Emulab's TDLS uses TPM technology to address the security challenges of configuring newly allocated PCs according to users' specifications in this environment.
Because many of above qualities are shared by Emulab and other environments, we believe our TDLS design could be the basis for similar services in other testbeds or clusters.
The xCAT 2 toolkit [16], for example, supports user-provisioning of physical PCs in clusters.
Although many cloud and grid platforms allow users to allocate virtual machines only, our TDLS could nevertheless be useful to the providers of cloud and grid services who must manage the underlying physical resources.
Our trusted disk-loading system for Emulab is not yet in production use.
However, in designing and implementing our prototype, we identified two principles that we believe are general.
We believe these "lessons learned" could be usefully applied to similar, trustworthy nodeconfiguration systems for security-conscious testbeds.Check in frequently to minimize damage.
While it would be possible to check boot state only at the end of the device "reconditioning" process, the timeout in some states may be very long.
If attestation is performed only at the end of the node-configuration process, it is not possible for a testbed to detect nodes that have left the trusted boot path until all timeouts have expired.
Performing attestations frequently, at a number of boot stages, helps to minimize the window of opportunity for attackers.Make an explicit transition to untrusted code.
The TDLS relies on a trusted boot path and disk loader to load and boot untrusted user code.
TPM-based attestation can make the transition point visible ( §3.2.5, §3.2.6) and prevent user code from impersonating trusted code.
Emulab's TDLS establishes only the initial condition of a physical PC that has been allocated to an experiment.
This purpose distinguishes our TDLS from prior work that uses the TPM to implement secure bootloading, integrity guarantees, and execution services.Emulab's TDLS is not "just" a secure bootloader; it is a large system that embeds a secure bootloader to implement a particular, staged, disk-loading protocol.
The goal of a typical secure bootloader is to ensure properties of the "user-visible" OS being booted.
In contrast, the task of the TDLS is only to ensure that a machine is ready to boot the user-visible OS, and is independent of the properties of that OS.
The security (or insecurity) of the OS contained within an Emulab disk image is explicitly up to the experimenter.
This is necessarily so: for security-related experiments, users must be allowed to install whatever OSes they choose.This difference in purpose leads to differences in design.
TrustedGRUB [12], for instance, uses the TPM to measure not only the binary of the kernel being loaded, but also individual files that are important to the system.
In contrast, Emulab's TDLS is designed to load entire disk images, so measuring the kernel or individual files within a disk image is unnecessary.Our TDLS uses a static root of trust for measurement (SRTM): i.e., measurement of a system's BIOS at boot time.
The OSLO bootloader by Kauer [8] establishes a dynamic root of trust by using the "late launch" features of recent AMD processors.
This technique removes the BIOS from the trusted computing base, which is useful in principle and practice.
We chose to use the SRTM in our TDLS.
Unlike OSLO, TDLS incorporates an agent (boss) that can be trusted to demand quotes, verify them, and take corrective actions.There is much work that aims to provide integrity guarantees to running operating systems.
Examples include SecVisor [13], a hypervisor that protects a kernel against code-injection attacks; Livewire [5], an intrusiondetection system based on VM introspection; Terra [4], a trusted virtual machine monitor that protects virtual machines from each other and from the underlying platform; and rootkit-resistant disks [1], which prevent system files from being modified on a node's persistent store.
Unlike these systems, our TDLS guarantees only the initial state of a user-chosen operating system.
Our TDLS provides integrity at the start of a testbed-based experiment, not within a running experiment.
Also, because Emulab provides users with unmediated access to physical devices, our TDLS avoids hypervisor-and VM-based approaches to ensuring the integrity of nodes.Flicker [9] uses TPM and late-launch features to create trustworthy environments for code execution.
Flicker allows code to be executed securely at essentially any time, whereas our TDLS is concerned with executing code only at node-configuration time.
A possible future project would be to use Flicker to allow a testbed to securely monitor experiments over their full lifetimes.
We have presented a new trusted disk-loading system for Emulab.
The task of the TDLS is to gain control over a physical PC, which may be in a nearly arbitrary state, and set its state as directed by Emulab.
In particular, the TDLS is responsible for establishing the initial condition of a PC that has been allocated to an experiment.
We have identified ways in which Emulab's standard diskloading system can be subverted by an attacker, thus causing initial conditioning to fail.
Using the TPM of modern PCs, our TDLS addresses these threats to reliable disk loading.
We believe our system is practical to deploy and maintain at the scale of hundreds of physical PCs, and in the face of constant testbed evolution.
We thank Ryan Jackson for his assistance with gPXE and the secure disk-loading MFS.
We also thank the anonymous CSET reviewers for their constructive comments.This material is based upon work supported by the National Science Foundation under Grant No. 0709427.
