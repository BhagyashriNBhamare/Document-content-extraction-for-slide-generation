How can we generate realistic graphs?
In addition, how can we do so with a mathematically tractable model that makes it feasible to analyze their properties rigorously?
Real graphs obey a long list of surprising properties: Heavy tails for the in-and out-degree distribution; heavy tails for the eigenvalues and eigenvectors; small diameters; and the recently discovered "Densification Power Law" (DPL).
All published graph generators either fail to match several of the above properties, are very complicated to analyze mathematically, or both.
Here we propose a graph generator that is mathematically tractable and matches this collection of properties.
The main idea is to use a non-standard matrix operation, the Kronecker product, to generate graphs that we refer to as "Kronecker graphs".
We show that Kronecker graphs naturally obey all the above properties; in fact, we can rigorously prove that they do so.
We also provide empirical evidence showing that they can mimic very well several real graphs.
What do real graphs look like?
How do they evolve over time?
How can we generate synthetic, but realistic, time-evolving graphs?
Graph mining has been attracting much interest recently, with an emphasis on finding patterns and abnormalities in social networks, computer networks, e-mail interactions, gene regulatory networks, and many more.
Most of the work focuses on static snapshots of graphs, where fascinating "laws" have been discovered, including small diameters and heavy-tailed degree distributions.A realistic graph generator is important for at least two reasons.
The first is that it can generate graphs for extrapolations, "what-if" scenarios, and simulations, when real graphs are difficult or impossible to collect.
For example, how well will a given protocol run on the Internet five years from now?
Accurate graph generators can produce more realistic models for the future Internet, on which simulations can be run.
The second reason is more subtle: it forces us to think about the patterns that a graph generator should obey, to be realistic.The main contributions of this paper are the following:• We provide a generator which obeys all the main static patterns that have appeared in the literature.
• Generator also obeys the recently discovered temporal evolution patterns.
• Contrary to other generators that match this combination of properties, our generator leads to tractable analysis and rigorous proofs.Our generator is based on a non-standard matrix operation, the Kronecker product.
There are several theorems on Kronecker products, which actually correspond exactly to a significant portion of what we want to prove: heavy-tailed distributions for in-degree, out-degree, eigenvalues, and eigenvectors.
We also demonstrate how a Kronecker Graph can match the behavior of several real graphs (patent citations, paper citations, and others).
While Kronecker products have been studied by the algebraic combinatorics community (see e.g. [10]), the present work is the first to employ this operation in the design of network models to match real datasets.The rest of the paper is organized as follows: Section 2 surveys the related literature.
Section 3 gives the proposed method.
We present the experimental results in Section 4, and we close with some discussion and conclusions.
First, we will discuss the commonly found (static) patterns in graphs, then some recent patterns on temporal evolution, and finally, the state of the art in graph generation methods.Static Graph Patterns: While many patterns have been discovered, two of the principal ones are heavy-tailed degree distributions and small diameters.Degree distribution: The degree-distribution of a graph is a power law if the number of nodes c k with degree k is given by c k ∝ k −γ (γ > 0) where γ is called the power-law exponent.
Power laws have been found in the Internet [13], the Web [15,7], citation graphs [24], online social networks [9] and many others.
Deviations from the power-law pattern have been noticed [23], which can be explained by the "DGX" distribution [5].
DGX is closely related to a truncated lognormal distribution.Small diameter: Most real-world graphs exhibit relatively small diameter (the "small-world" phenomenon): A graph has diameter d if every pair of nodes can be connected by a path of length at most d.
The diameter d is susceptible to outliers.
Thus, a more robust measure of the pairwise distances between nodes of a graph is the effective diameter [26].
This is defined as the minimum number of hops in which some fraction (or quantile q, say q = 90%) of all connected pairs of nodes can reach each other.
The effective diameter has been found to be small for large real-world graphs, like Internet, Web, and social networks [2,21].
Scree plot: This is a plot of the eigenvalues (or singular values) of the adjacency matrix of the graph, versus their rank, using a log-log scale.
The scree plot is also often found to approximately obey a power law.
The distribution of eigenvector components (indicators of "network value") has also been found to be skewed [9].
Apart from these, several other patterns have been found, including the "stress" [14,9], "resilience" [2,22], "clustering coefficient" and many more.Temporal evolution Laws: Densification and shrinking diameter: Two very recent discoveries, both regarding time-evolving graphs, are worth mentioning [18]: (a) the "effective diameter" of graphs tends to shrink or stabilize as the graph grows with time, and (b) the number of edges E(t) and nodes N (t) seems to obey the densification power law (DPL), which states thatE(t) ∝ N (t) a(1)The densification exponent a is typically greater than 1, implying that the average degree of a node in the graph is increasing over time.
This means that real graphs tend to sprout many more edges than nodes, and thus are densifying as they grow.Graph Generators: The earliest probabilistic generative model for graphs was a random graph model, where each pair of nodes has an identical, independent probability of being joined by an edge [11].
The study of this model has led to a rich mathematical theory; however, this generator produces graphs that fail to match real-world networks in a number of respects (for example, it does not produce heavy-tailed degree distributions).
The vast majority of recent models involve some form of preferential attachment [1,2,28,15,16]: new nodes join the graph at each time step, and preferentially connect to existing nodes with high degree (the "rich get richer").
This simple behavior leads to power-law tails and to low diameters.
The diameter in this model grows slowly with the number of nodes N , which violates the "shrinking diameter" property mentioned above.Another family of graph-generation methods strives for small diameter, like the small-world generator [27] and the Waxman generator [6].
A third family of methods show that heavy tails emerge if nodes try to optimize their connectivity under resource constraints [8,12].
Summary: Most current generators focus on only one (static) pattern, and neglect the others.
In addition, it is usually hard to prove properties of them.
The generator we describe in the next section addresses these issues.
The method we propose is based on a recursive construction.
Defining the recursion properly is somewhat subtle, as a number of standard, related graph construction methods fail to produce graphs that densify according to the patterns observed in practice, and they also produce graphs whose diameters increase.
To produce densifying graphs with constant diameter, and thereby match the qualitative behavior of real network datasets, we develop a procedure that is best described in terms of the Kronecker product of matrices.
To help in the description of the method, the accompanying table provides a list of symbols and their definitions.
G 1 the initiator of a Kronecker Graph N 1 number of nodes in initiator E 1 number of edges in initiator G [k] 1 = G k the k th Kronecker power of G 1 a densification exponent ddiameter of a graph P 1 probability matrix The main idea is to create self-similar graphs, recursively.
We begin with an initiator graph G 1 , with N 1 nodes and E 1 edges, and by recursion we produce successively larger graphsG 2 . . . G n such that the k th graph G k is on N k = N k 1nodes.
If we want these graphs to exhibit a version of the Densification Power Law, then G k should have E k = E k 1 edges.
This is a property that requires some care in order to get right, as standard recursive constructions (for example, the traditional Cartesian product or the construction of [4]) do not satisfy it.It turns out that the Kronecker product of two matrices is the perfect tool for this goal.
The Kronecker product is defined as follows: and B of sizes n × m and n 񮽙 × m 񮽙 respectively, the Kronecker product matrix C of dimensions (n * n 񮽙 ) × (m * m 񮽙 ) is given byC = A ⊗ B .
= ⎛ ⎜ ⎜ ⎜ ⎝ a 1,1 B a 1,2 B . . . a 1,m B a 2,1 B a 2,2 B . . . a 2,m B . . . . . . . . . . . .
a n,1 B a n,2 B . . . a n,m B ⎞ ⎟ ⎟ ⎟ ⎠ (2)We define the Kronecker product of two graphs as the Kronecker product of their adjacency matrices.
Edge (X ij , X kl ) ∈ G ⊗ H iff (X i , X k ) ∈ G and (X j , X l ) ∈ Hwhere X ij and X kl are nodes in G ⊗ H, and X i , X j , X k and X l are the corresponding nodes in G and H, as in Figure 1.
00 00 00 00 11 11 11 11 000 000 000 000 111 111 111 111 000 000 000 000 111 111 111 111 00 00 00 00 11 11 11 11 000 000 000 000 111 111 111 111 00 00 00 00 11 11 11 11 00 00 00 00 11 11 11 11 00 00 00 00 11 11 11 11 00 00 00 00 11 11 11 11X 3,3 X 2,3Central node is X 2,2X 3,1 X 3,2 X 1,1 X 1,2 X 1,3X 2,1 00 00 00 00 00 11 11 11 11 11 00 00 00 00 00 11 11 11 11 11 00 00 00 00 11 11 11 11 00 00 00 00 00 11 11 11 11 11 00 00 00 00 00 11 11 11 11 11 00 00 00 00 11 11 11 11 000 000 000 000 000 111 111 111 111 111 000 000 000 000 000 111 111 111 111 111 000 000 000 000 111 111 111 111 Figure 1(b)), and in fact is the X 2 node (i.e., the center) within this small H-graph.
(a) Graph G1 (b) Intermediate stage (c) Graph G2 = G1 ⊗ G1 1 1 0 1 1 1 0 1 1 G 1 G 1 G 1 G 1 G 1 G 1 G 1 0 0 (d) Adjacency matrix (e) Adjacency matrix (f) Plot of G4 of G1 of G2 = G1 ⊗ G1We propose to produce a growing sequence of graphs by iterating the Kronecker product: Definition 2 (Kronecker power).
The k th power of G 1 is defined as the matrix G [k] 1 (abbreviated to G k ), such that:G [k] 1 = G k = G 1 ⊗ G 1 ⊗ . . . G 1 񮽙 񮽙񮽙 񮽙 k times = G k−1 ⊗ G 1The self-similar nature of the Kronecker graph product is clear: To produce G k from G k−1 , we "expand" (replace) each node of G k−1 by converting it into a copy of G, and we join these copies together according to the adjacencies in G k−1 (see Figure 1).
This process is very natural: one can imagine it as positing that communities with the graph grow recursively, with nodes in the community recursively getting expanded into miniature copies of the community.
Nodes in the subcommunity then link among themselves and also to nodes from different communities.
We shall now discuss the properties of Kronecker graphs, specifically, their degree distributions, diameters, eigenvalues, eigenvectors, and time-evolution.
Our ability to prove analytical results about all of these properties is a major advantage of Kronecker graphs over other generators.
The next few theorems prove that several distributions of interest are multinomial for our Kronecker graph model.
This is important, because a careful choice of the initial graph G 1 can make the resulting multinomial distribution to behave like a power-law or DGX distribution.Theorem 1 (Multinomial degree distribution).
Kronecker graphs have multinomial degree distributions, for both in-and out-degrees.
Proof.
Let the initiator G 1 have the degree sequence d 1 , d 2 , . . . , d N1 .
Kronecker multiplication of a node with degree d expands it into N 1 nodes, with the corresponding degrees beingd × d 1 , d × d 2 , . . . , d × d N1 .
After Kronecker powering, the degree of each node in graph G k is of the form d i1 × d i2 × . . . d i k , with i 1 , i 2 , . . . i k ∈ (1 . . . N 1 ), and there is one node for each ordered combination.
This gives us the multinomial distribution on the degrees of G k .
Note also that the degrees of nodes in G k can be expressed as the k th Kronecker power of the Proof.
Let G 1 have the eigenvalues λ 1 , λ 2 , . . . , λ N1 .
By properties of the Kronecker multiplication [19,17], the eigenvalues of G k are k th Kronecker power of the vector (λ 1 , λ 2 , . . . , λ N1 ).
As in Theorem 1, the eigenvalue distribution is a multinomial.
QED A similar argument using properties of Kronecker matrix multiplication shows the following.vector (d 1 , d 2 , . . . , d N1 ).
We have just covered several of the static graph patterns.
Notice that the proofs were direct consequences of the Kronecker multiplication properties.Next we continue with the temporal patterns: the densification power law, and shrinking/stabilizing diameter.
with densification exponent a = log(E 1 )/ log(N 1 ).
Proof.
Since the k th Kronecker power G k has N k = N k 1 nodes and E k = E k 1 edges, it satisfies E k = N a k , where a = log(E 1 )/ log(N 1 ).
The crucial point is that this exponent a is independent of k, and hence the sequence of Kronecker powers follows an exact version of the Densification Power Law.
QED We now show how the Kronecker product also preserves the property of constant diameter, a crucial ingredient for matching the diameter properties of many real-world network datasets.
In order to establish this, we will assume that the initiator graph G 1 has a self-loop on every node; otherwise, its Kronecker powers may in fact be disconnected.
Proof.
Each node in G ⊗ H can be represented as an ordered pair (v, w), with v a node of G and w a node of H, and with an edge joining (v, w) and (x, y) precisely when (v, x) is an edge of G and (w, y) is an edge of H. Now, for an arbitrary pair of nodes (v, w) and (v 񮽙 , w 񮽙 ), we must show that there is a path of length at most d connecting them.
Since G has diameter at most d, there is a path v = v 1 , v 2 , . . . , v r = v 񮽙 , where r ≤ d.
If r < d, we can convert this into a path v = v 1 , v 2 , . . . , v d = v 񮽙 of length exactly d, by simply repeating v 񮽙 at the end for d − r times By an analogous argument, we have a path w = w 1 , w 2 , . . . , w d = w 񮽙 .
Now by the definition of the Kronecker product, there is an edge joining (v i , w i ) and (v i+1 , w i+1 ) for all 1 ≤ i ≤ d − 1, and so (v, Proof.
This follows directly from the previous lemma, combined with induction on k. QED We also consider the effective diameter d e ; we define the q-effective diameter as the minimum d e such that, for at least a q fraction of the reachable node pairs, the path length is at most d e .
The q-effective diameter is a more robust quantity than the diameter, the latter being prone to the effects of degenerate structures in the graph (e.g. very long chains); however, the q-effective diameter and diameter tend to exhibit qualitatively similar behavior.
For reporting results in subsequent sections, we will generally consider the q-effective diameter with q = .9, and refer to this simply as the effective diameter.w) = (v 1 , w 1 ), (v 2 , w 2 ), . . . , (v d , w d ) = (v 񮽙 , wTheorem 6 (Effective Diameter).
If G 1 has diameter d and a self-loop on every node, then for every q, the q-effective diameter of G k converges to d (from below) as k increases.Proof.
To prove this, it is sufficient to show that for two randomly selected nodes of G k , the probability that their distance is d converges to 1 as k goes to infinity.We establish this as follows.
Each node in G k can be represented as an ordered sequence of k nodes from G 1 , and we can view the random selection of a node in G k as a sequence of k independent random node selections from G 1 .
Suppose that v = (v 1 , . . . , v k ) and w = (w 1 , . . . , w k ) are two such randomly selected nodes from G k .
Now, if x and y are two nodes in G 1 at distance d (such a pair (x, y) exists since G 1 has diameter d), then with probability 1 − (1 − 2/N 1 ) k , there is some index j for which {v j , w j } = {x, y}.
If there is such an index, then the distance between v and w is d.
As the expression 1 − (1 − 2/N 1 ) k converges to 1 as k increases, it follows that the q-effective diameter is converging to d. QED While the Kronecker power construction discussed thus far yields graphs with a range of desired properties, its discrete nature produces "staircase effects" in the degrees and spectral quantities, simply because individual values have large multiplicities.
Here we propose a stochastic version of Kronecker graphs that eliminates this effect.
counterparts.We start with an N 1 × N 1 probability matrix P 1 : the value p ij denotes the probability that edge (i, j) is present.
We compute its k th Kronecker power P [k] 1 = P k ; and then for each entry p uv of P k , we include an edge between nodes u and v with probability p u,v .
The resulting binary random matrix R = R(P k ) will be called the instance matrix (or realization matrix).
In principle one could try choosing each of the N 2 1 parameters for the matrix P 1 separately.
However, we reduce the number of parameters to just two: α and β.
Let G 1 be the initiator matrix (binary, deterministic); we create the corresponding probability matrix P 1 by replacing each "1" and "0" of G 1 with α and β respectively (β ≤ α).
The resulting probability matrices maintain -with some random noise -the self-similar structure of the Kronecker graphs in the previous subsection (which, for clarity, we call deterministic Kronecker graphs).
We find empirically that the random graphs produced by this model continue to exhibit the desired properties of real datasets, and without the staircase effect of the deterministic version.
The task of setting α and β to match observed data is a very promising research direction, outside the scope of this paper.
In our experiments in the upcoming sections, we use heuristics which we describe there.
Now, we demonstrate the ability of Kronecker graphs to match the patterns of real-world graphs.
The datasets we use are:• arXiv: This is a citation graph for high-energy physics research papers, with a total of N = 29, 555 papers and E = 352, 807 citations.
We follow its evolution from January 1993 to April 2003, with one data-point per month.
• Patents: This is a U.S. patent citation dataset that spans 37 years from January 1963 to December 1999.
The graph contains a total of N = 3, 942, 825 patents and E = 16, 518, 948 citations.
Citation graphs are normally considered as directed graphs.
For the purpose of this work we think of them as undirected.
• Autonomous systems: We also analyze a static dataset consisting of a single snapshot of connectivity among Internet autonomous systems from January 2000, with N = 6, 474 and E = 26, 467.
We observe two kinds of graph patterns -"static" and "temporal."
As mentioned earlier, common static patterns include the degree distribution, the scree plot (eigenvalues of graph adjacency matrix vs. rank), principal eigenvector of adjacency matrix and the distribution of connected components.
Temporal patterns include the diameter over time, the size of the giant component over time, and the densification power law.
For the diameter computation, we use a smoothed version of the effective diameter that is qualitatively similar to the standard effective diameter, but uses linear interpolation so as to take on noninteger values; see [18] for further details on this calculation.Results are shown in Figures 2 and 3 for the graphs which evolve over time (arXiv and Patents).
For brevity, we show the plots for only two static and two temporal patterns.
We see that the deterministic Kronecker model already captures the qualitative structure of the degree and eigenvalue distributions, as well as the temporal patterns represented by the Densification Power Law and the stabilizing diameter.
However, the deterministic nature of this model results in "staircase" behavior, as shown in scree plot for the deterministic Kronecker graph of Figure 2 (second row, second column).
We see that the Stochastic Kronecker Graphs smooth out these distributions, further matching the qualitative structure of the real data; they also match the shrinking-before-stabilization trend of the diameters of real graphs.For the Stochastic Kronecker Graphs we need to estimate the parameters α and β defined in the previous section.
This leads to interesting questions whose full resolution lies beyond the scope of the present paper; currently, we searched by brute force over (the relatively small number of) possible initiator graphs of up to five nodes, and we then chose α and β so as to match well the edge density, the maximum degree, the spectral properties, and the DPL exponent.Finally, Figure 4 shows plots for the static patterns in the Autonomous systems graph.
Recall that we analyze a single, static snapshot in this case.
In addition to the degree distribution and scree plot, we also show two typical plots [9]: the distribution of network values (principal eigenvector components, sorted, versus rank) and the hop-plot (the number of reachable pairs P (h) within h hops or less, as a function of the number of hops h).
Here we list several of the desirable properties of the proposed Kronecker Graphs and Stochastic Kronecker Graphs.Generality: Stochastic Kronecker Graphs include several other generators, as special cases: For α=β, we obtain an Erd˝ os-Rényi random graph; for α=1 and β=0, we obtain a deterministic Kronecker graph; setting the G 1 matrix to a 2x2 matrix, we obtain the RMAT generator [9].
In contrast to Kronecker graphs, the RMAT cannot extrapolate into the future, since it needs to know the number of edges to insert.
Thus, it is incapable of obeying the "densification law".
Phase transition phenomena: The Erd˝ os-Rényi graphs exhibit phase transitions [11].
Several researchers argue that real systems are "at the edge of chaos" [3,25].
It turns out that Stochastic Kronecker Graphs also exhibit phase transitions.
For small values of α and β, Stochastic Kronecker Graphs have many small disconnected components; for large values they have a giant component with small diameter.
In between, they exhibit behavior suggestive of a phase transition: For a carefully chosen set of (α, β), the diameter is large, and a giant component just starts emerging.
We omit the details, for lack of space.
Theory of random graphs: All our theorems are for the deterministic Kronecker Graphs.
However, there is a lot of work on the properties of random matrices (see e.g. [20]), which one could potentially apply in order to prove properties of the Stochastic Kronecker Graphs.In conclusion, the main contribution of this work is a family of graph generators, using a non-traditional matrix operation, the Kronecker product.
The resulting graphs (a) have all the static properties (heavy-tailed degree distribution, small diameter), (b) all the temporal properties (densification, shrinking diameter), and in addition, (c) we can formally prove all of these properties.Several of the proofs are extremely simple, thanks to the rich theory of Kronecker multiplication.
We also provide proofs about the diameter and "effective diameter", and we show that Stochastic Kronecker Graphs can be tuned to mimic real graphs well.
show two more static patterns (see text).
Notice that, again, the Stochastic Kronecker Graph matches well the properties of the real graph.
