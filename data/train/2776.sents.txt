As more sensors and actuators are deployed in industrial manufacturing, the industry requires a new production system architecture that offers better real-time and network transmission performance.
Yet cloud computing (based on a centralized datacenter) is limited in its possibilities, because it suffers from heavy bandwidth costs and lengthy time delays.
As a solution, we propose an industrial robot system based on edge computing.
Here, we present its three-layer architecture in detail: the cloud, edge, and physical resource layers.
Initially, we deploy an edge node near the data sources, to integrate various devices' interfaces and acts as a raw data filter.
Then, we apply the proposed system on the robot-ic welding of the membrane wall cell.
Finally, we test the system by conducting an experiment.
The results demonstrate the system's feasibility and prove that the system yields better real-time and network transmission performance than a cloud-based scenario.
The cloud layer works as the robot system's service coordinator and supervisor.
Users are able to access the cloud over the network via an API.
The cloud layer's core component-the service management-coherently manages service and executes the service packages accordingly.
It keeps track of the state of available resources (information provided by the monitoring service) to identify the best candidates for hosting an application module and allocating the device's resources.
The management based on the quality of services requirements is posed by the robot application, so that the robot application receives the quality it needs.
It can also adjust the service-management policy's complexity to migrate components and allocate device resources dynamically to components based on diverse criteria (such as perceived latency)-or make the policy as simple as provisioning components statically on an edge device.
The current version offers the latter policy (static application placement).
With today's wide-ranging Internet, various robot resources and abilities are sensed and connected easily.
The robot resources and abilities are encapsulated into different robot cloud services (RCSs) that can be accessed, invoked, and deployed.
The RCSs are classified and aggregated according to specific rules and algorithms.
Users can search and invoke the qualified RCSs from a related robot cloud.
The cloud primarily provides two categories of service: the motion cloud service (MCS), and the process cloud service (PCS).
The MCS is the result of the robot motion ability's service encapsulation, which includes the control algorithm as path planning; forward and inverse kinematics; collision detection, and simulation.
The PCS provides various processes and skills that the tasks need, such as welding, assembling, stamping, and painting.
The edge layer provides a platform for filtering and analyzing data generated by sensors, making the data processing architecture distributed, and thereby scalable.
This layer's devices are any elements capable of hosting application modules, such as servers, local PC, routers, and gateways.
Between the cloud and physical resource layer, the edge layer is optional for three main reasons.First, to accomplish complex tasks, a huge amount of field data (such as power, current, and force) is generated dynamically by sensors.
It is inefficient to stream all the raw data directly to the cloud, because most content is unessential and generates heavy network traffics.
Thus, the edge can filter and preprocess data.
Then the filtered result is uploaded to the cloud.
This helps to balance the bandwidth load and manage cloud data.Second, the challenge is to achieve the real-time capability of the robot control's functions.
Because some functions are dependent on actual measured values during processing, they cannot tolerate a large latency.
In cloud robotics, running the control system on the cloud may be unavailable because of communication failures.
Thus, an edge device is needed to keep the real-time capability upright through short communication paths by placing the control system near to the robots.Third, in some cases, most of the sensors, cameras and so forth are not cloud-ready.
So an edge device can act as an interface and interact with the sensors (over IoT, in most cases) and communicate with the cloud.
At the physical resource layer, robot controllers interpret the task files received from the cloud and generate movement instructions.
These instructions, including the interpolation method and target point, are sent to drive the servos.
The robot controller can function in real time, and the embedded system implements any critical real-time functions for robot control.The production process is measured and monitored by sensors, such as cameras and smart meters.
The measuring results processed by edge devices are fed back to the cloud for simulation, monitoring, performance evaluation, motion planning, and path compensation.
Thus, it forms a closed-loop robot system.
To validate and evaluate the proposed robot system, the system was implemented on a robot cell for membrane wall welding.
Membrane walls are one of the most important components in the boiler industry.
They are composed of many long, thin steel tubes, welded together longitudinally using numerous pins (see Fig. 2a).
Membrane walls are usually very big in size (over 10m long and 7~9m wide).
The existing welding method for a membrane wall is manual spot-welding.
The welding points are marked on the surface of tubes with chalk.Workers are assigned to different areas of the same wall to weld artificially (Fig. 2b).
Without an online deformation measurement, manual welding has low efficiency and accuracy.
However, industry robots can be used to weld the membrane wall.
We designed an industry robot system to weld the membrane wall.
This case consists of several subtasks.In terms of the computer-aided design (CAD) model, the motion program is generated by an offline programming system.
Using sensor feedback, the system can compute the welding points' poses on the tube and compensate the deformation.
Then the motion path is downloaded and sent to the robot controller.
A gantry or external axis carries the robot to weld pins in the big workpiece.
Limited to the single robot power and storage, we used the edge computing-based system to this application.
Fig. 3 presents the architecture of the robotic welding use case.
Most of the subtasks are computationintensive, requiring high computational performance from the system.
Cloud computing offers robust power, but uploading all the raw data to the cloud takes significant time and bandwidth, which severely diminishes the real-time performance.
To contend with this, in the system we developed an edge node and deployed devices' API and pose measurement on it.
The result of the subtask pose measurement is urgently needed for compensating the preplanned paths on the cloud, thus it is assigned to the edge node.
This offers an elegant solution, because on one hand, now the edge node directly communicates with the robot cell through API.
On the other hand, it filters raw data and sends vital information to the cloud.
Other tasks are predefined and assigned to the cloud.
Fig. 4 shows the system network configuration.
The cloud is deployed on the Internet.
The edge node monitors and manages the physical resources at the workstation level.
Inside the workstation, a local area network (LAN) is established through a router, which ensures a high speed of data transmission.
Each device in the field is assigned a logical address.
Therefore, an edge node serves one robotic task.
For the sake of security, the LAN can block the external network.
In the future, we plan to establish a private cloud and use access authentication to further augment security.
x x count stepdistance y y R z z R                 (1)where R: the tube radius; θ: the angle between the pin axial and Z axis; (x 0 ,y 0 ,z 0 ): the center coordinate of a specific section; count: the index of current section; and stepdistance: the distance between every two adjacent sections.
To avoid collision between the tool and welded pins, the intermediate points are needed.
The intermediate point's coordinate (x,y,z) is Deformations and warps may occur while the tube is being welded (see Fig. 6).
Besides, the deviations between the CAD model and the membrane wall are inevitable.
The preplanned paths should be calibrated and compensated by the measurement data.
We use a light section sensor (a non-compact laser sensor) to measure the profile of cylindrical objects in the cross-section.
The raw data is a set of discrete coordinates.
The section center coordinate, radius, and orientation of the current tube are obtained by recognizing and fitting raw data into an ellipse.
The elliptic parameters include a center coordinate (x c ,y c ,z c ), major semi-axis a, minor semi-axis b, and the major axis deflection angle β.
Related methods are elaborately introduced in [22].
In the XY plane, the angle φ equals the anti-cosine of b and a.
That is, φ= rcos(b/a).
In the XZ plane, we can determine the angle β using the fitting result.
We can calculate the matrix of the final processing point T Up T as1 0 0 0 cos sin ( , ) ( , ) 0 sin cos 0 0 0 1                    c T c Up c x y T R Y R Z z(3)wherecos sin 0 0 sin cos 0 0 ( , ) 0 0 1 0 0 0 0 1                RZ (4) cos 0 sin 0 0 1 0 0 ( , ) sin 0 cos 0 0 0 0 1 RY                 (5)It is worth mentioning that the above formulas look simple, but over a big size membrane wall, for every 40mm interval in the longitudinal direction of one tube, 5~6 track points are needed to be calculated, which brings a big load for the system, especially for the iterative process in pose measurement.
To enhance the system reliability, diverse component failure (device faults, network failure and the data loss) are taken into consideration.
We establish a state table and design a polling program to periodically capture the devices' states.
At present, we will stop the running system once the cloud or the edge breaks down.
At the physical resource level, the collision detection algorithm is equipped to ensure the field security.
To prevent the data loss, such as the sensor detected data, the back-up of the primitive data will be uploaded to the cloud when it is free.
More work of this part is now on developing and will be presented in the future.
We used a Motoman robot MH50II, a light section sensor, a torch model, and a membrane wall to verify the system (see Fig. 7).
The light section sensor is a LPS36HI unit of Leuze Electronic.
To compare performance, we tested two approaches: the cloud-based approach and the cloud-edge hybrid approach.
The cloudbased approach uploads all raw data to the cloud and executes all tasks on the cloud.
The cloud-edge hybrid approach executes pose measurements on the edge node and executes the remaining tasks on the cloud.
Table 1 lists the two approaches' tasks.
We deployed the system on the Alibaba Cloud.
The edge is a PC with two cores and 4-gigabyte memories, with a router connecting to physical devices.
We conducted four experiments.
The number of times that sensors detected is 1, 5, 20, and 50, respectively.
Each experiment was executed 10 times, and we calculated the average as the result (see Fig. 8).
Light section sensor Welding torch model Membrane wall sample Figure 7: The experiment layout.
The experimental results show that the time for pose measurement in the cloud-based approach is much shorter than the cloud-edge hybrid approach in all four groups.
That is because in cloud-based approach, this task is executed on the cloud, which is more powerful than the edge node.
There are almost no differences in execution time for path planning, simulation and transferring robot files between two approaches, because they are all conducted in the cloud.It is obvious that the total execution time in the cloudbased approach is far greater than the cloud-edge hybrid approach.
In the first approach, uploading raw data to the cloud takes most of the total execution time.
Although the cloud is computationally more robust, it offers no advantages in terms of real-time performance when the number of times detected increases.
On the other hand, compared to the cloud-based approach, the cloud-edge hybrid approach saves network bandwidth by nearly three orders of magnitude (see Table 2).
We proposed a three-layer (cloud, edge, and physical resource) industrial robot system.
To respond to the lack of cloud computing solutions for aspects of time delay and network transmission, we deployed functions on an edge node to integrate various devices' interfaces and preprocess raw data from the field.
Then, we applied the proposed system to a scenario involving robotic welding on a membrane wall.
Finally, we conducted an experiment.
The results show that our system offers better real-time and network transmission performance than a cloud-based approach.
In the future, we will deploy our system on a private cloud and we intend to develop the dynamic deployment and on-demand allocation between the cloud and the edge.
Furthermore, we will develop the data compression module for the sensor data to further augment system real-time performance.
