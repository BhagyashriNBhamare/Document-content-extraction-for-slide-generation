Malicious URLs have been widely used to mount various cyber attacks including spamming, phishing and mal-ware.
Detection of malicious URLs and identification of threat types are critical to thwart these attacks.
Knowing the type of a threat enables estimation of severity of the attack and helps adopt an effective countermeasure.
Existing methods typically detect malicious URLs of a single attack type.
In this paper, we propose method using machine learning to detect malicious URLs of all the popular attack types and identify the nature of attack a malicious URL attempts to launch.
Our method uses a variety of discriminative features including tex-tual properties, link structures, webpage contents, DNS information, and network traffic.
Many of these features are novel and highly effective.
Our experimental studies with 40,000 benign URLs and 32,000 malicious URLs obtained from real-life Internet sources show that our method delivers a superior performance: the accuracy was over 98% in detecting malicious URLs and over 93% in identifying attack types.
We also report our studies on the effectiveness of each group of discriminative features, and discuss their evadability.
While the World Wide Web has become a killer application on the Internet, it has also brought in an immense risk of cyber attacks.
Adversaries have used the Web as a vehicle to deliver malicious attacks such as phishing, spamming, and malware infection.
For example, phishing typically involves sending an email seemingly from a trustworthy source to trick people to click a URL (Uniform Resource Locator) contained in the email that links to a counterfeit webpage.To address Web-based attacks, a great effort has been directed towards detection of malicious URLs.
A common countermeasure is to use a blacklist of malicious URLs, which can be constructed from various sources, This work was done when Hyunsang Choi was an intern at Microsoft Research Asia.
Contact author: Bin B. Zhu (binzhu@ieee.org).
particularly human feedbacks that are highly accurate yet time-consuming.
Blacklisting incurs no false positives, yet is effective only for known malicious URLs.
It cannot detect unknown malicious URLs.
The very nature of exact match in blacklisting renders it easy to be evaded.This weakness of blacklisting has been addressed by anomaly-based detection methods designed to detect unknown malicious URLs.
In these methods, a classification model based on discriminative rules or features is built with either knowledge a priori or through machine learning.
Selection of discriminative rules or features plays a critical role for the performance of a detector.
A main research effort in malicious URL detection has focused on selecting highly effective discriminative features.
Existing methods were designed to detect malicious URLs of a single attack type, such as spamming, phishing, or malware.In this paper, we propose a method using machine learning to detect malicious URLs of all the popular attack types including phishing, spamming and malware infection, and identify the attack types malicious URLs attempt to launch.
We have adopted a large set of discriminative features related to textual patterns, link structures, content composition, DNS information, and network traffic.
Many of these features are novel and highly effective.
As described later in our experimental studies, link popularity and certain lexical and DNS features are highly discriminative in not only detecting malicious URLs but also identifying attack types.
In addition, our method is robust against known evasion techniques such as redirection [42], link manipulation [16], and fast-flux hosting [17].
Identification of attack types is useful since the knowledge of the nature of a potential threat allows us to take a proper reaction as well as a pertinent and effective countermeasure against the threat.
For example, we may conveniently ignore spamming but should respond immediately to malware infection.
Our experiments on 40,000 benign URLs and 32,000 malicious URLs obtained from real-life Internet sources show that our method has achieved an accuracy rate of more than 98% in detecting malicious URLs and an accuracy rate of more than 93% in identifying attack types.
This paper has the following major contributions:• We propose several groups of novel, highly discriminative features that enable our method to deliver a superior performance and capability on both detection and threat-type identification of malicious URLs of main attack types including spamming, phishing, and malware infection.
Our method provides a much larger coverage than existing methods while maintaining a high accuracy.
• To the best of our knowledge, this is the first study on classifying multiple types of malicious URLs, known as a multi-label classification problem, in a systematic way.
Multi-label classification is much harder than binary detection of malicious URLs since multi-label learning has to deal with the ambiguity that an entity may belong to several classes.The remainder of this paper is organized as follows.
We present the proposed method and the learning algorithms it uses in Section 2, and describe the discriminative features our method uses in Section 3.
Evaluation of our method with real-life data is reported in Section 4.
We review related work in Section 5, and conclude the paper in Section 6.
Our method consists of three stages as shown in Figure 1: training data collection, supervised learning with the training data, and malicious URL detection and attack type identification.
These stages can operate sequentially as in batched learning, or in an interleaving manner: additional data is collected to incrementally train the classification models while the models are used in detection and identification.
Interleaving operations enable our method to adapt and improve continuously with new data, especially with online learning where the output of our method is subsequently labeled and used to train the classification models.
The two tasks performed by our method, detecting malicious URLs and identifying attack types, need different machine learning methods.
The first task is a binary classification problem.
The Support Vector Machine (SVM) is used to detect malicious URLs.
The second task is a multi-label classification problem.
Two multi-label classification methods, (RAkEL [38] and ML-kNN [48]), are used to identify attack types.
Task1: Support Vector Machine (SVM).
SVM is a widely used machine learning method introduced by Vapnik et al. [8].
SVM constructs hyperplanes in a high or infinite dimensional space for classification.
Based on the Structural Risk Maximization theory, SVM finds the hyperplane that has the largest distance to the nearest training data points of any class, called functional margin.
Functional margin optimization can be achieved by maximizing the following equationn ∑ i=1 α i − 1 2 n ∑ i,j=1 α i α j y i y j K(x i , x j ) subject to n ∑ i=1 α i y i = 0, 0 ≤ α i ≤ C, i = 1, 2, ..., nwhere α i and α j are coefficients assigned to training samples x i and x j .
K(x i , x j ) is a kernel function used to measure similarity between the two samples.
After specifying the kernel function, SVM computes the coefficients which maximize the margin of correct classification on the training set.
C is a regulation parameter used for tradeoff between training error and margin, and training accuracy and model complexity.
Task2: RAkEL.
and ML-kNN.
RAkEL is a highperformance multi-label learning method that accepts any multi-label learner as a parameter.
RAkEL creates m random sets of k label combinations, and builds an ensemble of Label Powerset (LP) [47] classifiers from each of the random sets.
LP is a transformation-based algorithm that accepts a single-label classifier as a parameter.
It considers each distinct combination of labels that exists in the training set as a different class value of a single-label classification task.
Ranking of the labels is produced by averaging the zero-one predictions of each model per considered label.
An ensemble voting process under a threshold t is then employed to make a decision for the final classification set.
We use C4.5 [32] as the single-label classifier and LP as a parameter of the multi-label learner.ML-kNN is derived from the traditional k-Nearest Neighbor (kNN) algorithm [1].
For each unseen instance, its k nearest neighbors in the training set are first identified.
Based on the statistical information gained from the label sets of these neighboring instances, maximum a posteriori principle is then utilized to determine the label set for the unseen instance.
Our method uses the same set of discriminative features for both tasks: malicious URL detection and attack type identification.
These features can be classified into six groups: lexicon, link popularity, webpage content, DNS, DNS fluxiness, and network traffic.
They can effectively represent the entire multifaceted properties of a malicious URL and are robust to known evasion techniques.
Malicious URLs, esp.
those for phishing attacks, often have distinguishable patterns in their URL text.
Ten lexical features, listed in Table 1, are used in our method.
Among these lexical features, the average domain/path token length (delimited by '.'
, '/', '?'
, '=', '-', ' ') and brand name presence were motivated from a study by McGrath and Gupta [24] that phishing URLs show different lexical patterns.
For example, a phishing URL likely targets a widely trusted brand name for spoofing, thus contains the brand name.
Therefore, we employ a binary feature to check whether a brand name is contained in the URL tokens but not in its SLD (Second Level Domain) 1 .
In our method, the detection model maintains two lists of URLs: a list of benign URLs and a list of malicious URLs.
The identification model breaks the list of malicious URLs into three lists: spam, phishing, and malware URL lists.
For a URL, our method extracts its SLD and calculates the ratio of the number that the SLD matches SLDs in the list of malicious URLs or a list of specific type of malicious URLs (e.g., spam URL list) to the number that the SLD matches SLDs in the list of benign URLs.
This ratio is called the malicious or a specific attack type (e.g., spam) SLD hit ratio feature, which is actually an a priori probability of the URL to be malicious or of a specific malicious type (e.g., spam) based on the precompiled URL lists.Previous methods use URL tokens as the "bag-ofwords" model in which the information of a token's position in a URL is lost.
By examining a large set of malicious and benign URLs, we observed that the position of a URL token also plays an important role.
SLDs are relatively hard to forge or manipulate than URL tokens at other positions.
Therefore, we discard the widely used "bag-of-words" approach and adopt several new features differentiating SLDs from other positions, resulting in a higher robustness against lexical manipulations by attackers.
Lexical features No. 1 to No. 4 in Table 1 are from previous work.
Feature No. 10 is different from the "bag-of-words" model used in previous work by excluding the SLD position.
The other lexical features in Table 1 are novel features never used previously.
One of the most important features used in our method is "link popularity", which is estimated by counting the number of incoming links from other webpages.
Link popularity can be considered as a reputation measure of a URL.
Malicious sites tend to have a small value of link popularity, whereas many benign sites, especially popular ones, tend to have a large value of link popularity.
Both link popularity of a URL and link popularity of the URL's domain are used in our method.
Link popularity (LPOP) can be obtained from a search engine 2 .
Different search engines may produce different link popularity due to different coverage of webpages each has crawled.
In our method, five popular search engines, Altavista, AllTheWeb, Google, Yahoo!, and Ask, are used to calculate the link popularity of a URL and the link popularity of its domain, corresponding to LPOP features No. 1 to 10 in Table 2.
One problem in using link popularity is "linkfarming [16]", a link manipulation that uses a group of webpages to link together.
To address this problem, we develop five additional LPOP features by exploiting different link properties between link-manipulated malicious websites and popular benign websites.
The first feature, the distinct domain link ratio, is the ratio of the number of unique domains to the total number of domains that link to the targeted URL.
The second feature, the max domain link ratio, is the ratio of the maximum number of links from a single domain to the total number of domains that link to the targeted URL.
Linkmanipulated malicious URLs tend to be linked many times with a few domains, resulting in a low score on the distinct domain link ratio and a high score on the max domain link ratio.
A study by Castillo et al. [4] indicates that spam pages tend to be linked mainly by spam pages.
We believe that a hypothesis to assume that not only spam pages, but also phishing and malware pages tend to be linked by phishing and malware pages, respectively, is plausible.
Therefore, we develop the last three features: spam link ratio, phishing link ratio, and malware link ratio.
Each represents the ratio from domains of a specific malicious type that link to the targeted URL.
To measure these three features, we use the malicious URL lists described in Section 3.1.
The link popularity features described in this subsection are all novel features.
Recent development of the dynamic webpage technology has been exploited by hackers to inject malicious code into webpages through importing and thus hiding exploits in webpage content.
Therefore, statistical properties of client-side code in the Web content can be used as features to detect malicious webpages.
To extract webpage content features (CONTs), we count the numbers of HTML tags, iframes, zero size iframes, lines, and hyperlinks in the webpage content.
We also count the number for each of the following seven suspicious native JavaScript functions: escape(), eval(), link(), unescape(), exec(), link(), and search() functions.
As suggested by a study of Hou et al. [18], these suspicious JavaScript functions are often used by attacks such as cross-site scripting and Web-based malware distribution.
For example, unescape() can be used to decode an encoded shellcode string to obfuscate exploits.
The counts of these seven suspicious JavaScript functions form features No. 6 to No. 12 in Table 3.
The last feature in this table is the the sum of these function counts, i.e., the total count of these suspicious JavaScript functions.
All the features in Table 3 are from the previous work [18].
Line count Integer 5Hyperlink count Integer 6∼12Count of each suspicious JavaScript function Integer 13Total count of suspicious JavaScript functions IntegerThe CONTs may not be effective to distinguish phishing websites from benign websites because a phishing website should have similar content as the authentic website it targets.
However, this very nature of being sensitive to one malicious type but insensitive to other malicious types is very much desired in identifying the type of attack that a malicious URL attempts to launch.
The DNS features are related to the domain name of a URL.
Malicious websites tend to be hosted by less reputable service providers.
Therefore, the DNS information can be used to detect malicious websites.
Ramachandran et al. [33] showed that a significant portion of spammers came from a relatively small collection of autonomous systems.
Other types of malicious URLs are also likely to be hosted by disreputable providers.
Therefore, the Autonomous System Number (ASN) of a domain can be used as a DNS feature.
All the five DNS features listed in Table 4 are novel features.
The first is the number of IPs resolved for a URL's domain.
The second is the number of name servers that serves the domain.
The third is the number of IPs these name servers are associated with.
The next two features are related to ASN.
As we have mentioned in Section 3.1, our method maintains a benign URL list and a malicious URL list.
For each URL in the two lists, we record its ASNs of resolved IPs and ASNs of the name servers.
For a URL, our method calculates hit counts for ASNs of its resolved IPs that matches the ASNs in the malicious URL list.
In a similar manner, it also calculates the ASN hit counts using the benign URL list.
Summation of malicious ASN hit counts and summation of benign ASN hit counts are used to estimate the malicious ASN ratio of resolved IPs, which is used as an a priori probability for the URL to be hosted by a disreputable service provider based on the precompiled URL lists.
ASNs can be extracted from MaxMind's database file [14].
A newly emerging fast-flux service network (FFSN) establishes a proxy network to host illegal online services with a very high availability [17].
FFSNs are increasingly employed by attackers to provide malicious content such as malware, phishing websites, and spam campaigns.
To detect URLs which are served by FFSNs, we use the discriminative features proposed by Holz et al. [17], as listed in Table 5.
φ of N IP , N AS Real 3∼5 φ of N N S , N N SIP , N N SAS RealWe lookup the domain name of a URL and repeat the DNS lookup after TTL (Time-To-Live value in a DNS packet) timeout given in the first answer to have consecutive lookups of the same domain.
Let N IP and N AS be the total number of unique IPs and ASNs of each IP, respectively, and N N S , N N SIP , N N SAS be the total number of unique name servers, name server IPs, and ASNs of the name server IPs in all DNS lookups.
Then, we can estimate fluxiness using the acquired numbers.
For example, fluxiness of the resolved IP address is estimated as follows,φ = N IP /N single ,where φ is the fluxiness of the domain and N single is the number of IPs that a single lookup returns.
Similarly, all of the other fluxiness features are estimated.
Attackers may try to hide their websites using multiple redirections such as iframe redirection and URL shortening.
Even though also used by benign websites, the distribution of redirection counts of malicious websites is different from that of redirection counts of benign websites [31].
Therefore, redirection count can be a useful feature to detect malicious URLs.
In a HTTP packet, there is a content-length field which is the total length of the entire HTTP packet.
Hackers often set malformed (negative) content-length in their websites in a buffer overflow exploit.
Therefore, content-length is used as a network discriminative feature.
Benign sites tend to be more popular with a better service quality than malicious ones.
Web technologies tend to make popular websites quick to look up and faster to download.
In particular, benign domains tend to have a higher probability to be cached in a local DNS server than malicious domains, esp.
those employing FFSNs and dynamic DNS.
Therefore, domain lookup time and average download speed are also used as features to detect malicious URLs.
The network features listed in Table 6 except the third and fifth features are novel features.
In this section, we evaluate the performance of our method for both malicious URL detection and attack type identification.
We also study the effectiveness of different groups of features.
The main findings of our experiments include:• Link popularity.
Link popularity first used in our method is highly discriminative for both malicious URL detection (over 96% accuracy) and attack type identification (over 84% accuracy).
Google's search engine was not suitable to estimate link popularity since it reported just a partial list of link popularity.
• Link distribution.
Malicious URLs are mainly linked by malicious URLs of the same attack type: about 56% of malicious URLs were found to be linked only by the malicious URLs of the same attack type.
• Multi-labels.
In our collected malicious URLs, over 45% belong to multiple types of threat.
Therefore, malicious URLs should be classified with a multi-label classification method in order to produce a more accurate result on the nature of attack.
• Identification.
Our method has achieved an accuracy rate of over 93% in attack type identification.
It is worth mentioning that novel features used in our method including malicious SLD hit ratio in LEX, three malicious link ratios in LPOP, two malicious ASN ratios in DNS were found to be highly effective in distinguishing different attack types.
Real-life data was collected from various sources to evaluate our method:• Benign URLs.
40,000 benign URLs were collected from the following two sources as used in previous work [49,43,21,22]: 1) randomly selected 20,000 URLs from the DMOZ Open Directory Project [10] (manually submitted by users), 2) randomly selected 20,000 URLs from Yahoo!'s directory (generated by visiting http://random.
yahoo.com/bin/ryl) 3 .
• Spam URLs.
The spam URLs were acquired from jwSpamSpy [19] which is known as an e-mail spam filter for Microsoft Windows.
We also used a publicly available Web spam dataset [3].
• Phishing URLs.
The phishing URLs were acquired from PhishTank [29], a free community site where anyone can submit, verify, track and share phishing data.
• Malware URLs.
The malware URLs were obtained from DNS-BH [11], a project creates and maintains a list of URLs that are known to be used to propagate malware.The data set of malicious URLs is simply the union of the three individual data sets of malicious types.
A total of 32,000 malicious URLs was collected.
A malicious URL may launch multiple types of attack, i.e., belongs to multiple malicious types.
The malicious data sets collected above were marked with only single labels.
URLs of multi-labels were found by querying both McAfee SiteAdvisor 4 [23] and WOT 5 (Web of Trust) [41] for each URL in the malicious URL data set.
The two sites provide reputation of a submitted website URL including the detailed malicious types it belongs to.
Their information was relatively accurate, although they had made errors (e.g., SiteAdvisor has incorrectly labeled websites 6 and WOT was manipulated by attackers to generate incorrect labels 7 ).
We use (λ i ) with a single index i to represent a single type: spam (λ 1 ), phishing (λ 2 ), malware (λ 3 ).
Multi-labels are represented by the set of their associated indexes, e.g., λ 1,3 represents a URL of both spam and malware.
Table 7 shows the resulting distribution of multi-label URLs, where L SAd and L W OT represent the results reported by SiteAdvisor and WOT, respectively, and L Both denotes their intersection.
From Table 7, about half of the malicious URLs were classified to be multi-labels: 45% by SiteAdvisor and 46% by WOT.
Comparing the labeling results by both L SAd and L W OT , 91% of the URLs were labeled consistently whereas 9% of URLs were labeled inconsistently by the two sites.
Once the URL data sets were built, three crawlers were used to crawl features from different sources.
A webpage crawler crawled the webpage content features and the network features by accessing each URL in the data sets.
We implemented a module to the webpage crawler using the cURL library [9] to detect redirections (including URL shortening) and find original URLs automatically.
A link popularity crawler crawled the link popularity features from the five search engines, Altavista, AllTheWeb, Google, Yahoo!, and Ask, for each URL and collected inlink information.
A DNS crawler crawled and calculated the DNS features and DNS fluxiness features by sending queries to DNS servers.Two-fold cross validation was performed to evaluate our method: the URLs in each data set were randomly split into two groups of equal size: one group was selected as the training set while the other was used as the testing set.
Ten rounds of two-fold cross validation were used to obtain the performance for both malicious The following metrics were used to evaluate the detection performance: accuracy (ACC) which is the proportion of true results (both true positives and true negatives) over all data sets; true positive rate (TP, also referred to as recall) which is the number of the true positive classifications divided by the number of positive examples; false positive rate (FP) and false negative rate (FN) which are defined similarly.
By applying all the discriminative features on the data sets described in Section 4.1, our malicious URL detector produced the following results: 98.2% for the accuracy, 98.9% for the true positive rate, 1.1% for the false positive rate, and 0.8% for the false negative rate.
We also conducted the same experiments using only the 20,000 benign URLs collected from Yahoo!'s directory.
The results were similar: 97.9% for the accuracy, 98.2% for the true positive rate, 0.98% for the false positive rate, and 1.08% for the false negative rate.To study the effectiveness of each feature group, we performed detection using only each individual feature group.
The resulting accuracy and true positive rate are shown in Figure 2.
We can clearly see in this figure that LPOP is the most effective group of features in detecting malicious URLs in terms of both detection accuracy and true positive rate.
We also compared the performance of each feature group on detecting each type of malicious URLs by mixing the corresponding malicious URL data set with the benign URL data set.
The resulting accuracies and true positive rates are shown in Table 8.
As expected, the lexical features (LEX) are effective on detecting phishing URLs, but did a poor job to detect spam and malware URLs.
This is because the latter types do not show very different textual patterns as Table 8 shows that the webpage content features (CONT) are useful in distinguishing malware URLs from benign ones.
This is because malware URLs usually have malicious tags or scripts in their Web content to infect visitors.
From Table 8, it seems that the webpage content features are also effective in detecting spam and phishing URLs as malicious URLs from a mixture of malicious and benign URLs.
That might be partially due to the fact that many spam or phishing URLs also belonged to malware, as we have seen in Section 4.1.
Note that a URL is claimed to be malicious no matter which malicious type it is detected to belong to.From Table 8, the DNS fluxiness features (DNSF) were effective to detect spam URLs.
This should be due to the fact that FFSNs were widely used by spam campaigns, as shown by Moore et al. [25].
Malicious network behaviors such as redirections using multiple proxies can be employed by any type of threat.
That can explain similar performance of the network features (NET) for detecting each type of malicious URLs.
In this section, we study the effectiveness of the link popularity features in detail, and show the effectiveness of our method for two unfavorable scenarios when the link popularity features are not effective:1) the case when malicious websites have high manipulated popularity scores; and 2) the case when newly-setup benign websites do not have high popularity scores.First, we studied the distribution of the link popularity for each data set.
In our data sets, malicious URLs had typically much smaller LPOP than benign URLs.
A majority, more precisely 60.35%, of the malicious URLs had 0 link popularity.
On the other hand, only a very small portion of benign URLs had almost 0 link popularity.
This confirms the observation in Section 4.2.1 that LPOP is effective to differentiate malicious URLs from benign URLs.Next we studied the quality of the link popularities retrieved from the five different search engines: Altavista, AllTheWeb, Google, Yahoo!, and Ask.
The distribution of LPOP for each search engine over 20,000 benign URLs randomly selected from the collected 40,000 benign URLs is shown in Figure 3, and the distribution over the 32,000 malicious URLs is shown in Figure 4.
The x-axis in both figures is the index of the URLs sorted by the link popularity.
The larger the gap between benign URLs and malicious URLs a search engine reports, the more accurate that the link popularity is in distinguishing malicious URLs from benign URLs.
Google tends to report a lower link popularity for both benign and malicious URLs and thus should produce higher false positives and lower false negatives.
Table 9 shows the measured metrics for the malicious URL detection using only LPOP reported by each individual search engine.
From the table, Google yielded high false positives (12.3%) and low false negatives (2.1%).
AllTheWeb showed a link popularity distribution similar to that of Yahoo!.
They had similar performance on malicious URL detection.
This is not a surprise since AlltheWeb started to use Yahoo!'s database since March 2004 8 .
The result using Google was a surprise to us.
We expected that Google would report the same, if not higher, link polarity than other search engines since it should have more comprehensive information of the Web.
It turned out that Google just reported a partial list of link popularity, as their official website described 9 .
The Google Webmaster Tool provides more comprehensive external link information, but we could not use it since it is available only for the owner's website.
Unpopular legitimate link classification.
From the results reported above, we can conclude that LPOP is the most effective discriminative feature for detecting malicious URLs.
It outperforms all the other feature groups by a large margin.
However, LPOP alone may be ineffective for certain types of URLs, for example, to distinguish malicious URLs from a group of unpopular or newly setup benign URLs which also have low LPOP scores.
This is the worst scenario for our malicious URL detector since the most effective feature, LPOP, is ineffective in this case.
To conduct a test on the performance for this worst scenario, we used only the benign and malicious URLs which had zero LPOP to evaluate the performance of our detector.
We obtained the following results on malicious URL detection: 91.2% for the accuracy, 4.0% for false positives, and 4.8% for false negatives.
The accuracy remains high even under this worst scenario.Popularity-manipulated link classification.
As described in Section 3.2, some malicious URLs have high LPOP scores because their links are manipulated using a link farm [16].
We have developed five features, i.e., distinct domain link ratio, max domain link ratio, spam link ratio, phishing link ratio, and malware link ratio, to detect link manipulated malicious URLs.
To make our detector light-weight and feasible in real-time applications, we used sampled link information instead of the whole link information to calculate each of these features.
To evaluate the performance when the links are manipulated, we collected malicious URLs which had high LPOP scores (LPOP > 10).
Among the 32,000 malicious URLs we collected, only 622 URLs could be selected.
Their distinct domain link ratio and max domain link ratio are shown against those of benign URLs in Figure 5.
This figure indicates that the popularity-manipulated malicious URLs show a different pattern from those of benign 8 AlltheWeb was taken over by Yahoo!.
URLs.
Moreover, about 90% of these malicious URLs have more than 10% malicious link ratio (spam link ratio, phishing link ratio, and malware link ratio), whereas about 5% of benign URLs have more than 10% malicious link ratio.
About 56% of these malicious URLs were linked exclusively by malicious URLs of the same type.
Consequently, we obtained 90.03% accuracy in detecting link-manipulated malicious URLs with the aforementioned five features.
Figure 5: Distinct domain link ratio and max domain link ratio for benign and malicious URLs.
In this section, both false positives and negatives are further studied to understand why these errors happened in order to further improve our method.
False positives.
A false positive is when a benign URL is misclassified as malicious.
False positives can be broadly categorized as follows:• Disreputable URL.
A benign URL is likely misclassified by our detector if it fits into two or more of the following three cases: 1) the URL's domain has a very low link popularity (LPOP errors), 2) the URL contains a malicious SLD (LEX errors), and 3) the URL's domain is hosted by malicious ASNs (DNS errors).
In this case, a benign URL can be considered as a disreputable URL.
More than 90% of the false positives belonged to the disreputable case (e.g., 208.43.27.50/ ˜ mike).
• Contentless URL.
Some benign URLs had no content on their webpages.
In this case, CONT would fail (e.g., 222.191.251.167, 1traf.com, and 3gmatrix.
cn).
• Brand name URL.
Some benign URLs contained a brand name keyword even they were not related to the brand domain.
These URLs could be misclassified as malicious (e.g., twitterfollower.
wikispaces.com).
• Abnormal token URL.
We observed several benign URLs which had unusual long domain tokens typically appearing in phishing URLs (e.g., centraldevideoscomhomensmaduros.
blogspot.com).
False negatives.
A false negative is when a malicious URL is undetected.
Most false negatives were hosted by popular social networking sites which had a high link popularity and most URLs they hosted were benign.
Most of the false negative URLs were of spam or phishing type.
They generated features similar to those of benign URLs.
More than 95% of the false negatives belonged to this case (e.g., blog.libero.
it/matteof97/ and digilander.libero.it/ Malvin92/?)
.
This will be further discussed in Section 4.4.
To evaluate the performance of attack type identification, the following metrics given in [37] for multi-label classification were used: 1) micro and macro averaged metrics, and 2) ranking-based metrics with respect to the ground truth of multi-label data.Identification metrics.
Additional notation is first introduced.
Assume that there is an evaluation data set of multi-label examples (x i , Y i ), i = 1, ...m, where x i is a feature vector, Y i ⊆ L is the set of true labels, and L = {λ j : j = 1...q} is the set of all labels.
• Micro-averaged and macro-averaged metrics.To evaluate the average performance across multiple categories, we apply two conventional methods: micro-average and macro-average [45].
The microaverage gives an equal weight to every data set, while the macro-average gives an equal weight to every category, regardless of its frequency.
Let tp λ , tn λ , f p λ , and f n λ denote the number of true positives, true negatives, false positives, and false negatives, respectively, after evaluating binary classification metrics B (accuracy, true positives, etc.) for a label λ.
The micro-averaged and macro-averaged version of B can be calculated as follows:B micro = B( M ∑ λ=1 tp λ , M ∑ λ=1 tn λ , M ∑ λ=1 f p λ , M ∑ λ=1 f n λ ), B macro = 1 M M ∑ λ=1 B(tp λ , tn λ , f p λ , f n λ ).
• Ranking-based metrics.
Among several rankingbased metrics, we employ the ranking loss and average precision for the evaluation.
Let r i (λ) denote the rank predicted by a label ranking method for a label λ.
The most relevant label receives the highest rank, while the least relevant label receives the lowest rank.
The ranking loss is the number of times that irrelevant labels are ranked higher than relevant labels.
The ranking loss, denoted as R Loss , is calculated as follows:R loss = 1 m m ∑ i=1 1 |Y i ||Y i | |{(λ a , λ b ) : r i (λ a ) > r i (λ b ), (λ a , λ b ) ∈ Y i × Y i }|where Y i is the complementary set of Y i with respect to L.
The average precision, denoted by P avg , is the average fraction of labels ranked above a particular label λ ∈ Y i which are actually in Y i .
It is calculated as follows: Identification accuracy.
We performed the multilabel classification by using three label sets, L SAd , L W OT and L Both mentioned in Section 4.1.
The results for two different learning algorithms, RAkEL algorithm and ML-kMN, are shown in Table 10, where micro TP and macro TP are micro-averaged true positives and macro-averaged true positives, respectively.
The following results were obtained: the average accuracy was 92.95%, whereas the average precision of ranking of the two algorithms was 97.76%.
The accuracy on the label set L Both was always higher than that on either L SAd or L W OT .
This implies that more accurate label set produces a more accurate result for identifying attack types.
6 shows effectiveness of each feature group in identifying attack types.
Among the top ten most effective features, eight are novel features.
They are three SLD hit ratio features in LEX, three malicious link ratios in LPOP, and two malicious ASN ratios in DNS.
From this figure, even the link popularity features were also rather effective in distinguishing different attack types.
In addition, no single feature group was highly effective in identifying attack types: they all yielded an accuracy lower than 85%.
The combination of all the groups of features, however, yielded a much improved performance.P avg = 1 m m ∑ i=1 1 |Y i | ∑ λ∈Yi |{λ ′ ∈ Y i : r i (λ ′ ) ≤ r i (λ)}| r i (λ) .
Existing methods can be evaded by capable attackers.
Similarly, our features are also evadable to a certain degree.
However, it is an improvement if we can raise the bar of evasion difficulty by either increasing the evasion cost or decreasing the effectiveness of threat.
To study evadability of our method, we discuss in this subsection the robustness of our method against known evasions and also possible evasion tactics.Robust against known evasions.
1) Redirection: One possible evasion tactic is to hide the original URL using multiple redirections (also known as a "drive-by website attack" such as Iframe redirection) or a URL shortening service which makes a webpage available under a very short URL in addition to the original URL.
Our method is robust against this kind of URL hiding and embedding evasions because our webpage crawler can automatically detect redirections and find the original URLs.
2) Link manipulation: As mentioned in Section 4.2.2, our method is robust against the link manipulation attack (more than 90% of link-manipulated URLs were detected).
3) Fast-flux hosting: The DNSF features used in our method can detect fast-fluxed domains.URL obfuscation.
If an attacker (or a domain generation algorithm in malware, e.g., Conficker Worm) generates a domain name and path tokens with random length and counts, most statistical features in LEX will be evaded.
Therefore, it is easy to evade the statistical features in LEX except our unique feature "malicious SLD hit ratio" since a plenty of domains have to be registered to evade the malicious SLD hit ratio.
Evading brand name presence feature is easy but such an evasion will make a malicious URL less likely to be clicked, resulting in a reduced effectiveness of attack.
URL obfuscation using IDN (Internationalized Domain Names) spoofing can also be used to evade our detector.
For example, http://www.p&#1072;ypal.com represents http://www.paypal.com.
Such an evasion can be easily prevented by adding a module to deobfuscate a URL to find the resulting URL in our webpage crawler.
JavaScript obfuscation.
Malicious javascript often utilizes obfuscation to hide known exploits, embed redirection URLs, and evade signature-based detection methods.
Particularly, JavaScript obfuscation can make the webpage crawler mislead webpage content features (CONT).
To extract webpage content features accurately, the webpage crawler should have an automated deobfuscation functionality.
The Firefox JavaScript deobfuscator add-on 10 inspired by "The Ultimate Deobfuscator" [5] can be used in our webpage content crawler as a JavaScript deobfuscation module.Social network site.
Utilizing social network sites (e.g., Twitter) to attack can reduce the effectiveness of LEX, LPOP, DNS, and NET features.
A possible solution against this evasion tactic is to adopt features which can differentiate hacker's fake accounts from normal users.
For example, we can use the number of incoming linked accounts (e.g., "followers" in Twitter) as a feature to detect faked accounts.
Such a feature is still evadable with more sophisticated attacks which build a fake social network to link each other.
Like the five link ratio features in LPOP to deal with the link popularity manipulation, similar linked account ratio features can be used to deal with a fake social network.
Other countermeasures against social spam and phishing [20] can also be combined with our detector.As mentioned in this section, it may cost little to evade a single feature group.
However, evading all the features in our method would cost much more and also reduce the effectiveness of attack.
This section reviews the related work of our method.
They can be classified into two categories depending on how the classifier is built: machine learning methods which use machine learning to build classifiers, and other methods which build classifiers with a priori knowledge.
Blacklisting.
One of the most popular approaches is to build a blacklist to block malicious URLs.
Several websites provide blacklists such as jwSpamSpy [19], PhishTank [29], and DNS-BH [11].
Several commercial products construct blacklist using user feedbacks and their proprietary mechanisms to detect malicious URLs, such as McAfee's SiteAdvisor [23], WOT Web of Trust [41], Trend Micro Web Reputation Query Online System [36], and Cisco IronPort Web Reputation [7].
URL blacklisting is ineffective for new malicious URLs.
The very nature of exact match in URL blacklisting renders it easy to be evaded.
Moreover, it takes time to analyze malicious URLs and propagate a blacklist to end users.
Zhang et al. [46] proposed a more effective blacklisting approach, "predictive blacklists", which uses a relevance ranking algorithm to estimate the likelihood that an IP address is malicious.VM execution.
Wang et al. [39] detected driveby exploits on the Web by monitoring anomalous state changes in a Virtual Machine (VM).
SpyProxy [26] also uses a VM-based Web proxy defense to block suspicious Web content by executing the content in a virtual machine first.
The VM-based approaches detect malicious webpages with a high accuracy, but only malware exploiting pages can be detected.Rule-based anti-phishing.
Several rule-based antiphishing approaches have been proposed.
Zhang et al. [49] proposed a system to detect phishing URLs with a weighted sum of 8 features related to content, lexical and WHOIS data.
They used the Google Web search as a filter for phishing pages.
Garera et al. [13] used logistic regression over manually selected features to classify phishing URLs.
The features include heuristics from a URL such as Google's page rank features.
Xiang and Hong [43] proposed a hybrid phishing detection method by discovering inconsistency between a phishing identity and the corresponding legitimate identity.
PhishNet [30] provides a prediction method for phishing attacks using known heuristics to identify phishing sites.
Detection of single attack type.
Machine learning has been used in several approaches to classify malicious URLs.
Ntoulas et al. [27] proposed to detect spam webpages through content analysis.
They used sitedependent heuristics, such as words used in a page or title and fraction of visible content.
Xie et al. [44] developed a spam signature generation framework called AutoRE to detect botnet-based spam emails.
AutoRE uses URLs in emails as input and outputs regular expression signatures that can detect botnet spam.
Fette et al. [12] used statistical methods to classify phishing emails.
They used a large publicly available corpus of legitimate and phishing emails.
Their classifiers examine ten different features such as the number of URLs in an e-mail, the number of domains and the number of dots in these URLs.
Provos et al. [31] analyzed the maliciousness of a large collection of webpages using a machine learning algorithm as a pre-filter for VM-based analysis.
They adopted content-based features including presence of obfuscated javascript and exploit sites pointing iframes.
Hou et al. [18] proposed a detector of malicious Web content using machine learning.
In particular, we borrow several webpage contents features from their features.
Whittaker et al. [40] proposed a phishing website classifier to update Google's phishing blacklist automatically.
They used several features obtained from domain information and page contents.Detection of multiple attack types.
The classification model of Ma et al. [21,22] can detect spam and phishing URLs.
They described a method of URL classification using statistical methods on lexical and hostbased properties of malicious URLs.
Their method detects both spam and phishing but cannot distinguish these two types of attack.Existing machine learning-based approaches usually focus on a single type of malicious behavior.
They all use machine learning to tune their classification models.
Our method is also based on machine learning, but a new and more powerful and capable classification model is used.
In addition, our method can identify attack types of malicious URLs.
These innovations contribute to the superior performance and capability of our method.Other related work.
Web spam or spamdexing aims at gaining an undeservedly high rank from a search engine by influencing the outcome of the search engine's ranking algorithms.
Link-based ranking algorithms, which our link popularity is similar to, are widely used by search engines.
Link farms are typically used in Web spam to affect link-based ranking algorithms of search engines, which can also affect our link popularity.
Researches have proposed methods to detect Web spams by using propagating trust or distrust through links [15], detecting bursts of linking activity as a suspicious signal [34], integrating link and content features [4], or various link-based features including modified PageRank scores [6].
Many of their techniques can be borrowed to thwart evading link popularity features in our detector through link farms.
The Web has become an efficient channel to deliver various attacks such as spamming, phishing, and malware.
To thwart these attacks, we have presented a machine learning method to both detect malicious URLs and identify attack types.
We have presented various types of discriminative features acquired from lexical, webpage, DNS, DNS fluxiness, network, and link popularity properties of the associated URLs.
Many of these discriminative features such as link popularity, malicious SLD hit ratio, malicious link ratios, and malicious ASN ratios are novel and highly effective, as our experiments found out.
SVM was used to detect malicious URLs, and both RAkEL and ML-kNN were used to identify attack types.
Our experimental results on real-life data showed that our method is highly effective for both detection and identification tasks.
Our method achieved an accuracy of over 98% in detecting malicious URLs and an accuracy of over 93% in identifying attack types.
In addition, we studied the effectiveness of each group of discriminative features on both detection and identification, and discussed evadability of the features.
