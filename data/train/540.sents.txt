Temporal Text Mining (TTM) is concerned with discovering temporal patterns in text information collected over time.
Since most text information bears some time stamps, TTM has many applications in multiple domains, such as summarizing events in news articles and revealing research trends in scientific literature.
In this paper, we study a particular TTM task-discovering and summarizing the evolutionary patterns of themes in a text stream.
We define this new text mining problem and present general probabilistic methods for solving this problem through (1) discovering latent themes from text; (2) constructing an evolution graph of themes; and (3) analyzing life cycles of themes.
Evaluation of the proposed methods on two different domains (i.e., news articles and literature) shows that the proposed methods can discover interesting evolutionary theme patterns effectively.
In many application domains, we encounter a stream of text, in which each text document has some meaningful time stamp.
For example, a collection of news articles about a topic and research papers in a subject area can both be viewed as natural text streams with publication dates as time stamps.
In such stream text data, there often exist interesting temporal patterns.
For example, an event covered in news articles generally has an underlying temporal and evolutionary structure consisting of themes (i.e., subtopics) characterizing the beginning, progression, and impact of the event, among others.
Similarly, in research papers, research topics may also exhibit evolutionary patterns.
For example, the study of one topic in some time period may have influenced or stimulated the study of another topic after the time period.
In all these cases, it would be very useful if we can discover, extract, and summarize these evolutionary theme patterns (ETP) automatically.
Indeed, such patterns not only are useful by themselves, but also would facilitate organization and navigation of the information stream according to the underlying thematic structures.Consider, for example, the Asian tsunami disaster that happened in the end of 2004.
A query to Google News (http://news.google.com) returned more than 80,000 online news articles about this event within one month (Jan.17 through Feb. 17,2005).
It is generally very difficult to navigate through all these news articles.
For someone who has not been keeping track of the event but wants to know about this disaster , a summary of this event would be extremely useful.
Ideally, the summary would include both the major subtopics about the event and any threads corresponding to the evolution of these themes.
For example, the themes may include the report of the happening of the event, the statistics of victims and damage, the aids from the world, and the lessons from the tsunami.
A thread can indicate when each theme starts, reaches the peak, and breaks, as well as which subsequent themes it influences.
A timelinebased theme structure as shown in Figure 1 would be a very informative summary of the event, which also facilitates navigation through themes.
D In addition to the theme structure, revealing the strength of a theme at different time periods, or the "life cycle" of a theme, is also very useful.
Consider another scenario in the literature domain.
There are often hundreds of papers published annually in a research area.
A researcher, especially a beginning researcher, often wants to understand how the research topics in the literature have been evolving.
For example, if a researcher wants to know about information retrieval, both the historical milestones and the recent research trends of information retrieval would be valuable for him/her.
A plot, such as the one shown in Figure 2, which visualizes the evolution patterns of research topics, would not only serve as a good summary of the field, but also make it much easier for the researcher to selectively choose appropriate papers to read based on his/her research interests.
In both scenarios, we clearly see a need for discovering evolutionary theme patterns in a text stream.
In general, it is often very useful to discover the temporal patterns that may exist in a stream of text articles, a task which we refer to as Temporal Text Mining (TTM).
Since most information bears some kinds of time stamps, TTM can be expected to have many applications in multiple domains.Despite its importance, however, TTM has not been well addressed in the existing work.
Most existing text mining work does not consider the temporal structures of text [7,8].
There are some previous studies on TTM [10,19,11,14], but the proposed methods are generally inadequate for generating the evolutionary theme patterns as shown in the two examples above.
A detailed discussion of related work is given in Section 6.
In this paper, we study the problem of discovering and summarizing the ETPs in a text stream.
We define this problem and present general probabilistic methods for solving the problem through (1) discovering latent themes from text, which includes both interesting global themes and salient local themes in a given time period; (2) discovering theme evolutionary relations and constructing an evolution graph of themes; and (3) modeling theme strength over time and analyzing the life cycles of themes.
We evaluate the proposed methods on two data sets -a collection of 50 day's worth of news articles about the tsunami event (Dec.19, 2004-Feb.08, 2005) and the abstracts of the ACM KDD conference papers from 1999 through 2004.
The results show that our methods can discover many interesting ETPs from both data sets.
In addition to news summarization and literature mining, the proposed TTM methods are also directly applicable to many other application domains, such as email analysis, mining user logs, mining customer reviews.The rest of the paper is organized as follows.
In Section 2, we formally define the general problem of ETP discovery.
In Section 3, we present our approaches to extracting themes and constructing a theme evolution graph.
In Section 4, we further present a hidden Markov model based method for analyzing the life cycles of themes.
We discuss our experiments and results in Section 5.
Finally, Section 6 and Section 7 are related work and conclusions, respectively.
The general problem of ETP discovery can be formulated as follows.Suppose we have a collection of time-indexed text documents, C = {d1, d2, ..., dT }, where di refers to a document with time stamp i. Each document is a sequence of words from a vocabulary set V = {w1, ..., w |V | }.
We define the following concepts.Definition 1 (Theme) A theme in a text collection C is a probabilistic distribution of words that characterizes a semantically coherent topic or subtopic.
Formally, we represent a theme by a (theme-specific) unigram language model θ, i.e., a word distribution {p(w|θ)}w∈V .
Naturally, w∈V p(w|θ) = 1.
Using a word distribution to model topics is quite common in information retrieval and text mining [5,9,2].
High probability words of such a distribution often suggest what the theme is about.
For example, a theme about the aid from the US to help recovery from the tsunami disaster may have high probabilities for words such as "U.S.", "million", "aid", "Bush", etc.Definition 2 (Theme Span) A theme span γ is defined as a theme θ spanning a given time interval l and is represented by 񮽙θ, s(γ), t(γ)񮽙, where s(γ) and t(γ) are the starting and termination time stamps of l, respectively.A theme span is a useful concept for associating time with themes.
For the purpose of TTM, a theme is almost always tagged with a time span.
We thus use "theme" and "theme span" interchangeably whenever there is no ambiguity.
We call a theme span that spans the entire text stream a transcollection theme.
Thus if γ = 񮽙θ, s, t񮽙 is a trans-collection theme, we must have s = 1 and t = T .
We use Γ to denote the set of all theme spans.Definition 3 (Evolutionary Transition) Let γ1 = 񮽙θ1, s(γ1), t(γ1)񮽙 and γ2 = 񮽙θ2, s(γ2), t(γ2)񮽙 ∈ Γ be two theme spans.
If t(γ1) ≤ s(γ2) (γ1 terminates before γ2 starts) and the similarity between theme span γ1 and γ2 is above a give threshold, we say that there is an evolutionary transition from γ1 to γ2, which we denote by γ1 񮽙 γ2.
We also say that θ2 is evolved from θ1, or θ1 evolves into θ2.
We use E ⊂ Γ × Γ to denote all the evolutionary transitions, so that if (γ1, γ2) ∈ E, then γ1 񮽙 γ2.The concept of evolutionary transition is useful for describing the evolution relations between theme spans.
With this concept, we can now define a particularly interesting theme pattern called a theme evolution thread.Definition 4 (Theme Evolution Thread) Let Γ be a set of theme spans, a theme evolution thread is a sequence of theme spans γ0, γ1, ..., γn ∈ Γ such that (γi, γi+1) ∈ E.Intuitively, a theme evolution thread characterizes how a family of related themes evolve over time.
Since a text stream generally has multiple such theme threads, we now define another concept called theme evolution graph to characterize the overall theme evolution patterns of a text stream.Definition 5 (Theme Evolution Graph) A Theme Evolution Graph is a weighted directed graph G = (N, E) in which each vertex v ∈ N is a theme span, and each edge e ∈ E is an evolutionary transition.
The weight on an edge indicates the evolution distance.
Clearly, each path in a theme evolution graph represents a theme evolution thread.An example of a theme evolution graph is shown in Fig- ure 3, where each vertex is a theme span extracted from a subcollection obtained through non-overlapping partitioning of the stream into n sliced intervals.
Each edge is an evolutionary transition.
The thickness of an edge indicates how close the two themes being connected are and how trustful Figure 3: An example of a theme evolution graph the corresponding evolutionary transition is; a thicker edge indicates a closer distance between the themes and a more trustful transition.
For example, the distance of θ12 񮽙 θ23 is smaller than that of θ11 񮽙 θ21, and the former is more trustful.
We also see a theme evolution thread from θ12, through θ23, and all the way to θn2.
Given a text stream C, a major task of the general ETP discovery problem is to extract a theme evolution graph from C automatically.
Such a graph can immediately be used as a summary of the themes and their evolution relations in the text stream, and can also be exploited to organize the text stream in a meaningful way.
Sometimes, a user may be interested in a specific theme.
For example, a researcher may be interested in a particular subtopic.
In this case, it is often useful to analyze the whole "life cycle" of a theme thread.
Thus another task of ETP discovery is to compute the strength of a theme at different time periods so that we can see when the theme has started, when it is terminated, and whether there is any break in between.The ETP discovery problem is challenging in many ways.
First, it is a completely unsupervised task; there's no training data to discriminate theme spans.
This indicates a great advantage of any techniques for ETP discovery -no/minimum prior knowledge about a domain is assumed.
Second, compared with the problem of novelty detection and event tracking, which aims to segment the text and find the boundaries of events [3,18,13], the ETP discovery problem involves a more challenging task of modeling the multiple subtopics at any time interval for an event, and aims to discover the changing and evolutionary relations between the theme spans.
Finally, the analysis of theme life cycles requires the system to decode the whole collection with themes and model the strength variations of each theme along the time line in a completely unsupervised way.In the next two sections, we propose and present probabilistic approaches for discovering ETPs and analyzing the life cycles of themes, respectively.
Given a stream of text C = {d1, d2, ..., dT }, our goal is to extract a theme evolution graph from C automatically.
At a high-level, our methods involve the following three steps: 1.
Partition the documents into n possibly overlapping subcollections with fixed or variable time intervals so that C = C1 ∪ ... ∪ Cn and Ci = {dt i , ..., d t i +l i −1 } is a subcollection of li documents in the time span [ti, ti + li − 1].
In general, ti < ti+1, but it may be that ti + li − 1 > ti+1, since Ci's may be overlapping.
The actual choice of the interval lengths li and whether Ci's should overlap are determined by specific applications.
2.
Extract the most salient themes Θi = {θi,1, ..., θ i,k i } from each subcollection Ci using a probabilistic mixture model.
3.
For any themes in two different subcollections, θ1 ∈ Θi and θ2 ∈ Θj where i < j, decide whether there is an evolutionary transition based on the similarity of θ1 and θ2.Step 1 is trivial; below we describe Steps 2 & 3 in detail.
We extract themes from each subcollection Ci using a simple probabilistic mixture model as described in [20].
In this method, words are regarded as data drawn from a mixture model with component models for the theme word distributions and a background word distribution.
Words in the same document share the same mixing weights.
The model can be estimated using the Expectation Maximization(EM) algorithm [6] to obtain the theme word distributions.Specifically, let θ1, ..., θ k be k theme unigram language models (i.e., word distributions) and θB be a background model for the whole collection C.
A document d is regarded as a sample of the following mixture model:p(w : d) = λBp(w|θB) + (1 − λB) k j=1 [π d,j p(w|θj)]where w is a word in document d, π d,j is the mixing weight for document d for choosing the j-th theme θj such that k j=1 π d,j = 1, and λB is the mixing weight for θB.
The purpose of using a background model θB is to make the theme models more discriminative; since θB gives high probabilities to non-discriminative and non-informative words, we expect such words to be accounted for by θB and thus the theme models to be more discriminative.
θB is estimated using the whole collection C as p(w|θB)= 3 T i=1 c(w,d i ) 3 w∈V 3 T i=1 c(w,d i )The additional parameters to estimate are Λ = {θj , π d,j |d ∈ Ci, 1 ≤ j ≤ k}.
The log-likelihood of Ci, log p(Ci|Λ) is4 d∈C i 4 w∈V [c(w, d) log(λBp(w|θB)+(1−λB) k 4 j=1 (π d,j p(w|θj )))]where c(w, d) is the count of word w in document d.According to the EM algorithm, we can use the following iterative updating formulas to estimate all the parameters.
{z d,w } is a hidden variable and p(z d,w = j) indicates that the word w in document d is generated using theme j given that w is not generated from the background mode.p(z d,w = j) = π (n) d,j p (n) (w|θj ) k j 񮽙 =1 π (n) d,j 񮽙 p (n) (w|θ j 񮽙 ) p(z d,w = B) = λBp(w|θB) λBp(w|θB) + (1 − λB) k j=1 π (n) d,j p (n) (w|θj) π (n+1) d,j = w∈V c(w, d)(1 − p(z d,w = B))p(z d,w = j) k j 񮽙 =1 w∈V c(w, d)(1 − p(z d,w = B))p(z d,w = j 񮽙 ) p (n+1) (w|θj ) = d∈C i c(w, d)(1 − p(z d,w = B))p(z d,w = j) w 񮽙 ∈V d∈C i c(w 񮽙 , d)(1 − p(z d,w 񮽙 = B))p(z d,w 񮽙 = j)The algorithm is only guaranteed to find a local maximum of the likelihood.
We use multiple trials to improve the local maximum we obtain.
We use 1|C i | d∈C i π d,jto measure the salience of theme j in Ci and select the most salient themes from Ci by using an empirically set threshold.
We obtain the theme spans for Ci by attaching the time span of Ci to all the selected salient themes.The same model can be applied to the whole collection C to extract trans-collection themes; we will do that in Section 4 to analyze the life cycles of trans-collection themes.
With the theme spans extracted from all the subcollections, we now turn to the discovery of evolutionary transitions.
To discover any evolutionary transition between two theme spans, we use the Kullback-Leibler divergence [4] to measure their evolution distance.
Let γ1 = 񮽙θ1, s(γ1), t(γ1)񮽙 and γ2 = 񮽙θ2, s(γ2), t(γ2)񮽙 be two theme spans where t(γ1) ≤ s(γ2).
We assume that γ2 has a smaller evolution distance to γ1 if their unigram language models θ2 and θ1 are closer to each other.
Since the KL-divergence D(θ2||θ1) can model the additional new information in θ2 as compared to θ1, it appears to be a natural measure of evolution distance between two themes.D(θ2||θ1) = |V | 4 i=1 p(wi|θ2) log p(wi|θ2) p(wi|θ1)Note that the KL-divergence is asymmetric and it makes more sense to use D(θ2||θ1) than D(θ1||θ2) to measure the evolution distance from θ1 to θ2.
For every pair of theme spans γ1 and γ2 where t(γ1) ≤ s(γ2), we compute D(θ2||θ1).
If D(θ2||θ1) is above a threshold ξ, we will infer that γ1 񮽙 γ2.
The threshold ξ allows a user to flexibly control the strength of the theme transitions.Once we extract the theme spans from all the subcollections and identify all the evolutionary transitions, we essentially have a theme evolution graph.
The theme evolution graph discussed above gives us a microcosmic view of the ETPs -revealing the major theme spans within each time interval and their evolutionary structures.
To obtain a macroscopic view of the ETPs, it would be useful to extract the global evolutionary patterns of themes over the whole text stream and analyze the "life cycle" of each specific theme.Definition 6 (Theme Life Cycle) Given a text collection tagged with time stamps and a set of trans-collection themes, we define the Theme Life Cycle of each theme as the strength distribution of the theme over the entire time line.
The strength of a theme at each time period is measured by the number of words generated by this theme in the documents corresponding to this time period, normalized by either the number of time points (giving an absolute strength), or the total number of words in the period (giving a relative strength).
The absolute strength measures the absolute amount of text which a theme can explain, while the relative strength indicates which theme is relatively stronger in a time period.We now present a method based on Hidden Markov Models (HMMs) [17] to model and decode the shift between trans-collection themes in the whole collection.
Based on the decoding results, we can then compute the theme strengths and analyze theme life cycles in a straightforward way.We first give a brief introduction to HMMs.
An HMM can be characterized by a set of hidden states S = {s1, ..., sn}, a set of observable output symbols O = {o1, ..., om}, an initial state probability distribution {πi} n i=1 , a state transition probability distribution {ai,j } n j=1 for each state si, and an output probability distribution {b i,k } m k=1 for each state si.
An HMM defines a generative probabilistic model for any sequence of symbols from O with parameters satisfying the following constraints: (1)n i=1 πi = 1; (2) n j=1 ai,j = 1; (3) m k=1 b i,k = 1.
To model the theme shifts in our text stream, we assume that the collection, which is represented as a long sequence of words, is stochastically generated from an HMM constructed in the following way.
We first extract k trans-collection themes from the collection using the mixture model described in the previous section.
We then construct a fully connected HMM with k + 1 states, of which k states correspond to the extracted k themes and the other one corresponds to a background theme language model estimated based on the whole collection.
The entire vocabulary V is taken as the output symbol set, and the output probability distribution of each state is set to the multinomial distribution of words given by the corresponding theme language model.
A 3-theme HMM is shown in Figure 4.
The background state, which corresponds to the background theme model, aims to account for non-discriminative words, while the content words and subtopics are modeled by the states corresponding to the trans-collection themes.
Since the extracted themes are discriminative, we may reasonably assume that each theme can only shift to another theme through the background model.
The unknown parameter set in the HMM is Λ = {πi, ai,i, ai,B, aB,i} n i=1 .
Λ can be estimated using an EM algorithm called Baum-Welch algorithm [17].
After the initial state probabilities and transition probabilities are estimated, the Viterbi algorithm [17] can be used to decode the text stream to obtain the most likely state sequence, i.e., the most likely sequence of theme shifts, as shown in Figure 5.
Once the whole stream C = {d1, ..., dT } is decoded with the labels of themes, we can use a fixed-size sliding window of time to measure the strength of each theme at a time point 1 .
Let di = di1...d i|d i | be the sequence of words in di.
The absolute and relative strengths of theme i at time t is computed as:AStrength(i, t) = 1 W t 񮽙 ∈[t− W 2 ,t+ W 2 ] |d t 񮽙 | j=1 δ(d t 񮽙 j , i) 1The use of a sliding window also avoids the "report delay" problem in the news domain.
= t 񮽙 ∈[t− W 2 ,t+ W 2 ] |d t 񮽙 | j=1 δ(d t 񮽙 j , i) t 񮽙 ∈[t− W 2 ,t+ W 2 ] |d t 񮽙 |The life cycle of each theme can then be modeled as the variation of the theme strengths over time.The analysis of theme life cycles thus involves the following four steps: (1) Construct an HMM to model how themes shift between each other in the collection.
(2) Estimate the unknown parameters of the HMM using the whole stream collection as observed example sequence.
(3) Decode the collection and label each word with the hidden theme model from which it is generated.
(4) For each trans-collection theme, analyze when it starts, when it terminates, and how it varies over time.
Two data sets are constructed to evaluate the proposed ETP discovery methods.
The first, tsunami news data, consists of news articles about the event of Asia Tsunami dated Dec. 19 On each data set, two experiments are designed: (1) Partition the collection into time intervals, discover the theme evolution graph and identify theme evolution threads.
(2) Discover trans-collection themes and analyze their life cycles.
The results are discussed below.
Since news reports on the same topic may appear earlier in one source but later in another (i.e., "report delay"), partitioning news articles into overlapping, as opposed to non-overlapping subcollections seems to be more reasonable.
We thus partition the our news data into 5 time intervals, each of which spans about two weeks and is half overlapping with the previous one.
We use the mixture model discussed in Section 3 to extract the most salient themes in each time interval.
We set the background parameter λB = 0.95 and number of themes in each time interval to be 6.
The variation of λB is discussed later.
Table 3 shows the top 10 words with the highest probabilities in each theme span.
We see that most of these themes suggest meaningful subtopics in the context of the Asia tsunami event.
§¨©¨!
§¨© §¨©¨ With these theme spans, we use KL-divergence to further identify evolutionary transitions.
Figure 6 shows a theme evolution graph discovered from Asia Tsunami data when the threshold for evolution distance is set to ξ = 12.
From Figure 6, we can see several interesting evolution threads which are annotated with symbols.
§¨©¨! "
# # " $ # % # % ! "
# # " $ " # §¨©§¨© & §¨©§¨© ' §¨©§¨© ( §¨©§¨© ) §¨©§¨© 0 § & © 1 ¨ § & © 1 & § & © 1 ' § & © 1 ( § & © 1 ) § & © 1 0 § ' © 1 ¨ § ' © 1 & § ' © 1 ' § ' © 1 ( § ' © 1 ) § ' © 1 0 § ( © 2 1 ¨ § ( © 2 1 & § ( © 2 1 ' § ( © 2 1 ( § ( © 2 1 ) § ( © 2 1 0 § ) © ¨ § ) © & § ) © ' § ) © ( § ) © ) § ) ©The thread labeled with a may be about warning systems for tsunami.
It is interesting to see that the nation covered by the thread seems to have evolved from the U.S. in period l1, to China in l2, and then to Japan in l3.
In thread b, themes 3, 4, and 5 in period l1 indicate the aids and financial support from UN, from local area, and special aids for children, respectively.
They all show an evolutionary transition to theme 2 (donation from UK) and theme 3 (aid from It starts with theme 5 in l2, goes through theme 6 in l3, theme 3 in l4, and finally evolves into theme 3 in l5.
There are also several short but noticeable theme evolution threads.
For example, thread e is about cricket matches for donation, while thread f is about deaths and losses in the disaster.
In the latest two time intervals, most themes are no longer about the tsunami event, indicating that the event was probably receiving diminishing attention in these two periods, which can be seen more clearly later from the analysis of the life cycles of themes.
There are two politics-related short theme threads (i.e., g and h).
In thread g, theme 1 in l4 is about political issues ("rebels" and "peace").
It splits into two themes in l5, about North Korea and the Aceh peace talk, respectively.
Theme 2 and theme 5 in l4 represent criticisms on the Iraq affair (one for military issues and one for the high expenditure/cost).
In l5, they merged into a single theme, which mentions the budget on Iraq and Afghanistan issues.
Interestingly, by linking back to the articles, it turns out to be arguing for shrinking the budget on the war issues and offering more aid for the disaster.Theme 1 Theme 2 Theme 3 Theme 4 Theme 5 Theme 6 l1: system 0.0104 Year 0.0074 debt 0.0148 Aceh 0.0320 Annan 0.0081 match 0.
Note that multiple threads may share one or more common themes, resulting in thread ambiguity.
For example, themes 2, 3 and 4 of l1 all have a high similarity to theme 2 of l2.
In the analysis above, we only included theme 2 of l1 in thread c, because themes 3 and 4 do not appear to be similar to theme 2 of l2 in the same way as theme 1 of l3 is.
A very interesting future research direction would be to study how we can automatically perform thread disambiguation.Our second experiment aims to model the life cycles of trans-collection themes.
In this experiment, we use two individual sources (CNN and Xinhua News) instead of the whole mixed collection to avoid "report delay".
The five transcollection themes extracted from CNN and Xinhua News are shown in Table 4.
The five themes from CNN roughly correspond to (1) research and lessons about the tsunami; (2) personal experience of survivors; (3) Special aid program for children; (4) general reports and statistics; (5) aids and donations from the world, especially from the U.S.
The five themes from Xinhua roughly correspond to (1) statistics of death and missing; (2) reports and stories at the scene; (3) donations from China; (4) aids and donations from the world; (5) research and lessons about the tsunami.
Some themes (e.g., CNN-theme1 and XINHUA-theme5) are common to both sources, while some others (e.g., CNN-theme5 and XINHUA-theme3) clearly reflect the different regions of the two sources.In Figure 7 we plot the absolute strengths of the transcollection themes over time for CNN (W = 10).
We see that the absolute strengths of all five themes are increasing in the first 10 days after Dec. 24, 2004.
Reports on aids for children and aids from the world begin to decay after that.
General reports and statistics starts to decay around Jan 10 for the rest of the time.
Around Jan. 7th, the theme on the research and lessons about tsunami starts to increase again.
The same pattern is discovered in reports on personal experiences, which is probably because survivors had come back to their home country around that time.
Both themes drop sharply around Jan. 17.
After Jan. 22, all 5 themes retain a low strength level, indicating the event was receiving diminishing attention.
The normalized strengths of themes in the CNN data show similar patterns.In Figure 8, we show the absolute and normalized strengths of the five trans-collection themes over time in Xinghua News (W = 10).
We see that, in the first week beginning Dec. 25th 2004, all 5 themes are increasing rapidly, but they all begin to decay around Jan. 10th except for stories and reports at the scene, which increases again after a roughly 10-day period of mild decreasing.
The theme about death statistics begins to decay all the time after Jan. 16.
Both aids from China and the research and lessons about tsunami present a second rise in late January, although not as significant as the first one.
In the normalized strength plot, it is easy to see that before Jan 3rd, the dominating theme is theme 5.
In the next 10 days, aid from the world is most significant.
In the following 20 days, "on-scene stories" is the dominating theme, although its absolute strength is decreasing for most of the time.
In the last time period when the overall coverage of the topic had significantly decreased, Aids from China is relatively stronger than other themes.
Comparing CNN and Xinhua, we see the life cycles of the correlated themes in the two data sets exhibit comparable patterns but with some differences.
The publication year naturally suggests a non-overlapping partition of the KDD abstract data.
We thus treat all the abstracts published in one year as one time interval.
The theme spans extracted from each year using the mixture Table 5.
The number of themes slightly differs from year to year because we apply a threshold to select only the most salient themes as described in Section 3.
Similar to what we have seen on the news data, the themes here are also mostly meaningful in the context of KDD publications.
The three themes in the year of 1999 are about association rule mining, clustering, and classification respectively, which are all traditional data mining topics, compared with the new topics, such as spatial data mining (theme 1) and gene and microarray mining (theme 2), extracted in the year of 2004.
A theme evolution graph extracted using an evolution distance threshold of ξ = 12.5 is shown in Figure 9, where we see several interesting theme threads.Thread a starts with theme 3 in 1999 (about classification).
It first evolves into theme 1 in 2001 (typical classification techniques such as SVM), and then evolves into web classification in 2002.
The next theme span on this thread is about clustering and random variables, which has some influence on theme 1 in 2004.
Another evolution thread (b) starts with association rule mining in 1999, and transits into frequent item set in 2001.
Both themes show strong evolu- This path ends at theme 2 in 2003, which covers the Web and social networks.
The discussion of web mining has not appeared as an explicit theme until theme 2 in 2001, which evolves into web and social networks in 2003 through theme 1 in 2002.
¡ ¢ ¡ £ ¡ ¤ ¦ ¥ § £ ¨ © § ¡ ¢ ¡ £ ¡ ¤ ¦ ¥ § £ ¨ © § ¢ ¡ ¢ ¡ £ ¡ ¤ ¦ ¥ § £ ¨ © § ¢ ¢ £ ¢ ¤ ¦ ¥ § ¢ ¨ © § ¢ £ ¢ ¤ ¦ ¥ § ¢ ¨ © § ¢ ¢ £ ¢ ¤ ¦ ¥ § ¢ ¨ © § ¢ ¢ £ ¢ ¤ ¦ ¥ § ¢ ¨ © § ¢ £ ¢ ¤ ¥ § £ ¨ © § £ ¢ ¤ ¥ § £ ¨ © § ¢ £ ¢ ¤ ¥ § £ ¨ © § ¢ £ ¢ £ ¤ ¦ ¥ § £ ¨ © § £ ¢ £ ¤ ¦ ¥ § £ ¨ © § ¢ £ ¢ £ ¤ ¦ ¥ § £ ¨ © § ¢ £ ¢ £ ¤ ¦ ¥ § £ ¨ © § ¢ £ ¢ £ ¤ ¦ ¥ § £ ¨ © § ¢ ¢ £ ¢ ¤ ¦ ¥ § ¢ ¨ © § ¢ £ ¢ ¤ ¦ ¥ § ¢ ¨ © § ¢ ¢ £ ¢ ¤ ¦ ¥ § ¢ ¨ © § ¢ ¢ £ ¢ ¤ ¦ ¥ § ¢ ¨ © § ¢ ¢ £ ¢ ¤ ¦ ¥ § ¢ ¨ © § ¢ £ ¢ ¤ ¦ ¥ § ¢ ¨ © § ¢ ¢ £ ¢ ¤ ¦ ¥ § ¢ ¨ © § ¢ ¢ £ ¢ ¤ ¦ ¥ § ¢ ¨ © § ¢ 񮽙񮽙񮽙񮽙 񮽙 񮽙 񮽙Before year 2000, there was no explicit theme about data mining in biological data.
There are two themes (theme 1, theme 2) which mention protein functionalities, but they fail to reappear in 2001.
A strong explicit theme evolution thread of mining biological data (path e) starts with theme 2 in year 2002 and evolves into theme 3 in 2003 and theme 4 in 2004 , respectively.As in the news data, we also analyzed the life cycles of trans-collection themes in KDD Abstracts.
Seven dominating trans-collection themes are shown in Table 6 and the interesting patterns of life cycles are presented in Figure 10 (W = 1).
Some new topics, such as spatial-temporal data mining, have not shown up as trans-collection themes, because when we consider the whole stream, they are not among the dominating topics.
From Figure 10, we see that the normalized strength of theme 1 decreases monotonically from 1999.
This theme is about a traditional application area of data mining -marketing and customer analysis.
Another theme showing a decaying pattern is association rule mining, which keeps decreasing after its peak in 2000.
In the year 1999, there is very little work on mining web information.
This topic keeps growing in the following three years, and drops a bit after its acme in the year 2002.
Mining from genes and biology data, as highlighted, keeps increasing over the 6 years from a very low level to one of the strongest themes.
Theme 4, which covers time series and other applications of clustering, shows an irregular pattern before 2002 but remains stable after that.There are also themes, such as classification (theme 5) and clustering (theme 7, mostly theoretical aspect, especially dimension reduction), which are somehow stable.
Indeed, the classification theme appears to be among the strongest themes over the whole time line.
Considering that several themes (theme 3, theme 4, and theme 7) all cover clustering, we may also infer that clustering is another major dominating theme in KDD publications.
In our methods for ETP discovery, there are a few parameters that are meant to provide the necessary flexibility for a In the mixture model for theme extraction, λB controls the strength of our background model, which is used to "absorb" non-informative words from the themes.
In general, λB should be set to reflect a user's knowledge about the noise (i.e., the non-informative common words) in the text stream; the more noise we believe our data set has, the larger λB should be.
Our experiments have shown that, in ordinary English text, the value of λB can be set to a value between 0.9 and 0.95.
Within this range, the setting of λB does not affect the extracted themes significantly, but it does affect the top words with the highest probabilities; a smaller λB tends to cause non-informative common words to show up in the top word list.
Parameter k represents the expected number of subtopics in a subcollection.
In our experiments, we determine the number of themes by using a relatively large k and drop a theme j, if the value of 1|C i | d∈C i π d,j is significantly low.Another parameter is the evolution distance threshold ξ.
This parameter has a "zooming" effect for the discovered theme evolution graph.
A tighter (smaller) ξ would only allow us to see the strongest evolutionary transitions, whereas a looser (larger) ξ would allow us to examine some weaker evolutionary transitions as well.Yet another parameter is the size of sliding window W , which controls the amount of supporting documents when computing the strength of theme θ at time t and affects the smoothness of the life cycle curve.
A small W introduces less smoothing and would allow us to see the temporal patterns in high resolution, but may also make it difficult to see the overall trend.
A larger W would give a smoother curve, but may hide some interesting local variation patterns.
Regarding the "report delay" problem in the news domain, a reasonable value for W appears to be 7-15 days (3-7 days at each side of time t).
While TTM has not been well studied, there are several lines of research related to our work.
For example, in Kleinberg's work on discovering bursty and hierarchical structures in streams [10], text streams are converted to temporal frequency data and an infinite-state automaton is used to model the stream.
Detection of novel topics and trends in text streams has been studied by several researchers [3,18,19,11,13,14], but their focus is to identify emerging trends rather than summarize the complete evolutionary theme patterns in a given text stream as we do.An interesting related work to our analysis of theme life cycles is [16], where Perkio and others used a Multinomial PCA model to extract themes from a text collection and they used a hidden theme-document weight, which is similar to π d,j in Section 3, to compute the strength of a theme.
The major difference between our work and theirs is that we model the theme transitions in a context-sensitive way with an HMM, which presumably captures the natural proximity of similar topics better.Text clustering is another well studied problem relevant to our work.
Specifically, the aspect models studied in [9,20,2] are related to the mixture theme model we use to extract themes.
However, these works do not consider temporal structures in text.
Nallapati and others studied how to discover sub-clusters in a news event and structure them by their dependency, which could also generate a graph structure [15].
A major difference between our work and theirs is that they perform document level clustering, while we perform theme level word clustering.
Another difference is that they do not consider the variations of subtopics in different time periods while we analyze life cycles of themes.Since a theme evolution graph and theme life cycle can serve as a good summary of a collection, our work is also partially related to document summarization (e.g., [12,1]).
Allan and others presented a news summarization method based on ranking and selecting sentences obeying temporal order [1].
However, summarization intends to retain the explicit information in text in order to maintain fidelity, while we aim at extracting non-obvious implicit themes and their evolutionary patterns.
Text streams often contain latent temporal theme structures which reflect how different themes influence each other and evolve over time.
Discovering such evolutionary theme patterns can not only reveal the hidden topic structures, but also facilitate navigation and digestion of information based on meaningful thematic threads.
In this paper, we propose general probabilistic approaches to discover evolutionary theme patterns from text streams in a completely unsupervised way.
To discover the evolutionary theme graph, our method would first generate word clusters (i.e., themes) for each time period and then use the Kullback-Leibler divergence measure to discover coherent themes over time.
Such an evolution graph can reveal how themes change over time and how one theme in one time period has influenced other themes in later periods.
We also propose a method based on hidden Markov models for analyzing the life cycle of each theme.
This method would first discover the globally interesting themes and then compute the strength of a theme in each time period.
This allows us to not only see the trends of strength variations of themes, but also compare the relative strengths of different themes over time.We evaluated our methods using two different data sets.
One is a stream of 50 days' news articles about the tsunami disaster that happened recently in Asia, and the other is the abstracts of the KDD conference proceedings from 1999 to 2004.
In both cases, the proposed methods can generate meaningful temporal theme structures and allow us to summarize and analyze the text data from temporal perspective.
Our methods are generally applicable to any text stream data and thus have many potential applications in temporal text mining.There are several interesting directions to further extend this work.
First, we have only considered a flat structure of themes; it would be interesting to explore hierarchical theme clustering, which can give us a picture of theme evolutions at different resolutions.
Second, we can develop a temporal theme mining system based on the proposed methods to help a user navigate the stream information space based on evolutionary structures of themes.
Such a system can be very useful for managing all kinds of text stream data.
Finally, temporal text mining (TTM) represents a promising new direction in text mining that has not yet been wellexplored.
In addition to evolutionary theme patterns, there are many other interesting patterns such as associations of themes across multiple streams that are interesting to study.
We thank Tao Tao for his constructive technical comments and Hang Su for helping collect the tsunami data.
We are grateful to the three anonymous reviewers for their extremely useful comments.
This material is based in part upon work supported by the National Science Foundation under award numbers CAREER-IIS-0347933 and ITR-IIS-0428472.
