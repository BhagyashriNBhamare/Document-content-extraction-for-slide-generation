Families of products are steadily emerging for distinct settings such as embedded systems, navigational systems, financial applications or even web applications.
This shifts the attention from individual product-centric development to software product line development where the focus is on constructing reusable assets from which customer-specific products are obtained.
This paper tackles the maintenance of an entire family of products, describing our approach to quantifying maintainability.
We report our experience measuring the maintainability index of each product in the family, and then propose a generalization of the results in terms of the entire family or product line.
This exposes a number of benefits towards the improvement of product-line maintainability, enhancing ultimately customer-specific products.
Software Product Lines (SPL) are defined as a set of software-intensive systems, sharing a common, managed set of features that satisfy the specific needs of a particular market segment or mission and that are developed from a common set of core assets in a prescribed way [6].
The SPL paradigm distinguishes between domain engineering and product engineering, where construction of the reusable assets and their variability is separated from production of the SPL products.
These reusable assets include the architecture, software components, design models and, in general, any artifact that is prepared and liable to be reused.These assets are the base on top of upon which products are created deciding its variability, which is expressed as features (i.e. increments in product functionality) [4].
Distinct techniques exist to realize feature implementations.
Feature Oriented Programming provides models and tools where the realization of each feature is modularized [1].
An SPL product is then obtained by composing customerdesired features.Quality measurement is a main requirement in software development.
SPLs are not an exception.
However, most measures and techniques use a holistic approach where the artifact to be measured is assessed as a whole.
This could be contra-intuitive for SPL products which are obtained as the synthesis of a set of features.
From this perspective, the question is whether the quality (whatever this means) of an SPL product can be obtained from the quality of the features the product supports.
And this in turn, poses the question of how to assess feature quality.
Notice that features are inconclusive pieces of code which do not make sense in isolation but assembled to a base or platform.
In this regard, they are different from components which can be run in isolation.This feature-based measurement would permit users to select features based on the expected contribution the feature makes to the final quality of the SPL product, or even to restrict the available products to those below a certain value for a specific quality attribute [3].
To assess the feasibility of this approach, this work focuses on the Maintainability Index (MI) as the measure to be assessed.
The MI is largely used to help reduce system's tendency toward "code entropy" or degraded integrity.
Existing tools enable to quantify MI for individual software products.The findings of this work include the difficulty of ascertaining MI by directly measuring the feature.
Rather the feature impact is assessed as the difference between SPL products, some exhibiting the feature and some others not.
This indirect way permits us to assess the contribution of a feature by measuring proper products rather than adapting existing MI techniques to the inconclusive products that features represent.
The adoption of SPL is reported in several case studies [6], [16].
In general, prior SPL experiences reported a number of general and potential benefits, namely, (i) productivity gains, (ii) faster time-tomarket, (iii) decreased labour efforts, and (iv) improved product quality.
Our work elaborates on such quality issues, specifically on maintainability from an SPL perspective.Maintainability is the ease with which a software system can be modified to correct faults, improve performance, or adapt to a changing environment [10].
The literature shows several efforts to characterize and quantify software maintainability.
The most widely accepted proposes the use of a polynomial regression model where regression analysis is used as a tool to ACCEPTED FOR PUBLICATION AT: 12th European Conference on Software Maintenance and Reengineering (CSMR 2008).
Athens, Greece.
April 1-4, 2008 explore the relationship between software maintainability and software metrics [17].
Prior work analyzed maintenance in traditional product-centric software development scenarios where the focus was on individual products.
However, our work introduces an SPL scenario, and this poses a number of differences.Distinct quality dimensions are introduced in SPL.
A product is obtained from the product-line reusable assets.
Hence, it is needed to measure such assets, not the product itself.
The significance is that the complexity of maintenance arises as product's assets are not maintained, but reusable assets are [12].
Error propagation has more impact in an SPL than in an individual product development.
While developing an individual product, errors are propagated inside such product.
However, one error in a reusable core asset (of the product line) can be propagated to a number of products as it is used by them.Change probability.
It is more likely to change a reusable asset than an asset for an individual product.
This happens as the domain to serve SPL products is larger and can require new functionalities faster than a single customer.These differences of SPL development from individual product-centric development vindicate a study of maintainability that should address not only final product code, but also the SPL platform that produces such products.More to the point, SPL developers no longer maintain each individual products (produced from the SPL), but rather they maintain the reusable assets from which those products are produced.
Our intention is not to measure maintainability in a qualitative way, but in a quantitative way.
This implies that our aim is to quantify the product line.
As our goal was to use existing measures instead of inventing new ones, we selected the maintainability index.
A program's maintainability is calculated through a Maintainability Index (MI) [15], which uses a combination of widely-used and commonly-available measures.
Note that all are based on average-per-codemodule measurement.
The MI of a program is a polynomial:( ) ( ) ' 23 .
0 ln 2 .
5 171 g aveV aveV MI × − × − = ( ) perCM aveLOC × × + × − 4 .
2 sin 50 ln 2 .
16where (i) aveV is the computational complexity of a program's module measured directly from source code [9], (ii) aveV(g') measures the number of linearlyindependent paths through a program module [13], (iii) aveLOC is the average count of lines of code per module.
Non Commenting Source Statements are measured, and (iv) perCM is the average percent of lines of comments per module.The larger the MI, the more maintainable is the program.
MI has been widely used and tested in industrial cases [14] and compared [7].
Nonetheless, MI measurement is not a trivial task, which requires sophisticated tooling such as SemanticDesigns 1 [5].
Feature Oriented Programming (FOP) is a paradigm to SPL development where features are the building blocks of products [4].
Features are units incrementing application functionality by which different products can be distinguished and defined within an SPL.
In general, an SPL is characterized by the set of features it supports, e.g. Focusing on Java, feature realization is achieved through Jak files.
A first approach would be to measure directly the MI of Jak files.
However, a number of problems prevented us from doing so.First, existing tools are targeted to Java or C. So, Jak-specific measurement tooling is unavailable (i.e. new tooling would be required).
Second, Jak can be measured adapting existing MI.
However, the measurement of refinements would require further study because a refinement is not a complete Java class, but an extension.
So, it is likely that a new MI for refinements would be necessary.Third, refinements may override existing code which would make the MI result to change.
Thus, there are some interactions among features we may want to detect.
These interactions would affect to product's MI [12].
In other words, feature addition does not always have a monotonic effect on the MI measure.
The addition of a new feature could result in a reduction of the MI for the resulting product since a feature can make the code of the resulting product harder to maintain.
Therefore, calculating the MI for each feature separately, and then, aggregating those values to obtain the MI of the product could be wrong (at least using the model used in this work for feature realization).
As a result, an indirect way to measure feature MI was devised.
Let P be the set of total products an SPL can generate.
Let P+ and P-be a total cover of P, which refer to the products exhibiting feature F and the products that lack feature F, respectively.
The MI impact for feature F can be ascertained from MI(P+) and MI(P-).
This intuition is formalized in terms of a matrix.
Each row stands for a product, and each column represents the MI contribution of a given feature F (the value we want to obtain).
Next subsection elaborates on the details using a case study.
Our aim is to experimentally quantify maintainability following the approach sketched before.
We evaluate our approach with 2 case studies.
The first case is a simple product line of calculators called MUKalk, which we developed [2].
This product-line consists of 15 features, yielding hundreds of distinct calculator products.
This case study enables us to evaluate initially our ideas [2].
However, this case (i) was developed by us, and (ii) consisted only of a few classes.
So, these reasons led us to consider that our initial ideas may not scale.
Hence, we decided to evaluate our ideas with an external case.We selected GPL (Graph Product Line) as (i) it has more classes (i.e. MUKalk consists of 3 Java classes and GPL of 16), and (ii) it is one of the case studies provided by AHEAD Tool Suite [1] (this means that at least it has been used before by others).
GPL is a product line of graph manipulation programs.
GPL can be downloaded together with AHEAD Tool Suite [1].
GPL product line provides 18 features, which are typically sketched using a feature model, representing feature variability in a domain (i.e. features that are mandatory, optional and the way they are arranged into groups) [8].
Figure 1 shows the feature model for GPL.We used GPL to first measure the MI for each product, then from this information we obtained the MI for each feature, and finally we elaborated on the overall MI of the product-line.
Considering all the features of GPL we built all the possible products (147) and get measures of the MI for each product using SemanticDesigns' tooling.
Next step was to create a system of equations with these results to get the values of MI for each feature (the equations system for GPL is partially shown in Figure 2).
To this end, we created a matrix where the rows contain equations.
There is one row per product.
The number of columns is the number of features (read from left to right as product expressions in AHEAD).
For instance, first equation in Figure 2 represents product P001 in Table 1 While creating this system, we assumed that • (composition operator) was addition.
This assumption was backed by recent studies showing AHEAD's duality where the rate of refinements within total is around 10%.
Thus, the most of the code (90%) are introductions [2].
Therefore, we can argue that • would be addition if the majority of the code is introduced.
(This premise was later confirmed in our experiments.)
MatLab 2 was used to resolve the matrix equation system.
To this end, a vector (MI_vector) with all the MI values for products was created.
Next, we show a partial vector with some values (the original vector has 147).
MI_vector=[153.96,146.62,149.50,153.23, 150.32,148.71,153.46]'Then, a matrix specifying product features (PF) was created: 147 rows (1 per product) and 18 columns (1 per feature).
Note that 1 designates the feature was present, whereas 0 means was not.
Next, PF matrix is partially shown (the original has 147 rows).
Note that 10 features out of 18 have an impact below 1 (positive and negative values).
The lowest impact was 0.0119 and corresponds to feature s Number .
The average impact was 1.6498.
MI incremented for 8 features and decremented for 9 (the base has an absolute value).
So, these results seemed reasonable as some features improve MI (positive values), whereas others deteriorate it (remind that the larger MI means more maintainable).
MatLab resolution provides a range of errors (for these resolution) from 0 (product P147) to 1.2414 (product P008).
.
It is possible to elaborate on the MI value of each feature in order to study the MI of the entire product line.
We sketched the feature model of GPL (see Figure 1), and annotate each feature with its corresponding MI value.A first proposal to characterize the MI of the product-line would be the summation of the values of all features together.
In GPL, the result would be 175.6524.
However, this value is even higher than that of the most maintainable product (154.9087 of P043).
This is because not all features can be selected in the same product (e.g. alternative features and exclusion dependencies).
In addition, MI is based on average and not on summation.
Hence, summation can neglect the sense of MI.Alternatively, we characterize a product-line's MI by its range of values.
Those values for GPL are: the lowest value is 144.4391 (P080), the highest is 154.9087 (P043), and the average is 149.2546.
We believe this range characterizes better the SPL.
Lessons LearnedWe encountered many problems during the MI measurement of GPL.
Most were not related with GPL, but with the quantification process itself.
We believe that these problems hold to the measurement of product lines in general.
Solutions to these problems in order to simplify future works are discussed below.
Dependencies among Features: Impact of Order.
We realize that the order in which a feature appears impacts on the whole product MI (i.e. the order is important as it affects to the product and to its maintainability).
This means that (i) the feature does not have a fixed MI value, but it has an average, and (ii) the product MI depends on the feature order.
Monotonicity.
AHEAD may produce a non monotonic effect when previous code is not preserved (e.g. method overriding).
This occurs scarcely, but it causes slight alterations in our estimations for MI as we calculate the average of those interactions.
We detect this problem in GPL example when adding BFS feature to 3 different products and compare those 3 products without BFS.
The impact of adding BFS ranged from 0.57, 0.72 and 0.97 (for each product).
This occurs (without feature dependency) because monotonicity is not preserved.
More to the point, BFS overrides different code and causes different changes.
This implies that the feature impact is not independent, but depends on prior composed code.Artifact Heterogeneity.
This work focuses on code maintenance but there are as well other artifacts to maintain in an SPL, such as documents, requirements specification, architecture, production plan, models and all the artifacts or core assets that form the platform.
Generality of Experiences.
There are distinct approaches and paradigms to SPL development from which we chose AHEAD.
It would be interesting to develop the same SPL using different variability implementation techniques, and evaluate whether the same MI are obtained for the same product constructed with different approaches Range of Maintainability Index.
Prior work on the maintenance of C language code showed that values of MI ranging from 65 to 85 (or higher) seem to offer a good maintenance.
However, in our case study measuring Java, we found values ranging from 145 to 155 (these figures are similar to our initial case study results).
Thus, there is a significant difference between 65-85 and 145-155 ranges.
We believe that such difference could be caused from the different languages that are used (i.e. C vs. Java).
So, the range may depend on the language.
This premise is backed by a recent work that suggests that MI can differ severely depending on the language [11].
Exploiting SPL Maintainability.
Our initial intention was just to quantify maintainability index of an SPL.
We realize that the ultimate goal is really to exploit such data.
Using MI impact enables to locate features where implementation may be enhanced, improving overall product's MI.
The focus should be placed on features most used, which depends on feature commonality [3].
Hence, we may focus on features where either MI, either feature commonality are large.
On these features, we can take design decisions such as (i) simplifying feature code, (ii) refactoring feature code using bad smells in code, or (iii) splitting feature code among new created features.
ConclusionsThe need for SPL measurement, and particularly maintainability quantification, is a major issue currently in SPL development.
We concentrated on Feature Oriented Programming as it provides a systematic approach to SPL development where a model to separate artifacts within features is provided.This paper reported our experience on quantifying SPL maintainability.
It introduced an initial model to measure it, and presented some experimental results with a product line case study.
Our results confirmed partially our assumptions that need to be evaluated with further cases.
We are currently using our approach on an industrial embedded system, which results could prove or refute our ideas.The maintenance effort in SPL is significantly reduced as SPL developers are no longer maintaining each individual product (produced from the SPL), but they maintain the reusable assets from which those products are produced (SPL features).
In our case, this meant maintaining 18 features code instead of 147 products code.
It is possible to elaborate on the MI value of each feature in order to study the MI of the entire product line.
We sketched the feature model of GPL (see Figure 1), and annotate each feature with its corresponding MI value.A first proposal to characterize the MI of the product-line would be the summation of the values of all features together.
In GPL, the result would be 175.6524.
However, this value is even higher than that of the most maintainable product (154.9087 of P043).
This is because not all features can be selected in the same product (e.g. alternative features and exclusion dependencies).
In addition, MI is based on average and not on summation.
Hence, summation can neglect the sense of MI.Alternatively, we characterize a product-line's MI by its range of values.
Those values for GPL are: the lowest value is 144.4391 (P080), the highest is 154.9087 (P043), and the average is 149.2546.
We believe this range characterizes better the SPL.
We encountered many problems during the MI measurement of GPL.
Most were not related with GPL, but with the quantification process itself.
We believe that these problems hold to the measurement of product lines in general.
Solutions to these problems in order to simplify future works are discussed below.
Dependencies among Features: Impact of Order.
We realize that the order in which a feature appears impacts on the whole product MI (i.e. the order is important as it affects to the product and to its maintainability).
This means that (i) the feature does not have a fixed MI value, but it has an average, and (ii) the product MI depends on the feature order.
Monotonicity.
AHEAD may produce a non monotonic effect when previous code is not preserved (e.g. method overriding).
This occurs scarcely, but it causes slight alterations in our estimations for MI as we calculate the average of those interactions.
We detect this problem in GPL example when adding BFS feature to 3 different products and compare those 3 products without BFS.
The impact of adding BFS ranged from 0.57, 0.72 and 0.97 (for each product).
This occurs (without feature dependency) because monotonicity is not preserved.
More to the point, BFS overrides different code and causes different changes.
This implies that the feature impact is not independent, but depends on prior composed code.Artifact Heterogeneity.
This work focuses on code maintenance but there are as well other artifacts to maintain in an SPL, such as documents, requirements specification, architecture, production plan, models and all the artifacts or core assets that form the platform.
Generality of Experiences.
There are distinct approaches and paradigms to SPL development from which we chose AHEAD.
It would be interesting to develop the same SPL using different variability implementation techniques, and evaluate whether the same MI are obtained for the same product constructed with different approaches Range of Maintainability Index.
Prior work on the maintenance of C language code showed that values of MI ranging from 65 to 85 (or higher) seem to offer a good maintenance.
However, in our case study measuring Java, we found values ranging from 145 to 155 (these figures are similar to our initial case study results).
Thus, there is a significant difference between 65-85 and 145-155 ranges.
We believe that such difference could be caused from the different languages that are used (i.e. C vs. Java).
So, the range may depend on the language.
This premise is backed by a recent work that suggests that MI can differ severely depending on the language [11].
Exploiting SPL Maintainability.
Our initial intention was just to quantify maintainability index of an SPL.
We realize that the ultimate goal is really to exploit such data.
Using MI impact enables to locate features where implementation may be enhanced, improving overall product's MI.
The focus should be placed on features most used, which depends on feature commonality [3].
Hence, we may focus on features where either MI, either feature commonality are large.
On these features, we can take design decisions such as (i) simplifying feature code, (ii) refactoring feature code using bad smells in code, or (iii) splitting feature code among new created features.
The need for SPL measurement, and particularly maintainability quantification, is a major issue currently in SPL development.
We concentrated on Feature Oriented Programming as it provides a systematic approach to SPL development where a model to separate artifacts within features is provided.This paper reported our experience on quantifying SPL maintainability.
It introduced an initial model to measure it, and presented some experimental results with a product line case study.
Our results confirmed partially our assumptions that need to be evaluated with further cases.
We are currently using our approach on an industrial embedded system, which results could prove or refute our ideas.The maintenance effort in SPL is significantly reduced as SPL developers are no longer maintaining each individual product (produced from the SPL), but they maintain the reusable assets from which those products are produced (SPL features).
In our case, this meant maintaining 18 features code instead of 147 products code.
