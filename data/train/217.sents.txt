The discussion in the computer-science literature of the relative merits of linear-versus branching-time frameworks goes back to early 1980s.
One of the beliefs dominating this discussion has been that the linear-time framework is not expressive enough semantically, making linear-time logics lacking in expres-siveness.
In this work we examine the branching-linear issue from the perspective of process equivalence, which is one of the most fundamental notions in concur-rency theory, as defining a notion of process equivalence essentially amounts to defining semantics for processes.
Over the last three decades numerous notions of process equivalence have been proposed.
Researchers in this area do not any-more try to identify the "right" notion of equivalence.
Rather, focus has shifted to providing taxonomic frameworks, such as "the linear-branching spectrum", for the many proposed notions and trying to determine suitability for different applications.
We revisit this issue here from a fresh perspective.
We postulate three principles that we view as fundamental to any discussion of process equivalence.
First, we borrow from research in denotational semantics and take contextual equivalence as the primary notion of equivalence.
This eliminates many testing scenarios as either too strong or too weak.
Second, we require the description of a process to fully specify all relevant behavioral aspects of the process.
Finally, we require observable process behavior to be reflected in its input/output behavior.
Under these postulates the distinctions between the linear and branching semantics tend to evaporate.
As an example, we apply these principles to the framework of transducers , a classical notion of state-based processes that dates back to the 1950s and is well suited to hardware modeling.
We show that our postulates result in a unique notion of process equivalence, which is trace based, rather than tree based.
One of the most significant recent developments in the area of formal design verification is the discovery of algorithmic methods for verifying temporal-logic properties of finitestate systems [23,52,66,76].
In temporal-logic model checking, we verify the correctness of a finite-state system with respect to a desired property by checking whether a labeled state-transition graph that models the system satisfies a temporal logic formula that specifies this property (see [25]).
Model-checking tools have enjoyed a substantial and growing use over the last few years, showing ability to discover subtle flaws that result from extremely improbable events.
While early on these tools were viewed as of academic interest only, they are now routinely used in industrial applications [36].
A key issue in the design of a model-checking tool is the choice of the temporal language used to specify properties, as this language, which we refer to as the temporal property-specification language, is one of the primary interfaces to the tool.
(The other primary interface is the modeling language, which is typically the hardware description language used by the designers).
One of the major aspects of all temporal languages is their underlying model of time.
Two possible views regarding the nature of time induce two types of temporal logics [51].
In linear temporal logics, time is treated as if each moment in time has a unique possible future.
Thus, linear temporal logic formulas are interpreted over linear sequences and we regard them as describing the behavior of a single computation of a program.
In branching temporal logics, each moment in time may split into various possible futures.
Accordingly, the structures over which branching temporal logic formulas are interpreted can be viewed as infinite computation trees, each describing the behavior of the possible computations of a nondeterministic process.In the linear temporal logic LTL, formulas are composed from the set of atomic propositions using the usual Boolean connectives as well as the temporal connectives G ("always"), F ("eventually"), X ("next"), and U ("until").
The branching temporal logic CTL ⋆ augments LTL by the path quantifiers E ("there exists a computation") and A ("for all computations").
The branching temporal logic CTL is a fragment of CTL ⋆ in which every temporal connective is preceded by a path quantifier.
Note that LTL has implicit universal path quantifiers in front of its formulas.
Thus, LTL is essentially the linear fragment of CTL ⋆ .
The discussion of the relative merits of linear versus branching temporal logics in the context of system specification and verification goes back to the 1980s [51,30,9,65,32,31,68,22,20,73,74].
As analyzed in [65], linear and branching time logics correspond to two distinct views of time.
It is not surprising therefore that LTL and CTL are expressively incomparable [22,31,51].
The LTL formula F Gp is not expressible in CTL, while the CTL formula AF AGp is not expressible in LTL.
On the other hand, CTL seems to be superior to LTL when it comes to algorithmic verification, as we now explain.Given a transition system M and a linear temporal logic formula ϕ, the modelchecking problem for M and ϕ is to decide whether ϕ holds in all the computations of M .
When ϕ is a branching temporal logic formula, the problem is to decide whether ϕ holds in the computation tree of M .
The complexity of model checking for both linear and branching temporal logics is well understood: suppose we are given a transition system of size n and a temporal logic formula of size m. For the branching temporal logic CTL, model-checking algorithms run in time O(nm) [23], while, for the linear temporal logic LTL, model-checking algorithms run in time n2 O(m) [52].
Since LTL model checking is PSPACE-complete [67], the latter bound probably cannot be improved.The difference in the complexity of linear and branching model checking has been viewed by some as an argument in favor of the branching paradigm.
In particular, the seeming computational advantage of CTL model checking over LTL model checking made CTL a popular choice, leading to efficient model-checking tools for this logic [24].
Through the 1990s, the dominant temporal specification language in industrial use was CTL.
This dominance stemmed from the phenomenal success of SMV, the first symbolic model checker, which was CTL-based, and its follower VIS, also originally CTL-based, which served as the basis for many industrial model checkers.In [75] we argued that the computational advantage of LTL over CTL is rather illusory.
We further argued that in spite of the phenomenal success of CTL-based model checking, CTL suffers from several fundamental limitations as a temporal propertyspecification language, all stemming from the fact that CTL is a branching-time formalism: the language is counterintuitive and hard to use, it does not lend itself to compositional reasoning, and it is fundamentally incompatible with semi-formal verification.
In contrast, the linear-time framework is expressive and intuitive, supports compositional reasoning and semi-formal verification, and is amenable to combining enumerative and symbolic search methods.
Indeed, the trend in the industry during this decade has been towards linear-time languages, such as ForSpec [7], PSL [29], and SVA [77].
In spite of the pragmatic arguments in favor of the linear-time approach, one still hears the arguments that this approach is not expressive enough, pointing out that in semantical analyses of concurrent processes, e.g., [71], the linear-time approach is considered to be the weakest semantically, yielding the coarsest notion of equivalence.
In this paper we address the semantical arguments against linear time and argue that even from a semantical perspective the linear-time approach is quite adequate for specifying systems.The gist of our argument is that branching-time-based notions of process equivalence are not reasonable notions of process equivalence, as they distinguish between processes that are not contextually distinguishable.
In contrast, the linear-time view does yield an appropriate notion of contextual equivalence.
The most fundamental approach to the semantics of programs focuses on the notion of equivalence.
Once we have defined a notion of equivalence, the semantics of a programs can be taken to be its equivalence class.
In the context of concurrency, we talk about process equivalence.
The study of process equivalence provides the basic foundation for any theory of concurrency [62], and it occupies a central place in concurrency-theory research, cf. [71].
The linear-time approach to process equivalence focuses on the traces of a process.
Two processes are defined to be trace equivalent if they have the same set of traces.
It is widely accepted in concurrency theory, however, that trace equivalence is too weak a notion of equivalence, as processes that are trace equivalent may behave differently in the same context [61].
An an example, using CCS notation, the two processes (a.b) + (a.c) and a.(b + c) have the same set of traces, but only the first one may deadlock when run in parallel with a process such as a.c.In contrast, the two processes above are distinguished by bisimulation, a highly popular notion of process equivalence [62,64,69].
It is known that CTL characterizes bisimulation, in the sense that two states in a transition system are bisimilar iff they satisfy exactly the same CTL formulas [18] (see also [43]).
This is sometime mentioned as an important feature of CTL.
This contrast, between the pragmatic arguments in favor of the adequate expressiveness of the linear-time approach [75] and its accepted weakness from a processequivalence perspective, calls for a re-examination of process-equivalence theory.
While the study of process equivalence occupies a central place in concurrency-theory research, the answers yielded by that study leave one with an uneasy feeling.
Rather than providing a definitive answer, this study yields a profusion 1 of choices [4].
This situation led to statements of the form "It is not the task of process theory to find the 'true' semantics of processes, but rather to determine which process semantics is suitable for which applications" [71].
This situation should be contrasted with the corresponding one in the study of sequential-program equivalence.
It is widely accepted that two programs are equivalent if they behave the same in all contexts, this is referred to as contextual or observational equivalence, where behavior refers to input/output behavior [78].
In principle, the same idea applies to processes: two processes are equivalent if they pass the same tests, but there is no agreement on what a test is and on what it means to pass a test.We propose to adopt for process-semantics theory precisely the same principles accepted in program-semantics theory.Principle of Contextual Equivalence: Two processes are equivalent if they behave the same in all contexts, which are processes with "holes".
As in program semantics, a context should be taken to mean a process with a "hole", into which the processes under consideration can be "plugged".
This agrees with the point of view taken in testing equivalence, which asserts that tests applied to processes need to themselves be defined as processes [26].
Furthermore, all tests defined as processes should be considered.
This excludes many of the "button-pushing experiments" of [61].
Some of these experiments are too strong-they cannot be defined as processes, and some are too weak-they consider only a small family of tests [26].
In particular, the tests required to define bisimulation equivalence [3,61] are widely known to be too strong [12][13][14]37].
In spite of its mathematical elegance [6,69] and ubiquity in logic [10,5], bisimulation is not a reasonable notion of process equivalence, as it makes distinctions that cannot be observed.
Bisimulation is essentially a structural similarity relation, as it relates states of the processes under comparison.
It is a tractable relaxation of isomorphism, rather than an observational comparison relation.The most explicit advocacy of using bisimulation-based equivalence (in fact, branching bisimulation) appears in [72], which argues in favor of using equivalence concepts that are based on internal structure because of their context independence: "if two processes have the same internal structure they surely have the same observable behavior."
It is hard to argue with the last point, but expecting an implementation to have the same internal structure as a specification is highly unrealistic and impractical, as it requires the implementation to be too close to the specification.
2 In fact, it is clear from the terminology of "observational equivalence" used in [62] that the intention there was to formulate a concept of equivalence based on observational behavior, rather than on internal structure.
Nevertheless, the terms "observational equivalence" for bisimulationbased equivalence in [62] is, perhaps, unfortunate, as weak-bisimulation equivalence is in essence a notion of structural similarity.Remark 1.
One could argue that bisimulation equivalence is not only a mathematically elegant concept; it also serves as the basis for useful sound proof techniques for establishing process equivalence, cf. [43].
The argument here, however, is not against bisimulation as a useful mathematical concept; such usefulness ought to be evaluated on its own merits, cf. [35,79].
Rather, the argument is against viewing bisimulation-based notions of equivalence as reasonable notions of process equivalence.The Principle of Contextual Equivalence does not fully resolve the question of process equivalence.
In additional to defining the tests to which we subject processes, we need to define the observed behavior of the tested processes.
It is widely accepted, however, that linear-time semantics results in important behavioral aspects, such as deadlocks, being non-observable [61].
It is this point that contrasts sharply with the experience that led to the adoption of linear time in the context of hardware model checking [75]; in today's synchronous hardware all relevant behavior, including deadlock and livelock is observable (observing livelock requires the consideration of infinite traces).
Compare this with our earlier example, where the process (a.b) + (a.c) may deadlock when run in parallel with a process such as a.c.
The problem here is that the description of the process does not tell us what happens when the first summand is selected in the context of the parallel process a.c.
The deadlock here is not described explicitly; rather it is implicitly inferred from a lack of specified behavior.
This leads us to our second principle.
A process description should model all relevant aspects of process behavior.The rationale for this principle is that relevant behavior, where relevance depends on the application at hand, should be captured by the description of the process, rather than inferred from lack of behavior by a semantical theory proposed by a concurrency theorist.
It is the usage of inference to attribute behavior that opens the door to numerous interpretations, and, consequently, to numerous notions of process equivalence.
As an example, consider the notion of completed-trace equivalence in [71].
Implicitly, this notion assumes that the completion of a trace is observable.
The Principle of Comprehensive Modeling requires that this observability be modeled explicitly, by the modeler, rather than attributed implicitly by the concurrency theorist.Remark 2.
It is useful to draw an analogy here to another theory, that of nonmonotonic logic, whose main focus is on inferences from absence of premises.
The field started with some highly influential papers, advocating, for example "negation as failure" [21] and "circumscription" [58].
Today, however, there is a profusion of approaches to nonmonotonic logic, including numerous extensions to negation as failure and to circumscription [57].
One is forced to conclude that there is no universally accepted way to draw conclusions from absence of premises.
(Compare also to the discussion of negative premises in transition-system specifications [14,37].)
Going back to our problematic CCS process (a.b) + (a.c), the problem is that the process is not receptive to the action c, after it has executed a on the left summand.
The position that processes need to be receptive to all allowed inputs from their environment has been argued by many authors [2,27,54,53].
It can be viewed as an instance of our Principle of Comprehensive Modeling, which says that the behavior that results from an action c by the environment after the process has executed a on the left summand needs to be specified explicitly.
From this point of view, process-algebraic formalisms such as CCS [61] are underspecified, since they leave important behavioral aspects unspecified.
For example, if the distinction between normal termination and deadlocked termination is relevant to the application, then this distinction ought to be explicitly modeled.
Rather, in CCS there is no observable distinction between normal and deadlocked termination, as both situations are characterized only by the absence of outgoing transitions.
Note that the approach in [61,62] takes communication to be the basic observable, and abstracts away the distinction between input and output, which is critical to our discussion.
3 It is interesting to note that transducers, which were studied in an earlier work of Milner [60], which led to [61], are receptive.
Transducers are widely accepted models of hardware.
We come back to transducers in the next section.Remark 3.
The Principle of Comprehensive Modeling is implicit in a paper by Halpern on modeling game-theoretic situations [40].
The paper shows that a certain gametheoretic paradox is, in fact, a consequence of deficient modeling, in which states of agents do not capture all relevant aspects of their behavior.
Once the model is appropriately enriched, the paradox evaporates away.
For extensive discussions on modeling multi-agent systems, see Chapters 4 and 5 in [34] and Chapter 6 in [39].
The Principle of Comprehensive Modeling can be thought of as the "Principle of Appropriate Abstraction".
Every model is an abstraction of the situation being modeled.
A good model necessarily abstracts away irrelevant aspects, but models explicitly relevant aspects.
The distinction between relevant and irrelevant aspects is one that can be made only by the model builder and users.
For example, a digital circuit is a model of an analog circuit in which only the digital aspects of the circuit behavior are captured [38].
Such a model should not be used to analyze non-digital aspects of circuit behavior, such as timing issues or issues of metastable states.
Such issues require richer models.
The Principle of Comprehensive Modeling does not call for infinitely detailed models; such models are useless as they offer no abstraction.
Rather, the principle calls for models that are rich enough, but not too rich, depending on the current level of abstraction.
Whether or not deadlocked termination should be considered distinct from normal termination depends on the the current level of abstraction; at one level of abstraction this distinction is erased, but at a finer level of abstraction this distinction is material.
For further discussion of abstraction see [49].
The Principle of Comprehensive Modeling requires a process description to model all relevant aspects of process behavior.
It does not spell out how such aspects are to be modeled.
In particular, it does not address the question of what is observed when a process is being tested.
Here again we propose to follow the approach of program semantics theory and argue that only the input/output behavior of processes is observable.
Thus, observable relevant aspects of process behavior ought to be reflected in its input/output behavior.
The observable behavior of a tested process is precisely its input/output behavior.Of course, in the case of concurrent processes, the input/output behavior has a temporal dimension.
That is, the input/output behavior of a process is a trace of input/output actions.
The precise "shape" of this trace depends of course on the underlying semantics, which would determine, for example, whether we consider finite or infinite traces, the temporal granularity of traces, and the like.
It remains to decide how nondeterminism is observed, as, after all, a nondeterministic process does not have a unique behavior.
This leads to notions such as may testing and must testing [26].
We propose here to finesse this issue by imagining that a test is being run several times, eventually exhibiting all possible behaviors.
Thus, the input/output behavior of a nondeterministic test is its full set of input/output traces.One could also argue that by allowing a test to observe all input/output traces and by allowing infinite traces, our notion of test is too strong, resulting in an overly fine notion of process equivalence.
Similarly, in modeling security protocols, cf.[28], we may want to require a weaker notion of observability of outputs.
We recognize that in some applications one may choose to use a coarser notion of equivalence than the one we use here.
Since our focus in this paper is on showing that trace equivalence is not too coarse, we do not pursue these points further here.It should be noted that the approach advocated here is diametrically opposed to that of [72], who argues against contextual equivalence: "In practice, however, there appears to be doubt and difference of opinion concerning the observable behavior of systems.
Moreover, what is observable may depend on the nature of the systems on which the concept will be applied and the context in which they will be operating."
In contrast, our guiding principles say that (1) by considering all possible contexts, one need not worry about identifying specific contexts or testing scenarios, and (2) process description ought to describe the observable behavior of the process precisely to remove doubts about that behavior.
In our opinion, the "doubt and difference of opinion" about process behavior stem from the underspecificity for formalisms such as CCS and CSP.Remark 4.
In the same way that bisimulation is not a contextual equivalence relation, branching-time properties are not necessarily contextually observable.
Adapting our principles to property observability we should expect behavioral properties to be observable in the following sense.
If two processes are distinguished by a property ϕ, that is, P 1 satisfies ϕ, but P 2 does not satisfy ϕ, there has to be a context C such that the set of input-output traces of C[P 1 ] is different than that of C[P 2 ].
Consider, however, the CTL property AGEF p, which says that from all given states of the process it is possible to reach a state where p holds.
It is easy to construct processes P 1 and P 2 , one satisfying AGEF p and one falsifying it, such that C[P 1 ] and C[P 2 ] have the same set of input-output traces for all contexts C. Thus, AGEF p is a structural property rather than an observable property.In the next section we apply our approach to transducers; we show that once our three principles are applied we obtain that trace-based equivalence is adequate and fully abstract; that is, it is precisely the unique observational equivalence for transducers.
We believe that this holds in general; that is, under our three principles, trace-based equivalence provides the "right" notion of process equivalence.
In this section, we apply the approach discussed above to a very simple notion of process: transducers [60].
We choose this notion of process, as it trivially satisfies the Principle of Comprehensive Modeling and the Principle of Observable I/O, since the behavior of a transducer is fully described by its state-transition and output functions.Transducers constitute a fundamental model of discrete-state machines with input and output channels [41].
They are still used as a basic model for sequential computer circuits [38].
We use nondeterministic transducers as our model for processes.
We define a synchronous composition operator for such transducers, which provides us a notion of context.
We then define linear observation semantics and prove adequacy and full-abstraction results for trace equivalence in terms of it.
Thus, this case study provides a concrete example in which our philosophical approach can be tested.
A nondeterministic transducer is a state machine with input and output channels.
The state-transition function depends on the current state and the input, while the output depends solely on the current state (thus, our machines are Moore machines [41]).
Definition 1.
A transducer is a tuple, M = (Q, q 0 , I, O, Σ, σ, λ, δ), where -Q is a countable set of states.
-q 0 is the start state.
-I is a finite set of input channels.
-O is a finite set of output channels.
-Σ is a finite alphabet of actions (or values).
-σ : I ∪ O → 2 Σ − {∅} is a function that allocates an alphabet to each channel.
-λ : Q × O → Σ is the output function of the transducer.
λ(q, o) ∈ σ(o) is the value that is output on channel o when the transducer is in state q. -δ : Q × σ(i 1 ) × . . . × σ(i n ) → 2 Q , where I = {i 1 , . . . , i n }, is the transition function, mapping the current state and input to the set of possible next states.Both I and O can be empty.
In this case δ is a function of state alone.
This is important because the composition operation that we define usually leads to a reduction in the number of channels.
Occasionally, we refer to the set of allowed values for a channel as the channel alphabet.
This is distinct from the total alphabet of the transducer (denoted by Σ).
We represent a particular input to a transducer as an assignment that maps each input channel to a particular value.
Formally, an input assignment for a transducer (Q, q 0 , I, O, Σ, σ, λ, δ) is a function f : I → Σ, such that for all i ∈ I, f (i) ∈ σ(i).
The entire input can then, by a slight abuse of notation, be succinctly represented as f (I).
We point to three important features of our definition.
First, note that transducers are receptive.
That is, the transition function δ(q, f ) is defined for all states q ∈ Q and input assignments f .
There is no implicit notion of deadlock here.
Deadlocks need to be modeled explicitly, e.g., by a special sink state d whose output is, say, "deadlock".
Second, note that inputs at time k take effect at time k + 1.
This enables us to define composition without worrying about causality loops, unlike, for example, in Esterel [11].
Thirdly, note that the internal state of a transducer is observable only through its output function.
How much of the state is observable depends on the output function.
In general there is no canonical way to compose machines with multiple channels.
In concrete devices, connecting components requires as little as knowing which wires to join.
Taking inspiration from this, we say that a composition is defined by a particular set of desired connections between the machines to be composed.
This leads to an intuitive and flexible definition of composition.A connection is a pair consisting of an input channel of one transducer along with an output channel of another transducer.
We require, however, sets of connections to be well formed.
This requires two things: -no two output channels are connected to the same input channel, and -an output channel is connected to an input channel only if the output channel alphabet is a subset of the input channel alphabet.
These conditions guarantee that connected input channels only receive well defined values that they can read.
We now formally define this notion.
Conn(M) = {X ⊆ C(M)|(a, b) ∈ X, (a, c) ∈ X⇒b = c} where C(M) = {(i A , o B ) |{A, B} ⊆ M, i A ∈ I A , o B ∈ O B , σ B (o B ) ⊆ σ A (i A )} is the set of all possible input/output connections for M. Elements of Conn(M) are valid connection sets.
Let M = {M 1 , . . . , M n }, where M k = (Q k , q k 0 , I k , O k , Σ k , σ k , λ k , δ k ), be a set of transducers, and C ∈ Conn(M).
Then the composition of M with respect to C, denoted by || C (M), is a transducer (Q, q 0 , I, O, Σ, σ, λ, δ) defined as follows:-Q = Q 1 × . . . × Q n -q 0 = q 1 0 × . . . × q n 0 -I = n k=1 I k − {i | (i, o) ∈ C} -O = n k=1 O k − {o | (i, o) ∈ C} -Σ = n k=1 Σ k -σ(u) = σ k (u), where u ∈ I k ∪ O k -λ(q 1 , . . ., q n , o) = λ k (q k , o) where o ∈ O k -δ(q 1 , . . ., q n , f (I)) = Π n k=1 (δ k (q k , g(I k ))) where g(i) = λ j (q j , o) if (i, o) ∈ C, o ∈ O j , and g(i) = f (i) otherwise.Definition 4 (Binary Composition).
Let M 1 and M 2 be transducers, and C ∈ Conn({M 1 , M 2 }).
The binary composition of M 1 and M 2 with respect to C isM 1 || C M 2 = || C ({M 1 , M 2 }).
The following theorem shows that a general composition can be built up by a sequence of binary compositions.
Thus binary composition is as powerful as general composition and henceforth we switch to binary composition as our default composition operation.
Let M = {M 1 , . . ., M n }, where M k = (Q k , q k 0 , I k , O k , Σ k , σ k , λ k , δ k ), be a set of transducers, and C ∈ Conn(M).
Let M ′ = M − {M n }, C ′ = {(i, o) ∈ C|i ∈ I j , o ∈ O k , j < n, k < n} and C ′′ = C − C ′ .
Then || C (M) = || C ′′ ({|| C ′ (M ′ ), M n }).
The upshot of Theorem 1 is that in the framework of transducers a general context, which is a network of transducers with a hole, is equivalent to a single transducer.
Thus, for the purpose of contextual equivalence it is sufficient to consider testing transducers.
Definition 5 (Execution).
An execution for transducer M = (Q, q 0 , I, O, Σ, σ, λ, δ) is a countable sequence of pairs s i , f i l i=0 such that s 0 = q 0 , and for all i ≥ 0,-s i ∈ Q. -f i : I → Σ such that for all u ∈ I, f (u) ∈ σ(u).
-s i ∈ δ(s i−1 , f i−1 (I)).
If l ∈ N , the execution is finite and its length is l.
If l = ∞, the execution is infinite and its length is defined to be ∞.
The set of all executions of transducer M is denoted exec(M ).
Thus a trace is a sequence of pairs of output and input actions.
While an execution captures the real underlying behavior of the system, a trace is the observable part of that behavior.
The length of a trace α is defined to be the length of the underlying execution and is denoted by |α|.
Definition 7 (Trace Equivalence).
Two transducers M 1 and M 2 are trace equivalent, denoted by M 1 ∼ T M 2 , if T r(M 1 ) = T r(M 2 ).
Note that this requires that they have the same set of input and output channels.We now study the properties of trace equivalence.
We first define the composition of executions and traces.
Definition 8.
Given α = s i , f i n i=0 ∈ exec(M 1 ) and β = r i , g i n i=0 ∈ exec(M 2 ), we define the composition of α and β w.r.t C ∈ Conn({M 1 , M 2 }) as followsα|| C β = (s i , r i ), h i n i=0 where h i (u) = f i (u) if u ∈ I 1 −{i|(i, o) ∈ C} and h i (u) = g i (u) if u ∈ I 2 −{i|(i, o) ∈ C}.
Definition 9.
Given t = ω i , f i n i=0 ∈ T r(M 1 ) and u = ν i , g i n i=0 ∈ T r(M 2 ), we define the composition of t and u w.r.t C ∈ Conn({M 1 , M 2 }) as followst|| C u = µ i , h i n i=0whereµ i (o) = ω i (o) if o ∈ O 1 − {o|(i, o) ∈ C} and µ i (o) = ν i (o) if o ∈ O 2 − {o|(i, o) ∈ C}, and h i is as defined in Definition 8 above.Note that the composition operation defined on traces is purely syntactic.
There is no guarantee that the composition of two traces is a trace of the composition of the transducers generating the individual traces.
The following simple property is necessary and sufficient to achieve this.
C ∈ Conn({M 1 , M 2 }), t 1 = ω 1 i , f 1 i n i=0 ∈ T r(M 1 ) and t 2 = ω 2 i , f 2 i n i=0 ∈ T r(M 2 ), we say that t 1 and t 2 are compatible with respect to C if for all (u, o) ∈ C and for all i ≥ 0, we have-If u ∈ I j and o ∈ O k then f j i (u) = ω k i (o), for all i ≥ 0 and for j, k ∈ {1, 2}.
Lemma 1.
Let C ∈ Conn({M 1 , M 2 }), t ∈ T r(M 1 ) and u ∈ T r(M 2 ).
Then t|| C u ∈ T r(M 1 || C M 2 )if and only if t and u are compatible with respect to C.We now extend the notion of trace composition to sets of traces.Definition 11.
Let T 1 ⊆ T r(M 1 ), T 2 ⊆ T r(M 2 ) and C ∈ Conn({M 1 , M 2 }).
We define T 1 || C T 2 = {t 1 || C t 2 | t 1 ∈ T r(M 1 ), t 2 ∈ T r(M 2 ), |t 1 | = |t 2 |} Theorem 2 (Syntactic theorem of traces).
Let T 1 ⊆ T r(M 1 ) ∩ T r(M 3 ) and T 2 ⊆ T r(M 2 ) ∩ T r(M 4 ), and C ∈ Conn({M 1 , M 2 }) ∩ Conn({M 3 , M 4 }).
Then (T 1 || C T 2 ) ∩ T r(M 1 || C M 2 ) = (T 1 || C T 2 ) ∩ T r(M 3 || C M 4 )Using Theorem 2, we show now that any equivalence defined in terms of sets of traces is automatically a congruence with respect to composition, if it satisfies a certain natural property.
Definition 12 (Trace-based equivalence).
Let M be the set of all transducers.
Let R : M → {A ⊆ T r(M )|M ∈ M} such that for all M ∈ M, R(M ) ⊆ T r(M ).
Then R defines an equivalence relation on M, denoted by ∼ R , such that for all M 1 , M 2 ∈ M, M 1 ∼ R M 2 if and only if R(M 1 ) = R(M 2 ).
Such a relation is called a trace-based equivalence.Trace-based equivalences enable us to relativize trace equivalence to "interesting" traces.
For example, one may want to consider finite traces only, infinite traces only, fair traces only, and the like.
Of course, not all such relativizations are appropriate.
We require traces to be compositional, in the sense described below.
This covers finite, infinite, and fair traces.Definition 13 (Compositionality).
Let ∼ R be a trace-based equivalence.
We say that ∼ R is compositional if given transducers M 1 , M 2 and C ∈ Conn({M 1 , M 2 }), the following hold:1.
R(M 1 || C M 2 ) ⊆ R(M 1 )|| C R(M 2 ).
2.
If t 1 ∈ R(M 1 ), t 2 ∈ R(M 2 ), and t 1 , t 2 are compatible w.r.t. C, then t 1 || C t 2 ∈ R(M 1 || C M 2 ).
The two conditions in Definition 13 are, in a sense, soundness and completeness conditions, as the first ensures that no inappropriate traces are present, while the second ensures that all appropriate traces are present.
That is, the first condition ensures that the trace set captured by R is not too large, while the second ensures that it is not too small.
Note, in particular, that trace equivalence itself is a compositional trace-based equivalence.
The next theorem asserts that ∼ R is a congruence with respect to composition.Theorem 3 (Congruence Theorem).
Let ∼ R be a compositional trace-based equiva- lence.
Let M 1 ∼ R M 3 , M 2 ∼ R M 4 , and C ∈ Conn({M 1 , M 2 }) = Conn({M 3 , M 4 }).
Then M 1 || C M 2 ∼ R M 3 || C M 4 .
An immediate corollary of Theorem 3 is the fact that no context can distinguish between two trace-based equivalent transducers.
Corollary 1.
Let M 1 and M 2 be transducers, R be a compositional trace-based equivalence and M 1 ∼ R M 2 .
Then for all transducers M and all C ∈ Conn({M,M 1 }) = Conn({M, M 2 }), we have that M || C M 1 ∼ R M || C M 2 .
Finally, it is also the case that some context can always distinguish between two inequivalent transducers.
If we choose a composition with an empty set of connections, all original traces of the composed transducers are present in the traces of the composition.
IfM 1 ∼ R M 2 , then M 1 || ∅ M ∼ R M 2 || ∅ M .
We claim the stronger result that given two inequivalent transducers, we can always find a third transducer that distinguishes between the first two, irrespective of how it is composed with them.Theorem 4.
Let M 1 and M 2 be transducers, R be a compositional trace-based equivalence and M 1 ∼ R M 2 .
Then there exists a transducer M such that for all C ∈ Conn({M,M 1 }) ∩ Conn({M, M 2 }), we have M || C M 1 ∼ R M || C M 2 .
The discussion so far has focused on the branching-or linear-time view of process equivalence, where we argued strongly in favor of linear time.
This should be distinguished from the argument in, say, [75] in favor of linear-temporal logics (such as LTL, ForSpec, and the like).
In the standard approach to linear-temporal logics, one interprets formulas in such logics over traces.
Thus, given a linear-temporal formula ψ, its semantics is the set traces(ψ) of traces satisfying it.
A system S then satisfies ψ if traces(S) ⊆ traces(ψ).
It has recently been shown that this view of linear time is not rich enough [50].
The context for this realization is an analysis of liveness properties, which assert that something good will happen eventually.
In satisfying liveness properties, there is no bound on the "wait time", namely the time that may elapse until an eventuality is fulfilled.
For example, the LTL formula F θ is satisfied at time i if θ holds at some time j ≥ i, but j − i is not a priori bounded.In many applications, such as real-time systems, it is important to bound the wait time.
This has given rise to formalisms in which the eventually operator F is replaced by a bounded-eventually operator F ≤k .
The operator is parameterized by some k ≥ 0, and it bounds the wait time to k [8,33].
In the context of discrete-time systems, the operator F ≤k is simply syntactic sugar for an expression in which the next operator X is nested.
Indeed, F ≤k θ is just θ ∨ X(θ ∨ X(θ∨ k−4 . . . ∨Xθ)).
A drawback of the above formalism is that the bound k needs to be known in advance, which is not the case in many applications.
For example, it may depend on the system, which may not yet be known, or it may change, if the system changes.
In addition, the bound may be very large, causing the state-based description of the specification (e.g., an automaton for it) to be very large too.
Thus, the common practice is to use liveness properties as an abstraction of such safety properties: one writes F θ instead of F ≤k θ for an unknown or a too large k.This abstraction of safety properties by liveness properties is not sound for a logic such as LTL.
Consider the system S described in Figure 1 below.
While S satisfies the LTL formula F Gq, there is no k ≥ 0 such that S satisfies F ≤k Gq.
To see this, note that for each k ≥ 0, the computation that first loops in the first state for k times and only then continues to the second state, satisfies the eventuality Gq with wait time k + 1.
q ¬q q Fig. 1.
S satisfies F Gq but does not satisfy F ≤k Gq, for all k ≥ 0.
In [50], there is a study of an extension of LTL that addresses the above problem.
In addition to the usual temporal operators of LTL, the logic PROMPT-LTL has a new temporal operator that is used for specifying eventualities with a bounded wait time.
The new operator is called prompt eventually and is denoted by F p .
It has the following formal semantics: For a PROMPT-LTL formula ψ and a bound k ≥ 0, let ψ k be the LTL formula obtained from ψ by replacing all occurrences of F p by F ≤k .
Then, a system S satisfies ψ iff there is k ≥ 0 such that S satisfies ψ k .
Note that while the syntax of PROMPT-LTL is very similar to that of LTL, its semantics is defined with respect to an entire system, and not with respect to computations.
For example, while each computation π in the system S from Figure 1 has a bound k π ≥ 0 such that Gq is satisfied in π with wait time k π , there is no k ≥ 0 that bounds the wait time of all computations.
It follows that, unlike LTL, we cannot characterize a PROMPT-LTL formula ψ by a set of traces L(ψ) such that a system S satisfies ψ iff the set of traces of S is contained in L(ψ).
Rather, one needs to associate with a formula ψ of PROMPT-LTL an infinite family L(ψ) of sets of traces, so that a system S satisfies ψ if traces(S) = L for some L ∈ L(ψ).
This suggests a richer view of linear-time logic than the standard one, which associates a single set of traces with each formula in the logic.
Even in this richer setting, we have the desired feature that two trace-equivalent processes satisfy the same linear-time formulas.
It could be fairly argued that the arguments raised in this paper have been raised before.-We are clearly not the first to advocate trace-based notions of process equivalence.It is, for example, the standard approach in the framework of I/O automata [54,70] (though without much of a discussion).
See also [1].
-Testing equivalence, introduced in [26], is clearly a notion of contextual equivalence.
Their answer to the question, "What is a test?"
, is that a test is any process that can be expressed in the formalism.
So a test is really the counterpart of a context in program equivalence.
(Though our notion of context in Section 4, as a network of transducers, is, a priori, richer.)
At the same time, bisimulation equivalence has been recognized as being too fine a relation to be considered as contextual equivalence [12][13][14]37].
-Furthermore, it has also been shown that many notions of process equivalence studied in the literature, for example, refusal semantics [17], can be obtained as contextual equivalence with respect to appropriately defined notions of directly observable behavior [15,47,55,63].
These notions fall under the title of decorated-trace equivalence, as they all start with trace semantics and then endow it with additional observables.
These notions have the advantage that, like bisimulation equivalence, they are not blind to issues such as deadlock behavior.With respect to the first point, this paper is clearly not addressed to those who believe that the trace-based approach to process equivalence is the correct one.
As we pointed out earlier, this is not the prevailing view in concurrency theory.With respect to the second point, it should be noted that despite the criticisms leveled at it, bisimulation equivalence still enjoys a special place of respect in concurrency theory as a reasonable notion of process equivalence [4,71].
In fact, the close correspondence between bisimulation equivalence and the branching-time logic CTL has been mentioned as an advantage of CTL.
Thus, it is not redundant, in our opinion, to reiterate the point that bisimulation and its variants are not contextual equivalences.With respect to the third point we note that our approach is related, but quite different, than that taken in decorated-trace equivalence.
In the latter approach, the "decoration" of traces is attributed by concurrency theorists.
As there is no unique way to decorate traces, one is left with numerous notions of equivalence and with the attitude quoted above that "It is not the task of process theory to find the 'true' semantics of processes, but rather to determine which process semantics is suitable for which applications" [71].
In our approach, only the modelers know what the relevant aspects of behavior are in their applications and only they can decorate traces appropriately, which led to our Principles of Comprehensive Modeling and Observable I/O.
In our approach, there is only one "right" contextual equivalence, which is trace-based equivalence.Admittedly, the comprehensive-modeling approach is not wholly original, and has been foretold by Brookes [16], who said: "We do not augment traces with extraneous book-keeping information, or impose complex closure conditions.
Instead we incorporate the crucial information about blocking directly in the internal structure of traces. "
Still, we believe that it is valuable to carry Brookes's approach further, substantiate it with our three guiding principles, and demonstrate it in the framework of transducers.An argument that may be leveled at our comprehensive-modeling approach is that it requires a low-level view of systems, one that requires modeling all relevant behavioral aspects.
This issue was raised by Vaandrager in the context of I/O Automata [70].
Our response to this criticism is twofold.
First, if these low-level details (e.g., deadlock behavior) are relevant to the application, then they better be spelled out by the modeler rather than by the concurrency theorist.
As discussed earlier, whether deadlocked termination should be distinguished from normal termination depends on the level of abstraction at which the modeler operates.
It is a pragmatic decision rather than a theoretical decision.
Similar, one could imagine two ways for a process to decline an input; it can block when that input is offered, or it can ignore it.
It is the modeler who should chose which approach is taken, rather than the theorist.
Second, if the distinction between normal termination and deadlocked termination is important to some users but not others, one could imagine language features that would enable explicit modeling of deadlocks when such modeling is desired, but would not force users to apply such explicit modeling.
The underlying semantics of the language, say, in terms of structured operational semantics [42], can expose deadlocked behavior for some language features and not for others.
In other words, Vaandrager's concerns about users being forced to adopt a low-level view should be addressed by designing more flexible languages, and not by introducing new notions of process equivalence.
Note that the alternative to our approach is to accept formalisms for concurrency that are not fully specified and admit a profusion of different notions of process equivalence.We want to emphasize that it is not our position that branching time has no value.
To the contrary, branching-time analysis can be highly useful.
For example, it is known that test trace containment between finite-state processes is PSPACE-complete.
In contrast, testing similarity between finite-state process is in PTIME [44].
This led to a proposal of using simulation as a tractable underapproximation for trace-containment [48].
In fact, for certain models of processes, for example, deterministic transducers, simulation and trace containment coincide.Furthermore, sometime the implementation is obtained from the specification via structural refinement, for example, deriving pipelined architectures from non-pipelined architectures.
In such cases, establishing a structural relationship between implementation and specification is appropriate [19,46,56].
This does not mean that in these cases branching-time semantics is appropriate; rather, it means that branching time can be useful in the "service" of linear time.
(In fact, it was already shown in [1] that structural relations can be used to establish trace containment.)
In conclusion, this paper puts forward an, admittedly provocative, thesis, which is that process-equivalence theory allowed itself to wander in the "wilderness" for lack of accepted guiding principles.
The obvious definition of contextual equivalence was not scrupulously adhered to, and the underspecificity of the formalisms proposed led to too many interpretations of equivalence.
While one may not realistically expect a single paper to overwrite about 30 years of research, a more modest hope would be for this paper to stimulate a lively discussion on the basic principles of process-equivalence theory.
The second author is grateful to E. Clarke, P. Cousot and G. Plotkin for challenging him to consider the semantical aspects of the branching vs. linear-time issue, and to M. Abadi, S. Abramsky, L. Aceto, S. Brookes, K. Cooper, W. Fokkink, O. Grumberg, J. Halpern, C.A.R. Hoare, R. Milner, P. Panagaden, A. Pitts, G. Plotkin, A. Pnueli, and W. Taha for discussions and comments on this topic.
