A general mature rule-based MT system is bound to reach a saturation point because of the intrinsic complexity of the natural language description.
For such systems, maintenance is a complex task and customization is expensive and time-consuming.
Therefore, improving the system's interaction with the linguistic rules has proven to be more productive than endlessly adding new rules and exceptions to reach the theoretical accuracy level of 100%.
In this paper , we describe our strategy to open up such a system and provide practical details on how this was done on SYSTRAN's classical engines.
This approach is the foundation of the SYSTRAN version 5 translation engines.
We show the immediate benets of the evolution of our architecture and the new extension potentiality.
The XML workow described in the previous and to re-inject the modied syntax tree into the translation engine (see section 3.3).
The linguistic rules in SYSTRAN's classical approach are written directly in C, at a very low level.
This makes them very powerful since they have full control over the linguistic procedures.However, the visibility is low and the learning curve is very steep.Ideally, everything should be described in a higher level formalism, easily accessible to linguists.
The linguists should not have to deal with implementation details that are not related to linguistics.
This is the main concept of NG.Given the amount of rules available in the system, and also the way they work, it is very hard to create this formalism.
Covering them with a declarative approach would mean re-inventing a kind of programming language that would not necessarily be easier to work with.
Also, the time needed for such a conversion is a considerable investment.
Therefore, as a compromise, new rules may be written declaratively, while keeping the available rules as they are.The formalism for these rules is easy to use and will eventually replace the classical approach.
In the meantime, it does however give a possibility for additional development.
This is possible using the common data structure for the syntagm structure described in the previous section.Example of a simple declarative rule:<Rule id="NP11" confidence="0.
plural is set, it should not keep the attribute singular if that was set by default.
In Figure 1 Simplest transitions are letters but the following special operators can also be used:• character properties operators (for instance translation memory takes into account characters properties for selecting best match)• Unicode operators -generic Unicode regular expression (level 1)• XPath operators on the complete sentence • predened lookup operators (chemical compounds, numbers, date. . . )• sub-matching: possibility of calling recursively a sub-graph as a part of the current entry.
This features allows for representation of local grammars as described in (Gross, 1997) • any request on the current XML node (containing information accumulated during the process)Any lookup performed by any module can have access to this whole set of lookup tools this means that even simple dictionary entries have access to those complex operators for restricting/extending matching conditions.In addition, the automaton can be combined on the y with lookup rules.
These lookup rules are also described using a nite state transducer and describe the possible variants allowed during the lookup.
These variants can be associated to a matching cost.
Figure 5 represents such a transducer for some basic spell-checking rules.
In this section, we illustrate on three simple examples, how the new architecture integrating classical translation engines allow to eciently improve translation quality and interact with existing rule set.
One simple example of the immediate outcome of the architecture as described above is the linguistic improvement coming from the simplication of the input.
For instance, it is possible to introduce a module in the workow special- In the case the user wants to modify system choice, the user choice is posted in the XML workow, and this information will be used by the homography resolution routine as a priority rule.
Figure 6 shows user review and selection of homography resolution.
On the same model, any system choice can be published and manually modied through user interaction.
Using the permanent synchronization between the classical analysis area and the high level tree representation, and by dening appropriate hooks in the linguistic workow, it is possible to add modules that independently modify the analysis of the sentence or add new transfer patterns before giving the control back to the existing workow.
Hence, adding special linguistic descriptions specic to a customized domain or modifying dynamically normal system choices is fully possible.For instance, one possible use of this extension possibility that we are currently working on, is to use statistical methods to validate and also extract new rules using corpus.
Conclusions and Outlook To complete this architecture, the current development focal points are:• Improving the value of existing rules by associating ponderation to each of them.Today it is possible to know the system's choices and to modify them.
The next step is for us to know the system's hesitations.In a post-editing workow, the reviewer would be able to focus on certain areas of the translation output, which would yield to higher productivity.
The same ponderation can be used to calculate the global condence level for the complete sentence translation, or can be used to decide that some decision should not be taken, and that the dierent possibilities be analyzed in parallel.
• Continue the modularization eort on the linguistic code in order to obtain smaller agents.
This will reduce the time required to generate new language pairs, and will enable a deeper interaction with the existing set of rules.
