In this paper, we design a real-time Java Remote Method Invocation (RMI).
Real-time timing constraints are preserved in a server centric fashion where Java RMI servers keep information for real-time guarantees.
Remote method invocations are modeled as sporadic events and so treated by a Total Bandwidth server, a guaranteed-rate scheduler.
The replenishment period of the Total Bandwidth server is determined probabilistically.
According to our measurements , the overhead we added for implementing real-time capabilities is negligible and the latency of real-time RMI is very stable and predictable.
A number of efforts have extended component-based systems to support real-time applications, for example with means to specify any real-time properties such as worstcase execution times and deadlines of services.
The TAO project [15] has implemented a CORBA that preserves the priority levels of calls across component boundaries.
Stankovic et al. [17] have proposed an approach for building embedded systems software through component-based techniques.
Their VEST toolkit provides a rich set of dependency checks to support distributed embedded system development via components.
The specification for realtime CORBA has also been proposed by an OMG working group [16].
The real-time CORBA specification extends standard CORBA with features for management of CPU, network, and memory resources.
It allows to use either server declared or client propagated model for fixed priority scheduling between client and server.
All these real-time extensions provide very limited isolation across components in the temporal domain: TAO, for example, relies on static priority scheduling with priority inheritance across components.
The temporal behavior of individual components therefore depends on the behavior of other components, specifically on that of higher-priority ones.
Due to the priority inheritance, it depends on the execution of remote components as well, for example when a remote high-priority component triggers the execution of methods provided by another local component.In this work we use a server-centric approach for scheduling real-time Java RMI [19].
That enables the isolation of the components from clients in terms of guaranteeing real-time properties of the exported services of the components.
The server-centric approach adopts component declared real-time property model instead of client propagated real-time property model for the exported services:The components keep the information of real-time properties for the exported services rather than inheriting those from clients in the component declared real-time property model.
As a result, clients cannot affect how the workload is executed on the component, and so temporal component isolation is provided.This paper is organized as follows.
In Section 2, we briefly discuss related work.
Our system model is described in Section 3, followed by design details in Section 4.
The evaluation is provided in Section 5.
Conclusions are in Section 6.
The Real-Time Specification for Java (RTSJ) [3] extends The Java Language Specification [7] and The Java Virtual Machine Specification [10] and provides application programming interfaces for real-time capabilities.
The RTSJ, coupled with a real-time operating system, leverages the capability of Java for developing real-time systems in the sense that it separates hard real-time, soft real-time and non-real-time threads.
The RTSJ Reference Implementation (RI) from TimeSys [20] and jRate [6] have implemented the RTSJ.However, both the RTSJ and its implementations do not support real-time capabilities for Java RMI.
There have been several efforts for integrating the RTSJ with the Java RMI mechanism, for example Jensen [9], Clark et al. [5], and Wellings et al. [21].
Jensen [9] has proposed the Distributed Real-Time Specification for Java (DRTSJ).
The DRTSJ addresses predictability of end-to-end timeliness in dynamic distributed real-time systems.
In distributed realtime computing systems, end-to-end timing constraints can be maintained over multi-node applications under each node's current environment.
The DRTSJ has been designed for general cases of dynamic distributed real-time computing systems.
Therefore, it is not easy to know each node's current environment a priori, such as latency properties of OS and network infrastructure, and system resource utilization.
To achieve end-to-end multi-node timeliness, the properties of each multi-node application behavior's timeliness need to be propagated to the resource managers of the OS and the Java Virtual Machine (VM) [10] on each node.The DRTSJ suggests three ways to integrate Java RMI with the RTSJ: based on changes to the RTSJ and Java RMI.
The first approach does not expect timely delivery of messages and inheritance of scheduling parameters between real-time Java threads and remote objects.
It therefore suggests no changes to the RTSJ and Java RMI.
The second approach expects timely delivery of messages and inheritance of scheduling parameters between realtime Java threads and real-time remote objects.
It therefore suggests extensions required to Java RMI but no extensions required to the RTSJ or the real-time Java VM.
The third approach suggests extensions required to Java RMI, the RTSJ and the real-time Java VM to support distributed thread functionality.
In distributed thread models, a distributed thread has a system-wide ID and the feature of transparent propagation of its properties along its execution environments.
While the last approach can be considered an ultimate solution, due to the practical difficulty of realization, attention has been paid to the second approach.
For example, Borg et al. [4], following the second, proposed a framework to support real-time RMI.
All these approaches are, however, still based on a client propagated real-time property model.
Our approach, designed in a server-centric fashion, supports temporal isolation of realtime Java RMI server components.
Since Remote method invocations are modeled sporadic events and treated by a Total Bandwidth server the latency of real-time RMI is stable and predictable.time units to execute on a reference host, takes We assume that remote methods are invoked synchronously: The execution on the caller is temporarily suspended while the thread of control transfers to the component with the remote method.
Upon completion of the remote invocation, the thread of control migrates back to the caller, which in turn resumes execution.
We provide realtime guarantees in form of deadline guarantees to remote method invocations.
We say that we guarantee a deadline 5 to a task 6 if we guarantee that every job is completed by at most 5 time units after it has been invoked.
In other words, the maximum response time of the remote method is bounded by 5 .
This can be provided by appropriate timing isolation.
By timing isolation we mean that the worst-case response time of jobs in a task does not depend on the processortime demands of other tasks.
To provide timing isolation at scheduling level, one can use guaranteed-rate schedulers.
Examples of such algorithms are the Constant Utilization Server, the Total Bandwidth Server, and the Preemptive Weighted Fair-queueing Server [11].
We have chosen the Total Bandwidth Server for our guaranteed-rate scheduling over the other two for two reasons: (1) The Total Bandwidth Server outperforms the Constant Utilization Server in terms of utilizing background time not used by periodic tasks.
(2) The proportional share scheduling algorithms, such as the Preemptive Weighted Fair-queueing Server, make no QoS guarantees if the sum of total weights grows very large [12].
We expect task invocations to be very bursty in the system we envision, for three reasons: First, any task may consist of invocations from more than one client, thus resulting naturally in a bursty invocation pattern.
Second, no explicit policing mechanism exists to shield the system from bursty invocations.
Third, even if invocations from clients were periodic, cascaded invocations to subsequent components would still be jittered by execution and scheduling, and so would be bursty.
As a result, we model task arrival as sporadic: The detailed arrival time of the nest invocation is unknown a priori, but worst-case execution time and deadline become known upon arrival.
The invoked jobs of the sporadic task are scheduled by using a Total Bandwidth Server.
Specifically, a Total Bandwidth Server is configured for each remote method of every component.
Every Total Bandwidth Server then allocates and controls the amount of CPU time that is consumed for execution of the assigned remote method on the component.
As a side effect, it shapes the service interval between successive jobs that invoke the same remote method of the same component.
This allows for a simple, utilization-based, admission control for both types of tasks.The response time of each job 7 of Task 6 is what the client experiences as latency.
If we do not take into ac- .
If a guaranteed-rate scheduler (in the following we limit the presentation to the Total Bandwidth Server) handles the jobs for a given component, and if appropriate admission control ensures that the server is not overloaded, then the relative deadline of Job can be guaranteed to meet its deadline through appropriate admission control.
The following shows how our workload models look like.
Table 1 describes the notations used for our workload models.
, and it also invokes one or more other single-chained remote methods on one or more other components.
By single-chained remote method we mean that the execution of the remote method invokes only local methods.
In this case, the workload of Job and the maximum response time for getting the result from each single-chained remote method.
Therefore, the workload of this kind of Job 7 is calculated by the following: ¢ £ § ¦ ¥ § § ¦ ¨ £ § " § ¦ ¢ ¤ £ © ¥ § § ¦ ¨ £ § " # § ¦ % $ & © ' ¥ ) ( 0 ¨ £ ) ( 2 1 Before new components are created and installed, an admission control step has to make sure that sufficient computing resources on the host can be allocated to the remote methods of the new component without affecting other components on the host.
For this, worst-case execution times of remote methods are determined either during system design or system configuration.
Similarly, the utilizations allocated to components and their remote methods are defined during system configuration.
We identified three issues that must be addressed when realizing a real-time capable Java RMI System.
First, the export of a remote object involves creating a number of Java threads.
One of those threads listens for incoming calls to the exported remote object.
The others are worker threads for handling each accepted incoming request separately.
To guarantee real-time properties, the Java VM must support real-time capable threads.
Second, clients must be able to propagate real-time timing constraints to the remote object.
This object may in turn invoke remote methods on other remote objects in different Java VMs, thus act as client to other remote objects.
Finally, we consider open systems, where we have no control over number and behavior of clients.
As a result, invocations can arbitrarily be bursty, due either to relative phasing of client requests, or to the invocation pattern of single clients.
One of the features of client arrivals should be aperiodic.
There may be bursty arrivals of clients as well.
In the following sections, we propose our solutions to the three issues listed above.
We adopt an early version of TimeSys RTSJ RI for our implementation base 1 .
Due to the limited space, however, detailed design of Java classes is not shown in this paper.
Whenever an incoming call arrives, the listening thread creates a real-time worker thread for handling the request from the incoming call.
The real-time worker thread executes the run() method of class ConnectionHandler.
In order to maintain a high responsiveness to incoming requests, we design three types of real-time threads, which differ by their priorities: (1) Worker threads execute the remote method invocations at their assigned priorities.
(2) The EDF scheduling thread handles worker threads, and runs at a priority higher than all worker threads.
(3) The listening thread runs at priority higher than both worker threads and EDF scheduler.
In this way, the listening thread executes like an interrupt service routine, which is very short and provides system responsiveness by executing at highest priority.
Threads Based on Admitted Utilization During the invocation of an exported remote method on the server side, a real-time worker thread dispatches an up-call to the remote object.
At this time, we get the object reference of the remote object and the name of the target method.
Our local admission control component provides the information about the workload and utilization of the target method.
By server-centric we mean that the real-time server components keep information for meeting real-time guarantees instead of delivering and inheriting the scheduling and release parameters of the server components between clients and themselves.
According to our task model, those timing constraints are defined as workload, deadline and utilization of each remote method of an exported remote object.
The main reason why we choose the server-centric approach is to provide component isolation, which in turn greatly simplifies the admission control needed for component creation and remote method invocation.
We use an utilization-based admission control to guarantee real-time properties of remote method invocation.
By utilizationbased admission control we mean that total utilization reserved for each method should be available at the candidate host for remote invocations.
The server-centric approach also reduces the overhead of remote invocations, as there is no need to exchange timing information as part of the remote invocation at run-time.
The Total Bandwidth Server The Total Bandwidth Server is a periodic server and is defined by two rules, consumption and replenishment rules.
In this section we follow J. Liu [11] to describe the operation of the Total Bandwidth Server.
Initially, our Total Bandwidth Server sets the server's execution budget¢ ¡ ¤ £ ¦ ¥ ¨ § ©and deadline of the server5 § ! "
£ ¨ $ # & % § ¦ 'to zero.
When a sporadic job with execution time( 0 ) 1 § !
2 3 ¡ 4 © # 5 !
% 6 # £ § 7 6 9 8 § (arrives at a time t to a job queue with no backlogged jobs, our Total Bandwidth Server sets5 § !
£ ¨ @ # A % § ¦ to (max( 5 - § !
£ ¨ @ # A % § 7 , t) + ( 0 ) 1 § !
2 3 ¡ 4 © # 5 !
% 6 # £ § !
6 9 8 § ( / © © #¨$ #¨$ # B " © # - 5 !
% ) and ¢ ¡ ¤ £ ¦ ¥ ¨ § © C equal to ( 0 ) 4 § 2 ¡ 1 © # 5 !
% 6 # £ - §6 D 8 § (.
When the current sporadic job of the server finishes, and if the server is backlogged, our Total Bandwidth Server sets5 § !
£ ¨ @ # & % § 'to ( evaluates the status of all instances of class javax.realtime.RealtimeThread.
There are several requests from instances of class javax.realtime.RealtimeThread for putting their operating system threads into desired operating systems' states, such as start, stop, resume, sleep and suspend.
The EDF scheduler also examines whether or not any instance of class javax.realtime.RealtimeThread missed its deadline and whether or not the operating system thread of an ongoing instance of class javax.realtime.RealtimeThread is alive.
Bandwidth Servers Each Total Bandwidth Server is characterized by the two parameters: the maximum budget and the replenishment period.
While the maximum budget can be established by an execution-time analysis of the remote methods, it is difficult to choose an optimal replenishment period of the Total Bandwidth Server.If we assume that inter-arrival times of client requests for each remote method are distributed based on a given distribution function, we have two options for deciding the replenishment period: One option is to use the minimum inter-arrival time of invocations as the replenishment period.
This approach is not applicable to open systems, where little is known about the client population.
Setting the invocation period short enough to handle the bursty arrivals caused by bursty client invocations and by phasing of invocations from multiple clients would lead to unacceptably low utilization of host resources.
Alternatively, one can take probabilistic approach.
In this approach, each Total Bandwidth Server is modeled as a G/D/1 queue [1].
Client requests arrive in the queue with a randomly distributed arrival time, and the Total Bandwidth Server allows for execution of the requested remote method for the given maximum budget time units in each period of the Total Bandwidth Server.
, we can have" !
¡ £ " ) # © % $ £ $ ¥ & !
¡ ' £ ( ¥1 # " § ), after some manipulation.As £ £ " § B D 4 Q ¡6 F I H P F 8 ' 9 0 £ £ " § B D 4 Q ¡6The transition probability matrix T looks like the following:e f f f f f f f f f f g E i h p r q S s u t p E i h p v q w s y x   y t p E i h p r q S s  x S   t p E i h p r q S s  x w w t p   t s     t s t s  x   t s y x w   t s     t s     t s t s y x    t s    t s     t s     t s  t s     t s    t s     t s   S       t        t                      Again, we can get the state probability matrix 3, where e f f g DR4" 6 D ¡ 4 " 6 D £ 4 " 6 ¥    e f f g E F ' H # ` ' ¥ ¥ ¥ ` # ¡ ¥ ¥ ¥ ¥ ¥ ¥ ¥ ¥ ¥ ¥ ¥    ' e f f g DR4 ¡6 D ¡ 4 ¡6 D £ 4 ¡6 ¥   Other models of the inter-arrival will produce a similar matrix of probability.
In this probabilistic approach, we can get an optimal period of a Total Bandwidth Server, § , which maximizes the value ofD  R4 & 6with a given distribution function of inter-arrival times of client requests and the worst-case execution time of each remote method.
Finally, the utilization of each remote method can be defined by dividing the maximum budget by the replenishment period § of the Total Bandwidth Server for each remote method.
Given these parameters, the Total Bandwidth Server is fully defined.
In this section, we evaluate the real-time capabilities of the extensions to Java RMI described in the previous sections.
First, the average and standard deviation of execution times of a local method are measured on five different Java Virtual Machines (VMs).
This experiment illustrates the level at which each Java VM guarantees predictable execution times for local methods.
We also use the same local method as a target method for upcalls requested by RMI clients throughout the experiments of this section.
In this way, we can later determine the net average overhead of remote method invocations in addition to the execution time of the local method.
In a second step, we measure latency of the remote method invocations.
This experiment evaluates whether or not our methodology provides predictable latency for a real-time RMI server in the presence of heavily CPU-bound tasks.
Finally, we evaluate the performance of the EDF job scheduler and the Total Bandwidth Server that ensure predictable execution times for both periodic and sporadic real-time tasks.
In order to focus on real-time performance we use the simple configuration depicted in Figure 1, where a network analyzer is directly connected between two hosts (Dell Dimension 4100 Pentium III 933 MHz with memory of 256 Megabytes).
We use a Fast Ethernet that supports 100 Mbps.
We also use an Agilent Technologies Network Analyzer that has nanosecond timer resolution and Windows 2000 Pro Embedded with two CPUs.
For comparison of local execution time, we have used TimeSys 3.1 Real-Time version for OS and five Java VMs: JDK 2 1.3.0-classic VM, JDK 1.3.0-interpreted mode, JDK 1.3.0-mixed mode [18], TimeSys Real-Time Specification for Java Reference Implementation (RTSJ RI) [20], and TAMU RTSJ RI with Real-Time Remote Method Invocation (RT-RMI), that is, our implementation.
Figure 2 shows the average execution time of a local method for each Java VM.
This was measured on the server (Dell Dimension 4100 Pentium III 933 MHz with memory of 256 Megabytes).
As can be seen, all JDK versions take less time to execute the local method than the TimeSys RTSJ RI.
TimeSys RTSJ RI takes approximately six times longer than JDK 1.3.0-mixed mode.
This is because the TimeSys version is 1) targeted toward real-time execution, thus does not contain many optimizations that optimize performance, and 2) is a very preliminary implementation.
Because we use an early version of TimeSys RTSJ RI as base to implement TAMU RTSJ RI with RT-RMI, our implementation inherits the overhead of the TimeSys version.
Importantly, however, as shown in Figure 2, the overhead of adding RT-RMI to our implementation is negligible.
In this experiment, the real-time Java RMI performance is measured in terms of averages of the latencies of periodic remote method invocations.
We show the latency of remote method invocation by measuring the time difference between the moment of client's sending of the first packet of the RMI request and the moment of server's sending of the last packet of the result.
The Agilent Technologies network analyzer captures all packets on the link between the server and the client.
We use Ethereal in order to extract timing information from the captured packets by using a refined data display for the RMI protocol.
The use of the network analyzer allows our measurements not to perturb the execution of the RMI server.
For periodic job arrivals multi-threaded client application generates remote method invocations to the server.
Java VM Running One RMI Server and High Background Load We run two non-real-time Java applications that compress big size of files on the RMI server's Java VM to generate a high background load.
Figure 3 shows the latency of remote method invocations on three Java VMs: JDK 1.3.0-interpreted mode, JDK 1.3.0-mixed mode, and TAMU RTSJ RI with RT-RMI.
As can be seen, JDK 1.3.0-interpreted and mixed modes show unusual high latencies.
It apparently shows sporadic long latencies of JDK 1.3.0-interpreted and mixed modes while TAMU RTSJ RI with RT-RMI shows very predictable latency.
TAMU RTSJ RI with RT-RMI, the top line, has larger average latency than those of two JDK 1.3.0 modes.
Again, however, as can be recalled from Figure 2, the average latency of TAMU RTSJ RI with RT-RMI for executing remote methods is inherited from the early version of TimeSys RTSJ RI.
Figure 4 shows the decomposition of standard deviation of RMI latency.
As can be seen, large portion of the deviations are due to RMI protocol handling in non-TAMU JDK versions.
Conversely, this figure also clearly demonstrates that our RT-RMI implementation (i.e., addition of real-time worker thread management and Total Bandwidth Server) greatly increases RMI predictability.
This result demonstrates that TAMU version clearly supports real-time capability while the other two versions do not.
Amount of Background Load Figure 5 shows the comparison of average and standard deviation of the RMI server's latencies in server execution environments where other workloads run together.
The RMI server consumes 22% of CPU utilization.
In Figure 5 each label in horizontal axis stands for the following.
"None": there is no other workload in the server VM except the RMI server.
"BG-25": one background Java thread is running in the RMI server's VM, which consumes 25% of CPU utilization.
It is not under control of our EDF scheduler for experiment purposes.
"Two RT-10s": two real-time Java threads are running in the RMI server's VM.
Each thread performs CPU-bound computations periodically and consumes 10% Figure 5.
RMI Latency with Varying Amount of Background Load of the RMI server's latencies increases very slightly as the workload of a real-time Java thread increases.
For example, there is an increase of only 3.68% in average latency of the RMI server when a real-time Java thread consumes 60% of CPU utilization in the RMI server's VM.
In addition, Fig- ure 6 shows the decomposition of the RMI server's latencies of the same experiment with Figure 5.
As can be seen in Figure 6, the averages of the RMI latencies both for invoked method and RMI protocol handling vary little when the workloads of other tasks that run on the RMI server's VM change widely.
This result demonstrates that TAMU RTSJ RI with RT-RMI provides predictable latency of remote method invocations even in conditions with varying amount of background load.
RMI protocol handling invoked method Latency (millisecs) no workload 25% of CPU utilization for a background process 20% of CPU utilization for two real-time Java threads 10% of CPU utilization for a real-time Java thread 20% of CPU utilization for a real-time Java thread 30% of CPU utilization for a real-time Java thread 40% of CPU utilization for a real-time Java thread 50% of CPU utilization for a real-time Java thread 60% of CPU utilization for a real-time Java thread Figure 6.
Decomposition of RMI Latency with Varying Amount of Background Load In this paper, we designed and implemented a realtime Java Remote Method Invocation (RMI).
By using a server centric approach and a Total Bandwidth server, we achieved efficient and effective real-time guarantees for Java RMI applications.
We believe that this work is an important and interesting step toward distributed real-time systems, a grand goal of the real-time research community.
