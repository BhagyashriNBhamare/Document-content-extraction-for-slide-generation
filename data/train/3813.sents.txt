Garbled circuits provide a powerful tool for jointly evaluating functions while preserving the privacy of each user's inputs.
While recent research has made the use of this primitive more practical, such solutions generally assume that participants are symmetrically provisioned with massive computing resources.
In reality, most people on the planet only have access to the comparatively sparse computational resources associated with their mobile phones, and those willing and able to pay for access to public cloud computing infrastructure cannot be assured that their data will remain unexposed.
We address this problem by creating a new SFE protocol that allows mobile devices to securely outsource the majority of computation required to evaluate a garbled circuit.
Our protocol, which builds on the most efficient garbled circuit evaluation techniques, includes a new out-sourced oblivious transfer primitive that requires significantly less bandwidth and computation than standard OT primitives and outsourced input validation techniques that force the cloud to prove that it is executing all protocols correctly.
After showing that our extensions are secure in the malicious model, we conduct an extensive performance evaluation for a number of standard SFE test applications as well as a privacy-preserving navigation application designed specifically for the mobile use-case.
Our system reduces execution time by 98.92% and bandwidth by 99.95% for the edit distance problem of size 128 compared to non-outsourced evaluation.
These results show that even the least capable devices are capable of evaluating some of the largest garbled circuits generated for any platform.
Secure Function Evaluation (SFE) allows two parties to compute the result of a function without either side having to expose their potentially sensitive inputs to the other.
While considered a generally theoretical curiosity even after the discovery of Yao's garbled circuit [43], recent advances in this space have made such computation increasingly practical.
Today, functions as complex as AES-128 and approaching one billion gates in size are possible at reasonable throughputs, even in the presence of a malicious adversary.While recent research has made the constructions in this space appreciably more performant, the majority of related work makes a crucial assumption -that both parties are symmetrically provisioned with massive computing resources.
For instance, Kreuter et al. [25] rely on the Ranger cluster at the Texas Advanced Computing Center to compute their results using 512 cores.
In reality, the extent of a user's computing power may be their mobile phone, which has many orders of magnitude less computational ability.
Moreover, even with access to a public compute cloud such as Amazon EC2 or Windows Azure, the sensitive nature of the user's data and the history of data leakage from cloud services [40,42] prevent the direct porting of known SFE techniques.In this paper, we develop mechanisms for the secure outsourcing of SFE computation from constrained devices to more capable infrastructure.
Our protocol maintains the privacy of both participant's inputs and outputs while significantly reducing the computation and network overhead required by the mobile device for garbled circuit evaluation.
We develop a number of extensions to allow the mobile device to check for malicious behavior from the circuit generator or the cloud and a novel Outsourced Oblivious Transfer for sending garbled input data to the cloud.
We then implement the new protocol on a commodity mobile device and reasonably provisioned servers and demonstrate significant performance improvements over evaluating garbled circuits directly on the mobile device.We make the following contributions:• Outsourced oblivious transfer & outsourced consistency checks: Instead of blindly trusting the cloud with sensitive inputs, we develop a highly efficient Outsourced Oblivious Transfer primitive that allows mobile devices to securely delegate the majority of computation associated with oblivious transfers.
We also provide mechanisms to outsource consistency checks to prevent a malicious circuit generator from providing corrupt garbled values.
These checks are designed in such a way that the computational load is almost exclusively on the cloud, but cannot be forged by a malicious or "lazy" cloud.
We demonstrate that both of our additions are secure in the malicious model as defined by Kamara et al. [21].
• Performance Analysis: Extending upon the implementation by Kreuter et al. [25], we conduct an extensive performance analysis against a number of simple applications (e.g., edit distance) and cryptographic benchmarks (e.g., AES-128).
Our results show that outsourcing SFE provides improvements to both execution time and bandwidth overhead.
For the edit distance problem of size 128, we reduce execution time by 98.92% and bandwidth by 99.95% compared to direct execution without outsourcing on the mobile device.
• Privacy Preserving Navigation App: To demonstrate the practical need for our techniques, we design and implement an outsourced version of Dijkstra's shortest path algorithm as part of a Navigation mobile app.
Our app provides directions for a Presidential motorcade without exposing its location, destination, or known hazards that should be avoided (but remain secret should the mobile device be compromised).
The optimized circuits generated for this app represent the largest circuits evaluated to date.
Without our outsourcing techniques, such an application is far too processor, memory and bandwidth intensive for any mobile phone.
While this work is similar in function and provides equivalent security guarantees to the Salus protocols recently developed by Kamara et al. [21], our approach is dramatically different.
The Salus protocol framework builds their scheme on a completely different assumption, specifically, that they are outsourcing work from low-computation devices with high communication bandwidth.
With provider-imposed bandwidth caps and relatively slow and unreliable cellular data connections, this is not a realistic assumption when developing solutions in the mobile environment.
Moreover, rather than providing a proof-of-concept work demonstrating that offloading computation is possible, this work seeks to develop and thoroughly demonstrate the practical potential for evaluating large garbled circuits in a resourceconstrained mobile environment.The remainder of this work is organized as follows: Section 2 presents important related work and discusses how this paper differs from Salus; Section 3 provides cryptographic assumptions and definitions; Section 4 formally describes our protocols; Section 5 provides security discussion -we direct readers to our technical report [6] for full security proofs; Section 6 shows the results of our extensive performance analysis; Section 7 presents our privacy preserving navigation application for mobile phones; and Section 8 provides concluding remarks.
Beginning with Fairplay [32], several secure two-party computation implementations and applications have been developed using Yao garbled circuits [43] in the semi-honest adversarial model [3,15,17,19,26,28,31,38].
However, a malicious party using corrupted inputs or circuits can learn more information about the other party's inputs in these constructions [23].
To resolve these issues, new protocols have been developed to achieve security in the malicious model, using cut-andchoose constructions [30], input commitments [41], and other various techniques [22,34].
To improve the performance of these schemes in both the malicious and semihonest adversarial models, a number of circuit optimization techniques have also been developed to reduce the cost of generating and evaluating circuits [8,11,24,35].
Kreuter et al. [25] combined several of these techniques into a general garbled circuit protocol that is secure in the malicious model and can efficiently evaluate circuits on the order of billions of gates using parallelized serverclass machines.
This SFE protocol is currently the most efficient implementation that is fully secure in the malicious model.
(The dual execution construction by Huang et al. leaks one bit of input [16].)
Garbled circuit protocols rely on oblivious transfer schemes to exchange certain private values.
While several OT schemes of various efficiencies have been developed [1,30,36,39], Ishai et al. demonstrated that any of these schemes can be extended to reduce k c oblivious transfers to k oblivious transfers for any given constant c [18].
Using this extension, exchanging potentially large inputs to garbled circuits became much less costly in terms of cryptographic operations and network overhead.
Even with this drastic improvement in efficiency, oblivious transfers still tend to be a costly step in evaluating garbled circuits.Currently, the performance of garbled circuit protocols executed directly on mobile devices has been shown to be feasible only for small circuits in the semi-honest adversarial model [5,13].
While outsourcing general computation to the cloud has been widely considered for improving the efficiency of applications running on mobile devices, the concept has yet to be widely applied to cryp-tographic constructions.
Green et al. began exploring this idea by outsourcing the costly decryption of ABE ciphertexts to server-class machines while still maintaining data privacy [12].
Considering the costs of exchanging inputs and evaluating garbled circuits securely, an outsourcing technique would be useful in allowing limited capability devices to execute SFE protocols.
Naor et al. [37] develop an oblivious transfer technique that sends the chooser's private selections to a third party, termed a proxy.
While this idea is applied to a limited application in their work, it could be leveraged more generally into existing garbled circuit protocols.
Our work develops a novel extension to this technique to construct a garbled circuit evaluation protocol that securely outsources computation to the cloud.In work performed concurrently and independently from our technique, Kamara et al. recently developed two protocols for outsourcing secure multiparty computation to the cloud in their Salus system [21].
While their work achieves similar functionality to ours, we distinguish our work in the following ways: first, their protocol is constructed with the assumption that they are outsourcing work from devices with low-computation but highbandwidth capabilities.
With cellular providers imposing bandwidth caps on customers and cellular data networks providing highly limited data transmission speed, we construct our protocol without this assumption using completely different cryptographic constructions.
Second, their work focuses on demonstrating outsourced SFE as a proof-of-concept.
Our work offers a rigorous performance analysis on mobile devices, and outlines a practical application that allows a mobile device to participate in the evaluation of garbled circuits that are orders of magnitude larger than those evaluated in the Salus system.
Finally, their protocol that is secure in the malicious model requires that all parties share a secret key, which must be generated in a secure fashion before the protocol can be executed.
Our protocol does not require any shared information prior to running the protocol, reducing the overhead of performing a multiparty fair coin tossing protocol a priori.
While our work currently considers only the two-party model, by not requiring a preliminary multiparty fair coin toss, expanding our protocol to more parties will not incur the same expense as scaling such a protocol to a large number of participants.
To properly compare security guarantees, we apply their security definitions in our analysis.
To construct a secure scheme for outsourcing garbled circuit evaluation, some new assumptions must be considered in addition to the standard security measures taken in a two-party secure computation.
In this section, we discuss the intuition and practicality of assuming a noncolluding cloud, and we outline our extensions on standard techniques for preventing malicious behavior when evaluating garbled circuits.
Finally, we conclude the section with formal definitions of security.
Throughout our protocol, we assume that none of the parties involved will ever collude with the cloud.
This requirement is based in theoretical bounds on the efficiency of garbled circuit evaluation and represents a realistic adversarial model.
The fact that theoretical limitations exist when considering collusion in secure multiparty computation has been known and studied for many years [2,7,27], and other schemes considering secure computation with multiple parties require similar restrictions on who and how many parties may collude while preserving security [4,9,10,20,21].
Kamara et al. [21] observe that if an outsourcing protocol is secure when both the party generating the circuit and the cloud evaluating the circuit are malicious and colluding, this implies a secure two-party scheme where one party has sub-linear work with respect to the size of the circuit, which is currently only possible with fully homomorphic encryption.
However, making the assumption that the cloud will not collude with the participating parties makes outsourcing securely a theoretical possibility.
In reality, many cloud providers such as Amazon or Microsoft would not allow outside parties to control or affect computation within their cloud system for reasons of trust and to preserve a professional reputation.
In spite of this assumption, we cannot assume the cloud will always be semi-honest.
For example, our protocol requires a number of consistency checks to be performed by the cloud that ensure the participants are not behaving maliciously.
Without mechanisms to force the cloud to make these checks, a "lazy" cloud provider could save resources by simply returning that all checks verified without actually performing them.
Thus, our adversarial model encompasses a non-colluding but potentially malicious cloud provider that is hosting the outsourced computation.
When running garbled circuit based secure multiparty computation in the malicious model, a number of welldocumented attacks exist.
We address here how our system counters each.
Malicious circuit generation: In the original Yao garbled circuit construction, a malicious generator can garble a circuit to evaluate a function f 񮽙 that is not the function f agreed upon by both parties and could compromise the security of the evaluator's input.
To counter this, we employ an extension of the random seed technique developed by Goyal et al. [11] and implemented by Kreuter et al. [25].
Essentially, the technique uses a cut-and-choose, where the generator commits to a set of circuits that all presumably compute the same function.
The parties then use a fair coin toss to select some of the circuits to be evaluated and some that will be re-generated and hashed by the cloud given the random seeds used to generate them initially.
The evaluating party then inspects the circuit commitments and compares them to the hash of the regenerated circuits to verify that all the check circuits were generated properly.Selective failure attack: If, when the generator is sending the evaluator's garbled inputs during the oblivious transfer, he lets the evaluator choose between a valid garbled input bit and a corrupted garbled input, the evaluator's ability to complete the circuit evaluation will reveal to the generator which input bit was used.
To prevent this attack, we use the input encoding technique from Lindell and Pinkas [29], which lets the evaluator encode her input in such a way that a selective failure of the circuit reveals nothing about the actual input value.
To prevent the generator from swapping garbled wire values, we use a commitment technique employed by Kreuter et al. [25].
Input consistency: Since multiple circuits are evaluated to ensure that a majority of circuits are correct, it is possible for either party to input different inputs to different evaluation circuits, which could reveal information about the other party's inputs.
To keep the evaluator's inputs consistent, we again use the technique from Lindell and Pinkas [29], which sends all garbled inputs for every evaluation circuit in one oblivious transfer execution.
To keep the generator's inputs consistent, we use the malleable claw-free collection construction of shelat and Shen [41].
This technique is described in further detail in Section 4.
Output consistency: When evaluating a two-output function, we ensure that outputs of both parties are kept private from the cloud using an extension of the technique developed by Kiraz [23].
The outputs of both parties are XORed with random strings within the garbled circuit, and the cloud uses a witness-indistinguishable zero-knowledge proof as in the implementation by Kreuter et al. [25].
This allows the cloud to choose a majority output value without learning either party's output or undetectably tampering with the output.
At the same time, the witness-indistinguishable proofs prevent either party from learning the index of the majority circuit.
This prevents the generator from learning anything by knowing which circuit evaluated to the majority output value.
To prevent the generating party from providing different inputs for each evaluation circuit, we implement the malleable claw-free collections technique developed by shelat and Shen [41].
Their construction essentially allows the generating party to prove that all of the garbled input values were generated by exactly one function in a function pair, while the ability to find an element that is generated by both functions implies that the generator can find a claw.
It is composed of a four-tuple ofalgorithms (G, D, F, R),where G is the index selection algorithm for selecting a specific function pair, D is an algorithm for sampling from the domain of the function pair, F is the algorithm for evaluating the functions in the pair (in which it should be difficult to find a claw), and R is the "malleability" function.
The function R maps elements from the domain of F to the range of F such that for b ∈ {0, 1}, any I in the range of G, and any m 1 , m 2 in the domain of F, we have for the function indexed byI and b f b I (m 1 񮽙 m 2 ) = f b I (m 1 ) 񮽙 R I (m 2 ), where 񮽙 and 񮽙 represent the group operations over the domain and range of F.
We provide full definitions of their construction in our technical report [6].
The work of Kamara et al. [21] presents a definition of security based on the ideal-model/real-model security definitions common in secure multiparty computation.
Because their definition formalizes the idea of a non-colluding cloud, we apply their definitions to our protocol for the two-party case in particular.
We summarize their definitions below.
Real-model execution.
The protocol takes place between two parties (P 1 , P 2 ) executing the protocol and a server P 3 , where each of the executing parties provides input x i , auxiliary input z i , and random coins r i and the server provides only auxiliary input z 3 and random coins r 3 .
In the execution, there exists some subset of independent parties (A 1 , .
.
, A m ), m ≤ 3 that are malicious adversaries.
Each adversary corrupts one executing party and does not share information with other adversaries.
For all honest parties, let OUT i be its output, and for corrupted parties let OUT i be its view of the protocol execution.
The i th partial output of a real execution is defined as:REAL (i) (k, x; r) = {OUT j : j ∈ H} ∪ OUT iwhere H is the set of honest parties and r is all random coins of all players.
Ideal-model execution.
In the ideal model, the setup of participants is the same except that all parties are interacting with a trusted party that evaluates the function.
All parties provide inputs x i , auxiliary input z i , and random coins r i .
If a party is semi-honest, it provides its actual inputs to the trusted party, while if the party is malicious (and non-colluding), it provides arbitrary input values.
In the case of the server P 3 , this means simply providing its auxiliary input and random coins, as no input is provided to the function being evaluated.
Once the function is evaluated by the trusted third party, it returns the result to the parties P 1 and P 2 , while the server P 3 does not receive the output.
If a party aborts early or sends no input, the trusted party immediately aborts.
For all honest parties, let OUT i be its output to the trusted party, and for corrupted parties let OUT i be some value output by P i .
The ith partial output of an ideal execution in the presence of some set of independent simulators is defined as:IDEAL (i) (k, x; r) = {OUT j : j ∈ H} ∪ OUT iwhere H is the set of honest parties and r is all random coins of all players.
In this model, the formal definition of security is as follows: Definition 1.
A protocol securely computes a function f if there exists a set of probabilistic polynomial-time (PPT) simulators {Sim i } i∈ [3] such that for all PPT adversaries (A 1 , ..., A 3 ), x, z, and for all i ∈ [3]:{REAL (i) (k, x; r)} k∈N c ≈ {IDEAL (i) (k, x; r)} k∈NWhere S = (S 1 , ..., S 3 ), S i = Sim i (A i ), and r is random and uniform.
Our protocol can be divided into five phases, illustrated in Figure 1.
Given a circuit generator Bob, and an evaluating mobile device Alice, the protocol can be summarized as follows:• Phase 1: Bob generates a number of garbled circuits, some of which will be checked, others will be evaluated.
After Bob commits to the circuits, Alice and Bob use a fair coin toss protocol to select which circuits will be checked or evaluated.
For the checkInputs: Alice has a string of encoded input bits ea of length 񮽙 · n and Bob has pairs of input values (x 0, j , x 1, j ) for j = 1... · n.
Our protocols reference three different entities: Evaluator: The evaluating party, called Alice, is assumed to be a mobile device that is participating in a secure two-party computation.Generator: The party generating the garbled circuit, called Bob, is an application-or web-server that is the second party participating with Alice in the secure computation.Proxy: The proxy, called cloud, is a third party that is performing heavy computation on behalf of Alice, but is not trusted to know her input or the function output.
Common inputs: a function f (x, y) that is to be securely computed, a claw-free collection(G CLW , D CLW , F CLW , R CLW ),two hash functions H 1 : {0, 1} * → {0, 1} n and H 2 : {0, 1} * → {0, 1} w , a primitive 1-out-of-2 oblivious transfer protocol, a perfectly hiding commitment scheme com H (key, message), and security parameters for the number of circuits built k, the number of primitive oblivious transfers t, and the number of encoding bits for each of Alice's input wires 񮽙.
Private inputs: The generating party Bob inputs a bit string b and a random string of bits b r that is the length of the output string.
The evaluating party Alice inputs a bit string a and a random string of bits a r that is the length of the output string.
Assume without loss of generality that all input and output strings are of length |a| = n. Output: The protocol outputs separate private values f a for Alice and f b for Bob.
Phase 1: Circuit generation and checking 5.
Cut and choose: Alice and Bob then run a fair coin toss protocol to agree on a set of circuits that will be evaluated, while the remaining circuits will be checked.
The coin toss generates a set of indices Chk ⊂ {1, ..., k} such that |Chk| = 3 5 k, as in shelat and Shen's cut-and-choose protocol [41].
The remaining indices are placed in the set Evl for evaluation, where |Evl| = e = 2 5 k. , where x b, j = [ik b, j,Evl 1 , ik b, j,Evl 2 , ..., ik b, j,Evl e ]||[γ b j , j,Evl 2 񮽙 (γ b j , j,Evl 1 ) −1 , γ b j , j,Evl 3 񮽙 (γ b j , j,Evl 1 ) −1 , ..., γ b j , j,Evl e 񮽙 (γ b j , j= y h j , j ⊕ H 1 ( j, T j ) for j = 1... · n.Here, h j denotes the j th bit of the string h and T j denotes the j th row in the T matrix.
Since for every j ∈ Evl, the cloud only has the commitment key for the b garbled value (not the b ⊕ 1 garbled value), the cloud can correctly decommit only the garbled labels corresponding to Alice's input bits.
Given the decommitted values [δ b,1,i , ..., δ b,,·n,i ] and the modified pre images[γ b j , j,Evl 2 񮽙 (γ b j , j,Evl 1 ) −1 , γ b j , j,Evl 3 񮽙 (γ b j , j,Evl 1 ) −1 , ..., γ b j , j,Evl e 񮽙 (γ b j , j,Evl 1 ) −1 ],the cloud checks that:δ b j , j,i = δ b j , j,Evl 1 񮽙 R CLW (I, γ b j , j,i 񮽙 (γ b j , j,Evl 1 ) −1 )for i = 2...e.
If any of these checks fails, the cloud aborts the protocol.
β b j , j,i = β b j , j,Evl 1 񮽙 R CLW (I, α b j , j,i 񮽙 (α b j , j,Evl 1 ) −1 )for i = 2...e.
If any of these checks fails, Alice aborts the protocol.
3.
Proof of output consistency: Using the OR-proofs as described by Kiraz [23], the cloud proves to Bob that CB contains valid garbled output bit values based on the de-committed output values from the previous step.
The cloud then performs the same proof to Alice for her committed values CA.
Note that these proofs guarantee the output was generated by one of the circuits, but the value ma j remains hidden from both Alice and Bob.
The cloud then decommits g f a ma j to Alice and g f b ma j to Bob.
Given these garbled outputs and the bit values corresponding to the hash of each output wire, Alice recovers her output string f a, and Bob recovers his output string f b.
In this section, we provide a summary of the security mechanisms used in our protocol and an informal security discussion of our new outsourced oblivious transfer primitive.
Due to space limitations, we provide further discussion and proofs of security in our technical report [6].
Recall from Section 3 that there are generally four security concerns when evaluating garbled circuits in the malicious setting.
To solve the problem of malicious circuit generation, we apply the random seed check variety of cut-&-choose developed by Goyal et al. [11].
To solve the problem of selective failure attacks, we employ the input encoding technique developed by Lindell and Pinkas [29].
To prevent an adversary from using inconsistent inputs across evaluation circuits, we employ the witness-indistinguishable proofs from shelat and Shen [41].
Finally, to ensure the majority output value is selected and not tampered with, we use the XORand-prove technique from Kiraz [23] as implemented by Kreuter et al. [25].
In combination with the standard semi-honest security guarantees of Yao garbled circuits, these security extensions secure our scheme in the malicious security model.
Outsourced Oblivious Transfer: Our outsourced oblivious transfer is an extension of a technique developed by Naor et al. [37] that allows the chooser to select entries that are forwarded to a third party rather than returned to the chooser.
By combining their concept of a proxy oblivious transfer with the semi-honest OT extension by Ishai et al. [18], our outsourced oblivious transfer provides a secure OT in the malicious model.
We achieve this result for four reasons:1.
First, since Alice never sees the outputs of the OT protocol, she cannot learn anything about the garbled values held by the generator.
This saves us from having to implement Ishai's extension to prevent the chooser from behaving maliciously.
2.
Since the cloud sees only random garbled values and Alice's input blinded by a one-time pad, the cloud learns nothing about Alice's true inputs.
3.
Since Bob's view of the protocol is almost identical to his view in Ishai's standard extension, the same security guarantees hold (i.e., security against a malicious sender).
4.
Finally, if Alice does behave maliciously and uses inconsistent inputs to the primitive OT phase, there is a negligible probability that those values will hash to the correct one-time pad keys for recovering either commitment key, which will prevent the cloud from de-committing the garbled input values.
It is important to note that this particular application of the OOT allows for this efficiency gain since the evaluation of the garbled circuit will fail if Alice behaves maliciously.
By applying the maliciously secure extension by Ishai et al. [18], this primitive could be applied generally as an oblivious transfer primitive that is secure in the malicious model.
Further discussion and analysis of this general application is outside the scope of this work.We provide the following security theorem here, which gives security guarantees identical to the Salus protocol by Kamara et al. [21].
However, we use different constructions and require a completely different proof, which is available in our technical report [6].
Theorem 1.
The outsourced two-party SFE protocol securely computes a function f (a, b) in the following two corruption scenarios: (1)The cloud is malicious and non-cooperative with respect to the rest of the parties, while all other parties are semi-honest, (2)All but one party is malicious, while the cloud is semi-honest.
We now characterize how garbled circuits perform in the constrained-mobile environment with and without outsourcing.
1 Two of the most important constraints for mobile devices are computation and bandwidth, and we show that order of magnitude improvements for both factors are possible with outsourced evaluation.
We begin by describing our implementation framework and testbed before discussing results in detail.
Our framework is based on the system designed by Kreuter et al. [25], hereafter referred to as KSS for brevity.
We implemented the outsourced protocol and performed modifications to allow for the use of the mobile device in the computation.
Notably, KSS uses MPI [33] for communication between the multiple nodes of the multi-core machines relied on for circuit evaluation.
Our solution replaces MPI calls on the mobile device with sockets that communicate directly with the Generator and Proxy.
To provide a consistent comparison, we revised the KSS codebase to allow for direct evaluation between the mobile device (the Evaluator) and the cloud-based Generator.
2 Our deployment platform consists of two Dell R610 servers, each containing dual 6-core Xeon processors with 32 GB of RAM and 300 GB 10K RPM hard drives, running the Linux 3.4 kernel and connected as a VLAN on an internal 1 Gbps switch.
These machines perform the roles of the Generator and Proxy, respectively, as described in Section 4.1.
The mobile device acts as the Evaluator.
We use a Samsung Galaxy Nexus phone with a 1.2 GHz dual-core ARM Cortex-A9 processor and 1 GB of RAM, running the Android 4.0 "Ice Cream Sandwich" operating system.
We connect an Apple Airport Express wireless access point to the switch attaching the servers, The Galaxy Nexus communicates to the Airport Express over an 802.11n 54Mbps WiFi connection in an isolated environment to minimize co-channel interference.
All tests are run 10 times with error bars on figures representing 95% confidence intervals.
We measured both the total execution time of the programs and microbenchmarks for each program.
All results are from the phone's standpoint.
We do not measure the time the programs take to compile as we used the standard compiler from Kreuter et al.
For our microbenchmarks, the circuit garbling and evaluation pair is referred to as the 'evaluation'.
Our tests evaluated the following problems: Millionaires: This problem models the comparison of two parties comparing their net worth to determine who has more money without disclosing the actual values.
We perform the test on input values ranging in size from 4 to 8192 bits.
Edit (Levenshtein) Distance: This is a string comparison algorithm that compares the number of modifications required to covert one string into another.
We performed the comparison based on the circuit generated by Jha et al. [19] for strings sized between 4 and 128 bytes.
Set Intersection: This problem matches elements between the private sets of two parties without learning anything beyond the intersecting elements.
We base our implementation on the SCS-WN protocol proposed by Huang et al. [14], and evaluate for sets of size 2 to 128.
AES: We compute AES with a 128-bit key length, based on a circuit evaluated by Kreuter et al. [25].
Figure 3 shows the result of the edit distance computation for input sizes of 2 to 128 with two circuits evaluated.
This comparison represents worst-case operation due to the cost of setup for a small number of small circuits-with input size 2, the circuit is only 122 gates in size.
For larger input sizes, however, outsourced computation becomes significantly faster.
Note that the graph is logarithmic such that by the time strings of size 32 are evaluated, the outsourced execution is over 6 times faster than non-outsourced execution, while for strings of size 128 (comprising over 3.4 million gates), outsourced computation is over 16 times faster.
The reason for this becomes apparent when we examine Figure 4.
There are three primary operations that occur during the SFE transaction: the oblivious transfer (OT) of participant inputs, the circuit commit (including the circuit consistency check), and the circuit generation and evaluation pair.
As shown in the figure, the OT phase takes 292 ms for input size 2, but takes 467 ms for input size 128.
By contrast, in the non-outsourced execution, the OT phase takes 307 ms for input size 2, but increases to 1860 ms for input size 128.
The overwhelming factor, however, is the circuit evaluation phase.
It increases from 34 ms (input size 2) to 7320 ms (input size 128) for the outsourced evaluation, a 215 factor increase.
For non-outsourced execution however, this phase increases from 108 ms (input size 2) to 98800 ms (input size 128), a factor of 914 increase.ED2 ED4 ED8 ED16 ED32 ED64 ED128 Time (ms The security parameter for the garbled circuit check is 2 −0.32k [25], where k is the number of generated circuits.
To ensure a sufficiently low probability (2 −80 ) of evaluating a corrupt circuit, 256 circuits must be evaluated.
However, there are increasing execution costs as increasing numbers of circuits are generated.
ficient of determination R 2 of 0.9971.
However, note that in the non-outsourced scheme, execution time increases over 10 times as quickly compared to outsourced evaluation.
Regression analysis shows execution time T = 5435.7k + 961 ms, with R 2 = 0.9998.
Because in this latter case, the mobile device needs to perform all computation locally as well as transmit all circuit data to the remote parties, these costs increase rapidly.
Fig- ure 6 provides more detail about each phase of execution.
Note that the OT costs are similar between outsourced and non-outsourced execution for this circuit size, but that the costs of consistency checks and evaluation vastly increase execution time for non-outsourced execution.Note as well that in the non-outsourced scheme, there are no reported values for 256 circuits, as the Galaxy Nexus phone ran out of memory before the execution completed.
We observe that a single process on the phone is capable of allocating 512 MB of RAM before the phone would report an out of memory error, providing insight into how much intermediate state is required for non-outsourced evaluation.
Thus, to handle circuits of any meaningful size with enough check circuits for a strong security parameter, the only way to be able to perform these operations is through outsourcing.
Table 1 presents the execution time of a representative subset of circuits that we evaluated.
It spans circuits from small to large input size, and from 8 circuits evaluated to the 256 circuits required for a 2 −80 security parameter.
Note that in many cases it is impossible to evaluate the non-outsourced computation because of the mobile device's inability to store sufficient amounts of state.
Note as well that particularly with complex circuits such as set intersection, even when the non-outsourced evaluation is capable of returning an answer, it can require orders of 2150.0 ± 1% 6130.0 ± 0.6% 8210.0 ± 3% 23080.0 ± 0.6% 38100.0 ± 7% 91020.0 ± 0.8% 75700.0 ± 1% 180800.0 ± 0.5% Millionaires 10244670.0 ± 6% 46290.0 ± 0.4% 17800.0 ± 1% 180500.0 ± 0.3% 75290.0 ± 1% 744500.0 ± 0.7% 151000.0 ± 1% 1507000.0 ± 0.5% Millionaires 819217280.0 ± 0.9% 368800.0 ± 0.4% 76980.0 ± 0.5% 1519000.0 ± 0.4% 351300.0 ± 0.7% -880000.0 ± 20% -Edit Distance 21268.0 ± 0.9% 794.0 ± 1% 4060.0 ± 1% 2125.0 ± 0.7% 19200.0 ± 2% 7476.0 ± 0.5% 42840.0 ± 0.4% 14600.0 ± 0.8% Edit Distance 32 2860.0 ± 3% 44610.0 ± 0.7% 7470.0 ± 5% 175600.0 ± 0.5% 30500.0 ± 3% 699000.0 ± 2% 63600.0 ± 1% -Edit Distance 128 12800.0 ± 2% 702400.0 ± 0.5% 30300.0 ± 2% 2805000.0 ± 0.8% 106200.0 ± 0.6% -213400.0 ± 0.3% - Set Intersection 2 1598.0 ± 0.8% 1856.0 ± 0.9% 5720.0 ± 0.7% 6335.0 ± 0.4% 26100.0 ± 2% 24420.0 ± 0.6% 56350.0 ± 0.8% 48330.0 ± 0.6% Set Intersection 32 5200.0 ± 10% 96560.0 ± 0.6% 13800.0 ± 1% 400800.0 ± 0.6% 59400.0 ± 1% -125300.0 ± 0.9% -Set Intersection 128 24300.0 ± 2% 1398000.0 ± 0.4% 55400.0 ± 3% 5712000.0 ± 0.4% 1998000.0 ± 0.5% -395200.0 ± 0.8% -AES-1282450.0 ± 2% 15040.0 ± 0.7% 9090.0 ± 5% 58920.0 ± 0.5% 39000.0 ± 2% 276200.0 ± 0.6% 81900.0 ± 1% 577900.0 ± 0.5% Figure 6: Microbenchmarks of execution time for Edit Distance with input size 32, evaluating from 2 to 256 circuits.
Note that the y-axis is log-scale; consequently, the vast majority of execution time is in the check and evaluation phases for non-outsourced evaluation.magnitude more time than with outsourced evaluation.
For example, evaluating the set intersection problem with 128 inputs over 32 circuits requires just over 55 seconds for outsourced evaluation but over an hour and a half with the non-outsourced KSS execution scheme.
Outsourced evaluation represents a time savings of 98.92%.
For space concerns, we have omitted certain values; full results can be found in our technical report [6].
Multicore Circuit Evaluation We briefly note the effects of multicore servers for circuit evaluation.
The servers in our evaluation each contain dual 6-core CPUs, providing 12 total cores of computation.
The computation process is largely CPU-bound: while circuits on the servers are being evaluated, each core was reporting approximately 100% utilization.
This is evidenced by regression analysis when evaluating between 2 and 12 circuit copies; we find that execution time T = 162.6k + 1614.6 ms, where k is the number of circuits evaluated, with a coefficient of determination R 2 of 0.9903.
As the number of circuits to be evaluated increases beyond the number of available cores, the incremental costs of adding new circuits becomes higher; in our observation of execution time for 12 to 256 circuits, our regression analysis provided the equation T = 247.4k − 410.6 ms, with R 2 = 0.998.
This demonstrates that evaluation of large numbers of circuits is optimal when every evaluated circuit can be provided with a dedicated core.The results above show that as many-way servers are deployed in the cloud, it becomes easier to provide optimal efficiency computing outsourced circuits.
A 256-core machine would be able to evaluate 256 circuits in parallel to provide the accepted standard 2 −80 security parameter.
Depending on the computation performed, there can be a trade-off between a slightly weaker security parameter and maintaining optimal evaluation on servers with lower degrees of parallelism.
In our testbed, optimal evaluation with 12 cores provides a security parameter of 2 −3.84 .
Clearly more cores would provide stronger security while keeping execution times proportional to our results.
A reasonable trade-off might be 32 circuits, as 32-core servers are readily available.
Evaluating 32 circuits provides a security parameter of 2 −10.2 , equivalent to the adversary having less than a 1 512 chance of causing the evaluator to compute over a majority of corrupt circuits.
Stronger security guarantees on less par- allel machines can be achieved at the cost of increasing execution time, as individual cores will not be dedicated to circuit evaluation.
However, if a 256-core system is available, it will provide optimal results for achieving a 2 −80 security parameter.
For a mobile device, the costs of transmitting data are intrinsically linked to power consumption, as excess data transmission and reception reduces battery life.
Bandwidth is thus a critical resource constraint.
In addition, because of potentially uncertain communication channels, transmitting an excess of information can be a ratelimiting factor for circuit evaluation.
Figure 7 shows the bandwidth measurement between the phone and remote parties for the edit distance problem with 2 circuits.
When we compared execution time for this problem in Figure 3, we found that trivially small circuits could execute in less time without outsourcing.
Note, however, that there are no cases where the non-outsourced scheme consumes less bandwidth than with outsourcing.
This is a result of the significant improvements garnered by using our outsourced oblivious transfer (OOT) construction described in Section 4.
Recall that with the OOT protocol, the mobile device sends inputs for evaluation to the generator; however, after this occurs, the majority of computation until the final output verification from the cloud occurs between the generator and the cloud, with the mobile device only performing minor consistency checks.
Figure 7 shows that the amount of data transferred increases only nominally compared to the non-outsourced protocol.
Apart from the initial set of inputs transmitted to the generator, data demands are largely constant.
This is further reflected in Table 2, which shows the vast bandwidth savings over the 32-circuit evaluation of our representative programs.
In particular, for large, complex circuits, the savings are vast: outsourced AES-128 requires 96.3% less bandwidth, while set intersection of size 128 requires 99.7% less bandwidth than in the non-outsourced evaluation.
Remarkably, the edit distance 128 problem requires 99.95%, over 1900 times less bandwidth, for outsourced execution.
The full table is in our technical report [6].
The takeaway from our evaluation is simple: outsourcing the computation allows for faster and larger circuit evaluation than previously possible on a mobile device.
Specifically, outsourcing allows users to evaluate garbled circuits with adequate malicious model security (256 circuits), which was previously not possible on mobile devices.
In addition, outsourcing is by far the most efficient option if the bandwidth use of the mobile devices is a principle concern.
Beyond the standard benchmarks for comparing garbled circuit execution schemes, we aimed to provide compelling applications that exploit the mobile platform with large circuits that would be used in real-world scenarios.
We discuss public-key cryptography and the Dijkstra shortest path algorithm, then describe how the latter can be used to implement a privacy-preserving navigation application for mobile phones.
Table 3 shows the execution time required for a blinded RSA circuit of input size 128.
For these tests we used a more powerful server with 64 cores and 1 Terabyte of memory.
Our testbed is able to give dedicated CPUs when running 32 circuits in parallel.
Each circuit would have 1 core for the generation and 1 core for the evaluation.
As described in Section 6, larger testbeds capable of executing 128 or 256 cores in parallel would be able to provide similar results for executing the 256 circuits necessary for a 2 −80 security parameter as they could evaluate the added circuits in parallel.
The main difference in execution time would come from the multiple OTs from the mobile device to the outsourced proxy.
The RSA circuit has been previously evaluated with KSS, but never from the standpoint of a mobile device.
We only report the outsourced execution results, as the circuits are far too large to evaluate directly on the phone.
As with the larger circuits described in Section 6, the phone runs out of memory from merely trying to store a representation of the circuit.
Prior to optimization, the blinded RSA circuit is 192, 537, 834 gates and afterward, comprises 116, 083, 727 gates, or 774 MB in size.The implementation of Dijkstra's shortest-path algorithm results in very large circuits.
As shown in Table 3 garbled circuits to date.
While it may be possible for existing protocols to evaluate circuits of similar size, it is significant that we are evaluating comparably massive circuits from a resource-constrained mobile device.
Mapping and navigation are some of the most popular uses of a smartphone.
Consider how directions may be given using a mobile device and an application such as Google Maps, without revealing the user's current location, their ultimate destination, or the route that they are following.
That is, the navigation server should remain oblivious of these details to ensure their mutual privacy and to prevent giving away potentially sensitive details if the phone is compromised.
Specifically, consider planning of the motorcade route for the recent Presidential inauguration.
In this case, the route is generally known in advance but is potentially subject to change if sudden threats emerge.
A field agent along the route wants to receive directions without providing the navigation service any additional details, and without sensitive information about the route loaded to the phone.
Moreover, because the threats may be classified, the navigation service does not want the holder of the phone to be given this information directly.
In our example, the user of the phone is trying to determine the shortest path.To model this scenario, we overlay a graph topology on a map of downtown Washington D.C., encoding intersections as vertices.
Edge weights are a function of their distance and heuristics such as potential risks along a graph edge.
Figure 8 shows graphs generated based on vertices of 20, 50, and 100 nodes, respectively.
Note that the 100-node graph ( Figure 8c) encompasses a larger area and provides finer-grained resolution of individual intersections than the 20-node graph ( Figure 8a).
There is a trade-off between detail and execution time, however; as shown in Table 3, a 20-vertex graph can be evaluated in under 26 seconds, while a 100-vertex graph requires almost 15 minutes with 32 circuits in our 64-core server testbed.
The 64 circuit evaluation requires more time: almost 50 seconds for the 20-vertex graph, and almost 22 minutes for a 100-vertex graph.
We anticipate that based on the role a particular agent might have on a route, they will be able to generate a route that covers their particular geographical jurisdiction and thus have an appropriately sized route, with only certain users requiring the highest-resolution output.
Additionally, as described in Section 6.3, servers with more parallel cores can simultaneously evaluate more circuits, giving faster results for the 64 circuit evaluation.
Figure 9 reflects two routes.
The first, overlaid with a dashed blue line, is the shortest path under optimal conditions that is output by our directions service, based on origin and destination points close to the historical start and end points of the past six presidential inaugural motorcades.
Now consider that incidents have happened along the route, shown in the figure as a car icon in a hazard zone inside a red circle.
The agent recalculates the optimal route, which has been updated by the navigation service to assign severe penalties to those corresponding graph edges.
The updated route returned by the navigation service is shown in the figure as a path with a dotted purple line.
In the 50-vertex graph in Fig- ure 8, the updated directions would be available in just over 135 seconds for 32-circuit evaluation, and 196 and a half seconds for 64-circuit evaluation.
While garbled circuits offer a powerful tool for secure function evaluation, they typically assume participants with massive computing resources.
Our work solves this problem by presenting a protocol for outsourcing garbled circuit evaluation from a resource-constrained mobile device to a cloud provider in the malicious setting.
By extending existing garbled circuit evaluation techniques, our protocol significantly reduces both computational and network overhead on the mobile device while still maintaining the necessary checks for malicious or lazy behavior from all parties.
Our outsourced oblivious transfer construction significantly reduces the communication load on the mobile device and can easily accommodate more efficient OT primitives as they are developed.
The performance evaluation of our protocol shows dramatic decreases in required computation and bandwidth.
For the edit distance problem of size 128 with 32 circuits, computation is reduced by 98.92% and bandwidth overhead reduced by 99.95% compared to non-outsourced execution.
These savings are illustrated in our privacy-preserving navigation application, which allows a mobile device to efficiently evaluate a massive garbled circuit securely through outsourcing.
These results demonstrate that the recent improvements in garbled circuit efficiency can be applied in practical privacy-preserving mobile applications on even the most resource-constrained devices.
