Relaxations based on (either complete or partial) ignoring delete effects of the actions provide the basis for some seminal classical planning heuristics.
However, the palette of the conceptual tools exploited by these heuristics remains rather limited.
We study a framework for approximating the optimal cost solutions for problems with no delete effects that bridges between certain works on heuristic search for probabilistic reasoning and classical planning.
In particular, this framework generalizes some previously known, as well as suggests some novel, tools for heuristic estimates for Strips planning .
The problems of classical planning correspond to state models with deterministic actions and complete information.
While several languages for describing classical planning problems have been proposed, the most canonical is probably the Strips language (Fikes & Nilsson 1971).
A planning problem in Strips is given by a tuple Π = P, A, I, G where P is a set of atoms (also called propositions), I ⊆ P encodes the initial situation, G ⊆ P encodes the goal situations, and A is a set of actions a = pre(a), add(a), del(a), where pre(a) ⊆ P , add(a) ⊆ P , and del(a) ⊆ P capture the preconditions, add effects, and delete effects of the action a, respectively.
The cost of a plan α ∈ A * for Π is given by C(s 0 , α) = a∈α C(a), where the (possibly non-uniform) costs of all actions in A are assumed to be non-negative.
Research on using abstractions for heuristic-search Strips planning has began in the late 90's (Bonet & Geffner 2001;McDermott 1999;Refanidis & Vlahavas 2001;Hoff- mann & Nebel 2001;Nguyen, Kambhampati, & Nigenda 2002), and one such abstraction has provided the foundations for numerous developments in heuristic-search planning.
Specifically, the "ignoring-delete-effects" abstraction Π| + = P, A| + , I, G of Π = P, A, I, G is obtained by removing the delete lists from the actions of Π, that is,A| + = {a ′ | a ∈ A, a ′ = (pre(a), add(a), ∅)} .
This abstraction is known to be rather informative for a wide spectrum of planning problems, but computing the optimal cost h + (s) for Π| + is still an NP-hard problem (Bylander 1994).
Thus, even if desirable, using h + as a heuristic estimate directly is problematic, and thus further approximation of h + is required.An elegant admissible approximation h max of h + has been suggested in (Bonet & Geffner 2001), and it corresponds to estimating the cost of achieving a set of atoms by the cost of achieving in Π| + the most costly atom in the set.
Given a state s that should be assigned a heuristic value, these estimates are computed for all atoms p ∈ P by performing incremental updatesg s (p) := min a∈A, p∈add(a) {g s (p), C(a) + g s (pre(a))}, (1)where, for a set of atoms P ′ ⊆ P ,g s (P ′ ) := max p∈P ′ g s (p).
(2)This iterative procedure starts with g s (p) = 0 if p ∈ s, and g s (p) = ∞, otherwise, and runs until the costs g s (p) reach the fix-point.
The heuristic estimate for s is then set to h max (s) := g s (G).
The max-heuristic h max is admissible, but typically is "too admissible".
The main weakness of h max is that it ignores independence between achieving different subgoals, and this leads to poor heuristic estimates in domains that exhibit a substantial degree of parallelism.
To alleviate this shortcoming, one can possibly trade admissibility of heuristic for its informativeness.
In some sense, one can see this move as trading the expected quality of the solution for efficiency of its generation.
This direction has leaded to formulation of the (much more informative) heuristics h add (Bonet & Geffner 2001) and h ff (Hoffmann & Nebel 2001), where the former is obtained by replacing the maximization in Eq.
2 with summation, and the latter estimates h + (s) with the (computable in low polynomial time) cost of some plan from s in Π| + .
In what follows, we distinguish between h ff and h FF with the former corresponding to the principal idea of basing the estimate on some relaxed plan, and the latter corresponding to the concrete procedure of the FF planner for computing such a plan (Hoffmann & Nebel 2001).
We now define a computational framework that characterizes what we call the cost-sharing class of approximations of h + .
All these approximations can be schematically specified via the same core mechanism of cost propagation over planning graphs, with the difference being in the actual propagated costs.We begin with some useful notation.
To indicate parent and child relations in a digraph (V, E) we use the convention that parents are "before" children along with subscript and superscript capturing the "immediately before" and "immediately after" (i.e., parents and children) relations.
For convenience, this notation is used for both nodes and edges; E v and E v are the sets of incoming and outgoing edges of node v, U v and U v are the parent and children nodes of v, and v e , v e are the source and end nodes of edge e, respectively.
Given a state s and a goal G, the planning graph eRPG(s, G) required for our purposes is very similar to the standard relaxed planning graph (Hoffmann & Nebel 2001).
The procedure build-RPG for constructing eRPG(s, G) is depicted in Figure 1.
Similarly to its well-known relative, eRPG is a layered acyclic digraph with two kinds of nodes: fact nodes and action nodes.
The layers alternate between fact layers P (0) , P (1) , . . . , and action layers A (0) , A (1) , . . . , where a pair of layers P (i) , A (i) together make up a "time step".
The specifics of eRPG are in (i) the depth ub to which the graph is constructed, and (ii) the additional special action layer A (ub+1) .
The construction of eRPG(s, G) ensures that the graph captures an optimal plan from s in Π| + .
For that, the depth of eRPG(s, G) is controlled by an upper bound ub on the number of actions in the shortest optimal plan from s in Π| + .
While there are several alternatives for setting ub, one very simple (though typically horribly inefficient) alternative would be ub = |P |.
However, much better alternatives are abound.
For instance, for "truly classical" planning problems with uniform cost actions, ub can be set to the number of actions in a plan from s in Π| + (that is, to the h ff estimate ( Hoffmann & Nebel 2001)), that can be computed at relatively low cost during the construction of eRPG.
In case of non-uniform action costs, the issue of devising an effective upper bound ub is somewhat more open.
However, if the variance of the action costs is not too high, then the effectiveness of the bound ub = argmaxA ′ ∈A, C(A ′ )≤C |A ′ |,(3)where C is the cost of the relaxed plan extracted by the FF procedure, should be close to the effectiveness of ub = h FF (s) on the problems with uniform-cost actions 1 .
Once eRPG is constructed up to the layers A (ub) and P (ub+1) , if some of the goal atoms are not present in P (ub+1) , then G is proven to be unreachable from s in Π| + (and thus, in Π), and therefore we can safely set h(s) = ∞.
Otherwise, we proceed with extending eRPG with the action layer A ub+1 = {ˇa}{ˇa}, withˇawithˇ withˇa being a dummy relaxed action with pre(ˇ a) = G, add(ˇ a) = ∅, and C(ˇ a) = 0, and connect between the goal fact nodes in P (ub+1) andˇaandˇ andˇa.Having constructed the planning graph eRPG(s, G), we proceed with the cost propagation step.
Here as well, we begin with providing some essential formalism.
An and-or dag ∆ = (V, E) is a connected acyclic digraph with a partition of nodes into and-nodes aV and or-nodes oV , and a single sink (out-degree 0) node r ∆ ∈ aV called the root node.
Each and-or dag ∆ induces a set A(∆) of its and-dags; An and-dag δ ∈ A(∆) is obtained from ∆ by removing all but one descendants from each or-node in ∆.
A weighted and-or dag (waodag) ∆ w is a pair (∆, w) where ∆ is an and-or dag, and w : V → R 0+ is a non-negative real-valued weight function from nodes.
The weight of ∆ w is defined asw(∆ w ) = min δ∈A(∆w) w(δ), w(δ) = v∈V δ w(v),and A min (∆ w ) = {δ ∈ A(∆ w ) | w(δ) = w(∆ w )} is the set of all minimal and-dags of ∆ w .
Now, consider the eRPG(s, G) graph constructed by the build-RPG procedure, and let us lift our cost function C from actions to (both fact and action) nodes of eRPG as C(a (i) ) = C(a), and C(p (i) ) = 0.
Proposition 1 Considering eRPG(s, G) as a waodag ∆ C with oV = P (i) , aV = A (i), and rootˇarootˇ rootˇa, we haveC(∆ C ) = h + (s).
The proof of Proposition 1 shows that each and-dag in A min (∆ C ) corresponds to an optimal plan for Π| + , and at least one optimal plan for Π| + corresponds to an and-dag in A min (∆ C ).
In particular, this implies that approximating h + is equivalent to approximating C(∆ C ), and this simple observation leads to specifying a general cost propagation scheme for approximating h + (s).
The skeleton of this weight propagation is given by Eq.
4.
Let ∆ C be a waodag 1 The bound provided by Eq.
3 can be computed efficiently by greedily expanding A ′ with actions from A in the increasing order of their cost.procedure build-RPG`s RPG` RPG`s, A| + , G, ub´, ub´ ub´,P (0) = s for t := 0 . . . ub do A (t) := {a (t) | a ∈ A| + , pre(a) ⊆ P (t) }; EA (t) := {(p (t) , a (t) ) | p ∈ pre(a)} P (t+1) := {p (t+1) | p ∈ add(a), a (t) ∈ A (t) }; EP (t+1) := {(a (t) , p (t+1) ) | p ∈ add(a)} if G ∈ P (t) then return FALSE A (t+1) := {ˇa}{ˇa}; EA (t+1) = {(p (t+1) , ˇ a) | p ∈ G} return TRUE Figure 1: Building eRPG from s to G.with ∆ = (V, E).
The heuristic estimate h(s) is defined via the parametric cost estimator ̟ :V ∪ E → D as h(s) = f (̟(ˇ a)) ̟(v) = ϕ a (v, E v ) , v is an action node ϕ p (v, E v ) , v is a fact node ̟(e) = ψ a (v e ) , v e is an action node ψ p (v e ) , v e is a fact node (4)where D is a set, andΛ = ϕ a , ϕ p , ψ a , ψ p , f is a set of functional parameters of ̟, with ϕ a , ϕ p : V × 2 E → D, ψ a , ψ p : V → D,and f : D → R 0+ .
Note that planning graphs are not really required for computing Eq 4, and the latter can be done iteratively a la Eqs.
1-2.
However, later we show that considering the framework through the lens of Proposition 1 does provide helpful insights into the process of cost propagation.Proposition 2 Heuristic functions h max , h add , and h ff can be casted as special cases of the framework (4).
While the h ff -instance of the framework is given later in the paper (in Eq.
11), h add and h max instances of (4) can be formulated by setting D = R 0+ , f = identity function, andϕ p (p (i) , E p (i) ) = 0, i = 0 min e∈Ep (i) ̟(e), i > 0 , ϕ a (a (i) , E a (i) ) = C(a (i) ) + e∈Ea (i) ̟(e), ψ p p (i) = ̟(p (i) ), ψ a a (i) = ̟(a (i) )(5)for h add , replacing for h max the internal summation of ϕ a in Eq.
5 by maximization.
Informally, in both cases, the cost estimate ̟(u) for a node u is determined by the estimates for its incoming edges E u , and the cost estimate ̟(e) for an edge e is determined given the estimate of its source node u e .
The process of cost propagation finishes by computing the cost estimate ̟(ˇ a) for the special action nodě a, and setting the heuristic estimate to ̟(ˇ a).
While h max , h add , and h ff fit the cost-sharing framework, this in itself is not especially helpful.
However, the generality of the framework may allow us specifying and studying a wider palette of heuristic functions.
In particular, the question we consider in this section is whether some non-trivial instances of Eq.
4 other than h max provide us with admissible approximations of h + , and how the informativeness of these approximations compares to this of h max .
Interestingly, the answer to the first question appears to be affirmative.
More than a decade ago, Charniak and Husain suggested an admissible estimate for the cost of waodags, and this estimate has been successfully used in probabilistic reasoning and cost abduction (Charniak & Husain 1991).
In our terms, this estimate h cs is given by D = R 0+ , f = identity function, and̟(p (i) ) = 0, i = 0 min e∈Ep (i) ̟(e), i > 0 , ̟(a (i) ) = C(a (i) ) + e∈Ea (i) ̟(e), ̟(e p (i) ) = ̟(p (i) ) |E p (i) | , ̟(e a (i) ) = ̟(a (i) ) |E a (i) | .
(6)Note that the cost propagation to the nodes in Eq.
6 is identical to this in Eq.
5 for (inadmissible) h add .
The difference is in the cost propagation to the edges.
Unlike for h add , the cost estimate of an action/fact node in Eq.
6 is not fully propagated along each outgoing edge, but partitioned between them.
This syntactically slight adaptation Eq.
5 is sufficient to make the heuristic admissible, and the proof of admissibility is rather straightforward from the results in (Charniak & Husain 1991).
The h cs heuristic has been shown very effective on various problems of probabilistic reasoning (Charniak & Husain 1991;Shimony, Domshlak, & Santos 1997), and a priori this suggests that the same heuristic could be effective on the planning problems as well.
However, the informativeness of h cs in our context is more problematic.
In our experience 2 , using A * equipped with h cs for planning as forward search turns out to be as (in)efficient as using uniform-cost search that completely ignores the heuristic estimates.
Figure 2 illustrates that on problems from the Blocksworld and Logistics domains, but the phenomenon holds for all benchmarks from the recent planning competitions.
The problem is that the values of h cs (s) for states encountered in searching for a plan are typically so low that the choice of the search node to expand is basically determined by the cost-so-far part g(s) of the node evaluation function f (s) = g(s) + h(s).
It appears that such a dramatic difference in effectiveness of h cs in estimating cost of the waodags in planning and in probabilistic reasoning can be explained.
The major factor affecting the informativeness of h cs is the degree of erosion of the propagated action costs.
This erosion is caused by the distribution of the cost of a node among its indirect descendants in the graph.
One property of the waodags that dramatically affects the cost erosion is the out-degree of the nodes.
While the out-degree of the nodes in waodags describing probabilistic models tend to be low, this is not the 2 Our implementation is based on the A * algorithm of the HSP2 planner, and we are thankful to B. Bonet and H. Geffner for making its code publicly available.
case in planning graphs, or at least, in planning graphs coming from the standard classical planning benchmarks 3 .
The problem is especially severe with the fact nodes, out-degrees of whose correspond to the number of applicable actions requiring these facts.
Due to the combinatorial structure of the benchmarks, these numbers for facts tend to be extremely large.
For instance, the out-degree of a fact node clear(b) (i) in Blocksworld gets as large as 2B, where B is the total number of blocks.In the past it was already observed that the problem of Eq.
6 with large node out-degrees can be partly alleviated (Charniak & Husain 1991;Shimony, Domshlak, & San- tos 1997).
Specifically, it can be shown that ψ p and ψ a in Eq.
6 can be replaced with̟(e p (i) ) = ̟(p (i) ) κ(p (i) ) , ̟(e p (i) ) = ̟(a (i) ) κ(a (i) )(7)where the effective out-degree κ(v) of a node v is the size of a largest subset of E v that belongs to some and-dag in A(eRPG), that is, κ(v) = max δ∈A(eRPG) |E v ∩ δ|.
Interestingly, comparing the modified Eq.
6 with the formulation of h add as in Eq.
5 shows that h add constitutes a variant of h cs that assumes κ(v) = 1 for all nodes v. (Obviously, this assumption rarely holds.)
The question, however, is whether determining the effective out-degrees of the eRPG's nodes can always be done efficiently.
Unfortunately, Proposition 3 below shows that this is not the case.Proposition 3 Given an and-or dag ∆ = (V, E), and v ∈ V , determining the effective out-degree κ(v) in ∆ is NPhard.The proof of Proposition 3 is by a polynomial reduction from the MAX-2-SAT problem.
It is worth noting that, in our context, the and-nodes of the waodags correspond to actions, and thus their in-and out-degrees correspond to the number of preconditions and add effects, respectively.
The latter parameters are typically bounded by a small constant, and our reduction from MAX-2-SAT respects this property.The efficiency of determining the effective out-degree of the nodes of eRPG is not the only issue with h cs .
While knowing the latter has the potential to reduce the cost erosion, it seems unlikely that this reduction will typically change the picture significantly.
First, large κ(v) in planning problems is more of a rule than of an anomaly.
For illustration, consider a Logistics problem in which all P packages and a truck t are initially located at the same location l, with the latter being the target location for none of the packages.
In this case, the fact node at(t, l) (0) will have outgoing edges to at least the P action nodes load(p, t, l) (0) , and all these edges will be part of a plan (and thus an anddag) in which t takes all the packages from l to their target destinations.
In fact, this plan can even be optimal.The second problem is that the node out-degrees are not the only cause of the cost erosion in h cs .
Consider two nodes v (t) and v ′ (t ′ ) in eRPG such that t > t ′ , and assume that the cost propagation as in Eqs.
6-7 results in cost estimate ̟(v ′ (t ′ ) ) contributing to the cost estimate ̟(v (t) ).
It is not hard to verify that the marginal cost contribution of v ′ (t ′ ) to ̟(v (t) ) may decrease exponentially with the distance t − t ′ between the two nodes, and this unless the effective outdegree of the eRPG nodes is (known to be) = 1.
In planning benchmarks, however, κ(v) = 1 never happens for fact nodes, and very rarely for action nodes.
On the other hand, even efficiently bounded depth of eRPG is typically such that most of the contributions to the node's cost are getting negligible.
The question that the previous section leaves open is whether a setting of the framework (4) results in a more informative that h max and h cs , admissible estimate for h + .
One can, however, also try exploiting the generality of the costsharing framework to derive non-admissible heuristics lying in between h add /h ff and h max .
That is, heuristics leading to discovering solutions of higher quality than h add /h FF , but expanding less nodes than h max .
Here we suggest and explore one such setting of the framework, which we refer to as h pmax (short for pairwise max).
The source of this name for the heuristic is now explained.The core difference between h pmax on one hand, and h max , h add , and h cs , on the other hand, is that in h pmax we propagate not single costs, but vectors of costs.
Specifically, each node v in eRPG is annotated with a cost vector Here we have P = {p 1 , . . . , p 5 } and A = {a 1 , a 2 , a 3 }, where pre(a 1 ) = {p 1 }, pre(a 2 ) = pre(a 3 ) = {p 2 }, and add(a 1 ) = {p 2 }, add(a 2 ) = {p 3 , p 4 }, add(a 3 ) = {p 3 , p 4 }.
̟ v in D = R |P | .
ated with p ∈ P .
For ease of presentation, each action node a (i) is also schematically annotated with a scalar estimate w a (i) derived from the cost vector Figure 3 for an illustration by example.)
The cost vectors for the rest of the nodes of eRPG are then iteratively defined (and computed) as follows.
Given the cost vectors of P (t) , for each action node a (t) ∈ A (t) , we set ̟ a (t) and̟ a (i) .
First, for each p (0) ∈ P (0) , we set ̟ p (0) [q] = 0 for all q ∈ P .
(Seew a (t) to ̟ a (t) [q] = max (p (t) ,a (t) )∈Ea (t) ̟ p (t) [q] , w a (t) = q∈P ̟ a (t) [q](8)Informally, w a (t) estimates the cost of being able to apply a at time t, with the "prerequisite set" P rq(a (t) ) = {q ∈ P | ̟ a (t) [q] 񮽙 = 0} containing the propositions that should be achieved prior to applying a at t, and the corresponding entries ̟ a (t) [q] capturing the marginal cost of achieving the "prerequisite" q. Importantly, while Eq.
8 estimates the cost of applying a at t as the sum of achieving its prerequisites, the prerequisites are treated as independent only when it is considered to be safe: If some fact q ∈ P rq(a (t) ) is considered contributing to achieving more than one precondition of a at time t, then only one such contribution is taken by Eq.
8 into account.Given the cost vectors and scalar estimates of A (t) , for each fact node p (t+1) ∈ P (t+1) , we select an action node a (t) ∈ A (t) that provides p (t+1) and satisfiesa (t) = argmin (a (t) ,p (t+1) )∈Ep (t+1) w a (t) + C(a (t) ) |E a (t) | .
(9)The cost vector of each p (t+1) ∈ P (t+1) is then defined as: 1, and P rq(p (t+1) ) captures the corresponding set of purported prerequisites.
The cost propagation finishes by computing the cost estimate w(ˇ a), and the heuristic value is set to h pmax (s) = w(ˇ a).
(As a practical comment, we note that the propagated cost vectors ̟ will typically be very sparse, and thus propagating them as sets of their non-zero entries significantly speeds-up computing h pmax .)
̟ p (t+1) [q] =      ̟ d a (t) [q], p (t+1) 񮽙 = q (t+1) ̟ d a (t) [q] + C( d a (t) ) |E d a (t) | , p (t+1) = q (t+1) ,(10)Let us now consider h pmax more closely.
Aiming to avoid overestimates in cost propagation, the cost of applying an action is partitioned in Eqs.
9-10 among its add effects.
h pmax inherits this "marginalization" of the action costs from h cs , and the semantics of this cost partition corresponds to a stronger than | + relaxation | +s .
In | +s , we have a ∈ A| +s if and only if a = (pre(a ′ ), {p}, ∅) for some a ′ ∈ A| + , p ∈ add(a ′ ), and C(a) = C(a ′ )/|add(a)|.
In other words, the actions of Π| +s are obtained from the actions of Π by (i) removing their delete lists, (ii) splitting each action into a set of single-effect actions, and (ii) dividing the cost of each original action between the actions resulted from its splitting.
It is not hard to verify that h +s ≤ h + , yet computing h +s is still NP-hard (follows from Theorem 4.2 and Corollary 4.3 in (Bylander 1994)).
Proposition 4 connects between the | +s relaxation and computing h pmax , showing that the latter basically aims at approximating the optimal plan cost for that relaxation.
Computing h pmax over Π| + is equivalent to computing it over Π| +s .
Given that Π| +s is always at least as relaxed as Π| + , at first view, the utility of targeting h +s instead of h + in the process of approximation is unclear.
However, this "step down" in h pmax allows us for a more delicate treatment of interactions between the problem's actions.
For example, consider two Blocksworld problems involving n blocks b 1 , . . . , b n .
In the first problem, the blocks are all initially unstacked, and the goal is to build an ordered tower with b 1 on top and b n at the bottom.
Assuming all actions have unit cost, for this initial state we have h + = h pmax = h add = n − 1, and h max = 1.
In the second problem, the blocks are initially stacked in an ordered tower with b 1 on top and b n at the bottom, and the goal is to obtain a reversely ordered tower with b n on top and b 1 at the bottom.
For these state and goal, we have h + = h pmax = h max = n, and h add = 2 n−1 i=1 i. Note that the relative informativeness of h max and h add varies between these two problems, while h pmax sticks to the correct value of h + .
In fact, looking at the definition of h pmax in Eqs.
8-10, one may wonder whether h pmax is actually admissible.
This, however, is not so, and the following example illustrates the pitfall.
Let relaxed actions a 1 , . . . , a 6 be defined as follows.
For 1 ≤ i ≤ 3, pre(a i ) = {p i }, add(a i ) = {p i+3 }, and pre(a 4 ) = {p 4 , p 5 }, add(p 7 ) pre(a 5 ) = {p 4 , p 5 }, add(p 8 ) pre(a 6 ) = {p 6 }, add(p 7 )Given these action set, for I = {p 1 , p 2 , p 3 }, and G = {p 7 , p 8 }, we have h pmax (I) = 5 > h + (I) = 4.
The question of whether h pmax can be slightly modified to guarantee admissibility remains open.
Likewise, before we move to discussing the empirical evaluation, it is worth noting that the idea of vector-based cost propagation can be taken beyond the specific setting of h pmax .
For instance, using cost vectors in D = R A (instead of in R P ) allows us to provide in Eq.
11 a cost-sharing formulation of h ff , required for Proposition 2.
̟ a (t) [a ′ ] = max (p (t) ,a (t) )∈Ea (t) ̟ p (t) [a ′ ] w a (t) = C(a (t) ) + a ′ ∈A ̟ a (t) [a ′ ] a (t) = argmin (a (t) ,p (t+1) )∈Ep (t+1) {w a (t) } ̟ p (t+1) = 0, t + 1 = 0 ̟ d a (t) , t + 1 > 0 (11)Needless to say that computing h ff this way is much more costly that doing that using the simple back-chaining procedure suggested in (Hoffmann & Nebel 2001).
Moreover, while "noops-first" strategy from (Hoffmann & Nebel 2001) can be incorporated in Eq.
11, "action nodes reusage" strategy used in computing the FF's heuristic cannot be formulated within the cost-sharing framework.
On the other hand, however, cost propagation might provide a better guidance on what no-noop action should better be selected to support achieving this or another sub-goal.
Further insights into this tradeoff are required, and for now, h ff formulation as in Eq.
11 is mostly of theoretical interest.
We have implemented h pmax and (the original FF's heuristic) h FF within the HSP2 planner (Bonet & Geffner 2001) that have already supported the h add and h max heuristics.
For the evaluation, we have used Strips problems from the IPC-2000domains Blocksworld, Freecell, and Logis- tics, IPC-2002domains Driverlog, Zenotravel, Depots, and Satellite, IPC-2004domain Pipesworld, and IPC-2006 domains Openstacks, Pathways, Rovers, and TTP, and, finally, the n-Puzzle problems from the HSP2 distribution.
As the quality of the generated solutions was of our interest, all the heuristics have been evaluated under the A * search algorithm.In general, the evaluation was aiming at answering the following questions.
Considering question (1), the h add , h FF , and h pmax columns in Table 1 summarize the effectiveness of these heuristics on guiding A * toward optimal solutions.
In general, h add typically does not guide the search towards an optimal solution, and only in Pathways all the solutions discovered with h add were optimal.
h FF is already much more effective, yet only for two domains it provided optimal solutions across all the problem instances that have been solved by A * with both h FF and h pmax within the time limit of 1 hour.
In contrast, the cost-sharing heuristic h pmax appears to be almost as quality-wise effective as the admissible h maxthe only problem on which we found h pmax guiding A * to a non-optimal solution was instance #9 in the Satellite domain.
Table 2 that • in all the domains, using h pmax resulted in expanding less search nodes than using h max , with the difference between the two reaching more than three orders of magnitude.
• using h pmax resulted in expanding more search nodes than h FF in all domains except for Satellite, with the difference between the two being mostly of up to one order of magnitude.
In addition, we note that in 5 domains, namely Blocksworld, Logistics, Driverlog, Depots, and Satellite, the relation between h pmax and h FF in terms of the number of expanded nodes varied between the problem instances.
Now, the cost vector propagation clearly makes computing h pmax per search node more costly than computing h FF , and the difference between the two in this respect depends on the structure of the domain in hand.
Figure 4, however, shows that this difference is not as substantial as one would probably conjecture.
For instance, we noticed that in the Logistics domain h pmax and h FF provide exactly the same numbers of expanded and generated nodes across all the problem instances 4 .
Thus, the time gap between A * with h pmax and h FF in Logistics (depicted in Figure 4) is exclusively due to the time difference in computing the heuristic values for each search node.
Specifically, if T (p, h) is the overall time taken by A * with h on problem p, then we had avg p∈Logistics {T (p, h pmax )/T (p, h FF )} = 1.8Finally, considering question (3), we have implemented a variant of h pmax , referred in Tables 1-2 as h † pmax , that eliminates the cost partitioning from Eqs.
9-10, all else being equal.
Considering the number of "optimally solved domains" in Table 1, one can notice that A * with h † pmax was still more effective than A * with h FF , and this using very similar numbers of expanded nodes (see Table 2).
Thus, propagating compound cost quantities such as cost vectors does impact the plan-quality effectiveness of the search.
However, Tables 1 also shows that A * with h † pmax was substantially less effective than with h pmax , bringing us to optimal solutions across 5 instead of 12 domains.
We believe this provides a clear evidence for the marginal impact of the cost partitioning (that is, of using the | +s abstraction) on the informativeness of the h pmax heuristic with respect to the optimal problem solving.
We introduced a framework for approximating the optimal cost solutions for classical planning with no delete effects.
This framework, called here cost-sharing, unified some previously suggested approximations, and suggested "importing" some admissible approximations developed for problems of probabilistic reasoning.
While the latter import appeared not to be fruitful, its analysis suggested a way to develop novel approximations that, in particular, appeared to be more informative (in terms of guidance towards solutions of higher quality) than the seminal h add and h FF heuristics.The cost propagation underlying the cost-sharing framework suggests numerous directions for further research.
• In this work, we focused on the "clean room" relaxation | + that completely ignores the delete effects of the actions.
At the next step, it is only natural to look for a semantically-clean and effective way of extending the cost-sharing framework to (selectively) account for negative interactions between the actions.
If developed, the effectiveness of such an extension could be compared to this of some state-of-the-art heuristics that also account for such type of information (e.g, the h m heuristics (Haslum & Geffner 2000), the planning graph heuristics (Nguyen, Kambhampati, & Nigenda 2002), etc.)• We believe that vector-based cost propagation has a potential in developing heuristics for problems with richer metrics of plan quality.
In particular, currently we are looking into extending h pmax to account for penalties and rewards for achieving certain facts (Bonet & Geffner 2006).
• Finally, the search for a more informative than h max , admissible estimate for h + remains challenging, and we hope that our work had shed some new light on this interesting problem.
The authors were partially supported by the C. Wellner Research Fund.
