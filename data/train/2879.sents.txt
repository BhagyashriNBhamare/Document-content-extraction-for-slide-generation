This paper introduces MediaMeter, an application that works to detect and track emergent topics in the US online news media.
What makes MediaMeter unique is its reliance on a labeling algorithm which we call WikiLabel, whose primary goal is to identify what news stories are about by looking up Wikipedia.
We discuss some of the major news events that were successfully detected and how it compares to prior work.
A long term goal of this project is to build a sociologically credible computational platform that enables the user to observe how social agenda evolve and spread across the globe and across the media, as they happen.
To this end, we have built a prototype system we call MediaMeter, which is designed to detect and track trending topics in the online US news media.
One important feature of the system lies in its making use of and building upon a particular approach called WikiLabel (Nomoto, 2011).
The idea was to identify topics of a document by mapping it into a conceptual space derived from Wikipedia, which consists of finding a Wikipedia page similar to the document and taking its page title as a possible topic label.
Further, to deal with events not known to Wikipedia, it is equipped with the capability of re-creating a page title so as to make it better fit the content of the document.
In the following, we look at what WikiLabel does and how it works before we discuss MediaMeter.
WikiLabel takes as input a document which one likes to have labeled, and outputs a ranked list of label candidates along with the confidence scores.
The document it takes as input needs to be in the form of a vector space model (VSM).
Now assume that θ represents a VSM of document d. Let us define l * θ , a likely topic label for d, as follows.l * θ = arg max l:p[l]∈U Prox(p[l], θ| N ),(1)where p[l] denotes a Wikipedia page with a title l and θ| N a VSM with its elements limited to top N terms in d (as measured by TFIDF).
Prox(p[l],θ| N ) is given by:Prox(p[l], θ| N ) = λSr(p[l], θ| N )+(1−λ)Lo(l, θ).
We let:Sr(r, q) = ( 1 + N ∑ t (q(t) − r(t)) 2 ) −1 and Lo(l, v) = ∑ |l| i I(l[i], v) | l | − 1where I(w, v) = 1 if w ∈ v and 0 otherwise.
Sr( x, y) represents the distance between x and y, normalized to vary between 0 and 1.
Lo(l, v) measures how many terms l and v have in common, intended to quantify the relevance of l to v. l [i] indicates i-th term in l. Note that Lo works as a penalizing term: if one finds all the terms l has in v, there will be no penalty: if not, there will be a penalty, the degree of which depends on the number of terms in l that are missing in v. U represents the entire set of pages in Wikipedia whose namespace is 0.
We refer to an approach based on the model in Eqn.
1 as 'WikiLabel.'
We note that the prior work by Nomoto (2011) which the current approach builds on, is equivalent to the model in Eqn.
1 with λ set to 1.
One important feature of the present version, which is not shared by the previous one, is its ability to go beyond Wikipedia page titles: if it comes across a news story with a topic unknown to Wikipedia, WikiLabel will generalize a relevant page title by removing parts of it that are not warranted by the story, while making sure that its grammar stays intact.
A principal driver of this process is sentence compression, which works to shorten a sentence or phrase, using a trellis created from a corresponding dependency structure (e.g. Figure 1).
Upon receiving possible candidates from sentence compression, WikiLabel turns to the formula in Eqn.
1 and in particular, Lo 1 to determine a compression that best fits the document in question.
South-Korea and Japan (the number of stories we covered was 2,230 (US), 2,271 (South-Korea), and 2,815 (Japan)).
Labels in the panels are given as they are generated by WikiLabel, except those for the Japanese media, which are translated from Japanese.
(The horizontal axis in each panel represents the proportion of stories on a given topic.)
Notice that there are interesting discrepancies among the countries in the way they talk about North Korea: the US tends to see DPRK as a nuclear menace while South Korea focuses on diplomatic and humanitarian issues surrounding North Korea; the Japanese media, on the other hand, depict the country as if it had nothing worth talking about except nuclear issues and its abduction of the Japanese.
Table 2 shows how two human assessors, university graduates, rated on average, the quality of labels generated by WikiLabel for articles discussing North-Korea, on a scale of 1 (poor) to 5 (good), for English and Japanese.
Curiously, a study on news broadcasts in South Korean and Japan ( Gwangho, 2006) found that the South Korean media paid more attention to foreign relations and open-door policies of North Korea, while the Japanese media were mostly engrossed with North Korean abductions of Japanese and nuclear issues.
In Figure 2, which reproduces some of his findings, we recognize a familiar tendency of the Japanese media to play up nuclear issues and dismiss North Korea's external relations, which resonate with things we have found here with WikiLabel.
MediaMeter 2 is a web application that draws on WikiLabel to detect trending topics in the US online news media (which includes CNN, ABC, MSNBC, BBC, Fox, Reuters, Yahoo! News, etc).
It is equipped with a visualization capability based on ThemeRiver ( Havre et al., 2002;Byron and Wattenberg, 2008), enabling a simultaneous tracking of multiple topics over time.
It performs the following routines on a daily basis: (1) collect news stories that appeared during the day; (2) generate topic labels for 600 of them chosen at random; (3) select labels whose score is 1 or above on the burstiness scale (Kleinberg, 2002); (4) find for each of the top ranking labels how many stories carry that label; and (5) plot the numbers using the ThemeRiver, together with the associated labels.
Topic labels are placed automatically through integer linear programming ( Christensen et al., 1995).
Figure 4 gives a ThemeRiver visualization of trending topics for the period from July 10 to 23, 2014.
Figures 5 and 6 show views focusing on particular topics, with the former looking at the World Cup and the latter at Malaysia.
The media's attention to the World Cup mushroomed on July 14th, the day when the final match took place, and fizzled out on the following day.
Meanwhile, in Figure 6, there is a sudden burst of stories related to Malaysia on July 17th, which coincides with the day when a Malaysian jetliner was shot down over the Ukrainian air space.
While it is hard to tell how accurately MediaMeter reflects the reality, our feeling is that it is doing reasonably well in picking up major trends in the US news media.
To find where we stand in comparison to prior work, we have done some experiments, using TDT-PILOT, NYT2013, and Fox News corpora.
TDT-PILOT refers to a corpus containing 15,863 news stories from CNN and Reuters, published between July 1, 1994 andJune 30, 1995.
The Fox News corpus has the total of 11,014 articles, coming from the online Fox news site, which were published between January, 2015 andApril, 2015 , 2004).
3 ROUGE-W gives a score indicating the degree of similarity between two strings in terms of the length of a subsequence shared by both strings.
The score ranges from 0 to 1, with 0 indicating no match and 1 a perfect match.
In the experiment, we ran TextRank (TRANK) ( Mihalcea and Tarau, 2004) -the current state of the art in topic extraction -and different renditions of WikiLabel: RM1 refers to a model in Eqn 1 with λ set to 0.5 and sentence compression turned off; RM1/X is like RM1 except that it makes use of sentence compression; RM0 is a RM1 with λ set to 1, disengaging Lo altogether.
Table 3 gives a summary of what we found.
Numbers in the table denote ROUGE-W scores of relevant systems, averaged over the entire articles in each dataset.
Per-document performance@1 means that we consider labels that ranked the first when measuring performance.
One note about FOX.
FOX has each story labeled with multiple topic descriptors, in contrast to NYT and TDT where we have only one topic label associated with each article.
Since there was no intrinsically correct way of choosing among descriptors that FOX provides, we paired up a label candidate with each descriptor and ran ROUGE-W on each of the pairs, taking the highest score we got as a representative of the overall performance.
Results in Table 3 clearly corroborate the superiority of RM0 through RM1/X over TextRank.
In this paper, we looked at a particular approach we call WikiLabel to detecting topics in online news articles, explaining some technical details of how it works, and presented MediaMeter, which showcases WikiLabel in action.
We also demonstrated the empirical effectiveness of the approach through experiments with NYT2013, FOX News and TDT-PILOT.
