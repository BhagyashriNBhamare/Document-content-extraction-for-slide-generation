Programmers can utilize the upcoming non-volatile memory (NVM) technology in various ways.
One appealing way is to directly store critical application data structures in NVM instead of serializing them to block-storage.
Changing legacy code to achieve this, however, is laborious and prone to bugs.
We present NVMOVE, a tool that simplifies this transition by analyzing the source code and automatically identifying persistent types, types that are serialized and persisted.
Aided by this tool, programmers can modify their applications to allocate such persistent types on the non-volatile memory heap.
Upon analyzing Redis, a key-value store with 122 struct types, NVMOVE identifies 25 types as persistent , with no false negatives and 11 false positives.
We evaluate the benefits of NVMOVE by moving the identified persistent types in Redis onto a non-volatile memory heap.
Redis modified in this manner offers full persistence of data, and performs within 78% of Redis with no persistence, achieving more than 2× the performance of Redis that performs logging on SSDs.
Non-Volatile Memory (NVM) provides byte-addressable and low-latency access, enabled by technologies such as Phase Change Memory [12,14,15,16,31], Memristors [27] and Spin-Transfer-Torque MRAM [11].
NVM promises to provide fast, cheap, non-volatile storage at near-DRAM latencies, blurring the line between memory and storage [20].
Moreover, NVM is expected to be available commercially soon, raising the question on how to best leverage this technology.
Programmers have the choice to use NVM as a drop-in replacement for traditional storage.
Currently, applications persist data using a block-based interface to storage.
They first serialize the in-memory data and then write the serialized form to storage; we term this Block-based Persistence (BLP).
BLP suffers from three problems: (a) the performance overhead of serialization, (b) the additional complexity (and resulting bugs) from maintaining both inmemory and in-storage data formats [24,25], and (c) the performance overhead of system calls that invoke * Work performed as an intern at VMware Research Group.
the kernel [2,20].
Alternatively, a new programming model for persistence can access NVM via loads and stores [20,29,30].
Thus, in-memory data structures can be persisted in-place without the need for serialization, assuming some mechanism exists for consistent updates [30].
We term this Byte-based Persistence (BYP) ( § 2).
Researchers have tackled the problem of writing new applications for NVM using the BYP model [30].
However, few projects address the conversion of existing applications from the BLP model to the BYP model.
To convert a BLP program 1 programmers first need to identify the data structures that are serialized and persisted.
Next, they need to allocate such structures on the nonvolatile heap, and make sure the structures are updated in a crash-consistent manner.
Performing this conversion manually is laborious and prone to bugs, and may take a long time.
For example, the open-source project porting the key-value store Redis to NVM has been active for over a year, and it still only supports strings for keys [1].
As a first step towards tackling this problem, we present NVMOVE, a tool that uses static analysis techniques to automatically analyze the source code of a BLP application, and identify the user-defined types that are persisted to storage.
The key observation behind NVMOVE is that any persistent data structure needs to be instantiated and initialized from persistent storage when the application starts or when it recovers from a crash.
We make the following contributions:• We describe our experience in designing and implementing NVMOVE, and discuss the trade-offs between different design approaches ( § 3).
• We evaluate NVMOVE on Redis [19,33].
When compared against a manual port of Redis to NVM, NVMOVE correctly identifies all persistent types, with no false negatives ( § 4.1).
• Using the analysis results from NVMOVE, we emulate transforming Redis into a BYP program with full durability (no data loss on crash), and show that this program outperforms Redis with synchronous logging by up to 2.2× ( § 4.2).
Traditionally, programmers use the BLP model to persist data in two steps: 1) serializing in-memory data, 2) using systems calls such as write to persist the serialized form of data.
Consider the code example in Figure 1c.
It shows a sample program in the BLP model that updates and persists a simple structure: record.
Note how only line 2 actually updates the record; lines 4-9 serialize the record into a temporary buffer buf, and persist it using system calls.
Figure 1c omits the code required to recover to a consistent state in the event of a crash.
The block-based persistence model is a poor fit for NVM for two reasons.
First, the block-based interface is optimized to hide the high latencies of block-storage devices, and has inherent software overheads that can cause large performance issues with NVM [2,20].
The performance overhead of providing persistence via the block interface causes programmers to trade-off safety for performance by reducing persistence frequency.
This strategy is not only vulnerable to possible loss of valuable data, but also causes problems in program recovery 2 .
Second, using the block interface forces serialization of in-memory data into a different format.
Maintaining two versions of the same data structure leads to additional complexity and bugs [24,25].
Both of these problems can be avoided by persisting to NVM using the BYP model.The code example of Figure 1d shows a BYP program that provides similar functionality as the BLP program in Figure 1c.
The BYP program persists the updated state of record directly in NVM.
For this program, the tag @persistent in struct declaration (at line 1 in Figure 1b) is needed to indicate that each instance of struct record should be allocated on the non-volatile heap.
For any instance of record, updating and persisting its state is as simple as directly updating the instance's field in line 2, and flushing the cache (not shown).
Note that a separate mechanism, e.g., transactions, is still needed to guarantee crash consistency [26,30].
NVMOVE analyzes a given application, and identifies user-defined types -structs for C programs -that represent semantically persistent state.
The types that represent the persistent state may be different from the types that are syntactically persisted.
For example, in Fig- ure 1c, we would like to identify record as the persistent type, and not char* (the type of buf).
NVMOVE achieves this goal via static analysis of the source code.Analyzing Recovery Code.
We observe that an application that persists state must restore it during initialization or recovery after a crash.
This leads to the main insight of NVMOVE: any user-defined type that is created or updated in the recovery/initialization phase must be persisted.
NVMOVE requires the programmer to provide the name(s) of the top-level source function(s) that initializes the in-memory application state by reading the previously persisted state.
3 Such functions are called load functions.
This implies that the programmer needs some knowledge of the application, but this knowledge is minimal.
Without NVMOVE, the programmer still needs to identify the load functions when manually porting the code to NVM.
A programmer could manually follow this approach to identify semantically persistent types, but the effort is prone to errors and takes significant time.
For example, our optimized implementation of NVMOVE visits 62 functions in Redis, and parses thousands of lines of code.We restrict our focus to applications that implement the recovery/initialization mechanism in static code and currently do not support applications that initialize their state using function pointers that are dynamically followed.NVMOVE starts the static analysis with an empty set T s used to store the types that are candidates for persistence, and a FIFO queue F q that stores the function names to visit.
At startup, it prompts the programmer to provide the name(s) of the load function, and inserts it in F q .
It then performs the following steps in a loop until F q is empty: it scans the source, and finds the definition of the function f at the head of the queue F q .
It then collects all the variables in f that are assigned or modified through assignment operators, or library calls such as memcpy/memmove.
For each such variable, it inspects its type t and adds it to T s if and only if t is defined in the application source.
If t was already present in the set T s , then it does not need to be added again.
NVMOVE then removes f from F q , and goes to the beginning of the loop.
This analysis is guaranteed to terminate as the application source is finite.
Upon termination, T s contains all the types defined in the application program that NVMOVE identifies as candidates for persistence.Note that marking all the types that are created/modified during initialization is likely to overestimate the persistent variables and may lead to sub-optimal performance.
We want to focus on correctness, and hence compromise on performance.
We optimize this approach by: (a) not parsing through application source functions that either accept no arguments, or accept only nonpointer built-in types, (b) using our knowledge of libc API and treating strcpy/memcpy/memmove and similar functions as assignment operations, (c) not visiting bodies of functions defined in libc API (fopen/fclose for example) whose results and side-effects are known to us, (d) analyzing each function body only once.Back-tracking from Writes.
An alternative approach is to statically identify all the system calls that write to the block-device 4 and follow the data flow backwards to the persistent data structures.
The steps of this method are as follows.
First, system calls can be easily found by parsing the code.
Next, the intermediate buffers used to serialize the data can be retrieved from the arguments of the system calls.
5 Using the knowledge of library functions, such as sprintf (and its variants), we can then back-track through the source-code -recursively visiting caller function definitions -to identify the structures that were serialized into such buffers.
This approach identifies struct record as persistent in Figure 1c.
However, programmers use write calls not only for serializing data to block-devices, but also for logging debug and error messages, writing to pipes, and network sock-4 e.g., write, fwrite, pwrite.
5 In Figure 1c, buf would be identified as the argument that was persisted.ets.
Therefore, this solution produces a large number of false positives for real applications.NVMOVE is implemented using Clang [13] and it currently works on C programs.
However, Clang supports many C-like languages, and thus our approach could be extended to programs in other languages.
We evaluate NVMOVE on the source code of Redis [19,33] (version 3.2.0, 64-bit), a widely-used fast data-structure store that persists its data to block storage.
The Redis codebase currently has ≈ 50K lines of code.We seek to answer the following questions: • How effective is NVMOVE in identifying user-defined types that should be persistent?
• How is Redis performance affected if all the types identified by NVMOVE are persisted in NVM?
Running NVMOVE on Redis source code takes five minutes on average, which suggests that NVMOVE can easily handle large code bases.
Apart from pointing out the load function (rdbLoad), we did not provide NVMOVE with any other information about the code base.To see how effective NVMOVE is at identifying persistent types, we compare the results of NVMOVE with a manual port of Redis performed by an independent industrial team of developers.
They provided us with a list of structs that they treat as persistent in their ported NVM-compatible version of Redis.
Table 1 Without any in-built knowledge of Redis source code, NVMOVE identifies all persistent types, and produces no false negatives.
Among the 11 false positives, four are iterators over persistent types, another four are variants of the same type with different data alignments.
We believe that results produced by NVMOVE can be of significant value to programmers, as they would be able to prune out these false positives upon closer examination.
We evaluate the performance impact of transforming Redis to a BYP program, by emulating non-volatile memory latencies when accessing persistent variables identified by NVMOVE.
The transformed program offers full persistence 6 , but does not have any mechanism for crash consistency.
For full persistence, every NVM write must be followed by a cache line flush (clwb instruction) as well as a PCOMMIT instruction, as described in Intel's recent ISA extensions [10].
We consider two primary NVM technologies: (1) Phase-Change Memory (PCM) representing slower NVM with a read/write latency of 300ns; and (2) SpinTransfer-Torque MRAM (STT-RAM) representing fast NVM with read/write latency of 100 ns.
We set the PCOMMIT latency to 500 ns for PCM and 200 ns for STT-RAM.
The latency of clwb is kept constant at 40 ns.
These latencies are per cache-line, and based on recent literature [32].
We simulate these delays by injecting configurable delay functions in Redis source code after each read/write operation of candidate variables.
This is done by an automated source-to-source transformation using Clang.
Overall, roughly around 4000 delay calls are injected in the source.
Our emulation indicates the worst-case performance.
We expect that performance would be better using real hardware for the following reasons.
First, many reads can be served from the cache, but our emulation assumes that all PCM reads are served from main memory.
Second, writes to the same cache line often need to incur only the cost of a single cache line flush, whereas in our evaluation every write incurs a cache line flush.
Third, multiple cache lines written together often only need to incur the cost of a single PCOMMIT.
Finally, the latencies of non-volatile memory reads and writes can be overlapped better by a memory controller that performs intelligent scheduling [17,22,34], which we do not model.
Our emulation is conservative in these regards and provides an estimated performance that errs towards the worst-case.
We consider two scenarios for performance comparison as Redis provides two modes of persistence: Redis Database (RDB): RDB files are point-in-time snapshots of data at specified intervals.
Redis forks a background process to perform serialization of data to storage.
Redis does not allow sub-second intervals for this mode and thus can lose one second worth of data.
Append Only File (AOF): Redis appends every write command received by the server to the end of a log.
The log is played at startup to reconstruct the original data.
6 On a crash, only the last write in progress could be lost.We first obtain practical upper bounds on performance by running Redis with both of these modes disabled (InMemory Redis).
We then run Redis in a RDB-only mode that takes a snapshot every second.
Next, we disable RDB and run it with AOF that logs every write command and flushes it immediately to block storage (by calling fsync).
Finally, we disable both RDB and AOF and run Redis under the two NVM emulation settings listed above.
We report the throughput results on a machine with 56 Intel Xeon (2.2GHz) cores, and 500 GB DRAM.
In the interest of space, we show baseline results with only SSD block-storage (throughput of AOF with a hard-disk is around one-third of that with SSDs).
For each experiment, we report mean values of five runs.
Results on YCSB.
Figure 2 compares the throughput of Redis when run under the above configurations on the Yahoo Cloud Serving Benchmark (YCSB) [6].
The three workloads tested are: read-heavy (90% reads, 10% updates), balanced (50% reads, 50% updates), and writeheavy (10% reads, 90% updates).
Each run first inserts one million records (of 1 KB each) in an empty database before starting throughput computations.
The speedup in the plot is the ratio of throughput for each setting divided by the throughput of our baseline, which uses the AOF mode on SSD, for the same workload.
The actual values (in operations/second) of baseline SSD throughputs are: 27946 for read-heavy, 17612 for balanced, and 6605 for write-heavy workload.
As expected, Redis without persistence gives the highest throughput.
RDB mode performance is close to optimal since checkpointing is triggered once every second at the most.
However, RDB mode could lose at least 46 MB (read-heavy), 47 MB (balanced), and 27 MB (write-heavy) of data due to its coarse-granularity approach to persistence.
Also, for many runs, the background process saving the snapshot takes more than ten seconds to save the final snapshot after the client disconnects.
Hence, in case of a crash/power-outage the size of lost data can be much larger.
Persisting types identified by NVMOVE yields better performance than baseline, while providing strong durability guarantees: a crash may leave only the latest write incomplete in persistent memory.
Even under the unfavorable delays we test that approximate the worst case, our NVM-emulated persistent Redis with slow PCM has higher throughput than the baseline, and has up to 2× higher throughput with faster STT-RAM.
Results on Redis-benchmark.
We also ran the Redisbenchmark, which ships with the Redis source-code.
There are 17 workloads, many of which are readheavy/read-only.
On several write-heavy workloads (such as MSET,LPUSH,RPUSH), our NVM-emulated persistent Redis is faster by as much as 45% than the baseline (AOF on SSD).
On read-only workloads, such as GET, our Redis is slower by 2-3%, mainly because NVMOVE falsely detects iterators as persistent types, which leads to a minor degradation in read performance.
NVMOVE may over-approximate results because it identifies types, not specific variables.
Even if only one variable among many instances needs to be persisted, the entire type is marked as persistent.
Another problem is that many types contain volatile state in addition to nonvolatile state.
For example, many applications keep reference counts of objects for memory management.
If an object's reference count is initialized during the load of its persisted state, then our analysis will flag the count variable as a persistent pointer.
Despite these limitations, we believe that our tool can be of significant value to programmers in porting a large codebase to byte-based persistence.
Future Work.
We plan to explore other approaches to identifying persistent types to decrease the number of false positives.
We are also working on precise identification of persistent variables, not just types.
In order to do so, we plan to combine our static analysis approach with dynamic/taint analysis.
This would allow us to follow the progression of the persistent variables through the execution of the program.
Converting a BLP program into a BYP program involves many changes, such as removing serialization code and replacing allocation calls for types identified as persistent.
We also would like to update persistent structures in a consistent manner, using techniques such as write-ahead logging [8] and transactions [7].
The vision behind NVMOVE is to allow legacy applications to use persistent memory without significant programmer effort.NVMOVE currently only identifies persistent data structures.
Updating such structures in a consistent manner without significant programmer involvement is a difficult problem.
We aim to address this problem in future work.
Atlas [3] atomically persists all updates between lock() and unlock() in multi-threaded programs.
Atlas targets legacy applications that do not durably store state, and transparently provides atomic persistence for such programs.
In contrast, NVMOVE targets legacy applications that already have protocols to durably store state to a block-device.
NVMOVE is suitable for both single-threaded and multi-threaded applications, and is not limited to applications that use a locking discipline (e.g., those employing lock-free data structures [9]).
ThyNVM [26] transparently checkpoints state of legacy applications onto persistent memory.
ThyNVM requires special hardware support.In contrast, NVMOVE does not require new hardware support, and persisting the data structures identified by NVMOVE can be done using a number of other approaches (e.g., [4,30]) that also do not require specialized hardware.Existing work that builds new systems and APIs on top of persistent memory [4,5,18,21,23,29,30] is complementary to NVMOVE: once NVMOVE identifies the data structures to be made persistent, existing work can be leveraged to persist them in a crash-consistent manner.
All of these systems require significant programmer effort in rewriting the applications using a new API.
A future version of NVMOVE could help alleviate this task.
The emergence of a new technology leads to a flurry of activity to create new applications that exploit its benefits.
It is equally important to consider how existing applications and use-cases can benefit from the new technology as seamlessly as possible.
Many research/opensource projects enable new applications for NVM, but there is little work to port current applications to NVM.
Given the large number of applications written for block storage, easing this transition is vitally important.
We believe NVMOVE is the first step towards easing the transition of programs from block storage to byte-addressable non-volatile memory.
Our preliminary results show promise, and can already be of significant value to programmers.
Continued research and development in this direction will lead to improved solutions that can further reduce the programming effort in adopting NVM.
