We extend the classic online ski rental problem, so that the rental price may change over time.
We consider several models which differ in the knowledge given to the algorithm: whereas the price development is unknown, an algorithm may have full, partial or no knowledge about the duration of the game.
We construct algorithms whose competitive ratios are up to constant or logarithmic factors optimal.
In the classic ski rental problem, a skier may rent skis for p dollars per day or buy them for s · p dollars, where s is an integer greater than one.
At the end of any day, the skier may break his legs along with the skis, or in some other way irrevocably finish skiing.
The goal is to develop an online strategy minimizing the cost of skiing; this cost is compared to the cost of an optimal offline strategy for the same input.
The worst-case ratio between these two amounts is called competitive ratio.A well-known result [11,12] states that the best deterministic online strategy is to rent skis for s − 1 days and then to buy them on day s.
It is easy to check that such a strategy achieves a competitive ratio of (2 − 1/s).
In this paper, we extend this model, so that the rental price p may evolve with time.
Therefore, the instance of the problem includes not only the duration of the process in days, but also a sequence of prices in consecutive days.
However, if we do not impose any constraints on the way the price changes, no algorithm may achieve a competitive ratio better than Ω(s) (even if the process is guaranteed to last infinitely).
To see this, assume that p = 1 at day one.
If the skier buys skis at the first day, then all the future prices are set to 1/s, otherwise they are set to s.
The optimal solution in these cases is to buy at the second day or at the first one, respectively, and the competitive ratio is Ω(s).
Note also that the ratio O(s) is achieved by a trivial algorithm which buys at the first day.
We view the whole process as a game between an algorithm (the skier) and an adversary (breaking-legs and fixing-prices reality).
Hence, we assume that the rate of price changes is bounded, i.e., the price for renting skis at any day is at least 1 and the prices in two consecutive days differ at most by 1.
Apparently, if we use the standard competitive analysis [1], the cost of any online algorithm, which knows neither the future prices nor the game duration, is rather high in comparison to the optimal offline solution.
Therefore, we investigate other scenarios, in which the algorithm has full or partial knowledge about the game duration.
We want to emphasize that in all cases, the algorithm does not know the future prices.
In particular, we consider a hybrid scenario in which the duration of the game is a random variable, corresponding to the following natural model: each day a skier quits with probability 1/Γ and continues skiing with probability 1 − 1/Γ .
In effect, an input sequence in such a scenario is generated partially by an adversary and partially by a stochastic process, and we measure the performance of an algorithm by a mixture of the average-case and competitive analysis.In this paper, we consider a continuous variant of the problem.
Namely, the prices are given as a continuous curve satisfying the Lipschitz condition and the skier is renting skis up to time T when he buys them (T is possibly a non-integer).
This hardly changes the problem; the calculations in the continuous model are simpler though.
Moreover, we show that our algorithms can be modified to work in the discrete model without increasing their competitive ratios.
A parameter of the problem is a real number s > 1, representing the ratio between the cost of buying skis and renting them.We assume that the input instance is a pair of an infinite curve of prices and a game duration.
The former is a continuous function p t ≥ 1 satisfying the Lipschitz condition, i.e., for any two times t 0 and t 1 , it holds that |p t1 − p t0 | ≤ |t 1 − t 0 |.
The latter is a real positive number γ.In online analysis, the input is revealed to an algorithm element by element: in the discrete counterpart of the problem, the algorithm would be given prices in consecutive days and may react after reading any of them.
We would like to formulate algorithms in a similar manner, i.e., by saying, for example, that "the algorithm waits for the price p to reach a given threshold".
While we use such phrases in the paper, we note that they can be justified without having the algorithm to process infinite number of input elements.
For example, the algorithm may choose a small probing frequency ε > 0, read the price curve at times 0, ε, 2ε, 3ε . . . and, at these times, make a decision whether to buy skis.
The last value presented to the algorithm is then the price at time γ ε · ε.
As the price curve satisfies the Lipschitz condition, for a small value of ε this read model gives the algorithm essentially the same power as the model in which it is possible to buy skis at any time.Fix any input curve p t and the game duration γ.
For any T , let F(T ) = T t=0 p t dt and let Buy(T ) be an algorithm which buys at time T .
In particular, Buy(∞) is an algorithm which always rents.
Then its cost is equal to The cost of the optimal offline solution, Opt, isC BUY(T) = F(T ) + s · p T if T ≤ γ , F(γ) if T > γ .
C OPT = min 0≤T ≤∞ C BUY(T) .
For any deterministic algorithm Alg, we say that Alg is R-competitive if for any input it holds that C ALG /C OPT ≤ R.
If the algorithm is randomized, we replace C ALG by its expected value.
For randomized algorithms, we assume oblivious adversaries, which do not see random bits used by the algorithm.We consider several scenarios, which differ in the knowledge given to the algorithm.Scenario A: Unknown game end.
This is the most straightforward case, in which the adversary dictates both price curve p t and game duration γ, and an algorithm learns γ at the end of the game.
For this scenario, in Sect. 2, we give a deterministic O( √ s)-competitive algorithm.
This ratio is asymptotically optimal as we present an up to a constant factor matching lower bound, which holds even for randomized algorithms.
Scenario B: Known game end.
In this scenario, the adversary defines both a price curve and duration γ, but the algorithm learns γ at the very beginning and can adjust its behavior accordingly.
For describing our results, we define a function L as in Fig. 1.
In Sect. 3, we construct an algorithm Prot which is O(L(log s γ))-competitive for Scenario B.
This means that for the worst possible choice of γ, we achieve a competitive ratio of O(s 2/5 ).
We provide a matching lower bound for any value of γ and any randomized algorithm in Sect. 4.
Scenario C: Stochastic game end.
In this scenario, the adversary defines a price curve and a parameter Γ ≥ 1, which is revealed to the algorithm at the very beginning.
Then the game duration γ is chosen randomly according to the exponential distribution with parameter Γ .
The algorithm learns the game end at time γ.
As mentioned above, this is a continuous counterpart of the following natural model: the probability of breaking a leg is 1/Γ each day, i.e., the expected duration is Γ .
Such modeling of the input builds another bridge between the average-case and competitive analysis.
In Sect. 3.3, we show that if we run an appropriately parameterized version of Prot, the expected value of its competitive ratio is O(L(log s Γ ) · (log s) 7/9 ).
We note that asymptotically the same results hold if we consider uniform distribution over interval [0, 2Γ ], i.e., with the same expected duration Γ .
Finally, we show that our algorithms for the continuous model can be adjusted to work in the discrete model with asymptotically the same competitive ratios.
For the classic ski rental problem (SRP), the competitive ratio of the best deterministic online algorithm is 2 − 1/s [11,12].
If we allow randomization, then this ratio can be reduced to e/(e − 1) ≈ 1.58 [10].
Similar constructions achieving optimal ratios (2 for the deterministic case and e/(e−1) for the randomized one) were shown for related rent-or-buy problems like the Bahncard problem [6,9], the spin-block problem [10], or the TCP acknowledgement problem [3,9].
In the multi-slope SRP [2,13], the buyer may switch between many lease options (r i , w i ), where r i is the startup cost for using this option and w i is the fee paid each day.
In these terms, the classic SRP means a binary choice between the pure rental option (0, p) and the pure purchase option (s · p, 0).
The SRP was also analyzed in an average-case: Fujiwara and Iwama [7] considered the case where the game duration is determined by a stochastic process and the goal is to minimize the expected value of the competitive ratio.
In particular, they proved that if the duration is an exponentially distributed (with parameter Γ ) random variable, the optimal strategies are either to rent forever if Γ ≤ s or to buy skis at day s 2 /Γ if Γ > s.For other successful applications of the competitive analysis where an input is generated randomly, see, e.g., [8] and the references therein.
However, in contrast to these papers, we consider a model in which the input is not chosen purely randomly, but partially randomly and partially by an adversary.
Our performance metric for the third scenario (the expected value of the competitive ratio) is thus similar in flavor to the smoothed competitive ratio [14].
To our best knowledge, the SRP was not analyzed in a model in which prices may change over time.
This problem is loosely related to various versions of currency trading (see, e.g., [5,4]).
Due to different focus and assumptions, algorithmic ideas developed there do not seem to apply to our problem.
In this section, we present a simple deterministic algorithm Thresh for Scenario A.
In period [0, √ s), Thresh always rents.
Then, it buys skis at the firsttime k ≥ √ s, such that F(k) ≥ s. Theorem 1.
Thresh is O( √ s)-competitive for Scenario A.Proof.
Let γ be the duration of the game.
Let k be the time of skis purchase or k = γ if Thresh does not buy skis.
To show the theorem, we relate the costs of Thresh and Opt to F(k), proving the following two relations.1.
C THRESH = O( √ s) · F(k).
If Thresh does not buy skis, then k = γ and the relation holds trivially.Otherwise, C THRESH = F(k) + s · p k .
By the definition of the algorithm,F(k) ≥ s and k ≥ √ s.
If p k ≤ 2 · √ s, then F(k) ≥ √ s · p k /2.
If p k > 2 · √ s, then in period [k − √ s, k] the price is at least p k − √ s > p k /2, and thusF(k) > √ s · p k /2 as well.
2.
C OPT ≥ F(k)/2.
This relation clearly holds if Opt rents forever or buys skis at time k or later.
Thus, we assume that Opt buys skis at time < k, paying at least s · p .
We consider two cases.
(a) k > √ s. By the construction of Thresh, F( √ s) < s, and thusF(k) ≤ s ≤ C OPT .
(The first inequality is strict only in case k = γ.)
(b) k ≤ √ s.
As any two prices in period [0, k] can differ at most by k, we obtain F(k) = k 0 p t dt ≤ k 0 (p + k) dt = k · p + k 2 ≤ 2 · s · p ≤ 2 · C OPT .
It appears that the achieved competitive ratio is asymptotically optimal, even for randomized algorithms.Theorem 2.
In Scenario A, the competitive ratio of any randomized algorithm is Ω( √ s).
In this section, we construct an algorithm Prot λ which we further analyze in Scenarios B and C; λ is a parameter of the algorithm.
The algorithm performs well if λ = γ.
This can be guaranteed in Scenario B; in Scenario C, we know only that E[γ] = Γ , and hence we choose λ close to Γ .
For any values of λ and γ, let R(λ, γ) be the competitive ratio of Prot λ run on a sequence of length γ.
Then, the actual competitive ratio of Prot in Scenario B is R(γ, γ) and the expected value of the competitive ratio inScenario C is E γ [R(λ, γ)].
Description of the Algorithm.
The behavior of algorithm Prot λ depends on the parameter λ.
We think of λ as the algorithm's estimate of the game duration γ.
As in the classic ski rental problem, we want to amortize the cost of skis purchase against the cost of their rental, e.g., to buy if we already rented for time Θ(s).
For example, if λ is small, it makes little sense to buy skis.
However, the fluctuation of the prices may trigger the purchase also at some other points of the time.We give an informal rationale for algorithm Prot s run on an input of length s.
The algorithm has to protect itself against two different types of inputs.
An input may contain a time point with a low price, giving Opt the possibility to buy for this price.
To cope with such inputs, Prot s chooses a threshold A and buys skis when the price falls below A.
The second threshold is less intuitive.
Assume that the price grows for the whole input.
In this case, the optimal solution is to buy as early as possible.
On the other hand, the total cost of renting skis grows quadratically with time (at least from a certain point).
To protect against such inputs, Prot s uses the second threshold B; it buys skis when the price goes above B.Although it is not necessary in Scenario B, the algorithm never buys skis (even if thresholds are reached) in period [0, 1).
The reason for this stems from Scenario C: in this case, if we just used thresholds A and B, the adversary could trigger the skis purchase of Prot at time 0, i.e., C PROT = s·p 0 .
For any Γ , it can happen (with non-negligible probability) that the sequence ends at time ε 1.
1 In this case, C OPT ≈ ε · p 0 , and the competitive ratio is very high.Taking these intuitions into account, we formally define the algorithm.
Prot λ uses two thresholds: A and B, which are depicted in Fig. 1 and defined as follows.λ = s y [0, s 2/3 ) [s 2/3 , s 4/5 ) [s 4/5 , s) [s, ∞) A 1/2 s (3/2)y−1 s (2y−1)/3 s 1/3 B ∞ ∞ s (y+1)/3 s 2/3If at time t ≥ 1 price falls outside range (A, B), then Prot λ buys at this price.
Otherwise, if the price remains in range (A, B) for the period [1, s], then Prot λ buys at time s.Note that as all the prices are at least 1, for λ ≤ s 2/3 , the strategy of Prot λ is just to rent for the whole period [0, s) and to buy at time s (if the game lasts till this time).
γ < 1, then R(λ, γ) = O(1).
Therefore, in the remaining part of this section, we assume that γ ≥ 1.
For making our arguments concise, we consider a restricted version of Opt which is not allowed to buy in period [0, 1).
Such a restriction increases its cost at most by a constant factor, and can be neglected as we are interested in the asymptotic performance.
We start with a classification of input curves and we characterize the behavior of Prot on them.with parameter k, either k = 1 and p 1 ≤ a, or k ≥ 1 and p k = a.
An analogous relation holds for (a, b)-high sequences.Throughout this section, we assume that γ ≥ 1 is the duration of the game, and A < B are the thresholds used by Prot λ .
We present three lemmas describing the algorithm behavior on the corresponding three types of input sequences.
For succinctness, we defineM A,B,γ = min B A , 1 + γ 2 s · A .
(1)In the following three lemmas, we characterize the behavior of Prot on different types of sequences.
Proofs of the second and third ones are relatively similar, and hence we omit one of them.
Proof.
If γ < k, then the prefix of the input seen by the algorithm is (A, B)-middle, and thus the competitive ratio is at most O(M A,B,γ ).
Below, we assume that γ ≥ k. By the definition, C PROT = F(k) + s · p k .
The main complication is that p k is not necessarily equal to B, as the input sequence may simply start with a very high price.
, which actually appears in the game.
Opt either rents skis in this period paying at least min{k + B/2, γ} · (p k − B/2) = Ω(min{B, γ} · p k ), or buys skis in this period paying at least s · (p k − B/2) = Ω(s · p k ).
Thus, the competitive ratio in this case isC PROT C OPT ≤ 1 + F(γ) s · A ≤ 1 + γ · A + γ 2 /2 s · A = O 1 + γ 2 s · A .
C PROT C OPT = O s · p k min{B, γ, s} · p k = O 1 + s γ + s B .
(2)2.
If k > B/2, then p k = B.
We consider two subcases.
(a) Opt buys skis in the period [1, k].
Then C OPT ≥ s · A, C PROT ≤ k · B + s · B ≤ 2 · s · B,and thusC PROT C OPT = O(B/A) .
(3)(b) Opt rents skis in the period [1, k].
Note that during period [k − B/2, k] the price remains above B/2.
Thus, C OPT ≥ F(k) and C OPT = Ω(B 2 ).
The competitive ratio is then bounded byC PROT C OPT = O F(k) + s · B F(k) + B 2 = O(s/B) .
(4)By combining (2), (3), and (4), we obtain the lemma.
If we look at thresholds A and B of Prot λ , it appears that for particular choices of parameter λ, we can restrict the input types that may appear during Prot λ execution.
For example, if s 2/3 ≤ λ < s 4/5 , B = ∞, and thus the input can be only (A, B)-low or (A, B)-middle.
Applying the results of Lemmas 1, 2, and 3, we immediately get the following theorem.
if y ≥ 1 .
In Scenario B, the algorithm knows the game duration γ and by running Prot γ , we may achieve the desired competitive ratio.
Corollary 1.
The competitive ratio of Prot γ on an input of length γ is at most O(L(log s γ)).
For Scenario C, we analyze the performance of Prot run on an input, whose length is an exponentially distributed random variable γ ∼ Exp(Γ ).
The density function of this distribution is f (x) = 1 Γ · e −x/Γ for x ≥ 0.
The following properties hold.Observation 2 If f (x) is the probability density function of the exponential distribution with parameter Γ ≥ 1,then ∞ 0 x · f (x) dx = Γ , ∞ 0 x 2 · f (x) dx = O(Γ 2 ), and ∞ 1 1 x · f (x) dx = O( log Γ Γ ).
As mentioned earlier, Prot performs well if λ corresponds to the game duration γ.
In Scenario C, this can be fulfilled only in expectation, e.g., by settingλ = Γ = E[γ].
Theorem 4.
For any Γ ≥ 1, the expected value of competitive ratio of Prot Γ run on a sequence of length γ ∼ Exp(Γ ) is O(L(log s Γ ) · log Γ ).
Proof.
Let f be the density function of the exponential distribution.
We want to upper-bound the value ofE γ [R(Γ, γ)] = ∞ 0 R(Γ, γ) · f (γ) dγ = O(1) + ∞ 1 R(Γ, γ) · f (γ) dγ ,where the second equality follows by Observation 1.
Recall, that by Theorem 3, R(Γ, γ) is a sum of terms, where each term is a linear function of γ c for c ∈ {−1, 1, 2}.
Therefore, by Observation 2, we obtain∞ 1 R(Γ, γ) · f (γ) dγ = O(R(Γ, Γ ) · log Γ ) .
As R(Γ, Γ ) = O(L(log s Γ )), this finishes the proof.The theorem above means that we pay an additional factor of log Γ in the competitive ratio for not knowing the exact end of the game, but only its expected value.
Roughly speaking, the algorithm pays more because there is a quite big probability that γ E[γ].
For such cases, the thresholds chosen by Prot are too large, which leads to poorer performance.
On the other hand, the effects of underestimating γ are more benign.
Hence, it appears that the expected value of the competitive ratio can be improved if we choose slightly smaller value of parameter λ of the algorithm Prot.Theorem 5.
Fix any Γ ≥ 1 and let λ = Γ/(log s) 1/3 .
Then the expected value of the competitive ratio of Prot λ run on a sequence of length γ ∼ Exp(Γ ) is O(L(log s Γ ) · (log s) 7/9 ) for Γ ∈ (s 2/3 , s · log s) and O(L(log s Γ )) for remaining values of Γ .
Finally, we observe that since in the proofs of Theorems 4 and 5, we base our reasoning entirely on Observation 2, the same results hold also for all probability distributions for which this observation holds, e.g., for a uniform distribution over the interval [0, 2Γ ].
In this section, we show that Prot γ achieves an asymptotically optimal competitive ratio on inputs of length γ.
Moreover, we show show that this lower bound holds even for randomized algorithms against an oblivious adversary.Theorem 6.
Fix any γ.
In Scenario B, the competitive ratio of any randomized algorithm (knowing γ) is at least Ω(L(log s γ)).
Proof.
Let y = log s γ, i.e., γ = s y .
For y < 1/2, the lower bound of Ω(L(y)) = Ω(1) follows trivially, thus we assume that y ≥ 1/2.
To show the theorem, we use Yao min-max principle [15].
Let f = min{y, 1}.
Let a be a non-negative number satisfying a ≤ f /2 and a ≤ 2f − 1; we will specify the exact value of a later.We call an input curve α-peaky if the price starts at s a , increases till it achieves level α, then drops to level 1 and remains there.
Formally,p t = s a + t if t ≤ α − s a , max{α − (t − α + s a ), 1} if t > α − s a .
We construct the following probability distribution π over input curves.
With probability 1/3, the input presented to the algorithm is 1 2 s f /2 -peaky and with probability 1/3, it is s f -peaky.
The remaining probability 1/3 is distributed uniformly over α-peaky inputs for α ∈ ( 1 2 s f /2 , s (1+a)/2 ).
This means that the probability density function isf (α) = 1 3 · s (1+a)/2 − 1 2 s f /2 −1 = Θ(s −(1+a)/2 ) for α ∈ 1 2 s f /2 , s (1+a)/2 .
Note that π contains only α-peaky curves for which α ≤ γ.
This guarantees that the curve of length γ achieves its peak; however for large α the decreasing part of the curve may be shortened or not occur.On an α-peaky curve from π, the algorithm which always rents pays O(α 2 + s f ) and the algorithm which buys at the very beginning pays s · s a .
Thus, on such an α-peaky curve, C OPT = O(min{α 2 + s f , s 1+a }).
On the other hand, an online algorithm does not know α, and cannot choose optimally between these two strategies.We want to analyze the best deterministic algorithm Det and its performance on an input chosen randomly according to the probability distribution π.
Let C DET (α) and C OPT (α) be the costs of Det and Opt, respectively, on an α-peaky input.
(5) Then, by the Yao min-max principle, the competitive ratio R of any randomized algorithm against an oblivious adversary is at leastE π C DET C OPT = 1 3 · C DET ( 1 2 s f /2 ) C OPT ( 1 2 s f /2 ) + 1 3 · C DET (s f ) C OPT (s f ) + s (1+a)/2 1 2 s f /2 C DET (α) C OPT (α) f (α) dαE π [C DET /C OPT ].
Essentially, Det has the following options.
It may opt for the always-rent strategy or it may choose a parameter r ∈ [s a , s f ] and buy if the price achieves r.
If the price starts to drop before it hits level r, it does not make sense for Det to buy skis in the remaining period, as this cost would be greater then renting skis till time γ.
We analyze this behavior in four cases below.1.
Det chooses r ∈ [s a , 1 2 s f /2 ).
With probability 1/3, the input curve is 1 2 s f /2 -peaky.
For such an input, C DET ≥ s · s a andC OPT = O(( 1 2 s f /2 ) 2 + s f ) = O(s f ).
As all the terms occurring in (5) are non-negative, we may omit some of them, obtainingR ≥ 1 3 · C DET ( 1 2 s f /2 ) C OPT ( 1 2 s f /2 ) = Ω s 1−f +a .
(6) 2.
Det chooses r ∈ [ 1 2 s f /2 , 1 2 s (1+a)/2 ).
For α-peaky inputs with r ≤ α ≤ s (1+a)/2 , C DET (α) ≥ s · r and C OPT (α) = O(α 2 + s f ) = O(α 2 ).
Then, R ≥ s (1+a)/2 r C DET (α) C OPT (α) f (α) dα = Θ s −(1+a)/2 · s (1+a)/2 r s · r α 2 dα = Θ s −(1+a)/2 · s · r r − s · r s (1+a)/2 = Θ(s −(1+a)/2 ) · (s − s/2) = Θ(s (1−a)/2 ) .
(7) 3.
Det chooses r ∈ [ 1 2 s (1+a)/2 , s f ].
With probability 1/3, the input is s f -peaky.
For such an input, C DET ≥ s · 1 2 s (1+a)/2 and C OPT = s · s a .
In this case,R ≥ 1 3 · C DET (s f ) C OPT (s f ) = Ω s (1−a)/2 .
(8)4.
Det never buys skis.
On an s f -peaky input, C DET = Ω((s f ) 2 ), and thereforeR ≥ 1 3 · C DET (s f ) C OPT (s f ) = Ω s 2f −1−a .
(9)For any fixed y and a, Det may freely choose one of the strategies above.
Thus, by (6), (7), (8), and (9),R = Ω min s 1−f +a , s (1−a)/2 , s 2f −1−a .
Finally, the adversary may choose a to maximize the ratio R. Therefore, in all cases R = Ω(L(y)), which concludes the proof.
This paper extends the classic ski rental problem in a way where the rental price may change each day.
Although the ski rental may be perceived as a toy example, the underlying rent-or-buy structure can be found in many other problems.
We believe that our preliminary work can contribute to developing solutions for these problems when they are analyzed in a dynamic setting.
A natural example would be the TCP acknowledgement problem [3], where the varying traffic on the link is modeled by changes in the cost associated with sending acknowledgements.
Moreover, if our algorithms can be adapted for such network problems, their simplicity ensures that they could be used in constrained devices.
Proof (of Theorem 2).
For this lower bound, we employ the Yao min-max principle [15], i.e., we construct a probability distribution π over inputs and show that on expectation no deterministic algorithm can achieve better competitive ratio.Our approach uses only prices from the range [1, √ s + 1].
The price curve is fixed: p t = 1 + min{t, √ s}.
The game duration γ is chosen randomly.
With probability 1/2, γ = ∞.
The remaining probability is distributed uniformly in the range [0, √ s], i.e., the density function is equal to f (x) = 1/(2 · √ s) in this range and 0 outside.
We look at a deterministic algorithm Det, which is the best algorithm against this distribution.
Let C DET (γ) be the cost of Det, provided it is run on a sequence of length γ.
We use an analogous definition for Opt.
By the Yao min-max principle, it follows that the competitive ratio R of any randomized algorithm is at least the expected performance of Det, i.e.,R ≥ E π C DET C OPT = 1 2 · C DET (∞) C OPT (∞) + √ s 0 C DET (γ) C OPT (γ) f (γ) dγ .
We consider two cases.
Thus, R = Ω( √ s) in this case.
2.
Det chooses to buy skis at time r ≤ √ s/2.
(Note that it actually buys when γ ≥ r.) On the other hand, the cost of an algorithm that always rents is O(γ 2 ).
Thus, C OPT (γ) = O(γ 2 ) and we getR ≥ √ s r C DET (γ) C OPT (γ) f (γ) dγ = Ω(1) · 1 2 · √ s · √ s r s · r γ 2 dγ = Ω(1) · 1 2 · √ s · s · r · 1 r − 1 √ s = Ω( √ s)In either case, R = Ω( √ s), and the theorem follows.Proof (of Observation 1).
The price in the period [0, γ] remains between p 0 − 1 andp 0 + 1.
Thus, C PROT ≤ γ · (p 0 + 1) = O(γ · p 0 ).
If Opt always rents, it pays the same amount as Prot.
Otherwise, it pays at least s · (p 0 − 1) = Ω(γ · p 0 ).
Proof (of Lemma 2).
If γ < k, then the prefix of the input seen by the algorithm is (A, B)-middle, and thus the competitive ratio is at most O(M A,B,γ ).
If γ ≥ k, then Prot rents in period [1, k), and then buys at time k paying at most s · A.
The rental price in this period is between A and min{k + A, B}.
Thus, C PROT = F(k) + s · A ≤ k · min{k + A, B} + s · A.One of the following cases occurs.1.
Opt buys skis in period [1, k), paying at least s · A.
In this case, the competitive ratio isC PROT C OPT ≤ 1 + k · min{k + A, B} s · A = O min B A , 1 + k 2 s · A .
(10)2.
Opt rents skis in period [1, k), paying F(k).
In the remaining period [k, γ], it either keeps renting or buys skis, i.e., pays at least min{γ −k, s}.
In this case, the competitive ratio is (F(k) + s · A)/(F(k) + min{s, γ − k}).
We consider two subcases.
(a) If k ≤ γ < 2 · k, then C PROT C OPT ≤ F(k) + s · A F(k) ≤ 1 + s · A k · A = 1 + s/k = O(1 + s/γ) .
(11) (b) If γ ≥ 2 · k, then C PROT C OPT ≤ s · A min{s, γ − k} ≤ A + s · A γ − k = O(A + s · A/γ) .
(12)By combining (10), (11), and (12), we obtain the lemma.Proof (of Observation 2).
Let X be an exponentially distributed (with parameter Γ ) random variable.
Then E[X] = Γ and variance of X, Var(X) = Γ 2 .
By the definition, ∞0 x·f (x) dx = E[X], which proves the first equality.
For proving the second one, we note that ∞ 0x 2 · f (x) dx = E[X 2 ] = (E[X]) 2 + Var(X) = 2 · Γ 2 .
We prove the third relation by a direct calculation:∞ 1 1 x · f (x) dx = 1 Γ ∞ j=0 (j+1)·Γ +1 j·Γ +1 1 x · 1 e x/Γ dx ≤ 1 Γ ∞ j=0 1 e j (j+1)·Γ +1 j·Γ +1 1 x dx = 1 Γ ∞ j=0 1 e j · ln (j + 1) · Γ + 1 j · Γ + 1 ≤ 1 Γ ∞ j=0 1 e j · ln(Γ + 1) = O(1) · log Γ Γ .
In this section, we show that any algorithm for continuous model can be turned into an algorithm for the discrete model with asymptotically the same competitive ratio.Theorem 7.
For any algorithm Cont that is R-competitive in the continuous model, there is an algorithm Disc that is 3 · R-competitive in the discrete model.Proof.
We fix any discrete infinite sequence of prices I = p 1 , p 2 , p 3 , . . . and we construct an algorithm Disc which performs well on this sequence.
First, we create a curve of prices I = p t , by setting p 0 = p 1 + 1 and p t = p t + 1 for any integer t ≥ 1, and later connecting the values at integral points with segments.
As the prices in two consecutive days differ at most by 1, the created input curve I satisfies the Lipschitz condition, and henceC CONT (I ) ≤ R · C OPT (I ) .
(13)The algorithm Disc runs Cont on I (note that I can be created in online fashion) and if Cont buys skis at time t , then Disc buys skis at day t = t .
First, we show thatC DISC (I) ≤ C CONT (I ) .
(14)To this end, observe that for any t ≥ 1, the price for renting at day t in the discrete model is at most the price for renting in the period of (t − 1, t] in the continuous model, i.e., p t ≤ t t−1 p x dx.
Assume that the sequence ends at day γ.
If Cont does not buy (in the period [0, γ]), Disc does not buy either, and (14) holds.
If Cont buys at time t ≤ γ, Disc buys at time t ≤ γ, and thenC CONT (I ) = F(t) + s · p t ≥ F(t) + s · (p t − 1) ≥ t−1 i=1 p i + s · p t = C DISC (I).
Second, we show that C OPT (I ) ≤ 3 · C OPT (I) .
(15)Observe that as the rental price is always at least 1 and I satisfies the Lipschitz condition, for any day t it holds that p t−1 ≤ p t + 2 ≤ 3 · p t andF(t) = t 0 p x dx = t i=1 i i−1 p x dx ≤ t i=1 (p i + 2) ≤ 3 · t i=1 p i .
LetOff be an offline algorithm for I that buys skis at time t − 1 if Opt for I buys skis at time t. Assume that the sequence ends at day γ.
If Opt does not buy skis, Off does not buy them either.
Then,C OFF (I ) = F(γ) ≤ 3 · γ i=1 p i = 3 · C OPT (I).
If Opt buys skis at day t ≤ γ, then C OFF (I ) = F(t−1)+s·p t−1 ≤ 3· t−1 i=1 p i +3·s·p t = 3·COPT (I).
Thus, in either case C OPT (I ) ≤ C OFF (I ) ≤ 3 · C OPT (I), and thus (15) holds.The theorem follows immediately by combining (13), (14), and (15).
In this section, we consider Scenario C again, and we show that if Prot uses parameter λ = Γ/(log s) 1/3 instead of λ = Γ , then it achieves a better competitive ratio.
We recall that by Theorem 3, for any λ and γ, it holds that We denote the integral above by K and compute it using Observation 2.
If Γ/c < s 2/3 or Γ/c ≥ s, the lemma follows immediately.
When Γ/c ∈ [s 2/3 , s 4/5 ),K = O (Γ/c) 3/2 s + (Γ/c) 3/2 · log Γ Γ + Γ 2 (Γ/c) 3/2 = O Γ 1/2 · log s c 3/2 + c 3/2 = O Γ 1/2 · (log s) 1/2 .
Finally, when Γ/c ∈ [s 4/5 , s),K = O 1 + (Γ/c) · log Γ Γ · s 2/3 (Γ/c) 1/3 = O s 2/3 Γ 1/3 · (log s) 7/9 .
Proof (of Theorem 5).
Let c = (log s) 1/3 .
We combine Corollary 2 and Lemma 4 to compute the ratio E γ [R(Γ/c, γ)]/R(Γ, Γ ), further denoted by B. First, we observe that for Γ < s 2/3 , B = O(1), and for Γ ≥ s · log s, B = O(1 + (s · log Γ )/Γ )) = O(1).
Second, we show that for the remaining values of Γ , it holds that B = O((log s) 7 Finally, the proof is concluded by noting that R(Γ, Γ ) = O(L(log s Γ )).
