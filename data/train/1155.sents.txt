By combining algorithmic learning, decision procedures, predicate abstraction, and simple templates, we present an automated technique for finding quantified loop invariants.
Our technique can find arbitrary first-order invariants (modulo a fixed set of atomic propositions and an underlying SMT solver) in the form of the given template and exploits the flexibility in invariants by a simple randomized mechanism.
The proposed technique is able to find quantified invariants for loops from the Linux source, as well as for the benchmark code used in the previous works.
Our contribution is a simpler technique than the previous works yet with a reasonable derivation power.
Recently, algorithmic learning has been successfully applied to invariant generation.
The new approach formalizes the invariant generation problem as an instance of algorithmic learning: to generate an invariant is to learn a concept from a teacher.
Using a learning algorithm as a black box, one only needs to design a mechanical teacher that guides the learning algorithm to invariants.
The learning-based framework not only simplifies the invariant generation algorithms, the new approach can also automatically generate invariants for realistic C loops at a reasonable cost [15].
Figure 1 shows the new framework proposed in [15].
In the figure, the CDNF algorithm is used to drive the search of quantifier-free invariants.
The CDNF algorithm is an exact learning algorithm for Boolean formulae.
It computes a (Grant 2010-0001717).
This work was partly supported by MoE Tier-2 grant R-252-000-411-112 and by the National Science Council of Taiwan projects No.
NSC97-2221-E-001-003-MY3, NSC97-2221-E-001-006-MY3, the FORMES Project within LIAMA Consortium, and the French ANR project SIVES ANR-08-BLAN-0326-01 Fig. 1.
The learning-based framework representation of an unknown target formula by asking a teacher two types of queries.
A membership query asks if a valuation to Boolean variables satisfies the unknown target; an equivalence query asks if a candidate formula is equivalent to the target.
With predicate abstraction, the new approach formulates an unknown quantifier-free invariant as the unknown target Boolean formula.
One only needs to automate the query resolution process to infer an invariant.If an invariant was known, a mechanical teacher to resove queries can be implemented straightforwardly.
In the context of invariant generation, no invariant is known.
However, a simple randomized automatic teacher is proposed in [15].
With the help of SMT solvers, user-provided annotations, and coin tossing, one can resolve both types of queries by a simple reduction to the satisfiability problem of quantifier-free formulae.
An ingenious feature of this design is its random walk.
Due to the lack of information, some queries cannot be resolved decisively.
In this case, the teacher simply gives a random answer.
The learning algorithm will then look for invariants consistent with both decisive and random answers from the teacher.
Since there are sufficiently many invariants for an annotated loop in practice, almost certainly the learning algorithm can find one.The work [15] has, however, one obvious limitation; it can only generate quantifier-free invariants.
Yet loops iterating over arrays often require invariants quantified over indices.
It will be very useful to extend the new approach to quantified invariants.
However, a na¨ıvena¨ıve extension would not work.
First of all, it is not clear how to associate an arbitrarily quantified formula with a quantified Boolean formula.
There is no counterpart (a Boolean formula) for quantified variables in, say, ∀i.i > 10.
Second, there is no exact learning algorithm for quantified Boolean formulae to the best of our knowledge.
Even if an abstraction for quantified formulae was available, we could not adopt the same learningbased framework.
Third, computability issues must be addressed because the satisfiability problem for arbitrarily quantified formulae is undecidable.
Developing an effective invariant generation algorithm for quantified invariants is therefore an interesting challenge to the learning-based framework.This article is about our findings in generating quantified invariants with algorithmic learning:-We show that a simple combination of algorithmic learning, decision procedures, predicate abstraction, and templates can automatically infer quantified loop invariants.
The technique is as powerful as the previous approaches [9,20] yet is much simpler.
-The technique needs a very simple template such as "∀k.[]" or "∀k.∃i.[].
"Our algorithm can generate any quantified invariants expressible by a fixed set of atomic propositions in the form of the given template.
Moreover, the correctness of generated invariants is verified by an SMT solver.
-The technique works in realistic settings: The proposed technique can find quantified invariants for some Linux library, kernel, and device driver sources, as well as for the benchmark code used in the previous work [20].
-The technique's future improvement is free.
Since our algorithm uses the two key technologies (exact learning algorithm and decision procedures) as black boxes, future advances of these technologies will straightforwardly benefit our approach.
In order to illustrate how our algorithm works, we briefly describe the learning process for the max example from [20].
Template and Atomic Propositions A template and atomic propositions are provided manually by user.
We provide the template ∀k.[].
The postcondition is universally quantified with k and gives a hint to the form of an invariant.
By extracting from the annotated loop and adding the last two atomic propositions from the user's guidance, we use the following set of atomic propositions:{m = 0 ∧ i = 0} while i < n do if a[m] < a[i] then m = i fi; i = i + 1 end {∀k.k < n ⇒ a[k] ≤ a[m]}{i < n, m = 0, i = 0, a[m] < a[i], a[k] ≤ a[m], k < n, k < i}.
Query Resolution In this example, 20 membership queries and 6 equivalence queries are made by the learning algorithm on average.
For simplicity, let us find an invariant that is weaker than the precondition but stronger than the postcondition.
We describe how the teacher resolves some of these queries.-Equivalence Query: The learning algorithm starts with an equivalence query EQ(T), namely whether ∀k.T can be an invariant.
The teacher answers NO since ∀k.T is weaker than the postcondition.
Additionally, by employing an SMT solver, the teacher returns a counterexample {m = 0, k = 1, n = 2, i = 2, a[0] = 0, a[1] = 1}, under which ∀k.T evaluates to true, whereas the postcondition evaluates to false.-Membership Query: After a few equivalence queries, a membership query asks whether {i ≥ n, m = 0,i = 0, k ≥ n, a[k] ≤ a[m], a[m] ≥ a[i]} is a part of an invariant.
The teacher replies YES since the query is included in the precondition and therefore should also be included in an invariant.
-Membership Query: The membership query MEM ({i < n, m = 0, i = 0, k < n, a[k] > a[m], k < i, a[m] ≥ a[i]})is not resolvable because the template is not well-formed (Definition 1) by the given membership query.
In this case, the teacher gives a random answer (YES or NO).
Interestingly, each answer leads to a different invariant for this query.
If the answer is YES , we find an invariant ∀k.(i < n ∧ k ≥ i) ∨ (a[k] ≤ a[m]) ∨ (k ≥ n); if the answer is NO, we find another invariant ∀k.(i < n ∧ k ≥ i) ∨ (a[k] ≤ a[m]) ∨ (k ≥ n ∧ k ≥ i).
This shows how our approach exploits a multitude of invariants for the annotated loop.
We organize this paper as follows.
After preliminaries in Section 2, we present problems and solutions in Section 3.
Our abstraction is briefly described in Section 4.
The details of our technique are described in Section 5.
We report experiments in Section 6, discuss related work in Section 7, then conclude in Section 8.
The abstract syntax of our simple imperative language is given below:Stmt = nop | Stmt; Stmt | x := Exp | b := Prop | a[Exp] := Exp | a[Exp] := nondet | x := nondet | b := nondet | if Prop then Stmt else Stmt | { Pred } while Prop do Stmt { Pred } Exp = n | x | a[Exp] | Exp + Exp | Exp − Exp Prop = F | b | ¬Prop | Prop ∧ Prop | Exp < Exp | Exp = Exp Pred = Prop | ∀x.Pred | ∃x.Pred | Pred ∧ Pred | ¬PredThe language has two basic types: Booleans and natural numbers.
A term in Exp is a natural number; a term in Prop is a quantifier-free formula and of Boolean type; a term in Pred is a first-order formula.
The keyword nondet is used for unknown values from user's input or complex structures (e.g, pointer operations, function calls, etc.).
In an annotated loop {δ} while κ do S {}, κ ∈ Prop is its guard, and δ, ∈ Pred are its precondition and postcondition respectively.
Quantifier-free formulae of the forms b, π 0 < π 1 , and π 0 = π 1 are called atomic propositions.
If A is a set of atomic propositions, then Prop A and Pred A denote the set of quantifier-free and first-order formulae generated from A, respectively.A template t[] ∈ τ is a finite sequence of quantifiers followed by a hole to be filled with a quantifier-free formula in Prop A .
τ = [] | ∀I.τ | ∃I.τ.Let θ ∈ Prop A be a quantifier-free formula.
We write t [θ] to denote the first-order formula obtained by replacing the hole in t[] with θ.
Observe that any first-order formula can be transformed into the prenex normal form; it can be expressed in the form of a proper template.A precondition Pre(ρ, S) for ρ ∈ Pred with respect to a statement S is a first-order formula that guarantees ρ after the execution of the statement S. Let {δ} while κ do S {} be an annotated loop and t[] ∈ τ be a template.
The invariant generation problem with template t[] is to compute a first-order formulat[θ] such that (1) δ ⇒ t[θ]; (2) ¬κ ∧ t[θ] ⇒ ; and (3) κ ∧ t[θ] ⇒ Pre(t[θ], S).
Observe that the condition (2) is equivalent to t[θ] ⇒ ∨ κ.
We have δ ⇒ t[θ] and t[θ] ⇒ ∨ κ for any invariant t[θ].
δ and ∨ κ are subsequently called the strongest under-approximation and weakest over-approximation to invariants respectively.A valuation ν is an assignment of natural numbers to integer variables and truth values to Boolean variables.
If A is a set of atomic propositions and Var (A) is the set of variables occurred in A, Val Var (A) denotes the set of valuations for Var (A).
A valuation ν is a model of a first-order formula ρ (written ν |= ρ) if ρ evaluates to T under ν.
Let B be a set of Boolean variables.
We write Bool B for the class of Boolean formulae over Boolean variables B.
A Boolean valuation µ is an assignment of truth values to Boolean variables.
The set of Boolean valuations for B is denoted by Val B .
A Boolean valuation µ is a Boolean model of the Boolean formula β (written µ |= β) if β evaluates to T under µ.Given a first-order formula ρ, a satisfiability modulo theories (SMT) solver [6,16] returns a model of ν if it exists.
In general, SMT solver is incomplete over quantified formulae and may return a potential model (written SMT (ρ) !
→ ν).
It returns UNSAT (written SMT (ρ) → UNSAT ) if the solver proves the formula unsatisfiable.
Note that an SMT solver can only err when it returns a (potential) model.
If UNSAT is returned, the input formula is certainly unsatisfiable.
Form) algorithm is an exact algorithm that computes a representation for any target λ ∈ Bool B by asking a teacher queries.
The teacher is required to resolve two types of queries:-Membership query MEM (µ) where µ ∈ Val B .
If the valuation µ is a Boolean model of the target Boolean formula λ, the teacher answers YES .
Otherwise, the teacher answers NO; -Equivalence query EQ(β) where β ∈ Bool B .
If the target Boolean formula λ is equivalent to β, the teacher answers YES .
Otherwise, the teacher gives a counterexample.
A counterexample is a valuation µ ∈ Val B such that β and λ evaluate to different truth values under µ.For a Boolean formula λ ∈ Bool B , define |λ| CNF and |λ| DNF to be the sizes of minimal Boolean formulae equivalent to λ in conjunctive and disjunctive normal forms respectively.
The CDNF algorithm infers any target Boolean formula λ ∈ Bool B with a polynomial number of queries in |λ| CNF , |λ| DNF , and |B| [3].
Given an annotated loop and a template, we apply algorithmic learning to find an invariant in the form of the given template.
We follow the framework proposed in [15] and deploy the CDNF algorithm to drive the search of invariants.
Since the learning algorithm assumes a teacher to answer queries, it remains to mechanize the query resolution process (Figure 1).
Let t[] be the given template and t[θ] an invariant.
We will devise a teacher to guide the CDNF algorithm to infer t [θ].
To achieve this goal, we need to address two problems.
First, the CDNF algorithm is a learning algorithm for Boolean formulae, not quantifier-free nor quantified formulae.
Second, the CDNF algorithm assumes a teacher who knows the target t [θ] in its learning model.
However, an invariant of the given annotated loop is yet to be computed and hence unknown to us.
We need to devise a teacher without assuming any particular invariant t [θ].
For the first problem, we adopt predicate abstraction to associate Boolean formulae with quantified formulae.
Recall that the formula θ in the invariant t [θ] is quantifier-free.
Let α be an abstraction function from quantifier-free to Boolean formulae.
Then λ = α(θ) is a Boolean formula and serves as the target function to be inferred by the CDNF algorithm.For the second problem, we need to design algorithms to resolve queries about the Boolean formula λ without knowing t [θ].
This is achieved by exploiting the information derived from annotations and by making a few random guesses.
Recall that any invariant must be weaker than the strongest under-approximation and stronger than the weakest over-approximation.
Using an SMT solver, queries can be resolved by comparing with these invariant approximations.
For queries unresolvable through approximations, we simply give random answers.Following a similar framework to [15], we are able to infer quantified invariants of a given template for annotated loops.
Our solution to the quantified invariant generation problem for annotated loops is in fact very general.
It only requires users to provide a sequence of quantifiers and a fixed set of atomic propositions.
With a number of coin tossing, our technique can infer arbitrary quantified invariants representable by the user inputs.
This suggests that the algorithmic learning approach to invariant generation has great potential in invariant generation problems.
We begin with the association between Boolean formulae and first-order formulae in the form of a given template.
Let A be a set of atomic propositions and B(A) = {b p : p ∈ A} the set of corresponding Boolean variables.
Figure 2 shows the abstraction used in our algorithm.
The left box represents the class Pred A of first-order formulae generated from A. Boolean formulae over the Boolean variables B(A).
The CDNF algorithm infers a target Boolean formula by posing queries in this domain.The pair (γ, α) gives the correspondence between the domains Bool B(A) and Prop A .
Let us call a Boolean formula β ∈ Bool B(A) a canonical monomial if it is a conjunction of literals, where each variable appears exactly once.
Defineγ : Bool B(A) → Prop A α : Prop A → Bool B(A) γ(β) = β[b p → p] α(θ) = {β ∈ Bool B(A) : β is a canonical monomial and θ ∧ γ(β) is satisfiable}.
Concretization function γ(β) ∈ Prop A simply replaces Boolean variables in B(A) by corresponding atomic propositions in A. On the other hand, α(θ) ∈ Bool B(A) is the abstraction for any quantifier-free formula θ ∈ Prop A .
A Boolean valuation µ ∈ Val B(A) is associated with a quantifier-free formula γ * (µ) and a first-order formula t[γ * (µ)].
A valuation ν ∈ Var (A) moreover induces a natural Boolean valuation α * (ν) ∈ Val B(A) .
γ * (µ) = p∈A {p : µ(b p ) = T} ∧ p∈A {¬p : µ(b p ) = F} α * (ν)(b p ) = ν |= pThe following lemmas characterize relations among these functions: Lemma 1 ( [15]).
Let A be a set of atomic propositions, θ ∈ Prop A , β ∈ Bool B(A) , and ν a valuation for Var (A).
Then 1.
ν |= θ if and only if α * (ν) |= α(θ); and 2.
ν |= γ(β) if and only if α * (ν) |= β.
Lemma 2 ( [15]).
Let A be a set of atomic propositions, θ ∈ Prop A , and µ a Boolean valuation for B(A).
Then γ * (µ) ⇒ θ if and only if µ |= α(θ).
We present our query resolution algorithms, followed by the invariant generation algorithm.
The query resolution algorithms exploit the information derived from the given annotated loop {δ} while κ do S {}.
Let ι, ι ∈ Pred.
We say ι is an Fig. 3.
Counterexamples in equivalence query resolution (c.f. Algorithm 1): (a) a counterexample inside the under-approximation ι but outside the candidate ρ (line 4); (b) a counterexample inside the candidate ρ but outside the overapproximation ι (line 5); (c) a random counterexample ν 0 (or ν 1 ) inside the candidate ρ (or over-approximation ι) but out of the under-approximation ι (or candidate ρ), respectively (line 6 and 7).
(κ ∧ ρ ∧ ¬Pre(ρ, S)) → UNSAT then return YES ; 3 if SMT (ι ∧ ¬ρ) !
→ ν then return α * (ν); 4 if SMT (ρ ∧ ¬ι) !
→ ν then return α * (ν); 5 if SMT (ρ ∧ ¬ι) !
→ ν0 or SMT (ι ∧ ¬ρ) !
→ ν1 then 6 return α * (ν0) or α * (ν1) randomly; 7 ι ρ ν ρ ν ι ι ι ρ ν 0 ν 1 (a) (b) (c)under-approximation to invariants if δ ⇒ ι and ι ⇒ ι for some invariant ι of the annotated loop.
Similarly, ι is an over-approximation to invariants if ι ⇒ ∨ κ and ι ⇒ ι for some invariant ι.
The strongest under-approximation δ is an underapproximation; the weakest over-approximation ∨ κ is an over-approximation.
Better invariant approximations can be obtained by other techniques; they can be used in our query resolution algorithms.
An equivalence query EQ(β) with β ∈ Bool B(A) asks if β is equivalent to the unknown target λ.
Algorithm 1 gives our equivalence resolution algorithm.
It first checks if ρ = t[γ(β)] is indeed an invariant for the annotated loop by verifying ι ⇒ ρ, ρ ⇒ ι, and κ ∧ ρ ⇒ Pre(ρ, S) with an SMT solver (line 2 and 3).
If so, the CDNF algorithm has generated an invariant and our teacher acknowledges that the target has been found.
If the candidate ρ is not an invariant, we need to provide a counterexample.
Figure 3 describes the process of counterexample discovery.
The algorithm first tries to generate a counterexample inside of underapproximation (a), or outside of over-approximation (b).
If it fails to find such counterexamples, the algorithm tries to return a valuation distinguishing ρ from invariant approximations as a random answer (c).
Recall that SMT solvers may err when a potential model is returned (line 4 -6).
If it returns an incorrect model, our equivalence resolution algorithm will give an incorrect answer to the learning algorithm.
Incorrect answers effectively guide the CDNF algorithm to different quantified invariants.
Note also that random answers do not yield incorrect results because the equivalence query resolution algorithm uses an SMT solver to verify that the found first-order formula is indeed an invariant.
In a membership query MEM (µ), our membership query resolution algorithm (Algorithm 2) should answer whether µ |= λ.
Note that any relation between atomic propositions A is lost in the abstract domain Bool B(A) .
A valuation may not correspond to a consistent quantifier-free formula (for example, b x=0 = b x>0 = T).
If the valuation µ ∈ Val B(A) corresponds to an inconsistent quantifier-free formula (that is, γ * (µ) is unsatisfiable), we simply answer NO to the membership query (line 1).
Otherwise, we compare ρ = t[γ * (µ)] with invariant approximations.
Figure 4 shows the scenarios when queries can be answered by comparing ρ with invariant approximations.
In case 4(a), ρ ⇒ ι does not hold and we would like to show µ |= λ.
This requires the following lemma: [], θ 1 ≡ i < 10, and θ 2 ≡ i < 1.
We have ∀i.i < 10 ⇒ ∀i.i < 1 but i < 10 ⇒ i < 1.
In order to infer more information from ρ ⇒ ι, we introduce a subclass of templates.
Using an SMT solver, it is straightforward to check if a template t[] is wellformed with respect to a quantifier-free formula θ by a simple recursion.
For instance, when the template is ∀I.t [], it suffices to check SMT (t [θ]∧∃I.¬t [θ]) → UNSAT and t [] is well-formed with respect to θ.
More importantly, well-formed templates allow us to infer the relation between hole-filling quantifier-free formulae.
Lemma 3.
Let t[] ∈ τ be a template.
For any θ 1 , θ 2 ∈ Prop A , θ 1 ⇒ θ 2 implies t[θ 1 ] ⇒ t[θ 2 ].
1 ρ ν ι ι ρ (a) (b)Lemma 4.
Let A be a set of atomic propositions, θ 1 ∈ Prop A , and t[] ∈ τ a well-formed template with respect to θ 1 .
For anyθ 2 ∈ Prop A , t[θ 1 ] ⇒ t[θ 2 ] implies θ 1 ⇒ θ 2 .
By Lemma 4 and 2, we have µ |= λ from ρ ⇒ ι (line 4) and the well-formedness of t[] with respect to γ * (µ).
As in the case of the equivalence query resolution algorithm, incorrect models from SMT solvers (line 3) simply guide the CDNF algorithm to other quantified invariants.
Note that Algorithm 2 also gives a random answer if a membership query cannot be resolved through invariant approximations.
The correctness of generated invariants is ensured by SMT solvers in the equivalence query resolution algorithm (Algorithm 1).
8 Algorithm 3 shows our invariant generation algorithm.
It invokes the CDNF algorithm in the main loop.
Whenever a query is made, our algorithm uses one of the query resolution algorithms (Algorithm 1 or 2) to give an answer.
In both query resolution algorithms, we use the strongest under-approximation δ and the weakest over-approximation κ ∨ to resolve queries from the learning algorithm.
Observe that the equivalence and membership query resolution algorithms give random answers independently.
They may send inconsistent answers to the CDNF algorithm.
When inconsistencies arise, the main loop forces the learning algorithm to restart (line 6).
If the CDNF algorithm infers a Boolean formula λ ∈ Bool B(A) , the first-order formula t[γ(λ)] is an invariant for the annotated loop in the form of the template t[].
In contrast to traditional deterministic algorithms, our algorithm gives random answers in both query resolution algorithms.
Due to the undecidability of firstorder theories in SMT solvers, verifying quantified invariants and comparing invariant approximations are not solvable in general.
If we committed to a particular solution deterministically, we would be forced to address computability issues.
Random answers simply divert the learning algorithm to search for other quantified invariants and try the limit of SMT solvers.
They could not be effective if there were very few solutions.
Our thesis is that there are sufficiently many invariants for any given annotated loop in practice.
As long as our random answers are consistent with one verifiable invariant, the CDNF algorithm is guaranteed to generate an invariant for us.Similar to other invariant generation techniques based on predicate abstraction, our algorithm is not guaranteed to generate invariants.
If no invariant can be expressed by the template with a given set of atomic propositions, our algorithm will not terminate.
Moreover, if no invariant in the form of the given template can be verified by SMT solvers, our algorithm does not terminate either.
On the AP : # of atomic propositions, MEM : # of membership queries, EQ : # of equivalence queries, MEMR : fraction of randomly resolved membership queries to MEM , EQR fraction of randomly resolved equivalence queries to EQ, ITER : # of the CDNF algorithm invocations, and σTime : standard deviation of the running time.other hand, if there is one verifiable invariant in the form of the given template, there is a sequence of random answers that leads to the verifiable invariant.
If sufficiently many verifiable invariants are expressible in the form of the template, random answers almost surely guide the learning algorithm to one of them.
Since our algorithmic learning approach with random answers does not commit to any particular invariant, it can be more flexible and hence effective than traditional deterministic techniques in practice.
We have implemented a prototype 2 in OCaml.
In our implementation, we use Yices as the SMT solver to resolve queries (Algorithm 1 and 2).
Table 1 shows experimental results.
We took two cases from the ten benchmarks in [20] with the same annotation (max and selection sort).
We also chose four for statements from Linux 2.6.28.
We translated them into our language and annotated preand post-conditions manually.
Sets of atomic proposition are manually chosen from the program texts.
Benchmark devres is from library, tracepoint1 and tracepoint2 are from kernel, and rm pkey is from InfiniBand device driver.
The data are the average of 500 runs and collected on a 2.66GHz Intel Core2 Quad CPU with 8GB memory running Linux 2.6.28.
Observe that our algorithm is able to infer an arbitrary quantifier-free formula (over a fixed set of atomic propositions) to fill the hole in the given template.
A simple template such as ∀k.{(¬ret ∧ ¬break ) ⇒ (∀k.k < n ⇒ pkeys[k ] = key) ∧(¬ret ∧ break ) ⇒ (pkeys[i] = key ∧ pkeyrefs[i] = 0) ∧ ret ⇒ (pkeyrefs[i] = 0 ∧ pkeys[i] = 0) } (c) devres { i = 0 ∧ ¬ret } 1 while i < n ∧ ¬ret do 2 if tbl[i] = addr then 3 tbl[i]:=0; ret:=true 4 else 5 i:=i + 1 6 end {(¬ret ⇒ ∀k. k < n ⇒ tbl[k] = addr) ∧(ret ⇒ tbl[i] = 0) } (b) selection sort { i = 0 } 1 while i < n − 1{(i ≥ n − 1) ∧ (∀k1.k1 < n ⇒ (∃k2.k2 < n ∧ a[k1] = a[k2]))}[] suffices to serve as a hint in our approach.
In this test case, we apply our invariant generation algorithm to compute an invariant to establish the postcondition of the outer loop.
For computing the invariant of the outer loop, we make use of the inner loop's specification.
We use the following set of atomic propositions:{k 1 ≥ 0, k 1 < i, k 1 = i, k 2 < n, k 2 = n, a[k 1 ] = a[k 2 ], i < n − 1, i = min}.
Using the template ∀k 1 .
∃k 2 .
[],our algorithm infers following invariants in different runs:∀k 1 .
(∃k 2 .
[(k 2 < n ∧ a[k 1 ] = a[k 2 ]) ∨ k 1 ≥ i]); and ∀k 1 .
(∃k 2 .
[(k 1 ≥ i ∨ min = i ∨ k 2 < n) ∧ (k 1 ≥ i ∨ (min = i ∧ a[k 1 ] = a[k 2 ]))]).
Note that all membership queries are resolved randomly due to the alternation of quantifiers in array theory.
Still a simple random walk suffices to find invariants in this example.
Moreover, templates allow us to infer not only universally quantified invariants but also first-order invariants with alternating quantifications.
Inferring arbitrary quantifier-free formulae over a fixed set of atomic propositions again greatly simplifies the form of templates used in this example.rm pkey from Linux InfiniBand Driver Figure 5(a) is a while statement extracted from Linux InfiniBand driver.
4 The conjuncts in the postcondition represent (1) if the loop terminates without break, all elements of pkeys are not equal to key (line 2); (2) if the loop terminates with break but ret is false, then pkeys[i] is equal to key (line 2) but pkeyrefs [i] is not equal to zero (line 4); (3) (∀k.(k < i) ⇒ pkeys[k ] = key) ∧ (ret ⇒ pkeyrefs[i ] = 0 ∧ pkeys[i ] = 0) ∧ (¬ret ∧ break ⇒ pkeys[i ] = key ∧ pkeyrefs[i ] = 0); and (∀k.(¬ret ∨ ¬break ∨ (pkeyrefs[i] = 0 ∧ pkeys[i] = 0)) ∧ (pkeys[k] = key ∨ k ≥ i) ∧(¬ret ∨ (pkeyrefs[i] = 0 ∧ pkeys[i] = 0 ∧ i < n ∧ break )) ∧ (¬break ∨ pkeyrefs[i] = 0 ∨ ret) ∧ (¬break ∨ pkeys[i] = key ∨ ret)).
In spite of undecidability of first-order theories in Yices and random answers, each of the 3000 (= 6×500) runs in our experiments infers an invariant successfully.
Moreover, several quantified invariants are found in each case among 500 runs.
This suggests that invariants are abundant.
Note that the templates in the test cases selection sort and tracepoint2 have alternating quantification.
Satisfiability of alternating quantified formulae is in general undecidable.
That is why both cases have substantially more restarts than the others.
Interestingly, our algorithm is able to generate a verifiable invariant in each run.
Our simple randomized mechanism proves to be effective even for most difficult cases.
Comparing with the work [15] of generating quantifier-free invariants, we develop the following technical extensions.
First, we integrate potential counterexamples in resolving equivalence query algorithm (line 6 -7 in Algorithm 1, and line 3 in Algorithm 2) instead of restarting.
Due to the undecidability of satisfiability of quantified formulae, SMT solvers often give potential counterexamples.
We exploit potential counterexamples to enhance our algorithm.
Second, a new condition (Definition 1) to answer positively in resolving membership queries is proposed.
Without this condition, we can answer negatively to membership queries.In contrast to previous template-based approaches [20,9], our template is more general as it allows arbitrary hole-filling quantifier-free formulae.
The templates in [20] can only be filled with formulae over conjunctions of predicates from a given set.
Any disjunction must be explicitly specified as part of a template.
In [9], the authors consider invariants of the form E ∧ n j=1 ∀U j (F j ⇒ e j ), where E, F j and e j must be quantifier free finite conjuctions of atomic facts.Existing technologies can strengthen our framework.
Firstly, its completeness can be increased by more powerful decision procedures [6,8,21] and theorem provers [18,1,19].
Moreover, our approach can be improved by using more accurate approximations from existing invariant generation techniques.
The tool InvGen collects reached states satisfying the program invariants, and also computes a collection of invariants for efficient invariant generation [11].
They can be used as under-and over-approximations, respectively.Regarding the generation of unquantified invariants, a constraint analysis approach is proposed in [10].
Invariants in the combined theory of linear arithmetic and uninterpreted functions are synthesized in [2], while InvGen [11] presents an efficient approach for linear arithmetic invariants.
For quantified loop invariants, Skolemization is used for generating universally quantified invariants [7].
In [18], a paramodulation-based saturation prover is extended to generate universally quantified invariants by interpolation.With respect to the analysis of properties of array contents, Halbwachs et al. [12] handle programs which manipulate arrays by sequential traversal, incrementing (or decrementing) their index at each iteration, and which access arrays by simple expressions of the loop index.
A loop property generation method for loops iterating over multi-dimensional arrays is introduced in [13].
For inferring range predicates, Jhala and McMillan [14] described a framework that uses infeasible counterexample paths.
As a deficiency, the prover may find proofs refuting short paths, but which do not generalize to longer paths.
Due to this problem, this approach [14] fails to prove that an implementation of insertion sort correctly sorts an array.
By combining algorithmic learning, decision procedures, predicate abstraction, and templates, we present a technique for generating quantified invariants.
The new technique searches for invariants in the given template form guided by query resolution algorithms.
We exploit the flexibility of algorithmic learning by deploying a randomized query resolution algorithm.
When there are sufficiently many invariants, random answers will not prevent algorithmic learning from inferring verifiable invariants.
Our experiments show that our learning-based approach is able to infer non-trivial quantified invariants with this na¨ıvena¨ıve randomized resolution for some loops extracted from Linux drivers.Under-and over-approximations are presently derived from annotations provided by users.
They can in fact be obtained by other techniques such as static analysis.
For deciding the set of atomic propositions, it will be interesting whether existing techniques [4,17] are applicable.
The integration of various refinement techniques for predicate abstraction will certainly be an important future work.
