Application workloads are used for system analysis, design, optimization, and evaluation.
As systems and their applications evolve, new workloads are required to reflect their characteristics and bottlenecks.
Edge-computing systems are a new model with unique characteristics, including heterogeneous and geodistributed components and complex failure patterns.
Their workload characteristics are also unique, including unpredictable load and user mobility, combined with stringent latency and bandwidth requirements.
Supporting these work-loads would require resource management and allocation policies that take into account a rich set of attributes.
In this paper, we show that currently available datasets include only partial subsets of these attributes.
Moreover, having been collected on existing systems, they do not reflect the unique characteristics of edge systems and applications.
At the same time, current edge systems in early deployment stages are not ready for the collection of representative application workloads.
We show how to bridge the gap between required and available datasets by workload composition: we combine attributes from several available datasets to create realistic representations of edge systems, their users, and their workloads.
Application workloads play an important role in systems research, design, and optimization.
Characterizing these workloads helps define system design objectives, identify optimization goals, and make appropriate tradeoffs [45,52,60,67,74,84,85,95,101,106].
Examples include storage caching and tiering designed according to data access frequencies [100,108], scheduling and resource allocations based on job sizes, interdependencies, and latency sensitivity [50,54,70,82,89,96], and consistency mechanisms chosen according to the degree of data sharing and the ratio between reads and writes [36,48].
Workload traces are further used to evaluate the resulting systems with respect to alternative designs.
Industry-standard benchmarks, such as YCSB [43], TPC [9], and SPEC [26], are based on representative workloads and are often used as a synthetic substitute for real application traces.New edge computing systems promise to meet the stringent latency requirements of emerging real-time applications, such as augmented and virtual reality [55,56], by bringing compute, storage and networking resources closer to user devices [46].
Thus, the edge infrastructure is a collection of interoperating edge nodes, each of limited size and resources, located one or two network hops away from the end user [38,41,71,88].
Edge systems represent a new, arguably disruptive, system model.
They are inherently different from existing systems, such as cloud datacenters or geodistributed systems, in two major aspects [46,102].
The first is their workloads: clouds aggregate service for large numbers of users, thus experiencing mostly predictable traffic volumes.
In contrast, edge services are intrinsically local and are thus subject to significantly larger workload fluctuations due to correlated events and user mobility.
The second aspect is the way their resources are managed.
Clouds can optimize user-perceived service as well as their resource utilization via centralized routing and load balancing.
Edge systems, however, are by definition distributed across multiple edge networks, possibly involving multiple service providers.
They are associated with considerable heterogeneity in bandwidth and compute resources, for which the centralized resource management model of datacentesr is not applicable.Thus, to design, optimize, and evaluate resource allocation and management policies for edge systems, we need workloads that (1) reflect the unique characteristics of edge applications and users, and (2) incorporate the attributes required for optimizing their service.
These attributes are a superset of the attributes used in various optimizations today.
For example, within a data center, the optimal allocation of jobs to nodes is orthogonal to the physical location of their user.
Similar allocation of user jobs to edge nodes will likely attempt to minimize latency by minimizing the physical distance between the node and the user.
As another example, strategies for call handovers in a cellular network are based on user mobility and service level, as well as the available resources in the new cell.
A similar handover of an edge-based session or function might also depend on the availability of the data or code, and require transferring non-negligible state and context information.
In both examples, the edge-based policies rely on attributes that are not used in current policies for datacenters or even networks.Unfortunately, application workloads that were collected on existing systems rarely reflect the combination of aspects required for optimizing the edge infrastructure, nor the lowlatency and high bandwidth requirements of edge applications.
At the same time, collecting edge-based workloads is currently impossible-there are no large-scale deployed and operational edge systems, and existing small-scale systems still do not host user-facing applications.
Without relevant and available workloads, current studies on the design and optimization of the edge infrastructure resort to basic synthetic distributions for important workload attributes [57,64,75,99,105].
Such limited evaluation settings inevitably limit the advancement of research and optimization of the edge infrastructure.We here turn the light to this (hopefully temporary) gap between edge-systems research and realistic input from the field.
We characterize the workload attributes required for informed research into four categories: storage, compute, user/application, and geolocation, and then describe respective categories for datasets describing the edge systems themselves: architecture, availability, and business.
We demonstrate that attributes from these categories are individually included in various datasets, but no available dataset includes the combination of attributes required to represent edge application workloads.Our approach for bridging the current gap is workload composition, in which existing datasets are joined to obtain attribute combinations that are otherwise unavailable.
We describe such composition in detail to show the advantage of this approach compared to using entirely synthetic workloads: it allows us to model and evaluate edge systems and designs with workloads that are more representative of how users move and access data, and how real applications interact with systems.
We are yet to learn how representative these behaviors are of future edge applications and users.
In the meantime, this approach can serve as a temporary solution to "bootstrap" research in edge computing systems.
By demonstrating the importance of real application workloads for the edge, we hope to also encourage collection and release of such workloads.
The first set of attributes refers to the information we are interested in with respect to the work done by the system.
These attributes would ideally describe each request in the workload.
We characterize them into four categories: storage, compute, user/application, and geolocation.Storage-related attributes describe the way data is accessed by users and applications.
Standard attributes are the timestamp, operation (PUT or GET), object ID, and possibly its size.
These attributes help understand (as in previous studies) object popularities over time, if the system is read-heavy or write-heavy, the request rate and how it fluctuates according to diurnal or weekly patterns, etc.
Previous studies addressing edge-based storage services obtained these attributes from various nonedge resources.
In one example, the authors used a peer-to-peer workload, to which they added synthetic request types [59].
Others used entirely synthetic request distributions [47,75].
Compute-related workloads describe jobs and their tasks, and are used to understand how resources should be consolidated, scheduled, and allocated.
Their standard attributes include job submission time, its tasks, dependencies between them, and their resource requirements, such as cores, GPUs, FPGAs, and memory and storage size and bandwidth.
Some workloads specify task deadlines that are used for setting scheduling priorities.
In the edge, this information could be used to determine whether a task can be offloaded to a neighboring node or to the cloud.
Another useful attribute is whether a submitted task is a resubmission (retry) of a previously failed task, in which case its resource requirements depend on the success or failure of the original task.
The need for compute-related workloads has become evident in several recent studies.
One used synthetic values for evaluating node placement and resource allocation [73], while others used non-edge applications to evaluate their edge systems [57,68].
Information linking requests to the user and application that issued them is important for aggregating requests into logical streams that may access shared data, code, and resources, while having different (possibly conflicting) objectives, service levels, and progress.
The relevant attributes are user ID, application name or ID, and possibly the device type.
The latter is relevant for applications such as web browsing that require different responses (e.g., image resolution) to requests originating from different devices.
In the context of edge computing, user permissions might imply constraints on request forwarding and collocation.
Many of these attributes were modeled by synthetic values and distributions in studies addressing the allocation of resources to users sharing the edge system [31,57,64,73,99].
In wide-area networks, geolocation information is used to map requests to available nearby resources, to identify opportunities for load-balancing, and to specify restrictions on possible routing and forwarding optimizations.
The most important attribute is the location from which a request originated, which can be absolute (e.g., global coordinates), or relative (e.g., system-specific zones).
The location is particularly valuable when it can be correlated to other attribute categories.
For example, when combined with storage attributes, it can help understand how object popularities vary between locations, and when combined with compute related attributes it can help identify areas with high resource requirements.
One recent study used the locations of edge clients to evaluate the benefit from their collaboration [58], and another relied on their location for the choice of service provider [104].
The first study used locations from Twitter, while the second simulated uniformly distributed clients.The second set of attributes refers to datasets that describe the infrastructure of the system itself.
They can be categorized into: system architecture, availability, and business.The edge system architecture is defined by two main components: (1) the nodes, characterized by their locations and resources, and (2) the network, characterized by the properties of the connections between nodes and their peers, their users (the edge devices), and their cloud backend.
These attributes are important for correlating user requests to nearby available resources and for optimizing and consolidating these requests via offloading and peer-to-peer collaboration.
For example, when evaluating models for allocating resources and contracting with providers, recent studies generated synthetic node locations, resources, and network topologies [73,99], or used topologies of non-edge networks [104,105].
As the availability of the system's components (nodes and network connections) may change over time, we are interested in logs specifying their state at fixed time intervals, or logs of failure events.
Ideally, we wish to distinguish between two main causes of unavailability: (1) excessive load, which is a result of the workload and the way the system was managed at the time of serving it.
For example, high load in certain areas, combined with suboptimal scheduling decisions, may result in nodes becoming unresponsive.
These failures might be avoided by an alternative resource management policy.
(2) External failures such as power outages, node hardware problems, or network partitions.
Alternative management of the edge infrastructure cannot avoid such failures, but it should minimize their effect.
For example, recent approaches for ensuring service availability with nodes whose availability is limited used synthetic datasets of node availability and failures for their evaluation [35,109].
Business-related attributes are important for identifying opportunities for sharing or consolidating resources, as well as respective constraints on such optimizations.
Relevant attributes include the operator a node or a connection belongs to, and the business agreements which specify who is entitled to using its resources and at which service level.
These agreements are important for identifying potential collaborative optimizations.
To the best of our knowledge, these attributes were not considered in previous edge-related studies.
The systems community has been using a wide range of datasets, each containing a different set of workload attributes or system characteristics.
We describe representative available datasets from different domains (summarized in Table 1).
Storage workloads.
The SNIA IOTTA [7] repository contains traces collected at various levels of the storage hierarchy.
System-call traces include file-system operations and attributes, e.g., the inode number, the requested byte range, and whether the request hit or missed in the page cache [39].
Block-level traces include the device, byte range, and sometimes the file and process associated with the I/O request [1,53,62,63,77,107].
The traces were collected in university servers, production clusters, and even smartphones.
None of them contains location attributes, and only limited information is available regarding their users and applications.
Datasets of file-system snapshots include file sizes and their organization into directories and logical volumes [8,51,74], but this information is not correlated to the way files are read and written by users.Several studies address object popularity and size in largescale systems [34,60].
Although the datasets are not available, their distributions are used to generate synthetic workloads in simulations and benchmarks [9,43].
Popularity can also be extracted from independent datasets of social networks graphs, collaborations, citations, links, and web accesses [27,65].
Mobility datasets.
Several available datasets provide location and mobility information.
We distinguish between location-centric datasets, such as camera traffic counts [12] or entrance and exit information from subway stations or parking lots [16,23], and user-centric datasets, such as logs of taxi and bike rides [14,17,18,79], and location-based online social networks [65].
Most of these datasets include only user and geolocation attributes [15].
One exception is the Mobile Data Challenge (MDC) dataset, with smartphone location and activity of 182 individuals in the Lake Geneva region, collected between 2009 and 2011 [61].
This dataset includes most of the properties we are interested in.
However, we are not aware of a similar, more recent, dataset, most likely due to the unusual effort involved in its collection.Cluster workloads.
Several large companies have released traces of jobs and VMs on their clusters.
These traces include information about jobs and their tasks, the dependencies between them, their resource utilization, the machine they were running on, and sometimes also the user that deployed them [44,91,98].
Available HPC cluster traces are less detailed, presenting only aggregate job statistics [32].
These datasets do not include any geolocation information, and their storagerelated attributes, such as I/O bandwidth and memory size, are insufficient for correlating jobs with their datasets.System architecture.
Some cluster traces also include information about the cluster nodes and their resources [44,98].
This information can be correlated with the jobs scheduled to run on them, but these allocations are location independent, as they take place within the datacenter.
Various datasets describe different aspects of network architectures, such as graphs of autonomous systems and P2P networks [65], as well as official datasets of hotspots and cellular towers [19,61].
Some of these datasets include information about the nodes' resources or ownership, but additional business or availability attributes are unavailable.Node availability.
There are two major sources of information regarding node availability in large-scale networks.
The first is the Internet, whose connections are constantly monitored for latency, round-trip, and connectivity.
Detailed as well as aggregate information is available in several public repositories [11,25].
The second source is datacenters that maintain detailed information about their storage devices.
For example, the Backblaze dataset includes detailed SMART statistics and failure information of hard drive [30].
Similar information was used to analyze drive failures at EMC [69] and Google [86,87], but their datasets have not been made public.Edge-related datasets.
Smart cities are one of the "killer apps" of edge computing.
Cities around the world are preparing or have already started to collect data and make it available through various platforms [12, 13, 16-21, 23, 29, 33, 79, 93].
Available datasets include some of the mobility and system architecture datasets described above, as well as datasets related to transportation infrastructure, air quality, small businesses, and many others.
We describe how these datasets can be used Table 1: Available datasets and their attributes.
V -available, X -not available, • -partially available.for edge-systems research in the next section.
Edge-related compute and storage attributes are more difficult to obtain.
E.g, data collected by autonomous-vehicle sensors is available [28], but primarily intended to improve machine learning applications.
The interesting attributes in the context of the infrastructure are the storage and compute requests such applications will eventually forward to the edge.
Similarly, a recently introduced benchmark for autonomous vehicles [97] models the workload the devices on the vehicle have to serve, and cannot be directly applied to the infrastructure.Deployed edge systems.
Current commercial systems are deployed as an orchestration layer on top of existing cellular and network infrastructure [2][3][4][5][6].
Data from these systems is not publicly available.
Several academic initiatives are deploying large-scale edge testbeds to facilitate related research and evaluation.
Some are extensions of systems originally deployed for global-scale network and cloud-based research, such as PlanetLab [42] and CloudLab [83].
Others are designed with the edge as their primary research objective, either by deploying dedicated physical infrastructure [72,78,80,81], by creating a virtual edge-layer on top of existing wireless and mobile infrastructure [24,37,40,90], or both [10].
Current research and development efforts related to those prototypes focus on porting applications to the edge and on exporting edge resources to applications [22].
In the future, these testbeds could be used for collecting the workloads of edge applications.
At the same time, workloads collected on commercial deployments would be valuable input for evaluations executed on these testbeds.
To bridge the gap between available datasets and the edge workloads we need, we can join attributes from several available datasets.
We refer to this method as workload composition.
The resulting composite workload represents edge workloads better than any of its individual components.
Workload composition is inevitably ad-hoc-the original workloads, their attributes, and the way they are composed are chosen according to the purpose for which the workload is created.
Similar techniques were used in previous studies, but to a much smaller extent: those examples that we are aware of augment one available dataset with a synthetic distribution for an additional attribute.
For example, [47] used a Zipf distribution for accesses to an available image dataset, while [58] accelerated a Twitter feed trace to simulate real world behavior.
To demonstrate the need for more complex compositions, we describe a representative use case of workload requirements and generation.Consider the design of an edge-based container store or caching service [47,76], and the evaluation of object-placement and eviction policies for such a service.
Ideally, we would use a trace of client requests that includes storage as well as geolocation attributes, with some dataset describing the physical architecture of the edge system.
In the absence of such a workload, we generate a composite workload from the following available datasets:• NYC taxi zones [18]: 263 polygons partitioning the city into neighborhood-sized zones.
• NYC yellow taxi [17]: 112M records of taxi rides, including their start and end times and pick-up and drop-off zones.
• NYC hotspots [19]: detailed coordinates of 3319 hotspots throughout the city.
• Wikipedia [66]: 28.5M graph edges representing links from one Wikipedia page to another for 1.8M pages.
Workload generation.
In our composite workload, the hotspots represent edge-node locations, passenger drop-off zones represent the location of the passengers when they issue their requests, and the Wikipedia links represent page popularity.
We first join the taxi-zones and hotspots workloads, to attribute each hotspot to the taxi zone it is located in.
We list the Wikipedia pages in descending order of the number of links pointing to them, thus ranking them by their popularity.
We then generate a trace of object GET requests of the form time,node,page as follows.Each taxi ride represents a 'browsing session' that starts at the drop-off time and takes place at the drop-off zone.
We choose a random hotspot from the drop-off zone as the node receiving the request, node h .
The first page of the session, page 0 , is chosen at random with a probability proportional to its static page rank.
With some probability p exit (exit rate), the session ends.
With probability 1 − p exit the session continues, and the next page is chosen from the pages pointed to by the current page, with a probability proportional to its rank.
The session further continues with probability 1 − p exit , with additional pages chosen in the same manner.
For a session with n pages starting at time drop-off T , our trace will include n requests of the form T + i × ε, node h , page i , for 0 ≤ i < n. ε is a parameter representing the request rate within a session.
Workload properties.
In addition to its use for evaluation purposes, our composite workload can also help characterize the system and its users.
For example, Figure 1 shows the taxi zones in Manhattan, ordered by the number of hotspots in them (zones without hotspots were removed), and the number of rides that ended in them in the course of three months (MayJuly 2018), separated into daytime and nighttime.
The trend lines, depicting linear regression, show the different mobility patterns throughout the day and indicate that the number of drop-offs is lightly correlated with the number of hotspots in the zone.To understand the difference between static page ranks and dynamic access frequencies, we generated the composite workload with four different exit rates.
Figure 2 shows the accesses to the 300 highest ranking pages in the first 4M requests in the composite trace.
When the exit rate is 100%, the requests are distributed exactly according to the page ranks.
With smaller rates, the request popularities differ from the static ones.
We can distinctly notice that some high-ranking pages are accessed very infrequently-these pages belong to a small category with few links from outside pages.
To best represent user behavior, the exit rate should be chosen according to the application whose accesses are simulated.Refinements and additional compositions.
More detailed workloads could be used to generate comprehensive and possibly more accurate compositions.
For example, if the pick-up and drop-off locations were given in finer granularity, we could assign sessions directly to the nearest hotspot rather than to a random hotspot in the zone.
A detailed trace of the rides' path, as in the SFO taxi dataset [15], could be used to generate sessions during the actual ride.
At the same time, we note that even the aggregate information in the yellow taxi dataset can be used to represent user mobility.
For example, Figure 3 depicts the most crowded zones bordering Central Park, and for each two zones Z f rom , Z to , the probability that a ride starting at Z f rom will end in Z to .
Similar characterization is often used for resource allocation and reservation in networked environments [92,94,103].
The composition we described can easily be done with alternative datasets.
For example, user presence around a hotspot can be represented by the number of exits from nearby subway stations [16].
Similarly, object requests can be generated from any object distribution, or taken directly from a trace of requests.
Datasets from location-dependent recommendation platforms, such as TripAdvisor, could be used to generate requests according to the user's location.
Finally, the number of sessions for each user and the inter-arrival times of requests within a session could be derived from a representative distribution or a separate workload, rather than a static parameter.
We described seven categories of attributes that are important for edge-system analysis, design, and optimization.
We showed how, in the absence of up-to-date datasets with all, or even most of these attributes, partial datasets can be used to compose a workload with the required set of attributes.
While these composite workloads provide an approximate representation of edge systems, applications, and user behaviors, they can help this field move forward by facilitating informed research, design, and management of the edge infrastructure.
Is the absence of datasets really temporary?
Looking forward, it is not clear how easy it would be to obtain edge workloads with all the relevant attributes, even when edge systems are fully deployed and widely used.
Storage, Internet, and content providers are already reluctant to share their datasets, and the research community relies on a small variety of datasets in each domain.
How realistic is it to expect more comprehensive workloads to be available in the future?On the positive side, many datasets related to the edge infrastructure, such as locations of cellular towers and traffic surveillance cameras, are already public.
Many mobility datasets originate from municipal repositories committed to open data, and this trend is likely to continue [93].
On the other hand, one of the most challenging aspects of workload collection is ensuring that they do not leak private information about the platform users, a challenge that is increased in edge-related workloads, where user and locality are major attributes.Collecting detailed user and locality information requires either explicit user opt-in, aggregation, or both.
In either case, this might become a critical issue preventing commercial operators from making their data public.
In this case, the following questions arise: how important is detailed user information, compared to aggregate attributes?
And, what is the best way to protect personal data while making the most detailed information available in the dataset?Will workload composition become standard practice?
Datasets that include less attributes might be easier to anonymize, and thus easier to make public.
Thus, it is possible that, while full and detailed edge workloads will remain proprietary and unavailable to the public, partial datasets will become increasingly available.
In this scenario, workload composition might be the best way of incorporating the available datasets into the process of system reserach, design, and optimization.How relevant are the basic workloads?
Workload traces are inevitably limited in their ability to represent future demand for system resources.
This limitation is bigger when the system itself changes, as in our case.
In the absence of real edge workloads, how can we verify that our composite workloads are representative of future edge systems and applications?
Which of the basic workloads described in this paper are most likely to represent future edge workloads?
Are other relevant workloads available?
Finally, can some predictable access patterns be generated synthetically for the purposes we described?
Synthetic distributions of specific aspects can facilitate a more systematic coverage of a large parameter space, including its extremities.
They can also be adapted as observed characteristics of edge systems change over time.
Which aspects are better modelled by synthetic distributions?How to generate realistic and useful compositions?
By composing existing workloads into new ones we are making assumptions about correlations between workload attributes.
For example, in our composite workload, we are assuming that drop-off locations are correlated with user presence in an area.
What type of analysis can we perform, and on which workloads, to determine which attributes are indeed independent of other attributes, which are correlated to others, and what is the nature of these correlations?
These questions are part of the general challenge of establishing validity, reliability, and replicability of evaluations, which are addressed in the context of experimental design [49].
