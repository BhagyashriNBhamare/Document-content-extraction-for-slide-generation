We describe a highly optimized protocol for general-purpose secure two-party computation (2PC) in the presence of malicious adversaries.
Our starting point is a protocol of Kolesnikov et al. (TCC 2015).
We adapt that protocol to the online/offline setting, where two parties repeatedly evaluate the same function (on possibly different inputs each time) and perform as much of the computation as possible in an offline preprocessing phase before their inputs are known.
Along the way we develop several significant simplifications and optimizations to the protocol.
We have implemented a prototype of our protocol and report on its performance.
When two parties on Amazon servers in the same region use our implementation to securely evaluate the AES circuit 1024 times, the amor-tized cost per evaluation is 5.1ms offline + 1.3ms online.
The total offline+online cost of our protocol is in fact less than the online cost of any reported protocol with malicious security.
For comparison, our protocol's closest competitor (Lindell & Riva, CCS 2015) uses 74ms offline + 7ms online in an identical setup.
Our protocol can be further tuned to trade performance for leakage.
As an example, the performance in the above scenario improves to 2.4ms offline + 1.0ms online if we allow an adversary to learn a single bit about the honest party's input with probability 2 −20 (but not violate any other security property, e.g. correctness).
Secure two-party computation (2PC) allows mutually distrusting parties to perform a computation on their combined inputs, while revealing only the result.
2PC was conceived in a seminal paper by Yao [34] and shown to be feasible in principle using a construction now known as garbled circuits.
Later, the Fairplay project [24] was the first implementation of Yao's protocol, which inspired interest in the practical performance of 2PC.
The leading technique to secure Yao's protocol against malicious adversaries is known as cut-and-choose.
The idea is to have the sender generate many garbled circuits.
The receiver will choose a random subset of these to be checked for correctness.
If all checked circuits are found to be correct, then the receiver has some confidence about the unopened circuits, which can be evaluated.The cost of the cut-and-choose technique is therefore tied to the number of garbled circuits that are generated.
To restrict a malicious adversary to a 2 −s chance of violating security, initial cut-and-choose mechanisms required approximately 17s circuits [20].
This overhead was later reduced to 3s circuits [21,31,32] and then s circuits [19].
Suppose two parties wish to perform N secure computations of the same function f (on possibly different inputs each time), and are willing to do offline preprocessing (which does not depend on the inputs).
In this online/offline setting, far fewer garbled circuits are needed per execution.
The idea, due to [14,22], is to generate many garbled circuits (enough for all N executions) and perform a single cut-and-choose on them all.
Then each execution of f will evaluate a random subset (typically called a bucket) of the unopened circuits.
Because the unopened circuits are randomly assigned to executions, only O(s/ log N) circuits are needed per bucket to achieve security 2 −s .
Concretely, 4 circuits per bucket suffice for security 2 −40 and N = 1024.
The idea is that two parties run two instances of Yao's protocol, with each party acting as sender in one instance and receiver in the other.
They then perform a reconciliation step in which their garbled outputs are securely compared for equality.
Intuitively, one of the garbled outputs is guaranteed to be correct, so the reconciliation step allows the honest party to check whether its garbled output agrees with the correct one held by the adversary.Unfortunately, the dual execution protocol allows an adversary to learn an arbitrary bit about the honest party's input.
Consider an adversary who instead of garbling the function f , garbles a different function f 񮽙 .
Then the output of the reconciliation step (secure equality test) reveals whether f (x 1 , x 2 ) = f 񮽙 (x 1 , x 2 ).
However, it can be shown that the adversary can learn only a single bit, and, importantly, cannot violate output correctness for the honest party.
Kolesnikov et al. [16] proposed a combination of dualexecution and cut-and-choose that reduces the probability of a leaked bit.
The idea is for each party to garble and send s circuits instead of 1, and perform a cut-andchoose to check each circuit with probability 1/2.
Each circuit should have the same garbled encoding for its outputs, so if both parties are honest, both should receive just one candidate output.However, a malicious party could cause the honest party to obtain several candidate outputs.
The approach taken in [16] is to have the parties use private set intersection (PSI) to find a common value among their sets of reconciliation values.
This allows the honest party to identify which of its candidate outputs is the correct one.In Section 4 we discuss in more detail the security offered by this protocol.
Briefly, an adversary cannot violate output correctness for the honest party, and learns only a single bit about the honest party's input with probability at most 1/2 s (which happens only when the honest part doesn't evaluate any correct garbled circuit).
We adapt the dual-execution protocol of [16] to the online/offline setting.
The result is the fastest protocol to date for 2PC in the presence of malicious adversaries.
At a very high level, both parties exchange many garbled circuits in the offline phase and perform a cut-andchoose.
In the online phase, each party evaluates a random bucket of its counterpart's circuits.
The parties then use the PSI-based reconciliation to check the outputs.
While the high-level idea is straight-forward, some nontrivial technical changes are necessary to adapt [16] to the online/offline setting while ensuring high performance in practice.In particular, an important part of any malicioussecure protocol is to ensure that parties use the same inputs in all garbled circuits.
The method suggested in [16] is incompatible with offline pre-processing, whereas the method from [23] does not ensure consistency between circuits generated by different parties, which is the case for dual-execution (both parties generate garbled circuits).
We develop a new method for input consistency that is tailored specifically to the dual-execution paradigm and that incurs less overhead than any existing technique.In [16], the parties evaluate garbled circuits and then use active-secure private set intersection (PSI) to reconcile their outputs.
We improve the analysis of [16] and show that it suffices to use PSI that gives a somewhat weaker level of security.
Taking advantage of this, we describe an extremely lightweight PSI protocol (a variant of one in [30]) that satisfies this weak level of security while being round-optimal.
We implemented a C++ prototype of our protocol using state-of-the-art optimizations, including the garbledcircuit construction of [35]; the OT-extension protocol of [15] instantiated with the base OTs of [7].
The prototype is heavily parallelized within both phases.
Work is divided amongst threads that concurrently generate & evaluate circuits, allowing network throughput to be the primary bottleneck.
The result is an extremely fast 2PC system.
When securely evaluating the AES circuit on colocated Amazon AWS instances, we achieve the lowest amortized cost to date of 5.1ms offline + 1.3ms online per execution.
There have been several implementations of garbledcircuit-based 2PC protocols that achieve malicious security [1,12,18,23,29,31,32].
Except for [23], none of these protocols are in the online/offline settings so their performance is naturally much lower (100-1000× slower than online/offline protocols).
Among them, the fastest reported secure evaluation of AES is that of [12], which was 0.46s exploiting consumer GPUs.
Other protocols have been described (but not implemented) that combine cut-and-choose with the dual-execution paradigm to achieve malicious security [13,26].
The protocol of [13] leaks more than one bit when the adversary successfully cheats during cut-and-choose.
Our protocol is most closely related to that of [23], which also achieves fast, active-secure 2PC in the online/offline setting.
[23] is an implementation of the protocol of [22], and we refer to the protocol and its implementation as "LR" in this section.
Both the LR protocol and ours are based on garbled circuits but use fundamentally different approaches to achieveing malicious secu-Input Labels Reconciliation LR [23] Figure 1: Asymptotic communication costs of the LR protocol vs. ours (comparing online phases).
B is the number of circuits in a bucket; B 񮽙 ≈ 3B is the number of auxiliary cheatingrecovery circuits in [23]; |x| is length of sender's inputs; κ s is the statistical security parameter; κ c is the computational security parameter.
|x|(B + B 񮽙 )κ c |x|B 񮽙 κ c Us (Async PSI) |x|Bκ c B 2 κ s κ c Us (Sync PSI) Bκ s + B 2 κ crity.
For clarity, we now provide a list of major differences between the two protocols.
(1) LR uses a more traditional cut-and-choose mechanism where one party acts as sender and the other as receiver & evaluator.
Our protocol on the other hand uses a dual-execution paradigm in which both parties play symmetric roles, so their costs are identical.Since parties act as both sender and receiver, each party performs more work than in the traditional cutand-choose paradigm.
However, the symmetry of dualexecution means that both parties are performing computational work simultaneously, rather than idle waiting.
The increase in combined work does not significantly affect latency or throughput if the communication channel is full-duplex.
(2) Our protocol can provide more flexible security guarantees; in particular, it may be used with smaller parameter choices.
In more detail, let κ s denote a statistical security parameter, meaning that the protocol allows the adversary to completely break security with probability 1/2 κ s .
In the LR protocol, a failure of the cut-and-choose step can violate all security properties, so the number of garbled circuits is proportional to κ s .
Our protocol has an additional parameter κ b , where the protocol leaks (only) a single bit to the adversary with probability 1/2 κ b .
In our protocol (as in [16]), the number of garbled circuits is proportional to κ b .
When instantiated with κ b = κ s = 40, our protocol gives an equivalent guarantee to the LR protocol with κ s = 40.
From this baseline, our protocol allows either κ s to be increased (strictly improving the security guarantee without involving more garbled circuits) or κ b to be decreased (trading performance for a small chance of a single bit leaking).
1 (3) Our online phase has superior asymptotic cost, stemming from the differences in protocol paradigmsee a summary in Figure 1.
LR uses a cheating-recovery phase, introduced in [19]: after evaluating the main circuits, the parties evaluate auxiliary circuits that allow the receiver to learn the sender's input if the receiver can "prove" that the sender was cheating.
Our protocol uses the PSI-based dual-execution reconciliation phase.The important difference is that in the LR protocol, the sender's input is provided to both the main circuits and auxiliary circuits.
If there are B main garbled circuits in a bucket, then there are B 񮽙 ≈ 3B auxiliary circuits, and garbled inputs must be sent for all of them in the online phase.
Each individual garbled input is sent by decommitting to an offline commitment, so it contributes to communication as well as a call to a hash function.
Furthermore, the cheating-recovery phase involves decommitments to garbled outputs for the auxiliary circuits, which are again proprotional to the sender's input length.In contrast, our protocol uses no auxiliary circuits so has less garbled inputs to send (and less associated decommitments to check).
Our reconciliation phase scales only with B and is independent of the parties' input size.
The overall effect is that our online phase involves significantly less communication and computation, with the difference growing as the computations involve longer inputs.
With typical parameters B = 4 and κ s = 40, our reconciliation phase is cheaper whenever |x| ≥ 54 bits.
Even for the relatively small AES circuit, our protocol sends roughly 10× less data in the online phase.
(4) LR's online phase uses 4 rounds of interaction 2 and delivers output only to one party.
If both parties require output, their protocol must be modified to include an additional round.
Our online phase also delivers outputs to both parties using either 5 or 6 rounds (depending on the choice of PSI subprotocols).
We conjecture that our protocol can be modified to use only 4 rounds, but leave that question to follow-up work.
(5) Our implementation is more efficient than LR.
The offline phase more effectively exploits parallelism and LR is implemented using a mix of Java & C++.
The architecture of LR has a serial control flow with computationally heavy tasks performed in parallel using low level C++ code.
In contrast, our protocol implementation is in C++ and fully parallelized with low level synchronization primitives.
Another paradigm for malicious security in the online/offline setting is based not on garbled circuits but arithmetic circuits and secret sharing.
Notable protocols and implementations falling into this paradigm include [8,9,10,11,27].
These protocols indeed have lightweight online phases, and many instances can be batched in parallel to achieve throughput comparable to our protocol.
However, all of these protocols have an online phase whose number of rounds depends on the depth of the circuit being evaluated.
As a result, they suffer from significantly higher latency than the constant-round protocols in the garbled circuit paradigm like ours.
The latest implementations of [9] can securely evaluate AES with online latency 20ms [33].
Of special note is the implementation of the [11] protocol reported in [10], which achieves latency of only 6ms to evaluate AES.
However, the implementation is heavily optimized for the special case of computing AES, and it is not clear how applicable their techniques are for general-purpose MPC.
In any case, no protocol has reported online latency for AES that is less than our protocol's total offline+online cost.The above protocols based on secret-sharing also have significantly more expensive offline phases.
Not all implementations report the cost of their offline phases, but the latest implementations of the [9] protocol require 156 seconds of offline time for securely computing AES [33]; many orders of magnitude more than ours.
We note that the protocols in the secret-sharing paradigm have an offline phase which does not depend on the function that will be evalauted, whereas ours does.
Secure computation.
We use the standard notion of universally composable (UC) security [6] for 2-party computation.
Briefly, the protocol is secure if for every adversary attacking the protocol, there is a straight-line simulator attacking the ideal functionality that achieves the same effect.
We assume the reader is familiar with the details.We define the ideal functionality F multi-sfe that we achieve in Figure 2.
The functionality allows parties to evaluate the function f , N times.
Adversaries have the power to delay (perhaps indefinitely) the honest party's output, which is typical in the setting of malicious security.
In other words, the functionality does not provide output fairness.Furthermore, the functionality occasionally allows the adversary to learn an arbitrary additional bit about the inputs.
This leakage happens according to the distribution L chosen by the adversary at setup time.
The probability of a leaked bit in any particular evaluation of f is guaranteed to be at most ε.
Further, the leakage is "risky" in the sense that the honest party detects cheating when the leaked bit is zero.Building blocks.
In Figures 10 & 11 we define oblivious transfer (OT) and commitment functionalities that are used in the protocol.
In the random oracle model, where H is the random oracle, a party can commit to v by choosing random r ← {0, 1} κ c and sending c = H(r񮽙v).
We use and adapt the Garbled Circuit notation and terminology of [5]; for a formal treatment, consult that paper.
In Appendix A we define the syntax and security requirements, highlighting the differences we adopt compared to [5].
We now give a high-level outline of the (nononline/offline) 2PC protocol paradigm of [16], which is the starting point for our protocol.
The protocol makes use of a two-phase PSI subprotocol.
In the first phase, both parties become committed to their PSI inputs; in the second phase, the PSI output is revealed.
This component is modeled in terms of the F n,, psi functionality in Figure 12.
Assume the parties agree on a function f to be evaluated on their inputs.
The protocol is symmetric with respect to Alice and Bob, and for simplicity we describe only Alice's behavior.
Setup stage: On common input (SETUP, f , N, ε) from both parties, where f is a boolean circuit:• If neither party is corrupt, set L = 0 N .
Otherwise, wait for input (CHEAT, L ) where L is a distribution over {0, 1} N ∪ {⊥} with the property that for every i,Pr L←L [L i = 1] ≤ ε.Sample L ← L using random coins χ and give (CHEATRESULT, χ) to the adversary.
If L = ⊥ then give output (CHEATING!)
to the honest party and stop responding.
• Send output (READY) to both parties.
Initialize counter ctr = 1.
Proceed to the execution stage.Execution stage: Upon receiving inputs (INPUT, x 1 ) from P 1 and (INPUT, x 2 ) from P 2 :• Compute z = f (x 1 , x 2 ).
If both parties are honest, give (OUTPUT, ctr, z) to both parties.
• If any party is corrupt, give (OUTPUT, ctr, z) to the adversary.
• If L ctr = 1, wait for a command (LEAK, P) from the adversary, where P is a boolean predicate.
Compute p = P(x 1 , x 2 ) and give (LEAKRESULT, p) to the adversary.
• If any party is corrupt, then on input (DELIVER) from the adversary, if p = 0 above, then give output (CHEATING!)
to the honest party, else give output (OUTPUT, ctr, z) to the honest party.
• If ctr = N then stop responding; otherwise set ctr = ctr + 1 and repeat the execution stage.
the output is {R * } then Alice outputs the value y such that R * = R y .
Suppose Alice is corrupt and Bob is honest.
We will argue that Alice learns nothing beyond the function output, except that with probability 2 −κ b she learns a single bit about Bob's input.Suppose Alice uses input x 1 as input to the OTs, and Bob has input x 2 .
Since Bob's circuits are honestly generated and use the same garbled output encoding, every circuit evaluated by Alice leads to the same garbled output Y b y * that encodes logical value y * = f (x 1 , x 2 ).
Note that by the authenticity property of the garbled circuits, this is the only valid garbled output that Alice can predict.Since Alice may generate malicious garbled circuits, honest Bob may obtain several candidate outputs from these circuits.
Bob's input to the PSI computation will be a collection of reconciliation values, each of the formR y = 񮽙 [Y a y ∪Y b y ].
At the time of PSI input, none of Bob's (honestly) garbled circuits have been opened, so they retain their authenticity property.
Then Alice cannot predict any valid reconciliation value except for this R y * .
This implies that the PSI output will be either {R y * } or / 0.
In particular, Bob will either abort or output the correct output y * .
Furthermore, the output of the PSI computation can be simulated knowing only whether honest Bob has included R y * in his PSI input.The protocol includes a mechanism to ensure that Alice uses the same x 1 input for all of the garbled circuits.
Hence, if Bob evaluates at least one correctly generated garbled circuit, it will give output y * and Bob will surely include the R y * reconciliation value in his PSI input.
In that case, the PSI output can be simulated as usual.The probability the Alice manages to make Bob evaluate no correctly generated garbled circuits is 2 −κ b -she would have to completely predict Bob's cut-and-choose challenge to make all opened circuits correct and all evaluated circuits incorrect.
But even in this event, the simulator only needs to know whether f 񮽙 (x 1 , x 2 ) = y * for any of the f 񮽙 computed by Alice's malicious garbled circuits.
This is only one bit of information about x 2 which the simulator can request from the ideal functionality.
Our high-level approach is to adapt the [16] protocol to the online/offline setting.
The idea is that the two parties plan to securely evaluate the same function f , N times, on possibly different inputs each time.
In preparation they perform an offline pre-processing phase that depends only on f and N, but not on the inputs.
They generate many garbled circuits and perform a cut-and-choose on all of them.
Then the remaining circuits are assigned randomly to buckets.
Later, once inputs are known in the online phase, one bucket's worth of garbled circuits are consumed for each evaluation of f .
Our protocol will leak a single bit about the honest party's input only when a bucket contains no "good" circuit from the adversary (where "good" is the condition that is verified for opened circuits during cut-andchoose).
Following the lead of [23], we focus on choosing the number of circuits so that the probability of such an event in any particular bucket is 2 −κ b .
We note that the analysis of parameters in [14,22] considers an overall cheating condition, i.e., that there exists a bucket that has no "good" circuits, which leads to slightly different numbers.Lemma 1 ( [23]).
If the parties plan to perform N exe-cutions, using a bucket of B circuits for each execution and a total of 񮽙 N ≥ NB garbled circuits generated for the overall cut-and-choose, then the probability that a specific bucket contains no good circuit is at most:max t∈{B,...,NB}    񮽙 񮽙 N−t NB−t 񮽙 񮽙 񮽙 N NB 񮽙 · 񮽙 t B 񮽙 񮽙 NB B 񮽙    .
Suppose the parties will perform N executions, using buckets of size B in the online phase, and wish for 2 −κ b probability of leakage.
We can use the formula to determine the smallest compatible 񮽙 N.
In the full version we show all reasonable parameter settings for κ b ∈ {20, 40, 80} and N ∈ {8, 16, 32,.
.
.
,32768}.
By adapting [16] to the online/offline setting, we obtain the generic protocol outlined in Figure 3.
Even with pre-processing, an online OT requires two rounds, one of which can be combined with the direct sending of garbled inputs.
The protocol therefore requires three rounds plus the number of rounds needed for the PSI subprotocol (at least two).
We highlight which parts of the [16] protocol break down in the online/offline setting and require technical modification:Same garbled output encoding.
In [16] each party is required to generate garbled circuits that have a common output encoding.
Their protocol includes a mechanism to enforce this property.
In our setting, we require each bucket of circuits to have the same garbled output encoding.
But this is problematic because in our setting a garbled circuit is generated before the parties know which bucket it will be assigned to.Our solution is to have the garbler provide for each bucket a translation of the following form.
The garbler chooses a bucket-wide garbled output encoding; e.g., for the first output wire, he chooses wire labels W * 0 ,W * 1 encoding false and true, respectively.
Then if W j 0 ,W j 1 are the output wire labels already chosen for the jth circuit in this bucket, the garbler is supposed to provide trans-lation values W j v ⊕ W * v for v ∈ {0, 1}.
After evaluating, the receiver will use these values to translate the garbled input to this bucket-wide encoding that is used for PSI reconciliation.Of course, a cheating party can provide invalid translation values.
So we use step 3 of the online phase ( Figure 3) to check them.
In more detail, a sender must commit in the offline phase to the output wire labels of every garbled circuit.
These will be checked if the circuit is chosen in the cut-and-choose.
In step 3 of the online phase, these commitments are opened so that the receiver can check the consistency of the translation values (i.e., whether 3) and abort if it is found to be invalid.
(4) The parties release the PSI output and abort if the output is / 0.
Otherwise, they output the plaintext value whose reconciliation value is in the PSI output.
they map to a hash of the common bucket-wide encoding provided during bucketing.)
.
This step reveals all of the bucket-wide encoding values, making it now easy for an adversary to compute any reconciliation value.
This is why we employ a 2-phase PSI protocol, so that PSI inputs are committed before these translation values are checked.Adaptive garbling.
Standard security definitions for garbled circuits require the evaluator to choose the input before the garbled circuit is given.
However, the entire purpose of offline pre-processing is to generate & send the garbled circuits before the inputs are known.
This requires the garbling scheme to satisfy an appropriate adaptive security property, which is common to all works in the online/offline setting [14,22].
See Appendix A for details.Input consistency.
To achieve security against active adversaries, GC-based protocols must ensure that parties provide the same inputs to all circuits that are evaluated.
This is known as the problem of input consistency.
The protocol of [16] uses the input consistency mechanism of shelat & Shen [32] which is unfortunately not compatible with the online/offline setting.
More details follow in the next section.
In this section we describe a new, extremely lightweight input-consistency technique that is tailored for the dualexecution paradigm.
We start with the "classical" dual-execution scenario, where Alice and Bob each generate one garbled circuit.We describe how to force Alice to use the same input in both of these garbled circuits (of course, the symmetric steps are performed for Bob).
The high-level idea is to bind her behavior as OT receiver (when obtaining garbled inputs for Bob's circuits) to the commitments of her garbled inputs in her own circuits.
It is well-known [2] that oblivious transfers on random inputs can be performed offline, and later "derandomized" to OTs of chosen inputs.
In the offline phase of our protocol, the parties perform a random OT for each Alice-input wire of each circuit, where Alice acts as the receiver.
These will be later used for Alice to pick up her garbled input for Bob's circuit.
Let c denote the string denoting Alice's random choice bits for this collection of OTs.Also in the offline phase, we will have Alice commit to all of the possible garbled input labels for the circuits that she generated.
Suppose she commits to them in an order determined by the bits of c; that is, the wire label commitments for the first input wire are in the order (false,true) if the first bit of c is 0 and (true,false) otherwise.In the online phase with input x, Alice sends the OT "derandomized" message d = x ⊕ c.
She also sends her garbled inputs for the circuits she generated by opening the commitments indexed by d; that is, she opens the first or second wire label of the ith pair, depending on whether Looking ahead, we will use cut-and-choose to guarantee that there is at least one circuit for which Alice's garbled input commitments are correct in this way.
d i = 0 or d i = 1, * 0 ⊕ (m d ⊕ m 񮽙 d⊕δ ) and m * 1 ⊕ (m 1⊕d ⊕ m 񮽙 1⊕d⊕δ).
The idea extends to aggregate any number B of different random OTs into a single one, with Alice sending B − 1 different δ difference values.
In our protocol, we aggregate in this way the OTs for the same wire across different circuits.
Intuitively, Alice either receives wire labels for the same value on each of these wires (by reporting correct δ values), or else she receives nothing for this wire on any circuit.
Now consider a bucket of B circuits.
In the offline phase Alice acts as receiver in many random OTs, one collection of them for each of Bob's circuits.
Let c j be her (string of) choice bits for the OTs associated with the jth circuit.
Alice is then supposed to commit to the garbled inputs of her jth circuit arranged according to c j .
Bob will check this property for all circuits that are opened during the cut-and-choose phase by Alice showing the corresponding OT messages.
3 Hence with probability at least 1 − 2 −κ b , at least one circuit in any given bucket has this property.
Alice also reports aggregation values δ j = c 1 ⊕ c j for these OTs.In the online phase Alice chooses her input x and sends d 1 = c 1 ⊕ x as the OT-derandomization message.
This is equivalent to Alice sending d j = δ j ⊕ d 1 as the message to derandomize the jth OTs.
To send her garbled input for the jth circuit, Alice is required to open her commitments indexed by d j .
If Alice lies in any of the aggregation strings, then she will be missing at least one of the B-out-of-B secret shares which mask her possible inputs.
Intuitively, Alice's two strategies are either to provide honest aggregation strings or not obtain any garbled inputs in the position that she lied.
In the latter case, the simulator can choose an arbitrary input for Alice in that position.If we then consider the likely case where Bob's jth circuit is "good" and Alice provided honest aggregation strings, then Alice will have decommitted to inputs for the jth circuit that are consistent with her effective OT input x * 1 .
From the discussion in Section 4.1, this is enough to guarantee that the reconciliation phase leaks nothing.Even if there are no "good" circuits in the bucket (which happens with probability 1/2 κ b ), it is still the case that Alice learns no more than if she had received consistent garbled input x * 1 for all of Bob's circuits.
So the reconciliation phase can be simulated knowing only whether Bob evaluates any circuit resulting in f (x * 1 , x 2 ).
This is a single bit of information about Bob's input x 2 .
In the garbled circuit paradigm, suppose Alice is acting as evaluator of some garbled circuits.
She uses OT to pick up the wire labels corresponding to her input.
A corrupt Bob could provide incorrect inputs to these OTs, so that (for instance) Alice picks up an invalid garbled input if and only if the first bit of her input is 0.
By observing whether the evaluator aborts (or produces otherwise unexpected behavior), Bob can deduce the first bit of Alice's input.
This kind of attack, where the adversary causes the honest party to abort/fail with probability depending on its private input is called a selective failure attack.A common way to prevent selective failure is to use what is called a k-probe-resistant input encoding:Definition 2 ( [20,32] ( ˜ x 1 , x 2 ) = f (M ˜ x 1 , x 2 ).
This additional computation of M ˜ x 1 involves only XOR operations, so it does not increase the garbled circuit size when using the Free-XOR optimization [17] (it does increase the number OTs needed).
Alice will now use˜xuse˜ use˜x 1 as her choice bits to the OTs.
The adversary can probe any number of bits of˜xof˜ of˜x 1 , by inserting invalid inputs to the OT in those positions, and seeing whether the other party aborts.
For each position probed, the adversary incurs a 1/2 probability of being caught.
4 The property of k-probe-resistance implies that probing k bits of the physical input˜xinput˜ input˜x 1 leaks no information about the logical input M ˜ x 1 .
However, probing k bits incurs a 1 − 2 −k probability of being caught.
Hence, our protocol requires a matrix that is κ s -probe resistant, where κ s is the statistical security parameter.
We refer the reader to [23] for the construction details of k-probe resistant matrices and their parameters.
Using k-probe-resistant encodings, the encoded input˜xinput˜ input˜x 1 is significantly longer than the logical input x 1 .
While the computation of M ˜ x 1 within the garbled circuit can involve no cryptographic operations (using Free-XOR), it still involves a quadratic number of XOR operations.Lindell & Riva [22] suggest a technique that moves these computations associated with k-probe-resistant encodings to the offline phase.
The parties will compute the related functionf 񮽙 ( ˆ x 1 , c, x 2 ) = f ( ˆ x 1 ⊕ Mc, x 2 ).
In the offline phase, Alice will use OT to obtain wire labels for a random string c.
She can also begin to partially evaluate the garbled circuit, computing wire labels for the value Mc.In the online phase, Alice announcesˆxannouncesˆ announcesˆx 1 = x 1 ⊕ Mc where x 1 is her logical input.
Then Bob directly sends the garbled inputs corresponding tô x 1 .
This introduces an asymmetry into our input consistency technique.
The most obvious solution to maintain compatibility is to always evaluate circuits of the formf 񮽙 ( ˆ x 1 , c 1 , ˆ x 2 , c 2 ) = f ( ˆ x 1 ⊕ Mc 1 , ˆ x 2 ⊕ Mc 2 ), so that Alice uses the same physical input (c 1 , ˆ x 1 ) in both hers and Bob's circuits.
However, we would prefer to let Alice use logical input x 1 rather than its (significantly longer) k-probe-encoded input, to reduce the concrete overhead.
It turns out that we can accommodate this by exploiting the Z 2 -linearity of the encoding/decoding operation.Consider a bucket of circuits {1,.
.
.
,B}.
For the jth circuit, Alice acts as receiver in a set of random OTs, and receives random choice bits c j .
The number of OTs per circuit is the number of bits in a k-probe-resistant encoding of Alice's input.
For Alice's jth circuit, she must commit to her garbled inputs in the order given by the string Mc j (rather than just c j as before).
This condition will be checked by Bob in the event that this circuit is opened during cut-andchoose.
To assemble a bucket, Alice reports aggregation values δ j = c 1 ⊕c j as before.
Imagine Alice derandomizing these OTs by sending an all-zeroes derandomization message.
This corresponds to her accepting the random c 1 as her choice bits.
(Of course, an all-zeroes message need not be actually sent.)
Bob responds and uses the aggregated OTs to send Alice the garbled inputs for c 1 for all of his garbled circuits (indeed, even in the jth circuit Alice receives garbled inputs corresponding to c 1 ).
In the online phase, Alice decides her logical input x 1 , and she sendsˆxsendsˆ sendsˆx 1 = Mc 1 ⊕ x 1 .
This value derandomizes the offline k-probe-resistant encoding.
Then in her own jth circuit, Alice must open the garbled input commitments indexed by the (public) stringˆxstringˆ stringˆx 1 ⊕ Mδ j .
To see why this solution works, suppose that Alice's jth circuit is "good" (i.e., garbled correctly and input commitments arranged by Mc j ).
As before, define her effective OT input to the jth OTs as c * = c j ⊕ δ j (which should be c 1 if Alice did not lie about δ j ).
Even if Alice lied about the δ values she surely learns no more than she would have learned by being truthful about the δ values and using effective input c * in all OTs.
Hence, we can imagine that she uses logical inputx * 1 = ˆ x 1 ⊕ Mc * in all of Bob's garbled circuit.Alice is required to open garbled inputs indexed byˆx byˆbyˆx 1 ⊕ Mδ j = ˆ x 1 ⊕ M(c * ⊕ c j ) = x * 1 ⊕ Mc j .
These are exactly the garbled inputs corresponding to logical input x * 1 , since the commitments were arranged according to Mc j .
We see that Bob evaluates at least one correctly garbled circuit with Alice using input x * 1 , which is all that is required for weak input consistency.
Our main insight is that our PSI reconciliation step does not require a fully (UC) secure PSI protocol.
Instead, a weaker security property suffices.
Recall that the final steps of the [16] protocol proceed as follows:• Alice & Bob commit to their PSI inputs.
• The garbled-output translations are opened and checked.
• The parties either abort or release the PSI output.
For simplicity, assume for now that only one party receives the final PSI output.
We will address two-sided output later.Suppose Alice is corrupt and Bob is honest.
Following from the discussion of security in Section 4, Bob will use as PSI input a collection of valid reconciliation values.
At the time Alice provides her PSI inputs, the authenticity property of the garling scheme is in effect.
This means that Alice can predict a valid reconciliation value only for the "correct" output y * .
All other valid reconciliation values that might be part of Bob's PSI input are unpredictable.Below we formalize a weak notion of security for input distributions of this form:Definition 3.
Let Π be a two-phase protocol for set intersection (F n,, psi , Figure 12).
We say that Π is weakly malicious-secure if it achieves UC-security with respect to environments that behave as follows: (1 In this definition, the adversary knows only one value in the honest party's set, while all other values are essentially uniform.
We claim that when 񮽙 is large, the simulator for this class of environments does not need to fully extract the adversary's PSI input!
Rather, the following are enough to ensure weakly-malicious security:• The adversary is indeed committed to some (unknown to the simulator) effective input during the commit phase.
• The simulator can test whether the adversary's effective PSI input contains the special value a * .
With overwhelming probability, no effective input element other than a * can contribute to the PSI output.
Any other values in the adversary's effective input can simply be ignored; they do not need to be extracted.For technical reasons and convenience in the proof, we have the environment give the adversary the coins used to sample A, but only after the PSI input phase.
We now describe an inexpensive protocol paradigm for PSI, due to Pinkas et al. [30].
Their protocol is proven secure only against passive adversaries.
We later discuss how to achieve weak malicous security.The basic building block is a protocol for private equality test (PEQT) based on OT.
A benefit of using OT-based techniques is that the bulk of the effort in generating OTs can be done in the offline phase, again leading to a lightweight online phase for the resulting PSI protocol.Suppose a sender has input s and receiver has input r, with r, s ∈ {0, 1} n , where the receiver should learn whether r = s (and nothing more).
The PEQT protocol requires n string OTs; in the ith one, the receiver uses choice bit r [i] , j) and send {S 1 ,.
.
.
,S t }, where F is a PRF.
5 The receiver can check whether񮽙 i F(m ir [i] , j) matches S j for any j. Finally, we can achieve a PSI where the receiver has strings {r 1 ,.
.
.
,r t } by running independent PSMTs of the form r j ∈ {s 1 ,.
.
.
,s t } for each r j (in random order).
The overhead of this approach is O(t 2 ), and [30] describe ways to combine hashing with this basic PSI protocol to obtain asymptotically superior PSI protocols for large sets.
However, we are dealing with very small values of t (typically at most 5), so the concrete cost of this simple protocol is very low.To make the PSI protocol two-phase, we run the OTs and commit to the S values in the input-committing phase.
Then the output phase consists simply of the sender opening the commitments to S. and double-sided output.We use the [30] protocol but instantiate it with malicioussecure OTs.
This leads to the standard notion of security against an active receiver since the simulator can extract the receiver's input from its choice bits to the OTs.
However, the protocol does not achieve full security against a malicious sender.
In the simple PEQT building block, the simulator cannot extract a malicious sender's input.
Doing so would require inspecting S, {m i b } and determining a value s such that S = 񮽙 i m i s [i] .
Such an s may not exist, and even if it did, the problem seems 5 Simply XORing the m i b values would reveal some linear dependencies; applying a PRF renders all of the S j values independently random except the ones for which r = s j .
closely related to a subset-sum problem.However, if the simulator knows a candidate s * , it can certainly check whether the corrupt sender has sent the corresponding S value.
This is essentially the only property required for weakly malicious security.We note that a corrupt sender could use inconsistent sets {s 1 ,.
.
.
,s t } in the parallel PSMT instances.
However, the simulator can still extract whether the candidate s * was used in each of them.
If the sender used s * in t 񮽙 of the t subprotocols, then the simulator can send s * to the ideal PSI functionality with probability t 񮽙 /t, which is a sound simulation for weakly-malicious security.Regarding double-sided output, it suffices to simply run two instances of the one-sided-output PSI protocol, one in each direction, in parallel.
Again, this way of composing PSI protocols is not sound in general, but it is sound for the special case of weakly-malicious security.
complexity.Even when random OTs are pre-processed offline, the PSI protocol as currently described requires two rounds to commit to the outputs, and one round to release the output.
The two input-committing rounds are (apparently) inherently sequential, stemming from the sequential nature of OT derandomization.In terms of round complexity, these two PSI rounds are a bottleneck within the overall dual-execution protocol.
We now describe a variant of the PSI protocol in which the two input-committing messages are asynchronous and can be sent simultaneously.
The modified protocol involves (a nontrivial amount of) additional computation but reduces the number of rounds in the overall 2PC online phase by one.
This tradeoff does not always reduce the overall latency of the 2PC online phase -only sometimes, depending on the number of garbled circuits being evaluated and the network latency.
The specific break-even points are discussed in Section 9.
In our PEQT protocol above, the two parties have preprocessed random OTs, with choice bits c and random strings m i 0 , m i 1 .
To commit to his PSI input, the receiver's first message is d = c ⊕ r, to which the sender responds with S = 񮽙 i m i d [i]⊕s [i] .
Consider randomizing the terms of this summation asS = 񮽙 i [m i d[i]⊕s[i] ⊕ z i ]where z i are random subject to 񮽙 i z i = 0.
Importantly, (1) each term in this sum depends only on a single bit of d; (2) revealing all terms in the sum reveals no more than S itself.
We let the sender commit to all the potential terms of this sum and reveal them individually in response to d.
In more detail, the sender commits to the following values (in this order):(񮽙) [m 1 s[1] ⊕ z 1 ] [m 2 s[2] ⊕ z 2 ] ·· · [m n s[n] ⊕ z n ] [m 1 s[1]⊕1 ⊕ z 1 ] [m 2 s[2]⊕1 ⊕ z 2 ] ·· · [m n s[n]⊕1 ⊕ z n ]Importantly, these commitments can be made before d is known.
In response to the message d from the receiver, the sender is expected to release the output by opening the commitments indexed by the bits of d.
The sender will open the commitments {m i d [i]⊕s [i] ⊕ z i }; the receiver will compute their XOR S and proceed as before.The simulator for a corrupt sender simulates a random message d and then checks whether the sender has used a candidate input s * by extracting the commitments indexed by d to see whether their XOR is For completeness, we provide formal descriptions of the final PSI protocols (synchronous 3-round and asynchronous 2-round) in Figures 13 & 14.
We defer the proof of their security to the full version.
The full details of our protocol are given in Figure 15 and the c++ implementation may be found at https: //github.com/osu-crypto/batchDualEx.
The protocol uses three security parameters: κ b is chosen so that the protocol will leak a bit to the adversary with probability at most 2 −κ b .
This parameter controls the number of garbled circuits used per execution.κ s is the statistical security parameter, used to determine the length of the reconciliation strings used as PSI input (the PSI protocol scales with the length of the PSI input values).
The adversary can guess an unknown reconciliation value with probability at most 2 −κ s .
κ c is the computational security parameter, that controls the key sizes for OTs, commitments and garbled circuits.
In our evaluations we consider κ c = 128, κ s ∈ {40, 80} and κ b ∈ {20, 40, 80}.
In the full version we prove the security of our protocol:Theorem 5.
Our protocol (Figure 15) securely realizes the F multi-sfe functionality, in the presence of malicious adversaries.
In the offline phase, the work is divided between p parallel sets of 4 threads.
Within each set, two threads generate OTs and two threads garble and receive circuits and related commitments.
Parallelizing OT generation and circuit generation is key to our offline performance; we find that these two activities take roughly the same time.We generate OTs using an optimized implementation of the Keller et al. [15] protocol for OT extension.
Starting from 128 base OTs (computed using the protocol of [28]), we first run an OT extension to obtain 128 · p OT instances.
We then distribute these instances to the p different thread-sets, and each thread-set uses its 128 OT instances as base OTs to perform its own independent OT extension.We further modified the OT extension protocol to process and finalize OT instances in blocks of 128 instances.
This has two advantages: First, OT messages can be used by other threads in the offline phase as they are generated.
Second, OT extension involves CPU-bound matrix transposition computations along with I/O-bound communication, and this approach interlaces these operations.The offline phase concludes by checking the circuits in the cut-and-choose, bucketing the circuits, and exchanging garbled inputs for the random k-probe-encoded inputs.The online phase similarly uses threading to exploit the inherently parallel nature of the protocol.
Upon receiving input, a primary thread sends the other party their input correction value as the first protocol message.
This value is in turn given to B sub-threads (where B is the bucket size) that transmit the appropriate wire labels.
Upon receiving the labels, the B threads (in parallel) each evaluate a circuit.Each of the B threads then executes (in parallel) one of the set-membership PSI subprotocols.
After the other party has committed to their PSI inputs, the translation tables of each circuit is opened and checked in parallel.
The threads then obtain the intersection and the corresponding output value.
We instantiate the garbled circuits using the state-of-theart half-gates construction of [35].
The implementation utilizes the hardware accelerated AES-ni instruction set and uses fixed-key AES as the gate-level cipher, as suggested by [3].
Since circuit garbling and evaluation is the major computation bottleneck, we have taken great care to streamline and optimize the execution pipeline.The protocol requires the bucket's common output labels to be random.
Instead, we can optimize the online phase choose these labels as the output of a hash at a random seed value.
The seed can then be sent instead of sending all of the common output labels.
From the seed the other party regenerates the output labels and proceed to validate the output commitments.
We evaluated the prototype on Amazon AWS instances c4.8xlarge (64GB RAM and 36 virtual 2.9 GHz CPUs).
We executed our prototype in two network settings: a LAN configuration with both parties in the same AWS geographic region and 0.2 ms round-trip latency; and a WAN configuration with parties in different regions and 75 ms round-trip latency.We demonstrate the scalability of our implementation by evaluating a range of circuits:• The AES circuit takes a 128-bit key from one party and a 128-bit block from another party and outputs a 128-bit block to both.
The circuit consists of 6800 AND gates and 26,816 XOR gates.
• The SHA256 circuit takes 512 bits from both parties, XORs them together and returns the 256-bit hash digest of the XOR'ed inputs.
The circuit consists of 90,825 AND gates and 145,287 XOR gates.
• The AES-CBC-MAC circuit takes a 16-block (2048-bit) input from one party and a 128-bit key from the other party and returns the 128-bit result of 16-round AES-CBC-MAC.
The circuit consists of 156,800 AND gates and 430,976 XOR gates.
7 In all of our tests, we use system parameters derived from Lemma 1.
N denotes the number of executions, and B denotes the bucket size (number of garbled circuits per execution) and we use ∼ B online threads.
In Section 7 we describe two PSI protocols that can be used in our 2PC protocol -a synchronous protocol that uses three rounds total, and an asynchronous protocol that uses two rounds total (at higher communication cost).
We now discuss the tradeoffs between these two PSI protocols.
A summary is given in Figure 5.
For small parameters in the LAN setting, the 2-round asynchronous protocol is faster overall, but for larger parameters the 3-round synchronous protocol is faster.
This is We compare our prototype to that of [23] with 40-bit security.
That is, we use κ b = κ s = 40; both protocols have identical security and use the same bucket size.
We use identical AWS instances and a similar number of threads to those reported in [23].
Figure 6 shows the results of the comparison in the LAN setting.
It can be seen that our online times are 5 to 7 times faster and our offline times are 4 to 15 times faster.
Indeed, for N = 1024 our total (online plus offline) time is less than the online time of [23].
In the WAN setting with small circuits such as AES where the input size is minimal we see [23] achieve faster online times.
Their protocol has one fewer round than ours protocol, which contributes 38ms to the difference in performance.
However, for the larger SHA256 circuit our implementation outperforms that of [23] by 16 to 100ms per execution and we achieve a much more ef- ficient offline phase ranging from 4 to 22 times faster for both circuits.
As discussed in Section 2.3, our protocol has asymptotically lower online communication cost, especially for computations with larger inputs.
Since both protocols are more-or-less I/O bound in these experiments, the difference in communication cost is significant.
Concretely, when evaluating AES with N = 1024 and B = 4 our protocol sends 16, 384 bytes of wire labels and just 564 bytes of PSI data.
The online phase of [23] reports to use 170, 000 bytes with the same parameters.
Even using our asynchronous PSI sub-protocol, the total PSI cost is only 10,280 bytes.κ b = κ s = 80 κ b = κ s = 40 κ b = 20; κ s = 40 We show in Figure 7 how our prototype scales for different settings of security parameters in the LAN setting.
In particular, the security properties of our protocol allow us to consider smaller settings of parameters than are advised with traditional cut-and-choose protocols such as [23].
As a representative example, we consider κ b = 20 and κ s = 40 which means that our protocol will leak a single bit only with probability 1/2 20 but guarantee all other security properties with probability 1 − 1/2 40 .
Our protocol scales very well both in terms of security parameter and circuit size.
Each doubling of κ s only incurs an approximate 25% to 50% increase in running time.
This is contrasted by [23] reporting a 200% to 300% increase in running time for larger security parameters.
Our improvement is largely due to reducing the number of cryptographic steps and no cheat-recovery circuit which consume significant online bandwidth.We see a more significant trend in the total storage requirement of the offline phase.
For example, when performing N = 1024 AES evaluations for security parameter κ b = 20 the protocol utilizes a maximum of 0.76 GB of storage while κ b = 40 requires 1.6 GB of storage.
This further validates κ b = 20 as a storage and bandwidth saving mechanism.
[23] munication for N = 1024 and 40-bit security.
In addition to considering the setting when executions are performed sequentially, we tested our prototype when performing many executions in parallel to maximize throughput.
Figure 8 shows the maximum average throughput for AES evaluations that we were able to achieve, under different security parameters and bucket sizes.
The time reported is the average number of milliseconds per evaluation.In the LAN setting, 8 evaluations were performed in parallel and achieved an amortized time of 0.26ms per evaluation for bucket size B = 2.
A bucket size of 2 can be obtained by performing a modest number (say N = 256) of executions with κ b = 20, or a very large number of executions with κ b = 40.
We further tested our prototype in the WAN setting where we obtain a slightly decreased throughput of 0.72ms per AES evaluation with 40-bit security.
A garbling scheme is a tuple of algorithms (Gb, En, Ev, De) with the following syntax and semantics.
All algorithms accept a security parameter as explicit input, which we leave implicit.
•Gb( f , d) → (F, e);Here f is a boolean circuit with m inputs and n outputs; d is an n × 2 array of (output) wire labels; F is a garbled circuit; and e is an m × 2 array of input wire labels.By wire labels, we simply mean strings (i.e., elements of {0, 1} κ c ).
We deviate from [5] in requiring the output wire labels d to be chosen by the caller of Gb, rather than chosen by Gb itself.
In the notation of [5], we assume that the scheme is projective in both its input and output encodings, meaning that e and d consist of two possible wire labels for each wire.
• En(e, x) → X takes an m × 2 array of wire labels e and a plaintext input x ∈ {0, 1} m and outputs a garbled encoding X of x. By assuming that the scheme is projective, we assume that X = (X 1 ,.
.
.
,X m ) whereX i = e[i, x i ].
• Ev(F, X) → Y ; takes a garbled circuit F and garbled encoding X of an input, and returns a garbled encoding of the output Y .
• 񮽙 De(Y ) → y.
We assume a way to decode a garbled output to a plaintext value.
It is a deviation from [5] to allow this to be done without the decoding information d. Rather, we may assume that the garbled outputs contain the plaintext value, say, as the last bit of each wire label.
Our correctness condition is that for the variables defined above, we have Ev(F, En(e, x)) = En(d, f (x)) and 񮽙 De(Ev(F, En(e, x))) = f (x) for all inputs x to the circuit f .
In other words, evaluating the garbled circuit should result in the garbled output that encodes f (x) under the encoding d.In our construction, an adversary sees the garbled circuit F first, then it receives some of the garbled inputs (corresponding to the k-probe matrix encoded inputs).
Finally in the online phase it is allowed to choose the rest of its input to the ciruict and receive the rest of the garbled inputs.
Hence, our security game considers an adversary that can obtain the information in this order.We overload the syntax of the encoding algorithm En.
Since En is projective, we write En(e, i, b) to denote the component e i,b -that is, the garbled input for the ith wire corresponding to truth value b. Recall that we also garble a circuit with output wire labels d specified (rather than chosen by the Gb algorithm).
Our security definition lets the adversary choose d.Definition 6.
For a garbling scheme (Gb, En, Ev, De), an interactive oracle program Adv, and algorithms S = (S 0 , S 1 , S 2 ), we define the following two games/interactions:G Adv real : get f , d from Adv H (F, e) ← Gb( f , d) give F to Adv H for i = 1 to m: get x i from Adv H X i ← En(e, i, x i ) give X i to Adv H Adv H outputs a bit G Adv,S ideal : get f , d from Adv S 0 F ← S 1 ( f ) give F to Adv S 0 for i = 1 to m − 1: get x i from Adv S 0 X i ← S 2 (i) give X i to Adv S 0 get x m from Adv S 0 y = f (x 1 ·· ·x m ) Y ← En(d, y) X m ← S 2 (m, y,Y )give X m to Adv S 0 Adv S 0 outputs a bit In G ideal , H is a random oracle.
In G ideal , the tuple S = (S 0 , S 1 , S 2 ) all share state.
All algorithms receive the security parameter as implicit input.Then the garbling scheme is adaptively secure if there exists a simulator S such that for all polynomial-time adversaries Adv, we have that񮽙 񮽙 Pr[G Adv real outputs 1] − Pr[G Adv,S ideal outputs 1] 񮽙 񮽙is negligible in the security parameter.Note that in the G ideal game, the simulator receives no information about the input x as it produces the garbled circuit F and all but one of the garbled input components.
Finally when producing the last garbled input component, the simulator learns f (x) and its garbled output encoding En(d, f (x)).
In particular, the simulator receives no information about x, so its outputs carry no information about x beyond f (x).
The game also implies an authenticity property for garbled outputs of values other than f (x) -the simulator's total output contains no information about the rest of the garbled outputs d.In Figure 9 we describe a generic, random-oracle transformation from a standard (static-secure) garbling scheme to one with this flavor of adaptive security.
The construction is quite similar to the transformations in [4], with some small changes.
First, since we know in advance which order the adversary will request its garbled inputs, we include the random oracle nonce R in the last garbled input value (rather than secret-sharing across all garbled inputs).
Second, since we garble a circuit with particular garbled output values in mind, we provide "translation values" that will map the garbled outputs of the static scheme to the desired ones.
These translation values also involve the random oracle, so they can be equivocated by the simulator.
De) is a doublyprojective garbling scheme satisfying the (static) prv and aut properties of [5] then the scheme in Figure 9 satisfies adaptive security notion of Definition 6 in the random oracle model.The proof is very similar to analogous proofs in [4].
The main idea is that the simulator can choose the "masked" 񮽙 F and δ translation values upfront.
Then it is only with negligible probability that an adversary will call the random oracle on the secret nonce R, so the relevant parts of the oracle are still free to be programmed by the simulator.
When the adversary provides the final bit of input, the simulator gets f (x) and can obtain a simulated garbled circuit F and garbled outputs d from the static-secure scheme.
Then it can program the random oracle to return the appropriate masks.
8 Figure 9: Transformation from a static-secure doublyprojective garbling scheme (Gb, En, Ev, De, 񮽙 De) to one satisfying Definition 6.񮽙
Gb( f , 񮽙 d): (F, e, d) ← Gb( f ) R ← {0, 1} κ for each output wire i: δ b i ← H(R񮽙out񮽙i񮽙b񮽙d b i ) ⊕ 񮽙 d b i 񮽙 F ← (F ⊕ H(R񮽙gc), {δ b i }) 񮽙 e ← (e 0 1 , e 1 1 , e 0 2 , e 1 2 ,.
.
.
,e 0 m 񮽙R, e 1 m 񮽙R) return ( 񮽙 F, 񮽙 e) 񮽙 Ev( 񮽙 F, 񮽙 X): parse 񮽙 X m as X m 񮽙R and 񮽙 F as (F 񮽙 , δ ) X ← ( 񮽙 X 1 , 񮽙 X 2 ,.
.
.
,X m ) Y ← Ev(F 񮽙 ⊕ H(R񮽙gc), X) y ← 񮽙 De(Y ) for each output wire i: 񮽙 Y i = δ y i i ⊕ H(R񮽙out񮽙i񮽙y i 񮽙Y i ) return 񮽙 YSetup stage: On common input (sid, SETUP, f , N, ε), where f is a boolean circuit, N is the number of executions.
The parties agree on parameters B, 񮽙 N derived from Lemma 1.
Let M ∈ {0, 1} µ×n be a κ s -probe resistant matrix for each party's input of size n. Let a ∈ {0, 1} denote the role of the current party and b = a ⊕ 1.
Note: the protocol is symmetric where both parties simultaneously play the roles of P a and P b .
• Cut-and-Choose Commit: P a chooses at random the cut and choose set σ a ⊂ [ 񮽙 N] of size 񮽙 N − NB.
P a send (COMMIT, (sid, CUT-AND-CHOOSE, a), σ a ) to F com .
For j ∈ [ 񮽙 N]: -OT Init: P a sends (INIT, (sid, OT, a, j) ) t∈[n],h∈{0,1} . 񮽙
(COMMIT, (sid, x b -INPUT, a, j,t, h), e b j,t,h ) t∈[n],h∈{0,1} 񮽙 (COMMIT, (sid, r-INPUT, a, j,t, h), e r j,t,h ) t∈[µ],h∈{0,1} -Output Commit: P a sends (COMMIT, (sid, OUTPUT, a, j), d j ) to F com .
• Cut-and-Choose: P b sends (OPEN, (sid Parameters: A sender P 1 and receiver P 2 .
Setup: On common input S from both parties, for every s ∈ S choose random m 0 , m 1 ← {0, 1} κ c and random c ← {0, 1}.
Internally store a tuple (s, m 0 , m 1 , c).
P 1 output: On input (GET, s) from P 1 , if there is a tuple (s, m 0 , m 1 , c) for some m 0 , m 1 , c then give (OUTPUT, s, m 0 , m 1 ) to P 1 .
P 2 output: On input (GET, s) from P 2 , if there is a tuple (s, m 0 , m 1 , c) for some m 0 , m 1 , c then give (OUTPUT, s, c, m c ) to P 2 .
Parameters: A sender P 1 and receiver P 2 .
Commit: On input (COMMIT, sid, v) from P 1 : If a tuple of the form (sid, ·, ·) is stored, then abort.
If P 1 is corrupt, then obtain value r from the adversary; otherwise choose r ← {0, 1} κ c and give r to P 1 .
Internally store a tuple (sid, r, v) and give (COMMITTED, sid) to P 2 .
Reveal: On input (OPEN, sid, r 񮽙 ) from P 2 : if a tuple (sid, r 񮽙 , v) is stored for some v, then give (OPENED, sid, v) to P 2 .
Otherwise, give (ERROR, sid) to P 2 .
Parameters: Two parties: a sender P 1 and receiver P 2 ; 񮽙 = length of items; n = size of parties' sets.First phase (input commitment): On input (INPUT, A i ) from party P i (i ∈ {1, 2}), with A i ⊆ {0, 1} 񮽙 and |A i | = n: If this is the first such command from P i then internally record A i and send message (INPUT, P i ) to both parties.Second phase (output): On input (OUTPUT) from P i , deliver (OUTPUT, A 1 ∩ A 2 ) to the other party.
Parameters: Two parties: a sender P 1 and receiver P 2 ; 񮽙 = bit-length of items in the set; n = size of parties' sets; F = a PRF.Offline phase: Parties perform random OTs, resulting in P 1 holding strings m i,t {0,1} ← {0, 1} κ c ; and P 2 holding c i and m i,t c i [t] .
Here, c i ∈ {0, 1} 񮽙 and i ∈ [n],t ∈ [񮽙].
• On input (INPUT, {A 2,1 ,.
.
.
,A 2,n }) to P 2 , P 2 randomly permutes its input and then sends d i := A 2,i ⊕ c i for each i ∈ [n].
• On input (INPUT, {A 1,1 ,.
.
.
,A 1,n }) for P 1 , P 1 randomly permutes its input and then computesS i, j = 񮽙 t F(m i,t d i [t]⊕A 1, j [t], j) for i, j ∈ [n].
• P 1 sends (COMMIT, sid, (S 1,1 ,.
.
.
,S n,n )) to F com .
On input (OUTPUT), P 1 sends (OPEN, sid) to F com and P 2 receives (OPENED, sid, (S 1,1 ,.
.
.
,S n,n )).
, j) = S i, j }.
Parameters: Two parties: a sender P 1 and receiver P 2 ; 񮽙 = bit-length of items in the set; n = size of parties' sets; F = a PRF.Offline phase: Parties perform random OTs, resulting in P 1 holding strings m i,t {0,1} ← {0, 1} κ c ; and P 2 holding c i and m i,t c i [t] .
Here, c i ∈ {0, 1} 񮽙 and i ∈ [n],t ∈ [񮽙].
For i ∈ [n], P 1 chooses π i ← {0, 1} 񮽙 .
Then for i, j ∈ [n], party P 1 does the following:• For t ∈ {0, 1} 񮽙 , choose z i, j t ← {0, 1} 񮽙 subject to 񮽙 t z i, j t = 0 • for t ∈ [񮽙], b ∈ {0, 1}; P 1 sends (COMMIT, (sid, i, j,t, b) (INPUT, {A 2,1 ,.
.
.
,A 2,n }) for P 2 , the parties randomly permute their inputs and asynchronously do:• , j) = 񮽙 t ρ i, j t } Figure 14: Weakly-malicious-secure, asynchronous (2-round), two-phase PSI protocol Π async-psi .
