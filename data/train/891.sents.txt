Similarity search is a primitive operation in database and Web search engines.
With the advent of large-scale heterogeneous information networks that consist of multi-typed, interconnected objects , such as the bibliographic networks and social media networks , it is important to study similarity search in such networks.
Intuitively, two objects are similar if they are linked by many paths in the network.
However, most existing similarity measures are defined for homogeneous networks.
Different semantic meanings behind paths are not taken into consideration.
Thus they cannot be directly applied to heterogeneous networks.
In this paper, we study similarity search that is defined among the same type of objects in heterogeneous networks.
Moreover, by considering different linkage paths in a network, one could derive various similarity semantics.
Therefore, we introduce the concept of meta path-based similarity, where a meta path is a path consisting of a sequence of relations defined between different object types (i.e., structural paths at the meta level).
No matter whether a user would like to explicitly specify a path combination given sufficient domain knowledge, or choose the best path by experimental trials, or simply provide training examples to learn it, meta path forms a common base for a network-based similarity search engine.
In particular, under the meta path framework we define a novel similarity measure called PathSim that is able to find peer objects in the network (e.g., find authors in the similar field and with similar reputation), which turns out to be more meaningful in many scenarios compared with random-walk based similarity measures.
In order to support fast online query processing for PathSim queries, we develop an efficient solution that partially materializes short meta paths and then concatenates them online to compute top-k results.
Experiments on real data sets demonstrate the effectiveness and efficiency of our proposed paradigm.
Heterogeneous information networks are the logical networks involving multiple typed objects and multiple typed links denoting different relations, such as bibliographic networks, social media Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Articles from this volume were invited to present their results at The 37th International Conference on Very Large Data Bases, August 29th -September 3rd 2011, Seattle, Washington.
networks, and the knowledge network encoded in Wikipedia.
It is important to provide effective search functions in such networks, where links play an essential role and attributes for objects are difficult to fully obtain.
In particular, we are interested in providing similarity search functions for objects that are from the same type.
For example, in a bibliographic network, a user may be interested in the (top-k) most similar authors for a given author, or the most similar venues for a given venue; in the Flickr network, a user may be interested in searching for the most similar pictures for a given picture, and so on.Similarity search has been extensively studied for traditional categorical and numerical data types in relational data.
There are also a few studies leveraging link information in networks.
Most of these studies are focused on homogeneous networks or bipartite networks, such as personalized PageRank (P-PageRank) [10], SimRank [8] and SCAN [20].
However, these similarity measures are disregarding the subtlety of different types among objects and links.
Adoption of such measures to heterogeneous networks has significant drawbacks: Objects of different types and links carry different semantic meanings, and it does not make sense to mix them to measure the similarity without distinguishing their semantics.
To distinguish the semantics among paths connecting two objects, we introduce a meta path-based similarity framework for objects of the same type in a heterogeneous network.
A meta path is a sequence of relations between object types, which defines a new composite relation between its starting type and ending type.
Consider a bibliographic network extracted from DBLP with four types of objects, namely, authors (A), papers (P), terms (T), and venues (C).
Table 1 shows the top-4 most similar venues for a given venue, DASFAA, based on (a) the common authors shared by two venues, or (b) the common topics (i.e., terms) shared by two venues.
These two scenarios are represented by two distinct meta paths: (a) CP AP C, denoting that the similarity is defined by the meta path "venue-paper-author-paper-venue", whereas (b) CP T P C, by the meta path "venue-paper-topic-paper-venue".
A user can choose either (a) or (b) or their combination based on the preferred similarity semantics.
According to Path (a), DASFAA is closer to DEXA, WAIM, and APWeb, i.e., those that share many common authors, whereas according to Path (b), it is closer to Data Knowl.
Eng., ACM Trans.
DB Syst., and Inf.
Syst., i.e., those that address many common topics.
The meta path framework provides a powerful mechanism for a user to select an appropriate similarity semantics, by choosing a proper meta path, or learn it from a set of training examples of similar objects.Under the proposed meta path-based similarity framework, there are multiple ways to define a similarity measure between two objects, based on concrete paths following a given meta path.
One may adopt some existing similarity measures, such as (1) random walk used in P-PageRank, (2) pairwise random walk used in SimRank, or directly apply (3) P-PageRank and (4) SimRank on the extracted sub-network.
However, these measures are biased to either highly visible objects (i.e., objects associated with a large number of paths) or highly concentrated objects (i.e., objects with a large percentage of paths going to a small set of objects).
We propose a new similarity measure PathSim, which is able to capture the subtle semantics of similarity among peer objects in a network.
In comparison, given a query object, PathSim can identify objects that not only are strongly connected but also share similar visibility in the network given the meta path.
Table 2 presents in three measures the results of finding top-5 similar authors for "Anhai Doan", who is a well-established young researcher in the database field, under the meta path AP CP A (based on their shared venues), in the database and information system (DBIS) area.
P-PageRank returns the most similar authors as those published substantially in the area, i.e., highly ranked authors; SimRank returns a set of authors that are concentrated on a small number of venues shared with Doan; whereas PathSim returns Patel, Deshpande, Yang and Miller, who share very similar publication records and are also rising stars in the database field as Doan.
Obviously, PathSim captures desired semantic similarity as peers in such networks.
Compared with P-PageRank and SimRank, the calculation for PathSim is much more efficient, as it is a local graph measure.
But it still involves expensive matrix multiplication operations for top-k search functions, as we need to calculate the similarity between the query and every object of the same type in the network.
In order to support fast online query processing for large-scale networks, we propose a methodology that partially materializes short length meta paths and then online concatenates them to derive longer meta path-based similarity.
First, a baseline method (PathSim-baseline) is proposed, which computes the similarity between query object x and all the candidate objects y of the same type.
Next, a coclustering based pruning method (PathSim-pruning) is proposed, which prunes candidate objects that are not promising according to their similarity upper bounds.The contributions of this paper are summarized as below.1.
It investigates similarity search in heterogeneous information networks, a new but increasingly important issue due to the proliferation of linked data and their broad applications.
2.
It proposes a new framework of meta path-based similarity and a new definition of similarity measure, PathSim, that captures the subtle similarity semantics among peer objects in networks.
3.
Computing PathSim is more efficient than computing PPageRank and SimRank due to the usage of limited meta paths.
Moreover, we provide an efficient co-clustering-based computation framework for fast query processing in large information networks.
4.
Our experiments demonstrate the effectiveness of meta pathbased similarity framework and the PathSim measure, in comparison with random walk-based measures, and the efficiency of PathSim search algorithms.
In this section, we introduce a meta path-based similarity framework, a novel similarity measure under this framework, PathSim, and propose a PathSim-based top-k similarity search problem in information networks.
A heterogeneous information network is a special type of information network with the underneath data structure as a directed graph, which either contains multiple types of objects or multiple types of links.
DEFINITION 1.
Information Network.
An information network is defined as a directed graph G = (V, E) with an object type mapping function φ : V → A and a link type mapping function ψ : E → R, where each object v ∈ V belongs to one particular object type φ(v) ∈ A, and each link e ∈ E belongs to a particular relation ψ(e) ∈ R.Different from the traditional network definition, we explicitly distinguish object types and relationship types in the network.
Notice that, if a relation exists from type A to type B, denoted as A R B, the inverse relation R −1 holds naturally for B R −1 A. For most of the times, R and its inverse R −1 are not equal, unless the two types are the same and R is symmetric.
When the types of objects |A| > 1 or the types of relations |R| > 1, the network is called heterogeneous information network; otherwise, it is a homogeneous information network.
EXAMPLE 1.
A bibliographic information network is a typical heterogeneous network, containing objects from four types of entities: papers (P), venues (i.e., conferences/journals) (C), authors (A), and terms (T).
For each paper p ∈ P , it has links to a set of authors, a venue, a set of words as terms in the title, a set of citing papers, and a set of cited papers, and the link types are defined by these relations.Given a complex heterogeneous information network, it is necessary to provide its meta level (i.e., schema-level) description for better understanding.
Therefore, we propose the concept of network schema to describe the meta structure of a network.
DEFINITION 2.
Network schema.
The network schema is a meta template for a heterogeneous network G = (V, E) with the object type mapping φ : V → A and the link mapping ψ : E → R, which is a directed graph defined over object types A, with edges as relations from R, denoted as TG = (A, R).
The concept of network schema is similar to that of the ER (Entity-Relationship) model in database systems, but only captures the entity type and their binary relations, without considering the attributes for each entity type.
Network schema serves as a template for a network, and tells how many types of objects there are in the network and where the possible links exist.
Notice that although a relational database can often be transformed into an information network, the latter is much more general and can handle more unstructured and non-normalized data and links, and is also easier to deal with graph operations such as calculating the number of paths between two objects.
EXAMPLE 2.
Bibliographic network schema.
For a bibliographic network defined in Example 1, the network schema is shown in Fig. 1(a).
Links exist between authors and papers denoting the writing or written-by relations, between venues and papers denoting the publishing or published-in relations, between papers and terms denoting using or used-by relations, and between papers, denoting citing or cited-by relations.
In a heterogeneous network, two objects can be connected via different paths.
For example, two authors can be connected via "author-paper-author" path, "author-paper-venue-paperauthor" path, and so on.
Intuitively, the semantics underneath different paths imply different similarities.
Formally, these paths are called meta paths, defined as follows.DEFINITION 3.
Meta path.
A meta path P is a path defined on the graph of network schema TG = (A, R), and is denoted in the form of A1R 1 −→ A2 R 2 −→ . . . R l −→ A l+1 , which defines a composite relation R = R1 • R2 • . . .• R l between type A1 and A l+1 , where • denotes the composition operator on relations.The length of P is the number of relations in P. Further, we say a meta path is symmetric if the relation R defined by it is symmetric.
For simplicity, we also use type names denoting the meta path if there exist no multiple relations between the same pair of types: P = (A1A2 . . . A l+1 ).
For example, in the DBLP network, the co-author relation can be described using the length-2 meta path A writing −→ P written-by −→ A, or short as AP A if there is no ambiguity.
We say a path p = (a1a2 . . . a l+1 ) between a1 and a l+1 in network G follows the meta path P, if ∀i, φ(ai) = Ai and each link ei = 񮽙aiai+1񮽙 belongs to each relation Ri in P.
We call these paths as path instances of P, which are denoted as p ∈ P.
A meta path P ′ is the reverse meta path of P, if P ′ is the reverse path of P in TG, which is denoted as P −1 and defines an inverse relation of the one defined by P. Similarly, we define the reverse path instance of p as the reverse path of p in G, which is denoted as p −1 .
Two meta paths P1 = (A1A2 . . . A l ) and P2 = (A ′ 1 A ′ 2 . . . A ′ k ) are concatenable if and only if A l = A ′ 1 , and the concatenated path is written as P = (P1P2), which equals to (A1A2 . . . A l A ′ 2 . . . A ′ k ).
A simple example of concatenation is: AP and P A can be concatenated to the meta path AP A, which defines the co-author relation.Analogously, a meta path in an information network corresponds to a feature in a traditional data set.
Given a user-specified meta path, say P = (A1A2 . . . A l ), several similarity measures can be defined for a pair of objects x ∈ A1 and y ∈ A l , according to the path instances between them following the meta path.
We list several straightforward measures:• Path count: the number of path instances p between x and y following P: s(x, y) = |{p : p ∈ P}|.
• Random walk: s(x, y) is the probability of the random walk that starts form x and ends with y following meta path P, which is the sum of the probabilities of all the path instances p ∈ P starting with x and ending with y, denoted as P rob(p): s(x, y) = 񮽙 p∈P P rob(p).
• Pairwise random walk: for a meta path P that can be decomposed into two shorter meta paths with the same length P = (P1P2), s(x, y) is then the pairwise random walk probability starting from objects x and y and reaching the same middle object: s(x, y) = 񮽙 (p 1 p 2 )∈(P 1 P 2 ) P rob(p1)P rob(p −1 2 ), where P rob(p1) and P rob(p −1 2 ) are random walk probabilities of the two path instances.In general, we can define a meta path-based similarity framework for the object x and object y as: s(x, y) = 񮽙 p∈P f (p), where f (p) is some measure defined on the path instance p between x and y. Notice that, for measures P-PageRank and SimRank defined on homogeneous networks, they are weighted combinations of random walk measure or pairwise random walk measure over different meta paths in homogeneous networks, in which the meta paths are in the form of the concatenation of one relation with different lengths.
Although there have been several similarity measures as presented above, they are biased to either highly visible objects or highly concentrated object but cannot capture the semantics of peer similarity.
For example, the path count and random walk-based similarity always favor objects with large degrees, and the pairwise random walk-based similarity favors concentrated objects that the majority of the links goes to a small portion of objects.
However, in many scenarios, finding similar objects in networks is to find similar peers, such as finding similar authors based on their field and reputation, finding similar actors based on their movie style and productivity, and finding similar products based on its function and popularity.This motivated us to propose a new, meta path-based similarity measure, called PathSim, that captures the subtlety of peer similarity.
The intuition behind it is that two similar peer objects should not only be strongly connected, but also share comparable visibility.
As the relation of peer should be symmetric, we then confine PathSim merely on the symmetric meta paths.
It is easy to see that, round trip meta paths with the form of P = (P l P −1 l ) are always symmetric.
DEFINITION 4.
PathSim: A Meta path-based similarity measure.
Given a symmetric meta path P, PathSim between two objects of the same type x and y is:s(x, y) = 2 × |{px񮽙y : px񮽙y ∈ P}| |{px񮽙x : px񮽙x ∈ P}| + |{py񮽙y : py񮽙y ∈ P}|where px񮽙y is a path instance between x and y, px񮽙x is that between x and x, and py񮽙y is that between y and y.This shows that given a meta path P, s(x, y) is defined in terms of two parts: (1) their connectivity defined by the number of paths between them following P; and (2) the balance of their visibility, where the visibility is defined as the number of path instances between themselves.
Notice that we do count multiple occurrences of a path instance as the weight of the path instance, which is the product of weights of all the links in the path instance.
To see how this new measure works, we compare PathSim with a set of measures using a toy example to find peer authors, using meta path ACA.
by each author in each venue.
The query is to find the peer authors for "Mike".
As "Bob" has exactly the same publication records as "Mike", it is expected to be the most similar peer.
PathSim generates similarity scores: s(M ike, Jim) = 2×(2×50+1×20) (2×2+1×1)+(50×50+20×20) = 0.0826, s(M ike, Bob) = 1, and so on; and the similarity scores derived by P-PageRank, SimRank, random walk (RW), and pairwise random walk (PRW) on the same meta path ACA, are also illustrated in We now introduce the calculation of PathSim between any two objects of the same type given a certain meta path.
DEFINITION 5.
Commuting matrix.
Given a network G = (V, E) and its network schema TG, a commuting matrix M for a meta path P = (A1A2 . . . A l ) is defined as M = WA 1 A 2 WA 2 A 3 . . . WA l−1 A l , where WA i A j is the adjacency matrix between type Ai and type Aj .
M (i, j) represents the number of paths instances between object xi ∈ A1 and object yj ∈ A l under meta path P.For example, commuting matrix M for the meta path P = (AP A) is a co-author matrix, with each element representing the number of co-authored papers for the pair of authors.
Given a symmetric meta path P, PathSim between two objects xi and xj from the same type can be calculated as s(xi, xj) =2M ij M ii +M jj, where M is the commuting matrix for the meta path P, Mii and Mjj are the visibility for xi and xj in the network given the meta path.It is easy to see that the commuting matrix for the reverse meta path of P l , which is P −1 l , is the transpose of commuting matrix for P l .
In this paper, we only consider the meta path in the round trip form of P = (P l P −1 l ), to guarantee its symmetry and therefore the symmetry of the PathSim measure.
Notice that, if the meta path is length-2, the measure of PathSim is degenerated to a measure that compares the similarity of the neighbor sets of two objects, which is called Dice's coefficient [4].
By viewing PathSim in the meta path-based similarity framework, f (p) = 2w(a 1 ,a 2 )...w(a l−1 ,a l )M ii +M jj , for any path instance p starting from xi and ending with xj following the meta path, where w(ai, aj ) is the weight for the link 񮽙ai, aj 񮽙 defined in the adjacency matrix.Some good properties of PathSim, such as symmetric, selfmaximum and balance of visibility, are shown in Theorem 1.
For the balance property, we can see that the larger difference of the visibility of the two objects, the smaller upper bound for their PathSim similarity.
1.
Symmetric: s(xi, xj) = s(xj, xi).
2.
Self-maximum: s(xi, xj) ∈ [0, 1], and s(xi, xi) = 1.
3.
Balance of Visibility:s(xi, xj) ≤ 2 √ M ii /M jj + √ M jj /M ii .
PROOF.
See Proof in the Appendix.Under the definition of PathSim, we formally define our top-k similarity search problem as follows.
Given an information network G and the network schema TG, given a meta path P = (P l P −1 l ), where P l = (A1A2 . . . A l ), the top-k similarity search for an object xi ∈ A1 is to find sorted k objects in the same type A1, such that s(xi, xj ) ≥ s(xi, x ′ j ), for any x ′ j not in the returning list and xj in the returning list, where s(xi, xj) is defined as in Def.
4.
Although using meta path-based similarity we can define similarity between two objects given any round trip meta paths, the following theorem tells us a very long meta path is not very meaningful.
Indeed, due to the sparsity of real networks, objects that are similar may share no immediate neighbors, and longer meta paths will propagate similarities to remote neighborhoods.
For example, as in the DBLP example, if we consider the meta path AP A, only two authors that are co-authors have a non-zero similarity score; but if we consider longer meta paths like AP CP A or AP T P A, authors will be considered to be similar if they have published papers in a similar set of venues or sharing a similar set of terms no matter whether they have co-authored.
But how far should we keep going?
The following theorem tells us that a very long meta path may be misleading.
We now use P k to denote a meta path repeating k times of the basic meta path pattern of P, e.g., (ACA) 2 = (ACACA).
THEOREM 2.
Limiting behavior of PathSim under infinity length meta path.
Let meta path P (k) = (P l P −1 l ) k , M P be the commuting matrix for meta path P l , and M (k) = (M P M T P ) k be the commuting matrix for P (k) , then by PathSim, the similarity between objects xi and xj as k → ∞ is:lim k→∞ s (k) (i, j) = 2r(i)r(j) r(i)r(i) + r(j)r(j) = 2 r(i) r(j) + r(j) r(i)where r is the primary eigenvector of M , and r(i) is the i th item.
PROOF.
See Proof in the Appendix.As primary eigenvectors can be used as authority ranking of objects [16], the similarity between two objects under an infinite meta path can be viewed as a measure defined on their rankings (r(i) is the ranking score for object xi).
Two objects with more similar ranking scores will have higher similarity (e.g., SIGMOD will be similar to AAAI).
Later experiments ( Table 8) will show that this similarity, with the meaning of global ranking, is not that useful.
Notice that, the convergence of PathSim with respect to path length is usually very fast and the length of 10 for networks of the scale of DBLP can almost achieve the effect of a meta path with an infinite length.
Therefore, in this paper, we only aim at solving the top-k similarity search problem for a relatively short meta path.Even for a relatively short length, it may still be inefficient in both time and space to materialize all the meta paths.
Thus we propose in Section 3 materializing commuting matrices for short length meta paths, and concatenating them online to get longer ones for a given query.
This section is on efficient top-k PathSim similarity search for online queries, under a single meta path, with two algorithms proposed: PathSim-baseline and PathSim-pruning, both returning exact top-k results for the given query.
The algorithm for multiple meta path combination with different weights is discussed in Appendix B. Note that the same methodology can be adopted by other meta path-based similarity measures, such as RW and PRW, by taking a different definition of commuting matrix accordingly.While the definition of meta path-based similarity search is flexible to accommodate different queries, it requires expensive computations (matrix multiplications), which is not affordable for online query processing in large-scale information networks.
One possible solution is to materialize all the meta paths within a given length.
Unfortunately, it is time and space expensive to materialize all the possible meta paths.
For example, in the DBLP network, the similarity matrix corresponding to a length-4 meta path, AP CP A, for identifying similar authors publishing in common venues is a 710K × 710K matrix, whose non-empty elements reaches 5G, and requires storage size more than 40G (up to 4T for longer meta path between authors).
Thus we propose the solution to partially materialize commuting matrices for short length meta paths, and concatenate them online to get longer ones for a given query, which returns search results in a reasonable response time while reduces the storage space significantly.
Given a meta path P = (P l P −1 l ), where P l = (A1 · · · A l ), the commuting matrix for path P l is M P = WA 1 A 2 WA 2 A 3 · · · WA l−1 A l , the commuting matrix for path P is M = M P M T P .
Let n be the number of objects in A1.
For a query object xi ∈ A1, if we compute the top-k most similar objects xj ∈ A1 for xi on-the-fly, without materializing any intermediate results, computing M from scratch would be very expensive.
On the other hand, if we have pre-computed and stored the commuting matrix M = M P M T P , it would be a trivial problem to get the query results: We only need to locate the corresponding row in the matrix for the query xi, re-scale it using (Mii+Mjj)/2, and finally sort the new vector and return the top-k objects.
However, fully materializing the commuting matrices for all possible meta paths is also impractical, since the space complexity (O(n 2 )) would prevent us from storing M for every meta path.
Instead of taking the above extreme, we partially materialize commuting matrix M T P for meta path P −1 l , and compute top-k results online by concatenating P l and P −1 l into P without full matrix multiplication.
We then examine the concatenation problem, i.e., if the commuting matrix M for the full meta path P is not pre-computed and stored, but the commuting matrix M T P corresponding to the partial meta path P −1 l has been pre-computed and stored.
In this case, we assume the main diagonal of M , i.e., D = (M11, . . . , Mnn), is pre-computed and stored.
Since for Mii = M P (i, :)M P (i, :) T , the calculation only involves M P (i, :) itself, and only O(nd) in time and O(n) in space are required, where d is the average number of non-zero elements in each row of M P for each object.
As the commuting matrices of P l and P −1 l are transpose to each other, we only need to store one of them in the sparse form.
But from the efficiency point of view, we will keep both row index and column index for fast locating any rows and columns.
In this study, we only consider concatenating the partial paths P l and P −1 l into the form P = P l P −1 l or P = P −1 l P l .
For example, given a prestored meta path AP C, we are able to answer queries for meta paths AP CP A and CP AP C. For our DBLP network, to store commuting matrix for partial meta path AP C only needs around 25M space, which is less than 0.1% of the space for materializing meta path AP CP A.
Other concatenation forms that may lead to different optimization methods are also possible (e.g., concatenating several short meta paths).
In the following discussion, we focus on the algorithms using the concatenation form P = P l P −1 l .
Suppose we know the commuting matrix M P for path P l , and the diagonal vector D = (Mii) n i=1 , in order to get top-k objects xj ∈ A1 with the highest similarity for the query xi, we need to compute s(i, j) for all xj.
The straightforward baseline is: (1) first apply vector-matrix multiplication to getM (i, :) = M P (i, :)M T P ; (2) calculate s(i, j) = 2M (i,j) M (i,i)+M (j,j)for all xj ∈ A1; and (3) sort s(i, j) to return the top-k list in the final step.
When n is very large, the vector-matrix computation will be too time consuming to check every possible object xj.
Therefore, we first select xj 's that are not orthogonal to xi in the vector form, by following the links from xi to find 2-step neighbors in commuting matrix M P , i.e.,xj ∈ CandidateSet = { 񮽙 y k ∈M P .
neighbors(x i ) M T P .
neighbors(y k )},whereM P .
neighbors(xi)= {y k |M P (xi, y k ) 񮽙 = 0}, which can be easily obtained in the sparse matrix form of M P that indexes both rows and columns.
This will be much more efficient than pairwise comparison between the query and all the objects of that type.
We call this baseline concatenation algorithm as PathSim-baseline (See Algorithm 2).
The PathSim-baseline algorithm, however, is still time consuming if the candidate set is very large.
Although M P can be relatively sparse given a short length meta path, after concatenation, M could be dense, i.e., the CandidateSet could be very large.
Still, considering the query object and one candidate object represented by query vector and candidate vector, the dot product between them is proportional to the size of their non-zero elements.
The time complexity for computing each candidate is O(d) on average and O(m) in the worst case, that is, O(nm) in the worst case for all the candidates, where n is the row size of M P , i.e., the number of objects in type A1, and m the column size of M P , i.e., the number of objects in type A l , and d the average non-zero element for each object in M P .
We now propose a co-clustering based topk concatenation algorithm, by which non-promising target objects are dynamically filtered out to reduce the search space.
In the baseline algorithm, the computational costs involve two factors.
First, the more candidates to check, the more time the algorithm will take; second, for each candidate, the dot product of query vector and candidate vector will at most involve m operations, where m is the vector length.
The intuition to speed up the search is to prune unpromising candidate objects using simpler calculations.
Based on the intuition, we propose a co-clustering (i.e., clustering rows and columns of a matrix simultaneously) based path concatenation method, which first generates co-clusters of two types of objects for partial commuting matrix, then stores necessary statistics for each of the blocks corresponding to different cocluster pairs, and then uses the block statistics to prune the search space.
For better illustration, we call clusters of type A1 as target clusters, since the objects in A1 are the targets for the query; and call clusters of type A l as feature clusters, since the objects in A l serve as features to calculate the similarity between the query and the target objects.
By partitioning A1 into different target clus- ters, if a whole target cluster is not similar to the query, then all the objects in the target cluster are likely not in the final top-k lists and can be pruned.
By partitioning A l into different feature clusters, cheaper calculations on the dimension-reduced query vector and candidate vectors can be used to derive the similarity upper bounds.
This pruning idea is illustrated in Fig. 2 as follows.
Given the partial commuting matrix M T l and its 3 × 3 co-clusters, and the query vector M l (xi, :) for query object xi, first the query vector is compressed into the aggregated query vector with the length of 3, and the upper bounds of the similarity between the query and all the 3 target clusters are calculated based on the aggregated query vector and aggregated cluster vectors; second, for each of the target clusters, if they cannot be pruned, calculate the upper bound of the similarity between the query and each of the 3 candidates within the cluster using aggregated vectors; third, if the candidates cannot be pruned, calculate the exact similarity using the non-aggregated query vector and candidate vectors.The details of the co-clustering algorithm and the co-clustering based pruning algorithm, PathSim-pruning are introduced in Appendix A. Experiments show that PathSim-Pruning can significantly improve the query processing speed comparing with the baseline algorithm, without affecting the search quality.
For the experiments, we use the bibliographic network extracted from DBLP and the Flickr network to show the effectiveness of the PathSim measure and the efficiency (Appendix A.1) of the proposed algorithms.
We use the DBLP dataset downloaded in Nov. 2009 as the main test dataset.
It contains over 710K authors, 1.2M papers, and 5K venues (conferences/journals).
After removing stopwords in paper titles, we get around 70K terms appearing more than once.
Our DBLP networks are built according to the network schema introduced in Example 2, except that there is no direct link between papers since DBLP provides very limited citation information.
This dataset is referred as "full DBLP dataset".
Two small subsets of the data (to alleviate the high computational costs of P-PageRank and SimRank) are used for the comparison with other similarity measures in effectiveness: (1) "DBIS dataset", which contains all the 464 venues and top-5000 authors from the database and information system area; and (2) "4-area dataset", which contains 20 venues and top-5000 authors from 4 areas: database, data mining, machine learning and information retrieval [17], and cluster labels are given for all the 20 venues and a subset of 1713 authors.For additional case studies (See Appendix C), we construct a Flickr network from a subset of the Flickr data, which contains four types of objects: images, users, tags, and groups.
Links exist between images and users, images and tags, and images and groups.
We use 10,000 images from 20 groups as well as their related 664 users and 10284 tags appearing more than once to construct the network.
When a meta path P = (P l P l −1 ) is given, other measures such as random walk (RW) and pairwise random walk (PRW) can be applied on the same meta path, and P-PageRank and SimRank can be applied on the sub-network extracted from P. For example, for the meta path CP AP C (CAC in short) for finding venues sharing the same set of authors, the bipartite graph MCA, derived from commuting matrix corresponding to CP A can be used in both PPageRank and SimRank algorithms.
In our experiments, the damping factor for P-PageRank is set as 0.9 and the one for SimRank is set as 0.8.
First, a case study is shown in Table 4, which is applied on "DBIS dataset", under the meta path CAC.
One can see that for query "PKDD" (short for "Principles and Practice of Knowledge Discovery in Databases", a European data mining conference), PPageRank favors venues with higher visibility, such as KDD and several well-known venues; SimRank prefers concentrated venues (i.e., a large portion of publications goes to a small set of authors) and returns many not well-known venues such as "Local Pattern Detection" and KDID; RW also favors highly visible objects such as KDD, but brings in fewer irrelevant venues due to that it utilizes merely one short meta path; PRW performs similar to SimRank, but brings in more not so well-known venues due to the short meta path it uses; whereas PathSim gives venues with similar area as well as similar reputation as PKDD, such as ICDM and SDM.We then labeled top-15 results for 15 queries from venue type (SIGMOD, VLDB, ICDE, PODS, EDBT, DASFAA, KDD, ICDM, PKDD, SDM, PAKDD, WWW, SIGIR, TREC and APWeb) in "DBIS dataset", to test the quality of the ranking lists given by 5 measures.
We label each result object with relevance score as three levels: 0-non-relevant, 1-some-relevant, and 2-veryrelevant.
Then we use the measure nDCG (Normalized Discounted Cumulative Gain, with the value between 0 and 1, the higher the better) [9] to evaluate the quality of a ranking algorithm by comparing its output ranking results with the labeled ones ( Table 5).
The results show that PathSim gives the best ranking quality in terms of human intuition, which is consistent with the previous case study.Next, we study the performance of different single meta pathbased similarity measures, including PathSim, RW, and PRW, in the task of clustering, where these measures use exactly the same information to determine the pairwise similarity between objects.
Note the clustering problem is rather different from node-oriented similarity search but can still be used to roughly compare the sensitivity of the similarity measures.
We use "4-area dataset" to evaluate the clustering performance, since this dataset naturally has 4 clusters, under the meta path CAC for venues and ACA for authors.
We apply Normalized Cut [15] to the 3 similarity matrices, and use NMI (Normalized Mutual Information, with the value between 0 and 1, the higher the better) [16] to calculate the clustering accuracy for both venues and authors, and their weighted average accuracy over the two types.
The average clustering accuracy results (based on 100 runs) for the venues-author network with different similarity measures are summarized in Table 6.
It turns out that PathSim produces overall better performance in terms of weighted average of clustering accuracy in both types.
As we pointed out, different meta paths give different semantic meanings, which is one of the reasons that similarity definitions in homogeneous networks cannot be applied directly to heterogeneous networks.
Besides the motivating example in the introduction section, Table 7 shows the author similarity under two scenarios for author Christos Faloutsos: co-authoring papers and publishing papers in the same venues, represented by the meta paths AP A and AP CP A respectively.
One can see that the first path returns co-authors who have strongest connections with Faloutsos (e.g., students and close collaborators) in DBLP, whereas AP CP A returns those publishing papers in the most similar venues.
The next interesting question is how the length of meta path impacts the similarity definition.
Table 8 shows an example of venues similar to "SIGMOD" with three meta paths, using exactly the same basic meta path, but with different repeating times.
These meta paths are (CP AP C) 2 , (CP AP C) 4 and its infinity form (global ranking-based similarity).
Notice that in (CP AP C) 2 , two venues are similar if they share many similar authors who publish papers in the same venues; while in (CP AP C) 4 , the similarity definition of those venues will be further relaxed, namely, two venues are similar if they share many similar authors who publish papers in similar venues.
Since venue type only contains 5K venues, we are able to get the full materialization commuting matrix for (CP AP C) 2 .
(CP AP C) 4 is obtained using meta path concatenation from (CP AP C) 2 .
The results are summarized in Table 8, where longer path gradually bring in more remote neighbors, with higher similarity score, and finally it degenerates into global ranking comparison.
Through this study, we can see that the meta path with relatively short length is good enough to measure similarity, and a long meta path may even reduce the quality.
Table 9 shows that short meta paths produce better similarity measures in terms of clustering accuracy.
We checked two other meta paths, namely CP T P C and AP T P A, which give the same conclusion.
Similarity measure has been widely studied in categorical, numerical, or mix-type data sets, such as cosine similarity defined on two vectors, Jaccard coefficient on two sets, and Euclidean distance on two numerical data points.
Based on the traditional similarity measures, a recent study [19] proposes an efficient top-k similarity pair search algorithm, top-k-join, in relational database, which only considers similarity between tuples.
Also widely studied are k nearest neighbor search in spatial data [11] and other high dimensional data [2], which aims at finding top-k nearest neighbors according to similarities defined on numerical features.
However, these similarity definitions cannot be applied to networks.Similarity measures defined on homogeneous networks emerged recently.
Personalized PageRank [10] is an asymmetrical similarity measure that evaluates the probability starting from object x to visit object y by randomly walking on the network with restart.
More discussions on how to scale the calculation for online queries are in [6,18], etc., and how to derive top-k answers efficiently is studied in [7].
SimRank [8] is a symmetric similarity measure defined on homogeneous networks, which can also be directly applied to bipartite networks.
The intuition behind SimRank is propagating pairwise similarity to their neighboring pairs.
Due to its computational complexity, there are many follow-up studies (e.g., [12]) on speeding up such calculations.
SCAN [20] measures similarity of two objects by comparing their immediate neighbor sets.ObjectRank [1] and PopRank [13] first noticed that heterogeneous relationships could affect the random walk, and assigned different propagation factors to each type of object relationship to either derive a revised version of P-PageRank (ObjectRank) or a global PageRank (PopRank).
However, such solutions only give one particular combination of all the possible meta paths using the fixed weights determined by the damping factor and propagation factors between different types.
In our PathSim definition, users can freely specify the meta paths they are interested in and assign any weight to them.
Random walk style similarity search is not adopted in PathSim, which overcomes the disadvantage of returning highly ranked objects rather than similar peers.
In this study, we assume that users know how to choose meta path.
In practice, there are several ways for a user to select the best meta path or meta path combinations.
First, a user can make a choice based on her interest and domain knowledge.
Second, she can have several experimental trials, such as those done in Section 4, and choose the best one according to her intuition.
Third, she can label a small portion of data according to specific applications.
For example, one can label similar objects or rank them, and then train the best meta path(s) and their weights by some learning algorithms.
By doing so, one can automatically choose appropriate meta paths as well as the associated weights, and make the similarity search adaptable to different application scenarios.
The problem on how to choose and weight different meta paths is similar to the feature selection process in machine learning.
In-depth study for a systematic solution is left as a future research task.
We have introduced a novel and practical notion of meta pathbased similarity for heterogeneous information networks.
We comparatively and systematically examine different semantics of similarity measures in such networks and introduce a new meta pathbased similarity measure to find similar objects of the same type in such networks.
Meta paths give users flexibility to choose different meta paths and their combinations based on their applications.
Moreover, we propose a new similarity measure, PathSim, under this framework, which produces overall better similarity qualities than the existing measures.
Since meta paths can be arbitrarily given, it is unrealistic to fully materialize all the possible similarity results given different meta paths and their combinations.
However, online calculation requires matrix multiplication, which is time consuming especially when the vector and matrix are not sparse.
Therefore, we proposed an efficient solution that partially materializes several short meta paths and then applies online concatenation and combination among paths to give the top-k results for a query.
Experiments on real data sets show the effectiveness of the similarity measure and the efficiency of our method.
The framework of meta path-based similarity search in networks can be enhanced in many ways, e.g., weight learning for different meta paths, which may help provide accurate similarity measures in real systems and discover interesting relationships among objects.
1: //Initialization.
2: Randomly assign row objects into {Ru} U u=1 ; 3: Randomly assign column objects into {Cv} V v=1 ;4: repeat 5: //get center vector of each Ru:6: f (Ru) = 1 |Ru| 񮽙 V v=1 M T P (Ru, Cv);7: //Adjust row objects 8: foreach object x i in row objects do 9:f (x i ) = 񮽙 V v=1 M T P (x i , Cv );10:assign x i into Ru, u = arg min k KL(f (x i )||f (Ru));11: end for 12: //get center vector of each Cv:13: f (Cv ) = 1 |Cv | 񮽙 U u=1 M T P (Ru, Cv)14: //Adjust column objects 15: foreach object y j in row objects do 16:f (y j ) = 񮽙 U u=1 M P (Ru, y j ); assign y j into Cv , v = arg min l KL(f (y j )||f (Cv ));18: end for 19: until {Ru}, {Cv } do not change significantly.Once the clusters for each type of objects are obtained, the commuting matrix can be decomposed into disjoint blocks.
To facilitate further concatenation on two meta paths for queries, necessary statistical information is stored for each block.
For each block b denoted by row cluster Ru and column cluster Cv, we store:1.
Element sum of each block T {U ×V } :tuv = 񮽙 i∈Ru 񮽙 j∈Cv M T P (i, j);2.
Sum of row vectors (1-norm of each column vector) of each block T {U ×m} 1:t uv,1 (j) = 񮽙 i∈Ru M T P (i, j), for j ∈ Cv;3.
Square root of sum of square of row vectors (2-norm of each column vector) of each block T T {U ×m} 1:t 2 uv,1 (j) = 񮽙 񮽙 i∈Ru (M T P (i, j)) 2 , for j ∈ Cv;4.
Sum of column vectors (1-norm of each row vector) of each blockT {n×V } 2 : t uv,2 (i) = 񮽙 j∈Cv M T P (i, j), for i ∈ Ru;5.
Square root of sum of square of column vectors (2-norm of each row vector) of each block T T {n×V } 2:t 2 uv,2 (i) = 񮽙 񮽙 j∈Cv (M T P (i, j)) 2 , for i ∈ Ru.
Now let's focus on how we can get top-k results efficiently for a query given the materialized block-wise commuting matrix.
The intuition is that we first check the most promising target cluster, then if possible, prune the whole target cluster; if not, we first use simple calculations to decide whether we need to further calculate the similarity between the query and the candidate object, then compute the exact similarity value using more complex operations only for those needed.
THEOREM 3.
Bounds for block-based similarity measure approximation.
Given a query object x, the query vector is x = M P (x, :).
Let D be the diagonal vector of M , letˆx1letˆ letˆx1 be the compressed query vector given feature clusters {Ru} U u=1 , wherêwherê x1(u) = maxj∈R u {x(j)}, and letˆx2letˆ letˆx2 be the 2-norm query vector given feature clusters Ru, wherê x2(u) = 񮽙 񮽙 j∈Ru x(j) 2 , the similarity between x and target cluster Cv, and the similarity between x and candidate y ∈ Cv can be estimated using the following upper bounds:1.
upperbound 1: ∀y ∈ Cv , s(x, y) ≤ s(x, Cv) = 񮽙 y∈Cv s(x, y) ≤ 2ˆx2ˆx T 1 T (:,v) D(x)+1 ; 2.
upperbound 2: ∀y ∈ Cv, s(x, y) ≤ 2ˆx2ˆx T 2 T T 1 (:,y) D(x)+D(y) .
In Theorem 3, the upper bound for s(x, Cv) can be used to find the most promising target clusters as well as to prune target clusters if it is smaller than the lowest similarity in the current top-k results.
The upper bound for s(x, y) can be used to prune target objects that are not promising, which only needs at most U times calculation, whereas the exact calculation needs at most m times calculation.
Here, U is the number of feature clusters and m is the number of feature objects, i.e., objects of type A l .
The search strategy is to first sort the target clusters according to their upper bound of the similarity between the query x and the cluster Cv, i.e., s(x, Cv), in a decreasing order.
The higher the similarity the more likely this cluster contains more similar objects to x.
It is very critical to use the order to check the most promising target clusters first, by which the most desirable objects are retrieved at an early stage and the upper bounds then have stronger power to prune the remaining candidates.
When a new target cluster needs to be checked, the upper bound can be used to prune the whole target cluster and all the remaining target clusters, if it is smaller than the k-th value of the current top-k list.
Next, when going to check the candidates within the target cluster, the upper bound between query object x and candidate y can be used to prune non-promising candidates if it is smaller than the current threshold.
The algorithm PathSim-pruning is summarized in Algorithm 3.
On Line 5, min(S) is the lowest similarity in the current top-k result set S. Similar to PathSim-baseline (Algorithm 2), before the pruning steps, we still need to first derive the candidate set.
Compared with the baseline algorithm, the pruning-based algorithm at most checks the same number of candidates with the overhead to calculate the upper bounds.
In practice, a great number of candidates can be pruned, and therefore the performance can be enhanced.
Input:Query x i , Commuting Matrix M P , Diagonal Vector D, top-k K Output: Top-k List SortList 1: CandidateSet = ∅; 2: foreach y k ∈ M P .
neighbors(x i ) do 3: foreach x j ∈ M T P.neighbors(y k ) do 4:CandidateSet = CandidateSet ∪ {x j };5: end for 6: end for 7: List = ∅; 8: foreach x j ∈ CandidateSet do 9: value = 2 * M P (i, :)M P (j, :) T /(D(i) + D(j))s(x i , x j ) = 2M P (x i ,:)(M P (x j ,:)) T D(x i )+D( The time complexity for SimRank is O (KN 2 d 2 ), where K is the number of iterations, N is the total number of objects, and d is the average neighbor size; the time complexity for calculating PPageRank for one query is O (KN d), where K, N, d has the same meaning as in SimRank; whereas the time complexity for PathSim using P athSim-baseline for single query is O(nd), where n < N is the number of objects in the target type, d is the average degree of objects in target type for partial commuting matrix M P l .
The time complexity for RW and PRW are the same as PathSim.
We can see that similarity measure only using one meta path is much more efficient than those also using longer meta paths in the network (e.g., SimRank and P-PageRank).
In this sub-section, two algorithms proposed in Section 3, i.e., PathSim-baseline and PathSim-pruning, are compared, for efficiency study under different meta paths, namely, CP AP C, (CP AP C) 2 and AP CP A (denoted as CAC, CACAC and ACA for short).
For the co-clustering algorithm, the number of clusters for authors is set as 50, and that for conferences as 20.
It is easy to see that the more clusters used, the more accurate the upper bounds would be, however the longer the calculation for the upper bounds would be.
A trade-off should be made to decide the best number of clusters.
Due to the limited space, we do not discuss the issue in this paper.First, we check the impacts of the number of neighbors of the query on the execution time.
Note, a query object with higher degree usually leads to larger number of neighbors.
Therefore, two test query sets are selected based on their degrees to test the execution time for each meta path: one is of top-20 objects and the other is of 1001th-1020th objects according to their link degrees.
We compare the performance of the two algorithms under three meta paths.
Each query is executed 5 times and the output time is the total average execution time within each query set, and the results are summarized in Figure 3.
From the results, one can see (1) PathSim-pruning is more efficient than PathSim-baseline; (2) the improvement rate depends on the meta path, the denser the corresponding commuting matrix, the higher rate PathSim-pruning can improve; and (3) the improvement rate also depends on the queries, the more neighbors of a query, the higher rate PathSim-pruning can improve.
In Figure 4, we compare the efficiency under different top-k's (k = 5, 10, 20) for PathSim-pruning using query set 1.
Intuitively, a smaller top-k has stronger pruning power, and thus needs less execution time, as demonstrated.
Now we compare the pruning power of PathSim-pruning vs. PathSim-baseline by considering two factors: the size of the neighbors of a query (Fig. 5) and the density of the partial commuting matrix M P (Fig. 6).
500 queries are randomly chosen for two meta paths (CAC and CACAC), and the execution time is averaged with 10 runs.
The results show that the execution time for PathSim-baseline is almost linear to the size of the candidate set, and the improvement rate for PathSim-pruning is larger for queries with more neighbors, which requires more calculation for exact dot product operation between a query vector and candidate vectors.
Also, the denser that the commuting matrix corresponding to the partial meta path (MCP AP C in comparison with MCP A), the greater the pruning power.
The improvement rates are 18.23% and 68.04% for the two meta paths.
In Section 3, we presented algorithms for similarity search in single meta path.
Now, we present a solution to combine multiple meta paths together.
Formally, given r round trip meta paths from Type A back to Type A, P1, P2, . . . , Pr, and their corresponding commuting matrix M1, M2, . . . , Mr, with weights w1, w2, . . . , wr specified by users, the combined similarity between objects xi, xj ∈ A are defined as:s comb (xi, xj) = 񮽙 r l=1 w l s l (xi, xj), where s l (xi, xj) = 2M l (i,j) M l (i,i)+M l (j,j).
EXAMPLE 4.
Following the motivating example in the introduction section, Table 10 shows the results of combining two meta paths P1 = CP AP C and P2 = CP T P C with different weights specified by w1 and w2, for query "DASFAA".
The reason why we need to combine several meta paths is that, each meta path provides a unique angle (or a unique feature space) to view the similarity between objects, and the ground truth may be a cause of different factors.
Some useful guidance of the weight assignment includes: longer path utilizes more remote relationships and thus should be assigned with a smaller weight, such as in PPageRank and SimRank; and, meta path with more important relationships should be assigned with a higher weight.
For automatically determining the weights, users could provide training examples of similar objects to learn the weights of different meta paths using machine learning algorithms.Since each meta path plays an independent role to decide the similarity, we can calculate top list for each of them and then combine the results together.
The critical problem is how to determine if the remaining candidate objects are not going to appear in the final top-k list, and thus can be safely removed.
The general idea for the search strategy is: (1) get top-k ′ objects for each meta path using single path top-k search algorithm, where k ′ should be larger than k (e.g., in a order of 2k, 4k, 8k, and so on); (2) check for each meta path, whether current top-k ′ objects can guarantee higher similarity than the remaining ones, if not, expanding the top-k ′ list by recalculating the single meta path top-k ′ list with a bigger k ′ (e.g., k ′ = 2k ′ ); (3) repeat (2) until all the candidates generated for each meta path can guarantee they are in the final list; and (4) get the exact similarity score for each candidate and return top-k of the candidates.
One possible upper bound for remaining objects other than those in the current top-k lists can be calculated asupper k = 񮽙 l w l * T opKList[l].
min, where T opKList [l].
min stands for the lowest similarity score of Top-k for the l th meta path.
The FA and TA methods [5] could also be applied here, if the full ranking list is ready for each meta path using PathSim-baseline.
We now study the accuracy of combined meta paths using the "fourarea dataset", evaluated by the clustering performance given the similarity matrix.
First, two meta paths for the type conference, namely, CAC and CT C (short for CP AP C and CP T P C), are selected and their linear combinations with different weights are considered.
Second, two meta paths with the same basic path but different lengths, namely ACA and (ACA) 2 , are selected and their linear combinations with different weights are considered.
The clustering accuracy measured by NMI for conferences and authors is shown in Table 11, which shows that the combination of multiple meta paths can produce better similarity than the single meta path in terms of clustering accuracy.
In this case study, we show that one can merely use links in the network rather than any content information to retrieve similar images for a query image.
Let "I" represent image, "T" tags that associated with each image, and "G" groups that each image belongs to.
Two meta paths are used and compared.
The first is IT I, which means common tags are used by two images at evaluation of their similarity.
The results are shown in Fig. 7.
The second meta path is IT IGIT I, which means tags similarities are further measured by their shared groups, and two images could be similar even they do not share many exact same tags as long as these tags are used by many images of the same groups.
One can see that the second meta path gives better results than the first one as shown in Fig. 8, where the first image is the input query.
This is likely due to that the latter meta path provides additional information related to image groups, and thus improves the similarity measure between images.
Discussion.
The Flickr network is an interesting example that goes beyond the relational data.
Our running example of bibliographic network can be viewed as a network constructed from relational data.
So, naturally, it leads to two questions: (1) one may wonder whether the meta path-based top-k similarity search can be applied to relational databases.
The answer to this question is "Yes", if we treat data from multiple relations as information networks.
For example, to find the students most similar to a given student, one can view multiple relations as interconnected information networks and meta-paths to be selected can be based on the course taken, venues of the publications, advisors, or their weighted combinations.
(2) One may also wonder whether the meta path-based similarity search can go far beyond the network formed based on relational data.
This case study on the Flickr network shows that the analysis of heterogeneous information networks can go far beyond typical relational data since this network consists of links connecting photos with bags of terms and groups.
There are many networks that cannot be constructed from relational data.
For example, a news/blog network contains links among themes, categories, time, locations, authors, terms, pictures, and so on, beyond relational data.
Similarity search in such networks can be readily handled under the framework presented in this study.
Here are the proofs of the theorems introduced in the previous sections.
(2) Let M l (i, :) = (a1, a2, . . . , ap), M l (j, :) = (b1, b2, . . . , bp), easy to see a k , b k are nonnegative for all 1 ≤ k ≤ p, then Mij = 񮽙 p k=1 a k b k ≥ 0, Mii = 񮽙 p k=1 a 2 k > 0 (no dangling object), and Mjj = 񮽙 p k=1 b 2 k > 0, therefore s(xi, xj) ≥ 0; also, 񮽙 p k=1 a 2 k + 񮽙 p k=1 b 2 k ≥ 2 񮽙 p k=1 a k b k , with equality holding when a k = b k for every k, therefore s(xi, xj) ≤ 1, and s(xi, xi) = 1.
(3) M ij = 񮽙 k a k b k ≤ 񮽙 񮽙 k a 2 k 񮽙 k b 2 k = 񮽙 M ii M XIn this Appendix, we present the technical details of the coclustering based pruning algorithm, examine the case of multiple meta path combination, show an additional experiment on the In this Appendix, we present the technical details of the coclustering based pruning algorithm, examine the case of multiple meta path combination, show an additional experiment on the
