Open-audit election protocols have, in recent years, focused on the ballot casting process, where the difficulty lies in proving to the unaided voter that the encrypted ballot faithfully captures her intent.
We present MarkPledge2, an evolution of Neff's MarkPledge scheme and the first efficient, covert-channel-resistant, receipt-free ballot casting scheme that can be used by humans without trusted hardware.
In comparison to the Moran-Naor proposal at CRYPTO 2006 which shares some of our goals, our scheme produces a significantly shorter ballot, prevents covert channels in the ballot, and opts for statistical soundness rather than everlasting privacy (achieving both seems impossible).
The human interface remains the same as MarkPledge, requiring of the voter only very-short-string comparisons.
This work solves an "interesting open problem" raised in the original Moran-Naor paper.
Elections require two seemingly contradictory properties: Alice, the voter, should be able to verify that her vote was properly captured into the final tally but should not be able to convincingly reveal this vote to a coercer even if she is willing to be coerced.
Classic voting schemes-the ones we use in democratic elections around the worldcompromise on verifiability in favor of incoercibility (also called receipt freeness): voters trust election officials to implement a secure chain of custody of anonymized ballots, where even a small mistake could surreptitiously corrupt the election result.Open-audit voting schemes strive to achieve both verifiability and receipt-freeness.
Typically, these schemes are structured much like public elections of yore: cast ballots are available for all to see on a public bulletin board, and the tabulation process is public.
The major difference is that ballots are encrypted through the entire public audit process.
Using various proof techniques, the voting machine demonstrates to Alice that her vote was properly encrypted, and the election trustees demonstrate to any observer that the encrypted ballots are properly tallied.While many contributions have been made to the field of cryptographic voting over the last 25 years, the ballot casting portion has garnered significant interest only recently.
Early research presumed that each voter would own a trusted device to perform cryptographic operations on her behalf.
Unfortunately, this does not accurately model real-world voters for the foreseeable future.
In 2004, Chaum [8] and Neff [5] independently introduced mechanisms that enable an unaided human to cast an encrypted ballot without trusting the voting machine.
More recently, Moran and Naor [19] presented a new definitional framework for receipt-freeness and a new ballot-casting scheme, based on Neff's earlier technique, MarkPledge.
In a concluding remark, Moran and Naor mention that preventing covert channels in the ballot is "an interesting open problem."
We propose a new ballot casting scheme, MarkPledge2, which builds on Neff's MarkPledge scheme [5].
MarkPledge2 generates a much shorter ballot than either MarkPledge or the Moran-Naor scheme.
In addition, it solves an important open problem: the voting machine in MarkPledge2 can no longer leak the voter's choice in her encrypted ballot without producing a corrupt ballot and getting caught with high probability.
We prove receipt-freeness in the model proposed by Moran and Naor, with notably weaker assumptions regarding the voting device.Privacy and Soundness.
The Moran-Naor scheme provides everlasting privacy and computational soundness, while MarkPledge provides computational privacy and statistical soundness.
In other words, an exceptionally powerful adversary could violate voter privacy in MarkPledge or corrupt the election result in the Moran-Naor scheme.
The choice between these two approaches is difficult, and there is no obviously superior approach: policy makers will have to decide which security property to prioritize.In this work, we present our improved ballot size and covert-channel resistance in the statistically sound and computationally private setting of MarkPledge.
We leave as an interesting open problem the application of these techniques to the computationally sound and statistically private setting of Moran-Naor, which will likely require more than simply replacing encryptions with commitments.
In open-audit ballot casting schemes, Alice typically interacts with a voting machine to generate an encryption (or commitment) of her plaintext ballot.
Alice cannot generate this encrypted ballot on her own, as she would clearly have an easily transferable receipt of her actions.
At the same time, Alice should not trust the voting machine to correctly capture her vote.
Thus, typically, the voting machine generates the encrypted ballot and provides a non-transferable proof to Alice that it did so correctly.In MarkPledge, the Moran-Naor scheme, and our new proposal MarkPledge2, Alice chooses one candidate from a fixed list using as representation an integer index into the candidate array.
Once she enters her selection, the voting machine produces a ballot ciphertext (or, in the case of the Moran-Naor scheme, a commitment) and performs a zero-knowledge proof, with Alice providing the challenge, that it did so correctly.
Then, to ensure that the protocol is incoercible, the voting machine simulates proofs that this same ballot encodes every other possible candidate.
The voting machine includes all proof transcripts, one real and the rest simulated, on Alice's receipt.
A third party thus cannot tell which proof was performed correctly and which were simulated.Human Verifier.
The MarkPledge, Moran-Naor, and MarkPledge2 ballot casting schemes ensure that Alice can verify her vote with only minimal computation inside the voting booth: she only checks the proper order of the proof messages for her chosen candidate during the exchange with the voting machine.
Then, outside the booth, Alice relies on a computer-possibly her own, but more likely one belonging to an organization she trusts, e.g. her political party-to ensure that the proof transcripts are otherwise correct.
Importantly, the external computer checks both the real and simulated proofs; in fact it has no way of knowing which is real and which is simulated.To enable this human verification in practice, the voting machine's first proof message and Alice's challenge must be very short strings, so that Alice can compare and manipulate them.
(Icons, or any other memorable representation with relatively small domain, can also be used.)
It isn't enough to adapt existing proof protocols by selecting short first and second proof messages: they must remain short and identically distributed at simulation time.
The crux of a human-verifiable voting scheme is precisely to provide a proof protocol whose first two messages are naturally short and whose soundness is maximized with respect to the challenge length.
In addition, for our covert-channel resistance approach, we need the proof to be simulatable in a particular order-messages 2, 1, then 3-that is not supported by typical 3-round zero-knowledge proofs.
We explain this requirement in Section 4.
The MarkPledge Structure.
The key idea of the MarkPledge2 protocol, like MarkPledge, is to use a special bitencryption scheme BitEnc that enables a human-friendly proof that a ciphertext encrypts the bit b = 1.
This special bit encryption schemes function as follows:1.
The plaintext bit b is represented as a message m.
There are many message representations possible for each of the two possible values of bit b.
The specifics of the message representation approach differ between MarkPledge and MarkPledge2, but in either case, m is composed of at least two plaintexts, each in the domain of an additively homomorphic encryption scheme, e.g. Exponential El Gamal.
The message representation depends in part on a security parameter κ.2.
The individual plaintexts that compose m are encrypted using the additively homomorphic scheme, and the bit encryption BitEnc(b) is then the sequence of the encryptions of the individual plaintexts of m.3.
To prove that b = 1, the encryptor produces a commitment string that is related to the message representation m. For a given m, there is exactly one possible commitment string.4.
The verifier produces a challenge string chal of length κ, the security parameter mentioned earlier that impacts the message representation m.5.
The prover reveals a portion of the randomness used to encrypt the individual components of the message representation m.
The verifier can check this reveal to assure himself that, indeed, b = 1.
However, if the prover knows chal in advance, then it is easy for him to produce a message representation m for b = 0 that will match the verifier's expectation given chal.
In other words, the protocol transcript can be easily simulated.6.
The protocol lends itself to the full utilization of the bits of chal.
In other words, the protocol can be performed by a human who will only need to compare strings of size κ while obtaining confidence of correct bit encryption with probability 2 −κ .
In MarkPledge, m is a sequence of pairs (m 1,1 , m 1,2 ), . . . , (m κ,1 , m κ,2 ), with each m i,j a single bit, and c = BitEnc(b) the corresponding sequence of pairs of Exponential El Gamal encryptions of the m i,j .
If b = 1, then the two bits of each pair are identical: m i,1 = m i,2 , i ∈ [1, κ].
Conversely, if b = 0, the bits within each pair are different:m i,1 = 1 − m i,2 , i ∈ [1, κ].
If the pairs are not consistent within m, the plaintext is considered invalid and denoted ⊥.
Note how there are 2 κ valid message representations for b = 1, and 2 κ valid message representations for b = 0.
One can pledge that c encrypts a 1 by stating, for each pair, the bit that each message encodes.
For example, a pledge of 11001 indicates that m = (1, 1), (1, 1), (0, 0), (0, 0), (1, 1).
A challenge chal is then a string of κ bits, where each bit chal[i] determines whether the prover should reveal the first or second element of pair i. Clearly, if m is an encoding of 1, the pledge string will match the revealed string no matter what the challenge.
If m is an encoding of 0, the pledge string will match the revealed string for only one possible challenge value, with probability 2 −κ .
Figure 1 illustrates this setup.
The Moran-Naor scheme is very similar, though it uses commitments instead of ciphertexts.A Shorter Bit Ciphertext.
In MarkPledge2, we develop a bit-encryption mechanism that achieves the same properties with a much shorter message representation m for a given challenge length κ.
Specifically, we consider SO(2, q), the special orthogonal group of two-by-two matrices with elements in Z q , which is isomorphic to the group of rotations represented as vectors in Z 2 q .
Subgroups of this group cleanly expose equivalence classes of "1-vectors", "0-vectors", and "test-vectors", such that any 1-vector and 0-vector are bisected by a test-vector.
Each vector can be encrypted using two Exponential El Gamal ciphertexts, which lets one homomorphically compute the dot product of an encrypted 1 or 0 vector with a plaintext test vector: any two vectors bisected by the test vector in question will yield the same dot product value.
A pledge is thus simply an index into the 1-vector equivalence class; if one pledges a 1-vector when c actually encrypts a 0-vector, the only way to go undetected is if the challenge is the single test vector that bisects the claimed 1-vector and actually encrypted 0-vector.
Figure 1 compares the message representation schemes of MarkPledge and MarkPledge2.The Ballot.
The MarkPledge2 scheme is effectively MarkPledge augmented with the more efficient bit encryption scheme.
If there are M candidates on the ballot, the voting machine produces a sequence of M bit encryptions c 1 , . . . , c M .
Then, it proves that c a , where a is Alice's choice, is indeed the bit encryption of 1, by pledging its representation m a , accepting chal from Alice, and partially revealing m a accordingly.
It can then simulate that the other bit encryptions c i are also encryptions of 1, using additional challenges provided by Alice.
The difference is merely in the timing: for c a , the voting machine must pledge m a before it sees Alice's challenge, while for the others it sees Alice's challenge first.
The verification of the partial reveals of m 1 , . . . , m M is performed outside the voting booth, by any computer.
(Any improper ballots -those that do not have exactly one c i which is a 1 encryption -will always be detected at tabulation time.)
Preventing Covert Channels in the Ballot.
We provide a technique for preventing the voting machine from abusing valid ballot ciphertexts, which are displayed for all to see on the bulletin board, to subliminally communicate information about the voter's choice.
In particular, our technique addresses one of the main threats described in Karlof et al. 's systems-perspective analysis of cryptographic voting systems [10].
This technique applies to MarkPledge and MarkPledge2, as it does not depend on the specific bit encryption scheme.
Like Benaloh and Tuinstra [3], we assume, in addition to the private channel between the voting device and the voter, a one-time one-way private channel (2) The prover provides a pledge, which is effectively an indicator of the message representation he chose: the selection of each pair's bit for MarkPledge, and the selected 1-vector for MarkPledge2.
(3) The verifier provides a challenge: a κ-bit string for MarkPledge, and an index (up to κ) into the set of test vectors for MarkPledge2.
(4) The prover responds by revealing the randomization factor for a portion of the ciphertexts he produced (the thick-boxed elements in the diagram): for MarkPledge, he reveals one element of each pair according to the corresponding bit from the challenge string, and for MarkPledge two the single dot-product of the encrypted 1-vector and test vector, which can be computed homomorphically.
(5) Given a pledge string and a challenge, there is only one possible message representation of the 0-bit that would successfully allow the prover to cheat this protocol, thus with probability 2 −κ .
from the election trustees to the voting device.
This simply models the installation of election-specific data onto the voting machine before the start of election day.
For a given pre-computed ballot with M candidates, all of the bit encryptions (c 1 , . . . , c M ) are generated before election day via multi-party computation among the election trustees.
The voting machine contains only the ballot identifiers and the corresponding plaintext representations (m 1 , . . . , m M ) such that m offset encodes 1 for a single random offset, and m i encodes 0 for i = offset.
The voter's choice is then an index that rotates the ciphertexts to appropriately match the 1 bit-encryption with the selected candidate, a value which obviously depends both on a, the selected candidate and offset the position of the 1-bit in the pre-computed plaintexts.
The voting machine's output is highly constrained: if it produces a ballot that passes the trustees' verification, all of its outputs are deterministic functions of the ballot identifier, Alice's candidate choice a, and Alice's challenge.
Thus, there is "no room" for the voting machine to encode any information covertly within the ballot.All partial reveals are now performed by the election trustees with results posted to the bulletin board, which leaves the voting machine with only simple plaintext operations.
Simplifying the voting machine equipment is advantageous to the operations and economics of elections, so this change is an important practical benefit as well.
Humans and Basic Cryptography.
In 1994, Naor and Shamir introduced visual cryptography [21], a secret-sharing method that uses visual superposition as a kind of human XOR.
A number of improvements were proposed to improve contrast and usability [12,13].
In 1997, Naor and Pinkas introduced visual authentication [20], a technique to help humans authenticate computers using visual cryptography methods.
Chaum used visual cryptography to build one of the first encrypted voter receipt techniques in 2004 [8,9].
Humans and Interactive Proofs.
The literature is rich with protocols that allow humans to securely authenticate to computer systems.
Hopper and Blum [16] were the first to use the Learning Parity with Noise (LPN) problem as a basis for human authentication, based on Blum et.
al.'s earlier LPN-related work [4].
Interestingly, the low-computationalpower constraint now applies to certain computing environments, like RFIDs, which led Juels and Weis to define an LPN-based authentication system for RFIDs [17].
A plethora of works deal with a human proving to a computer that he is, indeed, human.
A large number of such protocols, often called CAPTCHAs (Completely Automated Public Turing Test to Tell Computers and Humans Apart), use hard Artificial Intelligence problems to exploit tasks that only humans can do efficiently, e.g. reading garbled text.
These were first formalized by von Ahn et.
al. [28,29].
By contrast, ballot casting schemes like MarkPledge2 are human interactive proofs where a human being is the verifier.Receipt-Free Elections.
Benaloh and Tuinstra first introduced and implemented receipt-free voting [3].
Enhancements and variations were quickly proposed [27,23,24], under the assumption of a private channel between the administrator and voter.
Canetti and Gennaro showed how to accomplish incoercible multiparty computation without this assumption [7].
Moran and Naor [19] extended Canetti and Gennaro's model.
The voting literature is plentiful: a large number of receipt-free schemes have been proposed [11,15,2], all of which assume a computationally capable voter.
Some schemes even achieve optimal ballot secrecy [18,19].
Our proposal, like MarkPledge and the NaorMoran scheme, provides receipt-freeness without fully trusted hardware.
All three schemes require a private channel between the voting machine and the voter.
In Section 2, we review notation and number theory.
In Section 3, we define the model, soundness and receipt-freeness.
We present MarkPledge2 in Section 4 and covert-channel resistance in Section 5.
We denote PPT and PT * the class of probabilistic polynomial-time and non-uniform polynomial time Turing machines.
All algorithms and parties are denoted using caligraphic letters, e.g. A. All vectors are denoted using bold font, e.g. u or v.
A protocol run between parties A and B with inputs a and b respectively and output out is denoted out = A(a), B(b).
When we use the term "efficient," we mean "efficient from a practical standpoint," a far stricter constraint than polynomial time.
Background.
Recall that an orthogonal matrix is a square matrix whose transpose is its inverse.
O(n, F ) is then the group of n × n orthogonal matrices with matrix elements in field F , and matrix multiplication the group operation.
O(n, q) with q a prime refers to the group of n × n orthogonal matrices with matrix elements in GF q .
Because a matrix's transpose is its inverse, all have determinant 1 or −1.
SO(n, q), the special orthogonal group, is thus defined as the subgroup of O(n, q) of matrices with determinant 1.
Geometric Interpretation.
In this work, we consider specifically SO(2, q), whose elements are of the form: α β −β α with α 2 + β 2 = 1.
SO(2, q) is a cyclic group with order a multiple of 4, which we thus denote 4Λ.
Elements of SO(2, q) can be represented as 2-vectors by associating each matrix with its first row.
Thus, we consider elements u of the form (α, β).
We interpret elements in SO(2, q) as rotations, and the group's operation as rotation composition.
Considering vector operations in Z 2 q with generator γ, multiplicative notation in SO(2, q), and · the vector dot-product of the 2-vector representations of elements of SO(2, q), for all integer values of i and k:γ i+2k − γ i · γ i+k = 0Given the geometric interpretation, this is to be expected, as γ i+k bisects γ i and γ i+2k .
Lemma 1 Given t ∈ SO(2, q), α 0 ∈ Z q , there are exactly two elements u, v ∈ SO(2, q), such that u · t = v · t = α 0 .
The details, including geometric interpretation, order, and lemma proof, can be found in Appendix D.
Our model is similar to Moran and Naor's.
We assume a typical, precinct-based, supervised voting setting, with one election race with M candidates (and no write-ins).
As in most election schemes, we assume the existence of an authenticated bulletin board where any authorized party can post messages, and any observer can read the posted messages in synchronized order.
We assume only one voting machine.
We note that this is only meant to simplify exposition, whereas the Moran-Naor scheme actually requires this constraint because of its tabulation phase.In this paper, we focus on the ballot casting stage: we assume the existence of a robust universally-verifiable mixnet [25,27,22] that shuffles and decrypts cast ballots available on the bulletin board, then proves it did so correctly.
We also assume the existence of at least one honest verifier (e.g. Jimmy Carter and his election watchers).
We do not use the Universal Composability model [6], because our focus is on efficient techniques.
Instead, we prove security using a standalone definition of soundness.
We do, however, consider receipt freeness in the model of Moran and Naor.Parties.
We identify the following parties:• Voters: there are N voters V 1 , . . . , V N , each with a chosen candidate index a ∈ [1, M ].
• Voting Machine: the voting machine M is a computer inside the voting booth with a touch-screen input and a printer.
The voting machine can post to the bulletin board at the end of election day.
• Trustees: there are K trustees denoted T 1 , . . . , T K .
Each can post to the bulletin board.
• Verifiers: there are many verifiers, as anyone in the public can be a verifier.
A verifier can read the bulletin board and complain if he detects an error.
As these verifiers are effectively helpers where the voter is concerned, we denote any honest helper H.Human Capabilities.
We assume a voter has the ability to type, read, and compare κ-bit strings, where κ is, in practice, at most 20.
These strings may be represented alphanumerically or using some other clever technique, e.g. icons.
We also assume a voter can provide a short random input of this same size κ.Physical Commitment.
As in MarkPledge and the Moran-Naor scheme, we assume that the voting machine can perform a physical commitment where Alice, the voter, receives no information about the value of the commitment.
This can be achieved using a printer with a partial shield, so that Alice can tell that lines of text have been printed, but not what has been printed.
This is crucial to ensure that Alice cannot base her random challenge on the value of the commitment.Soundness.
For soundness, we assume every trustee, every voter other than Alice, and the voting machine may all be adversarial.
Still, if Alice's ballot is encrypted incorrectly, we want either Alice or a Helper to catch the problem with reasonable probability.
More formally, given an honest voter V selecting candidate a and an honest helper H, for any corrupt set of trusteesT * 1 , . . . , T * K ∈ PT * , any corrupt voting machine M * ∈ PT * : Pr (sk , pk ) = T * 1 , . . . , T * K ; (receipt, b V ) = M * (pk ), V(a) ; b H = H(pk , receipt) :Dec sk (receipt) = a ∧ b V = 0 ∧ b H = 0 ≤ 1 2taken over the coin flips of the voter V.
The Helper H is expected to check that the system's public key pk is "good".
In a real protocol, the secret key sk does not exist in a single location: decryption can only occur using a distributed protocol among the trustees.
For human-verifiable schemes, one should strive to reduce the soundness error to far less than 1/2.
In MarkPledge2, as in MarkPledge and the Moran-Naor scheme, we achieve the best possible soundness given a human's ability to compare κ-bit strings: 2 −κ .
Receipt-Freeness.
For receipt-freeness, we assume at least one trustee is honest (which is already required for the robust mixnet's privacy).
We assume the voting machine has no communication channel with the outside world other than the ballots and receipts it produces.
This last assumption implies some enforcement of practical constraints: the voting machine must be simple, shielded, un-networked, and easily resettable at the end of election day.We use the Moran-Naor model, which extends the Canetti-Gennaro incoercibility model.
The real-world protocol is compared to an ideal world, and the protocol is declared receipt-free if any coercion outcome in the real world can be recreated indistinguishably in the ideal world model with the same coercion attempts by the adversary and coercion response by the voters.
We review this model in detail in Appendix A.
We seek a plaintext representation for a bit encryption scheme that allows for partial reveals of the plaintext, down to exactly one possible representation of 0 and one possible representation of 1.
Recall that SO(2, q) is a group of order 4Λ, where group elements are vectors of norm 1 representing rotations, and the group operation is effectively rotation composition.
We partition the group into representations of 1, representations of 0, and test elements, such that any pair of a 1-vector and a 0-vector is bisected by a test vector on either side.
The dot product of either the 1 or 0 vector with the test vector will be the same.
Note how a quarter of the elements are 1-vectors, another quarter are 0-vectors, and the remaining half are test vectors.
Each test vector t can be paired up with its Z 2 q inverse −t, another test vector, so that in the end there are Λ 1-vectors, Λ 0-vectors, and Λ test vectors.Then, a bit encryption of a 0 or a 1 is the pair of Exponential El Gamal encryptions of a corresponding vector's coordinates.
A pledge is a 1-vector, a challenge is a test vector, and a partial reveal is the dot-product of the plaintext 1-vector and the challenge vector, an encryption of which can be computed homomorphically from the encrypted 1-vector and the plaintext challenge vector.
Thus, given a test vector and a dot-product value, as per Lemma 1, there are exactly two possible values for the encrypted vector, one of which is a 1-vector, and the other a 0-vector.
To simulate the reveal for an encrypted 0-vector given a challenge, one uses as a pledge the unique 1-vector whose dot-product with the given test vector is the same as that with the encrypted 0-vector.
Consider El Gamal in the q-order subgroup of Z * p , where q|(p − 1).
We will, in particular, make use of Exponential El Gamal, like the original MarkPledge, where Enc pk (m; r) = (g r , g m y r ), with x the secret key, and y = g x mod p the public key.
We can use Exponential El Gamal efficiently because we will never need to recover a long plaintext m: we will only compare decryptions and check for ciphertexts that decrypt to m = 0.
Defining Classes within SO(2, q).
Given q, the order of the El Gamal subgroup, let Γ be a subgroup of SO(2, q) of order 4λ with γ a generator.
Note that, like the primes p and q, the parameter λ is just another election parameter.
It can be any integral divisor of |SO(2, q)|/4.
1 Ideally, λ is selected such that a human can easily compare strings taken from a set of size λ.
For simplicity, we assume that λ = 2 κ , where κ is the bit length of a human-verifiable string, though a carefully selected alphabet can accommodate any λ.
We define:• Zero = { ζ i : ζ i = γ 4i+1 ; i ∈ [0, λ[}, • One = { ϑ i : ϑ i = γ 4i−1 ; i ∈ [0, λ[}, • Test = { τ i : τ i = γ 2i ; i ∈ [0, λ[}.
As the names imply, we consider any element of Zero a 0-plaintext, and any element of One a 1-plaintext.
Test is the challenge domain: challenges from the verifier will be selected from this class.Relating the Classes.
We denote the difference vector δ k c = ϑ k − ζ c−k , using standard vector subtraction in Z 2 q , and we note that, in the geometric interpretation, τ c = γ 2c effectively bisects ϑ k = γ 4k−1 and ζ c−k = γ 4c−4k+1 = γ 2c+(2c−(4k−1)) .
The geometric interpretation is found in Figure 2.
Thus, for a given element t ∈ Test and a given u ∈ Zero, there is exactly one element v ∈ One such that u · t = v · t (and no other element of Zero with the same dot product).
This follows from Lemma 1 and the careful choice of indices for the classes One, Zero, and Test.
there is exactly one element of Zero, ζ c−k , such that the difference vector δ k c is orthogonal to τc.Vector Encryption.
We can perform component-wise encryption of vectors in Z 2 q .
Using Exponential El-Gamal, we gain the ability to perform homomorphic vector addition of two encrypted vectors, and homomorphic vector dot-product of one encrypted vector with a plaintext vector.
We abuse the single-value notation to represent vector encryption:Enc pk (s; r) = Enc pk (s[0]; r[0]), Enc pk (s[1]; r[1])Note that, with vector components in exponential El Gamal ciphertext, homomorphic vector addition is trivial using component-wise homomorphic multiplication.
In addition, given Q = Enc pk (s; r), we can homomorphically compute an encryption of the dot product s·t where t is a plaintext element of Z 2 q .
Here, multiplicative notation denotes homomorphic multiplication (component-wise exponentiation of ciphertexts), while additive notation denotes homomorphic addition (component-wise multiplication of ciphertexts):Q · t = (Q[0]t[0] + Q[1]t[1]) = Enc pk (s · t; r · t)The result is a single ciphertext, which is to be expected when performing a vector dot-product.
Notice also how the randomization value in the resulting ciphertext is also the result of a dot-product, given that the homomorphic operation actually performs an exponentiation of the El Gamal ciphertexts.Bit Encryption.
Let b be the bit we wish to encrypt.
We define an SO(2, q)-based method of bit encryption.
First, pick a random vector γ 4r +2b+1 using randomness r ∈ Z λ .
This vector will be in Zero if b = 0, and in One if b = 1.
Then, perform encryption of this vector using randomness r ∈ Z 2 q :BitEnc pk (b, (r, r )) = Enc pk (γ 4r +2b+1 ; r)In other words, to perform a bit encryption, we first select a message representation of the bit b as an element of SO(2, q), which is a 2-vector with components in Z 2 q , then we perform the element-wise Exponential El-Gamal encryption of the vector's coordinates.
The result is a vector of two ciphertexts.
The MarkPledge2 protocol presents the exact same interface as MarkPledge [5], except BitEnc is now performed using the bit-encryption mechanism just described, and the proof algebra is adjusted accordingly.
ϑ ka is effectively a randomly selected "1-vector" which will be used when producing the bit encryption of b a , (c) (l i ) i∈ [1,M ],i =a , indexes into Zero, and the associated elements (ζ li ),(d) c a = Q a = Enc pk (ϑ ka ; r a ), for the chosen index a, (e) c i = Q i = Enc pk (ζ li ; r i ), for all i ∈ [1, M ], i = a,then physically commits on the receipt to the values (Q 1 , . . . , Q M ).
These values, which are the bit encryptions of a 1 for the selected option and a 0 for all others, are committed using the printer shield so that Alice knows they have been committed but cannot see their values.3.
For each candidate index i = a, Alice is prompted for a short challenge chal i .
Each such challenge is an index into the class Test, thus corresponding to a specific test vector τ chali .4.
The voting machine computes k i = chal i − l i , for i = a.
These are the indexes of elements of One, one for each candidate where the voting machine actually encrypted an element of Zero.The voting machine then physically commits to (i.e. prints under the shield) the values (k 1 , . . . , k M ).
Note that k a is being committed to before Alice has entered a challenge for the corresponding bit encryption of her selected option a.5.
Alice enters chal a , which corresponds to τ chala .
At this point, the previously physically committed data can be revealed.
(a) l a = chal a − k a , an element of Zero for the chosen index a.
This is the corresponding element of Zero for the one selected option a, now that the prover knows chal a .
(b) (δ k1 chal1 , . . . , δ k M chal M ), the difference vectors between ζ li and ϑ ki .
Note that δ ki chali is orthogonal to τ chali (as per Lemma 1).
(c) ρ i = r i · τ chali , for all i ∈ [1, M ].
This is effectively the revealed random factors of the encrypted dot products.
and prints to the receipt (ρ 1 , . . . , ρ M ) and (chal 1 , . . . , chal M ), which now contains:receipt = Q 1 , . . . , Q M , k 1 , . . . , k M , ρ 1 , . . . , ρ M , chal 1 , . . . , chal M 7.
Alice accepts the receipt if she confirms that her challenges (chal 1 , . . . , chal M ) are properly printed on the receipt next to their designated candidate.8.
Once outside the booth, Alice further verifies her receipt with the help of a program:(a) homomorphically compute Q i = Q i − ζ chali−ki , for all i ∈ [1, M ].
Thus, Qi is either the null vector (if i = a), or the difference vector δ ki chali (if i = a).
In either case, Q i is orthogonal to τ chali .
Because ζ chali−ki is a plaintext vector, this homomorphic subtraction can be performed so that Q i keeps the same randomization as Q i , which is r i .
(b) homomorphically compute Q i · τ chali and check that it is equal to Enc pk (0; ρ i ).
This verifies that Q i and τ chali are orthogonal.
Thus, Q i must be the encryption of ϑ ki or ζ li .
Ballot Canonicalization.
It is important to notice that even though encrypted ballots will be passed through a mixnet, ballots will eventually be decrypted: any uniqueness of the underlying plaintext could be used to identify the voter and violate her ballot secrecy.
Thus, before ballots enter the mixnet, we propose to canonicalize them.
All encrypted 1-vectors should be transformed into the canonical 1-vector γ −1 , and all encrypted 0-vectors into the canonical 0-vector γ.
Given that the bit encryptions are partially revealed to the public, each ciphertext Q i is publicly known to be the encryption of either the 0-vector ζ li or the 1-vector ϑ ki .
It is then trivial to publicly determine the plaintext linear transformation that transforms ζ li into γ and ϑ ki into γ −1 , and to publicly apply this transformation homomorphically to Q i .
The mixnet output will then reveal nothing more than the specific candidate choice, with all randomness, and thus all uniqueness, removed.
Intuitively, MarkPledge2 is sound because the voting machine can only cheat if it guesses the voter's challenge test vector ahead of time.
It has a 2 −κ chance of doing so correctly.
We prove this in detail in Appendix B. Intuitively, MarkPledge2 is receipt-free because Alice cannot take any action that depends on private information she sees in the booth and that affects her vote.
We prove this in detail in Appendix C.
We note, however, that a corrupt voting machine could leak Alice's vote by cleverly selecting the randomization factors that affect the ciphertexts in the ballot and thus on the bulletin board.
Thus, for now, we must assume that the voting machine is honest for receipt-freeness.
Next, we show how to reduce this requirement: we only require that the voting machine have no other communication channel than the ballots.
It may be too much of a burden for Alice to generate and remember a different challenge for each candidate.
Just like MarkPledge [1], MarkPledge2 can be adapted so that Alice need only enter a single challenge that can be used for the real proof and all of the simulated proofs.
In this case, the voting machine commits to its real pledge string on screen before Alice enters her challenge, and Alice verifies only two values: the pledge string for her candidate, and the single challenge string she entered.
This tweak presents two major benefits: Alice can now ignore all data regarding candidates she rejected, and the special shielded printer is no longer necessary.
One complication arises: Alice's challenge cannot depend on the pledge string, as this would clearly make the protocol coercible.
Thus, when this optimization is used, Alice must commit to her challenge ahead of time, e.g. when she signs in to vote.
In the currently described scheme, as well as in MarkPledge and the Moran-Naor scheme, the voting machine can easily select ciphertexts so as to reveal information about a, Alice's chosen candidate, e.g. using the last few bits of the ciphertexts.
We now propose a method to prevent this.
We ensure that, in order to discern information about the voter's choice from the receipt data, an adversary must have cooperation from at least a threshold number of Trustees.
We present this solution in the context of MarkPledge2, though it is immediately applicable to MarkPledge.
It is not immediately applicable to the Moran-Naor scheme.Intuitively, the solution is quite simple: only the first two steps of the three-round proof of bit encryption need to be performed inside the voting booth.
The last step, partial decryption, can be performed once Alice has left the booth, by the election trustees rather than the voting machine.
Thus, we limit the voting machine's power by pre-generating all of the ciphertexts, leaving the voting machine to deal only with the plaintexts.
With all ciphertexts pre-generated, the voting machine no longer has the "wiggle room" to embed any covert information inside the receipt.
Our proposal also greatly reduces the complexity of the voting machine itself, which is of great interest to voting officials who seek simple and inexpensive equipment.
The trustees generate the election public key pk using threshold El Gamal [26], such that each T i has a secret key share sk i .
Consider, then, the trivial encryption of a ballot: (1, (0, 0)), BitEnc pk (0, (0, 0)), . . . , BitEnc pk (0, (0, 0)))(c (0) 1 , . . . , c (0) M ) = (BitEnc pkIn turn, each trustee T i then re-encrypts and shuffles these bit encryptions for each ballot.
Re-encryption includes modifying both the El Gamal randomization factor and the specific plaintext representation.
We abuse notation here to indicate component-wise multiplication:BitReenc pk (c, r, r ) = c × Enc pk (γ 4r; r)Thus, for k ∈ [1, N β]where N is the number of voters and β is a cut-and-choose factor, and for l ∈ [1, M ] where M is the number of candidates, T i generates random values r k,l ∈ Z 2 q , r k,l ∈ Z λ and outputs:c (i) k,l = BitReenc pk (c (i−1) k,π k (l) , (r k,l , r k,l )) These values are then posted to the bulletin board for the next trustee to reencrypt and shuffle.
To parallelize the process, the ballots can be split into batches, then passed from one trustee to the next in circular order.To verify that all trustees performed their re-encryption tasks correctly, we perform a cut-and-choose on the final set of ballots, opening up (β − 1)/β of them, leaving N unrevealed ballots.
If any problematic ballot is encountered, the mistake is traced by asking each trustee to reveal how it shuffled and reencrypted that faulty ballot.
The guilty parties are removed and the process is restarted.
A small-factor β cut-and-choose is sufficient because any incorrect ballot that makes it through the cut-and-choose will be detected at tabulation time.
At the end of this setup phase, all ballot ciphertexts to be used are posted on the bulletin board, indexed by unique ballot identifier.
Each trustee T i communicates its permutation and reencryptions factors, {π k , r k,1 , . . . , r k,M } k∈ [1,N ] , to the voting machine via its private one-time one-way channel.
Thus, given ballot index k, the voting machine knows the plaintexts of the ciphertexts (c(K) k,1 , . . . , c (K)k,M ), including the exact single 1-vector and (M − 1) 0-vectors.
When Alice enters the voting booth, her ballot card (usually a smart card inserted into the machine) indicates a ballot identifier.
The voting machine performs the MarkPledge2 protocol as expected, using the vector plaintexts to compute the simulated pledge strings, and prints on the receipt a circular offset, modulo M , which indicates how to rotate the sequence (c(K) k,1 , . . . , c (K)k,M ) to capture Alice's chosen candidate.
The voting machine does not perform the partial reveal step: it can't.
It also need not print the full ciphertexts, only the pledge strings, voter challenges, and ballot identifier.
Note how the voting machine only needs plaintexts.
This process is diagrammed in Figure 3.
Once Alice casts her ballot, each trustee homomorphically computes the difference vectors (Q 1 , . . . , Q M ), then the dot-products (Q 1 ·τ chal1 , . . . , Q M ·τ chal M ), as per Step 8 of the protocol.
Then, instead of revealing the random factors (ρ 1 , . . . , ρ M ) which would be difficult to perform without revealing how the trustees shuffled the bit encryptions, the trustees perform a joint verifiable decryption [26,14] of this dot-product, proving that the plaintext is 0.
We note that the proof protocol must lend itself to simulation where messages are generated in order 2, 1, then 3, rather than the typical 2, 3, 1 order of special-sound proofs.
This requirement exists because step 3 is only performed by election trustees after Alice has left the voting booth, and it is another important property of the proof protocol presented here (as well as that of MarkPledge and Moran-Naor).
From the voter's point of view, the only difference between this variation and the previous protocol description is in the partial reveal step, which is now performed by threshold verifiable decryption rather than simply revealing the randomization values.
Assuming the soundness of this proof is at least as high as the soundness of our human verification (which is trivial to accomplish), the protocol's overall soundness remains the same.
Receipt-freeness is also unchanged: from the point of view of the voter and potential coercer, nothing has changed.We have, however, achieved an interesting additional improvement with this resistance to covert channels.
Because the voting machines are now highly constrained and can only output valid ballots using pre-generated ciphertexts, we ) At the start of election day, the trustees deliver to the voting machine just the message representation re-randomization and cyclic shift each performed for each ballot.
The voting machine thus knows which ciphertext is the bit-encryption of 1, and the underlying message representation of the plaintexts of the bit encryptions for each ballot.
However, the voting machine does not know the El Gamal randomization factors.
Given the voter's candidate choice, the voting machine can print the offset needed to shift the 1-bit into the right position and can provide the appropriate pledge string for this 1-bit, as well as the simulated pledge strings for the 0-bits, all using only basic operations in Z 2 q , i.e. only plaintext operations in a finite group.
Decryption is distributed amongst the trustees after the ballot pledge and reveal strings are posted on the bulletin board.can show that this system provides receipt-freeness even if the voting machine is malicious: a voting machine that deviates from the protocol and tries to leak information to violate receipt-freeness would be immediately caught, because the only ballot it can produce is a deterministic function of the ballot identifier and the voter's intent.
This stands in contrast to the Moran-Naor receipt-freeness proof, which assumes an honest voting machine.
We leave to future work the detailed discussion of how to set up the voting process to detect and recover from malicious voting machines.
We simply note that receipt-freeness comes more naturally once we have covert-channel resistance.
We've improved on Neff's MarkPledge and the Moran-Naor ballot casting schemes.
Our approach continues to be usable by unaided humans with exactly the same interface as before, but the ballot representation is much shorter, and we show how to ensure that the receipt cannot become a covert channel.
By the same token, we greatly simplify the voting machine itself, which is promising for real-world deployment, where the individual cost of such machines is crucial.It will be interesting to see if our techniques can be adapted to the everlasting privacy setting.
Though this would involve computational rather than statistical soundness, it is important to provide multiple technical options, so that policy makers can choose the compromise that is most sensible for their needs.
We use the Moran-Naor model.
We restate it in full for completeness, but we claim no novelty here.
We consider N parties V 1 , V 2 , . . . , V N with inputs x 1 , x 2 , . . . , x N .
A trusted third party collects all inputs, computes f (x 1 , x 2 , . . . , x N ), and broadcasts the result.
The ideal adversary is denoted I. Each party V i also has a coercionresponse input c i which indicates whether the party will comply with a coercion attempt (c i = 1), or will continue to vote as she chooses and pretend to be coerced (c i = 0).
The adversary I can choose to:• corrupt a subset V * of the parties: I learns the inputs (x i ) i∈V * , takes control of {V i } i∈V * , and replaces the inputs (x i ) i∈V * with (x i ) i∈V * .
• coerce a subset V c of the parties: I sends to each of {V i } i∈V c a new input x i .
If c i = 1, then V i sends its real input x i to I and uses the prescribed x i as its new input.
If c i = 0, then V i ignores x i and sends a randomly generated fake input x c i to I.
One exception exists: if I submits input ⊥, which means forced abstention, V i uses ⊥ regardless of its coercion-resistance bit c i .
I can choose to adaptively corrupt or coerce parties one at a time, based on what it learns regarding previously coerced parties' original input.
Once I signals to the trusted third party that its setup is complete, the trusted third party collects the inputs, including corrupt inputs (x i ) i∈V * and successfully coerced inputs (though the trusted third party doesn't know which are honest, corrupt, or coerced), then computes the corresponding output and broadcasts it.
The view of the ideal adversary includes its own random coins, the corrupted parties' original inputs (x i ) i∈V * , the coerced parties' supposed original inputs (some of which may be fake), and the output of the trusted third party.
Note that I does not see the coercion-response bits c 1 , . . . , c N , though it may indirectly learn some of them from the rest of its view.
We consider N parties V 1 , V 2 , . . . , V N with inputs x 1 , x 2 , . . . , x N and coercion-resistant inputs c 1 , c 2 , . . . , c N .
The real-world adversary is denoted A. All parties are probabilistic polynomial time interactive Turing machines, with pairwise communication tapes, synchronous and atomic message exchanges, and no erasures.Again as in Moran-Naor, each V i has a private communication channel with the adversary A and a special coercionstatus register ("honest","corrupt","coerced") that A can write once.
Each party V i effectively contains three ITMs with joint tapes, one for each of the honest, coerced-but-resisting, coerced-willfully-or-corrupt behaviors.
A specific protocol under consideration defines the honest and coerced-but-resisting behaviors, while the coerced-willfully-orcorrupt behavior is defined generically here:• corrupt: when A corrupts V i , V i becomes a puppet for A using the private channel they share.
Thus, A can send any message it wants in V i 's place, and can request any past view or portion of V i 's tape.
• coerced willfully: when A sets the coercion flag for V i and V i 's coercion-resistance bit is set to comply, V i sends x i to A and executes the puppet strategy, as if it were corrupt.A can corrupt or coerce any party at any time, adaptively.
A's view of the protocol consists of its random coins, the complete views of the corrupted parties, and the communication between A and the coerced parties.
Definition 1 A protocol is receipt-free if, for every real adversary A, there exists an ideal adversary I, such that, for every input vector x 1 , x 2 , . . . , x N and any coercion-response vector c 1 , c 2 , . . . , c N :1.
I's output in the ideal world is indistinguishable from A's output in the real world with the same input and coercion-resistance vectors, with distributions taken over the random coins of I, A, and the parties V i .2.
I corrupts (or coerces) exactly the same parties as A (respectively).
We now provide the proofs of soundness and receipt-freeness that did not fit in the main body of the paper.
Recall our definition of soundness, with malicious trustees T * 1 , T * 2 , . . . , T * K , malicious voting machine M * , and an honest voter V:Pr (sk , pk ) = T * 1 , . . . , T * K ; (receipt, b V ) = M * (pk ), V(a) ; b H = H(pk , receipt) :Dec sk (receipt) = a ∧ b V = 0 ∧ b H = 0 ≤ 1 2In MarkPledge2, as in MarkPledge, we assume that all ballots produced by an honest or malicious voting machine are at least valid: they contain exactly one bit encryption of 1 and M − 1 bit encryptions of 0.
We can safely make this assumption because ballots are eventually decrypted, and any "bad ballot" can simply be traced back to the original voting machine that produced it.
Our proof of soundness focuses on the voting machine producing a ballot that matches the voter's intent.Theorem 1 Assuming a verifiable threshold encryption scheme, a voting machine that only produces valid ballots, a voter with the ability to read, enter, and compare κ-bit strings, MarkPledge2 is a sound ballot casting algorithm with soundness 1 − 2 −κ .
Proof.
We prove this by contradiction.
Assume a bad voting machine M * that manages to produce a ballot for a candidate other than the voter's selected option a, without either the Voter V or the Helper H noticing.
To achieve this, M * might fool V or H (or both, but one is enough).1.
Fooling the Helper: M * can try to fool the Helper H by incorrectly revealing the pledge strings.
Before the distributed generation of the ballot, the reveal is performed via the randomization factors, which cannot be faked with the El Gamal cryptosystem (or any other cryptosystem with unique decryption).
When the distributed ballot generation improvement is used, the proof of decryption using threshold El Gamal has soundness error negligible in the cryptosystem security parameter: soundness is much higher than 1 − 2 −κ , since κ is smaller than any reasonable cryptographic security parameter.
Thus, the Helper H is fooled with negligible probability.2.
Fooling the Voter: Because we assume a well-formed ballot, and that V checks every step of the protocol correctly-in particular that the ciphertexts Q 1 , . . . , Q M and the pledges k 1 , . . . , k M are printed on the receipt before the challenges are issued-M * can only fool the voter by encrypting a 0-vector as Q a , so that its 1-vector is used for a different candidate a , a = a.Assuming this happens, and since pledges are revealed correctly when the Helper is not fooled, there is only one possible challenge that will let M * succeed: the test vector that bisects the pledged 1-vector and encrypted 0-vector.
Assuming the voter selects her challenges randomly and enters the one for her chosen candidate only after the pledge strings are printed, M * has a 2 −κ chance of receiving the right challenge that will let it cheat.Thus, the easiest way for M * to cheat is to cheat the human verifier, and the best chance it has to do so is 2 −κ .
Soundness is thus 1 − 2 −κ .
Theorem 2 Assuming an ideal mixnet functionality and semantic security of the El Gamal cryptosystem, MarkPledge2 is receipt-free.
Proof.
To prove receipt freeness, we first describe the voter's coercion-resistance strategy, which details how a voter can double-cross a coercer indistinguishably.
We then construct an ideal-model adversary that can output something indistinguishable from any real-world advesary, not knowing which parties will choose the coercion-resistance strategy.
The rest of this section provides all relevant details.
The voter V i 's only interactions with the voting machine are:1.
the selection of a candidate, before which the machine has produced no confidential information.
2.
the generation and entry of a challenge, after the voting machine has committed to its pledge strings in a physical way, which means the voter cannot see these ciphertexts.Thus, V i 's coercion-resistance strategy is very simple: she behaves exactly as a puppet would, except that she continues to use her preferred candidate x i in her interactions with the voting machine, responding to the adversary with the responses a puppet would give.
Specifically:• if the adversary instructs V i to use a specific set of challenges, V i complies.
Note that these challenges cannot be based on either the ciphertexts Q 1 , . . . , Q M , or the pledge string k a , which are committed to physically such that the voter must enter her challenges before she sees them.
(We actually do not need to physically commit to the ciphertexts, only to the chosen-candidate pledge string, as a challenge based on the ciphertexts does not result in coercibility.
However, for simplicity's sake, we assume everything before the voter enters her challenges is physically committed.)
• if the adversary instructs V i to vote for a specific candidate x i , V i ignores this command when dealing with the voting machine, but acts as if she had followed it when interacting with the adversary.
Since V i 's only actions are the entry of her candidate choice x i and the entry of the challenges, this is trivial even for a human to fake.
To abstract out the operation of the robust mixnet, we consider a hybrid situation for our real-world setup, where the voting machine broadcasts all encrypted ballots to all parties including the adversary, then submits all encrypted ballots to a decryption mixnet functionality, which shuffles, decrypts, and broadcasts the plaintext results to all parties, including the adversary.
(The broadcast of encrypted ballots is meant to mimick the effects of a bulletin board.)
The broadcast of all encrypted ballots and the shuffling does not begin until the adversary A allows it to.
Though we do not care to consider the mixnet's inner workings, it remains important to consider the output of this mixnet as part of the adversary's view, in case such an output provides the adversary with some insight that makes the protocol coercible.
We also assume a public-key setting where both I and A have access to pk , but not sk .
We construct an ideal adversary I. I uses the real-world adversarial strategy A as a black box, emulating to it the rest of the protocol.
(I also emulates the abstract mixnet functionality.)
The key intuition is that, when I emulates the rest of the protocol, it knows which parties A tries to coerce, but it doesn't know which will choose the coercionresistance response.
Thus, we show how I can forward coercion-and-corruption messages appropriately to the idealmodel parties and fill in the real-world portions of the protocol.
Eventually, I emulates the mixnet functionality so as to correct for any mistake it made in assuming that all coerced voters would become puppets.
This "false mixing" is an acceptable emulation because we assume an ideal mixnet functionality.Emulating the Corrupt and Coerced Parties.
When A sends the command to coerce or corrupt a party V i , I instantiates a puppet strategy V c i to talk to A, for which it will emulate the voting machine M. I creates this puppet strategy as a complete ITM with a random secret input x i and a consistent history.
Notably, I does not immediately send a coercion/corruption message to the corresponding ideal party.
Instead, it waits until A sends the actual candidate touch-screen selection to the puppet according to our specific MarkPledge2 protocol.
At this point, I sends the appropriate "corrupt" or "coerce" message to the corresponding ideal-world party along with the new input x i prescribed by A in its order to the puppet.
Note how, in the case of a corrupt party, I's choice to adopt the puppet strategy is exactly what the ideal party will do, but that it may not be so in the case of a coerced party.Emulating the Untouched Parties.
The adversary, real or ideal, sees nothing regarding the untouched partiesthose that it neither corrupts nor coerces-until their encrypted votes are broadcast just before shuffling.
For these parties, I picks random inputs x i , prepares a correctly distributed ballot ciphertext and receipt for such an input, and stores them for future use.
No messages are exchanged with A regarding these untouched parties.Emulating the Voting Machine.
I emulates the voting machine M for the benefit of the corrupt and coerced puppet parties.
It does so exactly as a normal voting machine would, using the election public key pk .
When A orders the voting machine to broadcast all ciphertext votes, I does so using the ciphertexts it generated interactively with the puppets of the corrupt and coerced parties (who are themselves talking to the real-world adversary A), and the ciphertexts it generated on its own for the untouched parties.Emulating the Mixnet.
When I receives the order to shuffle from A, it sends the signal to the trusted third party to perform its voting tabulation function, and obtains the outputs: plaintext ballots.
It then emulates for A the mixnet functionality, using these exact outputs as the claimed result of the shuffling.
In the end, I outputs whatever A outputs.Receipt-Freeness.
Note how I and A corrupt and coerce exactly the same parties in the real and ideal worlds.
By a standard hybrid argument, we can see that, if the outputs of I and A are distinguishable, then there exists two variants of I with distinguishable outputs that only differ by one party's response to a coercion attempt.
(We can safely ignore the differences regarding the untouched parties, since those depend entirely on the semantic security of the cryptosystem.)
The party's actions in the MarkPledge2 protocol include only candidate selection and challenge input.
The challenges are exactly the same, thanks to the coercion-resistance strategy, because the party has no private information to report to the adversary before entering her challenge.
Thus the only difference is the candidate selection, and thus the only difference in the output is the non-revealed portion of the ciphertexts.
If these are distinguishable, then the semantic security of the underlying El Gamal cryptosystem has been broken.
Lemma 2 If q is prime, and q ≡ 3(mod 4), then SO(2, q) is cyclic of order q + 1.
Proof.
X 2 + 1 is an irreducible element of Z q [X], hence R is a field and R * is cyclic.
Since det is multiplicative 2 , SO(2, q) is a multiplicative subgroup of R * , hence is cyclic.To deduce its order, note that the map α(z) = z q−1 defines a multiplicative homomorphism, α : R * → R * .
Since det is multiplicative, and since a q−1 = 1 for all a ∈ Z * q , α(R * ) ⊂ SO(2, q).
On the other hand, there are only two elements of Z q whose determinant (norm) is 1 : {1, −1}.
Since q − 1 = 4k + 2, −1 ∈ α(R * ), which implies SO(2, q) ⊂ α(R * ).
Thus we conclude: One can interpret each of these elements in SO(2, q) as rotations.
Consider u, v, w ∈ SO(2, q) such that w = u ⊗ v.
Then consider the vector dot product: u · w. First, we recall w:w = (u 0 v 0 − u 1 v 1 , u 0 v 1 + u 1 v 0 )then, we perform the dot product:u · w = u 2 0 v 0 − u 0 u 1 v 1 + u 0 u 1 v 1 + u 2 1 v 0 = (u 2 0 + u 2 1 )v 0 = v 0In other words, the dot product between two vector elements is the first coordinate of the ratio between the two vectors, where by ratio we mean to use the inverse group operation.
This property matches the geometric interpretation of rotation transformations, where the dot product yields the effective cosine of the angle between the two vectors (as they are both of norm 1.)
Note also that the inverse of c retains the same first coordinate v 0 , since, in SO(2, q), the inverse of a matrix is its transpose.
This is also consistent with the rotation interpretation: whichever direction one rotates, the resulting dot product between the start and end vectors should be the same given a fixed angle of rotation.The geometric interpretation can be particularly useful when combined with the dot-product operation.
In particular, consider γ a generator element of SO(2, q).
Vector addition and dot-product are performed in Z 2 q , while exponentiation denotes operations in SO(2, q).
We know from above that:γ i · γ j = γ j−i [0]Then, if we have γ i · γ j = γ i · γ k we conclude that:j − i = ±(k − i) mod 4ΛThis leads us to the property mentioned in the main body of the paper.
Consider vector addition and dot-product in Z 2 q , ⊗ the SO(2, q) operation, and exponentiation the composed SO(2, q) operation:(γ i+2k − γ i ) · γ i+k = (γ i+2k · γ i+k ) − (g i · g i+k ) = γ −k [0] − γ k [0] = 0This then leads to Lemma 1 from the main body of the paper, which we restate here.Lemma 1 Given t ∈ SO(2, q), and α 0 ∈ Z q , there are exactly two elements u, v ∈ SO(2, q), such that:u · t = v · t = α 0Proof.
Recall that the vector-representation of elements in SO(2, q) is (α, β) ∈ Z 2 q , where α 2 + β 2 = 1 mod 4Λ.
Denote δ ∈ SO(2, q) such that δ = α 0 .
There is, of course, exactly one such element.Then, by prior reasoning regarding vector dot product:u · t = α 0 =⇒ u = δ ±1 ⊗ tDenote γ a generator of SO(2, q), c ∈ Z * 4Λ such that t = γ c , and d ∈ Z * 4Λ such that δ = γ d .
The vectors u and v are thus γ (c+d) and γ (c−d) , and no other elements in SO(2, q) can have the same dot product α 0 with t.
