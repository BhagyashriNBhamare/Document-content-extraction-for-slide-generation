By combining algorithmic learning, decision procedures, and predicate abstraction, we present an automated technique for finding loop invariants in propositional formulae.
Given invariant approximations derived from pre-and post-conditions, our new technique exploits the flexibility in invariants by a simple randomized mechanism.
The proposed technique is able to generate invariants for some Linux device drivers and SPEC2000 benchmarks in our experiments.
Algorithmic learning has been applied to assumption generation in compositional reasoning [9].
In contrast to traditional techniques, the learning approach does not derive assumptions in an off-line manner.
It instead finds assumptions by interacting with a model checker progressively.
Since assumptions in compositional reasoning are generally not unique, algorithmic learning can exploit the flexibility in assumptions to attain preferable solutions.
Applications in formal verification and interface synthesis have also been reported [9,1,2,18,7].
Finding loop invariants follows a similar pattern.
Invariants are often not unique.
Indeed, programmers derive invariants incrementally.
They usually have their guesses of invariants in mind, and gradually refine their guesses by observing program behavior more.
Since in practice there are many invariants for given pre-and post-conditions, programmers have more freedom in deriving invariants.
Yet traditional invariant generation techniques do not exploit the flexibility.
They have a similar impediment to traditional assumption generation.This article reports our first findings in applying algorithmic learning to invariant generation.
We show that the three technologies (algorithmic learning, decision procedures, and predicate abstraction) can be arranged in concert to derive loop invariants in propositional (or, quantifier-free) formulae.
The new technique is able to generate invariants for some Linux device drivers and SPEC2000 benchmarks without any help from static or dynamic analyses.For a while loop, an exact learning algorithm for Boolean formulae searches for invariants by asking queries.
Queries can be resolved (not always, see below) by decision procedures automatically.
Recall that the learning algorithm generates only Boolean formulae but decision procedures work in propositional formulae.
We thus perform predicate abstraction and concretization to integrate the two components.In reality, information about loop invariant is incomplete.
Queries may not be resolvable due to insufficient information.
One striking feature of our learning approach is to exploit the flexibility in invariants.
When query resolution requires information unavailable to decision procedures, we simply give a random answer.
We surely could use static analysis to compute soundly approximated information other than random answers.
Yet there are so many invariants for the given pre-and post-conditions.
A little bit of random information does not prevent algorithmic learning from inferring invariants.
Indeed, the learning algorithm is able to derive invariants in our experiments by coin tossing.
The while loop assigns a random truth value to the variable b in the beginning of its body.
It increases the variable i by 1 if b is true.
Observe that the variable b must be true after the while loop.
We would like to find an invariant which proves the postcondition i = 10 ∧ b. Heuristically, we choose i = 0 and (i = 10 ∧ b) ∨ i < 10 as under-and over-approximations to invariants respectively.
With the help of a decision procedure, these invariant approximations are used to resolve queries made by the learning algorithm.
After resolving a number of queries, the learning algorithm asks whether i = 0 ∧ i < 10 ∧ ¬b should be included in the invariant.
Note that the query is not stronger than the under-approximation, nor weaker than the over-approximation.
Hence decision procedures cannot resolve it due to lack of information.
At this point, one could apply static analysis and see that it is possible to have this state at the beginning of the loop.
Instead of employing static analysis, we simply give a random answer to the learning algorithm.
For this example, this information is crucial: the learning algorithm will ask us to give a counterexample to its best guess i = 0 ∨ (i = 10 ∧ b) after it processes the incorrect answer.
Since the guess is not an invariant and flipping coins does not generate a counterexample, we restart the learning process.
If the query i = 0 ∧ i < 10 ∧ ¬b is answered correctly, the learning algorithm infers the invariant (i = 10 ∧ b) ∨ i < 10 with two more resolvable queries.
-We prove that algorithmic learning, decision procedures, and predicate abstraction in combination can automatically infer invariants in propositional formulae for programs in our simple language.
-We demonstrate that the technique works in realistic settings: we are able to generate invariants for some Linux device drivers and SPEC2000 benchmarks in our experiments.
-The technique can be seen as a framework for invariant generation.
Static analyzers can contribute by providing information to algorithmic learning.
Ours is hence orthogonal to existing techniques.We organize this paper as follows.
After preliminaries (Section 2), we present an overview of the framework in Section 3.
In Section 4, we review the exact learning algorithm introduced in [6].
Section 5 gives the details of our learning approach.
We report experiments in Section 6.
Section 7 briefly discusses our learning approach, future work, and related work.
Section 8 concludes our work.
The syntax of statements in our simple imperative language is as follows.Stmt = nop | assume Prop | Stmt; Stmt | x := Exp | x := nondet | b := Bool | b := nondet | if Prop then Stmt else Stmt | switch Exp do case Exp : Stmt · · · | { Prop } while Prop do Stmt { Prop }Natural number variables and Boolean variables are allowed.
They assign to arbitrary values in their respective domains by the keyword nondet.
Note that while statements are annotated.
Programmers are asked to specify a precondition before a while statement, and a postcondition after the statement.
An expression Exp is a natural number (n ∈ N), a variable (x), or a summation or the difference of two expressions.
Due to the limitation of decision procedures, only linear arithmetic is allowed.
It ensures complete answers from decision procedures.Exp = n | x | Exp + Exp | Exp − ExpA propositional formula Prop is either: the falsehood symbol (F), a Boolean variable (b), the negation of a propositional formula, the conjunction of two propositional formulae, or comparisons (E 0 < E 1 or E 0 = E 1 ).
Prop = F | b | ¬Prop | Prop ∧ Prop | Exp < Exp | Exp = ExpLet ρ 0 and ρ 1 be propositional formulae, π 0 and π 1 be expressions.
We writeT for ¬F, ρ 0 ∨ ρ 1 for ¬(¬ρ 0 ∧ ¬ρ 1 ), ρ 0 ⇒ ρ 1 for ¬ρ 0 ∨ ρ 1 , ρ 0 ⇔ ρ 1 for (ρ 0 ⇒ ρ 1 ) ∧ (ρ 1 ⇒ ρ 0 ), ρ 0 ⊕ ρ 1 for ¬(ρ 0 ⇔ ρ 1 ), π 0 ≤ π 1 for π 0 < π 1 ∨ π 0 = π 1, and π 0 = π 1 for ¬(π 0 = π 1 ).
Propositional formulae of the forms b, π 0 < π 1 , and π 0 = π 1 are called atomic propositions.
If A is a set of atomic propositions, Prop A denotes the set of propositional formulae generated from A.A Boolean formula Bool is a restricted propositional formula constructed from truth values and Boolean variables.Bool = F | b | ¬Bool | Bool ∧ BoolA valuation ν is an assignment of natural numbers to variables and truth values to Boolean variables.
A Boolean valuation µ is an assignment of truth values to Boolean variables.
If A is a set of atomic propositions and Var (A) is the set of variables occurred in A, Val Var (A) denotes the set of valuations for Var (A).
Let ρ be a propositional formula.
The valuation ν is a model of ρ (written ν |= ρ) if ρ evaluates to T under the valuation ν.
Similarly, the Boolean valuation µ is a Boolean model of the Boolean formula β (written µ |= β) if β evaluates to T under µ.
If B is a set of Boolean variables, the set of Boolean valuations for B is denoted by Val B .
Given a propositional formula ρ, a satisfiability modulo theories (SMT) solver returns a model of ρ if it exists (written SMT (ρ) → ν); otherwise, it returns UNSAT (written SMT (ρ) → UNSAT ) [11,22].
A precondition Pre(φ, S) for φ ∈ Prop with respect to a statement S is a universally quantified formula that guarantees φ after the execution of the statement S.Pre(φ, nop) = φ Pre(φ, assume θ) = θ ⇒ φ Pre(φ, S 0 ; S 1 ) = Pre(Pre(φ, S 1 ), S 0 ) Pre(φ, x := π) = ∀x.φ if π = nondet φ[x → π] otherwise Pre(φ, b := ρ) = ∀b.φ if ρ = nondet φ[b → ρ] otherwise Pre(φ, if ρ then S 0 else S 1 ) = (ρ ⇒ Pre(φ, S 0 )) ∧ (¬ρ ⇒ Pre(φ, S 1 )) Pre(φ, switch π case π i : S i ) = i (π = π i ⇒ Pre(φ, S i )) Pre(φ, {δ} while ρ do S {}) = δ if implies φ F otherwiseObserve that all universal quantifiers occur positively in Pre(φ, S) for any S.
They can be eliminated by Skolem constants [12,23].
We combine algorithmic learning, decision procedures [11], and predicate abstraction [13] in our framework.
Figure 1 illustrates the relation among these technologies.
In the figure, the left side represents the concrete domain; the right side represents the abstract domain.
Assume there is an invariant for a while statement with respect to the given pre-and post-conditions in the concrete domain.
We would like to apply algorithmic learning to find such an invariant.
To this purpose, we use the CDNF algorithm [6].
The CDNF algorithm is an exact learning algorithm for Boolean formulae.
It is an active learning algorithm that makes queries about an unknown Boolean formula and outputs a Boolean formula that is equivalent to the unknown one [3,6].
We perform predicate abstraction to represent propositional formulae as Boolean formulae in the abstract domain.
Since the CDNF algorithm is able to learn arbitrary Boolean formulae, our technique can infer arbitrary invariants in propositional formulae by answering queries.To realize this idea, we devise a mechanism (a teacher) to resolve queries in the abstract domain.
There are two types of queries: membership queries ask whether a Boolean valuation is a model of an invariant; equivalence queries ask whether a Boolean formula is an invariant and demand a counterexample if it is not.
It is not difficult to concretize queries in the abstract domain.
Answering queries however requires information about invariants yet to be computed.Although an invariant is unknown, its approximations can be derived from the pre-and post-conditions, or computed by static analysis.
Hence, we estimate invariant approximations heuristically and adopt decision procedures for query resolution.
For a membership query, we check if its concretization is in the under-approximation or outside the over-approximation by an SMT solver.
If it is in the under-approximation, the answer is affirmative; if it is out of the over-approximation, the answer is negative.
Otherwise, we simply give a random answer.
Equivalence queries are resolved similarly, but we restart the learning process when equivalence queries are not resolvable.
If the concretization is not weaker than the under-approximation or not stronger than the overapproximation, a counterexample can be generated by an SMT solver.
Otherwise, the learning process is restarted instead of giving random answers.
In [6], an exact learning algorithm for Boolean formulae over a finite set B of Boolean variables is introduced.
The CDNF algorithm generates a conjunction of formulae in disjunctive normal form equivalent to the unknown Boolean formula λ.
It assumes a teacher to answer the following queries:1.
Membership queries.
Let µ be a Boolean valuation for B.
The membership query MEM (µ) asks if µ is a model of the unknown Boolean formula λ.
If µ |= λ, the teacher answers YES (denoted by MEM (µ) → YES ).
Otherwise, the teacher answers NO (denoted by MEM (µ) → NO).
2.
Equivalence queries.
Let β ∈ Bool B .
The equivalence query EQ(β) asks if β is equivalent to the unknown Boolean formula λ.
If so, the teacher answers YES (denoted by EQ(β) → YES ).
Otherwise, the teacher returns a Boolean valuation µ for B such that µ |= β ⊕ λ as a counterexample (denoted by EQ(β) → µ).
(* B = {b1, b2, . . . , bm}: a finite set of Boolean variables *) Input: A teacher answers membership and equivalence queries for an unknown Boolean formula λ Output: A Boolean formula equivalent to λ t := 0; if EQ(T) → YES then return T; let µ be such that EQ(T) → µ; 0 t := t + 1; (Ht, St, at) := (F, ∅, µ);1 if EQ( t V i=1 Hi) → YES then return t V i=1Hi;let µ be such that EQ( Algorithm 1: The CDNF Algorithm [6] Let µ and a be Boolean valuations for B.The Boolean valuation µ ⊕ a is defined by (µ ⊕ a)(b i ) = µ(b i ) ⊕ a(b i ) for b i ∈ B. For any Boolean formula β, β[B → B ⊕ a]is the Boolean formula obtained from β by replacing b i ∈ B with ¬b i if a(b i ) = T. For a set S of Boolean valuations for B, defineM DNF (µ) = µ(bi)=T b i and M DNF (S) = µ∈S M DNF (µ).
For the degenerate cases, M DNF (µ) = T when µ ≡ F and M DNF (∅) = F. Algorithm 1 shows the CDNF algorithm [6].
In the algorithm, the step "walk from µ towards a while keeping µ |= λ" takes two Boolean valuations µ and a.
It flips the assignments in µ different from those of a and maintains µ |= λ.
Algorithm 2 implements the walking step by membership queries.
(* B = {b1, b2, . . . , bm}: a finite set of Boolean variables *) Input: valuations µ and a for B Output: a model µ of λ by walking towards a i := 1;while i ≤ m do if µ(bi) = a(bi) then µ(bi) := ¬µ(bi); if MEM (µ) → YES then i := 0 else µ(bi) := ¬µ(bi); end i := i + 1; end return µ Intuitively, the CDNF algorithm computes the conjunction of approximations to the unknown Boolean formula.
In Algorithm 1, H i records the approximation generated from the set S i of Boolean valuations with respect to the Boolean valuation a i .
The algorithm checks if the conjunction of approximations H i 's is the unknown Boolean formula (line 1).
If it is, we are done.
Otherwise, the algorithm tries to refine H i by expanding S i .
If none of H i 's can be refined (line 2), another approximation is added (line 0).
The algorithm reiterates after refining the approximations H i 's (line 3).
Let λ be a Boolean formula, |λ| DNF and |λ| CNF denote the minimum sizes of λ in disjunctive and conjunctive normal forms respectively.
The CDNF algorithm learns any Boolean formula λ with a polynomial number of queries in |λ| DNF , |λ| CNF , and the number of Boolean variables [6].
Appendix A gives a sample run of the CDNF algorithm.
Consider the while statement {δ} while ρ do S {}.
The propositional formula ρ is called the guard of the while statement; the statement S is called the body of the while statement.
The annotation is intended to denote that if the precondition δ holds, then the postcondition must hold after the execution of the while statement.
The invariant generation problem is to compute an invariant to justify the pre-and post-conditions.
Definition 1.
Let {δ} while ρ do S {} be a while statement.
An invariant ι is a propositional formula such that(a) δ ⇒ ι (b) ρ ∧ ι ⇒ Pre(ι, S) (c) ¬ρ ∧ ι ⇒ .
An invariant allows us to prove that the while statement fulfills the annotated requirements.
Observe that Definition 1 (c) is equivalent to ι ⇒ ∨ ρ.
Along with Definition 1 (a), we see that any invariant must be weaker than δ but stronger than ∨ ρ.
Hence δ and ∨ ρ are called the strongest and weakest approximations to invariants for {δ} while ρ do S {} respectively.Our goal is to apply the CDNF algorithm (Algorithm 1) to "learn" an invariant for an annotated while statement.
To achieve this goal, we first lift the invariant generation problem to the abstract domain by predicate abstraction.
Moreover, we need to devise a mechanism to answer queries from the learning algorithm in the abstract domain.
In the following, we show how to answer queries by an SMT solver and invariant approximations.
Domains for an SMT solver and algorithmic learning are adjoined via the predicate abstraction [13].
The α, α * , γ, and γ * are the abstraction (α, α * ) and concretization (γ, γ * ) maps between the two domains.
SMT solvers work in propositional formulae.
Algorithmic learning works in Boolean formulae.Prop A Bool B(A) γ * γ α * α Val B(A) Val Var (A)Let A be a fixed set of atomic propositions.
For each atomic proposition p ∈ A, we use a Boolean variable b p to represent p. Let B(A) = {b p : p ∈ A} be the set of Boolean variables corresponding to the atomic propositions in A. Consider the concrete domain Prop A and the abstract domain Bool B(A) .
A Boolean formula β ∈ Bool B(A) is called a canonical monomial if it is a conjunction of literals such that each Boolean variable in B(A) appears exactly once.
Define the mappings γ : Bool B(A) → Prop A and α : Prop A → Bool B(A) :γ(β) = β[b p → p]; and α(θ) = {β ∈ Bool B(A) : β is a canonical monomial and θ ∧ γ(β) is satisfiable}.
where b p and p are the Boolean variables in B(A) and their corresponding atomic propositions respectively.
The following lemmas are useful in proving our technical results:Lemma 1.
Let A be a set of atomic propositions, θ, ρ ∈ Prop A .
Thenθ ⇒ ρ implies α(θ) ⇒ α(ρ).
Lemma 2.
Let A be a set of atomic propositions, θ ∈ Prop A , and β a canonical monomial in Bool B(A) .
Then θ ∧ γ(β) is satisfiable if and only if γ(β) ⇒ θ.
3Recall that a teacher for the CDNF algorithm answers queries in the abstract domain, and an SMT solver computes models in the concrete domain.
In order to let an SMT solver play the role of a teacher, more transformations are needed.
A valuation induces a natural Boolean valuation.
Precisely, define the Boolean valuation α * (ν) for the valuation ν as follows.
A Boolean valuation on the other hand induces a propositional formula.
Define the propositional formula γ * (µ) for the Boolean valuation µ as follows.
(α * (ν))(b p ) = T if ν |= p F otherwiseγ * (µ) = p∈A {p : µ(b p ) = T} ∧ p∈A {¬p : µ(b p ) = F}Lemma 4.
Let A be a set of atomic propositions, θ ∈ Prop A , and µ a Boolean valuation for B(A).
Then γ * (µ) ⇒ θ if and only if µ |= α(θ).
Suppose ι ∈ Prop A is an invariant for the statement {δ} while ρ do S {}.
Let ι, ι ∈ Prop A .
We say ι is an under-approximation to an invariant ι if δ ⇒ ι and ι ⇒ ι.
Similarly, ι is an over-approximation to an invariant ι if ι ⇒ ι and ι ⇒ ∨ρ.
The strongest (δ) and weakest (∨ρ) approximations are trivial underand over-approximations to any invariant respectively.
Recall that the CDNF algorithm makes the following queries: (1) membership queries MEM (µ) where µ ∈ Val B(A) , and (2) equivalence queries EQ(β) where β ∈ Bool B(A) .
In the following, we show how to resolve these queries by means of an SMT solver and the invariant approximations (ι and ι).
Membership Queries In the membership query MEM (µ), the teacher is required to answer whether µ |= α(ι).
We concretize the Boolean valuation µ and check it against the approximations.
If the concretization γ * (µ) is inconsistent (that is, γ * (µ) is unsatisfiable), we simply answer NO for the membership query.
Otherwise, there are three cases:1.
γ * (µ) ⇒ ι.
Thus µ |= α(ι) (Lemma 4).
And µ |= α(ι) by Lemma 1.
2.
γ * (µ) ι.
Thus µ |= α(ι) (Lemma 4).
That is, µ |= ¬α(ι).
Since ι → ι, we have µ |= α(ι) by Lemma 1.
3.
Otherwise, we cannot determine whether µ |= α(ι) by the approximations.
Algorithm 3: Resolving Membership Queries Algorithm 3 shows our membership query resolution algorithm.
Note that when a membership query cannot be resolved by an SMT solver given invariant approximations, one can use better approximations from static analyzers.
Our framework is therefore orthogonal to existing static analysis techniques.Equivalence Queries To answer the equivalence query EQ(β), we concretize the Boolean formula β and check if γ(β) is indeed an invariant of the while statement for the given pre-and post-conditions.
If it is, we are done.
Otherwise, we use an SMT solver to find a witness to α(ι) ⊕ β.
There are three cases:1.
There is a ν such that ν |= ¬(ι ⇒ γ(β)).
Then ν |= ι ∧ ¬γ(β).
By Lemma 3 and 1, we have α * (ν) |= α(ι) and α * (ν) |= ¬β.
Thus, α * (ν) |= α(ι) ∧ ¬β.
2.
There is a ν such that ν |= ¬(γ(β) ⇒ ι).
Then ν |= γ(β) ∧ ¬ι.
By Lemma 3, α * (ν) |= β.
α * (ν) |= ¬α(ι) by Lemma 3 and 1.
Hence α * (ν) |= β ∧ ¬α(ι).
3.
Otherwise, we cannot find a witness to α(ι) ⊕ β by the approximations.
(* {δ} while ρ do S {} *) (* ι: an under-approximation; ι: an over-approximation *)Input: β ∈ Bool B(A) θ := γ(β); if SMT (ι ∧ ¬θ) → UNSAT and SMT (θ ∧ ¬ι) → UNSAT and SMT (ρ ∧ θ ∧ ¬Pre(θ, S)) → UNSAT then return YES ; if SMT (ι ∧ ¬θ) → ν then return α * (ν); if SMT (θ ∧ ¬ι) → ν then return α * (ν); abort with θ;Algorithm 4: Resolving Equivalence Queries Algorithm 4 shows our equivalence query resolution algorithm.
Note that Algorithm 4 returns YES only if an invariant is found.Similar to membership query resolution, one can refine approximations by static analysis when an equivalence query is not resolvable by an SMT solver given invariant approximations.
For simplicity, Algorithm 4 aborts the learning algorithm with the unresolved equivalence query.
Algorithm 5 gives the top-level loop of our framework.
Initially, we use the disjunction of strongest approximation and the postcondition as the underapproximation; the weakest approximation is the over-approximation.
The underapproximation aims to find an invariant that establishes the postcondition.
This heuristic is proved very useful in practice.
(* {δ} while ρ do S {} *) function randomized membership µ = try Algorithm 3 with input µ when abort → return YES or NO randomly;ι := δ ∨ ; ι := ∨ ρ; repeat try ι := Algorithm 1 with randomized membership and Algorithm 4 when abort → continue until an invariant ι is found ; After determining the approximations, Algorithm 1 is used to find an invariant.
We use Algorithms 3 and 4 to resolve queries with an SMT solver given the invariant approximations.
If Algorithm 3 aborts with an unresolved membership query, a random answer is returned by randomized membership.
If Algorithm 4 aborts with an unresolved equivalence query, the learning algorithm is restarted.Since algorithmic learning does not commit to any specific target, it always finds an invariant consistent with answers to previous queries.
In other words, the learning algorithm will always generate an invariant if there is one consistent with our random answers.
Although our random answers may exclude certain invariants, an invariant can still be inferred.
Verifying whether a formula is an invariant is done by checking the sufficient conditions of Definition 1 in our equivalence query resolution algorithm (Algorithm 4).
We have implemented a prototype in OCaml.
In our implementation, we use Yices as the SMT solver to resolve queries (Algorithm 3 and 4).
From SPEC2000 benchmarks and Linux device drivers we chose five while statements.
We translated them into our language and added postcondition manually.
Table 1 shows the performance numbers of our experiments.
Among five while statements, the cases parser and vpr are extracted from PARSER and VPR in SPEC2000 benchmarks respectively.
The other three cases are extracted from Linux 2.6.28 device drivers: both ide-ide-tape and ide-wait-ireason are from IDE driver; usb-message is from USB driver.
For each case, we report the number of language constructs in the loop (SIZE), the number of atomic propositions (AP ), the number of membership queries (MEM ), the number of equivalence queries (EQ), the number of randomly resolved membership queries (coin tossing), the number of the CDNF algorithm invocations (iterations), and the execution time.
The data are the average of 500 runs and collected on a 2.6GHz Intel E5300 Duo Core with 3GB memory running Linux 2.6.28.
Our technique is able to find invariants for four cases within 1 second.
Most interestingly, the learning algorithm is able to find an invariant for usb-message regardless of the outcomes of coin tossing.
For the most complicated case parser, our technique is able to generate an invariant with 991 random membership resolutions in about 33 seconds.
Figure 2 is a while statement extracted from Linux IDE driver.
4 It copies data of size n from tape records.
The variable count contains the size of the data to be copied from the current record (bh b size and bh b count).
If the current tape record runs out of data, more data are copied from the next record.
The flexibility in invariants can be witnessed in the following run.
After successfully resolving 3 equivalence and 7 membership queries, the CDNF algorithm makes the following membership query unresolvable by the invariant approximations:ρ n > 0 ∧ (bh b size − bh b count) < n ∧ ret = 0 ∧bh b count = bh b sizeAnswering NO to this query leads to the following unresolvable membership query after successfully resolving two more membership query:ρ ∧ bh b count = bh b size ∧ bh b count ≤ bh b sizeWe proceed with a random answer YES .
After successfully resolving one more membership queries, we reach the following unresolvable membership query:ρ ∧ bh b count = bh b size ∧ bh b count > bh b sizeFor this query, both answers lead to invariants.
Answering YES yields the following invariant:n = 0 ∨ (bh b size − bh b count) ≥ nAnswering NO yields the following invariant:(bh b count ≤ bh b size ∧ n = 0) ∨ (bh b size − bh b count) ≥ n Note that they are two different invariants.
The equivalence query resolution algorithm (Algorithm 4) ensures that both fulfill the conditions in Definition 1.6.2 parser from VPR in SPEC2000 Benchmarks Figure 3 shows a sample while statement from the parser program in SPEC2000 benchmark.
5 In the while body, there are three locations where give up or success is set to T. Thus one of these conditions in the if statements must hold (the first conjunct of postcondition).
Variable valid may get an arbitrary value if linkages is not zero.
But it cannot be greater than linkages by the assume statement (the second conjunct of postcondition).
The variable linkages gets an arbitrary value near the end of the while body.
But it cannot be greater than 5000 (the fourth conjunct), and always equal to the variable canonical (the third conjunct of postcondition).
Despite the complexity of the postcondition and the while body, our approach is able to compute an invariant in 13 iterations on average.
The execution time and number of iterations vary significantly.
They range from 2.22s to 196.52s and 1 to 84 with standard deviations 31.01 and 13.33 respectively.
By Chebyshev's inequality [27], our technique infers an invariant within two minutes with probability 0.876.
One of the found invariants is the following:success ⇒ (valid ≤ linkages ∧ linkages ≤ 5000 ∧ canonical = linkages) success ⇒ (¬search ∨ count > words ∨ valid = 0) success ⇒ (count > words ∨ cutoff = maxcost ∨ (canonical = 0 ∧ valid = 0 ∧ linkages = 0)) give up ⇒ ((valid = 0 ∧ linkages = 0 ∧ canonical = linkages)∨ (canonical = 0 ∧ valid ≤ linkages ∧ linkages ≤ 5000 ∧ canonical = linkages)) give up ⇒ (cutoff = maxcost ∨ count > words∨ (canonical = 0 ∧ valid = 0 ∧ linkages = 0)) give up ⇒ (¬search ∨ count > words ∨ valid = 0)This invariant describes the conditions when success or give up are true.
For instance, it specifies that valid ≤ linkages ∧ linkages ≤ 5000 ∧ canonical = linkages should hold if success is true.
In Figure 3, we see that success is assigned to T at line 18 when valid is positive.
Yet valid is set to 0 at line 14.
Hence line 16 and 17 must be executed.
Thus, the first (valid ≤ linkages) and the third (canonical = linkages) conjuncts hold.
Moreover, line 13 ensures that the second conjunct (linkages ≤ 5000) holds as well.
The complexity of our technique depends on the distribution of invariants.
It works most effectively if invariants are abundant.
The number of iterations depends on the outcomes of coin tossing.
The main loop may reiterate several times or not even terminate.
Our experiments suggest that there are sufficiently many invariants in practice.
For each of the 2500 (= 5 × 500) runs, our technique always generates an invariant.
On average, it takes 12.5 iterations for the most complicated case parser.Since plentiful of invariants are available, it may appear that one of them can be generated by merely coin tossing.
But this is not the case.
In parser, our technique does not terminate if the under-and over-approximations are the strongest and weakest approximations respectively.
Indeed, 6695 membership and 820 equivalence queries are resolved by invariant approximations in this case.
Invariant approximations are essential to our framework.For simplicity, predicates are collected from program texts, pre-and postconditions in our experiments.
Existing predicate discovery techniques can certainly be deployed.
Better invariant approximations (ι and ι) computed by static analysis can be used in our framework.
More precise approximations of ι and ι will improve the performance by reducing the number of iterations via increasing the number of resolvable queries.
Also, a variety of techniques from static analysis or loop invariant generation [12,17,28,16,19,21,23,25] in particular can be integrated to resolve queries in addition to one SMT solver with coin tossing.
Such a set of multiple teachers will increase the number of resolvable queries because it suffices to have just one teacher to answer the query to proceed.In comparison with previous invariant generation techniques [12,17,28,16,19,21,23,25], we have the following distinguishing features.
(1) We do not use fixed point computation nor any static or dynamic analyses.
Instead, we use algorithmic learning [6] to search for loop invariants.
(2) Templates for invariants are not needed.
Our approach does not restrict to specific forms of invariants imposed by templates.
(3) We employ SMT solvers instead of theorem provers in our technique.
This allows us to take advantages of recent development in efficient SMT algorithms.
(4) Our method can be extended and combined with the existing loop invariant techniques.Related Work Existing impressive techniques for invariant generation can be adopted as the query resolution components (teachers) in our algorithmic learningbased framework.
Srivastava and Gulwani [28] devise three algorithms, two of them use fixed point computation and the other uses a constraint based approach [17,16] to derive quantified invariants.
Gupta and Rybalchenko [19] present an efficient invariant generator.
They apply dynamic analysis to make invariant generation more efficient.
Flanagan and Qadeer use predicate abstraction to infer universally quantified loop invariants [12].
Predicates over Skolem constants are used to handle unbounded arrays.
McMillan [25] extends a paramodulationbased saturation prover to an interpolating prover that is complete for universally quantified interpolants.
He also solves the problem of divergence in interpolatedbased invariant generation.
By combining algorithmic learning, decision procedures, and predicate abstraction, we introduced a technique for invariant generation.
The new technique finds invariants guided by query resolution algorithms.
Algorithmic learning gives a platform to integrate various techniques for invariant generation; it suffices to design new query resolution algorithms based on existing techniques.
The learning algorithm will utilize the information provided by these techniques.To illustrate the flexibility of algorithmic learning, we deploy a randomized query resolution algorithm.
When a membership query cannot be resolved, a random answer is returned to the learning algorithm.
Since the learning algorithm does not commit to any specific invariant beforehand, it always finds a solution consistent with query results.
Our experiments indeed show that algorithmic learning is able to infer non-trivial invariants with this na¨ıvena¨ıve membership resolution.
It is important to exploit the power of coin tossing in our technique.
Let us apply Algorithm 1 to learn the Boolean formula b 0 ⊕ b 1 .
The algorithm first makes the query EQ(T) (Figure 4).
The teacher responds by giving the valuation µ 1 (b 0 ) = µ 1 (b 1 ) = 0 (denoted by µ 1 (b 0 b 1 ) = 00).
Hence Algorithm 1 assigns ∅ to S 1 , F to H 1 , and µ 1 to a 1 .
Next, the query EQ(H 1 ) is made and the teacher responds with the valuation µ 2 (b 0 b 1 ) = 01.
Since µ 2 |= F, we have I = {1}.
Algorithm 1 now walks from µ 2 towards a 1 .
Since flipping µ 2 (b 1 ) would not give us a model of b 0 ⊕ b 1 , we have S 1 = {µ 2 } and H 1 = b 1 .
In this example, Algorithm 1 generates (b 1 ∨ b 0 ) ∧ (¬b 0 ∨ ¬b 1 ) as a representation for the unknown Boolean formula b 0 ⊕ b 1 .
Observe that the generated Boolean formula is a conjunction of two Boolean formulae in disjunctive normal form.equivalence query answer I Si Hi ai T µ1(b0b1) = 00 S1 = ∅ H1 = F a1 = µ1 F µ2(b0b1) = 01 {1} S1 = {µ2} H1 = b1 b1 µ3(b0b1) = 11 ∅ S2 = ∅ H2 = F a2 = µ3 b1 ∧ F µ4(b0b1) = 01 {2} S2 = {µ5} † H2 = ¬b0 b1 ∧ ¬b0 µ6(b0b1) = 10 {1, 2} S1 = {µ2, µ6} S2 = {µ5, µ7} † H1 = b1 ∨ b0 H2 = ¬b0 ∨ ¬b1 (b1 ∨ b0) ∧ (¬b0 ∨ ¬b1)YES † µ5(b0b1) = 10 and µ7(b0b1) = 01
