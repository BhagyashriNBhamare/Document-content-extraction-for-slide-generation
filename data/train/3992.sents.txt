Floating-point computations introduce several side channels.
This paper describes the first solution that closes these side channels while preserving the precision of non-secure executions.
Our solution exploits micro-architectural features of the x86 architecture along with novel compilation techniques to provide low overhead.
Because of the details of x86 execution, the evaluation of floating-point side channel defenses is quite involved, but we show that our solution is secure, precise, and fast.
Our solution closes more side channels than any prior solution.
Despite the added security, our solution does not compromise on the precision of the floating-point operations.
Finally, for a set of microkernels, our solution is an order of magnitude more efficient than the previous solution.
To secure our computer systems, considerable effort has been devoted to techniques such as encryption, access control, and information flow analysis.
Unfortunately, these mechanisms can often be subverted through the use of side channels, in which an adversary, with the knowledge of the program, monitors the program's execution to infer secret values.
These side channels are significant because they have been used to discover encryption keys in AES [26], RSA [27], and the Diffie-Hellman key exchange protocol [14], thereby rendering these sophisticated schemes useless.Numerous side channels exist, including instruction and data caches [27,26], branch predictors [2], memory usage [12,35], execution time [31,4], heat [22], power [15], and electromagnetic radiation [9], but one particularly insidious side channel arises from the execution of variable-latency floating-point instructions [3,10], in which an instruction's latency varies widely depending on its operands, as shown in Table 1.
7 11 153 7 7 Table 1: Latency (in cycles) of the SQRTSS instruction for various operands.Both x86 1 and ARM 2 provide variable-latency floating-point instructions.
This variable latency stems from the desire to have graceful floating-point arithmetic behavior, which, as we explain in Section 3, requires the use of so-called subnormal values [8], which are processed using special algorithms.
Since subnormal values are rare, hardware vendors typically support such values in microcode, so as not to slow down the common case.
The resulting difference in instruction latency creates a timing side channel, which has been used to infer crossorigin data in browsers and to break differential privacy guarantees of a remote database [3].
However, variable latency floating-point instructions represent only a part of the problem, since higher level floating-point operations, such as sine and cosine, are typically implemented in software.
Thus, the implementation of these floating-point operations can leak secret information through other side channels as well.
Depending on the secret values, programs can throw exceptions, thereby leaking the presence of abnormal inputs through termination.
Programs can also contain conditional branches, which can leak secrets through the instruction pointer, branch predictor, or memory access count.
Finally, programs that index into lookup tables can leak secrets through the memory address trace.To prevent information leaks in both floating-point instructions and floating-point software, a strong solution should ensure at least four key properties, which correspond to the side channels that we discussed above:(1) fixed-time operations that are independent of secret values, (2) disabled exceptions, (3) sequential control flow, and (4) uniform data accesses that are independent of the value of secret variables.
Previous solutions [3,5] are inadequate because they do not ensure all four properties, are slow, are orders of magnitude less precise, or are difficult to implement.This paper presents a novel solution that closes side channels arising from both hardware and software implementations of floating point operations, providing all four properties mentioned above.
Our compiler-based solution has two components.The first component creates building blocks of elementary floating-point operations for instructions that are natively supported by the hardware (addition, subtraction, multiplication, division, square root, and type conversion).
Our solution leverages unused SIMD lanes so that fast operations on normal operands are accompanied by slower dummy computations on subnormal operands, yielding a consistent yet low instruction latency for all types of operands.The second component is a software library of higherlevel floating-point operations like sine and cosine.The key to creating this second component is a new code transformation that produces fixed-latency functions through normalized control flows and data access patterns.
Code generated by our compiler closes digital side-channels, which have been defined to be those side channels that carry information over discrete bits [28].
Whereas previous work in closing digital side channels employs a runtime system [28], our solution shifts much of the work to compile time, yielding a significantly smaller runtime overhead.
This paper makes the following contributions:1.
We present a novel compiler-based system, called Escort, for closing digital side channels that arise from the processing of floating-point instructions.2.
Secure: We demonstrate that our solution is secure not just against timing but also against digital side channels.
We demonstrate Escort's capabilities by defeating a machine-learning side-channel attack, by defending against a timing attack on the Firefox web browser, by conducting extensive performance measurements on an x86 processor, and by verifying our solution's code using typing rules.3.
Precise: We show that Escort provides precision that is identical to that of the standard C math library.
By contrast, the previous solution's precision is off by several million floating-point values.4.
Fast: We show that our solution is fast.
On a set of micro-benchmarks that exercise elementary floating-point operations, Escort is 16× faster than the previous solution [3].5.
As an ancillary contribution, we introduce a methodology for evaluating the precision and security of floating-point operations, which is fraught with subtleties.The rest of this paper is organized as follows.
Section 2 describes our threat model, related work, and system guarantees.
We provide background in Section 3 before presenting our solution in Section 4.
We evaluate our solution in Sections 5-7 .
Finally, we conclude in Section 8.
This section begins by describing our threat model, which shapes our subsequent discussion of related work and of Escort's security guarantees.Threat Model.
Our goal is to prevent secret floatingpoint operands from leaking to untrusted principals that either read digital signals from the processor's pins or that are co-resident processes.We assume that the adversary is either an external entity that monitors observation-based side channels (e.g. time [14], memory address trace [11], or the /proc pseudo-filesystem [12]) or a co-resident process/VM that monitors contention-based side channels (e.g. cache [27] or branch predictor state [2]).
For off-chip observation-based channels, we assume that the processor resides in a sealed and tamper-proof chip that prevents the adversary from measuring physical side channels like heat, power, electromagnetic radiation, etc.
We assume that the CPU encrypts data transferred to and from DRAM.
All components other than the processor are untrusted, and we assume that the adversary can observe and tamper with any digital signal.
For on-chip contention-based channels, we assume that the OS is trusted and does not leak the victim process's secret information.
We also assume that the adversary cannot observe or change the victim process's register contents.
Our trusted computing base includes the compilation toolchain.Side-Channel Defenses.
Decades of prior research have produced numerous defenses against side channels, the vast majority of which close only a limited number of side channels with a single solution.
For instance, numerous solutions exist that close only the cache side channel [6,36,39,37,16] or only the address-trace side channel [33,20,32,29].
Raccoon [28] is the first solution that closes a broad class of side channels-in particular, the set of digital side channels-with a single solution.
Similar to Raccoon, Escort also closes digital side channels with a single solution, but unlike Raccoon, Escort focuses on closing floating-point digital side channels, which can arise from variable latency floating-point instructions and from software implementations of floating-point libraries, in which points-to set sizes are typically small.
Given Escort's narrower focus on floating-point computations, Escort is faster than Raccoon by an order of magnitude.Timing Side-Channel Defenses.
Prior defenses against timing side-channel attacks utilize new algorithms [30], compilers [23], runtime systems [21], or secure processors [18].
However, these solutions only address one source of timing variations-either those stem from the choice of the algorithm [31] or those that stem from the microarchitectural design [10].
By contrast, Escort closes timing variations from both sources.Floating-Point Side-Channel Defenses.
Andrysco et al. [3] present libfixedtimefixedpoint (FTFP), the first software solution for closing the floating-point timing channel.
FTFP has some weaknesses, as we now discuss, but the main contribution of their paper is the demonstration of the significance of this side channel, as they use variable-latency floating-point operations to break a browser's same-origin policy and to break differential privacy guarantees of remote databases.
FTFP is a fixed-point library that consists of 19 hand-written functions that each operates in fixed time, independent of its inputs.
FTFP is slow, it is imprecise, and it exposes secrets through other side channels, such as the cache side channel or the address trace side channel.
Cleemput et al. [5] introduce compiler transformations that convert variable-timing code into fixed-timing code.
Their technique requires extensive manual intervention, applies only to the division operation, and provides weak security guarantees.
Both solutions require manual construction of fixed-time code-a cumbersome process that makes it difficult to support a large number of operations.
By contrast, Escort implements a fixed-time floatingpoint library, while preventing information leaks through timing as well as digital side channels.
Escort includes a compiler that we have used to automate the transformation of 112 floating-point functions in the Musl standard C library, a POSIX-compliant C library.
Escort also provides precision identical to the standard C library.Escort's Guarantees.
Escort rejects programs that contain unsupported features-I/O operations and recursive function calls.
Unlike prior work [18,28], Escort does transform loops that leak information through trip counts.
Escort is unable to handle programs containing irreducible control flow graphs (CFGs), but standard compiler transformations [24] can transform irreducible CFGs into reducible CFGs.
Escort assumes that the input program does not use vector instructions, does not exhibit undefined behavior, does not terminate abnormally through exceptions, and is free of race conditions.
Given a program that abides by these limitations, Escort guarantees that the transformed code produces identical results as the original program, does not leak secrets through timing or digital side channels, and that the transformed code does not terminate abnormally.
The variable latency of floating-point instructions creates security vulnerabilities.
In this section, we explain subnormal numbers, which are the cause of the variable latency, and we explain the difficulty of fixing the resulting vulnerability.
We also explain how the Unit of Least Precision (ULP) can be used to quantify the precision of our and competing solutions.
Subnormal numbers have tiny exponents, which result in floating-point values that are extremely close to zero: 10 −45 < |x| < 10 −38 for single-precision numbers and 10 −324 < |x| < 10 −308 for double-precision numbers.
Subnormal values extend the range of floating-point numbers that can be represented, but more importantly, they enable gradual underflow-the property that as floating-point numbers approach zero along the number scale, the difference between successive floating-point numbers does not increase 3 .
Figures 1a and 1b show the differences between zero and the two smallest positive floating-point numbers.
With subnormal numbers, the gap between any two consecutive floating-point values is never larger than the values themselves, thus exhibiting Gradual Underflow.
Subnormal numbers are indispensable because gradual underflow is required for reliable equation solving and convergence acceleration [8,13].
To avoid the added hardware complexity of supporting subnormal numbers, which occur infrequently, vendors typically process subnormal values in microcode, which is orders of magnitude slower than hardwired logic.The resulting difference in latencies creates a security vulnerability.
An adversary that can measure the latency of a floating-point instruction can make reasonable estimates about the operand type, potentially inferring secret values using the timing channel.
While subnormal values occur infrequently in typical program execution, an adversary can deliberately induce subnormal values in the application's inputs to enable subnormal operand timing attacks.
Unlike real (infinite precision) numbers, floating-point numbers use a limited number of bits to store values, thus making them prone to rounding errors.
Rounding errors in floating-point numbers are typically measured in terms of the Unit of Least Precision (ULP) [25].
The ULP distance between two floating-point numbers is the number of distinct representable floating-point numbers between them, which is simply the result of subtracting their integer representations.
If the result of the subtraction is zero, the floating-point numbers must be exactly the same.
Escort offers secure counterparts of ordinary non-secure floating-point operations, including both elementary operations and higher-level math operations.
The elementary operations include the six basic floating-point operations that are natively supported by the ISA-type conversion, addition, subtraction, multiplication, division, and square root-and a conditional data copy operation.
The 112 higher-level math operations are those that are implemented using a combination of native instructions.
Examples of higher-level functions include sine, cosine, tangent, power, logarithm, exponentiation, absolute value, floor, and ceiling.The next subsections describe Escort's design in three parts.
First, we describe the design of Escort's secure elementary operations.
These operations collectively form the foundation of Escort's security guarantees.
Second, we describe Escort's compiler, which accepts non-secure code for higher-level operations and converts it into secure code.
This compiler combines a code transformation technique with Escort's secure elementary operations.
Third, we present an example that shows the synergy among Escort's components.
The key insight behind Escort's secure elementary operations is that the latencies of SIMD instructions are determined by the slowest operation among the SIMD lanes (see Figure 2), so the Escort compiler ensures that each elementary instruction runs along side a dummy instruction whose operand will produce the longest possible latency.
Our analysis of 94 x86 SSE and SSE2 instructions (which includes single-and double-precision arithmetic, comparison, logical, and conversion instructions) reveals: (1) that only the multiplication, division, square root, and single-precision to double-precision conversion (upcast) instructions exhibit latencies that depend on their operands and (2) that subnormal operands induce the longest latency.In particular, Escort's fixed-time floating-point operations utilize SIMD lanes in x86 SSE and SSE2 instructions.
Our solution (1) loads genuine and dummy (subnormal) inputs in spare SIMD lanes of the same input register, (2) invokes the desired SIMD instruction, and (3) retains only the result of the operation on the genuine inputs.
Our tests confirm that the resulting SIMD instruction exhibits the worst-case latency, with negligible variation in running time (standard deviation is at most 1.5% of the mean).
Figure 3 shows Escort's implementation of one such operation.Escort includes Raccoon's conditional data copy operation (see Figure 4) which does not leak information through digital side channels.
This operation copies the contents of one register to another register if the given condition is true.
However, regardless of the condition, this operation consumes a fixed amount of time, executes the same set of instructions, and does not access application memory.
Escort's compiler converts existing non-secure code into secure code that prevents information leakage through digital side channels.
First, our compiler replaces all elementary floating-point operations with their secure counterparts.
Next, our compiler produces straight-line code that preserves control dependences among basic blocks while preventing instruction side effects from leaking secrets.
Our compiler then transforms array access statements so that they do not leak information through memory address traces.
Finally, our compiler transforms double result; __asm__ volatile( "movdqa %1, %%xmm14;" "movdqa %2, %%xmm15;" "pslldq $8, %1;" "pslldq $8, %2;" "por %3, %1;" "por %4, %2;" "movdqa %2, %0;" "mulpd %1, %0;" "psrldq $8, %0;" "movdqa %%xmm14, %1;" "movdqa %%xmm15, %2;" : "=x" (result), "+x" (x), "+x" (y) : "x" (k_subnormal_dp), "x" (k_normal_dp) : "xmm15", "xmm14"); return result; } Figure 3: Escort's implementation of double-precision multiplication, using the AT&T syntax.
loops whose trip count reveals secrets over digital side channels.
We now describe each step in turn.
The Escort compiler replaces x86 floating-point typeconversion, multiplication, division, and square root assembly instructions with their Escort counterparts.
However, Escort's secure elementary operations can be up to two orders of magnitude slower than their non-secure counterparts.
Hence, our compiler minimizes their usage by using taint tracking and by employing the quantifierfree bit-vector logic in the Z3 SMT solver [7], which is equipped with floating-point number theory.
If the solver can prove that the operands can never be subnormal values, then Escort refrains from replacing that instruction.In effect, the Escort compiler constructs path-sensitive Z3 expressions for each arithmetic statement in the 01: copy(uint8_t pred, uint32_t t_val, uint32_t f_val) { 02: uint32_t result; 03:__asm__ volatile ( 04:"mov %2, %0;" 05:"test %1, %1;" 06:"cmovz %3, %0;" 07:"test %2, %2;" 08:: "=r" (result) 09:: "r" (pred), "r" (t_val), "r" (f_val) 10:: "cc" 11:); 12:return result; 13: } Figure 4: Code for conditional data copy operation that does not leak information over digital side channels.
This function returns t val if pred is true; otherwise it returns f val.
The assembly code uses AT&T syntax.LLVM IR.
For every Φ-node that produces an operand for an arithmetic expression, Escort creates one copy of the expression for each input to the Φ-node.
If the solver reports that no operand can have a subnormal value, then Escort skips instrumentation of that floating-point operation.We set a timeout of 40 seconds for each invocation of the SMT solver.
If the solver can prove that the instruction never uses subnormal operands, then Escort skips replacing that floating-point instruction with its secure counterpart.
Figure 5 shows the percentage of floatingpoint instructions in commonly used math functions that are left untransformed by Escort.This optimization is conservative because it assumes that all floating-point instructions in the program have subnormal operands unless proven otherwise.
The correctness of the optimization is independent of the code's use of pointers, library calls, system calls, or dynamic values.
The static analysis used in this optimization is flow-sensitive, path-sensitive, and intra-procedural.
Figure 5: Percentage of instructions that are left uninstrumented (without sacrificing security) after consulting the SMT solver.
Basic block predicates represent the conditions that dictate whether an instruction should execute.
These predicates are derived by analyzing conditional branch instructions.
For each conditional branch instruction that evaluates a predicate p, the Escort compiler associates the predicate p with all basic blocks that execute if the predicate is true, and it associates the predicate ¬p with all basic blocks that execute if the predicate is false.
For unconditional branches, the compiler copies the predicate of the previous block into the next block.
Finally, if the Escort compiler comes across a block that already has a predicate, then the compiler sets the block's new predicate to the logical OR of the input predicates.
At each step, the Escort compiler uses Z3 as a SAT solver to simplify predicates by eliminating unnecessary variables in predicate formulas.
Figure 6 shows the algorithm for basic block predication.
The Escort compiler converts the given code into straight-line code so that every invocation of the code executes the same instructions.
To preserve control dependences, the basic blocks are topologically sorted, and then the code is assembled into a single basic block with branch instructions removed.
We now explain how Escort prevents side effects from leaking secrets.
Here, side effects are modifications to the program state or any observable interaction, including memory accesses, exceptions, function calls, or I/O.
Escort controls all side effects except for I/O statements.
if loop condition branch(br) then 񮽙 Skip branches that represent loops.19:pred[s 1 ] ← pred[s 1 ] ∨ pred[bb] 20: pred[s 2 ] ← pred[s 2 ] ∨ pred[bb]21:else 22:p ← condition(br)23:pred[s 1 ] ← pred[s 1 ] ∨ (pred[bb] ∧ p) 24: pred[s 2 ] ← pred[s 2 ] ∨ (pred[bb] ∧ ¬p) 25:end if26: pred[s 1 ] ← simpli f y(pred[s 1 ]) 27: pred[s 2 ] ← simpli f y(pred[s 2 ])28:end if 29: end for Memory Access Side Effects.
To ensure proper memory access side effects, the Escort compiler replaces store instructions with conditional data-copy operations that are guarded by the basic block's predicate, so memory is only updated by instructions whose predicate is true.Unfortunately, this na¨ıvena¨ıve approach can leak secret information when the program uses pointers.
Figure 7 illustrates the problem: If store instructions are not allowed to update a pointer variable when the basic block predicate is false, then the address trace from subsequent load instructions on the pointer variable will expose the fact that the pointer variable was not updated.The Escort compiler prevents such information leaks by statically replacing pointer dereferences with loads or stores to each element of the points-to set 4 .
Thus Escort replaces the statement in line 8 (Figure 7) with a store operation on b.
When the points-to set is larger than a ... p ← &b 񮽙 Instruction does not update pointer p, since basic block's execution-time predicate is false. 񮽙
Accesses a instead of b!
9: end if Figure 7: The use of pointers can leak information.
If store instructions are not allowed to access memory when the basic block's predicate is false, then pointer p will dereference the address for a instead of b, thus revealing that secret is true.singleton set, Escort uses the conditional data copy operation on all potential pointees i.e. the elements of the points-to set.
The predicate of the conditional copy operation checks whether the pointer points to the candidate pointee.
If the predicate is false, the pointee's existing value is overwritten, whereas if the predicate is true, the new value is written to the pointee.Function Call Side Effects.
Adversaries can observe the invocation of functions (or lack thereof) using side channels like the Instruction Pointer.
Thus, a solution incapable of handling function calls will leak information to the adversary.
While inlining functions is a potential solution, inlining is impractical for large applications.Escort handles side effects from function calls by propagating the predicate from the calling function to the callee.
Thus, each user-defined function is given an additional argument that represents the predicate of the call site's basic block.
The callee ensures correct handling of side effects by ANDing its own predicates with the caller's predicate.Side Effects from Exceptions.
Program termination caused by exceptions will leak the presence or absence of abnormal operands.
To prevent such information leakage, Escort requires that exceptions not occur during program execution 5 .
Escort manages floating-point and integer exceptions differently.
Escort requires that the programmer disable floating-point exceptions (e.g. using feclearexcept()).
For integer exceptions, Escort borrows ideas from Raccoon by replacing abnormal operands with benign operands (e.g. Escort prevents integer division-by-zero by replacing a zero divisor with a non-zero divisor).
Array index values reveal secrets as well.
For instance, if the adversary observes that accesses to array [0] and array[secret index] result in accesses to locations 10 and 50, then the adversary knows that secret index = 40.
To eliminate such information leaks, the Escort compiler transforms each array access into a linear sweep over the entire array, which hides from the adversary the address of the program's actual array index.Of course, the transformed code is expensive, but this approach is feasible because (1) math library functions typically use only a few small lookup tables, thus requiring relatively few memory accesses and (2) the processor's caches and prefetchers dramatically reduce the cost of sweeping over the arrays.
Some loops introduce timing channels because their trip counts depend on secret values.
The Escort compiler transforms such loops using predictive mitigation [38].
The loop body executes as many times as the smallest power of 2 that is greater than or equal to the loop trip count.
For instance, if the actual loop trip count is 10, then the loop body is executed 16 times.
The basic block predicate ensures that dummy iterations do not cause side effects.
With this transformed code, an adversary that observes a loop trip count of l can infer that the actual loop trip count l 񮽙 is between l and 0.5 × l. However, the exact value of l 񮽙 is not revealed to the adversary.Unfortunately, this naive approach can still leak information.
For instance, if two distinct inputs cause the loop to iterate 10 and 1000 times respectively, the transformed codes will iterate 16 and 1024 times respectively-a large difference that may create timing variations.
To mitigate this problem, Escort allows the programmer to manually specify the minimum and maximum loop trip counts using programmer annotations.
These annotations override the default settings used by the Escort compiler.
We now explain how Escort transforms an example non-secure function (Figure 8a) into a secure function (Figure 8c).
To simplify subsequent analyses and transformations, the Escort compiler applies LLVM's mergereturn transformation pass, which unifies all exit nodes in the input function (see Figure 8b).
Figure 8b.
each basic block, which we list in Table 2.
Third, the Escort compiler linearizes basic blocks by applying a topological sort on the control flow graph (see Figure 9) and fuses the basic blocks together.
Finally, the Escort compiler replaces the array access statement in line 4 with a function that sweeps over the entire array.
The resulting code, shown in Figure 8c, eliminates control flows and data flows that depend on secret values.
In addition to closing digital side channels, the code also uses secure floating-point operations.
This section demonstrates that Escort's floating-point operations run in fixed time and do not leak information through digital side channels.
Since precise timing measurement on x86 processors is tricky due to complex processor and OS design, we take special measures to ensure that our measurements are accurate.
In addition to Escort's timing and digital side channel defense, we also demonstrate Escort's defense against a floatingpoint timing channel attack on the Firefox web browser.
We run all experiments on a 4-core Intel Core i7-2600 (Sandy Bridge) processor.
The processor is clocked at 3.
We measure instruction latencies using the RDTSC instruction that returns the number of elapsed cycles since resetting the processor.
Since the latency of executing the RDTSC instruction is usually higher than the latency of executing operations, our setup measures the latency of executing 1024 consecutive operations and divides the measured latency by 1024.
Our setup uses the CPUID instruction and volatile variables for preventing the processor and the compiler from reordering critical instructions.
Finally, our setup measures overhead by executing an empty loop body-a loop body that contains no instructions other than those in the test harness.
By placing an empty volatile asm block in the empty loop body, our setup prevents the compiler from deleting the empty loop body.
Many factors outside of the experiment's control, like interrupts, scheduling policies, etc., may result in outliers in performance measurements.
We now explain our procedure for eliminating outliers, before demonstrating that the elimination of these outliers does not bias the conclusions.We use Tukey's method [34] To demonstrate that our outlier elimination process does not bias conclusions, we compare the distribution of outliers between (a) 100 million operations using randomly-generated operands, and (b) 100 million operations using one fixed operand.
The two experiments do not differ in any way other than the difference in their input operands.
Table 3 shows the mean, median, and standard deviation of outliers for the double-precision square-root operation.
Results for other floating-point operations are similar and are elided for space reasons.
Since the difference in mean values as well as the difference in median values is within a quarter of the standard deviation from the mean, we conclude that the discarded outlier count is statistically independent of the input operand values.
Since exhaustively testing all possible inputs for each operation is infeasible, we instead take the following threestep approach for demonstrating the timing channel defense for Escort's elementary operations: (1) We characterize the performance of Escort's elementary operations using a specific, fixed floating-point value (e.g. 1.0), (2) using one value from each of the six different types of values (zero, normal, subnormal, +∞, -∞, and nota-number), we show that our solution exhibits negligible variance in running time, and (3) to demonstrate that each of the six values in the previous experiment is representative of the class to which it belongs, we generate 10 million normal, subnormal, and not-a-number (NaN) values, and show that the variance in running time among each set of 10 million values is negligible.
Our key findings are that Escort's operations run in fixed time, are fast, and that their performance is closely tied to the performance of the hardware's subnormal operations.Figure 10: Comparison of running times of elementary operations.
sp identifies Escort's single-precision operations, dp identifies Escort's double-precision operations, and fix identifies FTFP's fixed-point operations.
Numbers at the top of the bars show the total cycle count.
We see that Escort's execution times are dominated by the cost of subnormal operations, and we see that FTFP's overheads are significantly greater than Escort's.
Figure 10 compares the running times of elementary operations of Escort and of previous solutions (FTFP).
First, we observe that the running times of Escort's single-and double-precision operations are an order-ofmagnitude lower than those of FTFP's fixed-precision operations.
Second, Escort's running time is almost entirely dominated by the processor's operation on subnormal numbers.
Third, conversion between fixed-point and floating-point takes a non-trivial amount of time, further increasing the overhead of FTFP's operations.
Overall, Escort elementary operations are about 16× faster than FTFP's.
Table 4 shows the variation in running time of elementary operations across six different types of inputs (zero, normal value, subnormal value, +∞, −∞, and nota-number value) and compares it with the variation of SSE (native) operations.
While SSE operations exhibit high variation (the maximum observed standard deviation is 176% of the mean), Escort's operations show negligible variation across different input types.Finally, we measure Escort's running time for 10 million random normal, subnormal, and not-a-number values.
We observe that the standard deviation of these measurements, shown in Table 5, is extremely low (at most Escort Native (SSE) add-sp 0 0 add-dp 0 0 sub-sp 0 0 sub-dp 0 0 mul-sp 0 49.2 (175%) mul-dp 0 49.2 (175%) div-sp 0.66 (0.4%) 65.67 (163%) div-dp 1.66 (0.8%) 69.08 (164%) sqrt-sp 1.49 (0.8%) 62.7 (170%) sqrt-dp 2.98 (1.5%) 66.87 (169%) upcast 0 40.99 (178%) Numbers in parenthesis show the standard deviation as a percentage of the mean.
The -sp suffix identifies single-precision operations while the -dp suffix identifies double-precision operations.
Compared to SSE operations, Escort exhibits negligible variation in running times.3.1% of the mean).
We thus conclude that our chosen values for each of the six classes faithfully represent their class.
Using different types of floating-point values (zero, normal, subnormal, +∞, −∞, and not-a-number), Figure 11 compares the performance of most of the commonly usedFn.
NaN Normal Subnormal add-sp 0.21 (3.1%) 0.21 (2.9%) 0.19 (2.7%) add-dp 0.21 (3.0%) 0.20 (2.9%) 0.21 (3.0%) sub-sp 0.18 (2.6%) 0.19 (2.7%) 0.20 (2.9%) sub-dp 0.19 (2.7%) 0.19 (2.7%) 0.19 (2.7%) mul-sp 0.98 (0.7%) 0.94 (0.7%) 1.05 (0.7%) mul-dp 0.90 (0.6%) 1.04 (0.7%) 1.02 (0.7%) div-sp 1.22 (0.6%) 1.27 (0.7%) 1.23 (0.6%) div-dp 1.39 (0.7%) 1.37 (0.6%) 1.17 (0.6%) sqrt-sp 1.15 (0.6%) 1.13 (0.6%) 1.14 (0.6%) sqrt-dp 1.29 (0.7%) 1.41 (0.7%) 1.33 (0.7%) upcast 1.03 (0.9%) 0.89 (0.8%) 0.95 (0.8%) Table 5: Standard deviation of 10 million measurements for each type of value (normal, subnormal, and not-anumber).
All standard deviation values are within 3.1% of the mean.
Furthermore, the mean of these 10,000,000 measurements is always within 2.7% of the representative measurement.single-and double-precision higher-level operations 6 .
Overall Escort's higher-level operations are about 2× slower than their corresponding FTFP operation, which is the price for closing side channels that FTFP does not close.
ceil floor floorf ceilf logf log2f log10f exp2f log expf log2 log10 exp exp2 powf pow tan exp10f cos sin tanf cosf sinf exp10 MEAN Processor Cycles baseline (non-secure) execution control flow obfuscation data access obfuscation subnormal operands Figure 12: Performance breakdown of Escort's commonly used higher-level functions.
The baseline (nonsecure) execution and exception handling together cost less than 250 cycles for each function, making them too small to be clearly visible in the above plot.
Figure 12 shows the breakdown of the performance of commonly used higher-level functions.
We observe that the performance of most higher-level functions is dominated by the latency of operations on subnormal operands, which is closely tied to the performance of the underlying hardware.
A handful of routines (exp10(), exp10f(), exp2(), and exp2f()) use lookup tables that are susceptible to address-trace-based side-channel information leaks, so the code transformed by Escort sweeps over these lookup tables for each access to the table.
Finally, we see that the cost of control flow obfuscation (i.e. the cost of executing all instructions in the program) contributes the least to the total overhead.
We now evaluate Escort's defense against the timing channel attack by Andrysco et al. [3] on the Firefox web browser.
The attack reconstructs a two-color image inside a victim web page using only the timing side channel in floating-point operations.
The attack convolves the given secret image with a matrix of subnormal values.
The convolution step for each pixel is timed using high resolution Javascript timers.
By comparing the measured time to a threshold, each pixel is classified as either black or white, effectively reconstructing the secret image.We integrate Escort into Firefox's convolution code 7 and re-run the timing attack.
The results (see Figure 13c) show that Escort successfully disables the timing attack.
We now show that Escort's operations do not leak information through control flow or data flow.
We first use inference rules over the LLVM IR to demonstrate noninterference between secret inputs and digital side channels.
We run a machine-learning attack on Escort and demonstrate that Escort successfully disables the attack.
Since Escort's elementary operations are small and simple-they are implemented using fewer than 15 lines of assembly code, they do not access memory, and they do not contain branch instructions-they are easily verified for non-interference between secret inputs and digital side channels.
Using an LLVM pass that applies the inference rules from Table 6, tracking labels that can be either L (for low-context i.e. public information) or H (for high-context i.e. private information), we verify that Escort's higher-level operations close digital side channels.
This compiler pass initializes all function arguments with the label H, since arguments represent secret inputs.Inference rules for various instructions dictate updates to the labels.
The environment Γ tracks the label of each pointer and each address.
The Escort compiler tags load and store instructions as secret if the pointer is tainted, or public otherwise.
Unlike a public load or store instruction, a secret load or store instruction is allowed to use a tainted pointer since Escort generates corresponding loads and stores to all statically-determined candidate values in the points-to set.
The sanitization rule resets the value's label to L and is required to suppress false alarms from Escort's loop condition transformation.
Escort's transformed code includes instructions with special LLVM metadata that trigger the sanitization rule.
During verification, the compiler pass iterates over each instruction and checks whether a rule is applicable using the rule's antecedents (the statement above the horizontal line); if so, it updates its local state as per the rule's consequent (the statement below the horizontal line).
If no applicable rule is found, then the compiler pass throws an error.
The compiler pass processes the code for Escort's 112 higher-level operations without throwing errors.
We use the TensorFlow [1] library to design a machinelearning classifier, which we use to launch a side-channel attack on the execution of the expf() function, where the input to the expf() function is assumed to be secret.
Using three distinct inputs, we run this attack on the implementations in the (non-secure) Musl C library and in the (secure) Escort library.
We first use the Pin dynamic binary instrumentation tool [19] to gather the full instruction address traces of both expf() implementations 8 .
We train the TensorFlow machine-learning classifier by feeding the instruction address traces to the classifier, associating each trace with the secret input to expf().
We use cross entropy as the cost function for TensorFlow's training phase.
In the subsequent testing phase, we randomly select one of the collected address traces and ask the classifier to predict the secret input value.We find that for the Musl implementation, the classifier is accurately able to predict the correct secret value from the address trace.
On the other hand, for the Escort implementation, the classifier's accuracy drops to 33%, which is no better than randomly guessing one of the three secret input values.
We examine the precision of Escort and FTFP by comparing Escort's and FTFP's results with those produced by a standard C library.
Methodology.
We adopt an empirical approach to estimate precision in terms of Unit of Least Precision (ULP), since formal derivation of maximum ULP difference requires an intricate understanding of theorem provers and floating-point algorithms.
We run various floating-point operations on 10,000 randomly generated pairs (using drand48()) of floating-point numbers between zero and one.
For elementary operations, we compare the outputs of Escort and FTFP with the outputs of native x86 instructions.
For all other operations, we compare the outputs of Escort and FTFP with the outputs produced by corresponding function from the Musl C library.Results.
We observe that Escort's results are identical to the results produced by the reference implementations, i.e. the native (x86) instructions and the Musl C library.
More precisely, the ULP difference between Escort's results and reference implementation's results is zero.
On the other hand, FTFP, which computes arithmetic in fixed-point precision, produces output that differs substantially from the output of Musl's doubleprecision functions (see Table 7).
The IEEE 754 standard requires that addition, subtraction, multiplication, division, and square root operations are computed with ULP difference of at most 0.5.
Well-known libraries compute results for most higher-level operations within 1 ULP.T-PUBLIC-LOAD Γ(ptr) = L P = ptset(ptr) m = max addr∈P Γ(addr) Γ 񮽙 = Γ[val 񮽙 → m] Γ 񮽙 val := public-load ptr : Γ 񮽙 T-PUBLIC-STORE Γ(ptr) = L ∀ addr ∈ ptset(p) m = max(Γ(val), Γ(addr)) Γ 񮽙 = Γ[addr 񮽙 → m] Γ 񮽙 public-store ptr, val : Γ 񮽙 T-SECRET-LOAD Γ 񮽙 = Γ[val 񮽙 → H] Γ 񮽙 val := secret-load ptr : Γ 񮽙 T-SECRET-STORE ∀ addr ∈ ptset(p) Γ 񮽙 = Γ[addr 񮽙 → H] Γ 񮽙 secret-store ptr, val : Γ 񮽙 T-BRANCH Γ(cond) = L Γ 񮽙 br cond,block1,block2 : Γ T-OTHER Γ 񮽙 = Γ[x 񮽙 → Γ(y)] Γ 񮽙 x:=y : Γ 񮽙 T-COMPOSITION Γ 񮽙 S 1 : Γ 񮽙 , Γ 񮽙 񮽙 S 2 : Γ 񮽙񮽙 Γ 񮽙 S 1 ; S 2 : Γ 񮽙񮽙 T-SANITIZER Γ 񮽙 = Γ[x 񮽙 → L]Γ 񮽙 S(x) : Γ 񮽙 lyze all 321 differences between MINPACK-FTFP and MINPACK-C by classifying them into the following five categories: (1) smaller than 10 −5 , (2) between 10 −5 and 10 −3 , (3) between 10 −3 and 10 0 , (4) between 10 0 and 10 3 , and (5) larger than 10 3 .
As seen in Table 8, almost half of the differences (49%) are extremely small (less than 10 −5 ), possibly arising from relatively small differences between fixed-point and floating-point calculations.
However, we hypothesize that differences amplify from propagation, since nearly 42% of the differences are larger than 10 −3 .
We now evaluate the end-to-end application performance impact of Escort's floating-point library and Escort's control flow obfuscation.
Table 9: Overhead of SPEC-ESCORT (SPECfp2006 using Escort operations) relative to SPEC-LIBC (SPECfp2006 using libc).
This section evaluates the performance impact of Escort on the SPEC floating point benchmarks, as well as on a security-sensitive program SVM light , a machine-learning classifier.Evaluation Using SPEC Benchmarks.
We use the C and C++ floating-point applications in the SPEC CPU 2006 benchmark suite with reference inputs.
We generate two versions of each program-the first version (SPEC-LIBC) uses the standard C library functions, and the second version (SPEC-ESCORT) uses functions from the Escort library 10 .
We compile the SPEC-LIBC program using the Clang/LLVM 3.8 compiler with the -O3 flag, and we disable auto-vectorization while compiling the SPEC-ESCORT program.
The following results demonstrate the worst case performance overhead of Escort for these programs, since we transform all floatingpoint operations in SPEC-ESCORT to use the Escort library.
More precisely, we do not reduce the number of transformations either using taint tracking or using SMT solvers.
Table 9 shows that Escort's overhead is substantial, with a geometric mean of 32.6×.
We expect a lower average overhead for applications that use secret data, since taint tracking would reduce the number of floating-point operations that would need to be transformed.
11 .
We mark the training data and the classification data as secret.
Before replacing floating-point computations, Escort's taint analysis discovers all floating-point computations that depend on the secret data, thus reducing the list of replacements.
We also instruct Escort to query the Z3 SMT solver to determine whether candidate floating-point computations could use subnormal operands.
Escort then replaces these computations with secure operations from its library.
We compile the baseline (non-secure) program using the Clang/LLVM 3.8 compiler with the -O3 flag, and we disable autovectorization while compiling SVM light with Escort.
We measure the total execution time using the RDTSC instruction.
Table 10 shows that Escort's overhead on SVM light .
We observe that Escort's overhead on SVM light is substantially lower than that on SPEC benchmarks.
Using the md5sum program, we verify that the output files before and after transformation of SVM light are identical.
To compare the performance impact of Escort's control flow obfuscation technique with that of Raccoon, we use the same benchmarks that were used to evaluate Raccoon [28], while compiling the baseline (nontransformed) application with the -O3 optimization flag.
Although both Escort and Raccoon obfuscate control flow and data accesses, we compare the cost of control flow obfuscation only, since both Escort and Raccoon obfuscate data accesses using the identical technique.
Ta- ble 11 shows the results.
We find that programs compiled with Escort have a significantly lower overhead than those compiled with Raccoon.
Escort's geometric mean overhead is 32%, while that of Raccoon is 5.32×.
The worst-case overhead for Escort is 2.4× (for ip-tree).
The main reason for the vast difference in overhead is that Raccoon obfuscates branch instructions at execution time, which requires the copying and restoring of the stack for each branch instruction.
Since the stack can be arbitrarily large, such copying and restoring adds substantial overhead to the running time of the program.
On the other hand, Escort's code rewriting technique obfuscates code at compile time using basic block predicates, which enables significant performance boosts on the above benchmarks.
In this paper, we have presented Escort, a compiler-based tool that closes side channels that stem from floatingpoint operations.
Escort prevents an attacker from inferring secret floating-point operands through the timing channel, though micro-architectural state, and also through off-chip digital side channels, such as memory address trace.
Escort uses native SSE instructions to provide speed and precision.
Escort's compiler-based approach enables it to support a significantly larger number of floatingpoint operations (112) than FTFP (19).
Escort's design motivates further research into hardware support for side-channel resistant systems.
For example, by allowing software to control the timing of integer instruction latencies and their pipelined execution, Escort's guarantees could be extended to instructions beyond floating-point instructions.
