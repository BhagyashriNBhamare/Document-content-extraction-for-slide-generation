With public cloud providers poised to become indispensable utility providers, neutrality-related mandates will likely emerge to ensure a level playing field among their customers ("tenants").
We analogize with net neutrality to discuss: (i) what form cloud neutrality might take, (ii) what lessons might the net neutrality debate have to offer, and (iii) in what ways cloud neutrality would be different from (and even more difficult than) net neutrality.
We use idealized thought experiments and simple workload case studies to illustrate our points and conclude with a discussion of challenges and future directions.
Our paper points to a rich and important area for future work.
A natural but relatively little addressed set of concerns in the emerging public cloud utility comes to the fore when one compares its likely evolution with that of Internet Service Providers (ISPs).
During the period of commercialization of the Internet in the 1990s (after the creation of the WWW), the principle of over-engineering reigned and cheap access plans without quotas were commonplace.
In the 2000s, the Internet access marketplace matured, ISPs consolidated, and it became apparent that the Internet was (i) prone to congestion by activity that generated little revenue 1 , and (ii) created a platform for stiff competition for the ISPs' own profitable "managed" video and voice services.The network neutrality debate began when Comcast throttled BitTorrent activity that was congesting its (broadcast-based CMTS) residential broadband service.
Though this violation of application neutrality targeted activity that was largely piracy of copyrighted material, third-party content and service providers viewed it as a dangerous precedent considering that ISPs are * This research supported in part by NSF CNS grants 1228717 and 1526133 and by NSF CAREER grant 0953541.
1 In the case of illegal file-sharing, negative revenue from the point of view of copyright holders.
themselves competing providers of content (particularly video) and services (e.g., telephony).
In 2014, Neflix negotiated payment for "fastlanes" to reach Comcast's subscribers [32], but this would have basically been a side payment (albeit willing), thus violating origin neutrality.
The debate continues: a federal court limited certain of the FCC's neutrality rules in 2014 [31] and the FCC deemed the Internet a utility in 2015 [25] in a move to consolidate neutrality rules.Somewhat similarly, the public cloud market was also plentiful initially compared to demand.
As the business has grown over the last decade, competition has intensified with an increased diversification in the types of offered service-level agreements (SLAs) and associated price-performance trade-offs [4,30,8,19,13].
It is reasonable to anticipate that issues of fair competition similar to those for ISPs may be on the horizon.
As an illustrative example, consider how Amazon Prime's video service and Netflix both use Amazon EC2.What might neutrality mean in this setting?
Do lessons and challenges from net neutrality suffice or does the public cloud raise novel issues?
We believe the answer is that it does and this is the context of our paper.
Contributions and Outline: In Section 2.1, we identify several ideas and lessons from the net neutrality debate that offer useful starting points for discussing cloud neutrality.
A public cloud is, however, a significantly different resource provider than an ISP.
In fact, it is significantly more complicated in some ways, presenting novel concerns that we discuss in Section 2.2.
Following this, in Section 3, we take preliminary steps towards exploring these issues using simple thought experiments and empirical case studies.
Finally, we conclude in Section 5.
Discussion on public cloud neutrality is relatively scant or preliminary [24].
Interxion, a European provider defines a carrier-and cloud-neutral "colo" data center as follows: "A truly neutral data centre provider is one that is independent of the companies colocating in the data centre, does not compete with them in any way, and offers no packaged services as part of colocation.
Customers are free to contract directly with the providers of their choice" [1].
Our interest herein is with public cloud providers that offer more general services than colos (IaaS clouds offering virtualized IT resources or PaaS/SaaS clouds offering even more abstract services), for which the neutrality discussion is much more complex and unclear.
The following insights and guiding principles from the net neutrality debate offer good starting points for our discussion of cloud neutrality.Resource congestion: If a utility provider can offer adequate resources to satisfy its customers -especially when it is in its initial growing phase e.g. ISPs in the 90s or public clouds till very recently -the neutrality concern is moot.
Resource congestion, whether actual or alleged, is the basic context of any neutrality debate.Neutrality modulo SLAs: Neutrality does not mean that every tenant is treated equally.
The fair/equal treatment across tenants may only relate to tenants that have chosen identical SLAs.
Therefore, it only ever makes sense to discuss neutrality in the context of specific SLAs.
In other words, a key aspect of a provider's resource allocation when assessing its neutrality is how it allocates any discretionary resources (i.e., resources left over after it has met its SLA obligations) among tenants in the same SLA class.
This view will play an important point in our case studies in Section 4.
Information limits and preferences: The providers behavior must not be based on "inside information" or "preferences."
E.g., Mogul et al. [22] consider a network bandwidth allocation problem wherein a cloud provider reckons tenant sensitivity to network bandwidth underprovisioning and uses this to allocate bandwidth differentially to improve its profits.
One may consider such a cloud provider non-neutral.
Fair competition: Fair competition needs to be upheld between affiliates of the cloud provider and its tenantswhether direct (e.g. recall from Section 1 how Amazon Prime and Neftlix both use Amazon EC2) or indirect.
That is, neutrality is related to antitrust.
Whereas ideas discussed above are useful in framing our cloud neutrality discussion, we believe that there are aspects of cloud operation that make for a more complicated situation than net neutrality.
We find two key sources of difficulty:Lack of an effective common "currency": Unlike network bandwidth, the basis of SLAs in the case of net neutrality, it is difficult to identify a single (virtual) resource/currency that can act as an effective proxy for the multiple physical resources that must be allocated for colocated tenants.
Different workloads need different resources and even within a workload this could change over time.
It is not clear how neutrality should be defined in such a multi-resource setting.
Existing literature on multi-resource fair scheduling offers one appealing option and we explore this in Section 3.
Difficulty of auditing resource usage: An important requirement for implementing a neutral utility is the ability to audit resource allocations/usage for verifying adherence to neutral behavior.
Whereas network bandwidth allocated by an ISP can be effectively monitored and audited [16,17], the same does not hold for many virtualized resources offered by a public cloud.
As identified by others [23,29,2,3], auditing virtualized resources is inherently difficult.
Existing solutions for measuring/auditing virtualized IT resource usage (e.g., resource containers [6]) implicitly assume trusted resource managers.
A hypervisor may over-commit CPUs to multiple VMs, which makes it difficult to detect/quantify each VM's shares of CPU capacity (CPU cycles) from within the guest OS.
As an extreme example, a hypervisor may "dilate" a VM's notion of time by slowing its delivery of virtualized timer interrupts [15].
Netflix relies upon the "stolen time" (a measure of competition for CPU) reported by the hypervisor underlying its Amazon EC2 instances for identifying incidents wherein its procured instances are not getting adequate CPU capacity [20].
What if the hypervisor (either deliberately or due to a bug) misreported this metric?
Similar difficulties apply to other resources such as memory and IO bandwidth.
Implementing cloud neutrality would require effective solutions to this auditing problem.Our discussion in the rest of the paper assumes the existence of such solutions.
The notion of fair scheduling is a natural starting point for formalizing neutral resource management.
Given the information limits inherent in neutrality as well as the general difficulty of application performance modeling by a cloud provider (even by the tenant, i.e., the application owner), we believe that SLAs in a neutral cloud would have to be in terms of effective resource capacities not in terms of application-specific performance metrics (e.g., [18,26] for the latter).
In multi-resource environments, a generalization of max-min fairness, Dominant Resource Fairness (DRF), can determine resource allocations to a user based on its maximum weighted share among its received resources.
DRF maximizes the minimum dominant share of all users and has several desirable properties, e.g., sharing incentive, strategy proofness, Pareto efficiency [12].
There are other fair allo-cation policies for multiple resources, e.g., Competitive Equilibrium from Equal Incomes (CEEI), that possess some of these desirably properties.
In the following, we assume an SLA class is characterized by a deterministic guaranteed element in combination with a statistical (possibly best effort) element.
Our SLA class definition is fairly general and expressive.
E.g., on-demand instances offered by Amazon EC2 or Google Compute Engine amount to SLAs with guaranteed resource capacities (the advertised capacities) whereas EC2's burstable or spot instances or Google's preemptible instances can be thought of as having different degrees of guaranteed plus best-effort resource capacities [5,7,14].
When costs are low, tenant demand will exceed available resources.
We assume that the tenants will contend for guaranteed (on-demand) resources, as stipulated in their SLAs, and the cloud will arbitrate.
For all tenants i, consider linear models of their net-benefit/utility functions based on workload intensity x, as set by the cloud, leading to assumed positive linear tenant net-utilities as follows:u i (x i ) := x i (V i − ∑ k d i,k ˜ P k ),where: V i is the benefit per unit workload, ˜ P k is the cost per unit resource of type k (e.g., ˜ P k = 1/R k for kind of asset fairness [12] where R k is the amount of type-k resource available), and d i,k is the type-k resource demand per unit workload.
Consider tenants i with linear net-utilities,∀i, ∂ i u i = V i − ∑ k d i,k ˜ P k > 0.
The resulting game will result in a set of Nash equilibria 2 on the feasibility boundary where at least one resource is exhausted by tenants 3 .
As in Nash bargaining problems, there is a choice of boundary equilibria.
A leader of the game (operator/provider of the cloud itself, or a government/market regulator) may desire equilibrium points that, e.g., maximize: cloud revenue, Ω := ∑ i x i ∑ k d i,k ˜ P k ; social welfare, Ω := ∑ i u i (x); or total tenants' benefit, Ω := ∑ i V i x i .
To such ends, resources may be shifted among tenants to control their Nash equilibrium, i.e., the cloud takes direct resource allocation actions at or near the feasibility region (as in the CEEI mechanism [12]).
Note that the three previous example objectives are planar.
They result in Nash play-actions x with maximal Ω corresponding to corner points or line segments of the feasibility region, 2 A Nash equilibrium x * = {x * i } is a stalemate from which no single tenant i can improve their utility u i by changing their workload to x i = x * i , i.e., any unilateral defection from a Nash equilibrium will not profit the defector.3 At the convex feasibility boundary with at least one resource exhausted, the only feasible unilateral move by any player i is to reduce demand (x i ), hence utility u i = x i ∂ i u i is reduced if, as assumed, marginal utility ∂ u j > 0 for all tenants j. recall the simplex algorithm [27].
Also note that a forprofit cloud with congested (low priced) resources would naturally choose to maximize revenue.Alternatively, resources x can be (maximally) allocated subject to rules of "fairness" [9].
For example, equal dominant resource share, x i max k d i,k /R k (leading to DRF) [12]; equal total asset-fraction share, x i ∑ k d i,k /R k (leading to a kind of asset fairness); or equal per unit net utility, x i /(V i − ∑ k d i,k ˜ P k ).
Note that notions of fairness may not separately consider the interests of the cloud and tenants particularly in a public, for-profit cloud setting with potentially competing tenants (possibly serving their own customers).
Also, tenants can be differently weighted (as considered in e.g., Sec. 4.3 of [12]); such weights could correspond to priority in a private cloud or enterprise network, or willingness to pay in a public cloud system.See Figure 1 for an illustrative example indicating DRF and maximum cloud revenue with: total resource pool R = (9 CPUs, 6GB RAM) and tenant demand vectors d 1 = (1, 2), d 2 = (3, 1).
For DRF, the dominant resource shares x i max k d i,k /R k of the two tenants i ∈ {1, 2} are equated -in this case, x 1 2/6 = x 2 3/9, i.e., Here, the DRF point is arguably a more "neutral" way (than maximum cloud revenue) to treat this congested scenario of tenants consuming resources with resource proportions stipulated in their SLAs.x 1 = x 2 .
But with˜Pwith˜ with˜P k ≡ 1/R k , Ω = ( 2 6 + 1 9 )x 1 + ( 1 6 + 3 9 )x 2 .
Now suppose that the tenants opt for cheaper SLAs involving only statistical resource guarantees.
In particular, this means that the cloud may exploit unused resources nominally assigned to one tenant for the benefit of other tenants, including to overbook resources to take advantage of statistical multiplexing.
Moreover, the cloud may have discretionary (unreserved) resources that it may assign to tenants.
Again, the assumption is that actual tenant demand will exhaust resources.
Now let m i,k = Ed i,k and σ 2 i,i,k = var(d i,k ) respectively be the mean and variance of the demand per unit workload d i,k for the k th resource by the i th tenant.
Also, let σ 2 i, j,k be the covariance of demand per unit workload by tenant i and tenant j for resource k and define the co-variance matrix C k = [σ 2 i, j,k ].
In practice, these quantities would be empirically estimated online.
We can extend our model of resource allocation by using nonlinear "chance constraints" for each resource k, leading to a convex feasibility region 4 ,x m k + n k x C k x ≤ R k < R k ,(1)where n k ≥ 1 is a confidence factor for the headroom R k − R k (e.g., [10]) corresponding to P(∑ j x j d j,k ≥ R k ) ≤ ε k , and for all k, x k ≥ 0 of course.
Run-time estimates of mean, variance and covariance of demand and dynamic calibration of resource headroom can be jointly used to deal with uncertain, time-varying demand needs, particularly when infeasible overages in demand must be rare (ε k 1).
Headroom will be important in the presence of estimation error in these statistical parameters of demand.If we take (conservatively with n k = 2) deterministicd i,k := m i,k + n k σ i,i,k(2)(quantities that could be involved in tenant i's SLA with the cloud), we can then define statistical multiplexing gain for resource k at demand x asn k ∑ i x i σ i,i,k − x C k x ≥ 0,i.e., capturing the difference between "deterministic" provisioning by the cloud using (2) and that using (1).
See Figure 2 for an example uncorrelated case with n k ≡ 2 and σ i,i,k ≡ 0.5.
For resource k = 1 with capacity 8, d 1,1 = 2 + 2 · 0.5 = 3 and d 2,1 = 1 + 2 · 0.5 = 2.
Similarly, d 1,2 = 2 and d 2,2 = 3 for the resource k = 2 with capacity 11.
The corresponding feasibility region, with piecewise linear boundary x 2 = min{(8 − 3x 1 )/2, (11 − 2x 1 )/3}, is contained in that given by the chance constraints, with shown strictly concave boundary meeting the piecewise linear boundary at the axes.In practice, it can be reckoned at run-time (online) whether different workloads are negatively correlated, or whether statistical multiplexing gains can be achieved by scaling a given workload [21,28].
A basic assumption here is that workloads are sufficiently stationary so that present estimates of correlation are valid in the near future.
Moreover, correlations need to be assessed jointly among the plurality IT resources used by the workloads in question.
Note that a cloud assesses and exploits workload correlations to overbook under resourceoriented, not performance-oriented, SLAs.
We consider two memcached tenants whose CPU and memory needs we manipulate to illustrate neutrality issues under different representative cloud resource management options.
Each tenant runs Memcached, an in-memory key-value data store, with workload generated by YCSB [11] in time-varying fashion according to i.i.d. Gaussian processes with identical mean but the variation of tenant 2 is double that of tenant 1.
The tenants have the same SLAs corresponding to one guaranteed core, and the cloud has a discretionary third core that it can share between the two tenants.
Empirically, we found that a single core can achieve throughput of 75k ops/s with satisfactory mean response times of 400us.
Figure 3 shows the CDF of the throughputs of the two tenants conditioned on each of them being greater than 75k ops/s, i.e., emulating a case where the third discretionary core is active when both tenants have exhausted their respective dedicated cores.
The cloud may employ a weighted reservation (Resv) based approach or a work-conserving, proportional-share (CFS) scheduling for the discretionary third core.
The Resv1:1 (equally weighted) and CFS1:1 schemes are arguably neutral as they are based only on parameters in the tenant SLAs, i.e., the same mean demands in this example corresponding to a single core; while CFS 3:7 is based on measured (conditional) demand-variation of the two tenants which is not part of their SLAs and so this scheme is arguably not neutral.
If the intention is to prevent tenant 2 (the one with more demand variation) from defecting to other cloud-services providers, the cloud may tend to adopt CFS1:1.
On the other hand, the cloud may want to entice tenant 2 to renegotiate a more costly SLA by adopting Resv1:1.
The premise here is that with greater demand variability, tenant 2 will outcompete tenant 1 for the discretionary CPU core; but this may not be entirely the case when the tenant demands are positively correlated, i.e., how workload is consolidated by the cloud will impact such "iso-neutral" decisionmaking.
In Tables 1,2, the more demand-variable tenant 2 has best latency performance (both in mean and 95 percentile) under non-neutral CFS 3:7.
Note that there is improved 95-percentile latency performance for tenant 2 under CFS1:1 over Resv1:1 but not for mean latency -this is attributable to simulated positive correlation in tenant demand for the results of Table 1.
For the uncorrelated case, tenant 2 has incremental decrease in its latency from Resv1:1 to CFS3:7, both in mean and 95-percentile.
To illustrate neutrality concerns using memory as the resource, we create identical maximum memory needs for our two Memcached tenants.
Tenant 1 has exponential key popularity distribution: 95% requests go to 5% of working set; tenant 2 has Zipfian key popularity distribution.
We assume that they both pick an SLA wherein 3 GB RAM capacity is guaranteed (50% of the working set) and they both stipulate their maximum needs of 6 GB.
However, tenant 1 has a much smaller set of popular data ("hot" data) than tenant 2, making it far less sensitive to memory underprovisioning by the cloud (as shown in Figure 4).
We compare tenant performance under two different memory allocation strategies the cloud may employ in Table 3: Under neutral underprovisioning, the cloud provider may not exploit its understanding of these different sensitivities to differentially allocate memory to the tenants whereas in a non-neutral scenario, it may underprovision tenant 1 far more aggressively (without any perceived performance difference by tenant 1) to reduce its own operational costs.
We identified novel challenges that would arise in a future neutral public cloud.
We identified four lessons from the net neutrality debate that offer a good starting point for discussion about cloud neutrality.
We then identified two particular aspects of cloud neutrality that would require novel thought and debate.
Using simple thought experiments, we considered whether notions of multi-resource fairness such as DRF are useful ways of defining cloud neutrality.
Finally, we created simple case studies with different types of resource management and discussed how these mapped to our notions of neutrality and the implications on the provider's profitability and the tenant's costs.
