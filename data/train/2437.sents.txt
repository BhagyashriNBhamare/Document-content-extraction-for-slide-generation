With increase in scale, the number of node failures in a data center increases sharply.
To ensure availability of data, failure-tolerance schemes such as Reed-Solomon (RS) or more generally, Maximum Distance Separable (MDS) erasure codes are used.
However, while MDS codes offer minimum storage overhead for a given amount of failure tolerance, they do not meet other practical needs of today's data centers.
Although modern codes such as Minimum Storage Regenerating (MSR) codes are designed to meet these practical needs, they are available only in highly-constrained theoretical constructions, that are not sufficiently mature enough for practical implementation.
We present Clay codes that extract the best from both worlds.
Clay (short for Coupled-Layer) codes are MSR codes that offer a simplified construction for decoding/repair by using pairwise coupling across multiple stacked layers of any single MDS code.
In addition, Clay codes provide the first practical implementation of an MSR code that offers (a) low storage overhead, (b) simultaneous optimality in terms of three key parameters: repair bandwidth, sub-packetization level and disk I/O, (c) uniform repair performance of data and parity nodes and (d) support for both single and multiple-node repairs, while permitting faster and more efficient repair.
While all MSR codes are vector codes, none of the distributed storage systems support vector codes.
We have modified Ceph to support any vector code, and our contribution is now a part of Ceph's master codebase.
We have implemented Clay codes, and integrated it as a plu-gin to Ceph.
Six example Clay codes were evaluated on a cluster of Amazon EC2 instances and code parameters were carefully chosen to match known erasure-code deployments in practice.
A particular example code, with storage overhead 1.25x, is shown to reduce repair network traffic by a factor of 2.9 in comparison with RS codes and similar reductions are obtained for both repair time and disk read.
The number of failures in storage subsystems increase as data centers scale [11] [17] [29].
In order to ensure data availability and durability, failure-tolerant solutions such as replication and erasure codes are used.
It is important for these solutions to be highly efficient so that they incur low cost in terms of their utilization of storage, computing and network resources.
This additional cost is considered an overhead, as the redundancy introduced for failure tolerance does not aid the performance of the application utilizing the data.In order to be failure tolerant, data centers have increasingly started to adopt erasure codes in place of replication.
A class of erasure codes known as maximum distance separable (MDS) codes offer the same level of failure tolerance as replication codes with minimal storage overhead.
For example, Facebook [19] reported reduced storage overhead of 1.4x by using Reed-Solomon (RS) codes, a popular class of MDS codes, as opposed to the storage overhead of 3x incurred in triple replication [13].
The disadvantage of the traditional MDS codes is their high repair cost.
In case of replication, when a node or storage subsystem fails, an exact copy of the lost data can be copied from surviving nodes.
However, in case of erasure codes, dependent data that is more voluminous in comparison with the lost data, is copied from surviving nodes and the lost data is then computed by a repair node, which results in a higher repair cost when compared to replication.
This leads to increased repair bandwidth and repair time.A class of erasure codes, termed as minimum storage regenerating (MSR) codes, offer all the advantages of MDS codes but require lesser repair bandwidth.
Until recently, MSR codes lacked several key desirable properties that are important for practical systems.
For example, they were computationally more complex [14], or demonstrated non-uniform repair characteristics for different types of node failures [18], or were able to recover from only a limited (one or two) number of failures [20], or they lacked constructions of common erasure code configurations [24], [20].
The first theoretical construction that offered all the desirable properties of an MSR code was presented by Ye and Barg [35].
This paper presents Clay codes that extend the theoretical construction presented in [35], with practical considerations.
Clay codes are constructed by placing any MDS code in multiple layers and performing pair-wise coupling across layers.
Such a construction offers efficient repair with optimal repair bandwidth, causing Clay codes to fall in the MSR arena.We implement Clay codes and make it available as open-source under LGPL.
We also integrate Clay codes as a plugin with Ceph, a distributed object storage system.
Ceph supports scalar erasure codes such as RS codes.
However, it does not support vector codes.
We modified Ceph to support any vector code, and our contribution is now included in Ceph's master codebase [4].
In erasure coding terminology, scalar codes require block-granular repair data, while vector codes can work at the sub-block granularity for repair.
In Ceph, the equivalent of an erasure-coded block is one chunk of object.
By this, we mean that Ceph supports chunkgranular repair data, while our contribution extended it to sub-chunk granularity.
To the best of our knowledge, after our contribution, Ceph has become the first distributed storage system to support vector codes.
Also, if Clay codes become part of Ceph's codebase, this will be the first-ever implementation of an MSR code that provides all desirable practical properties, and which is integrated to a distributed storage system.Our contributions include (a) the construction of Clay codes as explained in Section 3, (b) the modification made to Ceph in order to support any vector code, explained in Section 4, and (c) the integration of Clay codes as a plugin to Ceph, explained in Section 4.
We conducted experiments to compare the performance of Clay codes with RS codes available in Ceph and the results are presented in Section 5.
One of the example Clay codes that we evaluated, which has a storage overhead of 1.25x, was able to bring down the repair network traffic by a factor of 2.9 when compared with the RS code of same parameters.
Similar reductions were also obtained for disk read and repair time.
Erasure Code Erasure codes are an alternative to replication for ensuring failure tolerance in data storage.
In an [n, k] erasure-coded system, data pertaining to an object is first divided into k data chunks and then encoded to obtain m = n − k parity chunks.
When we do not wish to distinguish between a data or parity chunk, we will simply refer to the chunk as a coded chunk.
The collection of n coded chunks obtained after encoding are stored in n distinct nodes.
Here, by node, we mean an independent failure domain such as a disk or a storage node of a distributed storage system (DSS).
The storage efficiency of an erasure code is measured by storage overhead defined as the ratio of the number of coded chunks n to the number of data chunks k. Every erasure code has an underlying finite field over which computations are performed.
For the sake of simplicity, we assume here that the field is of size 2 8 and hence each element of the finite field can be represented by a byte 1 .
It is convenient to differentiate at this point, between scalar and vector codes.
Scalar Codes Let each data chunk be comprised of L bytes.
In the case of a scalar code, one byte from each of the k data chunks is picked and the k bytes are linearly combined in m different ways, to obtain m parity bytes.
The resultant set of n = k + m bytes so obtained is called a codeword.
This operation is repeated in parallel for all the L bytes in a data chunk to obtain L codewords.
This operation will also result in the creation of m parity chunks, each composed of L bytes (see Fig. 1).
As mentioned above, every coded chunk is stored on a different node.Data chunks Parity chunks Codeword Byte Figure 1: A pictorial representation of a scalar code.
The L = 6 horizontal layers are the codewords and the n = 6 vertical columns, the chunks, with the first k = 4 chunks corresponding to data chunks and the last (n − k) = 2 chunks, the parity chunks.
Each unit (tiny rectangle) in the figure corresponds to a single byte.
The difference in the case of vector codes is that here, one works with ordered collections of α ≥ 1 bytes at a time.
For convenience, we will refer to such an ordered collection of α bytes as a superbyte.
In the encoding process, a superbyte from each of the k data chunks is picked and the k superbytes are then linearly combined in m different ways, to obtain m parity superbytes.
The resultant set of n = k + m superbytes is called a (vector) codeword.
This operation is repeated in parallel for all the N = L α superbytes in a data chunk to obtain N codewords.
Figure 2 shows a simple example where each superbyte consists of just two bytes.The number α of bytes within a superbyte is termed the sub-packetization level of the code.
Scalar codes such as RS codes can be regarded as having subpacketization level α = 1.
Seen differently, one could view a vector code as replacing α scalar codewords with a single vector codeword.
The advantage of vector codes is that repair of a coded chunk in a failed node can potentially be accomplished by accessing only a subset of the α bytes within the superbyte, present in each of the remaining coded chunks, corresponding to the same codeword.
This reduces network traffic arising from node repair.Sub-chunking through Interleaving In Fig. 2, we have shown the α bytes associated to a superbyte as being stored contiguously.
When the sub-packetization level α is large, given that operations involving multiple codewords are carried out in parallel, it is advantageous, from an ease-of-memory-access viewpoint, to interleave the bytes so that the corresponding bytes across different codewords are stored contiguously as shown in Fig. 3.
This is particularly true, when the number N of superbytes within a chunk is large, for example, when L = 8KB and α = 2, contiguous access to N = 4K bytes is possible.
With interleaving, each data chunk is partitioned into α subsets, which we shall refer to as subchunks.
Thus each sub-chunk within a node, holds one byte from each of the N codewords stored in the node.
Figure 3: This figure shows the interleaving of the corresponding bytes within a superbyte across codewords, for the particularly simple case of two bytes within a superbyte.
This results in a partitioning of the data chunk into sub-chunks and can lead to improved-memory-access performance.
The sub-class of (n, k) erasure codes, either scalar or vector, having the property that they can recover from the failure of any (n − k) nodes are called MDS codes.
For a fixed k, these codes have the smallest storage overhead n k among any of the erasure codes that can recover from a failure of a fixed number of n − k nodes.
Examples include RS, Row-Diagonal Parity [9] and EVENODD [7] codes, see [5] for additional examples.
Facebook data centers [28] have employed an (14, 10) RS code in their data warehouse cluster.Node Repair The need for node repair in a distributed storage system can arise either because a particular hardware component has failed, is undergoing maintenance, is being rebooted or else, is simply busy serving other simultaneous requests for data.
A substantial amount of network traffic is generated on account of node-repair operations.
An example cited in [28], is one of a Facebook data-warehouse, that stores multiple petabytes of data, where the median amount of data transferred through top-of-rack switches for the purposes of node repair, is in excess of 0.2 petabytes per day.
The traffic arising from node-repair requests, eats into the bandwidth available to serve user requests for data.
The time taken for node repair also directly affects system availability.
Thus there is strong interest in coding schemes that minimize the amount of data transfer across the network, and the time taken to repair a failed node.
Under the conventional approach to repairing an RS code for instance, one would have to download k times the amount of data as is stored in a failed node to restore the failed node, which quite clearly, is inefficient.MSR Codes MSR codes [10] are a sub-class of vector MDS codes that have the smallest possible repair bandwidth.
To restore a failed node containing α bytes in an (n, k) MSR code, the code first contacts an arbitrarilychosen subset of d helper nodes, where d is a design parameter that can take on values ranging from k to (n − 1).
It then downloads β = α d−k+1 bytes from each helper node, and restores the failed node using the helper data.
The total amount dβ of bytes downloaded is typically much smaller than the total amount kα bytes of data stored in the k nodes.
Here α is the sub-packetization level of an MSR code.
The total number dβ of bytes downloaded for node repair, is called the repair bandwidth.
Let us define the normalized repair bandwidth to be the quantitydβ kα = d k(d−k+1) .
The normalization by kα can be motivated by viewing a single MSR codeword having sub-packetization level α as a replacement for α scalar RS codewords.
The download bandwidth under the conventional repair of α scalar RS codes equals kα bytes, corresponding to a normalized repair bandwidth of 1.
For the particular case d = (n − 1), the normalized value equals n−1 k(n−k) .
It follows that the larger the number (n − k) of parity chunks, the greater the reduction in repair traffic.
We will also use the parameter M = kα to denote the total number of databytes contained in an MSR codeword.
Thus an MSR code has associated parameter set given by {(n, k), d, (α, β ), M} with β = α d−k+1 and M = kα.Additional Desired Attributes: Over and above the low repair-bandwidth and low storage-overhead attributes of MSR codes, there are some additional properties that one would like a code to have.
These include (a) uniform- repair capability, i.e., the ability to repair data and parity nodes with the same low repair bandwidth, (b) minimal disk read, meaning that the amount of data read from disk for node repair in a helper node is the same as the amount of data transferred over the network from the helper node and (c) low value of sub-packetization parameter α, and (d) a small size of underlying finite field over which the code is constructed.
In MSR codes that possess the disk read optimal property, both network traffic and number of disk reads during node repair are simultaneously minimized and are the same.
The problem of efficient node repair has been studied for some time and several solutions have been proposed.
Locally repairable codes such as the Windows Azure Code [15] and Xorbas [28] trade the MDS property to allow efficient node-repair by accessing a smaller number of helper nodes.
The piggy-backed RS codes introduced in [26] achieve reductions in network traffic while retaining the MDS property but they do not achieve the savings that are possible with an MSR code.
Though there are multiple implementations of MSR codes, these are lacking in one or the other of the desired attributes (see Table 1).
In [8], the authors present 2-parity FMSR codes, that allow efficient repair, but reconstruct a function of the data that is not necessarily same as the failed node data.
This demands an additional decoding operation to be performed to retrieve original data.
In [24], the authors implement a modified productmatrix MSR construction [27].
Although the code displays optimal disk I/O performance, the storage overhead is on the higher side and of the form (2 − 1 k ).
In [20], the authors implement an MSR code known as the Butterfly code and experimentally validate the theoreticallyproven benefits of reduced data download for node repair.
However, the Butterfly code is limited to (n − k) = m = 2 and has large value of sub-packetization 2 k−1 .
The restriction to small values of parameter m limits the efficiency of repair, as the normalized repair bandwidth can be no smaller than 1 2 .
In [18], the authors propose a class of MDS array codes named as HashTag codes with α ≤ (n − k) k/n−k that permit flexibility in choice of α at the expense of repair bandwidth.
However, the code supports efficient repair only for systematic nodes, requires computations at helper nodes, and involves operations in a large finite-field.
The authors have presented an evaluation of HashTag codes in Hadoop.In a parallel line of work, many theoretical constructions of MSR codes are proposed in literature.
The product-matrix MSR codes proposed in [27] operate with very low sub-packetization and small finite-field size, however require a large storage overhead.
In a second notable construction known as zig-zag codes [30], the authors present the first theoretical construction of low-storage-overhead MSR codes for every n, k, when d = (n − 1).
The construction of zig-zag code is nonexplicit in the sense that the finite-field coefficients determining the parities have to be found by computer search.
Thus, despite the many theoretical constructions and a smaller number of practical implementations, the search for an MSR code having all of the desirable properties described above and its practical evaluation continued to remain elusive.
The recent theoretical results of Ye and Barg [35] have resulted in an altered situation.
In this work, the authors provide a construction that permits storage overhead as close to 1 as desired, sub-packetization level close to the minimum possible, finite field size no larger than n, optimal disk I/O, and all-node optimal repair.Clay codes offer a practical perspective and an implementation of the Ye-Barg theoretical construction, along with several additional attributes.
In other words, Clay codes possess all of the desirable properties mentioned above, and also offer several additional advantages compared to the Ye-Barg code.
The presentation of the Clay code here is from a coupledlayer perspective that leads directly to implementation, whereas the description in [35] is primarily in terms of parity-check matrices.
For example, using the coupledlayer viewpoint, both data decoding (by which we mean recovery from a maximum of (n − k) erasures) as well as node-repair algorithms can be described in terms of two simple operations: (a) decoding of the scalar MDS code, and (b) an elementary linear transformation between pairs of bytes (see Section 3).
While this coupledlayer view-point was implicit in the Ye-Barg paper [35], we make it explicit here.In addition, Clay codes can be constructed using any scalar MDS code as building blocks, while Ye-Barg code is based only on Vandermonde-RS codes.
Therefore, scalar MDS codes that have been time-tested, and best suited for a given application or workload need not be modified in order to make the switch to MSR codes.
By using Clay codes, these applications can use the same MDS code in a coupled-layer architecture and get the added benefits of MSR codes.
The third important distinction is that, in [35], only the single node-failure case is discussed.
In the case of Clay codes, we have come up with a generic algorithm to repair multiple failures, that has allowed us to repair many instances of multiple node repair with reduced repair bandwidth.
Our refinements over Ye-Barg code primarily aiming at its practical realization precede certain theoretical developments that are to come later.
In a recent work [6], it is proved that the sub-packetization of Clay codes is the minimum possible for any disk-read-optimal MSR code.
In [31], authors propose a permuatation-based transformation that converts a non-binary (n, k) MDS code to another MDS code permitting efficient repair of a set of (n − k) nodes, at the cost of increasing the sub-packetization (n−k) times.
An MSR code obtained by repeated application of the transformation results in the same sub-packetization as that of the Ye-Barg code.
Single Codeword Description In Section 2, we noted that each node stores a data chunk and that a data chunk is comprised of L bytes from N codewords.
In the present section we will restrict our attention to the case of a single codeword, i.e., to the case when N = 1, L = α.
Parameters of Clay Codes Evaluated Table 2 lists the parameters of the Clay codes evaluated here.
As can be seen, the normalized repair bandwidth can be made much smaller by increasing the value of (d − k + 1).
For example, the normalized repair bandwidth for a (20,16) code equals 0.297, meaning that the repair bandwidth of a Clay code, is less than 30% of the corresponding value for α = 1024 layers of a (20, 16) RS code.
Explaining Through Example We will describe the Clay code via an example code having parameters:{(n = 4, k = 2), d = 3, (α = 4, β = 2), M = 8}.
The codeword is stored across n = 4 nodes of which k = 2 are data nodes and n − k = 2 are parity nodes.
Each node stores a superbyte made up of α = 4 bytes.
The code has storage overhead nα kα = n k = 2 which is the ratio of Let us assume that a (4, 2) RS code M is used to encode and store data on these 4 nodes.
We assume that nodes (0, 0), (1, 0) store data, nodes (0, 1), (1, 1) store parity.
Two nodes are said to be in same y-section, if they have the same y-coordinate.
(n, k) d (α, β ) (dβ )/(kα)(6,{(x, y) | (x, y) ∈ J}, J = {(0, 0), (1, 0), (0, 1), (1, 1)}}.
(0,0) (0,1) (1,0) (1,1)The Uncoupled Code Next, consider storing on the same 4 nodes, 4 codewords drawn from the same RS code M .
Thus each node now stores 4 bytes, each associated to a different codeword.
We will use the parameter z ∈ {0, 1, 2, 3} to index the 4 codewords.
Together these 4 codewords form the uncoupled code U , whose bytes are denoted by {U(x, y, z) | (x, y) ∈ J, z ∈ {0, 1, 2, 3}}.
These 16 bytes can be viewed as being stored in a data cube composed of 4 horizontal layers (or planes), with 4 bytes to a layer (Fig. 5).
The data cube can also be viewed as being composed of 4 (vertical) columns, each column composed of 4 cylinders.
Each column stores a superbyte while each of the 4 cylinders within a column stores a single byte.
It can be verified that the uncoupled code inherits the property that data stored in the 4 nodes can be recovered by connecting to any 2 nodes.
As one might expect, this code offers no savings in repair bandwidth over that of the constituent RS codes, since we have simply replicated the same RS code 4 times.
We show below how the uncoupled code can be used to create a new coupledlayer (Clay) code that is an MSR code having the desired optimal, repair bandwidth.
Using a Pair of Coordinates to Represent a Layer The coupling of the layers is easier explained in terms of a binary representation (z 0 , z 1 ) of the layer-index z, defined by z = 2z 0 + z 1 i.e., 0 ⇒ (0, 0), 1 ⇒ (0, 1), 2 ⇒ (1, 0) and 3 ⇒ (1, 1).
We color in red, vertices within a layer for which x = z y as a means of identifying the layer.
For example in Fig. 6, in layer (z 0 , z 1 ) = (1, 1), the vertices (1, 0), (1, 1) are colored red.
Pairing of Vertices and Bytes We will abbreviate and write p = (x, y, z) in place of (x, y, z) and introduce a pairing (p, p * ) of vertices within the data cube.
The vertices that are colored red are unpaired.
The remaining vertices are paired such that a vertex p and its companion p * both belong to the same y-section.
In the data cube of our example code, there are a total of 4 * 4 = 16 vertices of which 8 are unpaired.
The remaining 8 vertices form 4 pairs.
Each pair is shown in the data cube appearing on the left in Fig. 7 using a pair of yellow rectangles linked by a dotted line.
Mathematically, p * is obtained from p = (x, y, z) simply by interchanging the values of x and z y .
Examples are presented in Table 3.
As mentioned earlier, each vertex p of the data cube is associated to a byte U(p) = U(x, y, z) of data in the uncoupled code U .
We will use U * (p) to denote the companion U(p * ), of the byte U(p).
In the reverse direction, we have U(p) = C(p) respectively if p is unpaired.
Else, U(p),C(p) are related by the pairwise reverse transform (PRT):Vertex p = (x, y, z 0 , z 1 ) Companion p * (interchange x, z y ) (0, 0, 1, 0) (1, 0, 0, 0) (1, 1, 1, 0) (0, 1, 1, 1) (0, 1, 1, 0) (0, 1, 1, 0) a red vertex, (p = p * )C(p) C * (p) = 1 γ γ 1 −1 U(p) U * (p) .
(1)U(p) U * (p) = 1 γ γ 1 C(p) C * (p) .
(2)We assume γ to be chosen such that γ = 0, γ 2 = 1, and under this condition, it can be verified that any two bytes in the set {U(p),U * (p),C(p),C * (p)} can be recovered from the remaining two bytes.
In Fig. 9, which shows a portion of the bytes in C , the dotted column corresponds to the failed node having coordinates (x, y) = (1, 0).
To repair the node, only the two layers z = (1, 0) and z = (1, 1) corresponding to the presence of red dots within the dotted column are called upon for node repair.
Thus each helper node contributes only 2 bytes, as opposed to 4 in an RS code, towards node repair and this explains the savings in repair bandwidth.
To understand how repair is accomplished, we turn to Fig. 11.
As shown in the figure, the PRT allows us to determine from the the bytes in layers z = (1, 0) and z = (1, 1) belonging to y-section y = 1 in data cube C, the corresponding bytes in data cube U. RS decoding allows us to then recover the bytes U(p) belonging to y-section y = 0 in the same two planes.
At this point, we have access to the bytes C(p),U(p) for p corresponding to vertices lying in planes z = (1, 0) and z = (1, 1) and lying in y-section y = 0.
This set includes 2 of the bytes C(p) in the column corresponding to the failed node.
The remaining two bytes C(p) in the failed column can be determined using properties of the PFT.Intersection Score To explain decoding, we introduce the notion of an Intersection Score (IS).
The IS of a layer is given by the number of hole-dot pairs, i.e., the vertices that correspond to erased bytes and which are at the same time colored red.
For example in Fig. 10, when nodes (0, 0), (0, 1) are erased, layers (0, 0), (0, 1), (1, 1) have respective IS=2, 1, 0.
Decoding The "Decode" algorithm of the Clay code is able to correct the erasure of any n − k = 2 nodes.
Decoding is carried out sequentially, layer-by-layer, in order of increasing IS.
This is explained in Fig.12 for the case when nodes (0, 0), (0, 1) are erased and for layers having IS= 0, IS= 1.
In a layer with IS= 0, U bytes can be computed for all non-erased vertices from the known symbols.
The erased U bytes are then calculated using RS code decoding.
For a layer with IS= 1, to compute U bytes for all non-erased vertices, we make use of U bytes recovered in layers with IS= 0.
Thus the processing of a layer with IS = 0 has to take place prior to processing a layer with IS = 1 and so on.
Once all the U bytes are recovered, the C bytes can be computed using the PFT.
As a result of the simple, pairwise nature of the PFT and PRT, encoding and decoding times are not unduly affected by the coupled-layer structure.
Clay code parameters Clay codes can be constructed for any parameter set of the form:(0,0) (0,1) (1,0) (1,1) (a) IS=2 (0,0) (0,1) (1,0) (1,1) (b) IS=1 (0,0) (0,1) (1,0) (1,1)(c)(n = qt, k, d) (α = q t , β = q t−1 ), with q = (d − k + 1), for any integer t ≥ 1 over any finite field of size Q > n.
The encoding, decoding and repair algorithms can all be generalized for the parameters above.
However, in the case d < n − 1, during single node repair, while picking the d helper nodes, one must include among the d helper nodes, all the nodes belonging to the failed node's y-section.
Clay codes for any (n, k, d) The parameters indicated above have the restriction that q = (d − k + 1) divide n.
But the construction can be extended in a simple way to the case when q is not a factor of n. For example, for parameters (n = 14, k = 10, d = 13), q = d − k + 1 = 4.
We construct the Clay code taking n = 16, the nearest multiple of q larger than n, and k = k + (n − n) = 12.
While encoding, we set data bytes in s = (n −n) = 2 systematic nodes as zero, and thus the resultant code has parameters (n = 14, k = 10, d = 13).
The technique used is called shortening in the coding theory literature.
We use s temporary buffers each of size equal to chunk size during the encoding, decoding and repair operations.
Our implementation of Clay code includes this generalization.
Ceph [32] is a popular, open-source distributed storage system [33], that permits the storage of data as objects.Object Storage Daemon (OSD) is the daemon process of Ceph, associated with a storage unit such as a solid-state or hard-disk drive, on which user data is stored.
Ceph supports multiple erasure-codes, and a code can be chosen by setting attributes of the erasure-codeprofile.
Objects will then be stored in logical partitions referred to as pools associated with an erasure-codeprofile.
Each pool can have a single or multiple placement groups (PG) associated with it.
A PG is a collection of n OSDs, where n is the block length of the erasure code associated to the pool.The allocation of OSDs to a PG is dynamic, and is carried out by the CRUSH algorithm [34].
When an object is streamed to Ceph, the CRUSH algorithm allocates a PG to it.
It also performs load balancing dynamically whenever new objects are added, or when active OSDs fail.
Each PG contains a single, distinct OSD designated as the primary OSD (p-OSD).
When it is required to store an object in a Ceph cluster, the object is passed on to the p-OSD of the allocated PG.
The p-OSD is also responsible for initiating the encoding and recovery operations.In Ceph, the passage from data object to data chunks by the p-OSD is carried out in two steps as opposed to the single-step description in Section 2.
For a large object, the amount of buffer memory required to perform encoding and decoding operations will be high.
Hence, as an intermediate step, an object is first divided into smaller units called stripes, whose size is denoted by S (in bytes).
If an object's size is not divisible by S, zeros are padded.
The object is then encoded by the p-OSD one stripe at a time.
The stripe-size is to be specified within the cluster's configuration file.
Both zero padding and system performance are important factors to be considered while fixing a stripe-size.
To encode, the p-OSD first zero pads each stripe as necessary in order to ensure that the strip size S is divisible by kα.
The reason for the divisibility by a factor of k is because as described earlier, the first step in encoding is to break up each stripe into k data chunks of equal size.
The reason for the additional divisibility requirement by a further factor α arises because we are dealing with a vector code and as explained in Section 2, operations in a vector code involve superbytes, where each superbyte contains α bytes.
In what follows, we will assume that S is divisible by kα.The encoding of a stripe is thus equivalent to encoding N = S kα codewords at a time.
The next step as explained in Section 2, is interleaving at the end of which one obtains α sub-chunks per OSD, each of size N bytes.
We note that the parameter L introduced in Section 2, is the number of bytes per data chunk and is thus given by L = S k .
This notion of sub-chunk is not native to Ceph, but rather is a modification to the Ceph architecture proposed here, to enable the support of vector codes.The advantage of a vector code is that it potentially enables the repair of an erased coded chunk by passing on a subset of the α sub-chunks.
For example, in the Clay code implemented in Ceph is an MSR code, it suffices for each node to pass on β sub-chunks.
However, when these β sub-chunks are not sequentially located within the storage unit, it can result in fragmented reads.
We analyze such disk read performance degradation in Section 5.
Our implementation makes use of the Jerasure [22] and GF-Complete [21] libraries which provide implementations of various MDS codes and Galois-field arithmetic.
We chose in our implementation to employ the finite field of size 2 8 to exploit the computational efficiency for this field size provided by the GF-complete library in Ceph.In our implementation, we employ an additional buffer, termed as U-buffer, that stores the sub-chunks associated with the uncoupled symbols U introduced in Section 3.
This buffer is of size nL = S n k bytes.
The Ubuffer is allocated once for a PG, and is used repetitively during encode, decode and repair operations of any object belonging to that PG.
Pairwise Transforms We introduced functions that compute any two sub-chunks in the set {U,U * ,C,C * } given the remaining two sub-chunks.
We implemented these functions using the function jerasure matrix dotprod(), which is built on top of function galois w08 region multiply().
Encoding Encoding of an object is carried out by p-OSD by pretending that m parity chunks have been erased, and then recovering the m chunks using the k data chunks by initiating the decoding algorithm for the code.
Pairwise forward and reverse transforms are the only additional computations required for Clay encoding in comparison with MDS encoding.
When one or more OSDs go down, multiple PGs are affected.
Within an affected PG, recovery operations are triggered for all associated objects.
We introduced a boolean function is repair() in order to choose between a bandwidth, disk I/O efficient repair algorithm and the default decode algorithm.
For the case of single OSD failure, is repair() always returns true.
There are multiple failure cases as well for which is repair() returns true i.e., efficient repair is possible.
We discuss these cases in detail in Appendix A. Identification In the current Ceph architecture, when a failure happens, minimum to decode() is called in order to determine the k helper chunk indices.
We introduced a function minimum to repair() to determine the d helper chunk indices when repair can be performed efficiently i.e., when is repair() returns true.
OSDs corresponding to these indices are contacted to get information needed for repair/decode.
When there is a single failure, minimum to repair() returns d chunk indices such that all the chunks that fall in the y-cross-section of the failed chunk are included.
We describe the case of multiple erasure cases in detail in Appendix A Fractional Read For the case of efficient repair, we only read a fraction of chunk, this functionality is implemented by feeding repair parameters to an existing structure ECSubRead that is used in inter-OSD communication.
We have also introduced a new read function with Filestore of Ceph that supports sub-chunk reads.
Decode and Repair Either the decode or repair function is called depending on whether if is repair() returns true or false respectively.
The decoding algorithm is described in Section 3.
Our repair algorithm supports in addition to single-node failure (Section.3), some multipleerasure failure patterns as well (Section 6).
Enabling vector codes in Ceph: We introduced the notion of sub-chunking in order to enable new vector erasure code plugins.
This contribution is currently available in Ceph's master codebase [4].
Clay codes in Ceph: We implemented Clay codes as a technique (cl msr) within the jerasure plugin.
The current implementation gives flexibility for a client to pick any n, k, d parameters for the code.
It also gives an option to choose the MDS code used within to be either a Vandermonde-based-RS or Cauchy-original code.
The Clay code [2] is yet to be part of Ceph's master codebase.
The experiments conducted to evaluate the performance of Clay codes in Ceph while recovering from a single node failure are discussed in the present section.
Experimental results relating multiple node-failure case can be found in Section 6.1.
Codes Evaluated While Clay codes can be constructed for any parameter set (n, k, d), we have carried out experimental evaluation for selected parameter sets close to those of codes employed in practice, see Table 4.
Code C1 has (n, k) parameters comparable to that of the RDP code [9], Code C2 with the locally repairable code used in Windows Azure [16], and Code C3 with the (20, 17)-RS code used in Backblaze [1].
There are three other codes C4, C5 and C6 that match with the (14, 10)-RS code used in Facebook data-analytic clusters [25].
Results relating to Codes C4-C6 can be found in Section 6.1, which focuses on repair in the multiple-erasure case.
The experimental results for Clay codes are compared against those for RS codes possessing the same (n, k) parameters.
By an RS code, we mean an MDS-code implementation based on the cauchy orig technique of Ceph's jerasure plugin.
The same MDS code is also employed as the MDS code appearing in the Clay-code construction evaluated here.Experimental Setup All evaluations are carried out on Amazon EC2 instances of the m4.xlarge (16GB RAM, 4 CPU cores) configuration.
Each instance is attached to an SSD-type volume of size 500GB.
We integrated the Clay code in Ceph Jewel 10.2.2 to perform evaluations.
The Ceph storage cluster deployed consists of 26 nodes.
One server is dedicated for the MON daemon, while the remaining 25 nodes each run one OSD.
Apart from the installed operating system, the entire 500GB disk is dedicated to the OSD.
Thus the total storage capacity of the cluster is approximately 12.2TB.
Object # Objects Total, T Stripe size (MB) (GB) size, S Fixed (W 1 ) 64 8192 512 64MB 64 6758 Variable 32 820 448 1MB (W 2 ) 1 614 Overview Experiments are carried out on both fixed and variable object-size workloads, respectively referred to as W 1 and W 2 .
Workload W 1 has all objects of fixed size 64MB, while in the W 2 workload we choose objects of sizes 64MB, 32MB and 1MB distributed in respective proportions of 82.5%, 10% and 7.5%.
Our choices of object sizes cover a good range of medium (1MB), medium/large(32MB) and large (64MB) objects [3], and the distribution is chosen in accordance with that in the Facebook data analytic cluster reported in [23].
The workloads used for evaluation are summarized in Table 5.
The stripe-size S is set as 64MB and 1MB for workloads W 1 and W 2 respectively, so as to avoid zeropadding.The failure domain is chosen to be a node.
Since we have one OSD per node, this is equivalent to having a single OSD as the failure domain.
We inject node failures into the system by removing OSDs from the cluster.
Measurements are taken using nmon and NMONVisualizer tools.
We run experiments with a single PG, and validate the results against the theoretical prediction.
We also run the same experiments with 512 PGs, which we will refer to as the multiple-PG case.
Measurements are made of (a) repair network traffic, (b) repair disk read, (c) repair time, (d) encoding time and (e) I/O performance for degraded, normal operations.
Network Traffic: Single Node Failure Network traffic refers to the data transferred across the network during single-node repair.
Repair is carried out by the p-OSD, which also acts as a helper node.
The network traffic during repair includes both the transfer of helper data to the primary OSD and the transfer of recovered chunk from primary OSD to the replacement OSD.
The theoretical estimate for the amount of network traffic isT k ((d −1) β α +1) bytes for a Clay code, versus T bytes for an RS code.
Our evaluations confirm the expected savings, and we observed reductions of 25%, 52% and 66%, (a factor of 2.9×) in network traffic for codes C1, C2 and C3 respectively in comparison with the corresponding RS codes under fixed and variable workloads (see Fig. 13(a), 13(d).)
As can be seen, the code C3 with the largest value of q = (d − k + 1) offer the largest savings in network traffic.In Ceph, the assignment of OSDs and objects to PGs are done in a dynamic fashion.
Hence, the number of objects affected by failure of an OSD can vary across different runs of multiple-PG experiment.
We present an network bandwidth performance with 512 PGs under the W 1 workload averaged across 3 runs in Fig. 14.
It was observed that in certain situations, an OSD that is already part of the PG can get reassigned as a replacement for the failed OSD.
In such cases, the number of failures are treated as two resulting in inferior network-traffic performance in multiple-PG setting.Disk Read: Single Node Failure The amount of data read from the disks of the helper nodes during the repair of a failed node is referred to as disk read and is an important parameter to minimize.Depending on the index of the failed node, the subchunks to be fetched from helper nodes in a Clay code can be contiguous or non-contiguous.
Non-contiguous reads in HDD volumes lead to a slow-down in performance [20].
Even for SSD volumes that permit reads at a granularity of 4kB, the amount of disk read needed depends on the sub-chunk-size.
Let us look at, for instance, disk read from a helper node in the case of single node failure for code C3 in workload W2.
The stripe-size S = 1MB, and the chunk size is given by L = S/k = 64kB.
During repair of a node, L/(d − k + 1) = 16kB of data is to be read from each helper node.
In the best-case scenario (for example, a systematic node failure), the 16kB data is contiguous, whereas for the worst-case scenario (as in the case of parity node failure) the reads are fragmented.
In the latter case, β = 256 fragments with each of size L/α = 64 bytes are read.
As a consequence, when 4kB of data is read from the disk, only 1kB ends up being useful for the repair operation.
Therefore, the disk read is 4 times the amount of data needed for repair.
This is evident in disk read measurements from a helper node in the worst-case as shown in Fig. 13(f).
A similar analysis shows that for workload W2, the code C2 leads to additional disk read while C1 does not.
This is observed experimentally as well.On the other hand, for workload W1 with stripe-size S = 64MB, all the three codes C1, C2, and C3 do not cause any additional disk read as shown in Fig. 13(b).
For instance, with code C3, fragments of size S/kα = 4kB are to be read in the worst-case scenario.
As the size is aligned to the granularity of SSD reads, disk read for the worst-case is equal to 256 * 4kB=1MB.
This is exactly the amount read during best-case as well.
(see Fig. 13(f)).
In summary, all the three codes result in disk I/O savings for the W1 workload whereas for workload W2 only C1 results in an advantage.The expected disk read from all helper nodes during repair is T dβ kα bytes for a Clay code in contrast to T bytes for an RS code.
In experiments with fixed object-size (see Fig. 13(b)), we obtain savings of 37.5%, 59.3% and 70.2% (a factor of 3.4×) for codes C1, C2 and C3 respectively, when compared against the corresponding RS code.
Fig. 14 shows the disk read in the multiple-PG setting.
I/O Performance We measured the normal and degraded (i.e., with a repair executing in the background) I/O performance of Clay codes C1-C3, and RS codes with same parameters.
This was done using the standard Ceph benchmarking tests for read and write operations.The results are shown in Fig. 15.
Under the normal operation, the write, sequential-read and random-read performances are same for both Clay and RS codes.
However in the degraded situation, the I/O performance of Clay codes is observed to be better in comparison with RS codes.
In particular, the degraded write, read throughput of (20,16,19) Clay code is observed to be more than the (20, 16) RS code by 106% and 27% respectively.
This can possibly be attributed to the reduced amount of repair data that is read, transmitted and computed on to build the lost data in the erased node.
Repair Time and Encoding Time We measure the time taken for repair by capturing the starting and stopping times of network activity within the cluster.
We observed a significant reduction in repair time for Clay codes in comparison with an RS code.
For the code C3 in a single-PG setting, we observe a reduction by a factor of 3× in comparison with an RS code.
This is mainly due to reduction in network traffic and disk I/O required during repair.
Every affected object requires recovery of (1/k)-th fraction of the object size, and the average repair time per object is plotted in Fig. 13(c).
We define the time required by the RADOS utility to place an object into Ceph object-store as the encoding time.
The encoding time includes times taken for computation, disk-I/O operations, and data transfer across the network.
We define the time taken for computing the code chunks based on the encoding algorithm as the encode computation time.
During encoding, the network traffic and I/O operations are the same for both the classes of codes.
Although the encode computation time of Clay code is higher than that of the RS code (See Fig. 16.)
[12], [24].
The significant savings in network traffic and disk reads during node repair are a sufficient incentive for putting up with overheads in the encode computation time.
The decoding time will be almost same as encoding time, since we perform encoding using the decoding function as described in Section 4.3.
The Clay code is capable of recovering from multiple node-failures with savings in repair bandwidth.
In the case of multiple erasures, the bandwidth needed for repair varies with the erasure pattern.
In Fig. 17, we show the average network traffic of Clay codes with parameters (n = 14, k = 10, d) for d = 11, 12, 13 while repairing f = 1, 2, 3, and 4 node failures.
The average network traffic for repairing f nodes is computed under the assumption that all the f -node-failure patterns are equally likely.
Detailed analysis of savings in network traffic for multiple erasures is relegated to Appendix A. Network Traffic and Disk Read While the primary benefit of the Clay code is optimal network traffic and disk read during repair of a single node failure, it also yields savings over RS counterpart code in the case of a large number of multiple-node failure patterns.
We evaluate the performance of codes C4-C6 (see Table 4) under W 1 workload injecting multiple node-failures in a setting of 512PGs.
The plots for network traffic and disk read are shown in Fig. 18, 19.
Clay codes extend the theoretical construction presented by Ye & Barg with practical considerations from a coupled-layer perspective that leads directly to implementation.
Within the class of MDS codes, Clay codes have minimum possible repair bandwidth and disk I/O.
Within the class of MSR codes, Clay codes possess the least possible level of sub-packetization.
A natural question to ask is if these impressive theoretical credentials of the Clay code result in matching practical performance.We answer this in the affirmative here by studying the real-world performance of the Clay code in a Ceph setting, with respect to network traffic for repair, disk I/O during repair, repair time and degraded I/O performance.
Along the way, we also modified Ceph to support any vector code, and our contribution is now a part of Ceph's master code-base.
A particular Clay code, with storage overhead 1.25x, is shown to reduce repair network traffic, disk read and repair times by factors of 2.9, 3.4 and 3 respectively.
Much of this is made possible because Clay codes can be constructed via a simple two-step process where one first stacks in layers, α codewords drawn from an MDS code; in the next step, elements from different layers are paired and transformed to yield the Clay code.
The same construction with minor modifications is shown to offer support for handling multiple erasures as well.
It is our belief that Clay codes are well-poised to make the leap from theory to practice.
The failure patterns that can be recovered with bandwidth-savings are referred to as repairable failure patterns.
Non repairable failure patterns are recovered by using the decode algorithm.Repairable Failure Patterns (i) d < n − 1: Clay codes designed with d < n − 1 can recover from e failures with savings in repair bandwidth when e ≤ n − d, with a minor exception described in Remark 1.
The helper nodes are to be chosen in such a way that if a y-section contains a failed node, then all the surviving nodes in that y-section must act as helper nodes.
If no such choice of helper nodes is available then it is not a repairable failure pattern.
For example, consider the code with parameters (n = 14, k = 10, d = 11).
The nodes can be put in a (2×7) grid, as q = d −k +1 = 2 and t = n q = 7.
In Fig.20, we assume that nodes (0, 0) and (0, 1) have failed, and therefore nodes (1, 0) and (1, 1) along with any 9 other nodes can be picked as helper nodes.
(ii) d = n − 1: When the code is designed for d = (n − 1), up to (q − 1) failures that occur within a single y-section can be recovered with savings in repair bandwidth.
As the number of surviving nodes is smaller than d in such a case, all the surviving nodes are picked as helper nodes.
See Fig. 21 for an example of a repairable failure-pattern in the case of a (14, 10, 13) Clay code.
Remark 1 Whenever d e β e > kα, decode algorithm is a better option and the is repair() function takes care of these cases by returning false.
For example, when there are q failures within the same y-section, every layer will have IS > 0 giving β e = α and hence repair is not efficient for this case.Repair Algorithm We present a repair algorithm in 1, that is generic for single and multiple erasures.
This is invoked whenever savings in bandwidth are possible, i.e, when is repair() returns true.
In the algorithm, we refer to those non-erased nodes that are not helper nodes as aloof nodes.
1: Input: E (erasures), I (aloof nodes).
2: repair layers = get repair layers(E ).
3: set s = 1.
4: set maxIS = max of IS(E ∪ I , z) over all z from repair layers 5: while ( 1 ≤ s ≤ maxIS ) 6: for (z ∈ repair layers and IS(E ∪ I , z) = s) 7: if (IS(E , z) > 1) G = φ G is set of all nodes in a's y-section.}
E = E ∪ G ∪ I Compute U sub-chunks in layer z corresponding to all the nodes other than E Invoke scalar MDS decode to recover U subchunks for all nodes in E We thank our shepherd Cheng Huang and the anonymous reviewers for their valuable comments.
P. V. Kumar would like to acknowledge support from NSF Grant No.1421848 as well as the UGC-ISF research program.
The research of Alexander Barg and Min Ye was supported by NSF grants CCF1422955 and CCF1618603.
