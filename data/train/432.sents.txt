The discovery, more than a decade ago, of the relation between Distributed-Computing (DC) and Algebraic-Topology (AT) raised the specter of requiring checking task solvability to be intimately connected to expertise in AT.
Yet, in the area of Centralized Algorithms proving a problem to be NP or PSPACE complete requires more algorithmic expertise than complexity one.
In analogy, we show that in DC the equivalent of polynomial-time reductions, is read-write reductions.
We define the notion of read-write reduction between distributed tasks, and show that all interesting known read-write impossible tasks can be proven impossible via read-write reduction to a task called Symmetry-Breaking (SB).
Discovering a read-write reduction requires solely algorithmic expertise.
Since the introduction of topological arguments [2,20,21], they have been used among other uses, to argue the insolvability of a given task in a given model.
Do we need now to run and study topology in order to make progress in this area of checking tasks for solvability?We propose task called Symmetry-Breaking whose role in proving another task to be read-write insolvable is informally but usefully the analogue of the role of SAT in proving NP-completeness.
To prove a problem NP-complete one does not need to be an expert in Turing Machine tricks.
Once SAT was proven NP-complete from here on NPcompleteness is proved by reduction.
Similarly, we exhibit that all natural tasks to-date which are known to be insolvable wait-free in the shared-memory read-write model, can be proven so by reduction from the corresponding size SB task.We do not claim that this analogy to be formal.
I.e. we do not claim that if a task A is insolvable wait-free in the read-write model then there exits a reduction.
In fact we know that to be false: SB is not solvable even when one is given the use of a Torus task [15] (or for that matter any orientable manifold), thus SB will not suffice to prove that the Torus task is insolvable.
Yet we do not know how to pose a Torus task for arbitrary number of processors in a way that will not be "artificial."
Thus, we conjecture that there exists a proper "natural" definition of "natural" families of tasks for which SB is the weakest task.A task is an input-output relation between sets of processors, each set called a participating set, and output tuples, each specifying an output value for each processor in the participating set.A task is solvable in certain model if there exists a protocol in the model, and a notion of when a processor participates in the protocol, such that for a run in the model with a participating set P , all processor output and halt so that the outputs constitute an allowed output tuple in the task.The tasks we consider will be families of tasks, each parametrized by n, denoting the maximum size of the participating set.
For each task we will consider two families: NonComparison, and Comparison.
In the former the largest participating set is drawn out of {p 0 , , p n−1 }.
In the latter, the participating set is any set of processors of cardinality less or equal to n.
It is known that the ability to draw the participating processors from a universe large enough is equivalent to the processor identifiers being used only via comparison [12].
Although the task definition is just a mapping from participating sets to output, it encompasses a processor that may wake up with different inputs by considering each input to be associated with different processor identifier and considering the comparison version of the task.
Thus w.l.o.g. below we will refer to different inputs, albeit in that case only the comparison version makes sense.We will say that a task A read-write implements B if given any numbers of copies of A and any number of read-write registers than we can wait-free solve B.
We than will say that A is potentially stronger than B.
If the opposite is also true than we say that A and B are equivalent.
If we know that B is impossible to solve read-write waitfree, than such an implementation proves that A is insolvable read-write wait-free by reduction from B. 1.
k-Set-Election: The task SE(k, n) says that for all participating sets of size at most n each processor outputs an id of a processor from the participating set, and the number of distinct ids that appear in an output tuple is less or equal to k. 2.
k-Strong-Set-Election: The task SSE(k, n) is like Set-Election but in addition if p i outputs p j then p j outputs p j i.e. itself.
3.
k-Set-Consensus: In the task SC(k, n) each processor wakes up with an input tuple of size k, where at position i there is a 0 or 1.
It returns as an output an index 1 ≤ j ≤ k and a single bit, 0 or 1.
All processors that return the same index j return with it the same bit b.
The non-triviality requires that b can be returned together with the index j only if there exist a participating processor who has b in the jth position of its input tuple.
4.
k-Test-and-Set: In the task T AS(k, n), n > k participating processors output 0 or 1, and each output tuple always contains at least one 0, and at most k 0s.
The largest participating set is of cardinality n 5.
Symmetry-Breaking: In the task SB(n) processors output 0 or 1.
The largest participating set is of size n and the output tuples for this size correspond to all the possible n length bit strings, excluding the all 0s and all 1s strings.
6.
n-Adaptive-Renaming: In the task AR(f (k), m, n) processors return positive distinct integers in the range 1 o m. For k < n they return in the range 1 to f (k).
7.
n-Renaming: In the task R(m, n), m ≥ n processors return positive distinct integers in the range 1 to m. Below we first outline the sequence of reductions from SB(n) that prove all the above tasks to be read-arite wait-free insolvable given that SB(n).
That SB(n) is insolvable is a consequence of its equivalence to comparison AR(2n−2, n).
The latter was proved insolvable by direct topological arguments in [20].
In the subsection that follow the outline we elaborate on each item in the outline, respectively.
Most of the reductions are almost at the level of folklore.
Some are substantial, and then we reference them.
No new reduction is introduced here and thus the contribution of the paper is just in organizing all these scattered related known items into a single place.
1.
SB(n) and AR(2n − 2, n) are trivially solvable in the non-comparison model.
2.
Below we show comparison SB(n) and comparison AR(2n−2, n) to be equivalent in the comparison model.
The task AR(2n − 2, n) was proved to be insolvable in the comparison model in [20].
3.
If comparison SB(n) is read-write wait-free solvable then comparison SB(n + 1)is [16].
Thus SB(n + 1) is weaker than SB(n), but the reduction is white-box rather than black-box reduction.
We do not know a black-box reduction for this fact.
4.
Non-comparison T AS(k, n) is equivalent to task T AS(k, n+1) and thus to T AS(k, ∞).
Below we show that non-comparison T AS(k, k + 1) implements SB(k + 1), and obviously comparison T AS(k, k + 1) implements non-comparison T AS(k, k + 1).
5.
Non-comparison SE(k, k + 1) is equivalent to SSE(k, k + 1) which is equivalent to non-comparison T AS(k, k + 1).
Obviously the comparison versions implement their corresponding non-comparison ones.
And obviously SE(k, k+2) implements SE(k, k + 1).
6.
The non-comparison SC(k, n) is equivalent to SE(k, n).
7.
The task AR(2k − 1, 2n − 2, n) is equivalent to T AS(n − 1, n).
1.
Needs no further comment.2.
(a) Comparison SB(n) implements comparison AR(2n − 2, n): Processors use SB(n) to break themselves into two disjoint groups each of which is nonempty when the cardinality of the participating set is n.
One group G 0 of cardinality n 0 consists of the processors that output 0 in SB(n) and the other group is G 1 of cardinality n 1 .
Both groups now use the comparison renaming algorithm AR(2k − 1, 2n − 1, n) in [?
,8].
Only that G 0 renames from position 1 upwards, while group G 1 renames from position 2n − 2 downward.
We observe that (2n 0 − 1) + 2n 1 − 1 ≤ 2(n 0 + n 1 ) − 2 ≤ 2n − 2, where the first inequality is true iff both G 0 and G 1 are non-empty.
It is easy to see that when the participating set cardinality is less than N the space is enough.
(b) Comparison AR(2n − 2, n) implements comparison SB(n): Processors that obtain values from AR(2n − 2, n) in the range 1 to n-1 output 0, while the rest output 1.
3.
This was put in to raise the question whether any task A that can be shown to implement B provided A was read-write wait-free solvable, means that if B is not solvable than B can be reduced to A.
We do not know the answer to this question but conjecture the answer to be positive.
We challenge the reader to show that comparison SB(n) implements comparison SB(n + 1).
4.
Trivially non-comparison T AS(k, n + 1) implements non-comparison T AS(k, n).
To see the reverse put processors p 0 to p n−1 through T AS 1 (k, n).
At most k of them will obtain a 0.
They then proceed some to T AS 2 (k, n) and some to T AS 3 (k, n).
They proceed by renaming AR(2k − 1, 2n − 1, n).
Those that obtain values in 1 to n − 1 go to the corresponding ports in T AS 2 (k, n), and those that obtain a value j higher than n − 1 go to port j − (n − 1) in T AS 3 (k, n).
Processor p n attaches to port n in T AS 2 (k, n).
Processors that obtain values in T AS 3 (k, n) return as final output the negation of their output from T AS 3 (k, n), while processor with output from T AS 2 (k, n) retain their output.
The idea of negation was proposed to us by Rafail Ostrovasky [17].
To see that non-comparison T AS(k, k + 1) implements comparison SB(n) take two copies T AS 1 (k, k+1) and T AS 2 (k, k+1).
The n processors AR(2k−1, 2n− 1, n) rename into port of T AS 1 (k, k + 1) and T AS 2 (k, k + 1) where port i in the latter stand for the integer i + (k + 1).
processors out of T AS 2 (k, k + 1) negate their output.
5.
(a) The task SE(k, k+1) is equivalent to SSE(k, k+1): Obviously SSE(k, k+1) implements SE(k, k + 1).
The reverse implementation appears in [2].
(b) The task SSE(k, k + 1) is equivalent to T AS(k, k + 1): See [2].
6.
Non-comparison SC(k, n) is equivalent to SE(k, n): In this issue [9].
7.
The task AR(2k − 1, 2n − 2, n) is equivalent to T AS(n − 1, n): (a) The task AR(2k − 1, 2n − 2, n) implements T AS(n − 1, n): Processors that get values in 1 to n − 1 output 0, the rest output 1.
(b) Processors do immediate snapshot [3].
Those that end up with snapshot of size n apply to T AS(n − 1, n).
They thus divide into three disjoint groups: Group G <n of those that obtain a snapshot of size less than n, Group G 0 of those that obtained 0 in T AS(n − 1, n), and the rest are in G 1 .
Processors in G <n and G 1 AR(2k − 1, 2n − 1, n) rename from 1 upward while those in G 0 rename from 2n − 2 downward [8,14,18].
We have presented a sequence of reductions/implementations that show how all known interesting insolvable task can be deemed so by reduction from the family SB.
This led to the speculation that any "interesting" task is at least as strong as SB.
Indeed that speculation led to a renewed push to understand the relation between SB and T AS that has recently resulted in the conclusion that SB is strictly weaker than T AS.
We also leave some interesting open problems.
If it can be (white-box) shown that the readwrite wait-free solvability of A, either by assumption of the existence of read-write code as in the BG-simulation [2,5], or by considering the topological ramification of such solvability, would imply the read-arite solvability of task B, does it necessarily implies that B can be reduced to A (black-box)?
It will be elegant and satisfying if the answer is positive.
Finally, it will be of the utmost interest to capture rigorously what is informally considered a "natural" task family and show that any task of interest at the least breaks symmetry.
