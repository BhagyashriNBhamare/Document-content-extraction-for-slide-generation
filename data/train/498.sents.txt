Quality of Service mechanisms and differentiated service classes are increasingly available in networks and servers.
While network clients can assess their service by measuring basic performance parameters such as packet loss and delay, such measurements do not expose the net-work's core QoS functionality.
In this paper, we develop a framework and methodology for enabling network clients to assess a system's multi-class mechanisms and parameters.
Using hypothesis testing, maximum likelihood estimation, and empirical arrival and service rates measured across multiple time scales, we devise techniques for clients to (1) determine the most likely service discipline among EDF, WFQ, and SP, (2) estimate the server's parameters with high confidence, and (3) detect and parameterize non-work-conserving elements such as rate limiters.
We describe the important role of time scales in such a framework and identify the conditions necessary for obtaining accurate and high confidence inferences.
Both research and commercial networks are increasingly able to provide minimum quality-of-service levels to traffic classes, e.g., [20].
Example components of such networks include QoS schedulers [10], [18], diffserv-style service level agreements [4], [8], [14], [21], [25], edge-based traffic shaping and prioritizing devices, and novel architectures and algorithms for scalable QoS management [6], [7], [18], [19], [25].
However, even as the network's infrastructure and services become increasingly sophisticated, the network's clients lack reciprocal tools for validation and monitoring of the network's QoS capabilities.
Clients of Service Level Agreements (SLAs) will have monitoring requirements ranging from basic validation of the SLA's raw bandwidth to more sophisticated inference of multi-class functionalities.
For example, is a class rate limited (policed)?
If so, what are the rate limiter's parameters and what is necessary to detect this?
In a multi-class environment with multiple classes within or among SLAs, what is the interclass relationship?
Fair, weighted fair, strict priority, and with what parameters?
Is resource "borrowing" across classes fully allowed or only allowed within certain limits?Obtaining "off-line" answers to such questions can be quite trivial.
In particular, consider a system with an unknown service (suppose the system is a single router for simplicity).
To assess whether classes are rate limited, one could probe each class, one at a time, with a high rate test sequence: the output of the system would yield the policing parameters.
Similarly, simultaneously probing at a high rate in all classes would yield the inter-class relationships: if one class receives all of the service, the system is strict priority (at least for that class); if weighted service is received, the system performs a variant of weighted fair queueing.
This research was supported by NSF CAREER Award ANI-9733610, NSF grants ANI-9730104 and ANI-0085842, and Texas Instruments.
The authors may be reached via http://www.ece.rice.edu/networks.In contrast, the "on-line" case, in which one cannot force all other traffic classes to remain idle while experiments are performed, is quite different.
Even for classes which are under the control of the client, it may be highly undesirable to disrupt the class with experiments such as above.
For example, sending at a high rate to detect rate-limiters may cause excessive packet losses for established sessions.The goal of this paper is to develop a framework for monitoring, validation, and inference of multi-class services for the on-line case in which existing services cannot be disrupted.
In particular, we show how passive monitoring of system arrivals and departures can be used to detect if a class has a minimum guaranteed rate and/or a rate limiter.
Moreover, if such elements exist, we will show how to compute their maximum likelihood parameters.
Beyond a single class, we will also show how inter-class relationships can be assessed.
For example, we devise tests which infer not only whether a service discipline is work-conserving or non-work-conserving, but also the relationship among classes, such as weighted fair or strict priority.Throughout our analysis, it is clear that time scales play a key role.
Short time scale measurements are crucial for detecting and analyzing non-work-conserving elements such as rate limiters.
In contrast, long time scale measurements best reveal "link sharing" rules and weights.
Thus, a key aspect of our contribution is that we develop all such measurement tools using a unifying abstraction of envelopes [5], [9], [16], hypothesis testing, and maximum likelihood estimations.
In this way, we treat phenomena occurring at different time scales in a uniform and methodical way.In addition to network services, our techniques also have applications to other multi-class systems such as quality-of-service web servers [1], [3], [11], [13].
For example, the framework can be applied to allow a client of a web hosting service to infer the mechanisms and parameters by which capacity is allocated to various hosted sights.
We therefore consider a simple system model which is sufficiently general to encompass a broad class of multi-service elements ranging from routers to servers, yet we necessarily forgo modeling of many of the intricacies of realistic systems (e.g., we limit our discussion to a single network node).
Thus, our contribution is to develop a basic framework for using passive monitoring to assess a system's core multi-class mechanisms and parameters.
Despite the simplified system model, a large set of simulation experiments indicate that the technique has practical implications.
For example, in our experiments with the majority-rule hypothesis test performed across multiple time scales, multi-class EDF scheduling was correctly inferred 100% of the time when the class delay bounds were sufficiently differentiated, and class-based fair queueing was correctly inferred 94% of the time.
Once the service discipline is known, the algorithm estimated class WFQ weights within 1.4% of the correct value with 95% confidence.The remainder of this paper is organized as follows.
In Section II we describe the basic system model, define the measurement and inference problem, and describe the measurement methodology.
In Section III, we devise the maximum likelihood estimates for the system parameters and hypothesis tests for inference of the service discipline.
Next, in Section IV, we present a set of ns-2 simulations to evaluate the effectiveness of the scheme under a number of different node functionalities.
Finally, in Section V, we conclude.
Figures 1 and 2 depict our two targeted systems.
(In both cases, passive measurement modules are depicted by diamonds.)
Figure 1 illustrates a distributed web server.
QoS functionalities in the server may include prioritized scheduling of incoming requests at the front-end, prioritized distribution of jobs to back-end nodes, and operating-system mechanisms such as prioritized scheduling of CPU, memory, and disk access [11].
In any case, our goal is to provide an application-layer characterization of the system's multi-class QoS mechanisms.
For example, if several QoS mechanisms are simultaneously employed with the goal of providing weighted fair service among different classes, our technique will estimate a class' net "guaranteed rate", i.e., it's minimum request throughput.
Such inferences have important implications for both performance monitoring and resource management.
Figure 2 depicts the targeted networking scenario.
In this case, measurement modules are placed at the periphery of the network.
The goal is to use passive edge-based client measurements to infer the multi-class QoS mechanisms and parameters employed by the network operator.
With an improved understanding of the way traffic is internally serviced, clients can better manage their use of multi-class networks.
Similarly, operators or third parties can employ the methodology to test and validate the performance and potential performance of multiple service classes.Below, we describe the system model and problem formulation for multi-class service inference.
We then devise a measurement methodology based on empirical arrival and service The general system model that we consider in this paper is depicted in Figure 3.
As in the basic abstraction of service disciplines described in [24], it consists of two stages: non-work-conserving elements which limit a class' rate and a work-conserving packet scheduler.
For rate limiters, we consider single-level leaky bucket regulators.
For the packet scheduler, we consider Strict Priority (SP), class-based Weighted Fair Queueing (WFQ), and Earliest Deadline First (EDF This formulation covers a broad set of class-based scheduling elements, including minimum guaranteed rates, maximum policed rates, weighted fairness, sorted priority, and strict priority.
While necessarily not comprehensive, it incorporates both work-conserving and non-work-conserving service disciplines and a number of mechanisms for inter-class resource sharing and quality-of-service differentiation.For inferences of the system's multi-class characteristics, we consider the case where internal system information is not available, i.e., neither static configuration information (such as the scheduler's parameters) nor empirical information (such as mean buffer length).
Instead, the available information consists of the external observations from passive monitoring of packets, namely packet arrival and departure times along with packet class labels and sequence numbers.
1 The goal is to provide a framework for inference of the mechanisms and parameters of the key elements in the multi-class system, utilizing only the aforementioned external measurements.
In particular, we develop a hypothesis test to identify the basic scheduling algorithm as SP, EDF, or WFQ.
We devise techniques to estimate the maximum-likelihood values of the class parameters, such as "guaranteed rate" in WFQ or deadlines in EDF and rate limiters in non-work-conserving servers.
Here we describe a general arrival characterization which can be applied to the multi-class inference problem.
The technique is based on traffic envelopes which provide a unifying abstraction for both arrivals and services and incorporate the system's behavior across time scales [16].
Measurement at multiple time scales is important in this context as different system components are most accurately detected at different time scales.Focusing on a single class for illustration, Figure Denoting the total arrivals in the interval"# ¤ £ $ # & % ( ' 0 ) by 1 2 "# ¤ £ 3 # & % ' 0 ), a traffic envelope refers to a time invariant characterization of the arrivals as a function of interval length ' (see [22] for examples of deterministic envelopes).
For a measurement window "# 4 £ 3 # 5 % 7 6 8 ) and a particular interval length 9 ¦ beginning at time @ In the case of web servers (both single node and distributed), both arrivals and departures are directly observable from the system's front end (see [1], [11] for a detailed description of such an architecture).
In the case of networks, packet time stamping provides a mechanism to observe both arrival and departure times at the departure node [17]; otherwise, the measurement modules can communicate their collected information off-line.
and# A % C B D © ¢ F E G 9 § , class H 's arrival rate is given by I Q P RS R U T 1 P "# % V B W © ¢ F E X 9 ¦ Y £ ` # % a b 9 ¦ c ) 9 ¦ for T ¢ ¤ £ ¦ ¥ ¦ ¥ § ¥ ¦ £ $ d ,I    P RS T ¢ d 2 t  u w y x   B I Q P s RS R © r I Q P RS E G (2)In Section III, we describe how this empirical class-based arrival envelope is incorporated into the above multi-class inference problems, and in Section IV, we experimentally investigate applications of this traffic characterization.
Here, we describe a general mechanism for measuring and characterizing a class' service rate.
Analogous to the traffic envelope, the service envelope is not simply a single service bandwidth, but a statistical characterization of service across time scales.
This multiple-time-scale characterization is critical to inference of diverse service components such as maximum policed bandwidth, minimum service, and analysis of inter-class resource sharing relationships.
Moreover, its statistical nature reflects the fact that a class' service can fluctuate according to the varying demands of other classes and the mechanism by which the scheduler arbitrates this demand.The empirical service envelope characterizes the service rate received by the flow as a function of the interval length over which the class is backlogged, where a flow is said to be backlogged whenever it has at least one packet in the system.
A traffic flow is continuously backlogged for ¡ packet transmissions in the interval " , the service rate received in£ $ !
y  F   ) if !
y      y        £ for all  U      ¡ 2 © d  £ for ¡ f e g  ."
# 4 £ 3 # A % q ' 0 ) is simply I P Rn B ' X E T l P "# ¤ £ $ # A % q ' 0 ) ' o (3)Finally, the measurement for each backlogged interval is included in the measurementp I q P Rn if B ¡ 2 ©  or E G 9   s '  t B ¡ % u  o v r E X 9  o(4)Measured service envelope samples p I q P Rn are used in inferring scheduling discipline, as explained in detail in the following Section.
2 As described above, our goal is to infer the elements and parameters of a multi-class system.
In Part A we consider the server and in Part B the rate limiters as defined in Figure 3.
In a multi-class system, the packet service discipline defines the inter-class relationships or the service received when different classes compete for resources.
For example, with an SP scheduler, the highest priority class receives all demanded service up to the available link capacity, and in that way is completely isolated from other classes' demands.
In contrast, lower priority classes utilize only remaining capacity from higher priority classes and their performance is strongly dependent on these classes' demands.Here, we provide a precise theoretical description of such inter-class relationships via statistical service envelopes.
Under a particular scheduler hypothesis, we perform Maximum Likelihood Estimations (MLEs) of the scheduler's parameters, such as guaranteed rates in WFQ and deadlines in EDF.
Using the envelope's ideal description of a class' service, we then develop hypothesis tests to infer which service discipline is employed by the system via statistical analysis of the empirical inter-class sharing relationships.
Finally, we select the MLEs of the unknown parameters under the inferred scheduler.
w Notice that for convenience, the arrival envelope is discretized in time and the service envelope is discretized in bits.
However, to perform the comparative computations of Section III, both are expressed in discrete time rates with service interpolated.
In [16] for which the class is continually backlogged.
Table I shows the statistical service envelopes (derived in [16]) for SP, WFQ, and EDF.
The envelopes are a function of the link capacity , and as described above, the other class' input traffic, described by the arrival envelope The key problem is then to assess the system's scheduler, parameters, and other components by comparing empirical measurements with the idealized relationships.
P B s ' X E    1 P "# ¤ £ $ # 5 % g ' 0 ) .
Here, we describe the expected distributions of service for a given arrival distribution under different service disciplines.
For simplicity, we consider a two-class system and aggregate traffic1 P "# 4 £ 3 # % 2 ' 0 )with a Gaussian distribution.
4 Notice that even under Gaussian arrivals, the service envelopes will be non-Gaussian due to the non-linearities of the multi-class server.
With two traffic classes, SP is a special case of WFQ with as the class- delay bound, as opposed to a departure time as in the previous section.
The Gaussian assumption is not necessary for traffic envelopes; see [5] for example.
Regardless, we make the assumption in this paper as it makes our solution more computationally efficient while also retaining a high degree of accuracy, both for our purposes here as well as in other scenarios such as admission control [12].
Table I, we have that the probability density function of ~ P under the EDF hypothesis is given by ~ P B s ' & % q  P E SP  { U B '  % q  P E © | P    x     B s ' & % q  P E G   WFQ x P U B s ' & % d  P E & %  B G ¢ © x P E y U B s ' & % q  P E © |    x P   B s ' & % q  P E   EDF  U B '  % q  P E © |    x P   B ' © ! 
% u !
P E   « & ¬  n z u B ¥ E T C  B ¢  2  s  b E G  B ¥ E $ % ¤ u B s ¥ ¦ E X 9  B     u ¥ f  7 Q 9 ¦ 4 E & %  B  ¢  e Q 9 ¦ i E X  B s ¥ © Q 9 ¦ ¤ E oExamples of empirical class service rate distributions for WFQ and SP servers are presented in Figures 5 and 6.
The interval length 9 ¦ is 400 msec and additional parameters such as traffic load and statistical workload characterization are given in Section IV.We make several observations about the figures.
First, the service distribution of WFQ visibly exhibits the truncated behavior defined by Equation (5): this is due to WFQ's guaranteed rate which lower bounds the service.
Second, observe that no such "hard" lower border exists for SP without strict rate limiters on all higher priority traffic classes.
Finally, notice that upper limits on the density functions are not evident here, as in this case, neither class reached its upper limits due to statistical fluctuations in the demand of the other class.
Here, we describe how a scheduler's parameters such as weights in WFQ and deadlines in EDF can be estimated under the hypothesis of a particular scheduler EDF, WFQ, or SP.
We employ the Generalized Likelihood Ratio Test by first obtaining Maximum Likelihood Estimates of unknown parameters under each hypothesis, and then using the likelihood ratio test.
We then show how the scheduling mechanism itself can be inferred by choosing the more likely hypothesis as the true one.
Finally, the MLEs of unknown parameters under the chosen hypothesis become the final estimates.
(6) is as follows.
The relative class weight estimation can be performed only over time intervals when both classes are backlogged since it is only during such intervals that both classes incur their lower bounds in service.
Such intervals cause peaks at the lower clipping of the service rate distribution (cf. Figure 5) and also maximize the joint distribution of Equation (6).
For EDF, similar expressions can be derived by applying the same methodology of using the EDF service envelopes to compute the MLE expressions for the class delay bounds, and performing a grid search to estimate ¯ !
 and ¯ !
.
The above technique allows estimation of a scheduler's parameters under the hypothesis of particular scheduler.
Here, we show how the scheduling policy itself can be inferred.
The key technique is to choose the hypothesis that makes the measured service observation most likely.To infer which service discipline is the most likely under the observations, for each time scale 9 ¦ , we have the scheduler hypothesis test given by« & ¬  B ¸ p I  Rn 9 ¦ i E s «  ¬  B  p I Rn 9 ¦ ¤ E ¸  U    B ¸ p I Rn 9 E s   U  &  B  p I Rn 9 E  » Y ¼ ³ ½ ¾ ¿ À ½ b Á ¢ o(7)As all time scales are not guaranteed to infer the same scheduler, the final decision is made by using majority rule over all time scales.
With this technique, the correct inference is attained 94% to 100% of the time in our experiments.Thus, the service envelopes of Table I describe particular rules for inter-class resource sharing, i.e., the mechanism by which the scheduler allocates capacity when multiple traffic classes are competing for resources.
Applying the above hypothesis test determines which scenario is most likely, considering multi-class measurements across all time scales.
Thus far, we have considered work-conserving service disciplines.
Here, we develop a measurement methodology applicable to rate-limiters, i.e., non-work-conserving elements which limit a flow's arrivals to within a pre-specified constraint.
For a single token bucket with a bucket depth of one packet, the rate limiter for class H is characterized by an unknown rate Â P .
The key problem is to distinguish such a limit on class H 's service from throughput limits due to the workloads of other traffic classes and other mechanisms in the multi-class scheduler.Thus, the goal is to find the maximum likelihood estimation of Â P under the hypothesis of a particular scheduler (inferred as above).
With rate limiters, the service envelopes of Table I have Â P in place of as the maximum service rate.
Thus considering the EDF hypothesis as an example, the maximum likelihood estimation of Â P can be computed asB ¯ Â P £ ¯ !
 £ ¯ !
E T argmax Ã z u RÄ ° RÄ ¹ « & ¬  B ¸ p I  Rn 9 ¦ Y £ ` p I Rn 9 ¦ ¦ ²Â P £ y !
 £ y !
E o(8)Estimation of rate limiter parameters highlights the importance of time scales.
This is illustrated in Figure 7 which depicts the probability that a class transmits at the rate limiter's bound as a function of interval length.
The scenario is a two-class classbased fair queueing scheduler with class weights of 0.5.
The classes have 60 and 40 exponential on-off flows with peak rate 32 kb/sec.
The figure shows the empirical probability that the aggregate traffic of class 1 transmits at its rate limit of 1 Mb/sec as a function of interval length.
As shown, for short time scales this occurs quite frequently whereas it is increasingly rare over longer time scales.
While this property is an inherent characteristic of any variable rate flow, the key point is that inference of rate limiter parameters at long time scales is inhibited by flows becoming less and less likely to send at peak rates for sustained periods.
As a consequence, measurement of multi-level leaky buckets, which require longer time scale measurements due to traffic constraint functions which shape the traffic differently at different time scales (see [23] for example) will incur higher measurement errors.
In this section, we perform a set of simulation experiments to evaluate the effectiveness of the multi-class inference tools described above.
We study WFQ weight estimation, inference of the service discipline for EDF, SP, and WFQ , as well as "measurable regions", the conditions necessary to obtain accurate estimates of WFQ weights.All simulations are performed with the ns-2 simulator with a single router and various numbers of hosts in the topology of Figure 3.
The link capacity is 1.5 Mb/sec and packet sizes are 500 and 100 bytes, as specified in the various experiments.
The minimum interval length for measuring arrival and service envelopes is 9  = 10 msec and the maximum interval-length for measurement is 0.5 sec for a 50-point arrival envelope.
The measurement window 6 is varied in the experiments from 2 to 10 seconds as indicated.
We consider two traffic classes and EDF, WFQ, and SP scheduling.
Here we experimentally investigate the statistical properties of the WFQ weight estimation algorithm.
In this scenario, the system has 65-68 flows exponential on-off sources with on-rate 32 kb/sec with on and off periods of 0.36 sec.
Moreover, there are 25-28 sources of the same type for class 2.
The true WFQ weights are x  = 0.7 and x = 0.3.
The packet size is 500 Bytes.
In the experiments, 50 simulation runs were performed corresponding to each data point in Figure 8.
For a particular simulation, the measurement window 6 is set to 2, 5, or 10 seconds as reported on the horizontal axis.
Each point on the plot indicates the maximum likelihood estimation of x  , ¯ x  , using the methodology of Section III.First observe that the variance of the estimator is reduced with increasing 6 , due simply to the fact that more sample points are available with larger 6 .
For example, with 6 = 2 sec, 95% of the weight estimations are within 11% of the true value, whereas with 6 = 10 sec, 95% of the weight estimations are within 1.4% of the true value.
However, 6 should not be set arbitrarily large, as longer-time-scale fluctuations due to flow arrivals and departures may introduce non-stationarities which would bias the tests.
While the number of flows in the system did vary in these simulations, as defined above it is within a range of 5 to 10% of the system load.
As described in Section III, the above WFQ weight estimations can only be performed under the hypothesis that the server is WFQ.
Thus, statistical tests are necessary to infer the scheduling mechanism itself.
Here we describe simulation experiments for scheduler inference using the same number of sources for each class and the same packet size as in the previous experiment.
Figures 9 and 10 depict the experimental probability of correct decision vs. time scale for the respective correct hypothesis of EDF and WFQ respectively.
In both cases, 50 simulations are performed and the probability of correct decision is computed as the number of correct decisions versus total number of tests for each time scale (recall the final decision is performed by majority rule).
For the experiments of Figure 9, the correct hypothesis is ED-F with delay bounds of !
 = 20 msec for class 1 and !
= 40, 60 and 80 msec for the three curves for class 2.
As indicated in the figure, EDF is correctly inferred 100% of the time at short time scales (9 up to 300 msec) while less frequently for longer interval lengths, especially as !
© !
 decreases.
Yet in all cases the probability of correct decision is no less than 92%.
The reason that the probability of correct decision decreases as !
© !
 decreases, is that there is less and less differentiation provided by the scheduler, making the service envelopes statistically closer, and the inference problem more difficult.
Indeed, if !
T !
 , the scheduler is actually performing FCFS, as is also evident from the service envelope in Table I.Regardless, in all cases, the correct final decision is made as majority rule is performed over different time scales, and incorrect decisions at a particular time scale are never frequent enough to form a majority.
Figure 10 depicts the experimental results for WFQ.
Observe that in this case, the correctness ratio is quite poor on shorter time scales.
This is due to the mismatch between the fluid approximation used in the analytical model and the packet-level simulations.
In particular, over short time intervals, the fluid approximation does not hold and not every packet gets serviced at rate x P (indeed, see [2] for a detailed discussion of such shorttime-scale unfairness).
In this case, such errors impact the final decision and the overall correctness probability is 0.94 (less than the correctness of 1 achieved in the EDF case) as the short-timescale errors form a majority in 6% of the cases.Finally notice that the relationship of the probability of correct decision and time scale are reversed for WFQ as compared to EDF.
The reason for this is that over longer time scales, WFQ overcomes packet level unfairness and, when flows are backlogged for long durations, it can become quite clear (statistically) that there is a minimum guaranteed service rate clipping the distribution of the service envelope.
In contrast, for EDF, the differences are most pronounced for small interval lengths where the shifts in the arrival envelopes (cf. Table I) are more prominent.
The methodology presented in this paper is based on passive measurements, i.e., no probing packets are transmitted to modify the system's workload.
However, with passive monitoring, it is possible that other classes' particular workloads prohibit inference of certain network elements.
For example, in the extreme case that all other classes are idle, it is impossible to detect a guaranteed minimum rate.
Similarly, the multi-class nature of the scheduler itself would not be measurable, and only ratelimiter parameters could be obtained.
We refer to the required workload to measure a particular network behavior as the measurable region.Here, we address the issue of the conditions necessary to infer lower and upper service limits for WFQ schedulers.
For the simulations, each flow has on and off periods of 0.36 sec and on-rate 32 kb/sec.
The packet size is 100 bytes and = 1.5 Mb/sec.
Figure 11 depicts the resulting measurable regions for WFQ weight estimates.
Each point represents the minimum number w1=0.5 WFQ, w1=0.7 WFQ, w1=0.9 Fig. 11.
Measurable Region for Lower Service Bounds of class 1 and class 2 flows needed such that the relative weights can be estimated within 5% of their correct value.
That is, if either class has fewer flows then indicated by this measurable region, then estimation is not possible, as the conditions required for weight estimation occur too rarely.Observe that as the weight of class 1 increases from x  of 0.5 to 0.7 and 0.9 (corresponding to the three curves), the curves shift to the lower right indicating that a higher number of class 1 flows and lower number of class 2 flows are needed to infer x  .
The reason for this is that as x  becomes larger, a higher traffic load in class 1 is required to backlog class 1 sufficiently to estimate the guaranteed rate.Finally, observe that a typical point on the curve refers to a relatively modest resource utilization.
For example, under x  = 0.7, at least 30 class 2 flows are required when 46 class 1 flows are present.
This corresponds to an average system utilization of 62%, i.e., the mean utilization must be at least 62% to perform the measurements passively, otherwise active probing is required.
Networks and servers are increasingly providing quality-ofservice functionalities.
The goal of this paper is to provide a framework for clients of multi-class services to assess a system's core QoS mechanisms.
We developed a scheme for clients to perform a series of hypothesis tests across multiple time scales in order to infer the packet service discipline among classbased weighted fair queueing, earliest deadline first, and strict priority.
For a particular scheduler, we devised techniques for clients to obtain maximum likelihood estimations of the system's class differentiation parameters, such as WFQ weights and EDF delay bounds.
Finally, we showed how parameters of nonwork-conserving elements such as rate limiters can be estimated.
Throughout, we utilized a general multiple-time-scale traffic and service model to characterize a broad set of behaviors within a unified framework.In future work, we plan to design mechanisms to coordinate the end-point measurements of the modules depicted in Figure 2 and generalize the system model of Figure 3 to consider multiple
