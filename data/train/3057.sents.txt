Large-scale datacenters (DCs) host tens of thousands of diverse applications each day.
Apart from determining where to schedule workloads, the cluster manager should also decide when to constrain application admission to prevent system oversubscription.
At the same time dat-acenter users care not only for fast execution time but for low waiting time (fast scheduling) as well.
Recent work has addressed the first challenge in the presence of unknown workloads, but not the second one.
We present ARQ, a multi-class admission control protocol that leverages Paragon, a heterogeneity and interference-aware DC scheduler.
ARQ divides applications in classes based on the quality of resources they need and queues them separately.
This improves utilization and system throughput, while maintaining per-application QoS.
To enforce timely scheduling, ARQ diverges work-loads to a queue of lower resource quality, if no suitable server becomes available within the time window specified by its QoS.
In an oversubscribed scenario with 8,500 applications on 1,000 EC2 servers, ARQ bounds performance degradation to less than 10% for 99% of workloads, while significantly improving utilization.
An increasing amount of computing is performed in the cloud, primarily due to cost benefits for both the endusers and the operators of datacenters (DC) that host cloud services [3].
The operator of a cloud service must schedule the stream of incoming applications on available servers in a resource-efficient manner, i.e., achieving fast execution (user's goal) at high resource utilization (operator's goal).
This scheduling problem is particularly difficult for several reasons, including diverse application characteristics [3,19], insufficient workload knowledge, co-scheduled application interference and platform heterogeneity.
An additional challenge occurs during periods of adversarial traffic, i.e., intervals with very high load, when the system can become oversubscribed, resulting in poor performance.
Most DCs employ some admission control to minimize such effects.DC users are interested in two performance metrics; how fast the application starts running (waiting time) and how fast it completes thereafter (execution time).
While recent work has shown how to improve execution time in the presence of unknown workloads, varying interference sensitivities and heterogeneous servers [14], it does not solve the "head of line blocking" problem [27].
Additionally, some applications have strict scheduling deadlines, while others can tolerate delays in order to be assigned to preferred servers.
In all cases, resource requirements should be taken into account at admission point [8].
We propose ARQ (Admission control with Resource Quality-awareness), a QoS-aware admission control protocol that builds on Paragon and accounts for the resource quality an application needs to preserve its QoS.
Resource quality reflects the additional load a server can support without violating application QoS, given its configuration and the applications it currently hosts.
ARQ divides workloads to multiple classes and directs them to different queues.
This way demanding workloads do not block easy-to-satisfy applications, as they wait for an appropriate server to become available.
On the other hand, since DC applications have strict QoS guarantees, they can only be queued for limited amounts of time, while waiting for an appropriate server.
ARQ detects when an application is about to violate its performance requirements and re-directs it to a different queue before the QoS violation occurs.
We explore the trade-off between waiting time and quality of resources and solve the corresponding optimization problem to find the optimal switching point.We evaluate ARQ both in small and large-scale experiments.
First, we compare the system without and with ARQ in a local cluster with 40 machines and show the benefits in performance and efficiency.
We also evaluate ARQ on a 1000-server cluster on Amazon EC2.
For an oversubscribed scenario with 8500 applications, Paragon with ARQ guarantees that 99% of workloads have less than 10% performance degradation, while improving utilization by 46%.
Paragon is a heterogeneity and interference-aware DC scheduler [14].
It assigns applications to heterogeneous servers based on the platform they benefit from and the co-scheduled applications that minimize destructive interference to preserve QoS.
Paragon has two components, a classification engine and a greedy scheduler.
We briefly describe their operation in the following paragraph.The first component of Paragon performs fast classi-fication of incoming applications, in terms of the server configuration (SC) they perform better on and the interference they cause and tolerate in various shared resources, such as the processor, cache hierarchy, memory, storage and networking subsystems.
The interference profile is obtained through targeted microbenchmarks of tunable intensity that create contention in specific shared resources.
These microbenchmarks are called sources of interference (SoIs).
The classification engine is built as a recommendation system, similar to Netflix [5] or e-commerce systems and leverages the knowledge the system already has about previously-scheduled applications, keeping profiling overheads low.
Then, the greedy scheduler searches for a machine of desired SC, that minimizes destructive interference between existing and new load.
Paragon scales to tens of thousands of applications and improves utilization, while maintaining per-application QoS.
While Paragon shows that accounting for heterogeneity and interference improves resource efficiency without QoS losses, it does not decide when applications should be admitted and scheduled.
Paragon accounts for workload characteristics to decide where to assign a workload, but it does not solve the "head of line blocking" problem that can cause high waiting times.
By default, applications are scheduled in a simple FIFO order.
This has two shortcomings; first, easy-to-satisfy workloads can get trapped behind demanding applications, e.g., workloads that require exclusive instances of high-end, multi-socket servers to preserve their QoS.
Second, in the event of an oversubscribed scenario, i.e., when the required resources are more than the total resources available in the system, Paragon implements an application-agnostic admission control protocol.
It queues applications in a single queue until the first server becomes available, and then resumes FIFO-ordered scheduling.
This ignores the fact that applications need resources of a certain quality to meet their QoS, and can result in performance degradation.
Large cloud providers such as Amazon EC2 and Windows Azure, typically deploy some admission control protocol.
This prevents machine oversubscription, i.e., the same core servicing more than one applications, resulting in high interference and QoS violations.
We design ARQ, a QoS-aware admission control protocol that queues and schedules applications based on the quality of resources they need.
This solves two problems; first, applications that demand few, easy-to-satisfy resources are not blocked behind demanding workloads.
Second, if no suitable servers are available for a given application, the workload waits for a server of appropriate quality to be freed.
Alternatively, the application would be directed to the first free server to avoid queueing delays, with the risk of performance losses.
Resource quality: The resource demands of a workload reflect the load a server should support for the application to meet its QoS.
This is a function of the interference the server can tolerate from the new application, and the interference the new workload can tolerate from applications already running on the machine.
We use the classification engine in Paragon to derive the per-server tolerated (t i ) and caused (c i ) interference over a set of shared resources.
Shared resources include the cache and memory hierarchy, CPU modules, and storage and networking devices.
Details on how c i 's and t i 's are obtained can be found in [14].
The interference profile of a server is updated upon initiation or completion of an application's execution.
Similarly, upon application arrival, an interference profile is obtained for each new workload.
This information guides scheduling decisions by assigning applications to suitable servers.
Given the interference profile of a server or application, we define resource quality as:Q i = avg( ∑ i c i + ∑ i (100 − t i ))(1)where c i and t i are summed over all shared resources for which interference is measured.
Conceptually, higher Q i reflects applications with high demands (high caused and low tolerated interference) that need high-quality system resources.
Low Q i on the other hand, corresponds to workloads that are insensitive to interference, and can satisfy their QoS even when assigned to servers with poor resource quality, e.g., highly-loaded machines, or machines with few cores.
Multi-class admission control: We design ARQ as an admission control protocol with multiple classes of "customers" [1,6,17,20,21], where customers in this case correspond to applications.
The class an application belongs to is determined by its Q i value.
Applications with Q i values that fall in the same range are assigned to the same class.
Q i s range from 0 to 100%.
We assume ten classes of applications for now, and justify this selection in the evaluation section (see sensitivity study in Section 5).
Fig. 1 shows an overview of ARQ.
Each queue corresponds to applications of a specific class.
From top to bottom we move from more to less demanding applications.
Upon arrival, the cluster manager determines the class an application belongs to and queues it appropriately.
Each class has a corresponding server pool of appropriate resource quality.
Separating applications based on their resource quality requirements helps ARQ resolve bottlenecks where applications that are sensitive to interference block workloads that are not.
On the other hand, applications cannot be queued indefinitely waiting for the perfect server.
We address this issue by diverging workloads to queues with better or worse resource qualities.
Diverging an application to a different queue creates a trade-off between the time an application is waiting in a queue, and the quality of resources it is allocated.
We approach this trade-off as an optimization problem.
Queue bypassing: When there is no available server in the pool of a class, queued workloads should be diverged to another queue.
There are two possible options for where a workload can be redirected.
First, it can be diverged to a higher queue.
If the queue directly above the queue the workload was originally placed in is empty, the workload is assigned to one of its servers.
This hurts utilization, since resources of higher quality than necessary are allocated, but preserves the workload's QoS requirements.
In the opposite case the workload is diverged to a lower queue.
In that case, performance may be degraded, since the application receives resources of lower quality than required.
However, the scheme guarantees that in all cases the application will be assigned to a server within the time window dictated by its QoS constraints.
Free-server probability distributions: ARQ needs to know the likelihood that a server of a specific class will become available within the time an application can be queued for, to decide when the workload should be diverged to the next queue.
We statistically analyze the server busy time periods for each server pool to obtain these probability distributions.
Busy periods are defined as the per-server time intervals from the moment a server is assigned a workload, until that workload completes.We first use distribution fitting to represent the per-pool server busy time in a closed form using known distributions.
Fig. 2a shows the CDF of server busy time for the first server pool (highest quality servers) in a 1,000 server experiment.
More details on the methodology can be found in Section 4.
We show the experimental data (dots) and the closed form representation, derived from distribution fitting.
In this case, the data is fitted to a curve resembling a normal distribution.
The CDF reflects the fraction of servers that are freed within some time after they have been allocated to an application.
For example, 60% of servers in this server pool are freed within 2700 sec from the time an application is scheduled to them.Using this closed form CDF we easily derive the freeserver CDF, which reflects the probability that within a time interval from an application's arrival, at least one server of the corresponding pool will be available.
Fig. 2b shows the free-server probability CDF for the first server pool.
The highlighted point shows that there is a 60% probability that within 56 sec from an application's arrival to that queue, there will be at least one free server in the pool.
Free-server CDFs are updated during workload execution to capture changes in application behavior.
Switching between queues: ARQ determines the switching point between queues with the objective to maximize the probability that a server becomes available within a certain window from an application's arrival.
For simplicity of explanation we assume that an application's QoS is defined at 0.95x of the application's optimal performance.
This means that the workload can tolerate at most a 5% performance degradation.
Scheduling deadlines or queries-per-second (QPS) can also serve as queueing constraints.
Given the free-server CDFs for each server pool, ARQ solves the following optimization problem for application a, switching between queues i and j:max {(S a − wt i (t)) · Q i · Pr i [t], (S a − wt j (t)) · Q j · Pr j [t]} s.t. (wt i (t) + wt j (t) + P a ) < 0.05 ·CT awhere Pr i [t] is the probability that there is a free server in queue i, Q i is the resource quality of queue i, CT a is the optimal execution time for application a, P a is the classification overhead of Paragon, and S a = 1.05 ·CT a − P a is the available "slack" that can be used for queueing, before the application violates its QoS constraints.
ARQ finds the switching time that maximizes the probability that a server of either queue i or j will become available such that the application preserves its QoS guarantees.
It also promotes waiting longer for a server of the same class rather than eagerly switching to the next queue (Q i > Q j ).
GHz, cores, L1(KB), LLC(MB), mem(GB) # Xeon L56091 In our analysis we assume batch, single-node applications.
In the case of interactive or transactional workloads additional care must be taken to accommodate load changes, e.g., through VM migration.
The scheduler detects such changes and adjusts workload placement to preserve QoS.
Detection is based on SoI injection and application reclassification.
Server systems: We evaluated Paragon on a 40-machine local cluster (Table 1) and a 1000-machine cluster with 14 server types on EC2.
We used exclusive (reserved) server instances, i.e., there is no interference from external workloads.
We also verified that no external scheduling decisions or actions such as auto-scaling or migration are performed during the course of the experiments.
Schedulers: We compared Paragon with ARQ to four schedulers.
First, Paragon without admission control, second, a heterogeneity-oblivious scheme that only accounts for interference but not heterogeneity.
Third, an interference-oblivious scheme and finally, a scheduler that is both heterogeneity and interference-agnostic, and assigns applications to least-loaded machines.
Workloads: We used 29 single-threaded, 22 multithreaded, 350 multi-programmed and 12 I/O-bound workloads.
We use the full SPEC CPU2006 suite and workloads from PARSEC [7], SPLASH-2 [32], BioParallel [18], Minebench [22] and SPECjbb.
For multiprogrammed workloads, we use 350 mixes of 4 applications each [26].
The I/O-bound workloads are data mining applications in Hadoop and Matlab.
For scenarios with more than 413 applications we replicated these workloads with equal likelihood and randomized their interleaving.
Workload scenarios: For the small-scale experiments we examine three workload scenarios.
First, we examine a low-load scenario with 178 applications, selected randomly from the workload pool, and submitted with 10 sec inter-arrival times.
Second, a high-load scenario where 178 applications arrive following a Gaussian distribution (µ=10, σ 2 =1) that experience significant phases during their execution.
Finally, we examine a scenario, where 178 applications arrive with 1 sec intervals.
This is an oversubscribed scenario, since after a few seconds there are not enough resources to execute all applications concurrently.
For the large-scale experiments on EC2 we examine an oversubscribed scenario where 7,500 workloads arrive with 1 sec intervals and an additional 1,000 applications arrive in burst after the first 3,750 workloads.
Performance: Fig. 3 shows the performance comparison between the different schedulers for the second and third scenarios in the small-scale cluster.
The differences for the low-load scenario where resources are plentiful are small.
We focus on the differences between Paragon without and with the use of ARQ.
Applications are ordered from worst to best performing.
For the scenario with workload phases the applications that preserve their QoS increase from 66% to 91%, and the average performance improves to 99.3%.
For the oversubscribed system, while without ARQ only 64% of applications maintain their QoS, with ARQ 88% of workloads preserve their performance requirements.
This shows that accounting for resource quality at admission point drains the backlog of queued workloads much faster.
Overheads: ARQ limits waiting time to preserve QoS.
Fig. 4 shows the breakdown of execution time for selected applications in the oversubscribed scenario.
Time is divided in useful execution time, overheads from training and classification, overheads from the greedy server selection [14] and overheads from queueing.
mcf and blackscholes do not have a bar for the least-loaded (LL) scheduler because they did not complete successfully due to memory exhaustion in the server.
In all cases overheads are very low and execution time for most workloads is very close to one (optimal).
The overheads from queueing are less than 5% at all times.
The cases where queueing is high correspond to workloads that had to be diverged to queues of lower resource quality, in which case useful execution time is also suboptimal.
Resource allocation: Fig. 5a shows the required versus allocated core count for Paragon with and without ARQ for the oversubscribed scenario.
Once the system enters the oversubscribed phase ([9000-17000]sec), Paragon without ARQ allocates all available cores and then queues applications, while Paragon with ARQ will only dispatch applications if an appropriate server is freed.
This drains the backlog faster since, even though applications are queued for longer, they run in higher quality platforms.
Server utilization: We also measure server utilization before and after the use of ARQ.
We focus on the oversubscribed scenario where ARQ has the highest impact.
Paragon without ARQ improves utilization by 47% compared to a LL scheduler.
Adding ARQ slightly reduces this improvement since applications are queued instead of being dispatched immediately.
Despite this, utilization still improves by 45.5%.
This means that the performance benefits of ARQ do not incur an efficiency penalty.
Sensitivity to design parameters: Fig. 5b shows the performance -utilization tradeoff for different numbers of queues.
Both metrics are normalized to the values for 10 queues.
More queues result in fewer cases of workloads being blocked behind demanding applications, therefore they improve performance, but reduce the number of servers in the corresponding pools, hurting utilization.
In contrast, few queues revert to the default scheduler where many applications are scheduled in FIFO order, increasing utilization and hurting performance.
10 queues achieve both high performance and efficiency.
Large-scale experiments: Fig. 6 compares the performance of the different schedulers for the large-scale scenario.
While Paragon without ARQ only preserves QoS for 61% of workloads, introducing admission control increases that fraction to 83%.
Additionally, it bounds degradation to less than 10% for 99% of workloads.
This shows that the protocol scales well with the number of servers and applications, while maintaining overheads similar to the ones for the small-scale experiments.
We have presented ARQ, a QoS-aware admission control protocol for heterogeneous datacenters.
ARQ divides applications to classes based on their resource quality requirements and queues them separately in a multi-class network.
ARQ is derived from validated queueing models, and it improves system throughput by reducing application waiting time, and diverging workloads to different queues when necessary.
In an oversubscribed scenario with 8,500 applications on 1,000 servers, 99% of workloads experience less than 10% degradation compared to 79% of workloads without ARQ.
We sincerely thank Christopher Stewart, Daniel Sanchez, and the anonymous reviewers for their feedback on earlier versions of this manuscript.
Christina Delimitrou was supported by a Stanford Graduate Fellowship.
