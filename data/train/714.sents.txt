This paper presents a new MRF optimization algorithm, which is derived from Linear Programming and manages to go beyond current state-of-the-art techniques (such as those based on graph-cuts or belief propagation).
It does so by relying on a much tighter class of LP-relaxations, called cycle-relaxations.
With the help of this class of re-laxations, our algorithm tries to deal with a difficulty lying at the heart of MRF optimization: the existence of inconsistent cycles.
To this end, it uses an operation called cycle-repairing.
The goal of that operation is to fix any inconsistent cycles that may appear during optimization, instead of simply ignoring them as usually done up to now.
The more the repaired cycles, the tighter the underlying LP relaxation becomes.
As a result of this procedure, our algorithm is capable of providing almost optimal solutions even for very general MRFs with arbitrary potentials.
Experimental results verify its effectiveness on difficult MRF problems, as well as its better performance compared to the state of the art.
Optimization algorithms for discrete MRFs are known to be of fundamental importance for numerous problems from the fields of vision, graphics and pattern recognition.
It is also known that many of the most successful of these algorithms are tightly related to Linear Programming (LP) [1][2] [3][4] [5][6] [7].
In particular, they are connected to the following LP relaxation P(¯ g, ¯ f ):P(¯ g, ¯ f ) = min x p∈V ¯ g p · x p + pp ′ ∈E ¯ f pp ′ · x pp ′ ,(1)s.t.l∈L x p (l) = 1, ∀ p ∈ V (2) l ′ ∈L x pp ′ (l, l ′ ) = x p (l), ∀ pp ′ ∈ E, l ∈ L(3)x p (l) ≥ 0, x pp ′ (l, l ′ ) ≥ 0.
(4)The connection between P(¯ g, ¯ f ) and MRFs lies in that if one replaces (4) with the constraints x p (·), x pp ′ (·, ·) ∈ {0, 1}, then the resulting integer program optimizes the energy of an MRF with unary potentials ¯ g p = {¯ g p (·)} and pairwise potentials ¯ f pp ′ = { ¯ f pp ′ (·, ·)}.
This MRF will be denoted by MRF(¯ g, ¯ f ) hereafter and L, V, E (in (2), (3)) represent respectively its labels, graph vertices and graph edges.Despite their success, LP-based methods are doomed to fail if relaxation P(¯ g, ¯ f ) does not approximate well the actual problem MRF(¯ g, ¯ f ) (i.e, it is not tight), which is exactly what happens when one has to deal with very hard MRF problems.
We believe this is an issue that has to be addressed, if a further advance is to be made in MRF optimization.
Motivated by this observation, the present work makes important practical, as well as theoretical, contributions in this regard.
In particular, in this work we attempt to go beyond most existing MRF techniques, by deriving algorithms that are based on much tighter LP relaxations.
Towards this goal, we try to strengthen relaxation P(¯ g, ¯ f ).
However, instead of doing that in the primal domain, which is inefficient, our strategy consists of applying this procedure in the dual domain.
As a result, we create an hierarchy of tighter and tighter dual relaxations that starts from the dual of P(¯ g, ¯ f ) and goes all the way up to a dual relaxation that actually coincides with the original problem MRF(¯ g, ¯ f ) ( §2).
From this hierarchy, we choose to deal with one particular class of relaxations, which we call cycle-relaxations.
This is achieved via a dual-based operation called cycle-repairing ( §3), which helps us to deal with a difficulty that, we believe, lies at the heart of MRF optimization: the existence of inconsistent cycles (see definition later).
As the name of that operation reveals, its role is to eliminate any inconsistent cycles that may appear during optimization.
Furthermore, the more the repaired cycles, the tighter the underlying relaxation becomes.
One efficient way of how one can actually do this cycle-repairing is described in §3.1, thus leading to a powerful algorithm that further promotes the use of general MRFs in future vision applications.Let us note at this point that Sontag and Jaakkola [8] have very recently tried as well to make use of a tighter LP relaxation for MRF optimization.
However, their method relies on a weaker relaxation than ours.
Furthermore, they use a primal-based cutting plane algorithm that requires solving a large primal LP (of growing size) at each iteration (i.e., after each new violated inequality is found), which makes their algorithm impractical for large MRFs.
On the contrary, by working in the dual domain, our method is able to improve the relaxation (cycle repairing) by reusing work done in previous iterations.
It is thus much more efficient, while it is also adaptive as it makes the relaxation tighter only when it needs to be.
Moreover, being dual-based, it can provide lower bounds to the optimum MRF energy, which can be useful for verifying a solution's optimality.
Let us also note that two other dual-based methods of similar spirit to ours, that have been proposed concurrently with our work, appear in [9] [10].
Finally, it is important to mention that, although one might be easily tempted to try to strengthen other type of MRF relaxations (e.g, quadratic or SOCP), these have been recently shown to be actually weaker than LP relaxation (1) [11].
Before examining how cycle-repairing works, let us first describe the hierarchy of dual relaxations that we will use.
At one end of this hierarchy, of course, there will lie the dual of relaxation P(¯ g, ¯ f ).
For the moment, we will simply refer to it as D(¯ g, ¯ f ).
The dual cost of any feasible solution to that relaxation is a lower bound to the optimum (i.e, minimum) energy of MRF(¯ g, ¯ f ).
However, it is often the case that even the maximum of these bounds will be much lower than the optimum MRF energy, which is exactly what happens when D(¯ g, ¯ f ) is not tight.To counter that, i.e, to raise the maximum lower bound, one has no choice but to introduce extra variables as well as extra constraints to D(¯ g, ¯ f ), which is exactly what relaxation D + (¯ g, ¯ f ), lying at the other end of our hierarchy, does:D + (¯ g, ¯ f ) = max f D(¯ g, f ) (5) s.t. f E ¯ f .
(6) In (6), we have used an abstract comparison operation E between pairwise potential functions.
In general, given any subset C ⊆ E of the MRF edges and any pairwise potential functions f , f ′ , the operation f C f ′ implies that, for each labeling l = {l p }, it should hold:pp ′ ∈C f pp ′ (l p , l p ′ ) ≤ pp ′ ∈C ¯ f pp ′ (l p , l p ′ ), ∀ l = {l p }(7)(This means that, instead of comparing pairwise potentials on individual edges, we compare sums of pairwise potentials over all edges in C).
The reason that we expressed D + (¯ g, ¯ f ) in the above form is to illustrate its relation to D(¯ g, ¯ f ).
As can be seen, one difference between D(¯ g, ¯ f ) and D + (¯ g, ¯ f ) is that the latter contains an additional set of variables f = {f pp ′ (·, ·)}, which can actually be thought of as a new set of pairwise potentials (also called virtual potentials hereafter).
In relaxation D(¯ g, ¯ f ), these virtual potentials f do not appear, as they are essentially kept fixed to the true potentials ¯ f (i.e, it is as if constraints (6) have been replaced with the trivial constraints f = ¯ f ).
On the contrary, in D + (¯ g, ¯ f ), we can vary these new potentials in order to achieve a higher dual objective value (i.e, a higher lower bound to the optimum MRF energy).
The restriction, of course, is that we must never allow f to become larger than the actual potentials ¯ f .
However, the comparison of f to ¯ f is done based not on the standard operator ≤, but on the generalized operator E .
As a result, relaxation D + (¯ g, ¯ f ) is much tighter than D(¯ g, ¯ f ).
In fact, as the next theorem certifies, it is so tight that it represents the MRF problem exactly: Theorem 1 ( [12]) D + (¯ g, ¯ f ) is equivalent to MRF(¯ g, ¯ f ).
This should, of course, come as no surprise, since D + (¯ g, ¯ f ) already contains an exponential number of constraints on f .
One may thus argue that relaxations D(¯ g, ¯ f ), D + (¯ g, ¯ f ) lie at opposite ends: D(¯ g, ¯ f ) imposes trivial constraints on f and is thus efficient but not tight, whereas D + (¯ g, ¯ f ) has an exponential number of constraints on f and is thus tight but not easy to handle.
However, one can adjust the amount of constraints on f by concentrating only on the virtual potentials at a subset C ⊆ E of the MRF edges.
Indeed, assuming that initially f = ¯ f , and that all f pp ′ (·, ·) with pp ′ / ∈ C will be kept fixed during the current step, constraints (6) then reduce to the easier upper-bounding constraints f C ¯ f , thus creating a relaxation in between D(¯ g, ¯ f ) and D + (¯ g, ¯ f ).
Contrary to f E ¯ f , constraints f C ¯ f focus only on a subset of the virtual potentials f pp ′ (·, ·), i.e, only on those with pp ′ in subset C, while the rest are left untouched.
Not only that, but, as optimization proceeds, one can choose a different local subset C i to focus on at each step.
Indeed, assuming that f ′ are the virtual potentials from the previous step, one can then simply focus on satisfying the constraints f Ci f ′ , while keeping all f pp ′ (·, ·) with pp ′ / ∈ C i unchanged (i.e, equal to f ′ pp ′ (·, ·)) during the current step (note that, together, these two things imply f E f ′ and, since f ′ E ¯ f already holds from the previous iteration, feasibility constraint (6) is thus maintained).
In this manner, different constraints are dynamically used at each step, implicitly creating a dual relaxation that becomes tighter and tighter as time passes by.
This relaxation (denoted by D {Ci} (¯ g, ¯ f ) hereafter) is actually part of an hierarchy of dual relaxations that starts from D(¯ g, ¯ f ) (e.g, if C i contains only a single edge) and goes all the way up to D + (¯ g, ¯ f ) (e.g, if C i contains all MRF edges).
Here we will deal with one particular type of relaxations from this hierarchy, where the edges from each set C i always form a simple cycle on the MRF graph.
We will call these "cycle-relaxations" hereafter.
Note that these are completely different from the more familiar cycle-inequalities relaxations, which impose constraints not on the dual but on the primal variables.Let us end this section by describing relaxation D(¯ g, f ), which forms the building block of our hierarchy.
Some terminology must be introduced first.
We will hereafter refer to each MRF vertex p ∈ V as an object, to each object-label combination (p, l) as a node and to each pair {(p, l), (p ′ , l ′ )} of nodes (from adjacent objects in E) as a link .
Relaxation D(¯ g, f ) is then defined as follows:D(¯ g, f ) = max h,r p∈V min l∈L h p (l) (8) s.t. r pp ′ (l, l ′ ) ≥ 0 ∀pp ′ ∈ E, l, l ′ ∈L(9)Here, the dual variables are all the components of vectors h, r. Each variable h p (l) will be called the height of node (p, l), while variable r pp ′ (l, l ′ ) will be called the residual of link {(p, l), (p ′ , l ′ )}.
Furthermore, if a node (p, l) has minimal height at p (i.e, h p (l) = min l ′ h p (l ′ )) it will be called minimal, while a link {(p, l), (p ′ , l ′ )} with zero residual (i.e, r pp ′ (l, l ′ ) = 0) will be called tight (see Fig. 1(a)).
As can be seen from (8), the goal of the above relaxation is to raise the heights of minimal nodes (i.e, to increase the quantity min l∈L h p (l) for each object p).
But, due to (9), this must be done without any of the residuals becoming negative.
Note, however, that heights h = {h p (·)} and residuals r = {r pp ′ (·, ·)} are tightly related to each other, since they are both defined in terms of a third set of dual variables y = {y pp ′ (·)} as follows:h p (l) = ¯ g p (l) + p ′ :pp ′ ∈E y pp ′ (l),(10)r pp ′ (l, l ′ ) = f pp ′ (l, l ′ )−y pp ′ (l)−y p ′ p (l ′ ),(11)Hence, if one adds ε to y pp ′ (l) in order to raise the height h p (l) of a minimal node, thus increasing the dual objective (8), residual r pp ′ (l, l ′ ) will then decrease by ε due to (11) and, so, (9) may become violated.
An observation (that will prove to be crucial later on) is that, due to (11), in a relaxation such as D {Ci} (¯ g, ¯ f ) or D + (¯ g, ¯ f ), one can alter a residual r pp ′ (·, ·) by changing either variables y, or potentials f .
The latter, however, is not possible in weak relaxation D(¯ g, ¯ f ), since f is assumed to be constant in this case, i.e, (11)) residuals rp 1 p 2 (a, ·) decrease by ε and thus the link between (p1, a),(p2, b) becomes tight (see red segment).
Hence, the new solution satisfies Thm.
2.
Furthermore, it satisfies Thm.
3, since a cyclic path goes through the black (i.e, minimal) nodes (p1, a), (p2, b), (p3, a).
Note also that the dual objective has increased, due to the increase by ε of the height of minimal node (p1, a).
(c) Visualization of a cycle p1p2 . . . ptp1 that is consistent to minimal node (p1, l1) (see also text).
f = ¯ f .
As we shall see later, this difference is exactly the reason why one is able to repair cycles while using relaxation D {Ci} (¯ g, ¯ f ).
l 1 p 1 … l 2 l i l t … p 2 p i p t (c) (a) In order to see how to make use of a tighter relaxation, let us first examine when relaxation D(¯ g, ¯ f ) itself is not tight, i.e, when even an optimal dual solution of D(¯ g, ¯ f ) has a lower cost than the minimum cost of MRF(¯ g, ¯ f ).
To do that, however, we will first need to characterize the optimal dual solutions of D(¯ g, ¯ f ).
Theorem 2 ( [6]) An optimal dual solution of D(¯ g, ¯ f ) must satisfy the following conditions: if (p, l) is a minimal node of object p, then for any neighboring objectp ′ there must exist a minimal node (p ′ , l ′ ) such that the link {(p, l), (p ′ , l ′ )} is tight, i.e, r pp ′ (l, l ′ ) = 0.
According to our visualization convention, this means that each minimal node must connect with a solid line to at least one minimal node from each neighboring object.
For instance, this property doesn't hold for the dual solution in Fig. 1(a), since (p 1 , a) does not have a tight link with any of the minimal nodes in p 2 , but it does hold for the dual solutions in Figs. 1(b), 2(a).
The above theorem essentially provides necessary (but not sufficient) conditions for having dual solutions which are optimal for D(¯ g, ¯ f ), i.e, which have maximum dual cost.
This means that if these conditions do not hold, one knows how to increase the dual objective by keep applying perturbations to the current dual solution (i.e, the current heights and residuals) until these conditions are satisfied.
The iterative routine used for this purpose will be called dual ascent hereafter.
Its name comes from the fact that these perturbations can only improve (i.e, increase) the dual objective, (b) To allow (p1, a) to later raise its height and possibly become non-minimal, cycle repair(p1, a) removes the blue tight link (i.e, makes it non-tight) by adding ε to potential fp 1 p 2 (a, a), thus making residual rp 1 p 2 (a, a) = ε > 0.
However, to also maintain feasibility constraint f C f ′ (where f ′ simply denotes the virtual potentials f before adding ε), it then has to add −ε to potentials fp 2 p 3 (a, a), fp 1 p 3 (a, b), thus creating 2 new tight links (red segments).
(c) cycle repair(p1, b) does the same for node (p1, b) so as to allow him to later raise its height.
As a result, a tight link (blue segment) is again removed and 2 new tight links (red segments) are created.
(d)Resulting dual solution after the 2 calls to cycle repair (same as (c), but reshown for clarity).
This solution no longer satisfies Thm.
2, since, due to the cycle-repairs, both (p1, a), (p1, b) do not have tight links with any of the minimal nodes of p2.
(e) Therefore, dual ascent can raise by ε the heights of (p1, a), (p1, b) (via adding ε to yp 1 p 2 (a), yp 1 p 2 (b), thus making all red links tight).
Hence, the dual objective increases by ε as well, and now actually coincides with the global MRF optimum.but never decrease it.
Just as an illustration, we show one such perturbation in Fig. 1.
In this case, the dual solution of Fig. 1(a) does not satisfy Thm 2, since node (p 1 , a) does not have tight links with any of the minimal nodes in p 2 .
We can therefore raise that node's height (by increasing variable y p1p2 (a) until one of these links becomes tight), thus increasing the dual objective and getting the dual solution of Fig. 1(b), which now, of course, satisfies Thm.
2 and is actually optimal for D(¯ g, ¯ f ).
Let us now return to the issue of tightness of relaxation D(¯ g, ¯ f ) with respect to problem MRF(¯ g, ¯ f ) and, to this end, let's assume that, by applying dual ascent, we have managed to increase the cost of the current feasible dual solution until Thm.
2 holds true.
When is the resulting dual cost high enough so as to have reached the minimum cost of MRF(¯ g, ¯ f ) (thus proving that D(¯ g, ¯ f ) is tight)?
The next theorem provides a sufficient condition for this.Theorem 3 ([12]) If there is a labeling {l p } such that each node (p, l p ) is min- imal and each link {(p, l p ), (p ′ , l p ′ )} is tight then D(¯ g, ¯ f ) is tight.
Hence, {l p } optimizes MRF(¯ g, ¯ f ), current feasible dual solution optimizes D(¯ g, ¯ f) and their costs coincide.
For instance, labeling {l p1 = a, l p2 = b, l p3 = a} in Fig. 1(b) is optimal (w.r.t. MRF(¯ g, ¯ f )), as it satisfies this theorem.
Visually, this can be understood by observing that there is a cyclic path in Fig. 1(b), passing only through the minimal nodes (p 1 , l p1 ), (p 2 , l p2 ), (p 3 , l p3 ).
No similar cyclic path exists, however, in Fig. 2(a), despite the fact that the shown dual solution is actually optimal to D(¯ g, ¯ f ) and satisfies Thm.
2 (this is a case where relaxation D(¯ g, ¯ f ) is not tight).
f ← ¯ f ; repeatapply dual ascent to relaxation D(¯ g, f ); get next cycle Ci = p1p2 . . . pn; f next ← {apply cycle repair to cycle Ci}; f ← f next ; until all cycles in {Ci} are consistent Indeed, if we start from any minimal node in Fig. 2(a), say, (p 1 , a) and keep traversing tight links until we return to that node, we won't be able to do that without first passing from node (p 1 , b).
We then say that cycle p 1 p 2 p 3 is inconsistent to (p 1 , a).
More generally, cycle p 1 p 2 . . . p t p t+1 (with p t+1 = p 1 ) is said to be inconsistent to minimal node (p 1 , l 1 ) if no labeling {l i } exists such that each node (p i , l i ) is minimal and each link {(p i , l i ), (p i+1 , l i+1 )} is tight (see Fig. 1(c)).
This inconsistency is, in fact, one of the main reasons why relaxation D(¯ g, ¯ f ) is often not tight (i.e, why P(¯ g, ¯ f ) may not have integral optimal solutions).
In our quest for better solutions, it is therefore crucial to figure out how to eliminate these inconsistent cycles (without, of course, reducing the dual objective).
Unfortunately, as demonstrated by the example in Fig. 2(a), this may not be possible when using relaxation D(¯ g, ¯ f ).
It is possible, however, if the tighter relaxation D {Ci} (¯ g, ¯ f ) is used.
As we shall see, the reason is that, in the latter case, if one wishes to modify the residuals (e.g, for changing whether a link is tight or not), he may modify for this purpose not only variables y = {y pp ′ (·)}, but also variables f = {f pp ′ (·)}, i.e, the virtual potentials.
The process of repairing inconsistent cycles by modifying the virtual potentials f will be named cycle-repairing, and the associated routine will be called cycle repair.Given such a routine, the following iterative strategy can then be followed (see Fig. 3): Initially, we set f = ¯ f .
Then, at each iteration, we apply successively routines dual ascent, cycle repair.
The former drives the current dual solution towards satisfying Thm.
2 for the relaxation D(¯ g, f ) at the current iteration, but it may create inconsistent cycles.
Therefore, the latter tries to repair these inconsistent cycles (thus tightening our relaxation even further), but, for this, it has to modify some residuals of the current dual solution by changing potentials f into f next .
Due to this, a new relaxation D(¯ g, f next ) is formed, which, however, violates Thm.
2 with respect to the current dual solution (dual ascent must therefore be applied to it again at the next iteration).
This process, of course, repeats until convergence, i.e, until no more inconsistent cycles exist.Note that both dual ascent and cycle repair never reduce the dual objective.
We are therefore using a dual ascent procedure, applied, however, not to weak relaxation D(¯ g, ¯ f ), but to tighter relaxation D {Ci} (¯ g, ¯ f ).
Each time cycle repair is applied, it helps dual ascent to escape from the fixed point it has previously got stuck in and thus further increase the dual objective function the next time it runs.
Hence, this essentially results in having a series of weak relaxations {D(¯ g, f k )} with f 0 = ¯ f and D(¯ g, f k ) ≤ D(¯ g, f k+1 ).
We now proceed to describe one way of implementing the cycle repair routine.
To get an intuition of how cycle repair might work, let us consider the example in Fig. 2(a).
The current dual solution is a fixed point of dual ascent (i.e, it satisfies Thm.
2), yet it has inconsistent cycles.
E.g, cycle C = p 1 p 2 p 3 is inconsistent to node (p 1 , a).
One way to repair for this is by trying to allow (p 1 , a) to raise its height, thus becoming a non-minimal node.
(if we can manage that, (p 1 , a) would then no longer be a problem as one cares only about minimal nodes when checking for inconsistent cycles).
To this end, it suffices that we find a neighboring object, say, p 2 so that node (p 1 , a) has no tight links with any of the minimal nodes in p 2 (indeed, if (p 1 , a) has tight links neither with (p 2 , a) nor with (p 2 , b), then dual ascent can later raise the height of (p 1 , a) simply by increasing the value of y p1p2 (a) until one of these links becomes tight).
Since link {(p 1 , a), (p 2 , b)} is already non-tight in Fig. 2(a), we are thus left with the task of making link {(p 1 , a), (p 2 , a)} non-tight as well (i.e, making r p1p2 (a, a) positive).
But how can we achieve that without decreasing the value of the dual objective function 3 , i.e, without decreasing the height of any minimal node?
This is impossible if we can manipulate only variables y (i.e, if relaxation D(¯ g, ¯ f ) is used), but it is easy if we can manipulate variables f as well (i.e, if we use a tighter relaxation).
Indeed, in the latter case we can make r p1p2 (a, a) equal to ε > 0 by simply adding ε to f p1p2 (a, a) (see blue segment in Fig. 2(b)).
Due to this update, however, we have violated the feasibility constrain f C f ′ (where C = p 1 p 2 p 3 ), since, for l p1 = l p2 = a and any l p3 , it then obviously holds ij f pipj (l pi , l pj ) = ij f ′ pipj (l pi , l pj ) + ε (here f ′ simply represents the virtual potentials f before adding ε).
To restore that constraint, it thus suffices that we add −ε to both f p1p3 (a, b) and f p2p3 (a, a) (see red segments in Fig. 2(b)).
In summary, the following update must be applied: f p1p2 (a, a)+= ε, f p1p3 (a, b)−= ε, f p2p3 (a, a)−= ε, which results into r p1p2 (a, a) = ε, r p1p3 (a, b) = r p2p3 (a, a) = 0.
Note that we chose to use the value ε because it was the maximum positive value for which the lowered residuals would remain non-negative after the update (as required by (9)), i.e, ε = min(r p1p3 (a, b), r p2p3 (a, a))A similar procedure can be applied for also repairing cycle p 1 p 2 p 3 with respect to node (p 1 , b) (see Fig. 2(c)).
The dual solution resulting after the above 2 cycle-repairs appears in Fig. 2(d).
As can be seen, it violates the conditions of Thm.
2 (e.g, node (p 1 , a) or (p 1 , b) has no tight links with any of the minimal nodes in p 2 ).
We can therefore reapply dual ascent, thus getting the dual solution in Fig. 2(e), which now has no inconsistent cycles and whose cost actually coincides with the global MRF optimum.
This means that, contrary to the initial relaxation, the final relaxation after the 2 cycle repairs is tight.
In general, each time we repair a cycle, we effectively make use of additional constraints and we thus tighten our current relaxation.For the general case, cycle repair may essentially mimic the procedure described above.
Let thus C = p 1 p 2 . . . p n (with p 1 = p n ) be an inconsistent cycle, e.g., with respect to minimal node (p 1 , l 1 ), which will be called the anchor node hereafter.
One way for cycle repair to repair this inconsistent cycle is to allow the anchor node to later raise its height.
For this, as explained in the previous example, it suffices that no tight link exists between the anchor node and any of the minimal nodes in the adjacent object p 2 .
This, in turn, means that if any such link exists, a positive value ε must be added to its associated virtual potential (the link would then be non-tight, as its residual would be equal to ε > 0).
Hence, for all minimal nodes (p 2 , l 2 ) of object p 2 that satisfy r p1p2 (l 1 , l 2 ) = 0, we need to apply the following update:f p1p2 (l 1 , l 2 )+= ε (12)As a result of this, however, feasibility constraint f C f ′ is now violated (where f ′ simply denotes the virtual potentials before the update).
To restore feasibility, we thus have to add −ε to the virtual potentials of some subset S of non-tight links (note that the virtual potential of tight links cannot decrease, as this would result into negative residuals, thus violating feasibility).
It is not difficult to verify that this set S suffices to contain all non-tight links {(p k , l k ), (p k+1 , l k+1 )} between an anchored node (p k , l k ) (where 2 ≤ k ≤ n − 1) and a non-anchored node (p k+1 , l k+1 ) (where l k+1 = l 1 if k + 1 = n).
Here we say that a node (p k , l k ) is anchored if only if there exists a path (p 1 , l 1 ) → (p 2 , l 2 ) → . . . → (p k , l k ) from the anchor node (p 1 , l 1 ) to node (p k , l k ) such that all the path links are tight (before applying (12)) and all the path nodes are minimal (e.g, in Fig. 2(b), the anchor node is (p 1 , a) and the set S consists of the red links).
The following transformation must then be applied:∀{(p k , l k ), (p k+1 , l k+1 )} ∈ S, f p k p k+1 (l k , l k+1 )−= ε.A possible choice for ε is to set it equal to any positive value that ensures that none of the decreased residuals of the links in S will become negative, e.g:ε = min {(p k ,l k ),(p k+1 ,l k+1 )}∈S r p k p k+1 (l k , l k+1 ).
(13)Note that, since C is inconsistent, such a positive ε will always exist.Finally, for implementing the dual ascent routine, one of the ways to achieve that is to use the augmenting DAG algorithm [6].
This is an iterative algorithm that increases the dual objective by keep perturbing the current dual solution until it satisfies Thm.
2.
To this end, it uses a procedure based on a so called augmenting directed acyclic graph (DAG) (this somewhat resembles the augmenting path algorithm for max-flow/min-cut).
In our case, an additional advantage comes from the fact that the change from f to f next after each cycle repair is always small (i.e, local), which means that the change from the augmenting DAG of relaxation D (¯ g, f ) to that of D(¯ g, f next ) will be small as well.
Hence, the convergence of dual ascent for D(¯ g, f next ) will be extremely fast, given that this routine has already converged for D(¯ g, f ) (this somewhat resembles the case of path augmenting max flow algorithms when applied to dynamic graphs).
After our algorithm in Fig. 3 converges, we have to compute an MRF labeling based on the final dual solution, i.e, the final heights and residuals.
To this end, one can traverse all objects in some predefined order, say, p 1 , p 2 , . . . , p n , and, then assign to each object p i a labeî l i that satisfies the following criteria: it has minimal height (i.e, node (p i , ˆ l i ) is minimal) and also minimizes the non-negative sum j<i r pipj ( ˆ l i , ˆ l j ).
The justification for this procedure comes from the next theorem, which generalizes Thm.
3: 4 Theorem 4 ( [12]) There always exist an optimal labelingîlabelingî = { ˆ l p } of MRF(¯ g, ¯ f ) and an optimal dual solution (h, r) of D + (¯ g, ¯ f ) such that each node (p, ˆ l p ) is minimal, i.e., h p ( ˆ l p ) = min l h p (l), and all links{(p, ˆ l p ), (p ′ , ˆ l p ′ )} are tight, i.e., pp ′ r pp ′ ( ˆ l p , ˆ l p ′ ) = 0 (thus pp ′ r pp ′ ( ˆ l p , ˆ l p ′ )attains its minimum possible value).
To verify our algorithm's effectiveness, we tested it on various MRF problems.We begun by applying it on a standard set of benchmark MRF problems from vision [13] and Fig. 4 shows some of our results.
For instance, Figures 4(a), 4(b) show stereo matching results from the widely used Middlebury stereo data set, Fig. 4(c) contains a result related to image inpainting and denoising, Fig. 4(d) displays an image segmentation result, while Fig. 4(e) contains a result from a panoramic stitching application.
Similarly, Fig. 4(f) shows a result from a group photo merging application.
In all cases, our method yielded solutions which were either optimal or had energy that was extremely close to the optimum (this can be proved due to that the dual costs always form a lower bound on the minimum MRF energy).
For instance, the worst accuracy of the labelings obtained for all MRFs was 0.0071 (where accuracy is defined as Energy of labeling−best lower bound best lower bound ).
Next, in order to do a more thorough analysis and to see how our algorithm behaves in much more difficult cases, we went on and tested it on a set of hard synthetic MRF problems.
We thus begun by conducting a full set of experiments on binary MRF problems, which are often used as subroutines by many popular MRF algorithms like [14], [15].
The binary MRFs were defined on 4-connected 30×30 grids and had different percentages of non-attractive couplings 5 .
Unary potentials ¯ g p (·) were drawn independently from a Gaussian distribution N (0, 1), while pairwise potentials were set as: ¯ f pp ′ (0, 0) = ¯ f pp ′ (1, 1) = 0, ¯ f pp ′ (0, 1) = ¯ f pp ′ (1, 0) = λ pp ′ , with λ pp ′ drawn from |N (0, σ 2 )| for attractive couplings and from −|N (0, σ 2 )| for non-attractive couplings.
The percentage of non-attractive couplings was controlled by parameter ρ, which was set to 1%, 25% and 50% in 3 different experiments 6 .
Also, for each experiment, we allowed parameter σ (that controls the strength of the coupling) to vary and take values from {0.1, 2, 4, 6, 8}.
These two parameters, ρ and σ, affect the difficulty of the resulting MRF.Along with our algorithm, the BP, TRW-S [4] and QPBOP [16] algorithms have been tested as well 7 .
The results appear in Fig. 5, where each point on a plot corresponds to the average of 20 random MRF instances.
As can be seen, our algorithm had the best performance in all cases (i.e, for all combinations of ρ and σ).
Its running times varied depending on the binary MRF's difficulty and were up to 1.5 secs using heavily unoptimized code on a 1.4GHz CPU (contrary, e.g., to 0.53 secs for QPBOP).
Note that the QPBOP algorithm did not perform very well in this case (and we speculate that this can be due to a possibly large percentage of unlabeled nodes).
Also note that the method from [7] cannot be applied here, due to the large number of ties that would exist.As can be seen, in the case of binary MRFs, it is only for extremely small ρ (i.e, for almost submodular MRFs) that methods such as TRW-S (which was a top performer in [13]) are able to perform equally well with our algorithm.
The reason is that, in this case, the standard LP relaxation upon which such methods rely is already a very good approximation to the MRF problem (recall that, in the special case of binary MRFs that are submodular, TRW-S can compute the global optimum, just like our method).
This is also shown in more detail in Fig. 6(a), where the lower and upper bounds (generated while applying TRW-S and our algorithm to a binary MRF with ρ = 1%) have been plotted.
In this case, the lower/upper bounds of TRW-S correspond to dual/primal costs of the standard LP relaxation.
Since, as shown in Fig. 6(a), these bounds converge, this, therefore, implies that the LP relaxation is tight.
(b) This is not the case, however, for a binary MRF with 50% non-attractive terms.
But, thanks to cycle repairing, our algorithm uses a much tighter relaxation and so its upper and lower bounds converge even in this case.
(c) An example of non-rigid point matching.
Source points (red) were generated by applying a global rigid motion plus a random non-rigid perturbation to the target points (green).
Despite the heavy distortion, our algorithm succeeded to find a meaningful set of point correspondences.
(d) On the other hand, BP failed as it did not manage to effectively minimize the MRF energy.
However, as can be observed in Fig. 5(c), the situation is completely different when a mixed MRF (with, say, ρ = 50%) is to be optimized.
These are really very hard problems to solve, for which TRW-S performs poorly.
Fig. 6(b) shows in more detail what is really happening in this case.
Contrary to the plot in Fig. 6(a), the upper and lower bounds of TRW-S no longer converge, and the reason, of course, is that the standard LP relaxation is now not tight.
However, this is not at all an issue for our algorithm, thanks to the cycle repairing that it uses.
This effectively enables him to take advantage of a much tighter relaxation, which yields upper and lower bounds far closer to each other (i.e, which almost converge).
As a result, a much better optimum is obtained as well.Using a procedure similar to the binary case, we also conducted another full set of experiments for multi-label MRFs, which are even more popular in vision.
The results are shown in Fig. 7 for various combinations of ρ and σ and when 5 labels were used.
Our algorithm had again the best performance among all other methods and did much better than TRW-S (which was a top performer in [13]) in all cases (and even for very small ρ).
Note that QPBOP, unlike our method, is applicable only to binary MRFs, and, so, it had to be replaced with the α-exp P+I algorithm proposed in [16] (note that this is essentially a generalization of α-expansion with a QPBOP-based technique being used as the binary optimizer at each step).
Note, also, that the set of cycles {C i } (used by our algorithm for the cycle-repairing) consisted only of 1×1, 1×2 and 2×1 rectangles on the grid (these were the settings used in all the grid-based MRFs of this paper).
We also considered the problem of subgraph matching, where one seeks a mapping T between a source and a target graph.
This can be formulated as a multi-label MRF problem, where source vertices correspond to MRF sites, while each target vertex represents one possible label.
The unary potential ¯ g p (T (p)) thus measures the "dissimilarity" between source vertex p and target vertex T (p), while potential ¯ f pp ′ (T (p), T (p ′ )) measures the "dissimilarity" between source edge pp ′ and target edge T (p)T (p ′ ).
We used this formulation for the purpose of non-rigid registration between geometric point sets.
In this case, the unary potentials are all set to zero (as there is no notion of similarity between mere geometric points), while the pairwise potentials (of the fully connected MRF) measure the geometric distortion for each pair of source points as follows: ¯ f pp ′ (T (p), T (p ′ )) = |d(p, p ′ ) − d(T (p), T (p ′ ))|/d(p, p ′ ), where d(·, ·) denotes Euclidean distance.
Results from applying our method and BP to this problem are shown in Figures 6(c), 6(d).
Contrary to BP, which failed to effectively minimize the MRF energy in this case, our algorithm managed to find a good minimum and thus extracted a good point matching despite the heavy geometric distortion (the result of α-exp P+I algorithm is even worse and is thus not shown).
Note that, since a fully connected MRF has been used, our algorithm was allowed to use triplets of vertices as the set {C i } of possible cycles to repair.
Similarly, we have applied our registration algorithm to the problem of deformable feature matching between images (see Fig. 8), where the unary potentials (instead of being 0) are now based on comparing geometric blur descriptors.
We presented a novel LP-based algorithm for MRF optimization, which, contrary to most state-of-the-art techniques, no longer relies on a weak LP-relaxation.
To this end, an hierarchy of dual relaxations (that become tighter and tighter) has been introduced, while it was shown how one can take advantage of a very tight class of relaxations from this hierarchy, named cycle-relaxations.
This is done through an operation called cycled repairing, where inconsistent cycles get repaired during optimization, instead of simply being ignored as was the case up to now.
The more the repaired cycles, the tighter the underlying relaxation becomes.
The outcome is an algorithm that can handle difficult MRF problems with arbitrary pairwise potentials.
The impact of our work can be both practical and theoretical.
On the one hand, the proposed method makes one more step towards the design of optimization algorithms that can effectively handle very general MRFs, thus allowing users to freely exploit such MRFs for a better modeling of future vision problems.
On the other hand, for a further advance to be made in MRF optimization, the use of tighter relaxations is a direction that, we believe, has to be followed.
To this end, the idea of cycle-repairing, as well as that of a dynamic hierarchy of dual relaxations (of which only the cyclerelaxations have been explored here), provide an extremely flexible and general framework that can be useful in opening new research avenues in this regard.
