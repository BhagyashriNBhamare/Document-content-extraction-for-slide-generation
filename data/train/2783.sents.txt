Multi-camera real-time vision at the Edge is facilitated by low-latency distributed data stores.
In this paper, we take the position that latency criticality in the challenging operating conditions at the Edge can only be attained through application specific designs incorporating autonomous computing techniques.
In our initial prototype, we implement a key-value Edge data store that autonomously monitors run-time conditions to maintain latency-criticality of one class of data (feature vectors), while sacrificing the latency and accuracy of another class of data (keyframes).
Early results show a median latency improvement of 84.8% over non-autonomous operation, for videos with large scene dynamics, and operational conditions of intermittent wireless channel interference.
The recent emergence of powerful Deep Learning algorithms, along with the ability to store and process massive amounts of data, has given us the ability to potentially recognize objects in near real-time [13].
Such real-time machine vision is a foundational technology in a number of applications such as automatic video surveillance, augmented and virtual reality, and vision assisted robots.
In many of these applications, timely recognition of objects and their activity is important since events need to be responded to within tight deadline constraints.
The latency critical nature of machine vision applications motivates the use of the Edge computing paradigm [22] [14][21] [20] [25][23] [7] [8].
While single cameras have been used for machine vision applications, increasingly researchers are investigating the use of multiple cameras for distributed video analytics.
In scenarios such as surveillance in dense urban environments, where occlusions are common, multiple camera views increases tracking robustness [26].
Vision analytics applications at the Edge aggregates data from multiple camera nodes to perform trajectory and behavioral analysis.
A data storage abstraction at the Edge is a key system component that facilitates development of such analytics applications.A number of Cloud storage systems have been proposed over the last decade [9][12] [6][4] [18].
While Edge and Cloud systems share similar features such as the need for scalability, and fault tolerance, significant differences exist.1.
Cloud systems are housed in pristine datacenters.
On the other hand, Edge systems are often deployed in the "field" where highly dynamic operating conditions exist.
For example, the nodes most likely use a wireless communication link operating in unlicensed bands, where significant intermittent interference exists from other users.2.
The data is inherently distributed at the Edge nodes due to the distributed nature of the data sources (for example, cameras).
This is different from the Cloud where the data is distributed by design across multiple nodes to accommodate large data sizes.3.
The heterogeneity of the storage nodes at the Edge is far more diverse than the Cloud.
From a storage perspective, the embedded boards (at the camera) has GB of storage, the Edge nodes (at access points/base stations) offer TB of storage, and the backend Cloud offers PB of storage.4.
The physical insecurity of the nodes in the field and the use of the Edge in critical cyberphysical systems brings additional security challenges to the Edge.In this paper, we present early results from our investigation of a storage architecture that can potentially meet the needs of distributed vision analytics at the Edge.
Our position is that the challenging performance requirements at the Edge is best addressed by (a) designing the storage architecture specifically for the application -in our case, multi-camera machine vision, and (b) employing system techniques from autonomic computing to meet performance metrics under dynamic operating conditions.
In our initial prototype, we implement a key-value Edge data store that autonomously monitors run-time conditions to maintain latency-criticality of one class of data (image feature vectors), while sacrificing the latency and accuracy of another class of data (keyframes).
Early results show a median latency improvement of 84.8% over non-autonomous operation, for videos with large scene dynamics, and WiFi operational conditions of intermittent channel interference.The paper is organized as follows -Section 2 briefly introduces recent work on designing data stores for the Edge.
Section 3 provides a description of the system architecture for distributed machine vision at the Edge.
Section 4 identifies latency control knobs, while Section 5 presents the design of the data store.
Section 6 reports the results.
Section 7 discusses future research directions, and concludes the paper.
In the VisFlow project, Lu et al. [16] describe a system that can analyze feeds from multiple cameras.
In particular, they describe a dataflow platform for vision queries that is built on top of the SCOPE dataflow engine, that offers general SQL syntax, and supports added user-defined operators such as extractors, processors, reducers and combiners.
In the Cachier project, Drolia et.
al. [10] propose a caching system for the Edge that caches Deep learning models available on the Cloud on to the Edge nodes to take advantage of spatio-temporal locality of user access, thus minimizing the number of requests that go to the Cloud.
In the CloudPath project, Mortazavi et.
al [17] propose Path Computing as a new paradigm that generalizes the Edge computing vision into a multi-tier Cloud architecture deployed over the geographic span of the network.
CloudPath has a distributed eventual consistent storage system (PathStore) that replicates application data on-demand.
The above projects can be considered complementary to our work; our focus is on enabling latency critical operation of Edge data stores through autonomous computing.
.
Depending on the scale of the system, a cluster of such Edge-nodes may be served by a Corenode (not shown), and so on, with the Cloud at the top-most level.
The End-nodes are assumed capable of one-hop communication to the Edge-node, with the Edge-node connected to the Cloud over the Internet.
Physically, the End-nodes are located in the field (for example, traffic signal pole), the Edge-node, in a more secure location adjacent to the End-node (for example, traffic signal box), and the Cloud is hosted in a data center.
We assume that the nodes at the higher levels of the hierarchy have more resources (compute, storage, network bandwidth, energy) available to them.
Also, we assume that latency from the cameras increases as we go up the hierarchy from the End-nodes to the Cloud.
Each End-node is equipped with a powerful embedded computing board that has multiple processing engines including CPUs, GPUs, and custom FPGA based accelerators capable of processing video frames at real-time using compute-intensive vision algorithms (often involving Deep Learning) to extract image feature vectors (N-dimensional vector of numerical features that represent objects in an image), and key-frames (images with maximal number of feature vectors) [24].
The feature vectors and keyframes are transfered from the End-node to the Edgenode.
Note that the feature vectors are typically 100x smaller in size than the key-frames.
However, the feature vectors are generated at a higher rate (typically 30 fps) compared to key-frames (typically 1 fps).
The Edge-node aggregates the feature vectors, from multiple End-nodes, to perform analytics (for example, behavioral analysis) across space and time depending on the event of interest.
The Edge-node also aggregates the key-frames from the End-nodes both for archival purposes (for example, legal evidence), and to obtain any information not contained in the feature vectors extracted by the End-node.
The data store operations involving the feature vectors is considered latency critical, while those involving key-frames is considered latency sensitive.
Additionally, since the key-frames primarily serve archival purposes, we assume some loss of accuracy can be tolerated.
The primary component of the Edge data store latency is the data transfer operation from the Endnode to the Edge-node over the wireless link.
For WiFi, this latency could be on the order of tens of milliseconds [11].
Additionally, due to crowding in the unlicensed WiFi spectrum, there is considerable variability in the latency due to interference from other users.
While low latency 5G links will become available in the near future, the low cost of WiFi associated with operation in unlicensed bands and ease of setup, will continue to make WiFi an attractive technology for many Edge computing applications.
Another source of of latency is due to head-of-line blocking from bufferbloat associated with transmit buffering of feature vectors and key-frames.
In a video stream with low scene dynamics (key-frames and feature vectors with low temporal variation), a new feature vector (key-frame) can be discarded if it is similar to a previously transmitted feature vector (key-frame), leading to low transmit buffer ingress rate.
Conversely, high scene dynamics results in minimal discarding of feature vectors (key-frames), and consequently, a high transmit buffer ingress rate.
Additionally, if the wireless network is congested due to interference in the channel, the egress rates from the transmit buffer is low, leading to transmit buffer bloat.Other sources of latencies such as read/write operations involving persistent storage such as flash (hundreds of microseconds) are far less significant as compared to that due to the wireless link, and transmit buffer bloat.
Additionally, prior work has made available low latency data stores (for example, RAMCloud [18], RocksDB [3]) that utilize RAMbased log structured data structures to effectively mask latencies associated with persistent storage.Based on the above observations on latency sources, our goal is to design latency tuning knobs that a controller can use to tune the latency associated with channel interference, and transmit buffer bloat.
A simple solution of using static priority classes per traffic has the disadvantage of prioritizing traffic even under conditions where the channel is not congested.
Intermittent congestion is dynamic, and effectively addressing it requires a dynamic controller.
Our key idea is to exploit the differing latency requirements of feature vectors, and key-frames, and the possibility of tolerating loss of key-frame accuracy.
The first control knob, key-frame TX, determines the rate at which the key-frame is transmitted.
When channel interference is detected, the key-frame transmission rate is reduced by the key-frame TX knob so as to improve the signal-to-noise ratio (SNR), and thereby the feature vector packet delivery probability (and hence latency) is improved.
Unfortunately, reducing the transmission rate of key-frames can exacerbate the bufferbloat problem.
To ameliorate bufferbloat, a second control knob, key-frame Sim, that determines the degree of similarity of keyframes in the buffer, is introduced.
When transmit bufferbloat exceeds a high-threshold, the key-frame Sim knob discards K closest matching key-frames from the buffer, thereby reducing the head-of-line blocking experienced by key-frames.
The discarding of the key-frames can be considered as trading off accuracy for latency.
A controller located at the End-node utilizes the two control knobs and a suitable control policy to ensure the best possible latency for the latency critical feature vectors under varying operating conditions (channel interference, and video scene dynamics).
The key-frames and feature vectors obtained from the video processing engines at the End-nodes are timestamped and inserted along with the unique node ID into the respective transmit buffers to be transferred to the Edge-node server.
An image similarity index such as Structural Similarity (SSIM) [27] is used to discard temporally adjacent images that are similar above a threshold level.The Edge-node server implements a persistent lowlatency data store such as RocksDB [3] or a distributed low-latency data store such as RAMCloud [18] depending on the data size and fault tolerance to node failure requirements.
Note that we avoid persistent storage at the End-node, since the End-node could be illegally accessed because of limited physical security.
Encrypted persistent storage may be used at the Edge-nodes; however, this entails additional encryption latency.
The Edge-nodes backup the data to a Cloud storage; this operation is considered to be latency insensitive.
Our primary goal was to prototype an emulation testbed that can be used to explore various aspects of the Edge data store for distributed machine vision including video workloads, wireless channel interference, data structures, key-frame similarity, and control algorithms.
We use LXC containers to emulate End and Edge nodes.
Containers implement light-weight OS level virtualization allowing a large number of containers to be spun-up on a single physical machine.
The one-hop WiFi network was simulated using an 802.11a based adhoc WiFi network model simulated using the NS3 [2] network simulator.
The LXC containers emulating the nodes are connected to NS3 using a tap-bridge device allowing communication between the nodes through the simulated WiFi network.
The End-node and Edge-node servers were implemented in Golang and support an RPC interface.
Image similarity was computed using the Python sckit-image [5].
BadgerDB [1], a Golang implementation of RocksDB, was used to implement the persistent key-value store at the Edge-node.
We use a synthetic workload consisting of keyframes with an average size of 500 KB, and feature vectors of size 4 KB.
High scene (low scene) dynamics was simulated by deriving the key-frames from a distribution with 0.1 (0.9) probability of temporally adjacent key-frames being sufficiently similar to allow discard.
The wireless channel interference was modeled through a 1 second long transmission generated by a Poisson process with a mean arrival time of 30 seconds.
The TCP latency was measured using the Linux qperf utility.
Figure 2 shows the latency CDF with and without latency control for high scene dynamics using the key-frame TX control knob described in Section 4.
A simple bang-bang controller was used -the key-frame transfer from the End-node to the Edge-node was disabled if the latency mea- Figure 3 shows the resulting increasing bufferbloat of the transmit buffer queue.
The bufferbloat was controlled using a simple bangbang controller using the key-frame Sim control knob -if the buffer length exceeded 12 key-frames, K = 2 key-frames was randomly chosen and dropped from the transmit queue.
Note that the choice of parameters (for example, buffer length and latency thresh- To understand the scene dynamics of real-life Edge computing video workloads, we studied a pedestrian car accident surveillance video obtained from YouTube.
Figure 4 plots the histogram of the image similarity of all keyframe pairs in the video.
We note that a policy of randomly dropping keyframes yields 63.1% less dissimilar keyframe pairs in the top 20 percentile as compared to the computationally expensive exhaustive evaluation of SSIM index of all image pairs.
In this paper, we have laid the ground work for a data store architecture for latency critical distributed vision applications at the Edge that incorporates application specific design, and autonomous computing techniques.Future extensions of our work include -node scalability studies, characterization of scene dynamics from multiple surveillance video benchmarks, incorporation of measurement based WiFi channel interference [15], and investigation of more sophisticated control algorithms as described in [19].
An experimental testbed would serve to evaluate the proposed approaches under real-life conditions.
