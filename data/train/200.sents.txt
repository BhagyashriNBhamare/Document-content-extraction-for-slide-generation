In this paper, we investigate optimal load balancing strategies for a multi-class multi-server processor-sharing system with a Poisson input stream, heterogeneous service rates, and a server-dependent holding cost per unit time.
Specifically , we study (i) the centralized setting in which a dis-patcher routes incoming jobs based on their service time requirements so as to minimize the weighted mean sojourn time in the system; and (ii) the decentralized, distributed non-cooperative setting in which each job, aware of its service time, selects a server with the objective of minimizing its weighted mean sojourn time in the system.
For the decentralized setting we show the existence of a potential function , which allows us to transform the non-cooperative game into a standard convex optimization problem.
For the two aforementioned settings, we characterize the set of optimal routing policies and obtain a closed form expression for the load on each server under any such policy.
Furthermore, we show the existence of an optimal policy that routes a job independently of its service time requirement.
We also show that the set of servers used in the decentralized setting is a subset of set of servers used in the centralized setting.
Finally, we compare the performance perceived by jobs in the two settings by studying the so-called Price of Anarchy (PoA), that is, the ratio between the decentralized and the optimal centralized solutions.
When the holding cost per unit time is the same for all servers, it is known that the PoA is upper bounded by the number of servers in the system.
Interestingly, we show that the PoA for our system can be unbounded.
In particular this indicates that in our system, the performance of selfish routing can be extremely inefficient.
Communication services such as web server-farms, database systems and grid computing clusters, routinely employ multiserver systems to provide a range of services to their customers.
An important issue in such systems is to determine the server to which an incoming request should be routed to in order to optimize a given performance criterion.
From the service provider's perspective, this choice of the strategy (centralized or decentralized) and the service discipline (Processor Sharing (PS), First-Come-First-Served (FCFS), etc.) determines the amount of resources it needs to deploy in order to guarantee a certain Quality-of-Service (QoS) to its customers.
Thus, an investigation of load balancing or routing strategies in multi-server systems can give guidelines to the service provider on dimensioning its system.In this paper we study the optimal load balancing in a multi-server processor-sharing system with heterogeneous service capacities.
This configuration is also known as processorsharing server-farms, and is a popular architecture in computing centers, used for example in the Cisco Local Director, IBM Network Dispatcher and Microsoft Sharepoint (see [5] for a recent survey).
This configuration can also be used to model a web server farm, where requests for files (or HTTP pages) arrive to a dispatcher are dispatched immediately to one of the servers in the farm for processing.
With each server, we associate a service capacity (i.e., some servers could be faster than the others) and a holding cost per unit time.
We assume that requests arrive as a Poisson process, and that the service requirement of each request is sampled from a finite set.
For such a multi-server system, we investigate load balancing in two different settings: (i) the centralized setting in which a dispatcher assigns the server to an incoming request with the objective of minimizing the weighted mean sojourn time of jobs in the system, and (ii) the distributed non-cooperative setting in which an incoming request selects a server in order to minimize its own weighted mean sojourn time in the system.
In both cases we assume that the only information available to the decision maker (the dispatcher or the request itself) is the service time requirement of the request.
This might be the case, for example, in situations where not all the servers are in the same location and it may be costly to gather information on the current queue lengths at the various servers.The main contributions of the present work are as follows.
For both settings, we characterize the set of optimal routing policies, and give closed-form expressions for the load on each server under any optimal policy.
It is worthwhile to note that for the distributed non-cooperative setting this is done by showing the existence of a potential function, which allows us to transform the non-cooperative game into a standard convex optimization problem.
We then give an optimal policy in which an incoming request is routed to a server with a probability that is independent of the service requirement of the request.
This property of the PS discipline could be useful in systems in which the service requirement of requests is not known a priori and it illustrates an important difference between the optimal load balancing policy in a PS server-farm and FCFS server-farm, since in the case of a FCFS server-farm it has been shown that the optimal load balancing does use information on the service requirement of each request [10,8].
Further, we show that higher the ratio of the holding cost per unit time to the service capacity of a server the lighter is the load on it, thus defining an index to order the servers.
For certain input parameters (i.e., an arrival process, service time distribution, available service capacities, holding cost per unit time), it is thus possible that some of the servers will not be processing any requests.
We show that the set of servers processing requests in the decentralized setting is a subset of that in the centralized setting.
Thus, there is a trade-off in the performance gains and cost of servers to be considered when choosing between the two settings.
We also note that, given the input parameters, this analysis gives the set of servers that a service provider should choose in order to minimize the mean sojourn time in its system.
Finally, we compare the performance perceived by jobs in the two settings by studying the so-called Price of Anarchy (PoA), that is, the ratio between the selfish decentralized and the optimal centralized solutions.
When the holding cost per unit of time is the same in every server it is has been shown that the PoA is upper bounded by the number of servers in the system, see for example [22,11].
Interestingly, we show that for our system the PoA is unbounded, that is, it can be arbitrarily close to infinity.
This indicates that unequal holding costs may have a profound impact on the system's performance.
In particular, the performance of selfish routing can be unboundedly worse than the performance obtained by a centralized routing.
Load balancing in multi-server systems has been previously investigated not only in the context of communications services but also in the broader context of queueing systems.
Global and Individual optimality in load balancing are considered in the monograph [13], which does not consider decisions based on knowledge of the amount of load.
Systems with general service time distribution and FCFS scheduling discipline were studied in [7,2,3,8], while [17,11] studied systems with exponential service time distributions and arbitrary scheduling discipline.
In [9] the authors analysed a multi-servers PS system where requests join the server that has the smallest number of requests.
In a recent work [6] the authors investigate the performance of a server farm where the scheduling discipline in each server is SRPT (Shortest Remaining Processing Time First).
Our work is closely related to [22] and [11].
The main differences are that (i) we consider a multi-class job arrival process, allowing the dispatcher to use information on the size of the requests and (ii) the addition of a heterogeneous holding cost per time unit in each server.
As we will see, both (i) and (ii) generalizations allow us to draw important conclusions, that to the best of our knowledge were not known before.By considering a multi-class system, we wish to analyze how the information on the service requirements of users impacts the structure of the optimal load balancing.
Our results show that the structure of the optimal routing in a system with the PS scheduling discipline is radically different with respect to the FCFS case.
For a multi-server FCFS system with homogeneous service capacities it was conjectured in [10], and proved in [8], that the optimal load balancing scheme consists in assigning to each server all jobs whose processing times fall within non-overlapping, continuous intervals of processing times.
The intuitive explanation to this result comes from the fact that this strategy reduces the variability of service times for each queue.
Since the mean delay in a FCFS queue is directly proportional to the variability of the service time distribution (Pollaczek-Khinchin formula), an interval-based policy can minimize the overall mean delay in the system.
Interestingly, if the service capacities are heterogeneous an interval-based strategy need not be optimal [8].
In contrast, we show that in the case of a multi-server PS system the optimal load balancing strategy does not take advantage of the service time information, that is, the probability that a job joins a given server is independent of the job's service requirement.
The rest of this paper is organized as follows.
In Section 2, we describe the system model, state the assumptions, and give the mathematical formulation for the problem under consideration.
In Section 3, we treat the centralized setting, which is followed by the treatment of the decentralized setting in Section 4.
In Section 5, we compare the performance of the two settings using various measures, such as the server utilization and the Price of Anarchy.
Consider a server farm consisting of a set of C servers.
Let S = {1, 2, ..., C} denote the index set of the set of servers.
Server j has a service rate rj, for all j ∈ S.
At every server, jobs are served according to the processor sharing (PS) discipline.
Customers arrive to the system according to a Poisson process with rate λ.
Depending on the application in mind, a customer may correspond to a job with a certain amount of service requirement, or of a file that has to be transmitted and has a certain size.
In the latter case we shall identify the service requirement of the file as being its size.Let {σ k : 1 ≤ k ≤ K} denote the set of possible service requirements (i.e. the job sizes) and assume that K is finite.
Let K = {1, 2, ..., K} denote the index set of the set of possible service requirement.
Customers have independent and identically distributed service requirements which are sampled from {σ k : k ∈ K} such that the probability that a customer has service requirement σ −1 i is given by βi, for all i ∈ K.As mentioned in the Introduction, we are interested in comparing the performance between the globally optimal solution and the distributed non-cooperative problem.
We assume that decisions are open-loop: they are taken without knowledge of the queue sizes.
However, we assume that the service requirement of an arriving user is known, both to the dispatcher in the centralized case and to the user itself in the distributed non-cooperative setting.
The decision on which queue an arrival joins is assumed to depend only on that information.
Since the processes generated by splitting a Poisson process are still Poisson, each server can be seen as an M/G/1 − P S queue.
We recall that the mean delay in a PS queue depends on the service time distribution only through its mean (the so-called insensitivity property of PS [14]), therefore the mean number of jobs in an M/G/1 − P S queue is the same as in an M/M/1 queue.All arrivals with a given size are called a class.
We thus have K classes of jobs where jobs of class i have mean size σ −1 i .
We associate with class i an arrival rate λi = λβi, and a traffic intensity ηi = λiσ −1 i .
Let η = X i∈K ηi denote the total input traffic intensity.Remark 1.
Note that the value of K is arbitrary.
Therefore our formulation allows us to approximate a continuous distribution arbitrarily closely, and thus we can investigate the optimal size-based routing strategy.Notation.
We shall use a lower case bold-faced character to denote a vector.
The elements of a vector will be denoted by the corresponding lower case characters.
For example, a denotes the 1 × m vector (a1, a2, ..., am) where m is the size of a.
The vectors 0m and 1m will denote the 1 × m vectors with all elements as 0 and 1, respectively.
We shall use the symbol to denote elementwise inequality for vectors.
Strategies.
A strategy for a class i of customers is defined to be the probability vector (pi1, ..., piC ), where pij is the probability that a class i customer goes to queue j. Note that for any strategyP C j=1 pij = 1.
We define a multi- strategy p = (pij), 1 ≤ i ≤ K, 1 ≤ j ≤ C as the matrix of strategies of all classes.For a multi-strategy p, let ρ i j (p) denote the load on server j due to class i.
The total load on server j is given byρj(p) = X i∈K ρ i j (p) = X i∈K ηipij rj .
(1)From queueing theory we know that server j is stable if ρj(p) < 1.
We shall say that p is a stable multi-strategy if all servers are stable.
The next proposition states the necessary and sufficient condition for the existence of a stable multistrategy.Proposition 1.
There exists a stable multi-strategy if and only ifX j∈S rj > η.
(2)Proof.
For a multi-strategy p, from (1) we getrjρj(p) = X i∈K ηipij, for all j ∈ S.Summing over all j and interchanging the two summations on the right-hand side we getX j∈S rjρj(p) = X i∈K ηi X j∈S pij = η.
(3)If P j∈S rj < η, then the load on some server must be larger than 1 for (3) to hold.
Thus, (2) is necessary for the existence of a stable multi-strategy.
Now, assume (2) and consider the multi-strategy defined bypij = rj P k∈S r k, for all i ∈ K, and for all j ∈ S.Due to the splitting property of Poisson processes, the arrival process to each of the queues will also be Poisson under this multi-strategy.
Then, each server can be modeled as an M/G/1 queue withρj(p) = X i∈K ηipij rj = P i∈K ηi P k∈S r k < 1.
(4)and as a consequence every server j is stable.
Thus, (2) is sufficient for the existence of a stable multi-strategy.
Assumption 1.
The traffic intensities and the service rates are such that (2) is always satisfied.Note that if p is a stable multi-strategy, then necessarilyP C j=1 ρj(p) < C.Since all the queues in our system are M/G/1−P S queues, the mean number of jobs at any queue has the insensitivity property: it depends on the service distribution only through its expectation.
For all j ∈ S, the mean number of jobs is given byE[Nj(p)] = ρj(p) 1 − ρj(p) ,(5)for ρj(p) < 1, and is infinity otherwise.
The total arrival rate to server j is P K i=1 λipij.
Thus, by Little's law the mean sojourn time at queue j is given byE[Tj(p)] = E[Nj(p)] P K i=1 λipij .
(6)Even though sometimes we will not make the dependency explicit, E[Nj], ρj and E [Tj], for all j ∈ S, shall be understood to depend on the multi-strategy relevant to the context.Our objective is to determine the multi-strategy p that minimizes the weighted mean number of jobs in the system, that is,argmin p C X j=1 cjE[Nj],(7)where cj are some constants that depend on the index of the of the queue and that can represent, for example, a cost on the holding time.
We recall that in all previous works, the case cj = c, for all j ∈ S, was studied.
By Little's law, minimizing the weighted mean number of jobs is equivalent to minimizing the weighted mean sojourn time in the system.
Finally we note that throughout the paper we will assume the servers are labeled such that c1 r1≤ c2 r2 ≤ . . . ≤ cC rC .
(8) In this section we consider the global optimization problem, in which a dispatcher decides where each job will get service so as to minimize the weighted mean number of jobs in the system.
The global optimization problem can be formulated in terms of the following Mathematical Program (MP):minimize X j∈S cjE[Nj(p)](9)subject to X j∈S pij = 1, for all i ∈ K;p 0; (11) X i∈K ηipij < rj, for all j ∈ S.(10)We note that if condition (2) is satisfied, then there exists a multi-strategy which satisfies these constraints and vice versa.Since the objective function is convex and the constraints are linear, MP is a standard convex programme, and its solution can be found in polynomial time in the number of unknowns and in the number of constraints.
We note that there may exist multiple multi-strategies that minimize (9) subject to (10)-(12).
The following result will play a key role in the rest of the paper.
It shows that there exists a size-unaware multistrategy that is optimal.Proposition 2.
Let p be a multi-strategy satisfying the constraints (10)-(12).
The multi-strategyˆpstrategyˆ strategyˆp defined byˆpijbyˆ byˆpij = P l∈K η l p lj η = ρj(p)rj η ,(13)for all i ∈ K and for all j ∈ S, also satisfies the constraints (10)-(12).
Moreover, the load on a server underˆpunderˆ underˆp is equal to the load on it under p.Proof.
The equalityX j∈Sˆpij j∈Sˆ j∈Sˆpij = X j∈S P l∈K η l p lj η = 1,for all i ∈ K, shows thatˆpthatˆ thatˆp satisfies (10).
Since ηi is non-negative for all i ∈ K, and p satisfies (11), ˆ p also satisfies (11).
The equalityX i∈K ηî pij = X i∈K ηi P l∈K η l p lj η = X l∈K η l p ljhelps us to verify thatˆpthatˆ thatˆp indeed satisfies (12).
Finally, sinceρj(ˆ p) = P i∈K ηî pij rj = P l∈K η l p lj rj = ρj(p),for all j ∈ S, the load on a server is the same under both p andˆpandˆ andˆp.From Proposition 2, we can infer that, for every feasible multi-strategy, there exists a feasible size-unaware multistrategy such that both these strategies induce the same load on the servers.
Since the objective function in the MP depends on the multi-strategy only through the induced load (cf. (5)), we can conclude that one may restrict oneself without loss of optimality to finding policies that take routing decisions independently of the (known) amount of service requirement of a job.
The result of Proposition 2 further illustrates that the optimal load balancing in PS server farms is rather different than in FCFS server farms, where the size of jobs is used by the optimal routing policy.Moreover, the value of the mathematical programming (9)-(12) can be obtained by optimizing directly over the loads.
The routing probabilities can be determined later from (13), once the load on each server is determined.Letfj(x) =  cjx/(1 − x), for 0 ≤ x < 1; ∞,otherwise.From (5) and Proposition 2, we can conclude that an optimal load balancing policy is obtained by applying (13) to the solution of the following Reduced Mathematical Program (RMP):minimize X j∈S fj(ρj)(14)subject to 0 ρ 1;(15) X j∈S rjρj = η.
(16)Constraint (16) guarantees that all incoming jobs are served.
Depending on the values of the service rates and the holding costs per unit time, the optimal multi-strategy may not use all servers, but due to constraint (16) we are certain that at least one server will be used.
Let SG ⊆ S denote the subset of servers that the optimal multi-strategy uses.In the following theorem we characterize the solution of (14)-(16).
In particular we note that the solution to (14)-(16) is unique.
Theorem 1.
The subset of servers that are used in the optimal load balancing is SG = {1, . . . , j * }, wherej * = sup ( j ≤ C : j X k=1 √ cjrj > j X k=1 r k − η !
r cj rj )(17)Under the optimal multi-strategy, the load on server j ∈ SG isρ * j = 1 − r cj rj P k∈S G r k − η P k∈S G √ c k r k .
(18)Proof.
The Lagrangian associated with the RMP can be defined asL(ρ, ν, ζ, γ G ) = X j∈S fj(ρj) + X j∈S νj(0 − ρj) + X j∈S ζj(ρj − 1) + γG X j∈S rjρj − η !
,(19)where ν 0, ζ 0 and γ G ∈ R.Note that the RMP is convex.
From Proposition 1 (see (4)) there exists a feasible solution.
As a consequence bySlater's condition [4, Section 5.2.3] strong duality is satisfied.
Then, ρ * and (γ G * , ν * , ζ * ) are primal and dual optimalwith zero duality gap if they satisfy the Karush-KuhnTucker (KKT) conditions0 ρ * 1; X j∈S rjρ * j = η; γ G * ∈ R; ν * 0; ζ * 0; ν * j ρ * j = 0, ζ * j (ρ * j − 1) = 0, for all j ∈ S;(20)cj 1 (1 − ρ * j ) 2 − γ G * rj − ν * j + ζ * j = 0, for all j ∈ S.(21)Condition (20) are the so-called complementary slackness, which hold due to strong duality.Since the objective function tends to infinity when ρj tends to 1 at any server j, it follows that necessarily ρ * 1.
Therefore, from (20) it follows that ζ * = 0.
Since ν 0, from (21) we getγ G * ≤ cj rj 1 (1 − ρ * j ) 2 , for all j ∈ S,(22)and on eliminating the variables νj from (20), we get" cj 1 (1 − ρ * j ) 2 − γ G * rj « ρ * j = 0, for all j ∈ S.(23)For a given server j, if γ G * is greater than cj/rj, then (22) can only be satisfied if ρ * j is greater than 0 as well, which together with (23) implies thatρj = 1 − r cj rj r 1 γ G * .
(24)Assume now that γ G * ≤ cj/rj.
If ρj is greater than 0 thenγ G * ≤ cj/rj < cj (1 − ρ * j ) 2 rj ,which violates the complementary slackness condition (23).
Thus, if γ G * ≤ cj/rj, then ρ * j is equal to 0.
In conclusion, we haveρ * j = ( 1 − q c j r j q 1 γ G * , if γ G * > cj/rj; 0, otherwise.
(25)From the above equation, we see that ρ * j are non-decreasing in γ G * .
Therefore, there is a unique value of γ G * such that constraint (16) is satisfied.
Since cj/rj is non-decreasing in j, it now follows that SG = {1, . . . , j * }, where j * can be computed using (22) and is such thatcj * rj * < γ G * < cj * +1 rj * +1 .
(26)From (24) and (16), we obtainr 1 γ G * = P k∈S G r k − η P k∈S G √ c k r k ,(27)which together with (26) givesj * = sup ( j ≤ C : cj rj < P j k=1 √ c k r k P j k=1 r k − η !
2 ) ,which is an equivalent condition to the one stated in (17) On combining (26) and (25), we getρ * j = 1 − r cj rj P k∈S G r k − η P k∈S G √ c k r k ,which is the result stated in (18).
Corollary 1.
The size-unaware multi-strategy, ˆ p * , is given byˆpbyˆ byˆp * ij = ρ * j rj η, for all i ∈ K and for all j ∈ S.Remark 3.
The solution structure of Theorem 1 is known as water-filling.
We will say more about this in Section 4.4.
From Theorem 1 we see that ρ * j > ρ * i , for any j < i.
Since the mean number of jobs in a server increases with its load, we conclude that, under any optimal multi-strategy, E[Nj] > E [Ni] for any j < i. Interestingly, in the next proposition we show that, even though ρ * j > ρ * i , the weighted mean sojourn time in server j will be smaller than the weighted mean sojourn time in server i.Proposition 3.
For the multi-strategy (28), and for any two servers j and i in SG,cjE[Tj] < ciE[Ti], for j < i.Proof.
From Little's law (see equation (6)) and the multistrategy (2) we havecjE[Tj] = cjE[Nj] P i∈K λî p * ij = cjE[Nj] P i∈K λi ρ j r j η .
Substituting (18) we getcjE[Tj] = r cj rj η P k∈S G √ c k r k P k∈K λi " P k∈S G r k − η " .
The result now follows by noting that for any j < i, cj/rj < ci/ri.
In this subsection we write in vector form the KKT conditions that characterize the optimal solution to the global optimization problem.
This representation will play a crucial role in determining the optimal routing strategy in the distributed non-cooperative setting.
For simplicity in the exposition, we assume that all servers are used.Let us first introduce the Hadamard product for matrices.
For two arbitrary matrices X = (x)ij and Y = (y)ij of the same dimension, we denote by X • Y the matrix whose (i, j) element is aijbij.
Thus, the Hadamard product just refers to the element-wise product of matrices.
The standard product of two matrices is denoted by X · B. Finally for an arbitrary matrix X we denote by X T its transpose matrix.Let t(p) be the gradient of the objective function, i.e., t(p) is a matrix of dimension K × C whose (i, j) element is given bytij = ∂ P k∈S f k (p) ∂pij .
(29)Then, similar to the derivation of (22)-(23), p is optimal for the original problem (9)-(12) if and only if there exist Lagrange multipliers γ1, ..., γC and a matrix Γ of dimensions K × C whose (i, j) element is given byΓij = γj, such that (t + Γ) • p = 0,(30)t + Γ 0,(31)1C · p T = 1K , p 0.
(32)Note that equations (30) and (31) are the analogue of equations (23) and (22), respectively.This equivalent characterization through complementarity inequalities of a globally optimal solution will be essential for the next section.
We study now the distributed non-cooperative setting, where an arriving customer, say of class i, aware of its required amount of service (σi) −1 , wishes to minimize its own weighted expected sojourn time.
The weighting is done according to the queue to which the file is sent as can be viewed as a pricing that may vary from one queue to another.
If a class-i user chooses to be served by server j then its weighted conditional expected sojourn time there isτij(p) = cjE[Tj(p)|i] = cj rjσi × 1 1 − ρj(p) .
(33)Definition 1.
We say that customers of class i use queue j if ρ i j > 0; i.e., queue j receives a strictly positive load from class i.Definition 2.
We say that a strategy p is an equilibrium for the individual optimization problem if for each i = 1, ..., K, each j = 1, ..., C and each queue k used by class i,E[c k T k (p)|i] = min j=1,...,K E[cjTj(p)|i].
(34)Without loss of generality, we can replace the equilibrium condition in (34) with the conditionE[dic k T k (p)|i] = min j=1,...,K diE[cjTj(p)|i].
(35)where di are arbitrary strictly positive constants.
Equation (34) characterizes the equilibrium, since only when (34) is satisfied users will not have an incentive to deviate from their strategy.
Denote by T(p) a K × C matrix whose (i, j) element is τij(p).
Let a be the matrix of dimensions K ×C whose (i, j) element is given by aij = aj.We can characterize the equilibrium by the following relations: p is an equilibrium if and only if there is some a such that the following holds.
` T(p) + a ´ • p = 0,(36)T(p) + a 0,(37)1C · p T = 1K , p 0.
(38)We observe (36)-(38) and note that they are the same as the system (30)- (32), provided that we identify the minimum cost vector a with the Lagrange multiplier vector Γ, and we identify T as a gradient vector of some potential function G.Since system (30)- (32) were equivalent to a global minimization, we conclude that (36)-(38) are equivalent to the equilibrium p being the global minimum of the function G subject to the constraints (38).
Note that the minimum is unique in terms of ρj if G is a strictly convex function of ρj.Games that can be transformed into an equivalent optimization problem with a common function optimized jointly by all users are known as potential games.
They have been introduced in [1] in the context of road traffic, see also [18,16,19,21].
In particular, the existence of a potential function is a sufficient condition for various greedy dynamics of the game to converge to equilibrium.Proposition 4.
The distributed non-cooperative game can be transformed into a standard convex optimization problem of minimizingC X k=1 c k log T (ρ k (p))(39)subject to the constraints (10)- (12) where T (z) := 1/(1 − z) for 0 ≤ z < 1 and ∞ for z ≥ 1.
Proof.
DefineG(p) := C X k=1 Z ρ k (p) z=0 c k T (z)dz.
(40)ThenG(p) = C X k=1 Z ρ k (p) z=0 c k T (z)dz = C X k=1 c k log T (ρ k (p))Thus,∂G(p) ∂pij = cjT j (p) × dρj dpij = cj 1 − ρj(p) × λi σirj = λi " cjE[Tj(p)|i] "We conclude that G is indeed a potential as its gradient coincides with the original costs as given in (35), where di = λi.
The optimal solution p to (39) is given by the only vector that satisfies the KKT conditions, which in turn are precisely given by (36)- (38), where a denotes the Lagrange multiplier vector.This implies that indeed the game can be transformed into a standard convex optimization problem of minimizing G subject to the constraints (10)-(12), whose solutions are equilibria in the original game.As we did in Section 3.1, we can further simplify the above optimization problem.
Indeed, the value is directly obtained through minimizing G(p) := P C k=1 R ρ k z=0c k T (z)dz subject to (15)-(16).
The solution to the game problem is obtained from the loads that achieve the minimization by using (13).
Let us interpret the meaning of the potential function G. Define ∆ k := 1 − ρ k to be the excess capacity at server k.
We note that the argument that achieves the minimization of G(p) achieves the maximum of the product of (∆1) c 1 × (∆2) c 2 × · · · × (∆C ) c C .
We conclude the following: Theorem 2.
The individual optimal load balancing solution coincides with the routing strategy that achieves the weighted proportional fair excess capacities between the C servers, where the weight for server k is given by the powers c k .
Proof.
The result is a direct consequence of (39) and the definition of Proportional Fair allocation.
Since we have shown that the individual setting corresponds to a potential game, in equilibrium, the optimal routing strategy will minimize (40) subject to (15)-(16).
We have the following result.Theorem 3.
The subset of servers that are used in the optimal routing strategy in the non-cooperative setting is of type SI = {1, . . . , j * }, wherej * = sup ( j ≤ C : j X k=1 cj > j X k=1 r k − η !
cj rj )(41)For every j ∈ SI , the load isρj = 1 − cj rj P j k=1 r k − η P j k=1 c k .
(42)Proof.
The derivation follows the same steps of the proof of Theorem 1.
From Proposition 1 (see equation (4) cj (1 − ρj) − γ I rj − νj + ζj = 0,(43)then ρj, j = 1, . . . , C and (γ I , ν, ζ) are primal and dual optimal with zero duality gap.
Since the objective function tends to infinity if ρj → 1 at some server, it follows that necessarily ρj < 1, j = 1, . . . , C. Because of (43) this implies that ζj = 0, for all j.
Now note that νj are slack variables which can be eliminated.
Since νj ≥ 0, from (44) we getγ I ≤ cj rj 1 (1 − ρj) ,(45)and from (43) we have" cj (1 − ρj) − γ I rj « ρj = 0.
(46)Now, if γ I > cj/rj, equation (45) can only be satisfied if ρj > 0, and from (46) this implies thatρj = 1 − cj rj 1 γ I .
(47)Assume now that γ I ≤ cj/rj.
If ρj > 0 then this implies that γ I ≤ cj/rj < c j (1−ρ j )r j , which violates the complementary slackness condition (46).
Thus if γ I ≤ cj/rj then ρj = 0.
In conclusion we have thatρj = ( 1 − c j r j 1 γ I γ I > cj/rj 0 γ I < cj/rj.
It follows that ρj > 0 are non-decreasing in γ I .
Thus there is a unique value of γ I such that constraint (16) is satisfied.
It follows that SI = {1, . . . , j * }.
From (45) we have that the index j * is such thatcj * rj * < γ I < cj * +1 rj * +1 .
(48)Substituting (47) in (16) we get1 γ I = P k∈S I r k − P K i=1 ηi P k∈S I c k .
(49)This proves equation (42).
From (48) we get that server j is used if and only ifcj rj < P j k=1 c k P j k=1 r k − P K i=1 ηi ,from where (41) follows.We note that a routing strategy that achieves the desired load (42) in every server (and as a consequence the same performance) can be obtained by (13).
Remark 4.
From (42) it is easy to see that (34) is satisfied for each i = 1, . . . , K and each j ∈ SI .
This can also be seen from equation (47), which implies that in every server j ∈ SI that is used the mean cost per unit of service required at the server, c j /r j 1−ρ j = γ I , is independent of the server.From Remark 4 and Proposition 3 we observe the main difference between the global and individual optimal solutions.
In the individual optimal solution is constrained to a solution such that the mean sojourn time is the same in each server.
In the global optimal solution the weighted mean sojourn time varies across the servers, and in fact, it increases as the index of the server increases (see Proposition 3).
When ci = c, ∀i, equation (41) becomesrj+1 < ( j X k=1 r k − K X k=1 ηi) 1 j .
(50)Equation (50) has a clear interpretation.
Server j+1 will not be used if the exceeding capacity per server when j servers are used is larger than rj+1.
We recall from (8) that servers are relabeled in increasing order with respect to the ratio cj/rj, j = 1, . . . , C. Let there be M1 servers with ci/ri = c1/r1.
Let there be M2 servers with ci/ri = cM 1 +1/rM 1 +1.
Let there be M k servers with ci/ri = cM k−1 +1/rM k−1 +1.
Then, from (34), the optimal policy has the following water-filling structure.
For λ sufficiently small, only the first M1 servers receive positive flow.
This flow is assigned in a way that equalizes the expected delay among the first M 1 servers.
We increase λ till a point wherec1 r1 × 1 1 − ρ1(p) = c2 r2 .
From this point, we route flow to all M1 + M2 first servers in a way that equalizes the expected delays on these servers.No flow is sent to other servers.
This type of solution is often referred as to water-filling.
In this section we compare the optimal load balancing expressed in Theorems 1 and 3.
Our first result shows SI ⊆ SG, that is, the number of servers that are used in the global optimum solution is greater or equal to the number of servers used in the distributed non-cooperative setting.
This indicates that in the non-cooperative setting, users will tend to overload fast servers, and fail to recognize the benefits that using a slower server can have.
A similar property was proven in [2] for a exponential multi-server system.In this section, ρ G j and ρ I j will denote the load in server j in the global and individual optimal solution, respectively.
In view of (24) and (47) we will consider that both ρ G j := ρ G j (γ) and ρ I j := ρ I j (γ) are a function of a common variable γ.
We start with the following Lemma.Lemma 1.
For 0 < γ ≤ cj/rj, ρ G j (γ) = ρ I j (γ) = 0.
For γ > cj/rj, ρ G j (γ) < ρ I j (γ).
Proof.
The case γ ≤ cj/rj is obvious.
For the second case, we haveγ > cj/rj √ γ √ γ √ γ > r cj rj = c j r j q c j r j r cj rj r 1 γ > cj rj 1 γand from equations (24) and (47) it follows that ρ G j (γ) < ρ I j (γ).
Proposition 5.
For any arrival rate and service time distribution it holds SI ⊆ SG Proof.
From Theorems 1 and 3 (equations (27) and (49)) it is sufficient to prove that γ G > γ I .
We prove the statement by contradiction.
Assume thatγ G ≤ γ I .
If γ I < cj/rj, then ρ I j (γ) = ρ G j (γ) = 0.
If γ I > cj/rj then ρ I j (γ I) > 0 and from Lemma 1 we haveρ I j = ρ I j (γ I ) γ I ≥γ G ≥ ρ I j (γ G ) Lemma 1 > ρ G j (γ G ) = ρ G j .
It follows then that P C j=1 rj(ρ I j − ρ G j ) > 0, but this is a contradiction with (3), and as a consequence γ G > γ I .
In the following theorem we show that the individual optimal overloads the servers with smallest cj/rj.
Theorem 4.
There exists an index i * such that  ρ G j < ρ I j j < i * ρ G j > ρ I j j ≥ i * .
Proof.
Due to constrain (3), there exists an index i * such that ρ G i * > ρ I i * .
Now it suffices to show that ρ G j > ρ I j , for all j > i * .
From (24) and (47) we have thatρ G i * > ρ I i * r ci * ri * r 1 γ G < ci * ri * 1 γ I γ I < r ci * ri * p γ G .
Since j > i * , it follows that cj/rj > ci * /ri * .
Thusγ I < r ci * ri * p γ G < r cj rj p γ G = c j r j q c j r j p γ G ,and rearranging we get qc j r j q 1 γ G < c j r j 1 γ I .
From (24) and (47) it follows that ρ G j > ρ I j .
We now study the so-called Price of Anarchy.
Definition.
The price of anarchy (PoA) is defined as the ratio between the performance (mean delay) obtained by the Wardrop equilibrium and the global optimal solution [15] (see also [20]).
By Little's law, calculating the ratio between the mean delays is equivalent to calculating the ratio of the mean number of users.
Then from the objective function (7) and the solution of Theorems 1 and (3) we get (note that x1−x = 1 1−x −1): P oA = P k∈S I c k P k∈S I r k P k∈S I r k −η − P k∈S I c k " P k∈S G √ c k r k " 2 P k∈S G r k −η − P k∈S G c k .
(51)The Price of Anarchy has been studied as a measure of the inefficiency of selfish-routing (or non-cooperative decentralized) in networks.
This measure has received lot of attention in recent years.
For example, in an important general result, it has been shown that when the cost function in every arc is linear, then for any arbitrary multi-commodity network the PoA is upper bounded by 4/3 [20].
In [11] and [22] the authors study a multi-server system with the objective of minimizing (7) with equal costs, that is, cj = c, ∀j, and show that P oA ≤ C, with C denoting the number of servers.
Note that the upper bound holds for any parameter configuration.
In addition, in [11, Example 3.1] it is shown that the upper bound is tight, i.e., there exists a network configuration such that the PoA is arbitrarily close to C.
This result indicates that the inefficiency of selfish routing is limited.
In Theorem 5 we show that this changes dramatically when holding costs per unit of time associated to each server are considered in the objective function.
In this case the PoA is unbounded, that is, for every θ < ∞, there exist a set of values such that P oA > θ.
Our main result on the Price of Anarchy is the following.Theorem 5.
For every θ, there exist cj and rj, j ∈ S, such that P oA > θ.Proof.
In order to prove this result we construct an example in which P oA can be unbounded.
Let r1 > η, and letcj = rj = 1 for 2 ≤ j ≤ C. Let (r1 − η) r1 < c1 < r1 − η.
(52)For this particular choice of costs and server speeds, cj/rj is non-decreasing in j.We first show that in the globally optimal multi-strategy all the servers are used, whereas in the solution of the individual optimization problem only the first server is used.Global optimization: Note that cj/rj = 1, ∀j ≥ 2.
In view of (17), server j, j ≥ 2, will be used ifj X k=1 √ cjrj = √ c1r1 + j − 1 > r1 − η + j − 1 = j X k=1 rj − η !
r cj rj ,where the inequality follows from the assumption c1 > (r 1 −η) 2 r 1 .
Since this is true for every j ≤ C, the load on every server is positive.Individual optimization: For j = 2, the left-hand side of (41) we havec1 + c2 = c1 + r2 < r1 − η + r2 = (r1 + r2 − η) r c2 r2 ,where the inequality follows from the assumption c1 < r1−η.
Thus, in the non-cooperative setting all the jobs choose to go to the first server.
From (51), the Price of AnarchyP oA = " c1r1 r1 − η − c1 « × 1 ( P k∈S G √ c k r k ) 2 P k∈S G r k −η − P k∈S G c k = c1η r1 − η × r1 − η + (C − 1) ( √ c1r1 + (C − 1)) 2 − (c1 + (C − 1))(r1 − η + (C − 1)) (53) Since (r 1 −η) 2 r 1 < c1 < r1 − η, let c1 = 1 2 " (r1 − η) 2 r1 + r1 − η « = (r1 − η) 2r1 − η 2r1 .
(54)Now as r1 ↓ η, the numerator of (53) tends to η 2 (C − 1), whereas the denominator tends to 0.
Therefore, by choosing r1 close enough to η, the Price of Anarchy for this system can be made to exceed any given real number.Remark 5.
We note that examples where the PoA is unbounded have been previously found.
For instance, it is easy to determine an instance of the popular Prisoner's dilemma where the PoA is unbounded.
It also follows from the network studied in [12] that the PoA is unbounded.
In order to provide an intuitive idea behind Theorem 5, first note that a key underlying idea is that in the global optimal all servers are used, whereas in the non-cooperative setting only one server is used.
This property follows directly from the the upper and lower bounds of (52).
Let us consider the lower bound in (52).
From equations (26) and (27) and the water-filling structure of the solution, we see that if r 1 c 1 (r 1 −η) 2 < c 2 r 2 = 1, only server 1 will be used.
Server 2 (and similarly all other servers), will start being used exactly when c1 > (r1 − η) 2 /r1, which explains the lower bound on c1 in (52).
Similarly, from (48) and (49) we can see that the upper bound in (52) guarantees that only server 1 is used in the non-cooperative setting.As we have seen, the Price of Anarchy is given by P oA =minp P C j=1 c j E[N I j ] minp P C j=1 c j E[N G j ].
Let us look to the numerator and denominator separately.In the non-cooperative solution only server 1 is used.
Thus P C j=1 cjE[N I j ] = c1E [N I 1 ], and server 1 is a standard M/G/1 queue.
Thus, as r1 ↓ η, E [N I 1 ] tends to infinity, but this is compensated by the fact that c1 → 0, and overall c1E[N I 1 ] → η/2.
Another way to see this is from equation (33), where we see that τi1 = c 1 r 1 −η .
Thus, with c1 given from (54), it turns out that as r1 ↓ η, the performance (weighted with the cost) that users joining server 1 remains unchanged.In the global optimal solution, always all servers are used.
As r1 ↓ η, the global optimal also tends to route everything towards server 1, but the key property is that since all servers are used, the global optimal can do this in such a way that E[N G 1 ] grows more slowly than the decrease of c1, and as a consequence This result states that the P oA is unbounded for the load balancing problem under consideration.
It is in complete contrast to finite upper bounds obtained by [11,22], for similar models but without holding costs per unit of time associated to each server.
Thus, when holding costs are taken into account, a significantly different P oA is obtained.
The case when rj and cj/rj are not equal Theorem 5 can be extended to the case when not all rj are equal and cj/rj are not necessarily equal.Let r = P j∈S rj be the aggregate available service rate of system.
Let us assume that we are given a sequence of server rates rj such that r1 > η.
We wish to show that there exists a sequence {cj, j ∈ S}, such that cj/rj is strictly increasing and that the following two inequalities are satisfied SThe work of the third author was carried out while he was a post-doctoral fellow with the CWI (Amsterdam), TU/e (Eindhoven) and EURANDOM (Eindhoven).
He wishes to acknowledge their support.
The work of the third author was carried out while he was a post-doctoral fellow with the CWI (Amsterdam), TU/e (Eindhoven) and EURANDOM (Eindhoven).
He wishes to acknowledge their support.
