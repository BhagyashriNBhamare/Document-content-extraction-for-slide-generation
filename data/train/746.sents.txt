We consider a wireless broadcast station that transmits packets to multiple users.
The packet requests for each user may overlap, and some users may already have certain packets.
This presents a problem of broadcasting in the presence of side information, and is a generalization of the well known (and unsolved) index coding problem of information theory.
Rather than achieving the full capacity region, we develop a code-constrained capacity region, which restricts attention to a pre-specified set of coding actions.
We develop a dynamic max-weight algorithm that allows for random packet arrivals and supports any traffic inside the code-constrained capacity region.
Further, we provide a simple set of codes based on cycles in the underlying demand graph.
We show these codes are optimal for a class of broadcast relay problems.
Consider a wireless broadcast station that transmits packets to N wireless users.
Packets randomly arrive to the broadcast station.
Each packet p is desired by one or more users in the set {1, . . . , N }.
Further, there may be one or more users that already have the packet stored in their cache.
The broadcast station must efficiently transmit all packets to their desired users.
We assume time is slotted with unit slots t ∈ {0, 1, 2, . . .}, and that a single packet can be transmitted by the broadcast station on every slot.
This packet is received errorfree at all users.
We assume that only the broadcast station can transmit, so that users cannot transmit to each other.If the broadcast station has P packets at time 0, and no more packets arrive, then the mission can easily be completed in P slots by transmitting the packets one at a time.
However, this approach ignores the side-information available at each user.
Indeed, it is often possible to complete the mission in fewer than P slots if packets are allowed to be mixed before transmission.
A simple and well known example for 2 users is the following: Suppose user 1 has packet B but wants packet A, while user 2 has packet A but wants packet B. Sending each packet individually would take 2 slots, but these demands can be met in just one slot by transmitting the mixed packet A+B, the bit-wise XOR of A and B.
Such examples are introduced in [1][2] [3] in the context of wireless network coding.The general problem, where each packet is contained as side information in an arbitrary subset of the N users, is much more complex.
This problem is introduced by Birk and Kol in [4] [5], and is known as the index coding problem.
Methods for completing a general index coding mission in minimumThe authors are with the Electrical Engineering department at the University of Southern California, Los Angeles, CA.This material is supported in part by one or more of the following: the DARPA IT-MANET program grant W911NF-07-0028, the NSF Career grant CCF-0747525, NSF grant 0964479, the Network Science Collaborative Technology Alliance sponsored by the U.S. Army Research Laboratory W911NF-09-2-0053.
time are unknown.
However, the recent work [6] shows that if one restricts to a class of linear codes, then the minimum time is equal to the rank of the minimum rank matrix that solves a certain matrix completion problem.
The matrix completion problem is NP-hard in general, and hence index coding is complex even when restricted to a simpler class of codes.Nevertheless, it is important to develop systematic approaches to these problems.
That is because current wireless cellular systems cannot handle the huge traffic demands that are expected in the near future.
This is largely due to the consistent growth of wireless video traffic.
Fortunately, much of the traffic is for popular content.
That is, users often download the same information.
Thus, it is quite likely that a system of N users will have many instances of side information, where some users already have packets that others want.
This naturally creates an index coding situation.
Thus, index coding is both rich in its mathematical complexity and crucial for supporting future wireless traffic.The problem we consider in this paper is even more complex because packets can arrive randomly over time.
This is a practical scenario and creates the need for a dynamic approach to index coding.
We assume there are M traffic types, where a type is defined by the subset of users that desire the packets and the subset that already has the packets.
Let λ m be the arrival rate, in packets/slot, for type M traffic.
We approach this problem by restricting coding actions to an abstract set A.
We then show how to achieve the code constrained capacity region Λ A , being the set of all rate vectors (λ m ) M m=1 that can be supported using coding actions in the set A.
The set Λ A is typically a strict subset of the capacity region Λ, which does not restrict the type of coding action.
Our work can be applied to any set A, and hence can be used in conjunction with any desired codes.
However, we focus attention on a simple class of codes that involve only bit-wise XOR operations, based on cycles in the underlying demand graph.
In special cases of broadcast relay problems, we show that these codes can achieve the full capacity region Λ.The capacity region Λ is directly related to the conceptually simpler static problem of clearing a fixed batch of packets in minimum time.
Further, index coding concepts are most easily developed in terms of the static problem.
Thus, this paper is divided into two parts: We first introduce the index coding problem in the static case, and we describe example coding actions in that case.
Section III extends to the dynamic case and develops two max-weight index coding techniques, one that requires knowledge of the arrival rates (λ m ), and one that does not.
The max-weight algorithms developed in this paper are new and contribute to the general theory of dynamic scheduling.
They can be used in other types of networks where controllers make sequences of actions, each action taking a different number of slots and delivering a different vector of packets.While the static index coding problem has been studied before [6][5] [4], our work provides new insight even in the static case.
We introduce a new directed bipartite demand graph that allows for arbitrary demand subsets and possibly "multiple multicast" situations, where some packets are desired by more than one user.
We also form a useful weighted compressed graph that facilitates the solution to the minimum clearance time problem in certain cases.
This extends the graph models in [6], which do not consider the possibility of multiple multicast sessions.
Work in [6] develops a maximum acyclic subgraph bound on minimum clearance time for problems without multiple multicast sessions.
We extend this bound to our general problem using a different and independent proof technique.
Further, we consider a class of broadcast relay problems for which the bound can be achieved with equality.The next section introduces index coding in the static case, shows its relation to a bipartite demand graph, and presents the acyclic subgraph bound.
Section III introduces the general dynamic formulation and develops our max-weight algorithms.
Section IV considers an important class of broadcast relay networks for which a simple set of codes are optimal.
This section introduces the index coding problem in the static case, where we want to clear a fixed batch of packets in minimum time.
Consider a wireless system with N users, P packets, and a single broadcast station.
We assume N and P are positive integers.
Let N and P represent the set of users and packets, respectively:N = {1, . . . , N } , P = {1, . . . , P }The broadcast station has all packets in the set P. Each user n ∈ N has an arbitrary subset of packets H n ⊆ P, and wants to receive an arbitrary subset of packets R n ⊆ P, where H n ∩ R n = φ, where φ represents the empty set.
Assume that all packets consist of B bits, all packets are independent of each other, and the B-bit binary string for each packet is uniformly distributed over each of the 2 B possibilities.We can represent this system by a directed bipartite demand graph G defined as follows (see Fig. 1):• User nodes N are on the left.
• Packet nodes P are on the right.
• A directed link (n, p) from a user node n ∈ N to a packet node p ∈ P exists if and only if user n has packet p.
That is, if and only if p ∈ H n .
• A directed link (p, n) from a packet node p ∈ P to a user node n ∈ N exists if and only if user n wants to receive packet p.
That is, if and only if p ∈ R n .
As an example for the 3-user, 5-packet graph of Fig. 1, the have and receive sets for nodes 1 and 2 are:H 1 = {5} , R 1 = {1, 2} H 2 = φ , R 2 = {1, 2, 4}We restrict attention to packets that at least one node wants.
Thus, without loss of generality, throughout we assume the graph G is such that all packet nodes p ∈ P contain at least one outgoing link.
Thus:P = {1, . . . , P } = ∪ N n=1 R n(1)In this static problem, the broadcast station has all packets in the set P at time 0, and no more packets ever arrive.
Every slot t ∈ {0, 1, 2, . . .} the broadcast station can transmit one B-bit message over the broadcast channel.
This message is received without error at all of the user nodes in the set N .
The goal is for the broadcast station to send messages until all nodes receive the packets they desire.Define a mission-completing coding action with T slots to be a sequence of messages that the broadcast station transmits over the course of T slots, such that all users are able to decode their desired packets at the end of the T slots.
We restrict attention to deterministic zero-error codes that enable decoding with probability 1.
The initial information held by each user n ∈ N is given by the set of packets H n (possibly empty).
Let M = {M 1 , . . . , M T } represent the messages transmitted by the broadcast station over the course of the T slot coding action.
At the end of this action, each node n ∈ N has information {H n , M}.
Because the coding action is assumed to complete the mission, this information is enough for each node n to decode its desired packets R n .
That is, we can write:{H n , M} ⇐⇒ {H n , M, R n }(2)where the above represents equivalence in the information set, meaning that the information on the left-hand-side can be perfectly reconstructed from the information on the righthand-side, and vice versa.
Clearly the information on the left in (2) is a subset of the information on the right, and hence can trivially be reconstructed.
The information on the right in (2) can be reconstructed from that on the left because the code is mission-completing.
For a given graph G with P packet nodes, define T min (G) as the minimum clearance time of the graph, being the minimum number of slots required to complete the mission, considering all possible coding techniques.
Clearly T min (G) ≤ P .
Our goal is to understand T min (G).
For a directed graph, we say that a simple directed cycle of length K is a sequence of nodes {n 1 , n 2 , . . . , n K , n 1 } such that (n i , n i+1 ) is a link in the graph for all i ∈ {1, . . . , K −1}, (n K , n 1 ) is a link in the graph, and all nodes {n 1 , . . . , n K } involved in the cycle are distinct.
For simplicity, throughout this paper we use the term cycle to represent a simple directed cycle.
We say that the graph G is acyclic if it contains no cycles.
Note that directed acyclic graphs have a much different structure than undirected acyclic graphs.
Indeed, the graph in Fig. 1 is acyclic even though its undirected counterpart (formed by replacing all directed links with undirected links) has cycles.Our first result is to prove that if a directed bipartite demand graph G is acyclic, then coding cannot reduce the minimum clearance time.
This result was first proven in [6] in the case without "multiple multicasts," so that each packet is desired by at most one user.
That result uses an argument based on machinery of the mutual information function.
It also treats a more general case where codes can have errors.
Further, their proof is developed as a consequence of a more general and more complex result.
Our work restricts to zero-error codes, but allows the possibility of multiple-multicast sessions.
We also use a different proof technique, developed independently, which emphasizes the logical consequences of users being able to decode.
Our proof uses only the following two facts:Fact 1: Every directed acyclic graph with a finite number of nodes has at least one node with no outgoing links.
Such a node is called a "leaf" node.Fact 2: If the graph contains only one user node, then T min (G) = P , where P is the number of packets that this user desires.
Fact 1 follows simply by starting at any node in the graph and traversing a path from node to node, using any outgoing link, until we find a leaf node (such a path cannot continue forever because the graph is finite and has no cycles).
Fact 2 is a basic information theory observation about the capacity of a single error-free link.Theorem 1: If the graph G is acyclic, then T min (G) = P , where P is the total number of packets in the graph.Proof: See Appendix A.As an example, because the graph G in Fig. 1 is acyclic, we have T min (G) = 5.
Theorem 1 shows that coding cannot help if G is acyclic, so that the best one can do is just transmit all packets one at a time.
Therefore, any type of coding must exploit cycles on the demand graph.
Theorem 1 provides a simple lower bound on T min (G) for any graph G. Consider a graph G, and form a subgraph G by performing one or more of the following pruning operations:• Remove a packet node, and all of its incoming and outgoing links.
• Remove a user node, and all of its incoming and outgoing links.
• Remove a packet-to-user link (p, n).
After performing these operations, we must also delete any residual packets that have no outgoing links.
Any sequence of messages that completes the mission for the original graph G will also complete the mission for the subgraph G .
This leads to the following simple lemma.Lemma 1: For any subgraph G formed from a graph G by one or more of the above pruning operations, we have:T min (G ) ≤ T min (G)Combining this lemma with Theorem 1, we see that we can take a general graph G with cycles, and then perform the above pruning operations to reduce to an acyclic subgraph G .
Then T min (G) is lower bounded by the number of packets in this subgraph.
Thus, the best lower bound corresponds to the acyclic subgraph generated from the above operations, and that has the largest number of remaining packets.
Note that the above pruning operations do not include the removal of a user-to-packet link (n, p) (without removing either the entire user or the entire packet), because such links represent side information that can be helpful to the mission.
Theorem 1 considers all possible zero-error coding techniques.
However, because the general index coding problem is difficult, it is useful to restrict the solution space to consider only sequences of simple types of coding actions.
Recall that coding actions must exploit cycles.
One natural action is the following: Suppose we have a cycle in G that involves a subset of K users.
For simplicity label the users {1, . . . , K}.
In the cycle, user 2 wants to receive a packet X 1 that user 1 has, user 3 wants to receive a packet X 2 that user 2 has, and so on.
Finally, user 1 wants to receive a packet X K that user K has.
The structure can be represented by:1 → 2 → 3 → . . . → K → 1(3)where an arrow from one user to another means the left user has a packet the right user wants.
Of course, the users in this cycle may want many other packets, but we are restricting attention only to the packets X 1 , . . . , X K .
Assume these packets are all distinct.In such a case, we can satisfy all K users in the cycle with the following K − 1 transmissions: For each k ∈ {1, . . . , K − 1}, the broadcast station transmits a message M k = X k + X k+1 , where addition represents the mod-2 summation of the bits in the packets.
Each user k ∈ {2, . . . , K} receives its desired information by adding M k−1 to its side information:X k + M k−1 = X k + (X k−1 + X k ) = X k−1Finally, user 1 performs the following computation (using the fact that it already has packet X 1 ):X 1 + M 1 + M 2 + . . . + M K−1 = X 1 + (X 1 + X 2 ) + (X 2 + X 3 ) + . . . + (X K−1 + X K ) = (X 1 + X 1 ) + (X 2 + X 2 ) + . . . + (X K−1 + X K−1 ) +X K = X KThus, such an operation can deliver K packets in only K −1 transmissions.
We call such an action a K-cycle coding action.
We define a 1-cycle coding action to be a direct transmission.
Note that 2-cycle coding actions are the most "efficient," having a packet/transmission efficiency ratio of 2/1, compared to K/(K − 1) for K ≥ 2, which approaches 1 (the efficiency of a direct transmission) as K → ∞.
While it is generally sub-optimal to restrict to such cyclic coding actions, doing so can still provide significant gains in comparison to direct transmission.
Further, we show in Section IV that such actions are optimal for certain classes of broadcast relay problems.Another important type of code action takes advantage of "double-cycles" in G: Suppose for example that user 1 wants packet A and has packets B and C, user 2 wants packet B and has packets A and C, and user 3 wants packet C and has packets A and B.
Then these demands can be fulfilled with the single transmission A + B + C, being a binary XOR of packets A, B, C.
The efficiency ratio of this action is 3/1.
Now consider a dynamic setting where the broadcast station randomly receives packets from M traffic flows.
Each flow m ∈ {1, . . . , M } contains fixed-length packets that must be delivered to a subset N m of the users, and these packets are contained as side-information in a subset S m of the users.
We assume N m ∩ S m = φ, since any user n ∈ N m who wants the packet clearly does not already have the packet as side information.
In the general case, M can be the number of all possible disjoint subset pair combinations.
However, typically the value of M will be much smaller than this, such as when each traffic flow represents packets from a very large file, and there are only M active file requests.Assume time is slotted with unit slots t ∈ {0, 1, 2, . . .}, and let A(t) = (A 1 (t), . . . , A M (t)) be the number of packets that arrive from each flow on slot t. For simplicity of exposition, we assume the vector A(t) is i.i.d. over slots with expectation:E {A(t)} = λ = (λ 1 , . . . , λ M )where λ m is the arrival rate of packets from flow m, in units of packets/slot.
For simplicity, we assume that A m (t) ∈ {0, 1} for all m and all t, so that at most one new packet can arrive per flow per slot.
This is reasonable because the maximum delivery rate in the system is one packet per slot, and so any packets that arrive as a burst can be "smoothed" and delivered to the network layer at the broadcast station one slot at a time.
Packets of each flow m are stored in a separate queue kept at the broadcast station, and exit the queue upon delivery to their intended users.We now segment the timeline into frames, each frame consisting of an integer number of slots.
At the beginning of each frame r, the network controller chooses a coding action α [r] within an abstract set A of possible actions.
For each α ∈ A, there is a frame size T (α) and a clearance vector µ(α).
The frame size T (α) is the number of slots required to implement action α, and is assumed to be a positive integer.
The clearance vector µ(α) has components (µ 1 (α), . . . , µ M (α)), where µ m (α) is the number of type m packets delivered as a result of action α.
We assume µ m (α) is a non-negative integer.
When frame r ends, a new frame starts and the controller chooses a (possibly new) action α[r+1] ∈ A.
We assume each coding action only uses packets that are delivered as a result of that action, so that there is no "partial information" that can be exploited on future frames.
We further assume there are a finite (but arbitrarily large) number of coding actions in the set A, and that there are positive numbers T max and µ max such that 1 ≤ T (α) ≤ T max and 0 ≤ µ(α) ≤ µ max for all α ∈ A.Assume that frame 0 starts at time 0.
Define t[0] = 0, and for r ∈ {0, 1, 2, . . .} define t [r] as the slot that starts frame r. Let Q[r] = (Q 1 [r], . . . , Q M [r]) be the queue backlog vector at the beginning of each frame r ∈ {0, 1, 2, . . .}.
Then:Q m [r + 1] = max[Q m [r] − µ m (α[r]), 0] + arrivals m [r] (4)where arrivals m [r] is the number of type m arrivals during frame r:arrivals m [r] = t[r]+T (α[r])−1 τ =t[r] A m (τ )(5)The max [·, 0] operator in the queue update equation (4) in principle allows actions α[r] ∈ A to be chosen independently of the queue backlog at the beginning of a frame.
In this case, if the action α[r] attempts to deliver one or more packets from queues that are empty, null packets are created and delivered.
In practice, these null packets do not need to be delivered.
Our focus is on index coding problems with action sets A defined by a specific set coding options, such as the set of all cyclic coding actions.
For example, an action α that is a 2-cyclic coding action that uses packets of type m and k has T (α) = 1 and µ(α) being a binary vector with 1s in entries m and k and zeros elsewhere.
However, the above model is general and can also apply to other types of problems, such as multi-hop networks where actions α ∈ A represent some sequence of multi-hop network coding.
We say that queue Q m [r] is rate stable if:lim R→∞ Q m [R] R = 0 (with probability 1) It is not difficult to show that Q m [R]is rate stable if and only if the arrival rate λ m is equal to the delivery rate of type m traffic [7].
The code-constrained capacity region Λ A is the set of all rate vectors (λ 1 , . . . , λ M ) for which there exists an algorithm for selecting α[r] ∈ A over frames that makes all queues rate stable.
Theorem 2: A rate vector λ is in the code-constrained capacity region Λ A if and only if there exist probabilities p(α) such that α∈A p(α) = 1 and:λ m ≤ α∈A p(α)µ m (α) α∈A p(α)T (α) ∀m ∈ {1, . . . , M }(6)Proof: The proof that such probabilities p(α) necessarily exist whenever λ ∈ Λ A is given in Appendix B. Below we prove sufficiency.
Suppose such probabilities p(α) exist that satisfy (6).
We want to show that λ ∈ Λ A .
To do so, we design an algorithm that makes all queues Q m [r] in (4) rate stable.
By rate stability theory in [7], it suffices to design an algorithm that has a frame average arrival rate to each queue Q m [r] that is less than or equal to the frame average service rate (both in units of packets/frame).
Consider the algorithm that, every frame r, independently chooses action α ∈ A with probability p(α).
Let α * [r] represent this random action chosen on frame r. Then{T (α * [r])} ∞ r=0 is an i.i.d. sequence, as is {µ m (α * [r])} ∞ r=0for each m ∈ {1, . . . , M }.
By the law of large numbers, the frame average arrival rate arrivals m and the frame average service µ m (both in packets/frame) are equal to the following with probability 1:µ m = E {µ m (α * [r])} = α∈A p(α)µ m (α) arrivals m = λ m E {T (α * [r])} = λ m α∈A p(α)T (α)We thus have for each m ∈ {1, . . . , M }:arrivals m µ m = λ m α∈A p(α)T (α) α∈A p(α)µ m (α) ≤ 1where the final inequality follows by (6).
Theorem 2 shows that all traffic can be supported by a stationary and randomized algorithm that independently chooses actions α * [r] ∈ A with probability distribution p(α).
This does not require knowledge of the queue backlogs.
However, computing probabilities p(α) that satisfy (6) would require knowledge of the arrival rates λ m , and is a difficult computational task even if these rates are known.
We provide two dynamic algorithms that use queue backlog information.
These can also be viewed as online computation algorithms for computing probabilities p(α).
Both are similar in spirit to the max-weight approach to dynamic scheduling in [8], but the variable frame lengths require a new approach that contributes to the general theory of dynamic scheduling.
Our first algorithm assumes knowledge of the arrival rates λ m .
Max-Weight Code Selection Algorithm 1 (Known λ): At the beginning of each frame r, observe the queue backlogs Q m [r] and perform the following:• Choose code action α[r] ∈ A as the maximizer of:M m=1 Q m [r][µ m (α[r]) − λ m T (α[r])](7)where ties are broken arbitrarily.
• Update the queue equation via (4).
The next algorithm uses a ratio rule, and does not require knowledge of the rates λ m :Max-Weight Code Selection Algorithm 2 (Unknown λ): At the beginning of each frame r, observe the queue backlogs Q m [r] and perform the following:• Choose code action α[r] ∈ A as the maximizer of:M m=1 Q m [r] µ m (α[r]) T (α[r])(8)where ties are broken arbitrarily.
• Update the queue equation via (4).
Theorem 3: Suppose that λ ∈ Λ A .
Then all queues are rate stable under either of the two algorithms above.Proof: See Appendix C.It can further be shown that if there is a value ρ such that 0 ≤ ρ < 1, and if λ ∈ ρΛ A , being a ρ-scaled version of Λ A , then both algorithms give average queue size O(1/(1 − ρ)).
Thus, the average backlog bound increases to infinity as the arrival rates are pushed closer to the boundary of the capacity region.
We omit the proof for brevity (see [9]).
Define˜ADefine˜ Define˜A as the action space that restricts to direct transmissions, 2-cycle code actions, 3-cycle code actions, and the 1-slot A + B + C code action that exploits double cycles, as described in Section II-B.
Algorithm 2 has a particularly simple implementation on action space˜Aspace˜ space˜A and when each packet has at most one destination.
Indeed, we note that cycles can be defined purely on the user set N , and any candidate cycle that involves a user-to-user part i → j should use a packet of commodity m ∈ {1, . . . , M } that maximizes Q m [r] over all commodities m that consist of packets intended for user j and contained as side information at user i. Fig. 2 presents simulation results for a system with N = 3 users, with action space˜Aspace˜ space˜A as defined above.
We consider only algorithm 2, which does not require knowledge of rates λ m , and compare against uncoded transmissions.
All packets are intended for at most one user.
Packets intended for user n ∈ {1, 2, 3} arrive as independent Bernoulli processes with identical rates λ.
We assume each packet is independently in the cache of the other two users with probability 1/2.
Thus, there are four types of packets intended for user 1: Packets not contained as side information anywhere, packets contained as side information at user 2 only, packets contained as side information at user 3 only, and packets contained as side information at both users 2 and 3.
Users 2 and 3 similarly have 4 traffic types, for a total of M = 12 traffic types.
Each data point in Fig. 2 represents a simulation over 5 million frames at a given value of λ.
The figure plots the resulting total average number of packets in the system (summed over all 12 queues).
The case of direct (uncoded) transmission is also shown.
Uncoded transmission can support a maximum rate of λ = 1/3 (for a total traffic rate of 1).
It is seen that algorithm 2 can significantly outperform uncoded transmission, achieving stability at rates up to λ = 0.57 (for a total traffic rate of 1.71).
Fig. 3.
An illustration of a 2-user broadcast relay system, with the 3 possible transmission modes shown.
In mode 3, packet p 3 is received at both users.
Consider now the following related problem: There are again N users and a single broadcast station.
However, the broadcast station initially has no information, and acts as a relay to transfer independent unicast data between the users.
Further, the users only know their own data, and initially have no knowledge of data sourced at other users.
Time is again slotted, and every slot we can choose from one of N +1 modes of transmission.
The first N transmission modes involve an error-free packet transmission from a single user to the relay.
The (N +1)th transmission mode is where the relay broadcasts a single packet that is received error-free at each of the N users.
Fig. 3 illustrates an example system with 2 users, where the 3 possible transmission modes are shown.
For simplicity, we assume the user transmissions cannot be overheard by other users, and the users first send all packets to the relay.
The relay then can make coding decisions for its downlink transmissions.
First consider a static problem where a batch of packets must be delivered in minimum time.
Let P ij represent the number of packets that user i wants to send to user j, where i, j ∈ {1, . . . , N }.
All packets are independent, and the total number of packets is P , where:P = N i=1 N j=1P ij This problem is related to the index coding problem as follows: Suppose on the first P slots, all users send their packets to the relay on the uplink channels.
It remains for the relay to send all users the desired data, and these users have side information.
The resulting side information graph G is the same as in the general index coding problem.
However, it has the following special structure: The only user that has side information about a packet is the source user of the packet.
Specifically:• Each packet is contained as side information in exactly one user.
Thus, each packet node of G has a single incoming link from some user that is its source.
• Each packet has exactly one user as its destination.
Thus, each packet node of G has a single outgoing link to some user that is its destination.
This special structure leads to a simplified graphical model for demands, which we call the weighted compressed graph WC(G) of G.
The graph WC(G) is formed from G as follows: It is a directed graph defined on the user nodes N only, and contains a link (a, b) if and only if the original graph G specifies that user node a has a packet that user node b wants.Further, each link (a, b) is given a positive integer weight P ab , the number of packets user a wants to send to user b.
It is easy to show that WC(G) is acyclic if and only if G is acyclic.
Hence, coding can only help if WC(G) contains cycles, and so T min (G) = P whenever WC(G) is acyclic.We say the weighted compressed graph WC(G) has disjoint cycles if each link participates in at most one simple cycle.
An example is shown in Fig. 4.
Consider such a graph that has C disjoint cycles.
Let w min c be the min-weight link on each disjoint cycle c ∈ {1, . . . , C}.
Theorem 4: If the broadcast relay problem has a weighted compressed graph WC(G) with disjoint cycles, then:T min (G) = P − C c=1 w min c(9)and so the full clearance time (including the P uplink transmissions) is the above number plus P .
Further, optimality can be achieved over the class of cyclic coding actions, as described in Section II-B.
As an example, the graph WC(G) in Fig. 4a has P = 48, three disjoint cycles with w min Proof: For brevity, we present only an abbreviated argument to prove (9).
First prune the graph WC(G) by removing the min-weight link on each of the disjoint cycles (breaking ties arbitrarily).
This corresponds to removing those packets from the original graph G, to produce a new graph G with exactly P − C c=1 w min c packets.
The weighted compressed graph WC(G ) is the subgraph of WC(G) with the min-weight links on each disjoint cycle removed (see Fig. 4a and Fig. 4b).
Both G and WC(G ) are acyclic, and so:T min (G) ≥ T min (G ) = P − C c=1 w min cIt remains only to construct a coding algorithm that achieves this lower bound.
This can be done easily by using w min c separate cyclic coding actions for each of the disjoint cycles (using a k-cycle coding action for any cycle of length k), and then directly transmitting the remaining packets.
Suppose we have a broadcast relay problem with N users, packet matrix (P ij ), and with the following additional structure: Each user i ∈ {1, . . . , N } wants to send data to only one other user.
That is, the matrix (P ij ) has at most one nonzero entry in each row i ∈ {1, . . . , N }.
We now show that the resulting graph WC(G) has disjoint cycles.
To see this, suppose it is not true, so that there are two overlapping cycles.Then there must be a shared link (a, b) that continues to a link (b, k) for cycle 1 and (b, m) for cycle 2, where k = m.
This means node b has two outgoing links, a contradiction because matrix (P ij ) has at most one non-zero entry in row b, and hence at most one outgoing link from node b.
We conclude that WC(G) has disjoint cycles, and so cyclic coding is optimal via Theorem 4.
A similar argument holds if each user wants to receive from at most one other user, so that (P ij ) has at most one non-zero entry in every column.
Again, WC(G) has disjoint cycles, and so cyclic coding is optimal.
Now consider the dynamic case where packets from source user i and destination user j arrive with rate λ ij packets/slot.
Suppose we have an abstract set of coding actions A, where each action involves a subset of packets, and first transmits these packets to the relay before any coding at the relay.
Let T (α) be the number of slots to complete the action, and (µ ij (α)) be the matrix of packets delivered by the action.
It can be shown that capacity can be approached arbitrarily closely by repetitions of minimum-clearance time scheduling on large blocks of the incoming data (similar to the capacity treatment in [10] for a limit of large packet size).
Hence, if T min (G) can be optimally solved using only cyclic-coding actions, then capacity is also achieved in the max-weight algorithms when A is restricted to cyclic-coding actions.
It follows that such actions are optimal for rate matrices (λ ij ) with at most one non-zero entry per row, and for rate matrices (λ ij ) with at most one non-zero entry per column.
Can we minimize clearance time by grabbing any available 2-cycle, then any available 3-cycle if no 2-cycle is available, and so on?
Not necessarily.
A simple counterexample is shown in Fig. 5a.
The graph has 5 users and 7 packets {A, . . . , G}, where each link has a single packet.
Using the middle 3-cycle 2 → 3 → 4 → 2 by transmitting B + D and D + E leaves a remaining acyclic graph with 4 packets, and hence would take 4 more transmissions, for a total of 6 slots.
However, using the two side cycles (with 2 transmissions each) and then transmitting the remaining packet E clears everything in 5 slots, which is optimal because the maximum acyclic subgraph has 5 packets (just remove links B and D).
One may wonder if all broadcast relay graphs can be optimally cleared with cyclic coding.
We can show this is true for N = 2 and N = 3 [9].
However, this is not true in general for N > 3.
Fig. 5b shows a counterexample with N = 6.
Suppose each link has a single packet, so that we have 9 packets {A, . . . , I}.
It can be shown that the maximum acyclic subgraph has 7 packets, and so T min (G) ≥ 7, but the best cyclic coding method uses 8 slots.
Here is a way to achieve 7 slots: Send messages M 1 = E+G+F , M 2 = H+E,M 3 = H + D, M 4 = A + B + H, M 5 = C + B, M 6 = C + G, M 7 = C + I + D.The decodings at users 2, 3, 4, 5, 6 are straightforward by combining their side information with just a single message.
The decoding at user 1 is done as follows:M 1 + M 2 + M 3 + M 6 + M 7 = F + I.Since user 1 knows F , it can decode I. M 3 + M 4 + M 5 + M 7 = A + I, since user 1 knows I it can get A. Proof: (Theorem 1) We already know that T min (G) ≤ P .
It suffices to show that T min (G) ≥ P .
Consider any missioncompleting coding action that takes T slots.
We show that T ≥ P .
Let M be the sequence of messages transmitted.
Then every node n ∈ N is able to decode its desired packets, being packets in the set R n , from the information {H n , M}, being the information it has at the end of the coding action.
That is, we have:{H n , M} ⇐⇒ {H n , M, R n } ∀n ∈ {1, . . . , N }(10)Because the graph is acyclic, there must be at least one node with no outgoing links (by Fact 1).
Choose such a node, and label this node n 1 .
The node n 1 cannot be a packet node, because we have assumed that all packet nodes have outgoing links.
Thus, n 1 ∈ N .
Because node n 1 has no outgoing links, it has H n1 = φ and thus has no initial side information about any of the packets.
Thus, it is able to decode all packets in the set R n1 by the messages M alone.
That is:M ⇐⇒ {M, R n1 }(11)We want to show that this node n 1 can decode all packets in the set P, so that:M ⇐⇒ {M, P}(12)If we can show that (12) holds, then the sequence of messages M is also sufficient to deliver P independent packets to node n 1 , and node n 1 did not have any initial side information about these packets.
Thus, the number of slots T used in the coding action must be at least P by Fact 2, proving the result.
Thus, it suffices to prove (12).
We prove (12) by induction on k, for k ∈ {1, . . . , N − 1}: Assume that there is a labeling of k distinct user nodes {n 1 , n 2 , . . . , n k } such that:{M} ⇐⇒ {M, R n1 , . . . , R n k }(13)This property holds for the base case k = 1 by (11).
We now assume that (13) holds for a general k ∈ {1, . . . , N − 1}, and prove it must also hold for k + 1.
Take the graph G, and delete the user nodes {n 1 , . . . , n k }, also deleting all links outgoing from and incoming to these nodes.
This may create packet nodes with no outgoing links: Delete all such packet nodes.Note that all deleted packet nodes (if any) must be in the set {R n1 , . . . , R n k }, being the set of packets desired by the users that are deleted.
The resulting subgraph must still be acyclic, and hence it must have a node n k+1 with no outgoing links.
This node must be a user node, as we have deleted all packet nodes with no outgoing links.
Because the user node n k+1 has no outgoing links, it either had H n k+1 = φ (so that it never had any outgoing links), or all of its outgoing links were pointing to packet nodes that we have deleted, and so those packets were in the set {R n1 , . . . , R n k }.
That is, we must have H n k+1 ⊆ {R n1 , . . . , R n k }.
Therefore:{M, H n k+1 } ⊆ {M, R n1 , . . . , R n k }(14)However, at the end of the coding action, node n k+1 has exactly the information on the left-hand-side of (14), and hence this information is sufficient to decode all packets in the set R n k+1 .
Thus, the information on the right-hand-side of (14) must also be sufficient to decode R n k+1 , so that:{M, R n1 , . . . , R n k } ⇐⇒ {M, R n1 , . . . , R n k , R n k+1 }But this together with (13) yields:{M} ⇐⇒ {M, R n1 , . . . , R n k , R n k+1 }which completes the induction step.
By induction over k ∈ {1, . . . , N − 1}, it follows that:{M} ⇐⇒ {M, R n1 , . . . , R n N }(15)However, by re-labeling we have:{R n1 , . . . , R n N } = {R 1 , . . . , R N } = P(16)where the final equality holds by (1).
Combining (15) and ( The set A is finite.
Thus, the values {(|F(α, R)|/R)} ∞ R=1 can be viewed as an infinite sequence of bounded vectors (with dimension equal to the size of set A) defined on the index R ∈ {1, 2, 3, . . .}, and hence must have a convergent subsequence.
Let R k represent the sequence of frames on this subsequence, so that there are values p(α) for all α ∈ A such that:lim k→∞ |F(α, R k )|/R k = p(α)The values p(α) inherit the property of being non-negative and summing to 1.
By (18) we have for all m ∈ {1, . . . , M }:lim k→∞ µ m [R k ] = α∈A p(α)µ m (α)(19)Likewise, from (17) and the law of large numbers (used over each α ∈ A for which lim k→∞ |F(α, R k )| = ∞, and noting that a m [r] is i.i.d. with mean T (α)λ m for all r ∈ F(α, R)) we have with probability 1:lim k→∞ a m [R k ] = α∈A p(α)T (α)λ m(20)Because each queue Q m [r] is rate stable, we have with probability 1 that for all m ∈ {1, . . . , M }:lim k→∞ Q m [R k ]/R k = 0(21)However, from the queue update equation (4) we have for all r ∈ {0, 1, 2, . . .}:Q m [r + 1] ≥ Q m [r] − µ m (α[r]) + a m [r]Summing the above over r ∈ {0, 1, . . . , R k − 1} and dividing by R k yields:Q m [R k ] − Q m [0] R k ≥ −µ m [R k ] + a m [R k ]Taking a limit as k → ∞ and using (19)-(21) yields:0 ≥ − α∈A p(α)µ m (α) + λ m α∈A p(α)T (α)(22)APPENDIX C -PROOF OF THEOREM 3We prove rate stability for Algorithm 2, which uses a ratio rule.
The proof for Algorithm 1 is simpler and is omitted for brevity (see [9]).
We have the following preliminary lemma.Lemma 2: (Sufficient Condition for Rate Stability [11]): Let Q[r] be a non-negative stochastic process defined over the integers r ∈ {0, 1, 2, . . .}.
Suppose there are constants B, C, D such that for all frames r ∈ {0, 1, 2, . . .} we have:E (Q[r + 1] − Q[r]) 2 ≤ D (23) E Q[r] 2 ≤ Br + C(24)Then lim r→∞ Q[r]/r = 0 with probability 1.
The condition (23) is immediately satisfied in our system because the queue changes over any frame are bounded.
Thus, to prove rate stability, it suffices to show that (24) holds for all queues and all frames.
That is, it suffices to prove the second moment of queue backlog grows at most linearly.
Lemma 3: Under any (possibly randomized) decision for α[r] ∈ A that is causal (i.e., that does not know the future values of arrivals over the frame), we have for each frame r:
