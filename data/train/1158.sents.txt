Constructions of k-wise almost independent permutations have been receiving a growing amount of attention in recent years.
However, unlike the case of k-wise independent functions, the size of previously constructed families of such permutations is far from optimal.
This paper gives a new method for reducing the size of families given by previous constructions.
Our method relies on pseudorandom generators for space-bounded computations.
In fact, all we need is a generator, that produces "pseudorandom walks" on undirected graphs with a consistent labelling.
One such generator is implied by Reingold's log-space algorithm for undirected connectivity [35, 36].
We obtain families of k-wise almost independent permutations, with an optimal description length, up to a constant factor.
More precisely, if the distance from uniform for any k tuple should be at most δ, then the size of the description of a permutation in the family is O(kn + log 1 δ).
In explicit constructions of pseudorandom objects, we are interested in simulating a large random object using a succinct one and would like to capture some essential properties of the former.
A natural way to phrase such a requirement is via limited access.
Suppose the object that we are interested in simulating is a random function f : {0, 1} n → {0, 1} n and we want to come up with a small family of functions G that simulates it.
The k-wise independence requirement in this case is that a function g chosen at random from G be completely indistinguishable from a function f chosen at random from the set of all functions, for any process that receives the value of either f or g at any k points of its choice.
We can also relax the requirement and talk about almost k-wise independence by requiring that the advantage of a distinguisher be limited by some δ.who sees a limited number of permuted credit card numbers and the original numbers (say its own cards) would not be able to obtain information on any other card for which it sees only the permuted value.
Furthermore, we would like to spread the permutation among the trusted servers at low cost (to save communication).
This means, that the permutation should be represented by a small number of bits.
Note that for this range even under cryptographic assumptions there is no ready made solution.
For instance, DES is a permutation on 2 64 values that is presumed pseudorandom, at least for sufficiently weak machines.
However, it is not clear how to use it in order to construct a permutation on 2 40 values.
This example may also point out practical values for which an efficient solution is needed.
While our main interest is description length, we discuss time efficiency in Section 6.
Our Technique and Main Results: we give a method for "derandomizing" essentially all previous constructions of k-wise almost independent permutations.
It is most effective, and easiest to describe for permutation families obtained by composition of simpler permutations.
As most previous constructions fall into this category, this is a rather general method.
In particular, based on any one of a few previous constructions, we obtain k-wise almost independent permutations with optimal description length, up to a constant factor.Consider a family of permutations F, with rather small description length s.
We denote by F t the family of permutations obtained by composing every t permutations f 1 , f 2 , . . . , f t in F.
Now assume that F t is a family of k-wise almost independent permutations.
The description length of F t is t · s as we need to describe t independent permutations from F.
We will argue that such constructions can be derandomized in the sense that it is sufficient to consider a subset of the t-tuples of F functions.
This will naturally reduce the overall description length.Our first idea uses generators that fool bounded space computations for the task of choosing the subset of F t , as we describe below.
Pseudorandomness for space-bounded computation has been a very productive area, see [27,28].
Such pseudorandomness has been used before in the context of combinatorial constructions where space is not an explicit issue by Indyk [15] and by Sivakumar [43].
Let g be the composition of t uniformly and independently selected f 1 , f 2 , . . . , f t in F. Let us also consider g which is the composition of t permutations f 1 , f 2 , . . . , f t in F, selected in some other manner.
Assume that the distribution on g is not k-wise almost independent.
This means that there are k inputs x 1 , x 2 , . . . x k such that the distribution g (x 1 ), g (x 2 ), . . . g (x k ) in not close enough to uniform.
That is, there exists a test T that distinguishes g (x 1 ), . . . g (x k ) from uniform.
On the other hand, by our assumption, g(x 1 ), . . . g (x k ) is close to uniform, therefore T also distinguishes g (x 1 ), . . . g (x k ) from g(x 1 ), . . . g (x k ).
This translates to a test that distinguishes the distribution of f 1 , f 2 , . . . , f t from uniform.
The key observation is that the distinguisher uses only space kn as a branching program (i.e., it is of width 2 kn ).
Therefore, if f 1 , f 2 , . . . , f t are selected by a generator that fools space-kn computations then no such distinguisher exists and g is k-wise almost independent, with a shorter description length than t · s.To complete this argument let us describe the small space distinguisher for the distribution f 1 , f 2 , . . . , f t .
Consider a protocol for t parties, where party i receives h i as input and altogether the parties want to distinguish the case that the h i 's are uniformly distributed from the case that they are distributed according to the distribution f 1 , f 2 , . . . , f t .
Party i will only be allowed to send nk bits to party i + 1.
Such communication network is equivalent to a branching program of space nk and the known pseudorandom generators for space bounded computations work against distinguishers in this model.
The distinguisher operates as follows.
The first party applies h 1 to x 1 , . . . x k and sends z 1 = (h 1 (x 1 ), . . . h 1 (x k )).
At its turn, party i > 1 implies h i to the sequence z i−1 received from party i − 1 to obtain z i that it sends to party i + 1.
At the end, party t evaluates z t and outputs T ( z t ).
We note the following facts: (1) Each z i is kn-bit long and thus this is indeed a space kn distinguisher.
(2) If the h i 's are uniformly distributed then z t is distributed according to g(x 1 ), . . . g(x k ).
Otherwise it is distributed according to g (x 1 ), . . . g (x k ).
As T behaves differently on these two distributions, we obtain the correctness of our small space distinguisher.Given an "ideal" generator the fools space bounded computations and has optimal parameters we could expect the method above to give k-wise almost independent permutations with description length O(nk + log( 1 δ ) + s + log t).
Based on previous constructions of k-wise almost independent permutations this implies description length O(nk + log( 1 δ )) as desired.
However, applying this derandomization method with currently known generators (which are not optimal) implies description length (nk + log( 1 δ )) times poly-logarithmic factors.
This leads us to our second idea: to obtain families with description length O(nk + log( 1 δ )) we revise the above method to use a more restricted derandomization tool: we use pseudorandom generators for walks on undirected labelled graphs.
That is walks which are indistinguishable from a random walk for any 'consistently labelled graph' and sufficient length.
Such generators with sufficiently good parameters are implied by the proof that undirected connectivity is in logspace of Reingold [35], and made explicit by Reingold, Trevisan and Vadhan [36].
Adaptive vs. Static Distinguishers: Consider a distinguisher, trying to guess whether the permutation it has is random or from the family G. Assume further, that the distinguisher is allowed to make k queries to the permutation.
A natural issue, is whether these queries are chosen ahead of time (statically) or adaptively, as a function of the responses the process receives.
When considering perfect k-wise independent permutation there is no difference between the two cases, but when considering almost k-wise independent permutations there could be a large difference † .
Nonetheless, here we shall consider the static case.
This is in general enough, for at least two reasons.
First, static indistinguishability up to distance δ2 −nk implies adaptive indistinguishability up to distance δ.
Second, a result of Maurer and Pietrzak [22] shows that composing two independently chosen k-wise almost independent permutations in the static case gives k-wise almost independent permutations with adaptive queries with similar parameters ‡ .
Related Work: There are several lines of constructions that are of particular relevance to our work.
We describe them in more detail in Section 4.
The information is summarized in Table 1.
Another notion which has been studied quite extensively in recent years is that of min-wise independence introduced by Broder et al. [7].
Informally, a permutation family is k-restricted min-wise independent (or simply min-wise independent, if k = n), if for every distinct k elements, each element is mapped to the minimum among the images of the elements, with equal probability.
The motivation for this notion stems from studying resemblance between documents on the Web † One of our favorite examples is involutions (permutations where the cycle length is at most 2).
A random involution is almost pairwise for the static case with ε = O(1/2 n ), but for the adaptive case ε = 1 − O(1/2 n ).
‡ Note that this is a case where k-wise independence is different from cryptographic pseudorandomness, as was demonstrated in recent papers by Myers and Pietrzak [23,32].
(Luby Rackoff) nk + O(n) k < 2 n 4 −O(1) , δ = k 2 2 n/2 O(nk · log δ δ 0 ) k < 2 n 4 −O(1) , any δ, δ 0 = k 2 2 n/2Simple 3-Bit Permutations [9,13,14] O(n 2 k(nk + lg( 1 δ )) lg(n)) k ≤ 2 n − 2 Thorp Shuffle [24, 26, 39] O(n 45 k log( 1 δ )) k ≤ 2 n Non-Explicit Constructions: Probabilistic (Thm.
3.4) O(nk + log( 1 δ )) k ≤ 2 n Sample space existence (Thm.
3.5) O(nk) k ≤ 2 n This Work (Theorem 5.9) O(nk + log( 1 δ )) k ≤ 2 n(see Broder et al. [8,7]).
This notion is weaker than k-wise independence.
Another definition, krankwise independence [16], demands that the k elements are mapped to any order with the same probability.
k-rankwise independence is stronger than k-restricted min-wise independence, but weaker than k-wise independence.
The best lower bound for k-restricted min-wise independence is from [17] and is roughly n k/2 .
For a more extensive treatment we refer the reader to [7,16,17].
In Section 2 we provide notation and some basic information regarding random walks and the spectral gap of graphs.
In Section 3 we define k-wise δ-dependent permutation, argue the (nonconstructive) existence of small families of such permutations and study the composition of such permutations.
In Section 4 we discuss some known families of permutations.
Section 5 describes our general construction of a permutation family, and proves our main result.
In Section 6 we describe possible extensions for future research.
• Let P n be the set of all permutations over {0, 1} n .
We will use N = 2 n .
• Let x and y be two bit strings of equal length, then x⊕y denotes their bit-by-bit exclusive-or.
• For any f, g ∈ P n denote by f • g their composition (i.e., f • g(x) = f (g(x))).
• For a set Ω, denote by U Ω the uniform distribution on the elements of Ω.
• Denote by [N k ] the set of all k-tuples of distinct n-bit strings.
§ The first row is based on 4 rounds with the first and last being pair-wise independent [26].
Analysis of related constructions [22,30,31] approaches k = 2 n/2 , but does not go beyond.
It is possible to obtain any δ ≤ δ by the composition of independent permutations (which adds a log δ δ multiplicative factor.)
A random walk on a graph starting at a vertex v is a sequence of vertices, u 0 , u 1 , . . . where u 0 = v and for i > 0 the vertex u i is obtained by selecting an edge (u i−1 , u i ), uniformly from the edges leaving u i−1 .
Undirected graphs that are connected, regular, and have self-loops in each vertex, have the property that a random walk on the graph (starting at an arbitrary vertex) converges to the uniform distribution on the vertices.
The rate of convergence is governed by the second largest (in absolute value) eigenvalue of the graph.
Below we formalize these notions.
M ∈ M n (R).
Denote by 1 = λ 1 ≥ λ 2 ≥ . . . ≥ λ n its eigenvalues.
We denote by λ(G) the second eigenvalue in absolute value.
Namely, λ(G) ˙ = max{|λ 2 |, |λ n |}.
The spectral gap of G, is defined by gap(G) ˙ =1 − λ(G).
Let G = (V, E) be a connected, regular, undirected graph with self-loops, on n vertices.
Let M ∈ M n (R) be the normalized adjacency matrix of G.
A random walk on this graph is an ergodic Markov chain, whose transition matrix is M .
Its stationary distribution π is the uniform distribution on the vertices.
For x ∈ V , define the mixing time of the walk starting from x, by τ x () = min{n||M n 1 x − π ≤ }, where 1 x is the distribution concentrated on x.
The mixing time of the walk is defined by τ () = max x∈V τ x ().
We have the following theorems, relating the mixing time of a walk with the spectral gap of the graph.
G = (V, E), M , π be as in Definition 2.2.
Let > 0.
Let λ be the second largest eigenvalue of G.
Then 1 2 λ 1 − λ ln( 1 2 ) ≤ τ () ≤ 1 1 − λ ln( |V | ).
Usually, such a claim is used to bound the mixing time.
However, we will be using constructions with a proven mixing time.
The construction itself may also provide a bound on the spectral gap.
In case it does not, we will be able to use Theorem 2.3 in order to bound the gap of the graph from below.
A simple calculation using Theorem 2.3 shows thatgap(G) = Ω( ln( 1 2 ) τ () ).
The following theorem will be useful for us.
It shows, that the distance of a distribution induced by a random walk, from its stationary distribution, is a sub-multiplicative function of the time.
We will use this result to obtain a composition theorem for families of permutations (Theorem 3.8).
Namely, if selecting one permutation from a family of permutations induces a distribution which is δ-close to uniform, then composing two such permutations yields a distribution which is O(δ 2 )-close to uniform.Theorem 2.4 ([2] Chapter 2, Lemma 20) Let G = (V, E), M , π be as in Definition 2.2.
Define d(t) = max x∈V M t 1 x − π.
Then for all s, t ≥ 0, d(s + t) ≤ 2d(s)d(t).
In this section we define k-wise δ-dependent permutations, discuss their existence, and show that the distance parameter δ is reduced by the composition of such permutations.
Most of this paper concentrates on permutations over bit strings and we consider more general domains in Section 6.2 The output of a k-wise almost independent permutation on any k inputs is δ-close to random, where "closeness" is measured by statistical variation distance between distributions.
D 1 , D 2 be distributions over a finite set Ω.
The variation distance between D 1 and D 2 is D 1 − D 2 = 1 2 ω∈Ω |D 1 (ω) − D 2 (ω)| .
We say that D 1 andD 2 are δ-close if D 1 − D 2 ≤ δ.Remark 3.2 Note that if two distributions are δ-close then there is no distinguisher (not even an inefficient one) that can distinguish the distributions with advantage better than δ.
- tions).
Let δ ≥ 0.
The family F is k-wise δ-dependent if for every k-tuple of distinct elements (x 1 , . . . , x k ) ∈ [N k ], the distribution (f (x 1 ), f (x 2 ), . . . , f (x k )), for f ∈ F chosen uniformly at random is δ-close to U [N k ] .
We refer to a k-wise 0-dependent family of permutations as k-wise independent.We are mostly interested in explicit families of permutations, meaning that both sampling uniformly at random from F and evaluating permutations from F can be done in polynomial time.
The parameters we will be interested in analyzing are the following:Description Length The description length of a family F is the number of random bits, used by the algorithm for sampling permutations uniformly at random from F. Alternatively, we may consider the size of F, which is the number of permutations in F, denoted |F|.
In all of our applications, the description length of a family F equals O(log(|F|)).
By allowing F to be a multi-set we can assume without loss of generality that the description length is exactly log(|F|).
The time complexity of a family F is the running time of the algorithm for evaluating permutations from F.Our main goal would be to reduce the description length of constructions of k-wise δ-dependent permutations.
Still, we would take care to keep the permutation efficient in terms of time complexity.
See additional discussion in Section 6.
We show the existence of non-explicit families of permutations that are k-wise almost independent.
Our goal in the other sections would be to obtain families of size which is as close as possible to that obtained by the non-explicit arguments below.
The first idea for showing the existence of families of k-wise δ-dependent is simply to consider a probabilistic construction, i.e. a random collection of permutations of a certain size.
The following theorem follows by the approximation method of Azar, Motwani and Naor [4].
They provide ([4] Theorem 3.1) a general way to approximate an arbitrary distribution over a finite set Γ.
Their point is that the weighted average of for different weights can be approximated to within simultaneously by a sample space of size O( log 2 ) and uniform distribution over the support.
Consider the sample space Γ consisting of all permutations and D is the uniform distribution.
To specify the requirements of k-wise δ-dependency we need for all (x 1 , . . . , x k ), (y 1 , . . . , y k ) ∈ [N k ] an approximation that should be within δ/|[N k ]|.
We get the following: Theorem 3.4 Let n ∈ N. For all 1 ≤ k ≤ 2 n and δ > 0 there exists a family of permutations F that is k-wise δ-dependent and is of size O( nk2 2nk δ 2 ).
The existence (even with a non-explicit construction) of exact k-wise family of permutations is unknown.
Nonetheless, we show that there exist a distribution on permutations, which is k-wise independent and has a small support.
The construction follows a result by Koller and Megiddo [19], which we briefly describe below.Their idea for constructing a small sample space for a given object was to consider the set of constraints it induces in terms of values of subsets.
Then argue that if a sample space satisfying these constraints exists, then there exists an assignment where the number of non-zero points is no larger than the number of constraints.In the case of k-wise independent permutations, we are defining a probability distribution over permutations π, i.e. for each permutation we want to assign a probability p π .
For every two k-tuples ¯ x = (x 1 , x 2 , . . . x k ) ∈ [N k ] and ¯ y = (y 1 , y 2 , . . . y k ) ∈ [N k ]we have the constraint that the probability that the chosen permutation π satisfiesy i = π(x i ) for 1 ≤ i ≤ k is exactly 1/ N k .
Let C ¯ x,¯ y = {π|y i = π(x i ) ∀1 ≤ i ≤ k}.
One can write for each ¯ x, ¯ y ∈ [N k ]this requirement as a linear constraint in the p π 's:π∈C¯ x,¯ y p π = 1 N k .
These N k 2 constraints plus the constraint π p π = 1 completely characterize k-wise independence.
We know that there is an assignment satisfying all these constraints: simply make all p π = 1/N !
.
As Koller and Megiddo [19] argue, this means that there is also a non-negative assignment, where the number of non-zero values is at most the number of constraints; since it is non-negative it defines a probability distribution.
Unfortunately, we do not know how to construct this distribution, or to sample from it in time polynomial in n and k. By the above discussion, we have the following: Theorem 3.5 (Existence of k-wise Independent Distribution) There exists a distribution on permutations which is k-wise independent (i.e. for any k points the value of the chosen permutation is uniform in [N k ]) and the size of the support of the distribution is at most 2 2nk .
Some of the permutations families we will inspect require several compositions to get a distribution close to uniform.
In fact, as we argue below, composing permutations is an effective method for reducing the distance parameter δ.
This motivates the following definition.
Definition 3.6 Let F ⊆ P n .
The t th power of F, denoted byF t ⊆ P n , is { f 1 • . . . • f t | f 1 , . . . , f t ∈ F }.
Remark 3.7 Let F ⊆ P n .
Observe that |F t | = |F| t and that the time complexity of F t is essentially t times the time complexity of F.As Theorem 3.6 will show, starting with a family F which is δ-dependent results in F t which is only (O(δ)) t -dependent.
Therefore, increasing the description length and time complexity linearly, pays off in an exponential decay of the error.
We now state our composition theorem.Theorem 3.8 Let F be a k-wise δ-dependent family.
Then, F 2 is a k-wise 2δ 2 -dependent family.
Furthermore, for every ∈ N, F is a k-wise ( 1 2 (2δ) )-dependent family.The proof of Theorem 3.8 uses a certain type of graph which is associated with a permutation family F.
The graph, which we call a companion graph, has a vertex for each k-tuple of[N k ].
For every two k-tuples ¯ x = (x 1 , x 2 , . . . x k ) ∈ [N k ] and ¯ y = (y 1 , y 2 , . . . y k ) ∈ [N k ]and every permutation σ ∈ F such that y i = σ(x i ) for 1 ≤ i ≤ k we have an edge in the companion graph between ¯ x and ¯ y.
This edge is labelled by σ.
More formally: Definition 3.9 (Companion Graph) Let F ⊆ P n be a family of permutations.
For k ∈ N, define the companion (multi-)graph of F, G F ,k = (V, E) by:• V = [N k ].
• E = { (i, σ(i)) | i ∈ [N k ], σ ∈ F }.
• Each edge (i, σ(i)) ∈ E is labelled by σ.
¯ x = (x 1 , . . . , x k ) ∈ [N k ], and a permutation σ ∈ F, we abbreviate σ(¯ x) for (σ(x 1 ), . . . , σ(x k )).
Observe, that a step on the companion graph is equivalent to evaluating a permutation from F on the elements of the k-tuple.
Proof: (of Theorem 3.6) Let F be a k-wise δ-dependent family.
This means, that after taking one random step on its companion graph, the distance from a uniform distribution is δ.
Let d(t) be as in Theorem 2.4.
Then d(1) = δ, and since by Theorem 2.4, d(2) ≤ 2d(1) 2 = 2δ 2 , we conclude that F 2 is a k-wise 2δ 2 -dependent family.
Applying Theorem 2.4 inductively we havethat d(t) ≤ ( 1 2 (2δ) ).
Therefore, F is a k-wise ( 1 2 (2δ) )-dependent family.
2 As mentioned in the Introduction, for k = 2 the set of linear permutations is a good construction (see also [26]), and for k = 3 using sharply 3-transitive permutation groups * (as suggested by Leonard Schulman (private communication)) is a good construction.
Unfortunately, from the classification of finite simple groups it follows that for k ≥ 6 there are no k-transitive groups over [n] other than the symmetric group S n and the alternating group A n and there are only few such groups for k = 4 and k = 5 (see [10,37]).
To conclude, for k ≥ 4 any small family of k-wise independent permutations is not a permutation group (i.e. is not closed under composition and inverse).
This is a major hurdle in providing efficient algebraic constructions of k-wise independent permutations, for k ≥ 4.
Note also that from Theorem 3.8 (Composition Theorem) we can also conclude that a (non-trivial) permutation group cannot even be k-wise δ-dependent for any δ < 1/2: since the error can be reduced sufficiently to imply k-transitivity and if the set of permutations is a group, then it is preserved under composition.There are no known k-wise exactly independent permutations, whether algebraic or not.
The rest of our discussion will therefore focus on k-wise almost independent permutations.
We now survey some known constructions yielding k-wise almost independent permutations with reasonable parameters.
In their famed work, Luby and Rackoff [20] showed how to construct pseudorandom permutations from pseudorandom functions.
The construction is based on the Feistel Permutation: For any function f ∈ {0, 1} n/2 → {0, 1} n/2 the Feistel Permutation is defined by (L, R) → (R, L ⊕f (R)), where |L| = |R| = n/2.
The construction uses a composition of several such permutations.Naor and Reingold [26] construct a family of k-wise δ-dependent permutations, where the description of each permutation is kn + O(n) bits with δ = k 2 /2 n/2 (note that the size is optimal up to the additive O(n) term).
The analysis is useless when k is larger than 2 n/4 .
There are Feistel constructions of k-wise δ-dependent permutations, for k up to 2 n/2 (see Naor and Reingold [26], Patarin [29,30,31], and Maurer and Pietrzak [21]).
The Feistel permutations approach yields succinct k-wise δ-dependent permutation as long as k is not too large and δ is not too small, and is probably the method of choice for this range.
To reduce the parameter δ one can use Theorem 3.8 and obtain a permutation with description length O(kn log(1/δ) (or even O(k log(1/δ)) for certain ranges of k and δ).
The Feistel method is not known to be useful for k larger than 2 n/2 .
* A permutation group over the set [N ] = {1, 2, . . . , N } is a subgroup of the symmetric group S n .
A permutation group G over [n] is k-transitive if for every two k-tuples {x 1 , . . . , x k } and {y 1 , . . . , y k } of distinct elements of [n] there exist a permutation π ∈ G such that ∀1 ≤ i ≤ k, π(x i ) = y i .
A permutation group G over [n] is sharply k-transitive if for every two such tuples there exists exactly one permutation π ∈ G such that ∀1 ≤ i ≤ k, π(x i ) = y i .
A sharply k-transitive permutation group is in particular k-wise independent.
Indeed for k = 2, the linear permutations form a sharply 2-transitive permutation group.
For k = 3, there are known constructions of sharply 3-transitive permutation groups.
Consider a process for shuffling cards.
Each round (shuffle) in such a procedure selects a permutation on the locations of the N cards of a deck (selected from some collection of basic permutations).
Starting at an arbitrary ordering of the cards, we are interested at the number of rounds it takes to get the deck into a (close to) random ordering.
In other words, a card shuffling defines a Markov chain on the state of the deck, and the goal is to bound its mixing time.The riffle shuffle models one of the most common "real life" shuffling techniques.
Loosely, in each shuffle, the deck is split roughly in the middle, into two sides.
Then, cards are dropped sequentially, from both sides, and form a new deck.
(The mathematical model for this shuffle is due to Gilbert, Shannon and Reeds.)
Aldous and Diaconis [1] provide a convenient implementation which we shall now describe.
Let us view the deck of cards as the set of n-bit strings, where each card is a string in {0, 1} n .
One round of the shuffle consists of two stages: assign and reorder.
In the assign stage, each of the N = 2 n cards is assigned a random bit 0 or 1.
In the reorder stage, the cards assigned with 0 are placed at the top, while preserving their internal order.
After O(log N ) = O(n) such rounds, the deck is close to uniform, see [1].
The random bits cost of this procedure is quite high.
We would need 2 n bits per round, total of O(n2 n ) bits.
Observe, that this is of the order of the number of bits needed to select a permutation, uniformly at random (and certainly much more than desired for k-wise independent permutations).
An even more troubling difficulty with using this shuffle, is that it is not "oblivious" in the sense that the location of each card is determined by looking at many random bits.
For instance, if the ith card is assigned a value of 0, it can still be in any of the first i position after the reorder stage, depending on how many of the first i − 1 cards are also assigned a 0.
As we shall see below, this does not completely preclude the applicability of such a process for generating k-wise independent permutations, but a more straightforward idea is to use an oblivious shuffle.Oblivious Card Shuffling: Call a shuffle oblivious if the location of a card, after each round, is easy to trace and is determined by only a few random bits, say O(1).
An excellent example is the Thorp Shuffle [45].
Here the deck is divided into two halves, and these two halves are interleaved in a more local manner than in the riffle shuffle.
In the Thorp shuffle, each time we pick one card from each half.
With equal probability, the card from the first half is dropped first, and otherwise the card from the second half is dropped first.
This means, that the location of a card, after one round, depends on a single bit.
It is therefore oblivious, in the sense described above.
It was conjectured in [1] that the mixing time of the Thorp Shuffle is O(n 2 ), but the problem remained open for many years.
Recently Morris [24] provided the first poly(n) bound on its mixing time.
More formally Definition 4.1 (Thorp Shuffle) Let n ∈ N. Given a deck of 2 n cards, one stage of the shuffle is determined by 2 n−1 bits that we will view as a random function g : {0, 1} n−1 → {0, 1}.
View the location of each card as an n-bit string according to the lexical order.
Card at location (σ, x) where σ ∈ {0, 1} and x ∈ {0, 1} n−1 moves to location (x, σ ⊕ g(x)).
An "old" proposal by the second author [39, page 17], [26] for the construction of k-wise almost independent permutations was to utilize oblivious card shuffling procedure.
The idea is the following: when using such a card shuffle to construct a k-wise almost independent permutation, all we care for is the final locations of k cards.
If we replace the random function g by a k-wise independent function, then this will not change the distribution on the k final locations.
Therefore, the obliviousness of card shuffles is useful when constructing k-wise almost independent permutation, in terms of both the description length and time complexity.Implementing permutations via the riffle shuffle: Even though the riffle shuffle is not oblivious there is a way of using it to construct k-wise almost independent permutations.
The idea is to generate the choices for each position in a range-summable manner: there should be an efficient way to determine the number of '1's in a given range (for a given 1 ≤ x ≤ N how many '1' where chosen for the cards in [1 . . . x]).
We need the choices and random variables of the range-sum to be k-wise independent.
Once this property exists, then the result is indistinguishable from a random riffle for any process that examines the location of at most k cards.There is a construction satisfying these properties based on a 'divide-and-conquer' tree.
This is described in [11] (due to Naor and Reingold) and [12].
The advantage of this construction over the Thorp shuffle is the lower round complexity, O(n 2 ) vs. O(n 44 ).
Both are amenable to the random walk derandomization.
A very intriguing method for generating k-wise δ-dependent permutation was explored first by Gowers [13] and then (with some variation) by Hoory et al. [14] and Brodsky and Hoory [9].
The idea is to pick a few bit positions, three to be concrete, which are the only bits the permutation is going to change.
The three bits that are changed define a small sub-cube (with eight elements).
To completely define the permutation, select a random permutation on this small sub-cube.
† This is reminiscent of a shuffle, but here we invest only a few bits in each round.
Therefore, the shuffle cannot converge quickly to a random permutation.
What this line of research shows is that a composition of not too many simple permutations still yields a k-wise almost independent permutation.
This approach is treated more formally in the Section 5.4 and it works very well with the derandomized walk approach, since the underlying set of permutations considered is the simplest and hence the description length of simple permutations is quite short.
In this section we give a method for reducing the description length of previous constructions of k-wise δ-dependent permutations.
As discussed in the introduction, this method is particularly suited to constructions based on composition of permutations.
We apply this method to the simple 3-bit permutations of [9,13,14] to obtain k-wise δ-dependent permutations with description length O(nk + log( 1 δ )).
† In the Hoory et al. variation the permutation is selected in a more restricted manner: Only a single bit is changed as a random function of the other bits.
Recall from Section 3.3 that we associate with a family F of permutations a companion graph (Def.
3.9) by connecting a k-tuples to ¯ x to σ(¯ x) for σ ∈ F. All of the families of permutations of Section 4 are closed under taking an inverse of a permutation and always include the identity permutation.
We summarize the properties of the companion graph that we need in the following proposition:Proposition 5.1 Let F ⊆ P n be a family of permutations, which is closed under taking an inverse and contains the identity permutation.
Let k ∈ N. Then, the companion graph G F ,k , is an undirected, |F|-regular, with self-loops.
Furthermore, the companion graph is consistently labelled graph, in the sense that for every vertex v, every two incoming edges into w have distinct labels.Assume that F is such that F t is a family of k-wise δ-dependent permutations.
We claim that the distribution over the vertices we reach by taking a walk of length t, starting at any vertex of G F ,k , is δ-close to uniform.
Simply, traversing an edge labelled π from the vertex ¯ x is the same as applying the permutation π on ¯ x (i.e., it reaches vertex π(¯ x)).
Taking t random edges is the same as applying the composition of t randomly chosen permutations.
If there is any starting point ¯ x that does not yield an end-point that is δ-close to uniform, then this ¯ x is a witness to the non k-wise δ-dependency of F t .
Derandomizing the family F t will mean that instead of composing independently chosen permutations from F, we will select the permutations with some dependencies.
Equivalently, we will take a pseudorandom walk instead of a random one.
The seed of the pseudorandom generator will be required to be sufficiently small and the number of labels the generator outputs will not be too large.
Such a generator was given by Reingold, Trevisan and Vadhan [35,36].
We now discuss generators for pseudorandom walks on graphs.
We will refer to graphs with the following parameters: G = (V, E) be a connected, undirected d-regular graph, on m vertices.
Then G is an (m, d, λ)-graph if λ ≤ λ(G).
Let G = (V, E) be a d-regular graph where for each node its d outgoing edges take distinct labels in [d].
Let A be a distribution overa = a 1 , a 2 , . . . a ∈ [d] .
We say that A is δ-pseudorandom for G, if for every u ∈ V , the distribution on the possible end vertices of a walk in G, which starts from u, and follows the edge labels in a is δ-close to uniform when a is distributed according to A.Note that if G is an (m, d, λ) graph, λ is sufficiently smaller than 1 and the walk is sufficiently long, then we expect a (truly) random walk to end in vertex that is close to being uniformly distributed no matter where the walk started.
We are now ready to state the parameters of a previously known construction of pseudorandom walk generators.Theorem 5.4 [35,36][Pseudorandom Walk Generator] For every m, d ∈ N, δ, > 0, there is a pseudorandom walk generator P RG = P RG m,d,δ, : {0, 1} r → [d] , with the following parameters:• Seed length r = O(log(md//δ)).
• Walk length = poly(1//) · log(md/δ).
• Computable in space O(log(md//δ)) and time poly(1//, log(md/δ)).
such that for every consistently labelled (m, d, 1 − )-graph G, the output of P RG(U r ) is δ-pseudorandom for G, where U r is the uniform distribution on {0, 1} r .
Remark 5.5 The generator of Reingold, Trevisan and Vadhan [36] is more general as it also applies to regular directed graphs (where the in-degree and out-degree of each vertex equals some fixed d).
Here, only undirected regular graphs are relevant.
Furthermore, the time-complexity of the generator is only implicit in [36].
We now describe our main construction which consists of applying the pseudorandom walk generators for the companion graph of a family of permutations F.
Our starting point is any family of permutations F where F t (for t not too large) is k-wise almost independent.
By Proposition 5.1, the companion graph G F ,k , is regular and consistently labelled.
As argued following Proposition 5.1, if F t is k-wise almost independent then the random walk on G F ,k has small mixing time.
By Theorem 2.3, this implies a bound on the eigenvalue gap ε of G F ,k .
Therefore, Theorem 5.4 gives us a pseudorandom walk generator for G F ,k (P RG = P RG m,d,δ,, with m = |[N ] k |, d = |F|, ε comes from the analysis of F and δ from how close to uniform we want the result to be).
We now use each seed s ∈ {0, 1} r of the pseudorandom generator P RG to define a new permutation σ s , which is the composition of the permutations from F that P RG(s) generates.
The set of all possible seeds defines our new family F .
Theorem 5.6 formalizes this approach:An advantage we have, which affects the parameters of our results (especially the description length), is that the efficiency of the generator of [36] depends on the spectral gap of the initial graph.
Since we are using families of permutations for which the companion graph is known to be of good expansion, we manage to achieve non-trivial parameters in the families we construct.The following theorem describes the family of permutations we achieve.Theorem 5.6 Let F ⊆ P n be a family of size d = |F|, and G F ,k be its companion graph.
Suppose that gap(G F ,k ) = , where may be a function of n and k. Then, there exists F ⊆ P n , such that F is a k-wise δ-dependent family, with the following properties.
• The description length of F is O(nk + log( d δ )).
• If the time complexity of any permutation in F is bounded by ξ(n, k), then the time complexity of F is poly(1//, n, k, log( d δ )) · ξ(n, k).
Proof: We apply Theorem 5.4 on the companion graph of F. Following Proposition 5.1 we know that G F ,k fits the requirements of Theorem 5.4.
Let r = O(log( 2 nk ·d δ )) and = poly(1//) · log( 2 nk ·d δ ) be as in Theorem 5.4.
For a string s ∈ {0, 1} r , we define σ s ∈ P n as follows.
Letw = P RG 2 nk ,d,δ,, (s) ∈ [d] .
Then w = τ 1 , τ 2 , . . . , τ , where for all 1 ≤ i ≤ , τ i ∈ F.
We let σ s = τ • . . . • τ 1 .
Next define a permutation family F ⊆ P n byF = { σ s | s ∈ {0, 1} r }.
We now show that F is a k-wise δ-dependent family.
By Theorem 5.4, for any starting vertex u ∈ V (G F ,k ), the pseudorandom walk starting at u and following the labels of P RG 2 nk ,d,δ,, (U r ) reaches a vertex that is δ-close to uniform.
Observe that picking a random σ s ∈ F and applying it to any value A ∈ V (G F ,k ) = [N k ] is exactly as taking a random walk on G F ,k according to the output of P RG 2 nk ,d,δ,, with a random seed s. Therefore, the output of a uniform σ s on any such A ∈ [N k ], is δ-close to uniform.
We can conclude that F is k-wise δ-dependent.
The description length of F is |r| = O(log(2 nk d δ )) = O(nk + log( d δ )).
The time complexity of F depends on the time complexity of running the generator, and of running permutations from F.
This can be bounded by poly(1//, n, k,log( d δ )) · ξ(n, k).
2For simplicity, we assumed in the above theorem that the bound ε on the eigenvalue gap is given, rather than deducing it by Theorem 2.3 (as in the discussion before the theorem).
But in principal what this theorem tells us is that instead of taking truly independent choices in F t it always makes sense (from description length point of view) to use P RG to define the permutations that are composed.
We now provide a formal definition and analysis of simple 3-bit permutations, mentioned in Section 4.3.
w ≤ n. For i ∈ [n], J = {j 1 , . . . , j w } ⊆ [n]{i}, and a function f ∈ {0, 1} w → {0, 1}, denote by σ i,J,f the permutationσ i,J,f (x 1 , . . . , x n ) ˙ =(x 1 , . . . , x i−1 , x i ⊕ f (x j 1 , . . . , x jw ), x i+1 . . . , x n )The following simple permutation family F w is defined byF w = {σ i,J,f |i ∈ [n], J ⊆ [n] {i}, |J| = w, f ∈ {0, 1} w → {0, 1}}.
We denote by F 2 the simple permutations family F w for w = 2.
Theorem 5.8 [9] For all 2 ≤ k ≤ 2 n −2, F 2 t is k-wise δ-dependent , for t = O(n 2 k(nk+log( 1 δ ))).
Furthermore, gap(G F ,k ) = Ω( 1 n 2 k ).
Evaluating σ i,J,f ∈ F 2 takes O(n) time.
The size of F 2 is O(n 3 ), and the size of F 2 t isO(n 3 ) t = n O(n 2 k(nk+log( 1 δ ))).
It follows that F 2 t has description length O(n 2 k(nk+log( 1 δ )) log(n)), and time complexity O(n 3 k(nk + log( 1 δ ))).
Combining Theorems 5.8 and 5.6 we obtain the main result of this paper: Theorem 5.9 There exists F ⊆ P n , such that F is k-wise δ-dependent.
F has description length O(nk + log( 1 δ )), and time complexity poly(n, k, log( 1 δ )).
Proof: Consider the permutations family F 2 .
The size of F 2 is d = O(n 3 ), and the spectral gap of its companion graph is = Ω( 1 n 2 k ).
Applying Theorem 5.6 on F 2 , we get a permutations family F , whose description length is O(nk+ log( d δ )) = O(nk + log( 1 δ )).
Since the time complexity of any permutation in F 2 is O(n), it follows that the time complexity of F is poly(n, k, log( 1 δ )).
2 The focus of this paper is the description length of k-wise almost independent permutations.
Still our derandomization preserves the time-complexity of the permutations up to factors that are polynomial in the original time complexity and in the description length (nk + log( 1 δ )).
One disadvantage of the approach of using a pseudorandom walk generator for derandomization is that we replace a permutation composed of simple permutations with another permutation composed of simple permutations (this disadvantage is somewhat less extreme when using the more efficient pseudorandom walk generator recently given in [38]).
In this respect it is better to derandomize using generators against general space-bounded computations (such as the Nisan generator [27]) as explained in the introduction.
While this approach is slightly sub optimal in terms of description length (using currently known generators) it is quite efficient in terms of time complexity.A more subtle concern in terms of time complexity is the following: Can we have k-wise almost independent permutations where the time complexity is independent of k (as the description length is larger than nk this only makes sense if we allow direct access to this description).
Note that even for k-wise independent functions this issue is not completely resolved; the basic construction based on polynomials is expensive and more efficient constructions have longer descriptions (some lower and upper bounds are given by Siegel [42]).
Assume now that we are starting with a construction of k-wise almost independent permutations that has this strong efficiency requirement.
When derandomizing with a generator against space bounded computations, the only additional cost is the evaluation of the generator.
In order for our derandomization to preserve such strong efficiency we need a pseudorandom generator with 'random access' properties.
In such a generator, evaluating the ith bit of its output, does not entail computing all bits up to i.
More specifically, it should be possible to compute each bit in time that is independent of k and only depends on n. Also note that since the only additional costs are in the evaluation of the pseudorandom generator, one can first "decompress" the succinct description of the derandomized permutations in order to speed up future computations (this may be useful in case storage is not expensive but randomness and communication are).
An issue that we did not explore so far, is constructing k-wise independent permutations over domains that are not powers of 2.
This problem was raised by Bar-Noy and S. Naor inspired by the needs of [5].
As was pointed out by Black and Rogaway [6], the credit card problem described in the introduction is in fact one on a domain size that is not a power of 2.
Black and Rogaway [6] suggested several methods, for obtaining a pseudo-random permutation on domain size M , that is not a power of 2, from a pseudo-random permutation on domain size N , that is a power of 2 (say N = 2 logM ).
The most relevant method for our purposes is the 'cycle walking' one, where the idea is to construct a permutation on [M ] When one translates this construction to k-wise almost independent permutations, then the requirement on the underlying permutation π is, that it should be k -wise δ -dependent for some k ≥ k (we will see the requirement on δ momentarily), since some of the evaluations of π require more than a single call to π .
Note also that this mapping requires that π be immune to adaptive attacks.
In general, consider the 'bad' case for a k tuple x 1 , x 2 , . . . x k in [M ]: the evaluation of π on x 1 , x 2 , . . . x k requires more than k calls to π .
If M/N ≥ 1/2, then the probability that this bad case happens, is proportional to an exponential in k − 2k, by a Chernoff bound.
Conditioned on the event that the bad case did not happen, then the distribution of π on x 1 , x 2 , . . . x k is δ -far from uniform on [M k ].
Hence, the resulting set of permutations is k-wise δ-dependent for δ that is larger than δ by an additive factor, which is exponential is k − 2k.
This analysis means, that for large k it is relatively easy to get a small error, by taking k to be, say, 2k, without significantly increasing the family size.
However, when k is small, the resulting error is too large.
In this case, as before, the derandomized walk method is applicable for reducing the error, since Theorem 5.6 does not require the domain size to be a power of 2.
One interesting question is whether it is possible to 'scale down' a construction for k-wise independent permutations on n bits to one on n ≤ n bits.
When n is very close to n then some of the techniques described in the previous section (such as cycle walking) are relevant, but they become inefficient when n − n is larger than logarithmic.
This is most relevant in the computational pseudorandomness setting: is it possible to obtain from a block-cipher on large blocks (e.g. 128 bits) a block-cipher on small blocks (e.g. 40 bits), while maintaining the security of the former.Finally, there is no strong reason to suppose that explicit small families (or distributions) of exact k-wise independent permutation do not exist and Theorem 3.5 hints to their existence.
So how about finding them?
The authors are grateful to Ronen Shaltiel for his invaluable collaboration during the early stages of this work, and thank Danny Harnik, Asaf Nussboim and Adam Smith for useful comments.
