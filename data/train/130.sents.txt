This paper explores the relation between the struc-tured parallelism exposed by the Decomposable BSP (D-BSP) model through submachine locality and locality of reference in multi-level cache hierarchies.
Specifically, an efficient cache-oblivious algorithm is developed to simulate D-BSP programs on the Ideal Cache Model (ICM).
The effectiveness of the simulation is proved by showing that optimal cache-oblivious algorithms for prominent problems can be obtained from D-BSP algorithms.
Finally, a tight relation between optimality in the D-BSP and ICM models is established.
The memory system of current microprocessors includes a hierarchical cascade of caches whose capacities and access times increase as they grow farther from the CPU and closer to main memory.
In order to amortize the larger cost incurred when referencing data in distant levels of the hierarchy, the data is automatically replicated across the faster levels and transferred in blocks of contiguous locations.
The rationale behind such a hierarchical organization is that the memory access costs of a computation can be reduced when the same data are frequently reused within a short time interval, and data stored at consecutive addresses are involved in consecutive operations, two properties known as temporal and spatial locality of reference, respectively.In the last decade a number of computational models have been proposed to explicitly account for such a hierarchical nature of the memory system.
The first This work was supported in part by the University of Padova under Grant CPDA033838, by MIUR of Italy under project "AL-GONEXT", and by the EU/IST Project "AEOLUS".
attempts in this direction were the Hierarchical Memory Model (HMM) defined in [1], a random access machine where access to memory location x requires time f (x), for a given nondecreasing function f (x), and the HMM with Block Transfer model (BT) [2] which augments the HMM with the capability of moving memory blocks of arbitrary size at a reduced cost.
Observe that both models reward temporal locality, while only BT rewards spatial locality.
However, the HMM/BT algorithm designer is in complete charge of orchestrating data layout, which makes the models unsuitable to describe current caches, where data are automatically moved and replicated across the hierarchy.A two-level memory organization is featured by the External Memory (EM) model [3,18], which has been extensively used in the literature to develop I/Oefficient algorithms.
This model is closer to actual caches, since it only features a fixed-size block transfer, however the programmer is still in charge of managing data placement and eviction in the fast memory level.
Borrowing ideas from the EM model, only recently a faithful model of a cache-main memory system, the Ideal Cache Model (ICM), has been defined in [13,14].
The ICM features automatic block transfer and eviction, and has been at the base of the vast literature on cache-oblivious algorithms, i.e., algorithms which run efficiently independently of the cache parameters (i.e., cache size and cache line size).
Most importantly, cache-oblivious algorithms attaining minimal miss rate on the ICM can be shown to attain minimal miss rates at all levels of any multi-level cache hierarchy [13].
A number of works in the literature have explored the relation between (structured) parallelism and locality of reference.
Earlier results [8,10,15] provided evidence that efficient EM algorithms for two-level hierarchies can be obtained by simulating parallel ones written for coarse-grained parallel models, such as BSP [17] or CGM [9], on the EM model.
The main intuition behind these works is that the interleaving between large local computation and bulk communication phases, which characterizes coarse-grained parallel algorithms, maps nicely on the two-level structure of the EM model.
However, the flat parallelism offered by the above coarse-grained models seems unable to afford the finer exploitation of locality needed to achieve cache obliviousness.A more general study on the relation between parallelism and locality of reference can be found in [12], where it is shown how a more structured form of parallelism, such as the one exhibited by the Decomposable BSP (D-BSP) (a clustered variant of BSP defined in [7]) can be simulated to yield efficient sequential algorithms on the HMM and BT models.
The simulation strategy crucially relies on a nontrivial exploitation of the submachine locality exposed in D-BSP to guarantee that the resulting sequential computation exhibit a high degree of temporal and spatial locality.The objective of this paper is to extend the above investigation by exploring the relation between structured parallelism and locality of reference in multi-level cache hierarchies, where the movement of data across the levels is outside the programmer's explicit control.
The core technical result of the paper is an efficient algorithm that simulates any D-BSP program on the ICM model.
The ICM simulation strategy makes sure that memory references trigger automatic data movements between cache and main memory analogous to those explicitly prescribed by the simulation algorithm developed in [12] for the HMM/BT models.
The most important feature of the simulation is that the several degrees of submachine locality exposed by D-BSP algorithms are exploited to ensure that the resulting ICM computations adapt to the cache parameters without explicitly knowing them.
Thus the simulation algorithm is cache oblivious, hence it can be efficiently ported onto any (multi-level) cache hierarchy.We provide evidence that our approach is successful by showing that optimal cache-oblivious algorithms for prominent problems can be obtained by simulating D-BSP ones.
Furthermore, we also exhibit a tighter relation between the D-BSP and ICM models by arguing that achieving an optimal ICM algorithm by simulating a D-BSP algorithm implies, under certain reasonable conditions, the optimality of the latter.The rest of the paper is organized as follows.
Section 2 defines our reference models.
The simulation algorithm is described and analyzed in Section 3.
In Section 4 we apply the simulation to two relevant case studies, namely matrix multiplication and DFT.
Finally, Section 5 discusses the relation between optimality in the D-BSP and ICM models.
D-BSP.
The Decomposable Bulk Synchronous Parallel (D-BSP) model was introduced in [6] to capture submachine locality in a structured way through a hierarchical decomposition, and was further investigated in [4,5,11].
Let N be a power of two.
A D-BSP(N, g) is a collection of N RAM processors {P j : 0 ≤ j < N } communicating through a router whose bandwidth characteristics are captured by vector g = {g 0 , . . . , g log N −1 }.
(Throughout the paper all logarithms are taken to the base 2.)
Specifically, for 0 ≤ i ≤ log N , the N processors are partitioned into 2 i fixed, disjoint i-clustersC i 0 , C i 1 . . . C i 2 i −1 of N/2 i processors each,where the processors of a cluster are capable of communicating among themselves independently of the other clusters.
The clusters form a hierarchical, binary decomposition tree of the D-BSP machine, in the sense that C log N j = {P j }, for 0 ≤ j < N , andC i j = C i+1 2j ∪ C i+1 2j+1 , for 0 ≤ i < log N and 0 ≤ j < 2 i .
A D-BSP program consists of a sequence of labeled supersteps.
In an i-superstep, 0 ≤ i < log N , each processor executes internal computation on locally held data and sends messages exclusively to processors within its i-cluster (an output and an input queue for message exchange are part of each processor's local memory).
The superstep ends with a barrier, which synchronizes processors independently within each icluster.
Messages are of constant size and messages sent in one superstep are available at the destinations only at the beginning of the following superstep.
It is also reasonable to assume that any D-BSP program ends with a global synchronization, that is, a 0-superstep.
In an i-superstep, if each processor spends at most w units of time performing local computation during one superstep, and sends/receives at most h messages (i.e., the communication pattern is an hrelation), then the cost of the i-superstep is given by w + hg i .
The running time of a D-BSP program is obtained as the sum of the running times of its constituent supersteps.
Observe that g i is an inverse measure of an i-cluster's per-processor bandwidth, hence we can safely assume that g i ≥ g j for 0 ≤ i < j < log N .
ICM.
The Ideal Cache Model (ICM(Z, L)) was introduced in [13] and consists of a sequential processor equipped with a (data) cache and a main memory of arbitrary size.
The cache contains Z words organized into lines of L words each, and it is ideal in the sense that it is fully associative and uses the optimal offline strategy for cache-line replacement.
The model rewards both spatial and temporal locality of reference.
As in [13], when analyzing ICM(Z, L) algorithms, we will make the tall cache hypothesis Z = Ω(L 2 ).
A miss is said to be a cold miss, if it is caused by a reference to a previously unreferenced memory block, or a capacity miss if the referenced memory block was previously evicted from cache.An ICM(Z, L) algorithm is characterized by its work complexity (number of operations) W (N, Z, L) and cache complexity (number of misses) Q(N, Z, L), where N denotes the input size.
An algorithm is called cache oblivious if its specification is independent of the two parameters Z and L, and cache aware otherwise.
Cache-oblivious algorithms for matrix multiplication, discrete Fourier Transform and sorting are presented in [13].
In this section we describe the algorithm to simulate a D-BSP(N, g) program P on an ICM(Z, L).
The algorithm is similar to the one developed in [12] for the simulation of D-BSP on the BT model, with a number of nontrivial modifications due to the fact that, unlike the BT model, memory access costs on the ICM do not depend on the absolute addresses being referenced but, rather, on the temporal sequence of references.
For the sake of completeness, we describe the entire algorithm rather than highlighting the differences with the algorithm in [12].
Given a D-BSP program P, we refer to the local memory used by a processor during the execution of P as the processor's context.
Let µ be an upper bound to the size of any context.
The ICM main memory is divided into N blocks, each of size Θ(µ), where the i-th block stores the context of processor P i , followed by an auxiliary free space of size cµ, for a suitable constant c > 1, which is used for bookkeeping purposes.
The simulation is divided into rounds, where a round simulates an i-superstep for a certain i-cluster and identifies the cluster involved in the following round.
Let the supersteps of P be numbered consecutively and let i s denote the label of the s-th superstep, for s ≥ 0.
Consider a generic round that simulates the s-th superstep of P for an i s -cluster C.
The simulation is divided into two parts: the execution of local computations for each processor of C, and the data movements corresponding to the message distribution.
The simulation of local computations is done recursively in the two (i s + 1)-clusters contained in C, until log Nclusters are reached.
As in [12], message distribution is simulated through sorting as follows.
The blocks containing the contexts of the processors in C, which are consecutive in main memory, are rearranged so to pack the actual contexts in the first µN/2 is words, followed by the cµN/2 is words of free space.
Then, the contexts are partitioned into Θ(µN/2 is ) constant-sized elements which are tagged with keys in such a way that, after sorting, contexts are still ordered by processor number and all messages are brought to the end of the respective destination processors' contexts.
Both tagging and sorting need auxiliary space that is extracted from the segment of free space created via packing.
After sorting, the keys are removed and the initial layout, with each context followed by free space, is restored.Finally, the cluster that will be simulated in the next round is identified by determining its first processor P .
Specifically, if i s+1 ≥ i s then P remains the first processor of C, and the next round will simulate the (s + 1)-st superstep for the first i s+1 -cluster contained in C.
If instead i s+1 < i s we have two cases.
LetˆCLetˆ LetˆC be the i s+1 -cluster containing C.
If the s-th superstep has been simulated for all i s -clusters contained inˆCinˆ inˆC, then P will be the first processor ofˆCofˆ ofˆC, otherwise P will be the first processor of the next i s -cluster contained inˆCinˆ inˆC (hence sibling of C) for which the s-th superstep has not been simulated yet.The pseudocode of the simulation algorithm is provided in the appendix at the end of the paper.
We have:Theorem 1.
The simulation algorithm is correct.Proof (sketch).
The correctness of the algorithm can be proved by modifying the argument presented in [12], taking into account that no explicit context movements are now specified in the algorithm but are automatically induced by the caching mechanism.
Full details are found in [16] and will be provided in the full version of this extended abstract.The simulation strategy outlined above exploits locality of reference by proceeding unevenly on the different D-BSP clusters.
In particular, the same cluster could be simulated for several consecutive supersteps so to avoid repeated, expensive reloads of its processors' contexts in cache.
We remark that by using a cacheoblivious sorting algorithm for implementing Line 5 of Communicate(C) (e.g., the algorithm by [13]), the simulation algorithm becomes cache-oblivious since it makes no use of parameters Z and L of the ICM model.
We analyze the work and cache complexities of the simulation algorithm described in the previous section.
In the analysis, we assume that Z = Ω(µ) so that, for every superstep, the simulation of the local computations of the D-BSP processors never incurs capacity misses.
In this way we are able to directly relate the cache complexity of the ICM simulation to the context switching overhead induced by the parallelism of the D-BSP program.
In fact, this assumption on Z is often satisfied by fine-grained D-BSP algorithms exploiting maximum parallelism with respect to the input size.Theorem 2.
Consider a D-BSP(N, g) program P using contexts of size µ, and let τ be the aggregate time for local computations, summed over all processors and all supersteps.
Let k i be the number of i-supersteps in P, 0 ≤ i < log N .
When Z = Ω(µ), P can be simulated on an ICM(Z, L) with work and cache complexities:W (N, Z, L) = Θ τ + µN log N −1 i=0 k i log µN 2 i (1) Q(N, Z, L) = Θ 1 + µN L 1 + λ−1 i=0 k i log µN 2 i log Z ,(2)where λ = max 0, log˜µNlog˜ log˜µN Z , with˜µwith˜ with˜µ = (c + 1)µ for a suitable constant c ≥ 1.
Proof.
Consider a round simulating the s-th superstep for an i s -cluster C, and let B C denote the segment of N/2 is contiguous memory blocks associated with the processors of C.
The work complexity of the round is obtained by adding the contributions of the call to Compute(C) and the call to Communicate(C), since the other operations account only for O(1) work.
It is easy to see that the work complexity of Compute(C) is proportional to the sum of the local computations of all processors in C in the superstep being simulated.
As for Communicate(C), the required packing and tagging operations and the respective unpacking and key deletion can be easily performed in O µN/2 is work, through a constant number of scans of B C .
By employing the algorithm proposed in [13], the sorting step requires additional O (µN/2 is ) log(µN/2 is ) work.
Equation 1 follows by combining the above contributions and summing over all rounds.For the analysis of the cache complexity, observe that the value λ defined in the statement of the theorem represents the index of the largest cluster C such that B C fits in cache.
Note that if λ = 0, then C is the entire D-BSP machine, hence the simulation incurs only O (1 + µN/L) cold misses.
Instead, if λ > 0, the cache complexity of a round depends on the size of the cluster being simulated in the round.Consider again a round simulating the s-th superstep for an i s -cluster C.
If i s < λ, B C cannot be contained entirely in cache.
In this case, the cache complexity of Compute(C) is given by Q Comp (i s , N, Z, L), where Q Comp obeys the following recurrence:Q Comp (j, N, Z, L) = O( µN 2 j L ) if j ≥ λ 2Q Comp (j + 1, N, Z, L) + O(1) if j < λ.
It is easily seen that Q Comp (i s , N, Z, L) = O(µN/(2 is L)).
Also, procedure Communicate(C) requires O µN/(2 is L) misses for packing, unpacking and tagging, and O µN log(µN/2 is )/(2 is L log Z) misses for sorting [13].
Therefore, in this case the cache complexity of the round isO µN log(µN/2 is )/(2 is L log Z).
Suppose now i s ≥ λ, and note that B C can be entirely contained in cache, hence the only misses that may occur are those triggered by the initial accesses to B C .
If s = 0 then the (cold) misses incurred in the simulation of the 0-th superstep for all of the 2 i0 i 0 -clusters is bounded from above by O(1 + µN/L).
Instead, if s > 0 we show that the misses, if any, can be neglected without affecting the asymptotic cache complexity of the entire simulation.
We distinguish among the following three cases depending on the label i s−1 of the previous superstep.
A number of remarks are in order.
First, we observe that the complexity gain of our simulation strategy over the trivial approach, where supersteps are simulated one after the other for all processors, becomes apparent in Equation 2, where the summation is truncated at index λ, which is a function of the cache size, rather than going up to log N −1.
This is made possible by the fact that the simulation proceeds unevenly on different clusters, thus fully exploiting temporal locality when dealing with small clusters.
In fact, the performance improvement could be substantial for D-BSP programs with high submachine locality, that is, confining most of the computation within i-clusters with i ≥ λ.Second, we note that the logarithmic terms occurring in the summations in both the work and cache complexities are introduced by the sorting employed for simulating communications.
In general the cache complexity of the simulation cannot be improved since arbitrary communication patterns in D-BSP translate into permutations on the ICM model for which a matching superlinear lower bound is known [3].
In the next section we show that for D-BSP algorithms that use certain structured communication patterns, a faster simulation can be obtained, yielding more efficient (in fact, optimal) ICM algorithms.Finally, recall that the ICM model assumes an ideal cache with optimal (yet practically unfeasible) replacement policy.
In many cases, however, the cache complexity on the more realistic cache model with the LRU replacement policy remains unaffected asymptotically as long as the algorithm satisfies a certain condition.
More precisely, an ICM algorithm is called regular if its (ideal) cache complexity satisfies Q(N, Z, L) = O(Q (N, 2Z, L)).
In [13] it is proved that the cache complexity of a regular algorithm remains asymptotically unaffected under the LRU replacement policy.We define a corresponding regularity condition in the parallel setting.
We say that a D-BSP program P is p-regular if k 0 = O(1) and k i = O i−1 j=0 k j , 0 < i < log N , where k i is the number of i-supersteps in P.
We have:Theorem 3.
Let P be a p-regular program for a D-BSP(N, g) with contexts of size µ.
Then, its simulation satisfies the regularity condition on an ICM(Z, L) with Z = Ω(µ), hence its asymptotic cache complexity remains unchanged under the LRU replacement policy.Proof.
If the cache size doubles, the value of λ defined in Theorem 2 decreases by at most one unit.
By the p-regularity of P, we have:N λ−1 i=0 k i µ log µN 2 i L log Z = O N λ−2 i=0 k i µ log µN 2 i L log Z + N k λ−1 µ log µN 2 λ−1 L log Z = O N λ−2 i=0 k i µ log µN 2 i L log Z + N λ−2 i=0 k i µ log µN 2 λ−1 L log Z = O N λ−2 i=0 k i µ log µN 2 i L log Z ,(3)and the theorem follows.
We apply the simulation presented in the previous section to two D-BSP algorithms for the prominent problems of Matrix Multiplication (MM) (limited to semiring operations) and Discrete Fourier Transform (DFT).
The D-BSP algorithms, which are briefly outlined below, are those used in [12] to obtain efficient HMM and BT counterparts.
(For simplicity, in the algorithms we assume that all relevant quantities are integral.
Easy modifications are sufficient to handle the general case without affecting the asymptotic complexities.)
MM We consider the natural recursive algorithm for multiplying two √ N × √ N matrices on a D-BSP(N, g).
Initially, the N elements of each matrix are evenly distributed among the N processors.
Then, by subdividing each input matrix into four quadrants, the input instance is decomposed into eight MM subproblems of size √ N /2× √ N /2 solved in two phases, where in each phase four subproblems are solved recursively within the four distinct 2-clusters.
To keep space requirements at a minimum, the subproblems are partitioned among the two phases in such a way that each submatrix is required exactly once in each phase.
Before each phase, elements are suitably redistributed between the clusters through a 0-superstep.
It is easy to see that the number of i-supersteps is k i = 0, if i is odd, and k i = Θ(2 i/2 ), if i is even, and that the aggregate time for local computations is τ = Θ(N 3/2 ).
Note that this algorithm is p-regular and needs contexts of size O(1).
By Theorems 2 and 3, its simulation yields a regular cache-oblivious algorithm on the ICM(Z, L), exhibiting W (N, Z, L) = O N 3/2 andQ(N, Z, L) = O 1 + N/L + N 3/2 /(L √ Z)work and cache complexities, which match the respective optimal complexities of the cache-oblivious matrix multiplication algorithm given in [13].
DFT The DFT of an N -element vector can be computed on a D-BSP(N, g) by recursively decomposing the N -input FFT dag into 2 layers of √ N independent √ N -input FFT subdags, which are computed recursively in two phases by the √ N ((log N )/2)-clusters, one layer per phase.
The outputs of the first layer become the inputs of the second layer where the correspondence is realized through a matrix-transpose permutation executed as a 0-superstep.
It is easy to see that the number of i-supersteps executed by the algorithm is k i = Θ(2 j ), when i = ((1 − 1/2 j ) log N ) (for every 0 ≤ j ≤ log log N ), and k i = 0 otherwise.Moreover, the aggregate time for local computations is τ = Θ(N log N ) and, as before, the algorithm is p-regular and needs contexts of size O(1).
By Theorems 2 and 3, its simulation yields a regular cache-oblivious algorithm on the ICM(Z, L), exhibiting W (N, Z, L) = O (N log N log log N ) and Q(N, Z, L) = O (1 + N/L + N log N log(log N/ log Z)/(L log Z)) work and cache complexities, respectively.
These complexities are only a doubly logarithmic factor away from the optimal complexities achieved by the cache-oblivious algorithm presented in [13].
It can be noted that the nonoptimality of the ICM algorithm for DFT obtained through the simulation of the D-BSP algorithm is mainly caused by the slowdown introduced by the recourse to sorting for simulating communications.
As already observed in the previous section, although the complexity of sorting cannot be avoided in the case of arbitrary communication patterns, more efficient approaches can be employed when the patterns exhibit some regularity.
This is indeed the case of the D-BSP algorithm for DFT outlined above.
Each i-superstep executed by the algorithm executes a matrix-transpose permutation within each i-cluster.
By using the regular cacheoblivious matrix-transposition algorithm proposed in [13] in place of sorting, the work and cache complexities of a round simulating an i-superstep for an i-cluster become O(µN/2 i ) and O(1 + µN/2 i L), respectively, hence the entire simulation yields a regular cacheoblivious algorithm for DFT on the ICM(Z, L), exhibiting W (N, Z, L) = O (N log N ) and Q(N, Z, L) = O (1 + N/L + N log N/(L log Z)) work and cache complexities, respectively, which are optimal.In general, consider a D-BSP program P and suppose that for every i-superstep executed by the program there exists an ICM procedure that can simulate the communication pattern required by the superstep within each i-cluster with O µN/2 i work and O 1 + µN/2 i L misses, using O µN/2 i auxiliary space.
Then, by replacing sorting with these procedures, the simulation of P on the ICM(Z, L) attains the following work and cache complexitiesQ(N, Z, L) = O 1 + µN L + N µ L λ−1 i=0 k i W (N, Z, L) = O τ + µN log N −1 i=0 k i ,where τ is the aggregate time for local computations and λ = max 0, log˜µNlog˜ log˜µN Z , with˜µwith˜ with˜µ = Θ(µ).
We refer to this type of simulations as ad-hoc simulations.
The case studies analyzed in the previous section provide evidence that efficient parallel algorithmic strategies can be transformed automatically into efficient cache-oblivious ones.
In this section, we show a tighter coupling between optimality in the parallel and memory hierarchy scenarios.
To this purpose, we need to exploit the following important feature of cacheoblivious algorithms.
Consider an extension of the ICM model consisting of a processor and k memory levels.
In [13] it is proved that a regular cache-oblivious algorithm exhibiting optimal work W and cache complexity Q on the two-level ICM, also exhibits optimal work W and optimal cache complexity Q i at each cache level i, with 0 ≤ i < k − 1, under certain reasonable assumptions on the relative values of the parameters of adjacent cache levels and under the LRU replacement policy.We say that a D-BSP(N, g) program which uses contexts of size µ is a full program if the communication required in every superstep is a Θ(µ)-relation.
We have:Theorem 4.
Let P be a full p-regular D-BSP(N, g) program using contexts of size µ, with g i = Ω(log(µN/2 i )), 0 ≤ i < log N .
If the simulation of P is optimal for the two-level ICM, then P exhibits optimal time complexity among all full p-regular D-BSP(N, g) programs for the same problem which use contexts of size Θ(µ).
Proof (sketch).
Let T (P, N, g) be the running time of program P on a D-BSP(N, g).
For the sake of contradiction, assume that there exists a full p-regular program for the same problem P using contexts of size Θ(µ), such that T (P , N, g) = o(T (P, N, g)).
Consider an extended ICM with log N cache levels, where the level-i cache has size Z i = Θ(2 i µ) and cache line size L i = O(1), for 0 ≤ i < log N .
Let W (P), Q i (P) and W (P ), Q i (P ) be the work and cache complexities attained by the simulations of P and P in such a model, respectively.
From the results in [13] it follows that the Q i 's can be obtained from Theorem 2 by plugging in the values Z i and L i in Equation 2.
It is easy to determine nonnegative coefficients t 0 , t 1 , . . . , t log N −1 such that W (P) + log N −1 i=0 t i Q i (P) = N T (P, N, g) W (P ) + log N −1 i=0 t i Q i (P ) = N T (P , N, g).
Since T (P , N, g) = o(T (P, N, g)), we must have that either W (P ) = o(W (P)) or Q i (P ) = o(Q i (P)) for some index i, which is impossible since the simulation of P is cache oblivious and optimal in the two-level ICM, hence also optimal on any multi-level ICM [13].
An almost identical property can be proved for adhoc cache-oblivious simulations, with the only difference that in this case D-BSP optimality holds with no restrictions on the vector g.
As a consequence, the D-BSP MM and DFT algorithms described in Section 4 turn out to be optimal among all D-BSP(N, g) algorithms for the corresponding problem using constantsize contexts (the reader can convince himself/herself that an ad-hoc cache-oblivious simulation for the MM algorithm exists).
eThe pseudocode of the simulation algorithm is given below.Algorithm Simulation(P) The pseudocode of the simulation algorithm is given below.Algorithm Simulation(P)
