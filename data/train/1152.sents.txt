This paper investigates how to "observe" a planar object being pushed by a finger.
The pushing is governed by a non-linear system that relates through contact the object pose and motion to the finger motion.
Nonlinear observability theory is employed to show that the contact information is often sufficient for the finger to determine not only the pose but also the motion of the object.
Therefore a sensing strategy can be realized as an observer of the nonlinear dynamical system, which is subsequently introduced.
The observer, based on the result of [6], has its "gain" determined by the solution of a Lyapunov-like equation.
Simulations have been done to demonstrate the feasibility of the observer.
A sensor has been implemented using strain gauges and mounted on an Adept robot with which preliminary experiments have been conducted.
From a general perspective, this work presents an approach for acquiring geometric and dynamical information about a task from a small amount of tactile data, with the application of nonlinear observability theory.
Sensing and grasping are often performed sequentially by robots.
But this is not the case with human beings.
Even with no help from vision, the human hand can usually manipulate an object by feeling the contact and utilizing this information to control the object.For example, try to grasp something, say, a pen, on the table while keeping your eyes closed.
Your hand gropes for it on the table until one of the fingers touches the pen and starts pushing it for a short distance.
By feeling if the contact is almost stable, moving counterclockwise, or moving clockwise on the fingertip, you can quickly tell ¡ Support for this research was provided in part by Carnegie Mellon University, and in part by the National Science Foundation through the following grants: NSF Presidential Young Investigator award IRI-9157643 and NSF Grants IRI-9213993 and IRI-9503648.
if the middle, the right end, or the left end of the pen is being touched, respectively.
Immediately, you are able to coordinate other fingers to close in for a grip.The above example suggests that the human hand has some intrinsic way of exploiting the shape information about an object and the tactile information generated by a mechanical interaction with the object.
In designing a sensing or grasping strategy, we should try to take advantage of the mechanics, the manipulator and object's geometry, and their correlation.
This paper illustrates such idea through the study of a specific problem: Can we determine the pose and motion of a known object from the contact motion on a pushing finger?In this paper we will answer yes in general to the above question, offering a pose and motion estimation algorithm in Section 4.
Figure 1 shows a simple example of a disk pushing a 7-gon and estimating the pose and motion of the polygon in less than a second using the algorithm.
Dynamics of sliding rigid bodies was treated by MacMillan [15] for non-uniform pressure distributions, and by Goyal et al. [7] using geometric methods based on the limit surface description of friction.Montana [17] derived a set of differential equations describing the motion of a contact point in response to a relative motion of the objects in contact.
The kinematics of spatial motion with point contact was also studied by Cai and Roth [3].
Mason [16] pioneered the study of the mechanics of pushing using quasi-static analysis.
Alexander and Maddocks [1] offered analytical solution to the problem of determining the motion of a slider under applied force by a reduction to the case of a bipod.
Lynch et al. [14] localized an object using the mechanics of pushing and tactile feedback.The paper by Salisbury [19] introduced fingertip force sensing which determines contact locations and orientations from force and moment measurements.
Fearing and Bin- The imaginary scene as "perceived" by the observer during the same time period.
Although the real contact and its estimate were about 4.5cm apart on the contact edge at the start of estimation, the error becomes negligible in 0.56s.ford [5] designed a cylindrical tactile sensor to determine the principal curvatures of an object through rolling contact.
Inspired by the results on exploratory procedures in human haptics, Allen and Roberts [2] fit a number of contact points around an object obtained by robot fingers to a superquadric surface representation to reconstruct the object's shape.The foundation of our work comes from the theory of the observability and observers of nonlinear systems.
For a general introduction to nonlinear control theory,we refer the reader to Isidori [9] and Nijmeijer and van der Schaft [18].
Necessary and sufficient conditions for linearization by output injection for autonomous nonlinear systems (i.e., without input) were given in [11] by Krener and Isidori, and in [12] by Krener and Respondek along with a constructive algorithm.Gauthier, Hammouri, and Othman [6] described an observer for affine-control nonlinear systems whose "gain" is determined via the solution of an appropriate Lyapunovlike equation.
Ciccarella et al. [4] proposed a similar observer whose gain vector is controlled by the properly chosen eigenvalues of a certain matrix obtained from the original system's Brunowsky canonical form.Zimmer [20] presented a state estimator based on Newton's method that conducts on-line minimization over some objective function.
gives the velocity of the contact point on the fingertip.
That ¥ and ¦ maintain contact imposes a velocity constraint: ¨ © B A C ) ˙ 0 ¨ D A 1 E G F H A F ) ˙ # P I (1)whereF R Q Sis the rotation matrix associated with the orientation In our previous work [10], we derived the contact and object motions from (1), the geometric constraints of contact, and Newton's and Euler's equations for dynamics.Theorem 1 In the given system of ¥ pushing ¦ , the points of contact evolve according to˙ 0 A C % ( ' T U ) !
V W X ¨ D A 1 E Y F H ` 4 ¨ © % & A a % ' ; (2) ˙ # b 0 ` A c % & U ) d V W e ¨ f A 1 E g F G ` B ¨ © h % i & p A a % ( ' ;(3)and the object's angular acceleration and acceleration are given as e d f its direction.
1 Given the nonlinear system (2)-(5), sensing can be viewed as to determine the object contact # , and possibly, the object's angular velocity and velocity¨, velocity¨ velocity¨, from the finger contact .
In this section we shall study whether contains enough information for such computation, resorting to the notion of local observability in nonlinear control theory.
Let us consider a smooth affine (or input-linear) control system together with an output map: , is the directional derivative˙ g 0 i h j g A l k m n X o 1 n S p n g x I Y q a 0 r R 1 I $ s t s $ s e I u k  w v r x z y k I { 0 } | h g x I (6) where g 0 ~  1 I $ s t s $ s e I u  (  d R P  ¡ e ¢ § 0 v  ¨  ¡ V © ¢, where P  ¡ 0  t ª S « x ¬ ª $ ­ 1 I t s $ s t s e I !
ª S «  ¬ ª $ ­ ¦ ® is the differential or gradient of  .
The observation space ¯ of system (6) £  ¤ 1 £  ¤ 2 V $ V $ V @ £  ¤ " °  ¦ ¡ y 0 ± £  ¤ 1 R £  ¤ 2 @ s $ s t s  R £  ¤ " °  ¦ ¡ W s $ s $ s @  I for ²  0 1I $ s t s $ s e I u ³ I ´ 1 0 1I 2I $ s t s $ s, and¢ 1 I $ s µ s  s  I 8 ¢ · ¶  ¸ h j I p 1 I t s $ s t s e I p k p ¹ .
The observability codistribution at stateg º  , denoted P ¯ H g, is defined as: ¨ ¯ » g ¼ 0 span¸ span¸ span¸ P ½ 4 g ¿ ¾ S ½  ¯ ¹ sWe refer the reader to [8] and [18, pp. 95-96] for more on nonlinear observability.
is called the observability rank condition.
Basically, to distinguish between a state and any other state in its neighborhood, it is necessary to consider not only the output functions but also their derivatives along all possible system trajectories.
The rank condition ensures the existence of  output functions and/or derivatives which together define a diffeomorphism on some neighborhood of the state, which in turn ensures that the state is locally distinguishable.
Now we study the case of pushing in which finger , respectively.
The system (2)-(5) now reduces to 3˙ Í 0 Â ; ˙ # ± 0  V ¦ X ¨ G ` B ¨ © U ` Â A Î  !
; ˙ 0 # # 2 A  2 t 2 R Â j A c  i Ï ` 2  V S e ¨ G ` B ¨ © h U `  E Y  © w ` § ! 
 # 2 A  2  E Γ;(7)˙ ¨  0  2 # 2 A  2 t Ê V  © 4 ` 2 R Â h A a  !
A 2  V ¦ X ¨ » ` 4 ¨ ©  Ð w Ê ` § ! 
 #  V Γ  ` # # 2 A  2 § ! 
 Ê V Γ Ê sWe refer to (7) and its future variations as the disk-polygon system.
To apply Theorem 2 we still need to rewrite (7) into the form (6) of an affine system.
Expressïn ð R £ ë £  ì e Õ j £ ë !
ð Ñ  0 Â # 2 `  2 R # 2 A  2 2 ; ð ð Ñ  £ ë £ Ï ì u Õ £ ë £  ì u Õ £ ë i í í í í s î o ï 0 Â P R Â j A c  i 4  4 s ñThe above proof in fact constructs several control sequences which, when applied for infinitesimal amounts of time, will distinguish between different states in any neighborhood.
Assuming Support friction does not affect the local observability of the disk-polygon system, as none of the differentials chosen in the proof to span  P ¯ involve the integral Γ or any of its partial derivatives.
With the local observability result we can view sensing strategies as nonlinear observers for the disk-polygon system (8) or for the general pushing system (2)-(5).
An observer of a nonlinear system is a new system whose state always converges to the state of the original system.
The input of the observer consists of the input as well as the output of the original system.Luenberger-like asymptotic observers [13] for nonlinear systems are often designed through linearization.
The diskpolygon system, however, cannot be linearized for we have£ ì Õ h £  ë P £ ì Õ £  ë d 0 Â P R Â j A C  !
# ¦ # 2 `  2 # 2 A  2 3 Iviolating one of Nijmeijer's necessary conditions [18, p. 156] on linearization.
Another approach of observer design transforms the original system into a linear system modulo an output injection [11].
The necessary conditions for a nonlinear system to admit linear observer error dynamics are rather restrictive and hardly satisfied by the disk-polygon system, let alone system (2)-(5).
Our observer, for the disk-polygon system only, uses the following result by Gauthier, Hammouri, and Othman [6].
Consider the single output nonlinear (and analytic) system is the solution of equation˙ g 0 h j g(10)ý 0 ` h þ ü û ` B ÿ  ü û ` ü û ÿ a A C ú  ú p I(12)with ÿ n ¡ ¡ Î 0 ¢ n ¡ ¡ õ 1 , for þlarge enough, is an observer for (10) with error dynamics£ ˜ g   u  ` g   u £  ¤ 4 X þ P @ Å õ ¦ ¥ ¨ § 3 £ ˜ g 0 U ` g 0 £ sThe GHO observer for a nonlinear system (6) with inputs is a copy of the original system plus the error corrective term given in (11).
To admit such an observer, not only must conditions 1 and 2 in Theorem 4 hold for the drift system ˙ g 0 h j g , but also the original system must be observable for any input.Getting back to the disk-polygon system (8), we consider U I e # W I, andê © ` ×  g 0 ä å å ae Â Â S £ ë Â S £ 2 ë è é é ê sFor all except at most a finite number of states, In the presence of contact friction between the finger and the object, we need to consider two modes of contact: rolling and sliding, according to whether the contact force lies inside the contact friction cone or on one of its two edges.
Each mode is hypothesized and solved; then the obtained contact force is verified with the contact friction cone for consistency.It is not difficult to set up motion equations for rolling and sliding that are similar to (2)-(5) and prove that local observability carries over to both situations.
A GHO observer for pure rolling can also be derived.
We will show the simulation results on this observer in the next section.
The GHO observers for frictionless contact (13) and for rolling were simulated.
The object data in our simulations were randomly generated polygons.
The coefficient of support friction was chosen to be uniformly 0.3.
The finger accelerations and velocities used in simulations are achievable on an Adept robot.For the rolling example shown in Figure 1, the trajectories of We have built a "finger" with tactile capability using four strain gauges as shown in Figure 5.
The strain gauges are connected to an Omega PC plug-in card to form two Wheatstone half bridges that measure the components of a force exerted on the disk boundary along the  and ö axes of the disk, respectively.
When contact friction is small enough, the contact force measured by the gauges would be along the disk normal at the contact, thereby indicating the contact point.The sensor can detect force in microstrains with a frequency over 2000 Hz.
It reports a contact with the disk boundary in terms of its polar angle with respect to the disk center.
After calibration, the sensed static contacts (in 1000 readings) constantly have a mean within one degree away from the real contact and a standard deviation of less than 0.5 degree.To realize the GHO observer, we are working on improving the sensor readings of moving contacts which are currently noisy due to varying contact friction.
We have introduced a sensing approach based on nonlinear observability theory which makes use of one-finger tactile information.
The approach determines the pose of a known planar object by pushing it with a finger that can "feel" the contact motion.
It also estimates the object motion during the pushing.The kinematics of contact and the dynamics of pushing yield a system of nonlinear ODEs whose state includes the object pose and motion and whose output is the moving of observation for frictionless contact took about 600s.
contact on the fingertip.
We establish the local observability of this system for the special case of a disk pushing a polygon.
Such result is expected to carry over to most other finger and object shapes.
This result forms the underlying principle of our sensing algorithm, which is an observer of the nonlinear dynamical system.Based on the result of [6], we construct asymptotic nonlinear observers taking into account support friction and/or contact friction and demonstrate them by simulations.
These online observers are capable of correcting any local error in estimating the object pose and motion.We have implemented a force sensor using strain gauges to detect contact locations.
Preliminary experiments have been carried out with an Adept robot.Our undergoing research focuses on the sensor experiments and the extension of pose and motion observability to 3-D tasks.
