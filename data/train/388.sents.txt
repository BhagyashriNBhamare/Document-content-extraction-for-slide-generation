We evaluate different two-dimensional non-linear deformation models for handwritten character recognition.
Starting from a true two-dimensional model, we derive pseudo-two-dimensional and zero-order deformation models.
Experiments show that it is most important to include suitable representations of the local image context of each pixel to increase performance.
With these methods, we achieve very competitive results across five different tasks, in particular 0.5% error rate on the MNIST task.
In many object recognition tasks it is important to use suitable models of image transformation to obtain good results.
The recognition of handwritten digits is a prototypical task in this context, as different writing styles lead to strongly varying appearances of the images, but at the same time the reference model for each class is well-defined.
In this paper we show that two-dimensional non-linear deformation models in combination with suitable representations of the local image context of each pixel are an effective means to obtain excellent results for this task.
We use five different databases and a comparison to other approaches shows that the proposed methods generalize very well.We describe deformation models of different order: Two-dimensional (2D) hidden Markov models (HMMs) take into account the connections between the displacements of pixels in both directions of the image plane.
They have been introduced in several publications, e.g. [1].
Pseudo-two-dimensional (P2D) HMMs relax the constraints in one of the dimensions, thus reducing the computational effort considerably [2].
If we further relax the constraints on the deformation grid such that the pixel displacements are independent of each other, we arrive at a zeroorder model that we call image distortion model (IDM).
This simple model has been introduced in the literature several times with different names, e.g. [3].
Finally, the P2DHMM can be extended to allow additional distortions.The experiments show that the important aspect for these models is the use of local context information at the pixel £ This work was partially funded by the DFG (Deutsche Forschungsgemeinschaft) under contract NE-572/6.
level.
Using this context information in the form of the image gradient and local image parts, the performance can be improved significantly, leading to state-of-the-art results.
Since we investigate the influence of different deformation models on the classification accuracy, we use a simple classification setup, i.e. the well-known nearest neighbor (NN) classifier.
On most databases, the 3-NN classifier was used, as other groups report good results for this choice.The deformation models result in distance measures that are used in the NN classifier, where the test image¤ ¦ ¥ ¨ § © ¥ " !
# % $ & $ % $ ' ( ) 1 0 2 ¥ " !
& $ & $ % $ 3 3 4is explained by a suitable deformation of the reference image5 ¥ 6 § 8 7 & 9 A @ # C B D ¥ !
# % $ & $ & $ & C E F G " ¥ H !
& $ % $ & $ 3 P I. Here, the image pixels takeQ - dimensional values © P 79 % @ S R U TV X W .
We now want to determine an image deformation mapping Y B a ` ' b c P c G d ` ' b c c f e h g Y i 1 0 e q p r Y B C G sd f e g h  Y B ` ' b c P c G` i b c P c e C  ¥ i   k j e d Y B m l i G s n l 0 eOn the other hand, relative cost functions depend on the relative displacement of neighboring pixels:d p o g % q  Y B ` ' b c P c G` i b c P c f e C  ¥   r j oY B ) l Y B ) s c u t v !
e G # l G # s c w C B x s l B ) y s c G # l Y G # z s c t v !
e C eHere, j e and j o determine the model structure as mentioned above.
The distance measure is determined by minimizing the costs over the possible deformation mappings:Y ¤ u 5 e ¥ ¡ £ ¢ ¥ ¤ t 9 % v x w y 1 y @ & v u w y 1 y ¦    ¤  5 Y B `  b c P c C G`  b c P ce t ¨ § d  Y B `  b c P c G`  b c ce ©where § is the deformation cost weight andd ¥ d o t d eis the sum of relative and absolute deformation costs.
Additionally, the border constraintsB c " ¥ !
# B ` " ¥ E F C G # c ¥ !
# C B x b ¥ Iare applied.
To soften these constraints the images can be extended by e.g. 3 pixels at the borders.Two-dimensional HMM.
The 2DHMM is an extension to two dimensions of the (0,1,2)-or (loop, jump, skip)-HMM that is frequently used e.g. in speech recognition.
It results from using the relative cost function j oY9 @ 9 @ e ¥ ¡ Y  9   y  @   y  9   z  @  e " !
!
# otherwiseThis cost function ensures monotonicity (no backward steps) and continuity (no large jumps) of the displacement grid.
Here, instead of using the cost value 0, we can also use a function depending on the relative displacements.
In addition, we may also use an absolute cost function j eY$ 9 @ e ¥ ¡ £ % Y  9   @  e & !
( ' # otherwise (1)with a warp range' (e.g. ' ¥ 0 )), which restricts the absolute global deformation.
The minimization of this true 2D model is NP-complete [4], and therefore approximation algorithms are used as e.g. dynamic programming with beamsearch [1], or simulated annealing.Pseudo-two-dimensional HMM.
The P2DHMM [2] is obtained from the 2DHMM by neglecting the dependencies between pixels of neighboring image columns, using: This model is computationally equivalent to a onedimensional HMM and therefore the minimization process can be solved in polynomial time.
Nevertheless, the computational effort can be substantial and methods like beam search can be used to speed up the minimization.Image Distortion Model.
The IDM is a zero-order model, i.e. local dependencies in the displacement grid are neglected.
Consequentially, it results from using no relative cost function (i.e. f g f f h i q p s r ¥ t v u w $ x y s p  r R     $ x f   Figure 2.
Example P2DHMDM mapping.IDM.
It results from the P2DHMM when we allow additional distortions from the columns that are matched by an additional pixel, where these distortions are independent of each other.
Figure 2 shows an example mapping allowed under the restrictions of the P2DHMDM.
Using the above models, experiments on the USPS corpus (Section 4) showed that only a comparatively small improvement from 5.6% to 4.0% was possible when using the pixel values directly.
Furthermore, the improvements depended strongly on the choice and weight of the deformation cost function for the allowed relative displacements.
An analysis showed that some wanted deformations but also unwanted deformations changing the class membership of the images were modeled.
This behavior can be restricted by including the local image context of each pixel in an appropriate way, with the result that pixel values are vectors.Derivatives as context.
One straight forward way to include the local image context is to use derivatives of the image values with respect to the image coordinates as computed by the horizontal and vertical Sobel filter.
These values have the additional advantage of invariance with respect to the absolute image brightness.
Now the question arises of how to weight the importance of the context information with respect to the image gray values.
Figure 3 shows the error rate on the USPS corpus (using the P2DHMM) with respect to the relative weight of the gradient image (a relative weight of 1 means that only the gradient information is used).
From the graph it is clear that best results are obtained when using only the gradient information.
The additional use of the second derivative lead to only small improvements in first experiments.
All results presented here were obtained using 3  3 sub images of the horizontal and vertical gradient images only, i.e. 18-dimensional vectors as pixel values, as these settings showed the overall best performance among those investigated.
Figure 4 shows the process of the feature extraction: The horizontal and vertical gradient images are calculated using the Sobel filter, then the local 3 .
To speed up the classification process, a preselection of the e.g. 500 best fitting references based on the Euclidean distance was performed in some of the experiments [5].
The software used for the experiments is available for download 1 .
An overview of the used corpora is shown in Table 1.
For each database some example images are shown along with the sizes of training and test sets and the sizes of the images.
Reference results are shown in Table 2 along with the results obtained using the methods presented in this paper.
It can be observed that the results are state-of-the-art and even improve on the best published error rates for three of the five corpora.
In the following paragraphs we shortly summarize special results for each of the databases used.USPS.
On the US postal service database, the P2DHMDM gave the best results.
Some experiments were 1 http://www-i6.informatik.rwth-aachen.de/¦ gollan/w2d.html performed for training of prototypes with the presented models.
Figure 5 shows the mean images for all ten classes and the prototypes learned using the deformation model.
The error rates show that the P2DHMDM performs better using the learned prototypes and interestingly using only one prototype per class, the error rate is as low as 4.9%.
The learned prototypes appear much less blurred than the means, as the variation is compensated by the non-linear deformation model.
On the other hand the corresponding mean images perform better if no deformation is used.UCI.
On the University of California, Irvine, optical digits corpus, a scaling to 16  16 pixels using spline interpolation was performed.
Here, the IDM performed as good as the more complex P2DHMDM.MCEDAR.
On the Modified CEDAR (Center of Excellence for Document Analysis and Recognition) task, again the images were scaled to 16  16 pixels using splines.
Here, the P2DHMDM performed slightly better than the IDM.MNIST.
On the Modified National Institute of Standards and Technology task, due to the good results of the IDM on the other databases and the lower complexity, only the IDM [12] and 56 reported in [13].
ETL6A.
The Electrotechnical Laboratory, National Institute of Advanced Industrial Science and Technology, Japan, 6A sub corpus contains Latin uppercase letters of 26 classes that were scaled down to 16  16 pixels.
The proposed deformation models, which are similar to the methods used in [15,16], also obtained very good results, here.Comparison of different models.
Due to space limitations, we cannot give a complete list of reference results for the different models here.
A detailed discussion can be found in [5].
In the experiments, some general results could be observed.
For all of the models, the performance increased significantly with the use of local image context.
This increase was greater for the simpler models, leading to the conclusion that the context information can compensate for the neglected restrictions.
One of the reasons for the fact that the more complex models did not outperform the simpler models is the following: Due to the computational complexity of the minimization, approximation methods had to be applied and for the more complex models usually a smaller number of images was preselected using the Euclidean distance to reduce the computational effort.
We presented different non-linear deformation models and introduced the P2DHMDM as an extension.
The most important aspect when applying these methods is the inclusion of local image context information, for which we propose the gradient and small sub images.
Using the context information, very good results can be achieved even with simple deformation models.
The experiments gave new best results on three of the five databases used and were very competitive on the remaining two.
The excellent overall results show the general applicability of the methods, which is also true for medical images [17].
Aspects to be addressed in future work include other methods of context extraction, as e.g. PCA, the use of more prototypes per class and the extension to the recognition of continuous script.
