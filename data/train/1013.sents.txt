We present a general graph learning algorithm for spectral graph partitioning, that allows direct supervised learning of graph structures using hand labeled training examples.
The learning algorithm is based on gradient descent in the space of all feasible graph weights.
Computation of the gradient involves finding the derivatives of eigenvec-tors with respect to the graph weight matrix.
We show the derivatives of eigenvectors exist and can be computed in an exact analytical form using the theory of implicit functions.
Furthermore, we show for a simple case, the gradient converges exponentially fast.
In the image segmentation domain, we demonstrate how to encode top-down high level object prior in a bottom-up shape detection process.
Image segmentation and data clustering are two fundamental operations in computer vision and machine learning.
Let I = {x 1 , ..., x n } be a set of feature vectors representing n image pixels or data points.
The image segmentation process partitions pixels into K disjoint groups.
In a 2-way segmentation, we seek an output vector SEG(I) = {y 1 , ..., y n } ∈ {0, 1} n , such that a segmentation goodness measure is optimized.
We defined segmentation as a mapping from x i to y i ∈ {0, 1} to purposely hint its potential connection to a supervised learning method we should propose.
Our goal is to teach the image segmentation through a set of hand labeled training examples.
Given a set of image/segmentation pairs {I i , SEG * (I i )}, the system will learn to adjust so that the computed segmentation SEG(I i ) is close to SEG * (I i ).
With a supervised image segmentation, we are able to encode top-down object familiarity prior in a bottom-up distributed process.
In this paper, we will demonstrate a system that can detect and segment rectangular shaped objects in a clutter image background by learning from examples.To appreciate why learning image segmentation is difficult, we summarize below its basic principles.
Segmentation algorithms are defined by the clustering criteria and computational process to optimize it.
For example, in the Markov Random Field (MRF) formulation, the criteria is to maximize P (SEG(x)|x) = 1 Z exp( −f (y i , y j |x)), where f (y i , y j |x), called clique potential, specifies a local measure of grouping pixel i with j.
While each f (y i , y j |x) can be easily corrupted, the global optimum of P (SEG(x)|x) must balance preferences on all pairs of f (y i , y j |x) and therefore is stable.
Spectral graph partitioning, such as Normalized Cut (Ncut) [6][5], has been developed as a computationally efficient alternative to MRF.
Image segmentation is mapped to a graph partitioning problem, where the graph consists of the pixels/data points as nodes, and the weighted graph edges W (i, j) serve as the equivalent of Clique Potential f (y i , y j |x).
The global segmentation criterion Ncut seeks a balanced segmentation and grouping of the pixels.
Computationally the solution is derived from the eigenvectors of W y = λDy, where D is the degree matrix.
As in the MRF case, the eigenvectors are implicitly related to the input weight matrix W , and are quite insensitive to random perturbation of W .
While global decision process from local feature comparison brings a stable segmentation, it makes the learning segmentation a difficult task.
Treating any segmentation learning algorithm as a black box, one must be able to back-trace error on the output of global segmentation to the input local clique potential or pair-wise weight matrix.
Since the global decision is only implicitly related to the input, it is hard to explicitly assign a blame to a particular clique potential or weight matrix entry.
To account for segmentation error on just one pixel, we would potentially need to adjust all possible pairs of clique potential or weight optimizes the graph weight W (I, Θ) by minimizing the KL-divergence between an equivalent random walk matrix P (I, Θ) and the target P * (I, Θ).
(B) Our method directly optimize the error on the output Ncut segmentation vector X N cut [W (I, Θ)] by gradient descent in the space of all feasible graph weights using explicit computation of the derivatives of eigenvectors.matrix entries!
Meila-Shi [4] first studied the problem of learning spectral graph cuts with supervised training data.
Their proposed algorithm learned the graph weight W ij by minimizing the KL-divergence between an equivalent random walk matrix P ij and the target P * ij derived from the hand labeled segmentation.
However the formulation provides no explicit constraints on the Ncut eigenvector itself.
Bach-Jordan [1] formulated a direct optimization of W with respect to its Ncut eigenvector.
They transform the implicit relationship between W and Ncut eigenvector into an explicit one by making a differentiable approximation of eigenvector using power method.
The resulting computation of derivatives of eigenvector is however complex and can be computationally unstable.We present in this paper a direct method for learning spectral graph cut, based on efficient computation of derivatives of Ncut eigenvectors in exact analytical form.
We show that there is an explicit computation that assigns the segmentation error to the input graph weight matrix.
This capability allows us to design parameterized graphs that can encode and detect complex objects.
The paper is organized as follows.
We describe in Sec. 2 the structure of the graph we use for image and shape segmentation.
Sec. 3 describes the learning algorithm and its convergence properties.
We show our results in Sec. 4.
We will demonstrate a learnable segmentation algorithm for detecting and segmenting desired object shape such as a rectangle in an image.
The shape detection-segmentation process begins with edge detection.
Each edge i is parametrized by (x i , y i , θ i ), its location and orientation.
Denote F (I) = {e 1 , ..., e k |e i = (x i , y i , θ i )} the set of edges detected for image I, and F the complete set of possible edges detected in all images.
The goal of the segmentation algorithm is to group the edges which form a rectangle, and separate them from background edge clutters, as shown in Fig. 11.
While a rectangle is a relatively simple shape, its aspect can be quite flexible with variable aspect ratio in x, y, and variable orientation.
Assuming we have quantized the orientation into N angle angles, for an image size of N pixel × N pixel a brute force method would need to search over O(N 4 pixel N angle possible configurations (for a 100 × 100 image with 10 orientations quantization, we have 1 billion configurations!)
.
One way to avoid this large scale search is to decompose the rectangles into simple local configurations (corners, lines, parallel lines), and combine them by checking their global consistency.
This datadriven bottom-up process only needs to check roughly O(N edge ) = O(|F (I)|) local configurations (assuming a fixed neighborhood size).
The global integration can be carried out in the grouping framework of graph partitioning such as Ncut, which has empirically a running time of O(N 1.5 edge ).
Furthermore, the decomposition of a shape into local edge relationships also makes the detection more robust to image background clutter.
We need to define functions on local configuration goodness, with the hope of discriminating rectangular object vs. background.
Since we are using oriented edges, we can favor convex configurations and penalize concave or other impossible configurations, as illustrated in Fig. 2.
The function that assesses the goodness of a particular configuration is denoted as clique potential: f (e 1 , . . . , e K ) is high only when (e 1 , . . . , e K ) form a familiar configuration.
The problem of designing this clique potential can be quite complex in general.
For example, consider the case of binary relationships: we need to find a potential function for all possible pairs of edges (e 1 , e 2 ): Figure 2: Different oriented edge configurations and associated clique potential.
Left: three edges forming a convex object (likely to be found in rectangle shapes).
Middle: concave configuration (unlikely in rectangular shapes).
Right: impossible configuration (very unlikely to be found in any object).
invariance, f (x 1 , y 1 , θ 1 ; x 2 , y 2 , θ 2 ) = ¯ f (x 2 − x 1 , y 2 − y 1 , θ 1 , θ 2 ) and, f (z 1 , θ 1 ; z 2 , θ 2 ) = ¯ ¯ f ((z 2 − z 1 )e −iθ1 , θ 2 − θ 1 ).
Right: summing up ternary affinities to obtain a binary affinity, f (e 1 , e 2 ) = i f 3 (e 1 , e 2 , e i ).
f (e 1 , e 2 ) = f (x 1 , y 1 , θ 1 , x 2 , y 2 , θ 2 ).
The function takes 4-dimensional inputs, and even in the simple case of 10x10 possible edge locations, with 4 orientations {π/2, 2π/2, 3π/2, 4π/2}, that makes 160,000 different values to design through learning.
To make the learning problem more managable, we use the following parameterization that induces translational invariance:f (x 1 , y 1 , θ 1 ; x 2 , y 2 , θ 2 ) = ¯ f (x 2 − x 1 , y 2 − y 1 , θ 1 , θ 2 ) (1)If in addition we also require invariance by rotation, the use of complex numbers comes in handy, with z = x+iy we obtain f (z 1 , θ 1 ; z 2 , θ 2 ) = ¯ ¯ f ((z 2 −z 1 )e −iθ1 , θ 2 − θ 1 ).
These invariance properties are illustrated in Fig. 3.
With local edge clique function we could eliminate wrong patterns of edges, retrieve the correct edge orientation when ambiguous, and enhance good configurations.
However, there are many ambiguous cases in which local properties are insufficient to decide the foreground/background labeling.
Think about a weak edge at object boundary, or a strong clutter edge in the background.
A direct thresholding technique would fail here.
Another example is provided by Fig. 4, where a local approach would favor the wrong edge orientation.
As in the case of image segmentation, local grouping measures need to be aggregated to form a global segmentation decision.
We will see in the next section how to formulate this precisely in graph framework, through Spectral Graph Partitioning.Figure 4: Each edge has 2 hypothesized opposite polarities.
We want to inhibit clutter edges and recover correct polarity.
Left: local segmentation of edges produces the wrong polarity for one edge (barred), grouping it with clutter.
Right: global aggregation of edge affinities yields a correct grouping and inhibits clutter.
Such local relationships between image features are well captured by the notion of graph G = V, W .
The graph nodes V consist of the image edge features F = {e i }, and the graph edges are the relationships between the edge features with affinity matrix W ∈ R n×n defined by W ij = f (e i , e j ).
Higherorder edge feature relationships can be translated into binary affinities by summing over cliques: W ij = i1=i,i2=j,i3,...,iK f (e i1 , ..., e iK ), as illustrated in Fig.
3.
We denote V (I) the image edge features, F (I), detected in I; W (I) = W (V (I), V (I)), the subgraph affinity induced by image features in I.Let us recall our goal: we want to partition the graph nodes V (I) into two groups, using an indicator vector X: X i = 1 if detected feature V (I) i belongs to foreground, and X i = −1 if it belongs to background.
The segmentation process should ensure that edge features (nodes) grouped together have high mutual affinity, and nodes in different sets have low affinity.
We will use the Normalized Cuts (Ncut) criterion for the segmentation process.
Ncut criterion can be optimized by finding the second generalized eigenvector of (W (I), D(I)) (D(I) is the degree matrix of W (I)):W (I)X(I) = λ 2 D(I)X(I)(2)X(I) is then thresholded to determine the foreground/background labelling.
Note that, the solution we obtain for X(I) is an implicit function of the weight matrix W (I), which is defined by the local W (LN, F ) = W (RN, F ) = W (LN, N F ) = W (RN, N F ) = 1 2, making it impossible to distinguish between a Face and a Non-Face.
The graph learning algorithm we propose does not suffer from this.
clique potentials, f (e i , e j ).
However, its computation is tractable and, as we shall see, we can apply perturbation theory to analyze their effect on the segmentation task.
This last point is essential: it means that we can assign a blame to the local graph structure, by looking at the global segmentation result.
Hence the system is not a black box anymore, we can train it.
As we have seen, the design of the clique potential is as crucial to the segmentation as it complex.
In the Ncut formulation, whether we use a parameterization of the affinity matrix W (Θ) or a direct representation through its coefficients W ij , real image segmentation tasks will require a large number of parameters to be optimized.
Hence the need for a principled algorithm to learn the clique potential.
One natural idea in learning the graph clique potential is simply to measure the coocurrence of image features accross a set of training images, in accordance to the Hebbian rule.
This rule strengthens the weight W ij if feature i and feature j are strongly correlated, according to: W ij = I V (I) i V (I) j in our notation.
Though intuitive, this rule is insufficient for our problem.
Fig.
5 illustrates a typical situation that the Hebbian rule is unable to handle, namely the XOR boolean function.
More generally, the Hebbian rule cannot learn non-linearly separable functions.
We have shown in [2] 1 that our system does not have this limitation and it could learn XOR.1 http://www.seas.upenn.edu/∼timothee/research.html The Maximum Likelihood formulation (ML) tries to adjust the clique potential so that it maximally explains the data (the set of training images).
However, this formulation doesn't take into account the graph inference procedure I → X(I), as a result, it can produce a probability distribution that cannot be inferenced efficiently.
We use a different approach.
We adjust the clique potential so that the output of the system gets closer to the desired segmentation.
In the following, we assume we are given a set of images I with a target segmentation X * (I).
Definitions X p [W ], λ p are the p th largest eigenvec- tor, eigenvalue of W X = λD W X with X p [W ] = 1 and D W = diag(W 1).
X p [W ]is uniquely defined up to polarity, which we disambiguate using a fixed vector Y and forcing sign(Y T X p [W ]) = +1.
This is possible only when Y T X p [W ] 񮽙 = 0.
We also require λ p be unique.
To satisfy these constraints, we will restrict our attention to weight matrices W in a certain subset S 2,X * (I) n of symmetric matrices, whereS p,Y n = {W ∈ S n : W 1 > 0, ker(W − λ p D W ) 񮽙 ⊂ Y ⊥ , λ p single}.
Note that if W ∈ S n and W 1 > 0, W has probability 1 of being in the feasible space.
What's more, S 2,X * (I) n is open, which implies that any small perturbation of W is allowed.
Define the one-target energy function:E(W, I) = 1 2 X 2 [W (I)] − X * (I) 2 , for W ∈ S 2,X * (I) n(3)The multi-target energy function is defined asE(W ) = I E(W, I), for W ∈ ∩ I S 2,X * (I) n.
This error energy function has the following property, which will be useful later on when we try to learn the graph network.
The single target energy function has all its local minima in S 2,X * n {W : λ 2 (W ) 񮽙 = −1} equal to the global minimum, 0.
The proof, in [2], shows that at a critical point, the error vector X 2 − X * (I) is in the kernel of a certain matrix of rank n-1.
This shows in fact that X 2 − X * (I) is proportional to X 2 , which finally leads to X 2 = X * (I).
e i , e j ) = ¯ f (x 2 − x 1 , y 2 − y 1 , θ 1 , θ 2 ), which is a 4 dimensional lookup table.The main difficulty is to study how the Ncut eigenvector, X 2 [W (Θ)], varies with the graph weight matrix W (Θ).
We will write down a continuous-time PDE describing evolution of the error energy on X 2 [W (Θ)] with respect to Θ.
We show that this PDE has an exact analytical form, and the resulting PDE converges.
We have also proved the convergence rate is exponential for a simple case [2].
This result shows that we can minimize the error energy over W or Θ by gradient descent.
The map W → (X p , λ p ) is C ∞ over S p,Y n , and we can express the derivatives over any C 1 path W (t) as:dX p [W (t)] dt = −(W − λ p D W ) † (W ′ − λ p D ′ W − dλ p dt D W )X p dλ p dt = X T p (W ′ − λ p D ′ W )X p X T p D W X pWe obtain an analog theorem for the derivative of standard eigenvectors, by simply replacing D W with I n .
The proof in [2] uses the implicit function theorem to showX p [W ] is C ∞ , then differentiates W X p = λ p D W X p to obtain (W − λ p D W )X ′ p + (W ′ − λ p D ′ W − λ ′ p D W )X p = 0.
Computation of the partial derivatives ∂X2∂W alone requires O(n 3 ) time because of the pseudo-inverse term (W − λ p D W ) † in each gradient direction.
We remove this bottleneck by first left-multiplying by ∂E ∂X2 .
We in-troduce Y = −(W − λ 2 D W ) † (X 2 − X * (I)), which we showed how to compute efficiently in [2], and obtain a O(n 2 ) gradient update rule:∂E ∂W ij = X 2,i Y j + X 2,j Y i − λ 2 (X 2,i Y i + X 2,j Y j ) −λ ′ 2ij Y T D W X 2 with λ ′ 2ij = 2X 2,i X 2,j − λ 2 (X 2,i 2 + X 2,j 2 ) X T 2 D W X 2 Empirically, we observe that E(W (t)) converges to 0 exponentially fast when W (t) follows the gradient path, even if the number of training examples grows as O(n).
We will prove this fact in the case of a single target.
The convergence of E(W (t)) however does not imply that of W (t).
Indeed, one can construct functions for which gradient descent leads to limit cycle oscillations.
The following proposition shows that this cannot happen here.
The 1-target energy PDE ˙ W = − ∂E ∂W either converges to a global energy minimum W ∞ , or it escapes any compact K ⊂ S 2,X * n .
In the first case, E(W (t)) → 0 exponentially.Our proof in [2] shows that ∂E ∂W ≥ b √ E, leading to the convergence of W (t), and then d dt E(W (t)) ≤ −b 2 E, which shows the exponential decay of E(W (t)).
Pathological non-convergence cases.
As stated in the proposition, W (t) could potentially hit the boundary of S 2,X * n .
This arises in 2 pathological cases: 1)λ 2 (t) → 1 or λ 2 (t) − λ 3 (t) → 0, and 2) D W (t) (i, i) → 0 for some i. Note that X * (I) T X 2 [W (t)] → 0 can- not happen, because initially X * (I) T X 2 [W (t)] > 0and E(W, I) decreases.
There are ways to alleviate those problems through weight parameterization, but in practice they only occur when learning a lot of target vectors.
In experiment 1, figure 6, we examine our spectral graph learning algorithm on simple 2D point set clustering examples.
The graph weight matrix W ij = exp(−σ x (x i − x j ) 2 ) + exp(−σ y (y i − y j ) 2 )has two parameters σ x , σ y which we aim to optimize.
We update (σ x , σ y ) as follows:∆σ x = −η(X − X * ) T ∂X ∂σ x (4) ∆σ y = −η(X − X * ) T ∂X ∂σ y (5)We use directly the derivatives given in Sec. 3.4 with the following expressions of W ′ :∂w ij ∂σ x = −(x i − x j ) 2 e −σx(xi−xj ) 2 (6) ∂w ij ∂σ y = −(y i − y j ) 2 e −σy(yi−yj ) 2 (7)The experiments on simple clustering show a fast convergence of the gradient descent.
We also tested the algorithm with radial distributed point sets.
In this experiment, we focus on an application of spectral learning in image segmentation.
The aim is to provide a powerful tool to find the best scales of edge extraction in Ncut segmentation [3].
Basically the idea of multiscale segmentation is to use several edge scales find a consistent segmentation of the image across scales.
The simultaneous use of various scale levels is interesting for complex and big images which mixes textures with sharp and soft contours.
In those images, meaningful boundaries may exist at weak contours or between textures that do not rise to edges.
Using simultaneously several scales of edges enable to face this problem.
The global affinity matrix is the sum of r-affinity matrices at different scales: the scales and to set up the weighting coefficients when more than two scales are required.
Learning on σ coefficients enables to find the sensitivity to edge strength at a given scale.W (I) i,j = k r=1 α r exp (−σ r ∆ (r) i,j (I))(The update rules for α r , σ r are as following: Figure 9: The learned shift-invariant graph clique function ¯ f (x 2 − x 1 , y 2 − y 1 , θ 1 , θ 2 ) with θ 1 = 0, and θ 2 = π/2.
Each 2D function corresponds to a fixed (θ 1 , θ 2 ) pair.
The clique function learns to favor good continuation of the edges with (θ 1 = 0, θ 2 = 0), (θ 1 = π/2, θ 2 = π/2), and corner configurations (θ 1 = π/2, θ 2 = 0), (θ 1 = 0, θ 2 = π/2)∆α r = −ηY ( ∂W ∂α r − λ ∂D ∂α r − ∂λ ∂α r D)X (9) ∆σ r = −ηY ( ∂W ∂σ r − λ ∂D ∂σ r − ∂λ ∂σ r D)X (10) We first generate random rectangles in synthetic images of 100 by 100, see Fig. 8.
The edges extracted, e i are specified by its quantized location (x i , y i ), orientation θ i , and polarity p i .
Three graph weight clique potential functions are implemented:1.
unconstrained f (e 1 , e 2 ) = f (x 1 , y 1 , θ 1 , x 2 , y 2 , θ 2 ) 2.
translational invariant f (e 1 , e 2 ) = ¯ f (x 2 − x 1 , y 2 − y 1 , θ 1 , θ 2 )3.
translational invariant with ternary clique potential f (e 1 , e 2 ) = 1N k g(x 1 − x k , y 1 − y k , x 2 − x k , y 2 − y k , θ 1 , θ 2 , θ k ).
We apply the following graph learning algorithms to train segmentation algorithm to detect rectangles.
for each training set and the result displayed in fig.10 have been averaged.
We noticed a very low standard deviation on our training sets.We see that the best results are achieved with the triplet clique method involving summation of ternary affinities over a third node.
With only 20 training examples, an average of 75% of the noise was eliminated in the 2000 testing examples.
We achieved the best result with a training data set of 500 squares.
15 iterations were enough to reach energy convergence and it took 4 minutes.
This fast convergence can be explained by the averaging on a third node: when the affinity between two nodes is updated, all ternary affinities involving this pair are updated in a single pass.
Also, ternary clique potentials carry out a stronger, more robust cue than binary affinities.
This rectangle detection algorithm can be applied directly on real images, fig.12.
We just have to adapt the filter parameters to have a good edge extraction.
The amount of noise on real images turns out to be frequently below the one we used in the learning step, thus giving those encouraging results.
