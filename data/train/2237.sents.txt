The Internet is producing a wealth of data about its own operation, in the form of NetFlow records, routing table entries, traffic statistics, etc.
Several previous works-including, for instance, Clark's "knowledge plane"-have considered the idea of building a giant distributed database that (at least conceptually) contains all of this information.
Such a database could have many attractive uses, including distributed troubleshooting, attack miti-gation, or traffic management.
However, so far the idea has not been realized, and it is likely that privacy concerns have played a role.
In this paper, we ask whether differential privacy could provide the strong privacy guarantees that would be needed to put this idea into practice.
We discuss some key concerns that have been raised about differential privacy , such as its limited scalability and its finite "pri-vacy budget", and we point out several characteristics of the Internet that could mitigate these concerns.
We also sketch the design of PRISM, a system for differentially private queries on NetFlow records that could form the basis of a potential "knowledge plane".
The proposal to create a "knowledge plane" for the Internet has been around for almost a decade -it goes back to a paper by Clark et al. [24] -and the network is producing a wealth of data that could be used for this purpose, e.g., in the form of NetFlow records, routing tables, or data from a variety of active and passive measurement systems [43,44,37].
Numerous papers have shown the advantages of a collaborative analysis, which could rely on a "global view" of the Internet instead of merely data that each network collects locally; also, a variety of potential applications have been suggested, including collaborative network measurement [58,60,59], distributed troubleshooting [17,16], forecasting [9], cooperative intrusion detection [70], botnet analysis [56,10], and many others (e.g., [66]).
However, despite the wealth of data and the many possible applications, such a "knowledge plane" has not yet become a reality.
We postulate that this is, at least in part, due to privacy concerns.
As recent events have shown, seemingly innocent metadata, such as IP addresses, can be used to infer very personal information.
Consider, for instance, the example of Paula Broadwell and former CIA director David Petraeus [64]: even though the two used an anonymous email account to communicate, Broadwell was eventually tracked down by the FBI by correlating the IP addresses she had logged in from with the hotels at which she had been staying.
Other wellpublicized cases, such as the Netflix prize [12] and the AOL search data [11], have demonstrated that even a good-faith effort to protect privacy, e.g., by anonymizing or "scrubbing" data before release, cannot reliably prevent a privacy disaster.
Thus, it is not surprising that ISPs are reluctant to make data available, or sometimes even attempt to deliberately hide information [39,7,25].
In this paper, we ask whether differential privacy [29] could be the enabling technology for an Internet knowledge plane.
Differential privacy is one of the strongest forms of privacy available; it essentially promises to each individual I that, when a query is answered about the data, the answer would have been almost as likely if I's data had not been included.
Thus, differential privacy is very well suited for releasing large trends in the data (such as the high-level traffic flow across a network) while effectively protecting the privacy of individuals.
Most importantly, differential privacy rests on solid mathematical foundations: it can be formally proven that accidental privacy leaks, like the ones experienced by Netflix and AOL, are impossible -even under very pessimistic assumptions.We discuss several common concerns about differential privacy, and we examine whether they would apply to a possible knowledge plane.
For instance, differential privacy is often discussed in terms of a centralized database that contains all the private information (which, in the Internet, would be a privacy nightmare in itself!)
, and it has the concept of a finite "privacy budget" that must be charged for the "privacy cost" of queries and that, once exhausted, prevents further queries forever.
We find that it should be possible to address these concerns: briefly, the centralized database could be replaced by a network of ISP-local databases that answer queries using a distributed cryptographic protocol, and the budget, while certainly finite, is enormous and could probably be replenished slowly over time; thus, it may be possible to keep answering queries indefinitely, without jeopardizing privacy.We also sketch the design of a system called PRISM that enables Private Retrieval of the Internet's Sensitive Metadata.
Unlike its namesake that has received so much media attention [5], PRISM would allow access to data only with very strict differential privacy guarantees.
For concreteness, we discuss PRISM in the context of NetFlow data, but we hypothesize that it could be extended to other types of data that exists on the Internet, such as routing tables or access logs.Differential privacy is not a magic bullet -there are interesting and useful queries that cannot be answered with such strong privacy guarantees.
For instance, we might legitimately want to identify the command node of a botnet, or to obtain a list of nodes that are infected by a particular type of malware.
These queries identify specific individuals, which is the very thing differential privacy is designed to prevent!
However, PRISM does not have to be the only way that queries can be answered -human administrators can still approve and answer any query they wish, just as it is done today.
PRISM would add a way to answer certain "safe" queries automatically, in cases where very strong privacy assurances can be given.
Thus, PRISM could enable ISPs to safely obtain at least some of the potential benefits that have been suggested for a knowledge plane.
In this section, we briefly review the key definitions of differential privacy, and then sketch a possible architecture for the PRISM system.
Differential privacy [29] is a property of randomized queries that take a database as input and return a result that is typically some form of aggregate (e.g., a histogram, or a count of items that have some property of interest).
The database is viewed as a collection of rows, and each row contains data about one individual.
Intuitively, differential privacy promises that each row has only a very small impact on the overall result of the query.
More formally, a query q (with range R) is ε-differentially private if, for all databases B and B that differ in at most one row, and for all possible outputsS ⊆ R, Pr[q(B) ∈ S] ≤ e ε · Pr[q(B ) ∈ S](1)In other words, if we add or remove a single individual's data, the probability that the (randomized) output will fall into some set S can change by at most a factor of e ε .
Here, ε is a privacy parameter; smaller values of ε yield stronger privacy.
If q is a numerical query -say, a count -a common way to achieve differential privacy is to use the Laplace mechanism [30].
Suppose ¯ q is the precise query (without the noise).
Then the Laplace mechanism first computes the precise result ¯ q(B), based on the data in the database B, and then adds noise from a Laplace distribution -i.e., returns q(B) := ¯ q(B)+Lap(λ ).
The parameter λ of the Laplace distribution, which controls the amount of noise that is to be added, depends on the sensitivity of the query: If | ¯ q(B) − ¯ q(B ) | ≤ s for any pair of databases B, B that differ in at most one row, then the sensitivity of ¯ q is s, and the parameter λ is chosen to be λ = s/ε.
When q is a non-numerical query -e.g., one that returns elements from a set, such as AS numbers -the Laplace mechanism is not appropriate.
However, there are other mechanisms that can answer such queries, e.g., the exponential mechanism [48].
In order to serve as a useful "knowledge plane", we would like PRISM to have access to as much data as possible, including sensitive data -such as NetFlow records -that would not normally be available for querying.
At the same time, we insist on strong, provable privacy guarantees for the individuals (the ISPs' customers) whose data is accessed through PRISM.
We obviously cannot prevent ISPs from accessing their own local data, but we can ensure that the sensitive data never leaves the ISP that collected it, except through differentially private queries.
Figure 1 shows a proposed architecture that achieves these goals.
Each ISP operates a local PRISM node that is given unrestricted access to local information; however, the PRISM node (unlike its namesake) only answers queries that it can certify as differentially private, e.g., through static analysis [33].
Only other ISPs are authorized to ask queries, and each PRISM node maintains a "privacy budget" to limit the amount of private information that is revealed as more and more queries are answered over time.
In Section 4, we discuss the privacy budget in more detail.Not all queries can be answered by querying ISPs individually; for instance, to reveal a botnet's command-andcontrol structure, it may be necessary to combine data from several ISPs [56].
PRISM can support queries that join data from multiple ISPs, and it can answer them using a secure, distributed query processing protocol, such as DJoin [52].
Even in this case, private data does not have to leave the network of the ISP that collected it: DJoin uses cryptographic techniques such as private set intersection [45,31] to ensure that only differentially private results can be observed outside of its domain.
We hope that many different types of data will eventually be available through PRISM; however, for concreteness, we focus on NetFlow records for the purposes of this paper.
Cisco's NetFlow [23] and its variants (e.g., Sampled NetFlow [6], IPFIX [15]) provide a wellstandardized solution for collecting flow-level measurements, and they are already widely supported by many vendors [4].
They comprise an important data source both for research [53,41] and for industrial innovations [2,3].
In fact, sharing NetFlow traces has already been proposed [8], but without differential privacy guarantees.In this context, PRISM would provide the abstraction of a global database that contains NetFlow records from the entire Internet.
The "rows" of this database would contain the flows to and from a specific IP address.
(Recall from Section 2.1 that differential privacy protects the privacy of rows.)
While we would ideally like the rows to have all the data that pertain to a specific individual, this seems impractical because there is no way to tell which individual(s) caused a given packet to be sent.
IPs seem like a reasonable approximation.
In other words, PRISM aims to answer queries on NetFlow data without revealing too much about which IPs fit the query criteria.
For concreteness, we now give a few examples of queries that PRISM might support.
Easy queries: The "easiest" queries for PRISM are queries that can be broken into subqueries, such that each subquery can be answered by an individual ISP.
This includes common queries, e.g., counts, that serve as a basis for many advanced analyses [21]: spikes in the number of flows, e.g., may indicate port scanning, flash crowds, etc [40].
A query might ask PRISM to count the number of flows exceeding a certain size, e.g., containing more than 100 packets and lasting for more than 60 seconds [50], because extreme counts may trigger a subsequent DDoS detection.
In an SQL-like syntax, the query could be written as follows:SELECT COUNT(f.id) FROM ISP 1-N WHERE (f.pkts>100 AND f.duration>60)A variety of techniques have been proposed that could answer such queries, including [21,55]; similar techniques are available for querying, e.g., histograms [21] or aggregate time-series [63].
If some of these techniques are included in PRISM, answering queries such as the example above is clearly feasible.Harder queries: If a query cannot be broken into per-ISP subqueries, it is more difficult for PRISM to answer, but by no means impossible.
For instance, a querier might try to trace attack flows back to their source using a sequence of cross-domain joins; thus, we could gain a backtrace capability without a specialized infrastructure for that purpose, such as [42].
For instance, a querier could expose the source ASes of spoofed traffic in the entire Internet by checking whether a flow's source IP address is contained in the ISP it originates from:SELECT f.SrcASN FROM JOIN Internet BY FlowID WHERE (f.SrcIP / ∈ f.OrigISP)Or, we could change the WHERE predicate to obtain the source ASes of all traffic ending in darknets [68]:WHERE (f.DstIP is unallocated)PRISM could rely on DJoin [52] for answering queries like this.
Since the answer in this case is a set and not a number, the Laplace mechanism is not appropriate (noising an AS number does not make sense), but PRISM could use the exponential mechanism [48] instead.
So queries of this type are more difficult (and potentially more computationally expensive) but still seem feasible.Hard queries: There is no doubt that there are some interesting queries that we currently do not know how to answer efficiently.
For instance, we might want to use a "similarity join" query [19], which joins databasesby key similarity instead of exact match.
For example, a similarity join based on the similarity of flow on/off patterns could allow queriers to find correlated Internet flows, which could help to expose stepping stones [71].
Right now, we do not know how to support similarity joins, but, as research progresses, PRISM could be extended with more advanced query processing techniques.
A common concern about differential privacy is that it can only answer a finite number of queries.
In this section, we examine how severe this concern would be in the context of an Internet knowledge plane.
Recall the guarantee from Section 2.1: if an ε-differentially private query is answered for a database that includes data about an individual I, then any bad (or good) outcome for I becomes at most e ε more (or less) likely.
ε is a tunable parameter that controls the strength of the privacy guarantee: smaller values of ε mean more privacy.
[34] also offers an economic interpretation of ε values.Of course, in practice we would like to ask more than one query.
This is possible because differential privacy is compositional: answering two queries that are ε 1 and ε 2 -differentially private, respectively, is no worse than answering a single (ε 1 + ε 2 )-differentially private query [46].
In essence, we can think of the parameter ε as a privacy budget: we negotiate once with the users what setting of ε they feel comfortable with, and we can then answer an arbitrary set of ε i -differentially private queries, as long as∑ i ε i ≤ ε.But what happens if the privacy budget is exhausted?
In this case, PRISM would have to (forever) stop answering queries!
However, we could avoid this undesirable outcome if a) the budget is very large, or b) there is a way to replenish the budget.
We discuss each in turn.
To estimate how many queries PRISM could answer, we use a simple model that was proposed in [52].
Suppose our privacy budget is ε and we would like to answer queries with sensitivity s using the Laplace mechanism, such that the noised answer is within ±E of the true answer with probability c.
Then we can answerN = ε · E −2 · s · ln(1 − c)queries.
The value of ε depends on the users' preferences, but ε = 1 has been suggested in [21,49,47].
Size helps: The first factor that works in favor of PRISM is that the Internet is very big -and differential privacy works best for large amounts of data.
For concreteness, let us assume that PRISM is typically asked counting queries (s = 1) about IP addresses, of which there are 4 · 10 9 .
If a typical true answer is around 4 · 10 7 , and we would like the noisy answer to be within 10% of that with confidence c = 95%, we can ask N = 667, 616 queries -more than half a million!
This is a lot, but, of course, there are also approximately 60,000 ASes, many of which would want to answer queries fairly regularly.
Based on this calculation alone, each AS could only ask ten queries, which seems discouraging.
But there are other factors that work in PRISM's favor.
Sampling helps: Another favorable fact is that, due to the enormous amount of data, it is often necessary to use sampling for scalability.
For instance, the NetFlow functionality is often configured to sample flows or packets in a 1-in-N fashion.
This helps with privacy, too: it is known [36] that, when sampling the data with a factor β (say, 1%), the privacy cost of the queries can also be scaled by β , since the data of each individual contributes to only one in 1/β samples on expectation.
If we assume that NetFlow sampling uses a rate of β = 1%, we can immediately scale the privacy budget by a factor of 1/β = 100 and arrive at 1, 000 queries per AS.
Sampling inevitably introduces imprecision, but estimating the statistics of a larger population with its subsamples is a well-studied topic.If sampling is additionally applied to the NetFlow records themselves, we can further boost ε at the expense of some additional imprecision in the result (see also Section 5.2).
For instance, the US census bureau uses a 1% Public Use Microdata Sample [1].
If we assume that β = 1% is reasonable, we can boost the privacy budget by another factor of 1/β = 100.
(Of course, it must not be revealed which individuals were sampled for which query; in practice, this could be implemented with a secure coin toss and a simple multiparty computation circuit [13].)
With this, we arrive at 6.68 · 10 9 queries, or roughly 100, 000 per AS.
Competition between ISPs helps: Perhaps the biggest opportunity comes from the fact that differential privacy makes very pessimistic assumptions about collusion: once a query is answered, the recipient of the answer shares it with everyone.
This assumption is prudent in some scenarios, but in the Internet, most ISPs are business competitors and have conflicting interests, so it seems unlikely that they would collude on a massive scale.In principle, if responses received by one ISP could never make it to another ISP, we could give each ISP its own privacy budget of six billion queries.
But mistakes happen, computers get hacked, and some ISPs might in-deed collude on a small scale, so this is not entirely realistic.
But even if each ISP eventually shares its responses with several other ISPs, it still seems possible to let each ISP answer several hundred million queries.
Even at 1,000 queries per day, 400 million queries would last more than 1,000 years -far beyond the likely lifetime of PRISM, or even the Internet.
So far, we have assumed that the budget is set once and for all, and can never be replenished.
This is because differential privacy conservatively assumes that all the queries are answered based on the same data; it is designed to protect against a "worst case" in which the entire privacy budget is used to gain information about a single individual.
However, in practice, much of the Internet's metadata is ephemeral: 40% of the /24-blocks are dynamically allocated, with a median re-allocation period of 2.5 hours [18], and most end-to-end Internet routes change within several hours [27].
Since the Internet's old metadata are being constantly replaced by new entries, we expect that its underlying databases will eventually be entirely new.This high level of churn also applies at other levels.
At the flow level, a GEANT router receives roughly 10 5 new flow records per second [26], and this is at a sampling rate of 1/1000.
Previous studies also found that flows expire quickly ( [14] reports that 45% flows expire within two seconds, and 98% within 15 minutes), and that longer flows are more likely to be computer-tocomputer protocols that do not involve end users [54], which are presumably not as sensitive.
At the user level, the IP-to-user mapping also changes over time, as users change ISPs or move to a different workplace.Since PRISM's database is thus likely to be in constant flux, it does not seem unreasonable to replenish the privacy budget once in a while.
Very conservatively, we could replenish the budget once every 100 years, since the database almost certainly contains different individuals by then; based on the above calculations, this would still be enough to answer 10,000 queries per ISP per day, and faster schedules are probably possible.
For practical reasons, we might opt for a much smaller budget that is replenished much more frequently -say, a budget of 1,000 queries, with 100 added each day.
This would limit the damage in case an ISP's PRISM account is compromised and the attacker chooses to burn the entire budget on a single query.
At first glance, it seems that a system like PRISM could only work for a short time, until its privacy budget is exhausted.
However, due to the Internet's enormous size and the low likelihood of massive collusion between ISPs, the budget could last a very long time, possibly decades -and, due to the Internet's high rate of churn, it would probably be safe to replenish it periodically.
Indeed, the numbers are large enough that, even if some of our arguments were dismissed, the rest would still be enough to show that PRISM is feasible.
In this section, we discuss other questions about PRISM and a potential "knowledge plane".
So far, our discussion has focused on the privacy of individuals, which we have taken to mean individual users who connect to the Internet.
However, it is clear that ISPs, too, are concerned about privacy.
For instance, an ISP might be concerned that, if its topology or traffic matrix were revealed, other ISPs might use this information to gain a competitive advantage.
This concern is frequently discussed in papers on active and passive measurement techniques [65,59,60], and there is evidence that at least some ISPs have taken steps to discourage probing, e.g., by ICMP rate limiting [65].
If PRISM does not address these concerns, ISPs may choose to share only data they would publish anyway, or they may even choose not to participate at all.
However, there is a way to enforce ISP privacy in PRISM: it can consider other database schemata in which rows contain the data from entire subnets, PoPs, or even entire ISPs, and then add noise according to the schema that is the most restrictive.
1 It is true that some information could still be learned, e.g., a very rough traffic matrixdifferential privacy is meant to release large trends like this!
However, high-level information like that can often be inferred remotely anyway, as systems like Hubble [38], DisCarte [62], etc., have repeatedly shown.
Indeed, these systems typically yield far more specific data than PRISM ever would.So, on the one hand, PRISM would substantially broaden the range of queries that could be asked, and it might yield data at a higher quality than measurement systems would, since it operates on the true data, without heuristics-based inference or measurement errors.
But, on the other hand, ISPs would gain more explicit control over the information they are sharing (including an option to audit queries that involve their local node, and to block queries that are abusing the system).
Differential privacy inherently returns imprecise results, so it is natural to ask how this imprecision would affect utility.
However, dealing with imprecision is a challenge in almost all quantitative studies.
For instance, there is often too much data to collect, so sampling has to be used, which introduces sampling error; indeed, sampling is a built-in part of NetFlow for that very reason [6].
Other sources of error include "gaps" in the data because of partial deployment or partial visibility, data quality issues, samples from slightly different points in time, etc.
The effects of this imprecision are well understood, and there are excellent statistical tools and techniques that can be used to deal with them, which are standard practice for measurement studies.
In a sense, PRISM's "noise" might even be cleaner than that in many measurements today: PRISM would operate on the true data, so there would be less inaccuracy due to heuristics-based inferences, data quality issues, or assumptions that do not hold everywhere.
Moreover, PRISM's "noise" would be drawn from a well-known distribution, so it would be easier to reason about its impact on the data.
Unlike classical measurement studies, PRISM would return only the final answer (e.g., the average traffic on a given set of links), but not return intermediate results (the traffic on the individual links).
This would make it harder to spot problems with the data.
For instance, if a router is misconfigured and reports Exabits of traffic per second, the overall result will be completely implausible, but there will not be an easy way to identify the problem.One way to address this problem would be to encode the quality-checking in the query itself.
In Section 3.1, we have used a simple SQL-like syntax, but there are far more sophisticated query languages for differentially private data analysis, including higher-order languages [57].
Recall that the query has access to the true, un-noised data while it is being processed, so it can perform plausibility checks and data cleaning internally; if a problem with a particular row of data is too severe, the query might return a default value for that row.
To assess the quality of the data, a second query could be issued to count the number of problematic rows.Since PRISM would be operated by ISPs, intentional tampering with the results does not seem very likely.
Nevertheless, we note that there are ways to address this if it should become an issue, e.g., by (privately) enforcing upper and lower bounds on the data each ISP can return, analogous to PDDP [21].
Another possibility would be to enforce differential privacy in a verifiable manner, similar with VerDP [51].
In principle, PRISM could be used to run queries across the entire Internet; however, we expect that, in practice, many queries will involve only a small number of ISPs.
For example, [22] says that results from four domains are sufficient to detect DDoS with 98% accuracy; another study [16] only used data from a network's 17 customers.Whether a query can scale depends on the operators it contains.
If a query can be broken into per-ISP subqueries, the subqueries can be processed in parallel, and the final aggregation step is fairly easy.
If joins are involved, more expensive cryptographic techniques like private set intersection [31,52] will probably need to be used, and these do not yet scale too well.
However, this is an active and fairly young field of research, so PRISM could benefit from new discoveries over time.
For example, SEPIA [45] was able to intersect sets from 25 players with one million elements in slightly more than 1 minute; this seems like a practical scale for at least some queries.
Like many other systems, PRISM would initially face a chicken-and-egg problem because its utility depends in part on the amount of data that is available for querying.
Nevertheless, the situation is not as dire as, e.g., in S-BGP: even a small deployment of two or three large ISPs could initially be useful, e.g., to privately find ways to optimize traffic between them, or to privately track down attacks.
Other ISPs would have an incentive to join because this would give them the ability to ask queries of their own.Despite all this, it would be na¨ıvena¨ıve to expect a full deployment, or that all PRISM nodes are always available.
This should not be a problem for most queries, however: if a query is limited to a moderate set of ASes, it can be answered by the PRISM nodes in these ASes, without involving the others; sampling-based queries could be run using samples from other ISPs that are currently available.
Global queries, or queries that require a truly unbiased sample, could be processed in stages.Some queries might return a biased answer if they are answered based on data from a subset of ISPs.
However, working with partial data is a familiar problem for many administrators (e.g., from working with Internet looking glasses) and researchers doing measurement studies.
Moreover, the set of ISPs that operate PRISM nodes could probably be made public, just as the set of RouteViews nodes and looking glasses is public; this should help with query design.
Analyzing the Internet's sensitive metadata with privacy guarantees has been used for distributed troubleshooting [17,16], measurement [58,60,59,28], forecasting [9], route computation [32], and private alerts correlation [70].
There has also been initial attempts to apply differential privacy [29] -the strongest privacy modelto centralized [51,47,46] and distributed [52,21] data sources.
Our work puts differential privacy in the context of forming an Internet knowledge plane, and explores a common concern whether differential privacy's limited budget restricts its practicality [33,56,21,20].
Creating a "knowledge plane" for the Internet is a longstanding proposal [24].
Many existing papers advance this goal by, e.g., measuring [43,44] or predicting [44] Internet performance, developing an Internetscale query processor [35], a scalable distributed information management system [69], a framework for Internet forensics [61], or a declarative programming environment [67].
In contrast, our work focuses less on a concrete design and more on providing strong privacy guarantees, which would be important for any practical knowledge plane.
We have made a case for differential privacy to be a potential basis for realizing the long-standing vision of a "knowledge plane" for the Internet.
We have sketched the design of a system called PRISM that could serve as the foundation of such a knowledge plane; and we have especially focused on a common concern of differential privacy's limited budget.
PRISM may not be able to support all queries we might like to ask, but it would certainly be able to answer a wide range of queries -completely automatically and, unlike its namesake, with one of the strongest privacy guarantees available today.
Although we have mainly used NetFlow records as examples, the idea of PRISM should be generalizable to other types of network data, too.
