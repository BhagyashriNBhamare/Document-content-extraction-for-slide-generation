In this paper, we present a patch-based variational Bayesian framework of image processing using the language of factor graphs (FGs).
The variable and factor nodes of FGs represent image patches and their clustering relationship respectively.
Unlike previous probabilistic graphical models, we model the structure of FGs by a latent variable, which gives the name "stochastic factor graphs"(SFGs).
A sparsity-based prior is enforced to the local distribution functions at factor nodes, which leads to a class of variational expectation-maximization (VEM) algorithms on SFGs.
VEM algorithms allow us to infer graph structure along with the target of inference from the observation data.
This new framework can systematically exploit nonlocal dependency in natural images as justified by the experimental results in image denoising and inpainting applications.
To overcome the curse of dimensionality, it is often convenient to make the Markovian assumption that the probability structure of images can be defined locally.
Such assumption is at the foundation of both classical Markov random field (MRF) models (refer to recent high-order extension [1]) and popular transform-domain models (e.g., [2], [3]).
However, important image structures such as edges and textures are often characterized by self-similarity that is beyond the reach of local models.
In recent years, a flurry of socalled patch-based image models have been proposed to exploit the nonlocal dependency in natural images and found several successful applications in texture synthesis [4], super-resolution [5], image inpainting [6] and image denoising [7], [8], [9].
In this paper, we attempt to set patch-based image processing on a rigorous ground using the language of factor graphs (FGs).
Specifically, patches generated by translational operators correspond to variable nodes V and the clustering relationship among patches is characterized by a collection of factor nodes F (refer to Fig. 1a).
When compared with the classical MRFs (in which edge connectivity is defined by location-related geometric proximity), the structure of FG in this work is recursively defined by intensityrelated structural similarity, which dictates its stochastic nature.
Therefore, given observation data y (e.g., noisy or incomplete images), we have to estimate the latent variable defining graph structure T : V → F along with the target of inference x (e.g., clean and complete images).
A variational EM (VEM)-based technique [10] is developed to support efficient inference on the proposed SFG, which iteratively updates the estimate of x and T.URL: http : //www.csee.wvu.edu/ ∼ xinl/demo/sf g.htmlUnder the SFG-based framework, it becomes easier to compare and unify different patch-based image processing algorithms.
Various image prior models have been proposed for p(x|T) -e.g., from parametric Gaussian distributions [5], [8] to nonparametric models [4], [6] and most recent sparsity-based transform-domain models [3], [9].
The discovery of graph structure (i.e., update T) can be implemented by k-nearest-neighbor (kNN) finding or k-means clustering (many more powerful tools can be borrowed from the literature of data clustering).
Even though the theoretic convergence of iterative VEM algorithm remains elusive, we have found through experiments that it has promising performance in several image recovery applications including denoising and inpainting.
A FG is a bipartite graph G = (V + F, T) that expresses the dependency structure among variable nodes V = {Bm} M m=1 by a collection of factor nodes F = {fn} N n=1 .
For notational simplicity, we use a mapping function T : F → V to denote the edge (graph structure) information.
At node fn, we use |fn| to denote its degree -i.e., the total number of variable nodes it is connected to.
Throughout this paper, we use x, B, x to denote a single pixel, a patch of fixed size B × B and the whole image respectively.
Given an image x sized H × W , we simply put all patches generated by translation into V (with maximum overlap and boundary extension, we have M = HW ).
The primary motivation for representing images by FGs is due to their capability of decomposing a high-dimensional pdf f (x) into the product of local functions at factor nodesf (x) = 񮽙 n fn(Dn)(1)where Dn denotes the collection of variable nodes connected to a common factor node fn and fn(Dn) is the local pdf 1 .
The key challenge lies in the definition of edge connectivity at factor nodes (i.e., the graph structure T).
Conventional MRF models connect patches that are geometrically adjacent to each other (and hence characterize local dependencies only).
However, important structures such as edges and textures are often characterized by nonlocal, self-similar dependency that is beyond the reach of local models.
Fig. 1b gives a specific example of how nonlocal dependency looks like -all patches connected to the same factor node are structurally similar (e.g., small Euclidean distance or large pearson product-moment correlation) but are spatially distant from each other.
The power of FGs largely depends on the choice of local pdf fn(Dn)'s as well as the graph structure |T|.
There are several choices for local pdfs.
For instance, one might impose parametric models -e.g., Gaussian distributions such as N ( 񮽙 mx, Cx) have been adopted by learning-based approach [5].
An alternative approach is through Least-Square regression [11] which models B0 as the linear combination of B1, ..., B k .
It is also possible to obtain the local pdfs by sparse representations in the transform domain [3], [9].
Specifically, one can normalize-and-sort (for the purpose of maximizing the sparsity) the patches linked by the same factor node to form a data array D -i.e., D = [B0, B1, ..., B k ] (this array can be 2D if we reshape patches into vectors or 3D if we simply pack 2D patches together).
Conceptually similar to existing transform-based models, we can characterize transform coefficients S = T D by the distribution of exponential families, which essentially translates the a priori information into the sparsity constraint of Sf (x) ≈ exp(− 񮽙 n ||Sn||) (2)where ||Sn|| denotes the norm of data array (e.g., L1 implies a Laplacian distribution).
The structure of FGs is largely determined by its capacity N = |F| and degree distribution {|fn|} N n=1 .
The capacity of a FG can be understood from an associative memory perspective [12] each factor node stores a novel relationship among variable nodes.
When N → 0, FG model can only describe the class of images that are strongly self-similar (showing little positional differentiation).
To handle complex structures, it is desirable to have N → ∞ even though some factor nodes might be empty (left for learning new association rules).
We note that such theoretic prediction is supported by the empirical findings of visual cortex in human vision system (HVS) -its capacity measured by the number of neurons dramatically increases as the visual pathway reaches higher level of cortexes.
The degree distribution more directly affects the structure of FG and reflects our a priori knowledge of image structures.
Image structures of strong self-similarity (e.g., regular textures and edges) tend to give high-connectivity node |fn| >> 1; while structures of weak self-similarity (e.g., irregular textures) often produce low connectivity |fn| ≈ 1.
The framework of SFG-based modeling is useful to unify and compare various image processing algorithms built upon different models.
For example, conventional MRFs and their high-order extensions (e.g, Field-of-Expert [1]) can be viewed as FG with pre-fixed graph structure in which only spatially adjacent patches are connected to a common factor node.
Image recovery under overcomplete expansions (wavelet [2] or DCT [3]) can also be interpreted as special cases of fixed FGs with M ≥ HW and |fn| = 1 (i.e., FGs degenerate into local models).
Texture synthesis by nonparametric resampling [4] and its related exemplar-based inpainting [6] associate a patch and its nearest neighbor in the patch space (i.e., |fn| = 2, ∀n).
Inclusion of k-nearest-neighbors (kNN) in learning-based approach [5] and nonlocal-mean denoising [7] give rise to |fn| >> 1.
Current state-of-the-art image denoising algorithm BM3D [9] can be interpreted as using a FG with factor nodes located at a down-sampled lattice (e.g., N = M/16 when down-sampling ratio is 4) and generated by a variant of kNN search (it also involves a one-time update of graph structure T).
Sparsity-based prior function defined by Eq.
(2) is generic but depends on the graph structure T.
In various image processing tasks, T is often unknown and has to be estimated along with x (target of inference) from the noisy or incomplete observation y.
A fully Bayesian treatment of the latent variable T is to marginalize it out byp(x|y) = 񮽙 p(x, T|y)dT = 񮽙 p(x|T, y)p(T|y)dT.
(3)However, such approach involves the calculation of posterior probability p(T|y), which is computationally intractable.
A compromised solution is via Laplacian approximation, namelyp(x|y) ≈ p(x|y, T * )(4)where T * = arg max T p(y|T) is a maximum-likelihood estimate (assuming a uniform prior p(T)).
Although it is possible (at least theoretically) to evaluate the likelihood term at various T values by Monte-Carlo methods, the computational cost is prohibitive.
The basic idea behind variational approaches [10] is to approximate the likelihood function p(y|T) by a lower bound F(q(x), T) that is easier to calculate in practice (e.g., q(x) = f (x) can be obtained by mean field approximation).
Specifically, we can intoL(T) = lnp(y|T) = ln p(x, y|T) p(x|y, T) = 񮽙 dxq(x) ln p(x, y|T)q(x) p(x|y, T)q(x) = 񮽙 dxq(x) ln p(x, y|T) q(x) + 񮽙 dxq(x) ln q(x) p(x|y, T) = F (q(x), T) + KL[q(x)||p(x|y, T)] ≥ F(q(x), T)(5)where F (q(x), T) is the negative to a well-known quantity in statistical physics as f ree energy and KL[q||p] ≥ 0 denotes the Kullback-Leibler divergence.
Under such formulation, the ML estimation of T can be obtained by a variational expectationmaximization (VEM) algorithm which iteratively maximizes the lower bound F(q(x), T) or minimizes the free energy (parenthesized superscript t = 1, ..., tmax denotes the iteration number)• E-step:x (t+1) ← arg max x F (q(x), T (t) ), • M-step: T (t+1) ← arg max T F(q (t+1) (x), T).
Loosely speaking, E-step and M-step respectively refine the estimate of inference target x and graph structure T. Note that detailed implementation of VEM algorithm depends on the observation model which varies from application to application (we will consider two examples next).
In this section, we take two concrete examples to elaborate on the implementation details of VEM algorithm: image denoising (y is a noisy version of x) and image recovery (y is an incomplete version of x).
In both cases, we compare this work with previous benchmark schemes on three classes of images with decreasing amount of self-similarity: regular textures, regular edges and irregular textures (refer to Fig. 2).
In addition to MSE-based fidelity measures, we also report SSIM performance [13] which has shown to better reflect the structural similarities between two images.
The main objective is to validate the hypothesis that SFG-based models are capable of characterizing a wide range of structures in natural images.
We first study the classical image denoising problem: y = x + w where w ∼ N (0, σ 2 w ).
Depending on the formulation of local pdf at factor nodes, the E-step (updating of x based on T) can be implemented by linear/nonlinear filters in the spatial domain (e.g., nonlocal mean [7] and its extension [8]) or in the transform domain (e.g., DCT [3], [14]).
We have adopted a Wiener filtering implementation in 2D-DCT domain (i.e., we treat each patch as a row vector).
The implementation of M-step is also flexible: we have opted to apply a fast kmeans algorithm [15] while other choices (e.g., kNN search) also exist.
The parameters of VEM algorithm in our experiments are fixed: B = 7, N = 100, tmax = 20 (they have not been optimized).
MATLAB codes of SFG-based denoising can be accessed at http://www.csee.wvu.
edu/ ∼ xinl/demo/sfg.html.
Tables I and II include the PSNR and SSIM performance comparison between our SFG denoising and five benchmark schemes: Shape-adaptive DCT [14], Gaussian-Scalar-Mixture [2], Field-ofExpert [1], Block-matching 3D [9] and Total-Least-Square [11].
It can be observed that even without any optimization, ours has achieved comparable performance to state-of-the-art denoising scheme BM3D.
Since patch-based schemes (BM3D, TLS and SFG) are capable of exploiting nonlocal dependency in an image, they have achieved noticeably better performance than those based on local models (especially for the class of regular textures).
Fig.
3 includes the comparison of denoised images among different schemes.
The readers are referred to the above website for direct visual inspection.
In our second experiment, we study the application of VEM algorithm into image inpainting -i.e., the recovery of missing pixels in an image.
In inpainting scenario, likelihood term p(y|x) is a simply binary indicator function 1 x∈Ω c I where ΩI denotes the inpainting domain.
Unlike denoising, the E-step is implemented by a hard thresholding operator (motivated by the recent work [3], we obtain an approximately fixed-point solution by gradually decreasing the threshold).
The implementation of M-step is based on kNN search (i.e., |fn| = k +1).
Three parameters (patch size B, neighborhood size k and graph size N ) can be adjusted by the user.
Different parameter settings are adopted for three classes of images respectively.
More details can be found from the accompanying source codes available from the above link.
The five benchmark schemes in our inpainting experiments include: overcomplete DCT-based scheme [3], Field-of-Expert [1], exemplar-based method [6], BM3D-based (our own extension of [9] into inpainting) and Least-Square Prediction scheme.
Tables III and IV include the PSNR and SSIM performance comparison between our SFG-based inpainting and five benchmark schemes.
Note that both objective metrics are calculated for pixels within the inpainting domain only, which explains low PSNR/SSIM values when inpainting technique fails.
Again it can be observed that overall SFG-based inpainting achieves the best performance.
Local models become more competent for images of irregular textures.
Fig. 4 includes the comparison of inpainted images by different schemes.
We observe again that local models are often inferior to nonlocal ones for regular textures and edges.
For irregular textures, visual quality comparison becomes more tricky and even SSIM metric appears to become less effective (e.g., for test5, FoE gives the second best SSIM performance though its subjective quality appears the worst).
Patch-based image representations using the language of FGs provide a promising framework for unifying existing image models.
The degree distribution of FGs carries useful information about the tradeoff between local and nonlocal dependencies of the source.
Variational techniques, powered by sparsity-based priors, can offer computationally feasible solutions to difficult inference problems.
Under this new framework, it is desirable to explore more sophisticated strategies of constructing FGs (e.g., M > HW if rotational and reflection operators are included).
It is also possible to further improve the performance of VEM algorithm by more powerful data clustering and adaptive choosing of model parameters.
SFGbased models have intriguing connection to self-organization and associative memory [12].
In the long run, we believe it is important to combine the strengths of local and nonlocal models using a fully (yet empirical) Bayesian approach which has been elegantly solved by HVS through the process of evolution.
