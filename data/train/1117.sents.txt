We consider the problems of predicting, classifying, and annotating friends relations in friends networks, based upon network structure and user profile data.
First, we document a data model for the blog service LiveJournal, and define a set of machine learning problems such as predicting existing links and estimating inter-pair distance.
Next, we explain how the problem of classifying a user pair in a social network, as directly connected or not, poses the problem of selecting and constructing relevant features.
We document feature analyzers for attributes that depend only on graph attributes, those that depend on individual user demographics and set-valued attributes (e.g., interests, communities, and educational institutions), and those that depend on candidate user pairs.
We then extend our data model using whole-network attributes and report machine learning experiments on learning the concept of a connected pair of friends from LiveJournal data.
Finally, we develop a theory of dependent types for deriving causal explanations and discuss how this can be used to scale statistical relational learning up to our full corpus, a recent crawl of over a million records from LiveJournal.
Analysis of friends networks provides a basis for understanding the web of influence [Ko01] in social media.
In particular, the problems of determining the existence of links and of classifying and annotating known links are first steps toward identifying potential relationships.
This inferred information can in turn be used to introduce new potential friends to one another, make basic recommendations such as community recruits or moderator candidates, or identify whole cliques and communities.In this paper, we consider the problem of discovering links in an incomplete graph.
We present an approach to link prediction that is based on graph feature analysis and intrinsic attributes of entities (users and communities).
We report some promising preliminary results on radius-limited neighborhoods of the blogging service LiveJournal and discuss the results of exploratory experiments that point toward a need to differentiate the types of features in a friends network, namely:1.
those that depend on the demographics of the entire network 2.
those that are computable for each user or each pair of user 3.
those that depend on the existence of a reported, inferred, or suspected linkWe derive some such features and discuss the costs of computing, selecting, and recombining them.
Of particular interest in the domain of commercial weblogs and social media are demographic features relevant to collaborative recommendation of goods and formation of branding communities.
The structural dependence and context-specific dependence of features determines what new features are feasible to construct, both in terms of statistical sufficiency and computational complexity.In conclusion, we examine some new features that were derived by hand, discuss the algorithms used to compute them, and relate these specific algorithms to a broader class of relational database queries that form the basis of a more powerful feature construction system.
Social network services such as MySpace and Facebook allow users to list interests and link to friends, sometimes annotating these links by designating trust levels or qualitative ratings for selected friends.
Some such services, such as Google's Orkut, are community-centric; others, such as the video blogging service YouTube and the photo service Flickr, emphasize social media; while some, such as Six Apart's LiveJournal and Vox, are organized around text-and-image weblogs.
LiveJournal and its derivative services, such as GreatestJournal, DeadJournal, and JournalFen, are based on the same open-source server code.
At the time of this writing, there are over 11.7 million LiveJournal accounts, 1.8 million of them active.The friends network of LiveJournal, our topic of study, has two varieties of accounts: users and communities (we omit RSS feeds).
One advantageous property of its data model, stemming from a common schema for the two account types (which could originally be converted from user to community), is that it provides a simple, flexible representation for entities and relations.
Table 1 shows the types of links in LiveJournal and their constituent attributes.
Friendship is an asymmetric relation between two accounts, each represented by a vertex in a directed graph.
The type of the start and endpoint defines the relationship set attributes of the link.
For example, a user u who adds another user v to his or her friends list can specify the membership in any of up to 30 groups.
These serve the dual purpose of blog aggregation (posts from each group's members are filtered into its aggregator page, which u can read or make public) and groupsbased security (each group denotes a read/comment access control list).
Access control lists for communities are associated with memberships (community-to-user links), while content is controlled by posters or subscribers.
A user can "watch" a community in order to add all accessible posts to a main aggregator page or to custom groups.
The set of accessible posts consists of either public posts only, or public and restricted (members-only) posts.
The access control list is defined by the membership relation and individual posters' selections (whether to allow comments and whether to display them by default from no readers, all readers, non-anonymous readers, or community members).
Acquisition of privileges is a community property, of which only membership may be acquired solely by user action ("joining" a community), if the moderator has specified open membership.
Figure 1.
LiveJournal access control list maintenance (community moderator interface).
Thus, a reciprocal link between a user and a community means that the user both subscribes to the community and is an approved member.
Links from user u to v are listed in the "Friends" list of u and in an optionally displayed "Friends Of" list of v.
This list can be partitioned into reciprocal and non-reciprocal sublists for a user u: Mutual Friends: { v | (v, u) ∈ E ∧ (u, v) ∈ E } Also Friend Of: { v | (v, u) ∈ E ∧ (u, v) ∉ E }The community analogue of the "Friends Of" list is the "Watched By" (subscriber) list, whose members have the community name listed in the "Friends: Communities" sections of their individual user profile pages.
The community analogue of the "Friends" list is the "Members" list.The friends network for LiveJournal consists of a very large central connected component and many small islands, most of which are singleton users.
There are a few source vertices, corresponding to accounts that link to others but have no reciprocated friendships; these are usually RSS or blog aggregator accounts owned by individuals.
Additionally, there are sink vertices corresponding to accounts watched by others, but which have named no friends.
Some of these are channels for announcement or dissemination of creative work.
In previous work [HKP+06], we introduced a link prediction problem for LiveJournal: given a graph in which the existence of a candidate link is hidden (elided if it exists), classify it as present or absent given all other attributes of the graph and of the endpoints.
Our initial approach to link identification consisted of dividing friends network features into graph features and interestbased features.
The degree attributes can be enumerated in time linear in the number of users, as can the mutual friends count for each pair of users.Forward deleted distance measures the distance from u to v by alternate routes, after the edge (u, v) is elided.
The prediction task is thus to reconstruct the incomplete graph resulting from this erasure, to determine whether a particular link (u, v) existed.
Forward deleted distance can be precomputed exhaustively for the entire graph in Θ(|E| (|V| + |E|)) = Θ(|E| 2 ) time by erasing each edge in E and re-running a breadth-first search from the start vertex.
If a candidate edge is not stored in the resulting cache, its deleted distance is that found by BFS on the original graph, in Θ(|V| + |E|) time.
In a graph (V, E), backward distance requires Θ(|V| + |E|) using BFS for a particular candidate edge.
Since the expected size of the edge set is E[|E|] = k|V|, about k = 20 on average across LiveJournal, the bottleneck computation is that of forward deleted distance: Θ(|E|2) = Θ(k 2 |V| 2 ), or Θ(|V| 2 ) with a large constant.Using a straightforward string pair enumeration and comparison algorithm, the mutual interest counts are stored in matrix of |V|2 elements, each requiring constant time to check (given a maximum of 150 interests).
previous work [HKP+06], we introduced a link prediction problem for LiveJournal: given a graph in which the existence of a candidate link is hidden (elided if it exists), classify it as present or absent given all other attributes of the graph and of the endpoints.
Our initial approach to link identification consisted of dividing friends network features into graph features and interest-based features.
Getoor and Diehl [GD05] recently surveyed techniques for link mining, focusing on statistical relational learning approaches and emphasizing graphical models representations of link structure.
Ketkar et al. [KHC05] compare data mining techniques over graph-based representations of links to first-order and relational representations and learning techniques that are based upon inductive logic programming (ILP).
Sarkar and Moore [SM05] extend the analysis of social networks into the temporal dimension by modeling change in link structure across discrete time steps, using latent space models and multidimensional scaling.
One of the challenges in collecting time series data from LiveJournal is the slow rate of data acquisition, just as spatial annotation data (such as that found in LJ maps and the "plot your friends on a map meme) is relatively incomplete.
There have been numerous recent applications of social network mining based on the text and headers of e-mail.
One notable research project by McCallum et al. [MCW05] uses the Enron email corpus and infers roles and topic categories based on link analysis A primary goal of this work is to extend the graph mining approach beyond link prediction and recommendation towards link explanation and annotation.
It may be much more useful to explain why a group of friends in a blog service created accounts en masse or added one another as friends than to recommend relationship sets that are already extant or structured according to a preexistent social group.
For example, high school classmates often create accounts and encourage their peers to join the same service.
In a few cases, this is encouraged or facilitated by a teacher, for a class project.
Solving the problem of link prediction is not particularly useful in this case, because the user decisions have already been made or strongly constrained; however, it may be very useful to link other classmates not working on the same project to the same relationship set (perhaps they were encouraged to join the blog service by students who continued to use it after the class project).
Large groups such as web comic subscriberships, community comembers, etc. are also somewhat identifiable, and relating members of a blog service to one another through relationship sets is a typical entity-relational data modeling operation that can be made more robust and efficient through graph feature extraction.
To acquire the graph structure and attributes describe in the previous section, we developed an HTTP-based spider called LJCrawler to harvest user information from LiveJournal A multithreaded version of this program, which retrieves BML data published by Denga (the owners of LiveJournal), collects an average of up to 15 records per second, traversing the social network depth-first and archiving the results in a master index file.
Because LiveJournal's functionality for looking up users by user number is only available to administrators, we decided to compile a list of seeds for a disjoint-set representation of the disconnected social network.
For purposes of this experiment, however, starting from just one seed (the first author's LiveJournal ID) and restricting the crawl to one connected component was sufficient.Using LJCrawler, we compiled an adjacency list and the following ground features for each user:• We define a single example to be a candidate edge (u, v) in the underlying directed graph of the social network, along with a set of descriptive features calculated from the annotated graph recorded by LJCrawler:Other features: Additional planned features for continuing experiments include dates (update frequencies when taken differentially), user options such as maximum friends count, and content descriptors of LiveJournal entries and comments (average post length, word frequency, etc.).
Computing the minimum forward and backward distances can be done more efficiently by using breadth-first search.
Currently, a Java implementation of this algorithm requires under one minute on a 2GHz AMD Opteron system to process a 2000-node graph.
However, enumerating all possible candidate pairs within a neighborhood of 2 nodes (1.6 million pairs for 4000 nodes) requires several hours on the same system.We note that the amortized cost of running BFS to precompute all-pairs shortest paths (APSP) with the actual edge deleted (which is necessary to avoid knowing the prediction target in link predicton) is Θ(|E| (|V| + |E|)).
This is prohibitively large even for our "mid-sized" subgraphs of 10-50K nodes; when |V| is about 11 million, |E| is a little over 200 million, enumerating APSP is completely infeasible.
However, we do not typically consider all of E, so the bottleneck is typically the first step plus a constant number of calls to BFS, requiring running time in Θ(k (|V| + |E|)).
We considered several alternative ways to generate candidate edges (u, v):The first technique is likely to be unscalable, as the number of candidates is |V| 2 .
The second requires having a representatively large sample of the full LiveJournal social network, in order to fit the distribution parameters accurately.
The third was the most straightforward to implement.
Two calls to the all pairs shortest path algorithm provided cost matrix, and one pass at each radius up to a maximum of 10 yielded the data shown in Table 2.
To simplify the initial experiments, we defined the classification problem to be classification of d(u, v) as 1 or 2.
This task is actually useful for social network recommender systems because discrimination of a direct friend from a "friend of a friend" (FOAF) is functionally similar to recommending FOAFs to link to directly.
There are more detailed classification targets, such as placement, promotion, and demotion of linked friends within strata of trust (setting, increasing, and decreasing the security level), but choosing a user's friends to begin with is the more fundamental decision.
Table 2 and Table 3 report the distribution of inter-vertex distances in the friends network for two subnetworks induced by limiting the maximum number of nodes.
In a preliminary experiment, we constructed a 941-node subgraph, defining the concept IsFriendOf and trained three types of inducers with:1.
all attributes 2.
all graph attributes excluding the forward and backward distances 3.
the backward distances alone 4.
the backward and forward distances alone 5.
interest-related attributes alone.
Table 4 and Table 5 show the results for three inducers: the J48 decision tree inducer, Holte's 1R inducer (a single-rule classifier based on a single attribute) [Ho93], and the Logistic regression inducer.
All accuracy measures were collected over 10-fold cross-validated runs.
The J48 output wth all features achieves a significant boost over the next highest (distance only).
We developed an application, ljclipper, to restrict the overall friends graph to that induced by a subset of nodes of fixed number, found using breadth-first search starting from a given seed.
Using a 4000-node subgraph summarized in Table 3, we generated 1633185 candidate edges.
Note that all forward distances are greater than 1: when u and v are actually connected, we erase (u, v).
In preliminary experiments, we then computed the length of the shortest alternative path.
This is, however, a less scalable approach, because the asymptotic running time is dominated by the superlinear time required to computeThe complete listing of all twelve features is given in Section 2.2.
The numerical types of all of the network features -both the ones describing the graph and those measuring and interests and ratios -makes data set amenable to logistic regression.
Table 8 show the accuracy, precision, and recall for the 1000,2000, and 4000-node friends graphs.
Trends of higher precision than recall, and diminishing precision and recall as the network grows larger, are observed.
These trends are sustained for subsamples of size 10000 and size 100000, though precision and recall also diminish slightly with sampling.
The crawler has been improved with several service-specific optimizations for fetching user info pages.
Presently these do not use LiveJournal's BML feed of user data, which is incomplete for our purposes (that is, not all ground attributes in our initial relations are provided).
At press time, this crawler processes about 20000 user records per hour and thus would require over a week to crawl LiveJournal.The current bottleneck is the Θ(|V| (|V| + |E|)) step described in Section 3.3.
This is the dominant term, because the constant k denoting the number of candidate edges is usually much smaller than n, e.g., 100-1000, so that Θ(k (|V| + |E|)) is not only in Θ (|V| + |E|), but actually just a few hundred times the cost of a single BFS.
Using mutual interests alone, even with normalization based on the number of interests in u and v, results in very poor prediction accuracy using all inducers with which we experimented.Intermediate results are achieved using mutual friends count and degree (NoDist: 65.7% on predicting edges) and using forward deleted distance and backward distance (Dist: 67.7%).
Using all 12 computed graph and annotation features resulted in the highest precision (All: 89.5%) and accuracy (All: 98.2%).
We note that LiveJournal once used a variant of normalized mutual interests to produce a list of potential friends, arranged in decreasing order of match quality.
Although this was not the same type of recommender system as LJMiner supports, it shows that the state of the art user matching systems have a lot of room for improvement.
The results indicate that features produced by LJMiner, used with a good inducer, can generate collaborative and structural recommendations.
Scaling up: Our current research focuses on scaling up to tens of thousands and eventually millions of users.
Crawling over 11-12 million records is at least technically feasible, but scaling up the graph analyzers is a challenge that may best be met with heuristic search.Learning relational models: A promising area of research is the recovery of relational graphical models, including class-level (membership and reference slot) uncertainty.
[GFKT02] LJMiner has yielded a ready source of semistructured data for both structure learning and distribution learning.
Another potentially useful approach is to organize users and communities into clusters using this relational model.
We have developed schemas for blog posts (entries, threads, comments) and for users and dynamic groups of users.
This is related to previous preliminary work on relational data mining for personalization of web portals, especially computational grid portals.
[HBJ03].
Much of the relational metadata in the bioinformatics domain comes from description languages for workflows and workflow components [Hs04].
The next step in our experimental plan is to use schemas such as our detailed ones for blog sevice users and bioinformatics information and computational grid users [Hs05] to learn a richer predictive model.
Finally, modeling relational data as it persists or changes across time is an important challenge.
We thank Todd Easton and Kirsten Hildrum for helpful discussions concerning algorithms and the LiveJournal data model.
We also thank Andrew King and Tejaswi Pydimarri for contributions to the original LJMiner system and Vikas Bahirwani for contributions to the second version.
