We show attacks on several cryptographic schemes that have recently been proposed for achieving various security goals in sensor networks.
Roughly speaking, these schemes all use "perturbation polynomials" to add "noise" to polynomial-based systems that offer information-theoretic security, in an attempt to increase the resilience threshold while maintaining efficiency.
We show that the heuristic security arguments given for these modified schemes do not hold, and that they can be completely broken once we allow even a slight extension of the parameters beyond those achieved by the underlying information-theoretic schemes.
Our attacks apply to the key predistribution scheme of Zhang et al. (MobiHoc 2007), the access-control schemes of Subramanian et al. (PerCom 2007), and the authentication schemes of Zhang et al. (INFOCOM 2008).
Implementing standard security mechanisms in sensor networks is often challenging due to the constrained nature of sensor nodes: they have limited battery life, relatively low computational power, and limited memory.
As such, a significant body of research has focused on the design of special-purpose, highly efficient cryptographic schemes for sensor network applications.Here, we examine an approach based on "perturbation polynomials" that has been used to construct several recent schemes [7,5,6].
This approach, initiated by Zhang, Tran, Zhu, and Cao [7] and Subramanian, Yang, and Zhang [5], takes a polynomial-based scheme that offers informationtheoretic (i.e., perfect) security for some "resilience parameter" t -e.g., a bound on the number of compromised nodes or the number of messages authenticated -and then modifies this underlying scheme so that the resilience is supposedly increased against a computationally bounded attacker.
The common idea is to add a small amount of "noise" to the low-degree polynomials used in the original scheme; the claim is that the presence of this noise makes breaking the scheme infeasible even in regimes well beyond the original resilience parameter.
Unfortunately, we show here that this naive view is unfounded.We describe efficient attacks against the schemes from [7,5,6], demonstrating that these scheme do not offer any better resilience than the original, information-theoretic schemes on which they are based.
We provide theoretical justification as to why our attacks work, as well as experimental evidence that convincingly illustrates their effectiveness.
Our results cast strong doubt on the viability of the "perturbation polynomials" approach for the design of secure cryptographic schemes.
We focus the bulk of our attention on the initial paper of Zhang et al. [7], which concerns key predistribution in sensor networks.
A description of their scheme, and details of our attack, are given in Section 2.
In Section 3 we show how to apply our attack to a set of message authentication schemes suggested by Zhang et al. [6], and in Section 4 we show the same for a system for secure data storage/retrieval proposed by Subramanian et al. [5].
2 The Key Predistribution Scheme of Zhang et al.
Schemes for key predistribution enable nodes in a large network to agree on pairwise secret keys.
Before deployment, a central authority loads some secret information s i onto each node i, for i ∈ {1, . . . , N } (where N is the network size).
Later, any two nodes i and j can agree on a shared key k i,j of length κ using their respective secret information.
(Probabilistic schemes, where two nodes are only able to compute a shared key with high probability, have also been considered but will not concern us here.)
The security goal is to offer resilience as large as possible, where a scheme has resilience t if an adversary who compromises t nodes I = {i 1 , . . . , i t } is still unable to derive any information about the shared key k i,j for any i, j such that i, j ∈ I. Efficiency considerations require computation of the shared keys to be fast, thus ruling out standard public-key approaches, and dictate that the storage (i.e., the size of the keying information s i ) should be minimized.One simple approach is for all nodes to share a single key k (i.e., set s i = k for all i) that is used also as the pairwise key for any pair of nodes.
While having minimal storage, this scheme has resilience t = 0 since it is completely broken after only one node is compromised.
A second trivial approach is for each pair of nodes to store an independent key.
This has optimal resilience t = N , but the storage requirement of N 2.2 The Scheme of Zhang et al.Zhang et al. [7] suggested a "noisy" version of the above scheme, and claimed that the new scheme has improved resilience for some fixed amount of storage.
Roughly, their idea is to give node i a polynomial s i (y) that is "close", but not exactly equal, to F (i, y).
Nodes i and j can compute s i (j) and s j (i) as before; these results will no longer be equal, but because they are close they can still be used to derive a shared key (by, e.g., using the high-order bits).
The hope was that the addition of noise to the nodes' secret information would prevent reconstruction of the master secret F even if an adversary corrupts many more than t + 1 nodes; in fact, Zhang et al. claim optimal resilience t = N as long as the adversary is computationally bounded.
(Of course, for a computationally unbounded adversary the lower bound from [3] applies.)
We show that this is not the case.
We first describe their scheme in further detail.
Let p be a prime, and let r < p be a "noise bound".
Elements in Z p are represented as integers in [0, p − 1] in the natural way and we freely interchange between the two representations (so, e.g., a < b means that the integer representation of a is smaller than the integer representation of b).
Their scheme operates as follows:Pre-distribution: The authority chooses a random symmetric, bivariate polynomial F ∈ Z p [x, y] of degree t in each variable.
It also chooses at random two univariate degree-t "noise polynomials" g(y), h(y) over Z p .
Let Small be the set of points for which both g(y) and h(y) are small; that is:Small def = {y ∈ Z p : g(y), h(y) ∈ [0, r]}.
For any fixed y ∈ Z p , the probability (over choice of g, h) that y ∈ Small is r 2 /p 2 .
The authority finds (in time O N · p 2 /r 2 ) a set of N points x 1 , . . . , x N in Small.
For each node i, the authority chooses a random bit b i and gives node i the point x i and the univariate polynomials i (y) = F (x i , y) + b i · g(y) + (1 − b i ) · h(y) .
Namely, the noise polynomial is chosen as either g(y) or h(y), depending on the random bit b i .
Key agreement: To compute a shared secret key, nodes i and j exchange their points x i , x j and then node i computes s i (x j ) mod p and node j computes s j (x i ) mod p. Sinces i (x j ), s j (x i ) ∈ {F (x i , x j ), F (x i , x j ) + 1, . . . , F (x i , x j ) + r} ,the points computed by the two parties are close enough that they can be used to obtain a shared key by taking, e.g, the high-order bits of their respective results.
(Zhang et al. describe an interactive protocol to handle wraparound, but this is irrelevant for the attacks we describe.)
Suggested parameters.
The expected size of Small (over random choice of g, h) is r 2 /p, so we require r 2 /p ≥ N .
(Zhang et al. suggest a way to guarantee that the size of Small is at least r 2 /p, but this still requires r 2 /p ≥ N .)
The shared key has length roughly log(p/r), but p/r cannot be too large since the predistribution phase requires O N · p 2 /r 2 work.
If a larger key is desired, multiple instances of the scheme can be run in parallel and the derived pairwise keys concatenated.In Table 1 we list the parameters suggested by Zhang et al.
We note that with these parameters, each node must store a secret key of size ≈ 250κ bits in order to compute κ-bit shared keys.
For the same amount of storage, the original scheme of Blundo resilience to compromise of about 250 nodes.
In contrast, Zhang et al. claim (computational) resilience t = N , an improvement of 1-2 orders of magnitude.
As we will see, this claim is unfounded and the scheme can be broken by an attacker who compromises t + 3 ≤ 80 nodes.
Thus the scheme of Zhang et al. is less resilient (as well as less efficient) than the original scheme of Blundo et al.
We begin by describing a relatively simple attack on the scheme as described above.
We discuss two variants: a very efficient attack that requires corruption of ≈ 4t nodes, and an attack that runs in time O(r) but requires corruption of only ≈ 3t nodes.
Both attacks rely on the error-correction algorithm of Ar, Lipton, Rubinfeld, and Sudan [1].
The first attack works as follows: Compromise n = 4t+1 nodes with points x 1 , x 2 , . . . , x n to obtain the n polynomials s 1 (·), . . . , s n (·).
Choose a point x * ∈ Z p belonging to any non-compromised node v * , and compute y i = s i (x * ) for i = 1, . . . , n. By construction of the s i we haves i (x * ) = F (x i , x * ) + b i · g(x * ) + (1 − b i ) · h(x * ) = f * (x i ) + noise b i , where f * (·) def = F (·, x * ), noise 0 def = h(x * ), and noise 1 def = g(x * ).
Define f * b (x) def = f * (x) + noise b .
Considering the set of pairs {(x i , y i ) : i = 1, . . . , n}, we have that for all i eithery i = f * 0 (x i ) or y i = f * 1 (x i ).
Hence, for at least one of b = 0 or b = 1 we have y i = f * b (x i ) for at least 2t + 1 values of i. Applying the error-correction algorithm of Ar et al.[1], we can recover at least one of the polynomials f * 0 (·) or f * 1 (·).
Once we have either of these polynomials, we can compute the shared key between the node v * (that is associated with the point x * ) and any other node in the network: to get the shared key between v * and another node v associated with the point x , we computey = f * b (x ) = f * (x ) + noise b .
Since noise b ∈ [0, r], we see that y is close to f * (x ) = F (x , x * ).
Hence the high-order bits of y are (essentially) equal to the shared key between the two nodes.A variant of the attack, which requires corrupting only ≈ 3t nodes, is as follows.
Define x * , f * , f * b , and noise b as above; here, set n = 3t + 1.
Assume without loss of generality that noise 1 > noise 0 , and treat the value δ def = noise 1 − noise 0 as known.
(Enumerating over all possible values of δ increases the running time by a multiplicative factor of r.)Corrupt n nodes and compute the set S = {(x i , y i ) : i = 1, . . . , n} as above.
Construct S by adding to S an additional n tuples {(x n+i , y n+i )} where x n+i = x i and y n+i = y i − δ.
Observe that for every tuple (x i , y i ) ∈ S it holds that eitherf * 0 (x i ) = y i , or f * 1 (x i ) = y i , or f * 0 (x i ) − δ = y 1 .
Moreover, for 1 ≤ i ≤ n, either f * 0 (x i ) = y i or else f * 0 (x n+i ) = y n+i ;thus, for exactly n tuples (x i , y i ) ∈ S it holds that f * 0 (x i ) = y i .
The error-correction algorithm of Ar et al. can thus be used to recover f * 0 .
(The rest of the attack proceeds as before.)
For the parameters in Table 1 it always holds that 3t + 1 < 233 and so this already shows that the scheme performs worse than the original, perfectly secure scheme of Blundo et al.
In the following section we show that even a generalized version of the scheme that uses more noise (and is not susceptible to the attack described in this section) is vulnerable to attack, and moreover using only ≈ t corruptions.
The attack described in the previous section relies strongly on the fact that the same noise polynomial is used half the time.
This suggests an easy patch that foils the attack described in the previous section: Let g, h, and Small be as in Section 2.2, and let u be "small" relative to p (we will see exactly how small below).
Now for each node i choose random α i , β i ∈ [−u, u], and give to node i (with identity x i ) the univariate polynomials i (y) = F (x i , y) + α i · g(y) + β i · h(y).
This generalizes the scheme of Zhang et al., since their scheme can be obtained by setting α i = b i , β i = 1 − b i .
The "error polynomial" α i g(y) + β i h(y) still evaluates to a value in a small range (namely, [−2ur, 2ur]) on every point in Small, and so this still allows every pair of parties to compute a shared key.The noise is now larger than in the scheme of Zhang et al. by a factor of 4u, so for the same values of p, r, t the pairwise keys will have roughly log(4u) fewer bits.
Still one might hope that this modification would make the scheme more secure, even for small values of u. Unfortunately this is not the case, and below we present an attack that breaks also this more general scheme in time (roughly) O t 3 + t · (2u) 3 using only t + 3 compromised nodes.
Note that u = 1 for the original scheme of Zhang et al., and so this gives a very efficient attack on their scheme (using fewer compromised nodes than the attack of the previous section).
Furthermore, u cannot be too large: we need 4ur < p in order for even a single-bit shared key to be derived, meaning that in the worst case (for the attacker) the running time of the attack is O t 3 + t · (p/2r) 3 .
Unfortunately, the time required to initialize the scheme is O N · (p/r) 2 , so p/r cannot be too large.
In will be helpful in what follows to identify univariate polynomials of degree-t with vectors of length t + 1.
Specifically, we will identify the degree-t polynomial p(y) = a 0 + a 1 y + · · · + a t y t with its coefficient vectorp = (a 0 , a 1 , . . . , a t ).
Let f i (y) = F (x i , y),where F is the bivariate polynomial chosen by the authority and x i is the point associated with node i.
The polynomial s i given to node i is thus identified with the vectors i = f i + α i · g + β i · h .
The crucial observation underlying our attack is that the "noise" added to f i is drawn from a low-dimensional linear subspace spanned by the two vectors g and h.
The attack proceeds by first identifying this "noise space", then finding the noise polynomials g and h, and finally solving for the bivariate polynomial F .
We describe these steps in the three sections that follow.
The attack begins by corrupting n = t + 3 nodes with associated points x 0 , . . . , x t+2 .
This gives a set of n vectors { s i } t+2 i=0 withs i = f i + α i · g + β i · h .
The "noise space" is the vector space spanned by g and h, and we now show how to identify this space.
We use the fact that the f i are all derived from the same bivariate polynomial F .
Thus, if we write F (x, y) as F (x, y) = t j=0 F j (x) · y j (where each F j is a univariate degree-t polynomial), then for every node i we havef i = (F 0 (x i ), . . . , F t (x i )) .
Recall now the Lagrange interpolation formula: If P is a degree-t polynomial, then for any set of t + 1 points X = {x 0 , x 1 , . . . , x t } and any point x, it holds thatP (x) = t i=0 P (x i ) · j =i x − x j x i − x j L(X,x,i) .
In particular, this formula applies to each of the polynomials F j .
If we compromise t + 3 nodes with points x 0 , x 1 , . . . , x t , x t+1 , x t+2 and set X = {x 0 , x 1 , . . . , x t }, then we havef t+1 − t i=0 L(X, x t+1 , i) · f i = 0 and f t+2 − t i=0 L(X, x t+2 , i) · f i = 0.
(1)Note that we can compute explicitly all the coefficients L(X, x, i) in the equations above.
Taking the same linear combinations of the { s i } we getv def = s t+1 − t i=0 L(X, x t+1 , i) · s i = α t+1 − t i=0 α i · L(X, x t+1 , i) g + β t+1 − t i=0 β i · L(X, x t+1 , i) h ∈ span( g, h) ,and similarlyv def = s t+2 − t i=0 L(X, x t+2 , i) · s i ∈ span( g, h).
Since the α's and the β's are chosen independently and uniformly from [−u, u], it is easy to prove that v and v span the entire space span( g, h) except with probability at most 1/2u.
Experimentally, we find that v and v span the entire space almost surely.
Having computed two polynomials v, v whose associated vectors v , v span the noise space, we now set out to find the original polynomials g and h.
Here we use the fact that g, h are such that g(x i ), h(x i ) are "small" (namely, in [0, r]) for all the x i 's.
Consider the n -dimensional integer lattice Λ spanned by the rows of the following matrix:         v(x 0 ) v(x 1 ) · · · v(x n −1 ) v (x 0 ) v (x 1 ) · · · v (x n −1 ) p 0 · · · 0 0 p · · · 0 . . . . . . . . . . . . 0 0 · · · p          ,(2)where n ≤ t will be fixed later.
Defineg * def = (g(x 0 ), . . . , g(x n −1 )) and h * def = (h(x 0 ), . . . , h(x n −1 )) (where the polynomial evaluation is done modulo p), and note that these are both short vectors (of length at most r · √ n ) in this lattice.
We argue in Appendix A.1 (and verified experimentally) that when n is large enough so that p 2 · (4r/p) n < 1, then with high probability the two shortest (independent and non-zero) vectors in the lattice Λ are ±(g * − h * ) and the smaller of g * or h * .
This allows us to recover g * , h * (and hence the polynomials g and h) using lattice-basis reduction, as described next.
Observe that to ensure p 2 · (4r/p) n < 1, it is sufficient to set n > 2 log p log p−log 4r, which is independent of the degree t. For the parameters suggested in [7] using n = 11 is always enough.
For this small dimension, standard lattice-reduction algorithms can exactly compute all the small vectors in the lattice, including the two shortest vectors that we need.
Denote by 1 , 2 the two shortest (independent and non-zero) vectors in Λ.
As we said above, with high probability one of these vectors is ±(g * − h * ) and the other is the shorter of g * or h * .
In other words, with high probability the original vectors g * , h * belong to the set { 1 , 2 , ±( 1 ± 2 )}.
We can identify g * , h * using the fact that g * , h * ∈ [0, r] n .
(In fact, g * , h * are uniform in [0, r] n since the polynomials g, h are random and the x i 's are chosen subject to the constraint g(x i ), h(x i ) ∈ [0, r].
Thus, with high probability the only vectors in the set { 1 , 2 , ±( 1 ± 2 )} that belong to [0, r] n are the original g * and h * .)
So, given 1 , 2 the original vectors g * , h * can be easily found.
Once we have recovered g and h, we can solve for F itself.
Recall that each of the s i obtained from a compromised node satisfiess i = f i + α i · g + β i · h , where α i , β i ∈ [−u, u].
Using the fact that F is symmetric, we haves i (x j ) − α i · g(x j ) − β i · h(x j ) = f i (x j ) = f j (x i ) = s j (x i ) − α j · g(x i ) − β j · h(x i )(3)for all i = j. Having compromised n = t + 3 nodes, this gives a set of n 2 linear equations in the 2n unknowns {α i , β i } n−1 i=0 .
Naively, we would expect this system to have full rank when n 2 ≥ 2n, in which case we could solve for all the α i , β i and then recover the f i and F itself.
However, this is not the case: the system is under-defined, even if we add to the system the constraints from Eq.
(1).
In fact, the space of solutions to this system of equations turns out to have dimension exactly three, irrespective of t or n. for the rest of the α's and β's and check whether they also lie in the desired range.
(Heuristically, we expect that will overwhelming probability there will be a unique solution to the system of linear equations that also satisfies ∀i : For large u, one could also use lattice-reduction techniques to eliminate the exhaustive search for the α's and β's.
This follows from the observation that the set of solutions to our linear system forms a dimension-three integer lattice, and the desired solution of α's and β's is a short vector in that lattice.α i , β i ∈ [−u, u], We implemented our attack both in C++ using NTL (http://shoup.net/ntl) and in Sage [4] using Damien Stehlé's fpLLL implementation (http://perso.ens-lyon.fr/damien.stehle) to carry out the LLL reduction.
The source code of our attack (in Sage) is available on-line at http://www.bitbucket.org/malb/algebraic_attacks/noise_poly.py.
Our attack ran quickly, and was successful the vast majority of the time; see Table 2 for representative results.
Note that what prevented us from carrying out our attack on larger parameter sets was not the time required for the attack, but the time required to initialize the system!
2.10 Adding More Noise in The Free Term A further generalization of the scheme of Zhang et al. would be to add more noise in the free term of the secret polynomials, setting ur].
Our attack can be easily adapted to break this variant:s i (y) = F (x i , y) + α i · g(y) + β i · h(y) + γ i , where α i , β i ∈ R [−u, u] and γ i ∈ R [−ur,• In the first stage, we recover the noise space but ignore the free term.
That is, we recover the same two polynomials v, v , but instead of having g = a · v + b · v for some scalars a, b, we would have g = a · v + b · v + c · 1, 0, . . . , 0 for some a, b, c (and similarly for h).
• Instead of the lattice from Eq.
(2), we use the lattice that is spanned by the rows of the following matrix:         v(x 1 ) − v(x 0 ) v(x 2 ) − v(x 1 ) · · · v(x n ) − v(x n −1 ) v (x 1 ) − v (x 0 ) v (x 2 ) − v (x 1 ) · · · v (x n ) − v (x n −1 ) p 0 · · · 0 0 p · · · 0 . . . . . . . . . . . . 0 0 · · · p         Note that the values v(x i ) − v(x i−1 ) are independent of the free term of v (and similarly for v ), and that the short vectors in this lattice correspond to the vectors˜ g = g(x 0 ) − g(x 1 ), . . . , g(x n ) − g(x n −1 ) and˜hand˜ and˜h = h(x 0 ) − h(x 1 ), . . . , h(x n ) − h(x n −1 ) .
For this lattice, the two shortest vectors (that can be obtained using lattice reduction) are ±˜g±˜g and ± ˜ h themselves, which allow recovery of the polynomials ±g and ±h except for the free terms.
The free terms can then be approximated by any scalars that force g(x i ), h(x i ) ∈ [0, r] for all the x i .
• The system of equations for the coefficients of F now includes the additional unknowns γ i , and the degree of the solution space would be six rather than three; see Appendix A.2.
(It is also possible to eliminate the γ i 's from the system and arrive at a system that has only three degrees of freedom as before.)
Solving this system would not determine the free term of F , but the free term of F can be approximated by any scalar that makes F (x i , x j ) close enough to s i (x j ) for all i, j. Zhang, Subramanian, and Wang [6] proposed schemes for message authentication in sensor networks.
They begin by describing an initial scheme, called Scheme-I in their paper, that allows a base station to authenticate a message for a set of nodes.
This scheme is information-theoretically secure as long as a bounded number of messages are authenticated, and a bounded number of nodes are compromised.
We describe this scheme here.
Let p be a prime.
The master secret key, stored by the base station, is a bivariate polynomial = f i (m).
The master secret key can be recovered in its entirety if either d n + 1 nodes are compromised, or if d m + 1 messages are authenticated by the base station.
If no nodes are compromised and at most d m messages are authenticated, or if no messages have been authenticated and at most d n nodes have been compromised, the scheme is information-theoretically secure (with probability of forgery 1/p).
F ∈ Z p [x,Zhang et al. present a series of extensions to this basic scheme in their paper.
Scheme-II, as above, enables the base station to authenticate messages for the nodes (i.e., multicast), and Scheme-IV allows for authentication of messages between the nodes (i.e., many-to-many communication).
Zhang et al. also propose a Scheme-III, but they themselves show that it is not secure.
To enhance the security of Scheme-I, Zhang et al. suggest to add noise in the free term of the various polynomials.
Specifically, fix a noise parameter r < p/2.
The secret key of a node i is now the univariate polynomial s i (·) = F (i, ·) + γ i , where γ i is chosen uniformly in [0, r].
Similarly, the authentication tag for a message m is now the univariate polynomial t m (·) = F (·, m)+γ m , where γ u is chosen uniformly in [0, r].
Node i verifies the authentication tag t m on a message m by checking whether |s i (m) − t m (i)| ≤ r, where elements of Z p are viewed as being in the range [−−p/2, p/2].
Zhang et al. claim that an attack on this scheme requires complexity at least r min{dm,dn}+1 , even if an arbitrary number of nodes are compromised and an arbitrary number of messages are authenticated (cf. Theorems 3.2 and 3.3 in [6]).
This scheme is, in fact, easy to break.
Noise is only introduced in the free term, so most of the coefficients of the master polynomial can be recovered by simple interpolation.
If F (x, y) = i,j F j i x i y j , then by compromising d n +1 nodes an attacker can recover all the F j i 's with j > 0, and after seeing d m +1 authentication tags an attacker can recover all the F j i 's with i > 0.
Compromising d n + 1 nodes and seeing d m + 1 authentication tags thus allows the attacker to recover all the coefficients of F except for the free term.
The free term can then approximated by finding any element of Z p for which the resulting polynomial F (x, y) gives node keys and authentication tags whose free term is close to the free term of the keys and tags already observed.
Scheme-III and Scheme-IV in [6] were designed to authenticate many-to-many communication.
These schemes extend Scheme-I by using a tri-variate master polynomial whose three variables correspond to senders, receivers, and messages.
Namely, the master key of the underlying scheme is a polynomial F (x, y, z).
A node i is given two secret keys: the bivariate polynomial F (i, ·, ·) (to be used when it acts as a sender), and the bivariate polynomial F (·, i, ·) (for when it acts as a receiver).
The tag for a message m sent by node i is the univariate polynomial F (i, ·, m); and a receiver j verifies this tag in the obvious way.
Scheme-III is obtained from this underlying scheme by adding noise to the free term, but Zhang et al. observe that the resulting scheme is not secure.
Hence, in Scheme-IV they adopt the perturbation polynomial technique from [7] as described next.In Scheme-IV there are noise parameters u, r with u < r < p/4.
The master secret is again a trivariate polynomial F ∈ Z p [x, y, z] of degree d s (the "sender degree") in x, degree d r (the "receiver degree") in y, and degree d m (the "message degree") in z. Two univariate "noise polynomials" g(x) (of degree d s ) and h(y) (of degree d r ) are also chosen.
These define the sender ID-space Small S (resp., the receiver ID-space Small R ), which contains all the points on which the value of g (resp., h) is "small"; i.e.,Small S def = {x : g(x) ∈ [0, r/u]} and Small R def = {y : h(y) ∈ [0, r/u]}.
The scheme works as follows:• Each node is given two keys: one for when it acts as a sender, and one for when it acts as a receiver.The sender secret key consists of an identity i ∈ Small S and the bivariate polynomial a i (·, ·) = Similarly, the receiver secret key consists of an identity j ∈ Small R and the bivariate polynomial b j (x, z) = F (x, j, z) + γ j · g(x) + δ j with γ j chosen uniformly in [0, u] and δ j chosen uniformly in [0, r].
• The authentication tag computed by a node with sender-ID i on the message m consists of the identity i and the univariate polynomial This scheme can be broken much as in the case of Scheme-II.
A key observation is that noise is only introduced in the coefficients that are independent of the message-variable z. Partition the master polynomial into one polynomial that depends on z and another that does not:F (x, y, z) = i,j,k F i,j,k x i y j z k = dz k=1 z k i,j F i,j,k x i y j F 1(x,y,z) + i,j F i,j,0 x i y j F 2(x,y).
Let h(y) = j h j · y j .
Then the secret key for node with sender-ID w isa w (y, z) = dy j=0 dz k=1 dx i=0 F i,j,k w i y j z k + dy j=1 α w h j + dx i=0 F i,j,0 w i y j + α w h 0 + β w + dx i=0 F i,0,0 w i .
Observe that for k > 0, the coefficient of y j z k in a w depends only on F 1 and not on the noise.
Similarly, for k > 0 the coefficient of x i z k in the receiver polynomial b w (x, z) depends only on F 1 and not on the noise.
This means that once the attacker compromises d x + 1 senders or d y + 1 receivers, it can fully recover the polynomial F 1.
Then, the only part of the master secret key that the attacker is missing is F 2(x, y), which is independent of the message variable z.
This allows easy forgery, as described next.
Given a tag t x * ,m (y) computed by a non-compromised sender x * on a message m, the attacker (who knows F 1) can compute the polynomial∆(y) def = t x * ,m (y) − F 1(x * , y, m) = F 2(x * , y) + α x * h(y) + β x * + η m .
The attacker can now forge the tag of any message m as sent by the same x * , by setting˜ t x * ,m (y) def = F 1(x * , y, m ) + ∆(y) = F 1(x * , y, m ) + F 2(x * , y) + α x * h(y) + β x * + η m * .
Note that this is exactly the tag that the sender x * would have sent if it chose η m = η m * , which means that this is a valid tag for m and would therefore be accepted by all the receivers.
Alternatively, the attacker can apply an attack similar to the one from Section 2 (using the fact that g, h have "small values" on all the identities) to recover also the remaining master polynomial F 2(x, y), and thereafter it can forge messages for any sender.
We omit the details.
Subramanian, Yang, and Zhang [5] presented three schemes for the management of encryption (and decryption) keys, which can in turn be used for protecting sensitive information stored in sensor nodes.
Below we consider the third scheme from [5], which uses a variant of perturbation polynomials.
That scheme is quite involved and contains many details that are not relevant to our attacks.
Hence, we first present a simplified scheme and show how to attack it (cf. Section 4.1), and then explain why the same attacks apply to the full scheme of Subramanian et al.Roughly speaking, Subramanian et al. assume a network where nodes are initialized before deployment, and then deployed to the field where they operate unattended, collecting information from their environment and then encrypting it and storing it locally.
The nodes are willing to send their encrypted data to users who request it, but only users with the appropriate keys can decrypt the information.The lifetime of the system is partitioned in a series of phases, and nodes update their keys from one phase to the next.
The goal of the third scheme from [5] is to be able to provide a user with keys that can be used to decrypt the data from all the nodes in phase i but not any other phase, while minimizing the storage and communication requirements and maximizing the resilience to node compromise and/or user compromise.Underlying the third scheme from [5] is the following polynomial-based solution: The master key is a bivariate polynomial F ∈ F [x, y].
The secret key of node u is the polynomial f u (·) = F (u, ·), and the encryption key used by node u in phase v is K u,v = f u (v) = F (u, v).
A user that needs the keys for phase v is given the polynomial g v (·) = F (·, v) that can be used to compute the keys for all the nodes at this phase asg v (u) = F (u, v) = K u,v .
The problem with this noise-free solution is resilience.
Specifically, Subramanian et al. identified the following three attack scenarios:• When a node u is compromised, the polynomial f u (·) is recovered and the attacker can compute the key K u,v used by u in every phase v. Ideally, we would like the encryption at the nodes to be forward secure so that compromising node u at phase v will not allow the attacker to decrypt the storage from any prior phases.
• If F has degree d x in x, then once the attacker compromise d u + 1 nodes it can recover the entire master polynomial.
• Similarly, if F has degree d y in y, then once a user is given g v for d v + 1 different phases it can recover the entire master polynomial.
To overcome the problems mentioned above, Subramanian et al. proposed to add noise to the free terms of the relevant polynomials.
The system is again defined over F = Z p for some prime p, and we have a noise parameter r p.
The master key is a polynomial F (x, y) of degree d x in x and degree d y in y; the secret key for node u is s u (·) = F (u, ·) + α u ; and the user secret key for phase v is t v (·) = F (·, v)+β v , where α u , β v are scalars that are chosen uniformly at random in [0, r].
The encryption key for node u in phase v is taken to be the high-order bits of s u (v), which are essentially equal to the high-order bits of t v (u).
(The exact mechanism by which a key is derived are not important for our attack.)
Subramanian et al. suggest to use p ≈ 2 64 , r = 2 16 , and a master polynomial of degree 15 in each variable.
This simple scheme does not address the forward-secrecy concern, but it is supposed to provide better resilience than the noise-free scheme from the previous section.
Unfortunately, this is not the case.
Similar to the attack described in Section 3.1, compromising d x + 1 nodes allows an attacker to reconstruct the coefficients of the master polynomial F (x, y) corresponding to all the terms x i y j with j > 0, and learning user keys for d y + 1 different phases allows an attacker to reconstruct the coefficients of the master polynomial F (x, y) corresponding to all the terms x i y j with i > 0.
We now exhibit two different attacks based on this:Attack 1: A simple attack, similar to the one from Section 3.2, requires learning one user key and compromising d x + 1 nodes.
Partition the master polynomial F (x, y) into the part that depends on the phase-variable y and the part that does not; i.e., write F (x, y) = F 1(x, y) + F 2(x).
As noted above, an attacker that compromises d x + 1 nodes can fully recover F 1(x, y).
Given a user key for one phase v (namely, the polynomial t v (·) = F (·, v) + β v ), the attacker can then compute the univariate polynomial∆(x) def = t v (x) − F 1(x, v) = F (x, v) + β v − F 1(x, v) = F 2(x) + β v .
This allows the attacker to derive a user key for any other phase v as˜ t v (x) = F 1(x, v ) + ∆(x) = F (x, v ) + β v .
As in the attack from Section 3.2, we observe that˜tthat˜ that˜t v (x) is a valid user key for phase v and can thus be used to compute the encryption keys of all the nodes in this phase.Attack 2: In this attack the attacker compromises n + 1 nodes for some n > d x , but does not need to learn any user keys.
Denote the IDs of the compromised nodes by u 0 , u 1 , . . . , u n .
As before, the attacker uses the polynomials s u i (·) to recover the bivariate polynomial F 1(x, y) where F (x, y) = F 1(x, y) + F 2(x).
Then, choosing some arbitrary value v * , the attacker can compute for every u i a valuey i = s u i (v * ) − F 1(u i , v * ) = F 2(u i ) + α u i .
(4)Next, the attacker can try to recover F 2 using the fact that all the α u i 's are small (i.e., in [0, r]).
Consider the lattice defined by integer linear combinations of the rows of the following matrix:Λ =                 y 1 − y 0 y 2 − y 1 · · · y n − y n−1 u 1 − u 0 u 2 − u 1 · · · u n − u n−1 u 2 1 − u 2 0 u 2 2 − u 2 1 · · · u 2 n − u 2 n−1 . . . . . . . . . . . .
u dx 1 − u dx 0 u dx 2 − u dx 1 · · · u dx n − u dx n−1 p 0 · · · 0 0 p · · · 0 . . . . . . . . . . . . 0 0 · · · p                 .
(5)(We also let Λ refer to the lattice itself.)
Note that if we write F 2 = dx i=0 f i · x i then there exist integers k 1 , . . . , k n such that(−1, f 1 , f 2 , . . . , f dx , k 1 , k 2 , . . . , k n ) · Λ = (α u 1 − α u 0 , α u 2 − α u 1 , . . . , α un − α u n−1 ),which is a "short" vector in the lattice.
The attacker can thus use lattice-reduction tools to find the coefficients of F 2 (except for the free term).
A heuristic argument similar to the one in Appendix A.1 suggests that when n is large enough so that p (dx+1) · (4r/p) n < 1 then the vector corresponding to the α's is indeed the shortest vector in this lattice.
With the parameters suggested by [5] (i.e., d x = 15, p ≈ 2 64 , and r = 2 16 ), we need n > (d x + 1) log(p)/(log(p) − log(4r)) = (16 · 64)/(64 − 18) ≈ 22.
We verified experimentally that the attack works for those parameters even for n = 22.
Once the attacker recovers the coefficients f 1 , . . . , f dx of F 2, it can approximate the free term of F 2 as in Section 3.1.
This gives it a good enough approximation to the master polynomial F .
The actual scheme from [5] has many additional components on top of the simple scheme from the previous section, but these components have no real impact on the attacks that we have described.
Below we list these additional components and show how the attacks can be tweaked to accommodate them.Many copies of the scheme.
As described in [5], each node stores several univariate nodepolynomials, corresponding to several copies of the scheme.
At any time, one scheme is "active" (i.e., used to encrypt data) while others are "dormant".
Every so often, the central key-distribution center broadcasts some message that causes all the nodes to activate the next copy of the scheme, and then erase all the keying material from the previously active copy.
(Of course, user keys for the current phase always correspond to the appropriate phase of the currently active copy.)
This has very little effect on the attacks: an attacker that compromises some nodes learns the relevant information for all the copies that are stored on these nodes at the time of compromise.
By compromising sufficiently many nodes, it learns the node-key material corresponding to the currently active scheme, as well as to all the schemes that are still dormant.
The only thing that the attacker cannot do is attack copies of the scheme that were already erased.
Also, to mount Attack 1 from the previous section against some copy of the scheme, the attacker must wait until that scheme becomes active (since that attack requires the attacker to learn one user-key that belongs to the copy under attack).
Forward secrecy between phases.
As pointed out above, the simple scheme from Section 4.1 does not address forward secrecy.
Subramanian et al. use the following simple trick to obtain forward secrecy: when a copy of the scheme is activated, the center announces the interval of phases (denoted [v s , v e ]) to be used with that copy.
Each node u then derives the keys for all these phases, setting K u,v as the high-order bits of s u (v) for all v ∈ [v s , v e ]; then the node u erases the polynomial s u corresponding to this copy of the scheme and stores only the keys K u,v .
Thereafter, the key K u,v is used during phase v and is erased when that phase is over.The attacks from Section 4.1 can still be applied to all the dormant copies, since for these copies the nodes must still store the polynomial s u (·).
As for the active copy of the scheme, depending on the size of the interval [v s , v e ] it may be possible to recover the polynomial s u (·) from the K u,v 's by using techniques similar to Attack 2 above.
Namely, after corrupting some node u we have K u,v = s u (v) + ρ v where s u has degree d y and the ρ v 's are all small (i.e., in [0, r]).
As long as we have sufficiently many of these v's, we can use the same lattice reduction techniques as in Attack 2 to recover s u .
Forward-secrecy within a phase.
Instead of using the same key K u,v to encrypt all the information during phase v, Subramanian suggested using the hashed key H i (K u,v ) to encrypt the i'th piece of information.
The only effect of this on our attacks is that the key K u,v is erased earlier from the memory of node u.Polynomial one-time pad.
Another component of the scheme in [5] that is different from the simple scheme described earlier is that the nodes do not store the node-polynomial s u (·) explicitly.
Essentially, a node u stores for each copy of the scheme a "pad polynomial" p u (·) derived from a "master pad polynomial" p(u, v) by setting p u (·) = p(u, ·)−α u for a random α u ∈ [0, r].
To activate the next copy of the scheme, the center chooses at random the master polynomial F (x, y) for the scheme and broadcasts to all the nodes the bivariate polynomial s(x, y) = p(x, y) + F (x, y); node u then computes its node-polynomial ass u (·) = s(u, ·) − p u (·).
It is clear that this has no real effect on our attacks.
Upon compromising a node, the attacker learns the pad polynomials used by that node.
The attacker can apply Attack 2 directly, thus recovering the "master pad polynomial" p(x, y).
The attacker then waits until the center broadcasts s(x, y) and recovers F (x, y) = s(x, y) − p(x, y).
Alternatively, the attacker can wait until that copy is activated, compute all the s u (·)'s just as the nodes do, and recover F (x, y) directly using Attack 1 or Attack 2.
Miscellaneous.
In the actual scheme that is described in [5], the handling of the pad polynomials is slightly obfuscated as follows:• The "master pad polynomials" for the different copies of the scheme are not necessarily independent.
Rather, they are all derived from the same tri-variate polynomial p * (x, y, z), where the master pad for the k'th copy of the scheme is set as p(·, ·) = p * (·, ·, k).
We did not find in [5] a specification of the copy-degree of p * (i.e., the degree of the copy variable z).
Hence, we assume that it is taken as large as the number of copies, so that the copies are truly independent.
(This has no effect on any of the efficiency parameters that are discussed in [5].)
If the copy-degree is smaller, then it is likely that one can find more attacks, where compromising some copies of the scheme allows the attacker to break also other copies.
• The noise in the free term is added in several steps rather than all at once (and is not quite independent between the different copies of the scheme).
Specifically, the pad polynomials are computed by first setting˜psetting˜ setting˜p u (y, z) = p * (u, y, z) − α u , and then the pad for the k'th copy is set as ¯p u,k (y) = ˜ p u (y, k) − α u,k with α u , α u,k all chosen uniformly in [0, r/4].
1• When activating the k'th copy, the center chooses a random master polynomial F k (x, y) for this copy and broadcasts a noisy bivariate polynomials k (x, y) = p * (x, y, k) + F k (x, y) + γ,where γ is uniform in [0, r/2].
Each node u computes its node-polynomial for this copy ass u,k (·) = s k (u, ·) − ¯ p u,k (·).
Obviously, these details have no bearing on our attacks.
We have shown attacks on the schemes from [7,5,6], which are all based on "perturbation polynomials".
Our attacks show that the modified schemes are no better -and may, in fact, be worse -than the information-theoretically secure schemes they are based on.
Our results cast doubt on the viability of the "perturbation polynomials" technique as an approach for designing secure cryptographic schemes.        
g(x 0 ) g(x 1 ) · · · g(x n −1 ) h(x 0 ) h(x 1 ) · · · h(x n −1 ) p 0 · · · 0 0 p · · · 0 . . . . . . . . . . . . 0 0 · · · p          .
(6)(We have substituted g, h in place of v, v ; since v, v and g, h span the same space, the lattice is unchanged.)
Recall that g * (resp., h * ) denotes the first (resp., second) row of the lattice above, and that the length of g * , h * is at most r · √ n .
Let 1 , 2 denote the two shortest (independent and non-zero) vectors in Λ.
We provide a heuristic argument that 1 , 2 ∈ {g * , h * , ±(g * − h * )} with high probability over the initial choice of g * , h * .
The polynomials g and h are chosen during system set-up as random polynomials of degree t, and the x i are chosen such that g(x i ), h(x i ) ∈ [0, r].
Since n ≤ t, the values of g(x 0 ), . . . , g(x n −1 ) are independent and uniform in [0, r] (and similarly for h).
That is, g * and h * are independent and uniform in [0, r] n .
We note that we expect the vector g * −h * to be shorter than both g * , h * (since the expected size of each entry in g * − h * is roughly r/3, as compared to r/2 for each entry in g * , h * ).
We ask what is the probability that there exist some a, b ∈ Z p (with (a, b) / ∈ {(0, ±1), (±1, 0), ±(1, −1)}) such that the vector ag * + bh * mod p is shorter than both g * and h * (where the mod p operation maps integers into the range [−−p/2, p/2]).
We distinguish between "small pairs" where |a|, |b| < p/4r and "large pairs" where at least one of |a|, |b| is at least p/4r.
• For a "small pair", we have no reduction mod p (since ag * + bh * is already in the range [−p/2, p/2]).
Hence, there exists a "small pair" as needed if and only if the integer lattice that is spanned by only two vectors g * , h * contains a vector other than ±(g * − h * ) which is shorter than both g * , h * .
When (a, b) / ∈ {(0, ±1), (±1, 0), ±(1, −1)}, the expected size of each entry in ag * + bh * is larger than r/2 and so we expect ag * + bh * to be longer than g * , h * .
Hence, we expect the two shortest vectors in the lattice spanned by g * , h * to be in the set {±g * , ±h * , ±(g * − h * )} except with probability exponentially small in n .
• For any fixed "large pair" (a, b), the distribution of the vector ag * + bh * mod p is rather close to the uniform distribution over [−−p/2, p/2].
To see this, assume |a| > p/4r.
Fix b and h * to some arbitrary values, and consider the residual distribution on ag * +bh * mod p induced by choosing g * ∈ [0, r] n .
Consider a "simplified setting" where the entries of g * are chosen from the real interval [0, r] (instead of only the integers in this interval).
In this setting, each entry of ag * + bh * mod p would be chosen from a distribution that has statistical distance at most 3/4 from the uniform distibution on [−p/2, p/2].
(When |a| is larger still, the distibution gets even closer to uniform.
For example, for |a| = Θ(p) the distance from uniform is O (1/r).)
The quantization to integers of course changes the distribution, but does not change substantially the probability that the resulting vector is short.Making the heuristic assumption that the length of ag * + bh * mod p is distributed as if that vector were uniform in [−−p/2, p/2] n , we can estimate the probability that this vector lies in the ball of radius r √ n around the origin.
The volume of such a ball is (r √ n ) n π n /2 (n /2)!
≈ r n (2πe) n /2 ≈ (4r) n .
Hence, the probability that a uniformly distributed vector in [−p/2, p/2] n has length below r √ n is upper-bounded by (4r/p) n , and we can heuristically use the same bound also for the length of ag * + bh * mod p for any fixed "large pair" (a, b).
As there are fewer than p 2 "large pairs", a union bound implies that when p 2 · (4r/p) n 1 we expect to have |ag * + bh * mod p | ≥ r √ n for every "large pair".
Experimentally, we observe that for even moderate values of n , the two smallest vectors in the lattice are indeed ±(g * −h * ) and the smaller of g * , h * .
Specifically, we ran the following experiment: generate g * , h * uniformly in [0, r] n and then run LLL on the lattice from Eq.
(6) to compute the shortest vectors 1 , 2 of the resulting lattice.
Call it a "success" if g * , h * ∈ {± 1 , ± 2 , ±( 1 ± 2 )}.
For each setting of p and r, we then determined the minimum value of n for which a success occurred at least 95% of the time (in 200 trials).
The results are in Table 3 Here we explain why the linear system of equations described in Section 2.8 is under-defined, and why the vector space of solutions has dimension 3.
Every solution to our system of linear equations must correspond to a bivariate degree-t polynomial F (due the the inclusion of Eq.
(1)) which is symmetric (due to the equations from Eq.
(3)).
Moreover, for each node associated with the point x i the polynomial F induces coefficients f i such that s i − f i belongs to the vector space spanned by g and h. Let F, F be two polynomials satisfying these constraints, and consider their difference polynomial D = F − F .
This polynomial D satisfies the following three conditions:• D is a bivariate degree-t polynomial (since F and F are);• D is symmetric (since F and F are);• For every i, if we let d i denote the coefficients of the univariate polynomial D(x i , ·), then all the d i 's belong to the vector space spanned by g and h.We now show that there are exactly three degrees of freedom in choosing a polynomial D with these properties.
Denote the matrix of coefficients of D by [D], and denote by [d] The conditions on the polynomial D translate to the conditions that [D] is a (t + 1) × (t + 1) symmetric matrix, and that the rows of [d] are in the vector space spanned by g and h.
The last condition can be expressed in matrix notation by saying that there exists a (t + 1) × 2 matrix X such that[d] = X · g h .
To obtain a D satisfying these conditions, choose an arbitrary symmetric 2 × 2 matrix R and set[D] := g T | h T · R · g h ,where g T and h T (the transpose of g and h, respectively) are column vectors.
This ensures that [D] is a (t + 1) × (t + 1) symmetric matrix, and moreover[d] = V · [D] = V · g T | h T · R X · g has needed.
Since there are three degrees of freedom in choosing a symmetric 2×2 symmetric matrix, we get exactly three degrees of freedom for D.We observe that if we had the additional noise in the free term (as in Section 2.10), then the noise space would be spanned by the three vectors g, h, and e 1 = 1, 0, . . . , 0.
In this case, we can use the exact same argument, except that the matrix R is a symmetric 3 × 3 matrix and so we have six degrees of freedom in choosing it.
(However, the lower-right t × t sub-matrix of D is still rank-2, so once we eliminate the dependence on the free terms we can get back to a system with only three degrees of freedom.)
