Question classification plays an important role in cross-language question answering (CLQA) systems, while question Informer plays a key role in enhancing question classification for factual question answering.
In this paper, we propose an integrated Genetic Algorithm (GA) and Machine Learning (ML) approach for question classification in English-Chinese cross-language question answering.
To enhance question informer prediction, we use a hybrid method that integrates GA and Conditional Random Fields (CRF) to optimize feature subset selection in a CRF-based question informer prediction model.
The proposed approach extends cross-language question classification by using the GA-CRF question informer feature with Support Vector Machines (SVM).
The results of evaluations on the NTCIR-6 CLQA question sets demonstrate the efficacy of the approach in improving the accuracy of question classification in English-Chinese cross-language question answering.
Question classification plays an important role in cross-language question answering (CLQA) systems [11,16], such as NTCIR CLQA (Cross-Language Question Answering) and QA@CLEF (Question Answering at Cross Language Evaluation Forum).
The goal of question classification is to accurately classify a question in to a question type and then map it to an expected answer type (question type determination) [2].
For example, the question classification for "What is the biggest city in the United States?"
(question) is "Q_LOCATION_CITY" (question type).
Question types thus derived are used to extract and filter answers in order to improve the overall accuracy of a cross-language question answering system.Question informer plays a key role in enhancing question classification for factual question answering.
Krishnan et al. [5] introduced the notion of the answer type informer span of a question and showed that humanannotated informer spans substantially improve the accuracy of machine learning-based question classification.
They define question informer as choosing a minimal, appropriate contiguous span of a question token, or tokens, as the informer span of question that is adequate for question classification.
For example, in the question: "What is the biggest city in the United States?"
the question informer is "city".
Thus, "city" is the most important clue for question classification.
In contrast, we define a question informer as the most important clue for question classification.
Hence, in the above example "city" is actually the most important clue.
Note that question informers are only useful if their informer spans can be identified automatically.In machine learning approaches, feature selection is an optimization problem that involves choosing an appropriate feature subset.
Day et al. [3] showed that a hybrid approach that integrates Genetic Algorithm (GA) and Conditional Random Fields (CRF) improves the accuracy of question informer prediction in traditional CRF models.In this paper, we propose an Integrated Genetic Algorithm (GA) and Machine Learning (ML) approach for question classification in cross-language question answering.
Specifically, we focus on a bilingual QA system for English source language queries and Chinese target document collections.
To enhance the hybrid approach for cross-language question classification, we use the GA-CRF question informer feature with Support Vector Machines (SVM).
The remainder of the paper is organized as follows.
Section 2 describes the background to cross language question classification and reviews related works.
In Section 3, we propose an Integrated Genetic Algorithm (GA) and Machine Learning (ML) approach for crosslanguage question classification.
Section 4 discusses the experiment and the test bed, and Section 5 details the experimental results.
Finally, in Section 6 we present our conclusions and indicate future research directions.
Numerous works on question classification for crosslanguage question answering have been reported in literature [2,4,10,13,18,19,21].
Approaches to question classification can be divided in two broad classes, namely, rule-based and machine learning methods.
Most recent studies have been based on machine learning approaches.Li and Roth [10] proposed 6 coarse classes and 50 fine classes for TREC factoid question answering.
The UIUC QC dataset, which they developed, contains 5,500 training questions and 500 test questions, and it is now the standard dataset for question classification [3].
Li and Roth use the Sparse Network of Windows (SNoW) with over 90% accuracy.Krishnan et al. [5] used SVM with question bi-grams, CRF question informer q-grams, and informer hypernyms.
On the UIUC dataset, they derived coarse-grained categories with 93.4% accuracy and fine-grained categories with 86.2% accuracy.Plamondon and Foster [14] proposed a method that relies on a statistical translation engine to translate keywords, as well as a set of manually written rules for analyzing French questions, so that a monolingual English question answering system can be modified to accept French questions.
Using regular expressions that combine words and part-of speech tags to analyze a question, they wrote approximately 60 analysis patterns in both English and French.Kwok and Deng [7] used heuristic rules with cue words and adjacent meta-keywords to assign a possible answer class to an English question and attained approximately 80% accuracy on the NTCIR-5 test set.
In contrast, Day et al. [2] achieved 92% accuracy on the same test set by using an integrated knowledge-based and machine learning approach.Question classification for multi-lingual queries can be performed by a single question classifier or multiple question classifiers.
For instance, in English-Chinese cross-language question answering, there are two strategies for question classification: 1) Chinese Question Classification (CQC) for both English and Chinese queries.
In this case, the English source language has to be translated into the Chinese target language in advance.
2) English Question Classification (EQC) for English queries and Chinese Question Classification (CQC) for Chinese queries.In this paper, we focus on question classification in English-Chinese cross-language question answering, which is a bilingual QA system for English source language queries and Chinese target document collections.
Hence, we adopt a two-question classifier strategy, namely, English Question Classification and Chinese Question Classification, for question classification in English-Chinese cross-language question answering.
We propose an Integrated Genetic Algorithm (GA) and Machine Learning (ML) approach for question classification in cross-language question answering.
The architecture of the proposed, shown in Figure 1, comprises three phases for transforming an input question into output question type: 1) the GA feature selection phase, which uses GA for CRF feature selection to obtain a near optimal feature subset of CRF; 2) GA-CRF question informer prediction, which uses the near optimal CRF question informer prediction model to predict question informers; and 3) SVM-based question classification, which uses the GA-CRF predicted question informers as the key features for SVM-based question classification.
We use CRF++ [6], developed by Taku Kudo, to predict question informers because it allows us to redefine feature sets and specify the feature templates in a flexible manner.
We use GA to generate the best feature templates for CRF++.
The application of GA to obtain the near optimal feature subset of CRF involves the following steps.1) Encode a feature subset of CRF with the structure of chromosomes.
The value of the codes for feature subset selection is set to a one-bit digit, '0' or '1', where '0' indicates that the corresponding feature is not selected, and '1' means that it is selected.
The length of each chromosome is n bits, where n is the number of features.2) Initialization: Generate the initial population, which is initialed with random values before the search process.3) Population: Use the initial population, which is a set of seed chromosomes, to find the optimal feature subsets.
4) Evaluation: Calculate the fitness score of each chromosome.
5) CRF model 10-fold cross validation: Apply the feature subsets derived by the previous procedure to the CRF module.
The fitness function is determined by the Fscore of 10-fold cross validation of the CRF model.
We use 10-fold cross validation on the training dataset of the CRF model as the fitness function of each chromosome to avoid over-fitting on the test dataset.
6) Stopping criteria satisfied?
If the stopping criteria are satisfied the best chromosome and near optimal feature subset of CRF model is obtained; otherwise, apply GA operators and produce a new generation.7) Apply GA operators and produce a new generation: Use three GA operators, namely, reproduction, crossover, and mutation to produce a new generation.In summary, we can obtain a near optimal feature subset of CRF after the GA procedures for CRF feature selection.
We integrate the GA architecture with CRF to optimize feature selection for CRF-based question informer prediction.
This hybrid GA-CRF approach involves two phases: the GA-CRF learning phase with a training dataset, and the CRF test phase with a test dataset.
The experimental results, detailed in Section 5, demonstrate that the hybrid GA-CRF model for question informer prediction improves the accuracy of the traditional CRF model.
For English question classification, we use an SVMbased machine learning approach that incorporates GA-CRF predicted question informers as important features.
Because SVM consistently outperforms other machine learning techniques in several tasks, including text classification [15,17] and question classification [21], we adopt it as the machine learning approach for question classification.
To implement it, we use SVMlight [15], an implementation of Vapnik's Support Vector Machine for pattern recognition.
Training dataset We use Li and Roth's UIUC QC dataset [10] and the corresponding Question Informer dataset from Krishnan et al. [5] to train the classification model.
There are 5,500 training questions, 500 test questions, and the corresponding question informers.
Li and Roth used supervised learning for question classification of the UIUC QC dataset; this is now the standard dataset for question classification [3].
It has 6 coarse-grained and 50 fine-grained answer types in a two-level taxonomy, as well as the above training and test questions.
For English question classification, we use NTCIR-6 CLQA's formal run of 150 English questions (CLQA2T150E) as our test dataset.
Training dataset We use the IASLQ2322C training dataset with 2,322 Chinese questions for our SVM-based CQC.
The questions are derived from three sources: 500 from the NTCIR-5 CLQA development set plus 200 from the NTCIR-5 CLQA test set, 384 from a translated TREC 2002 dataset in Chinese, and 1,238 that are manually built in IASL (http://iasl.iis.sinica.edu.tw).񮽙
Test dataset We use NTCIR-6 CLQA's formal run of 150 Chinese questions (CLQA2T150C) as our test dataset for Chinese question classification.
The following syntactic features and semantic features are used in EQC.1 The following syntactic features and semantic features are used in CQC.1.
Syntactic features We use two syntactic features in our SVM model: bagof words (n-grams) and part-of-speech (POS).
-Bag-of-Words Bag-of-words features are comprised of characterbased bi-grams (CB) and word-based bi-grams (WB).
-Part-of-Speech (POS) We use AUTOTAG [1], a POS tagger developed by CKIP, Academia Sinica, to obtain the POS of the given Chinese questions, and then use the POS features for CQC.2.
Semantic Features -HowNet Senses We use "HowNet 2000" to derive the semantic features of the Chinese questions.
Our SVM Model uses two semantic features, namely, HowNet Main Definition (HNMD) and HowNet Definition (HND).
To enhance the robustness of CQC, we introduced a new semantic feature called TongYiCi CiLin (TYC) [12], a Chinese synonym dictionary, for the machine learning approach of Chinese Question Classification (CQC) in CLQA2.
The TongYiCi we use is an extended version of TongyiciCilin (ECilin for short), developed by the Information Retrieval Laboratory of the Harbin Institute of Technology (http://www.ir-lab.org/).
We use accuracy and the mean reciprocal rank (MRR) [13] to evaluate the performance of question classification.
Given a set of questions, M, their corrected question types, and a ranked list of classification scores, the accuracy of question classification is calculated as follows:questions of number Total types question corrected of Number Accuracy = (1)The MRR of question classification is calculated as follows [13]:∑ = = M i i rank M MRR 1 1 1 ,(2)where rank i is the rank of the first corrected question type of the i th question, and M is total number of questions.
We now present the experimental results of the proposed approach for question classification in EnglishChinese cross-language question answering.
For question informer prediction, the experimental results show that the proposed hybrid GA-CRF model of question informer prediction outperforms the traditional CRF model.
Using GA to optimize the selection of the feature subset in CRF-based question informer prediction improves the F-score from 88.9% to 93.87%, and reduces the number of features from 105 to 40.
Note that the fitness function is used to evaluate the test dataset (UIUC Q500) with the training dataset (UIUC Q5500).
In addition, the accuracy of our proposed GA-CRF model for the UIUC dataset is 95.58% compared to 87% for the traditional CRF model reported by Krishnan et al.
Thus, the proposed hybrid GA-CRF model for question informer prediction significantly outperforms the traditional CRF model.
For English question classification, the fine-grained accuracy is 82.32% for 10-fold cross validation on the training dataset (IASLEQ5288E), and approximately 88.79% for the coarse-grained accuracy.
The features used for SVM-based English question classification are WB (word bi-gram), F1 (first word), F2 (first two words), QIF (question informer), QIFB (question informer bigram), and WH (question wh-word, 6W1H1O: who, what, when, where, which, why, how, and other).
We also conducted an experiment on the training data of IASLEQ5088E and the test data of CLQA1T200E.
The results show that by using Support Vector Machines (SVM), our approach enhances the fine-grained accuracy of English Question Classification (EQC) from 68.0% (WB) to 78.5% (WB+F1+F2+WH+QIF+QIFB).
Meanwhile, the coarse-grained accuracy increases from 71.0% to 83.5%.
We use the 5,288 questions mentioned in Section 4 as our training dataset and the WB+F1+F2+WH+QIF+QIFB features to train our SVM model for the test dataset, which was taken from NTCIR-6 CLQA's formal run of 150 English questions (CLQA2T150E).
The experimental results are as follows.The top-1 accuracy of fine-grained English question classification is 94% for CLQA2T150E.
The results of using different features in SVM models for English question classification are shown in Figure 2.
It is significant that, by integrating GA-CRF-based question informer prediction as a feature, the SVM-based English question classification model performs better than the model that uses the baseline word-based bi-grams feature.
Figure 2.
Experimental results for English Question Classification (EQC) using SVM The features used for SVM-based Chinese question classification are 1) syntactic features: Chinese characters (C), Chinese character-based bi-grams (CB), Chinese words (W), Chinese word-based bi-grams (WB), Part-ofSpeech (POS), and Part-of-Speech bi-grams (POSB); and 2) semantic features: HowNet Main Definition (HNMD), HowNet Definition (HND), TongYiCi (TYC).
We use the 2,322 Chinese questions (IASLQ2322C) as our training dataset, and combinations of syntactic and semantic features (CB+HNMD+HND+TYC) to train our SVM model for the test dataset questions, which are taken from NTCIR-6 CLQA's formal run of 150 Chinese questions (CLQA2T150C).
We compare the contribution of different syntactic and semantic features to the classification performance.
Table 1 shows the results of Chinese Question Classification (CQC) using SVM with different features.
We observe that TYC outperforms HND and HNMD.
The top-1 accuracy derived by using TYC solely is 77.33%, compared to 74.67% for HND solely, and 71.33% for HNMD solely.However, the best Chinese question classification performance is achieved by using a combination of syntactic and semantic features (CB+NHMD+HND+TYC).
Figure 3 shows the results of using SVM with different combinations of features for Chinese question classification.
The top-1 accuracy of fine-grained Chinese question classification using SVM with a combination of syntactic and semantic features is Figure 3.
Experimental results of Chinese Question Classification (CQC) using SVM 78% for CLQA2T150C, while the coarse-grained top-1 accuracy is 90.67%.
In This research was supported in part by the thematic program of Academia Sinica under Grant AS 95ASIA02, and by the National Science Council under Grants NSC 95-2752-E-001-001-PAE and NSC 95-2416-H-002-047.
