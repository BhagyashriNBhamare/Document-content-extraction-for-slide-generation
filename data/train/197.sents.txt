We study the impact of the modifications proposed for TCP in the context of short file transfers.
The two most important proposals are the increment of the initial window size (IW) [3] and the Limited Transmit algorithm (LT) [1].
We analyze analytically and by simulations the effect of these proposals on the TCP latency.
We demonstrate that the LT proposal reduces the TCP latency similarly to the IW proposal however LT is less aggressive than IW.
Nevertheless, in the context of short file transfers we point out a scenario, when upon a single packet loss the sender times out even if IW or LT are enabled.
This harmful scenario happens when the very last packets of the file transfer are lost.
Therefore to avoid this situation we propose a new modification which is based on reducing the number of duplicate acknowledgements TCP reacts to.
In order to avoid the potentially harmful effect of needless retransmissions on the network load we suggest to implement the new modification only for short file transfers.
It has been observed that TCP loss recovery mechanism does not work properly when the congestion window of the TCP sender is small.
This can happen either in transient or steady-state behavior, as for example due to the limit imposed by the receiver advertised window or because of the constraints imposed by a connection with a small bandwidth-delay product link.
In order to avoid this harmful effect several suggestions have been proposed recently.
Probably the two most important ones are the increase of the initial congestion window (IW proposal [3]) and the Limited Transmit algorithm (LT proposal [1]).
In both cases the aim is to decrease the probability of the event that a TCP connection goes into timeout.
A timeout is very harmful for the TCP performance since based on conservative approach its value is normally set to several times greater than the average RTT (round-trip time) [24], which implies a reduction of the average throughput in the case of long-live TCP sessions and an increment of the transfer time in the case of short-live TCP sessions.So far the same TCP algorithm is used regardless the size of the file to be transfered.
However, it is known (see, e.g. [15]) that a TCP session typically belongs to one of the following two kinds: "mice" or "elephants".
Most TCP sessions are "mice" with a small size, but a smaller amount of "elephants" (in terms of flows) is responsible for the largest amount of transfered data (in terms of bytes).
Therefore, it seems to be natural to use a little bit different TCP modifications for different types of flows.
In the present paper we would like to initiate the research on this subject.
Still we first want to concentrate our efforts on short-live TCP transfers.
We evaluate both analytically and by simulations the performance of the IW and LT proposals.
We point out two situations when upon a single loss event the sender will inevitably timeout even with the IW and LT proposals.
We propose further modifications in order to decrease the probability of timeout events.
We suggest to use these modifications only for "mice" type TCP transfers.The rest of the paper is organized as follows, Section 2 outlines a recursive approach for the calculation of the expected transfer time for short TCP session.
The detailed version of this approach can be found in [6].
Section 3 provides the performance analysis for IW and LT proposals.
In section 4 the numerical results are presented and further possible TCP modifications are discussed.
In this section we explain the model we use to calculate the expected time of a TCP file transfer, for a complete explanation we refer the reader to [6].
The expected latency is computed conditioning on the number of losses.
The input parameters for the model are the packet loss probability ¡ , the average round trip time¢ ¤ £ ¥ £, the document size to be transfered ¦ § , the initial window sizë sizë © , the initial slow start threshold¨, threshold¨ threshold¨, the maximum receiver's advertised window and the number of packets the receiver acknowledges by one ACK (delAck option).
The fluid model [5] approach is used to represent the evolution of the congestion window.
In particular, this means that instead of a discrete number of packets, a continuous volume of data (of course, with the same size) is transfered over the network.
It turns out that the fluid model approach is more analytically tractable than the discrete one.
As in all related previous works [12,20,22] the assumption that packets are lost independently with probability ¡ is used.
Thus the expected latency for a file size of using the recursive approach as outlined below.First we calculate¡ ' ¦ § ¤which is the probability of having retransmission when ¦ § bytes are transmitted [6].
¡ ¦ § ¤ ¦ ¥ ) ( 1 0 2 4 3 6 5 7 9 8 © A @ % B C ¦ § E D G F I H ¤ Q P R P S ¤ T ¤ © £ UThe parameter C corresponds to the amount of data successfully transmitted between two consecutive losses.
Given that packets are lost in an independent fashion the number of packets successfully sent between two consecutive losses has a geometric distribution.
To adapt this assumption to the fluid model, the standard approximation of the geometric distribution by an exponential distribution is used.
Therefore the parameter C of the exponential distribution can be determined from the following relation ` h g ¥ § i T r H D X s Y ¡ `¤ Q P p P q ¢ ¤ £ ¥ £ ¢ ¨ © ¢ ¨ ¤ H f t ¨ © v u T H D X 1 Y ¡ `¤ Q P p P q ¢ ¤ £ ¥ £ E wThere is yet another situation when the sender will inevitably timeout.
Namely, if a loss occurs when the remaining amount of data is less thanX 1 Y ¡ ` Q P p P, no matter what the actual value of the sending rate is, the sender will not receive three duplicate ACKs and will have to rely on a timeout to detect the loss.These two scenarios can be very harmful from the performance point of view.
The TCP retransmission time¢ ¤ £ y xis based on measured round-trip times between sender and receiver as specified in [24] and therefore to avoid retransmissions of packets that are only delayed and not lost the minimum¢ £  xis conservatively chosen to be 1 second.
For computational purposes we substitute the value of the timeout¢ £  x with the expression   %  r H 1 & ¢ T "  ¢ ¤ £ ¥ £  ¤as suggested in [14].
Anyhow at some future point it might be suggested that a smaller value minimum leads TCP to a better performance [24].
Let us analyze what can happen during the transmission of a file when a packet is lost.
We consider three scenarios depending the amount of bytes § sent before the loss occurs, see (Figures 1, 2 and 3).
In Figure 1 bytes.
In the second scenario, Figure 2, the TCP sender will detect the loss event upon the reception of three duplicate ACKs.
In this case the TCP sender will halve its sending ratë tö i q f  F Q P p P q ¢ £ £.
This approximation on the remaining data allows us to keep exact track of the evolution of the sending rate.
In this scenario the total transfer time will be equal to the sum of the time required to send § bytes with the initial parameters and the time required to send ).
After a timeout, the value of¨© of¨ of¨© andäre and¨ andäre changed according to [2].
In particular, the value of¨© of¨ of¨© , regardless the value of the sending rate just before the timeoutï timeout¨timeoutï , must be set to no more than 1 packet and the new value for the slow-start threshold is¨¡tö i q f  F Q P p P q ¢ £ £as the density function of the amount of data § that is sent before the first loss occurs given that loss events happened during the transmission of ¦ § data.
This density is related to the uniform distribution, namely, the distribution of the amount of bytes sent before the first loss § is the minimum of independent uniformly distributed random variables [13].
Thus the corresponding density function is given by¨ one can calculate the expected latency by formula (1).
tö i q f  F Q P p P q ¢ £ £The validation of this result and its comparison with formulas derived in [12,20] is given in [6].
One of the distinct features of our approach is the fact that it is capable to model accurately and easily the situations when the sender timeouts.
Our model permits to study the impact of the initial window parameter in a straightforward manner since it is one of the input parameters.
Some adaptation is however needed to model the limited transmit algorithm.
This algorithm is described in detail in [1].
The basic idea is to make TCP react to two duplicate ACKs instead of three duplicate ACKs in an attempt to avoid timeout events without making TCP more aggressive.
With LT algorithm the TCP sender will send two new packets upon the arrival of two duplicate ACKs and eventually it will receive a third duplicate which will trigger off fast retransmission and fast recovery phases.
Let us define as ) the limited transmit algorithm will take over and eventually the sender will get into fast retransmission, and finally we have the scenario when upon a loss event the sender will receive three duplicate ACKs from the beginning (¨data and it does not take the decision to retransmit any packet till X s Y ¡ ` packets are received.
Further, if the TCP sender's congestion window does not allow to receive two duplicate ACKs (¨ i u r H D X s Y ¡ P 4 ¤ Q P p P q ¢ ¤ £ ¥ £ ) it will timeout upon a loss event, ifi ¡ r H D X s Y ¡ 5 P 4 ¤ Q P p P q ¢ ¤ £ ¥ £ ).
For the sake of simplicity in our model we consider two different possibilities, where either the sender will timeout or it will get into fast retransmission directly upon the reception of X s Y ¡ P 4 duplicate ACKs.
For this purpose it is enough to redefine the parameter § ` h g and to use the model described in Section 2.
In the case the initial window is less than three packets the value of § ` h g is given by§ ` h g ¥ § % i r T H D X 1 Y ¡ 5 P 4 ¤ Q P p P q ¢ ¤ £ ¥ £ ¢ ¨ © ¢ ¨ ¤ H 1 t ¨ © u r H D X s Y ¡ 1 P 4 ¤ Q P p P q ¢ £ £  w In the previous section we have introduced a model to calculate the TCP latency and we have explained under which circumstances a single lost packet will make the TCP sender timeout.
This model provides several interesting and useful conclusions.
For instance, calculating with the theoretic model the expected conditional latency, we have observed a very interesting phenomena -the non monotonicity of the expected conditional latencies, see Figure 4.
This behavior is due to the conservative value of the retransmission timer, see Section 1.
In fact, there exists a threshold of the file size ( P ( # ) $ , such that if the file size is less than this threshold a loss will inevitably lead to a timeout.
(see Figure 5).
In the previous example, we observe in Figure 4 that the maximum conditional latency given one packet is lost corresponds to .
To justify this result we have to explain that the last segment who provokes the sender to timeout corresponds to the first one of the congestion window of size¢ Q P p P.
It is clear that if this segment is lost a timeout will happen since the sender will only receive two duplicate ACKs.
If this segment is sent successfully and the next one is lost, the sender will send two new packets upon reception of the ACK corresponding to the successfully transmitted segment.
The receiver will receive three out of order packets and thus it will send back three duplicate ACKs who will make the sender enter fast recovery and avoid a timeout.
Of course the analysis of delAck is much more complicated in reality and there are many phenomena that have not been taken into account in this simple derivation.In Tables 1 and 2 could be considered.
In actual TCP implementation the value ofX s Y ¡ `is set to three so TCP will avoid spurious retransmissions.
With LT algorithm we improve the performance of TCP without being more aggressive since no packet is retransmitted till three duplicate ACKs are received.
In the context of short TCP file transfers the sender faces two different harmful scenarios.
The first scenario corresponds to the situation when the size of the congestion window size does not allow the sender to receiveX 1 Y ¡ ` duplicate ACKs (X s Y ¡ P 4in the case of LT) and the second scenario when 4 For example in the beginning of the transmission, or after timeouts where initial window is set to 1 packet and the slow-start threshold is set to the half of the current congestion size 5 For example when upon a loss event the TCP sender enters into fast-recovery or after certain timeouts when the initial window is set to 1 packets and the Slow-Start threshold to 2 6 Some systems use an adaptive implementation for very short flows than can be modeled well with b=1 [12].
any packet lost out of the lastX 1 Y ¡ `packets will make the sender timeout.In the case of short files the occurrence of a timeout deteriorates severely the performance since the retransmission timer is typically much greater than the average¢ ¤ £ ¥ £.
Therefore it is necessary to introduce some changes to improve the transfer of short files.
Thus we propose to modify TCP for short file transfers as follows: ¢ In order the reduce the probability of timeouts because of small congestion window size we propose to use the LT algorithm with parameterX 1 Y ¡ Q P 4 ¥ H.
This implies that considering a initial value for the window size of¨© of¨ of¨© ¥   or greater TCP will be able always, regardless the value of , to recover from a single loss without having to rely on a timeout.
If the sender receives a duplicate ACK corresponding to one of the lastX s Y ¡ # `packets, we propose that TCP retransmits immediately the lost packet.
With this modification only the very last packet of the file will provoke a timeout.In order to allow retransmissions upon reception of a single duplicate ACK it is mandatory to have a small probability of packet reordering in the network.
Recent studies [23] point out 2/3's of the Internet paths had routes persisting for either days or weeks.
In this section we use the theoretic model to evaluate the benefit obtained using the different proposals and we validate the results with NS simulations.
Let us consider the simple topology a single link with are chosen in such a way so we can model TCP behavior in terms of "rounds", where a round starts with the transmission of the first packet of the congestion window and ends when the sender receives the last acknowledgment.
In order for this assumption to hold, the Bandwidth-Delay product has to be greater than the maximum window size.
This assumption is the responsible of the stair case pattern for the simulated conditional latency in the case of no losses since all the file sizes that need the same number of "rounds" will require the same amount of time to be transfered.
Increasing the initial window has several advantages [3], as for example avoiding timeouts due to not enough ACKs at the beginning of the transfer, elimination of up to three¢ ¤ £ ¥ £, elimination of a delayed ACK timeout and hence it reduces in general the transmission time.
When thë is increased TCP becomes more aggressive and it has been observed that under certain conditions TCP sessions would have performed better starting with a small initial window.
In the context of short TCP transfers the beneficial effect of increasing the initial window is clear from the observation of Tables 1 and 2 and it is related to the reduction of § ` h g .
However it does not have a beneficial effect on reducing timeouts at the end of transmission.Observing Tables 1 and 2 for ¥ H ¢  we see that the similar benefit can be achieved using the LT algorithm, which is less aggressive modification than IW.
Let us study to what extent LT is beneficial.
In Figures 6 7 we depict the conditional latency with and without LT algorithm.
We observe that the utilization of LT algorithm does not solve completely the problem of timeouts and the value of packets.
However, as we will show later, LT algorithm will benefit long-live TCP sessions reducing notably timeout probability.
in Section 3.1.
As one can see the transfer time of a file is significantly reduced in the case when the loss event happens during the transfer.
Finally we would like to note that our proposal brings a dramatic improvement of the TCP latency given the file transfer experiences a loss.
For instance, one can see from Figure 10 that, given the file size experiences a loss, the LT proposal decreases the transfer time of a In this paper we carry out the analysis of IW and LT proposals which aim to improve the performance of TCP.
We demonstrate that the LT proposal brings similar benefits as the IW proposal but it is less aggressive.
Then we show neither of these proposals completely achieve their goal in the context of short TCP transfers.
In particular, this is because of the fact that they do not take into account the losses at the end of the file transfers which lead inevitably to timeouts.
This deficiency could be corrected by reducing the number of duplicate acknowledgments which allow the packet loss detection.
In particular, this modification reduces significantly the TCP latency given the file transfer experiences a packet loss.
Of course, our proposal is a more aggressive modification than IW and LT, since it might result in unnecessary packet retransmissions.
However, if one uses this modification only for the transfer of short files, it will not lead to a large additional network load.
We recall that the total contribution of the short-live TCP transfers to the Internet traffic is small in terms of bytes [15].
For instance, in this work we have considered as short, sessions which are smaller than
